,FEATURE REQUEST,DuplicatedCode,LargeClass,LongMethod,ExtractInterface,ExtractMethod,ExtractSuperclass,InlineMethod,MoveAndRenameClass,MoveAttribute,MoveClass,MoveMethod,PullUpAttribute,PullUpMethod,PushDownAttribute,PushDownMethod,RenameClass,RenameMethod
0,add  relmetadataprovider  parameter  standard  planner  program  program  class  static  method  standard  used  default  calcite  driver  far  calcitephoenix  using  sql  prepare  logic  slight  customization  like  plugging  set  rule  static  standard  though  work  properly  phoenix  since  subprogram  return  initiated  default  relmetadataprovider  phoenix  need  plugin  otherwise  could  work  code  program  convert  filter  project  link  calcs  public  static  final  program  calcprogram  hepcalcrules  true  new  defaultrelmetadataprovider  program  expands  subqueries  public  static  final  program  subqueryprogram  hep  immutablelistofreloptrule  subqueryremoverulefilter  subqueryremoveruleproject  subqueryremoverulejoin  true  new  defaultrelmetadataprovider  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1,allowing  sqloperator  overridden  validation  calcite  allows  function  overridden  validation  step  specific  user  provide  sqloperatortable  validation  step  sqloperatortable  called  method  lookupoperatoroverloads  get  overriding  function  however  far  sqloperator  eg  etc  mechanism  yet  since  system  eg  apache  drill  would  flexible  typechecks  sqloperators  operand  mechanism  necessary  system  pas  validation  step,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2,add  support  translate  expession  fromstring  tostring  calcite  follows  standard  sql  reference  sql  reference  isoiec  907522011e  section  630  character  transliteration  translate  left  paren  character  value  expression  using  transliteration  name  right  paren  need  add  support  translate  expession  fromstring  tostring  alternative  syntax  ex  add  oraclestyle  translate  function  sqlstdoperatortable  call  say  translate3  since  3  parameter,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3,extend  simplify  reducing  expression  would  like  cover  case  expression  simplification  x5  x  null  x5  x5  x  null  satisfiable  x5  x5  satisfiable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4,add  support  timestampadd  timestampdiff  function  calling  timestampadd  timestampdiff  first  parameter  sqltsimicrosecond  sqltsifracsecond  deprecated  leave  older  version  compatibility  sqltsisecond  sqltsiminute  sqltsihour  sqltsiday  sqltsiweek  sqltsimonth  sqltsiquarter  sqltsiyear  ex  timestampaddsecond  1  currentdatetime  calcite  throw  error  caused  orgapachecalcitesqlparsersqlparseexception  encountered  second  line  1  column  25  expecting  one,1,0,1,0,1,0,0,0,0,0,1,0,0,1,0,0,1
5,add  unary  operator  support  isnull  isnotnull  reximplicationchecker  currently  support  sql  comparison  operator  sqlkindcompare  checking  one  predicate  implies  another  using  reximplicationchecker  would  like  extend  couple  unary  operator  based  user  request  calcite1104  isnull  isnotnull,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6,add  projectremoverule  preprocessing  program  materialization  substitution  volcanoplanner  apply  simple  preprocessing  hep  program  normalize  target  query  rels  materialization  substitution  currently  program  run  two  rule  filterprojecttransposerule  projectmergerule  need  extra  rule  projectremoverule  phoenix  use  case  secondary  index  modeled  materialized  view  defined  view  materialized  view  queryrel  may  identity  projection  introduced  view,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
7,send  back  errorresponse  failure  parse  request  trying  debug  issue  asf  jenkins  noticed  serialization  error  result  errorresponse  sent  back  client  serverside  stacktrace  lost,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
8,improve  twolevel  column  structure  handling  calcite  support  nested  column  structure  parsing  validation  representing  innerlevel  column  rexfieldaccess  based  rexinputref  meanwhile  flatten  inner  level  structure  wildcard  expansion  would  cause  unsupportedoperationexception  avatica  idea  take  account  nested  structure  column  resolving  flatten  structure  translating  relnoderexnode  example  table  structure  defined  codevarchar  k0  varchar  c1  recordtypeinteger  c0  integer  c1  f0  recordtypeinteger  c0  integer  c2  f1code  viewed  flat  type  like  codevarchar  k0  varchar  c1  integer  f0c0  integer  f0c1  integer  f1c0  integer  f1c2code  1  column  reference  k0  translated  0  2  column  reference  f0c1  translated  3  3  wildcard  translated  0  1  2  3  4  5  4  complexcolumn  wildcard  f1  translated  2  3  would  like  resolve  column  based  following  rule  consider  suffix  part  qualified  name  mean  table  resolving  already  done  time  twopart  column  name  matched  firstlevel  column  name  secondlevel  column  name  example  f1c0  corresponds  4  f1x  throw  column  found  error  b  singlepart  column  name  matched  nonnested  column  first  match  matched  secondlevel  column  name  example  c1  matched  1  instead  3  since  nonnested  column  higher  priority  c2  matched  5  c0  lead  ambiguous  column  error  since  exists  f0  f1  c  would  also  like  way  defining  default  firstlevel  column  precedence  column  resolving  firstlevel  column  example  f0  defined  default  c0  cause  ambiguous  column  error  instead  matched  2  reference  firstlevel  column  without  wildcard  allowed  eg  f1,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
9,add  new  rule  materialised  view  optimisation  join  query  keep  track  adding  new  rule  would  enable  optimisation  using  view  join  query  instance  materialised  view  table  x  named  xpart  defined  query  select  x  xa  20160101  expect  following  query  optimised  xpart  select  x  inner  join  xid  yxid  inner  join  z  yidzyid  xa  20160202  yb  bangalore  following  change  done  quark  planning  pull  calcite  1  add  new  rule  filter  tablescan  basically  predicate  pushed  join  onto  table  scan  new  rule  check  optimised  materialised  view  httpsgithubcomqubolequarkblobmasteroptimizersrcmainjavacomqubolequarkplannermaterializedviewfilterscanrulejava  2  add  new  unify  rule  materialisedsubstitutionvisitor  httpsgithubcomquboleincubatorcalcitecommit2d031d14d23810291377d92dc5ef2eaa515d35b7,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
10,add  method  sqloperatorbinding  determine  whether  operand  literal  drill  type  inference  decimal  colorred  literal  color  treated  double  case  however  sqloperatorbinding  method  tell  caller  operand  literal  jira  proposes  adding  helper  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
11,add  view  name  viewexpander  viewexpanderexpandview  call  already  schema  path  contains  view  view  name  context  useful  also  know  name  view  expanded  current  call  code  relroot  expandview  reldatatype  rowtype  string  querystring  schemaplus  rootschema  liststring  schemapath  code  proposed  code  relroot  expandview  reldatatype  rowtype  string  querystring  schemaplus  rootschema  liststring  schemapath  string  viewname  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
12,lazy  evaluate  rexcall  digest  currently  rexcall  compute  digest  eagerly  constructor  also  compute  digest  every  time  tostring  invoked  may  cause  performance  issue  rexcall  tree  large,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
13,standardize  code  style  import  package  house  style  specify  whetherwhen  import  converted  star  propose  import  converted  star  3  package  thus  code  import  abc1  import  abc2  import  abc3  code  becomes  code  import  ab  code  abc4  added  consistent  intellijs  default  rule  ok  use  star  3  fewer  us  thus  removing  use  abc2  would  require  import  changed  checkstyle  rule  ban  star  import  excluding  certain  package  allow  limited  particular  number,0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,0,1
14,add  statistic  spi  lattice  optimization  algorithm  optiq427  added  optimization  algorithm  choose  initial  set  tile  materialize  rowcountestimate  attribute  number  row  lattice  add  spi  generate  estimate  number  row  lattice  b  number  row  given  tile  lattice  specified  dimension  also  add  default  implementation  spi  executes  sql  query  cache  result  us  kind  approximation  cardinality  set  attribute  eg  quarter  4  distinct  value  year  10  distinct  value  year  quarter  40  distinct  value  perhaps  expectation  3979  distinct  value  table  3650  row  per  formula  n  1  n  1  n  p  implementation  read  stats  external  stats  table  execute  sql  sample  small  percentage  row  would  also  possible,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
15,make  parser  accept  configurable  max  length  sql  identifier  calcite  currently  us  128  maximum  length  sql  identifier  would  like  enhance  sql  parser  system  able  choose  identifier  max  length  following  discussion  copied  dev  mailing  list  jinfeng  calcite  formly  optiq  set  maximum  length  sql  identifier  128  sound  quite  reasonable  ordinary  sql  identifier  however  system  like  drill  allows  user  query  file  directly  quite  likely  run  allowed  identifier  length  drill  allows  use  case  select  dfsschemadirectory1directory2filenamejson  directory  plus  filename  parsed  sql  identifer  since  many  file  system  would  allow  file  name  255  byte  1  likely  user  could  use  identifier  128  byte  query  file  directly  would  like  ask  calcite  community  whether  performance  impact  bump  maximum  length  sql  identifier  negligible  performance  impact  make  maximum  length  configurable  sql  parser  could  make  slightly  modification  combinedparserjj  template  allow  system  set  max  length  default  still  128  approach  allow  configurable  setting  seems  match  postgres  2  allows  length  raised  changing  namedatalen  constant  srcincludepgconfigmanualh  2  julian  system  able  choose  identifier  max  length  iâ€™d  prefer  make  configurable  runtime  test  add  extra  parameter  sqlparserâ€™s  constructor  call  parsersetidentifiermaxlength  similar  call  setquotedcasing  right  want  go  create  interface  sqlparserconfig  int  identifiermaxlength  casing  quotedcasing  casing  unquotedcasing  replace  parameter  sqlparserâ€™s  constructor  one  config  parameter,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
16,use  usergiven  name  reloptutilcreateproject  createrename  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
17,allow  tablemacro  consume  map  collection  actually  possible  pas  tablemacro  smth  like  codetablemytablesimplename  map  key  value  anotherkey  anothervalue  code  sqluserdefinedtablemacroconvertarguments  lead  illegalargumentexception  argument  call  macro  xxx  literal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
18,add  reldistribution  trait  exchange  relational  expression  calcite  increasingly  targeting  support  distributed  execution  engine  distributed  sql  engine  shuffleexchange  operator  shuffle  data  deamons  runtime  system  useful  add  notion  shuffle  relnode  first  class  citizen  calcite,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
19,add  avatica  support  gettables  per  title,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
20,connection  isolation  avatica  client  avatica  manage  independent  connection  underlying  data  source  client  connection  client  isolated  one  statement  dont  collide  anothers,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1
21,pas  serverside  exception  back  client  avatica  rpc  response  object  contain  exception  field  deserialized  rethrown  client  side  way  client  see  stack  trace  meaningful  500  error,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1
22,implement  connectionsync  rpc  per  thread  dev  list  titled  avatica  handling  connection  state  ticket  implement  rpc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
23,dml  avatica  split  execute  fetch  request  0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
24,use  factory  materializationservice  create  table  follow  conversationhttpsmailarchivesapacheorgmodmboxincubatorcalcitedev201503mbox3ccang6qpx7elmurkxrty09ygw7gchmnrssdnrcqend3z3djcx3dgg40mailgmailcom3e  two  task  1  use  factory  create  table  represent  materialized  view  2  add  entry  schema  materialized  table  created  definematerialization  ill  open  wip  progress  soon  1  easy  implement  2  proving  hard  rest  code  requires  calciteschematableentry  object  available  table  added  schema  dont  know  get  object  existing  entry,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
25,commit  functionality  exposed  rpc  server  seems  commitrollback  functionality  exposed  rpc  server  mean  usable  autocommit  mode  avatica  doesnt  concept  commit  rpc  remote  jdbc  connection  raise  exception  calling  commit  phoenix  native  jdbc  connection  implement  commit  rpc  need  extended  allow  calling  remotely  easiest  way  test  autocommit  commit  fails  sqlinethinpy  work  sqlinepy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
26,provide  way  avatica  client  query  server  version  currently  doesnt  seem  way  avatica  client  find  avatica  rpc  protocol  version  version  server  component  use  case  allow  apache  phoenix  client  request  avatica  version  phoenix  version  hbase  version  phoenix  query  server,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
27,register  combination  materialization  substitution  query  multiple  table  reference  could  1  multiple  combination  substituted  rels  one  materialization  applicable  one  subtree  2  multiple  combination  substituted  rels  different  materialization  applicable  different  subtrees  respectively  code  test  public  void  testsinglematerializationmultiusage  string  q  select  n  select  emps  empid  300n  join  select  emps  empid  200  using  empid  try  preparethreadtrimsettrue  materializationservicesetthreadlocal  calciteassertthat  withmaterializationsjdbctesthrmodel  m0  select  emps  empid  500  queryq  enablematerializationstrue  explainmatches  new  functionresultset  void  public  void  applyresultset  try  final  string  actual  utiltolinuxcalciteasserttostrings  final  string  scan  enumerabletablescantablehr  m0  asserttrueactual  two  occurrence  scan  stringutilscountmatchesactual  scan  2  return  null  catch  sqlexception  e  throw  new  runtimeexceptione  sameresultwithmaterializationsdisabled  finally  preparethreadtrimsetfalse  test  public  void  testmultimaterializationmultiusage  string  q  select  n  select  emps  empid  300n  join  select  emps  deptno  10  using  empid  try  preparethreadtrimsettrue  materializationservicesetthreadlocal  calciteassertthat  withmaterializationsjdbctesthrmodel  m0  select  emps  empid  500  m1  select  emps  deptno  20  queryq  enablematerializationstrue  explaincontainsenumerabletablescantablehr  m0  explaincontainsenumerabletablescantablehr  m1  sameresultwithmaterializationsdisabled  finally  preparethreadtrimsetfalse  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
28,enable  client  recover  missing  serverside  state  deploying  one  instance  avaticaserver  desire  treat  collection  server  single  server  ideally  want  avaticaclient  operate  manner  doesnt  expect  server  specific  state  example  avaticaclient  able  know  server  doesnt  statement  id  client  think  client  create  new  statement  desirable  allows  u  use  generic  loadbalancer  client  server  without  need  clustering  sticky  session  downside  face  failure  operation  take  longer  normal  even  performance  hit  long  avaticaserver  exists  client  still  retrieve  result  query  ideal  tldr  take  longer  client  still  get  answer  two  major  area  need  addressed  presently  1  automatic  recreation  statement  cached  2  recreation  resultsets  resume  iteration  fetch  depends  stable  result  underlying  jdbc  driver  otherwise  external  synchronization  would  required  considered  prerequisite,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
29,pas  url  connection  property  avatica  server  ticket  proposes  ability  pas  connectioncreationtime  property  info  remote  avatica  driver  avatica  server  use  case  phoenix  property  like  currentscn  tenantid  similar  usecases  custom  driver  company  work  user  password  property  enables  authentication  cfr  calcite519  calcite643  see  also  discussion  mailing  list  httpmailarchivesapacheorgmodmboxincubatorcalcitedev201510mbox3ccaaf1jdizbrumfo2cfruoxphbbf3dyq5t2bd2b1ig1fzknvdj8rgoa40mailgmailcom3e  thing  consider  remote  driver  might  property  like  url  passed  server  remote  driver  responsible  removing  server  might  want  disallow  setting  property  remotely  eg  allow  connect  different  database  currently  avatica  server  creates  default  connection  though  marked  removal  using  authentication  particularly  annoying  since  need  start  server  url  containing  user  password  attach  patch  based  calcite  14  add  ability  pas  property  part  new  openconnectionrequest  rpc  call  creationconnetionrequest  proposed  different  reason  calcite663  authentication  reason  mentioned  default  connection  also  dropped  one  jdbcmeta  instance  server  side  manages  map  connection  since  connection  already  created  per  clientside  connection  different  except  connection  created  explicitly  implicit  connection  creation  dropped  look  autorecreation  connection  part  recovery  calcite903  somewhat  hacky  thing  patch  addition  avaticaconnectionsetid  let  server  decide  connection  id  seemed  logical  first  though  easily  reversed  remotedriver  creates  extra  service  instance  able  openconnection  request  request  happen  within  remotemeta  patch  also  pass  error  message  back  client  simple  improvement  towards  calcite645  call  metadata  getcolumns  also  connection  id  fixing  calcite871  becomes  easy  patch  ready  well  patch  acceptable  rework  master  14,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
30,match  materialized  view  predicate  contain  string  range  continuation  calcite786  query  optimized  using  materialized  view  earlier  supporting  predicate  specifying  range  variable  eg  x  90  x  30  would  able  optimize  even  predicate  used  either  query  specify  view  also  adding  support  string  optimization,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
31,make  httpserver  configurable  met  case  increase  requestheadersize  currently  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
32,organize  applicable  materialization  reversed  topological  order  calcite890  try  applying  materialization  possible  substitution  combination  work  fine  applicable  materialization  independent  dependent  materialization  order  materialization  perform  substitution  matter  example  table  b  materialization  table  c  us  another  materialization  table  us  table  c  b  thus  apply  materialization  c  applying  materialization  right  output  applicable  materialization  list  iterate  input  materialization  list  could  random  order  actually  directed  graph  used  find  applicable  materialization  also  take  advantage  graph  organize  desired  order,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
33,support  stream  join  stream  join  used  relate  information  different  stream  stream  relation  combination  calcite  lack  proper  support  streamtorelation  join  streamtostream  join  streamtorelation  join  like  fails  sql  validation  stage  select  stream  ordersorderid  ordersproductid  productsname  order  join  product  ordersproductid  productsid  product  stream  query  valid  according  calcite  even  though  streamtostream  join  query  valid  due  unbounded  nature  stream,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
34,provide  generic  server  metadata  response  follow  calcite903  assumption  work  common  case  running  behind  loadbalancer  given  client  would  continue  routed  back  avatica  server  instance  sadly  necessarily  reality  load  balancer  technology  available  capable  roundrobin  algorithm  similar  need  provide  information  client  make  decision  return  server  upon  subsequent  request  eg  fetching  next  page  result  thinking  generally  server  processed  given  request  general  metadata  could  include  thing  like  avatica  version  real  jdbc  version  information  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0
35,create  separate  sqlfunctioncategory  value  table  function  macro  avoids  trying  apply  table  function  context  apply  regular  function  table  function  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
36,support  inputfiles  currently  support  inputsegmentnumbers  reading  specified  segment  reading  data  one  segment  add  inputfiles  reading  specified  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
37,support  absolute  path  without  scheme  loading,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
38,disk  hotspot  found  data  loading  scenario  currently  done  massive  data  loading  input  data  71gb  csv  formatï¼œand  88million  record  using  carbondata  use  dictionary  encoding  testing  environment  three  node  11  disk  yarn  executor  directory  submit  loading  command  jdbcserverthe  jdbcserver  instance  three  executor  total  one  node  respectively  loading  take  10minutes  3min  vary  time  observed  nmon  information  loading  findï¼š  1  lot  cpu  wait  first  half  loading  2  one  single  disk  many  writes  almost  reach  bottleneck  avg  80ms  max  150ms  sa  disk  3  disk  quite  idel  analyze  data  loading  carbondata  read  sort  data  locallydefault  scope  write  temp  file  local  disk  case  one  executor  one  node  carbondata  write  temp  file  one  diskcontainer  directory  yarn  local  directory  thus  resulting  single  disk  hotspot  modification  support  multiple  directory  writing  temp  file  avoid  disk  hotspot  p  improved  environment  result  pretty  optimistic  loading  take  6minutes  10  minute  improving,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
39,change  query  related  rdd  use  tableinfo  currently  query  related  rdd  using  carbontable  read  file  system  introduces  unnecessary  file  read  pas  schema  information  driver  serializing  tableinfo,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
40,secure  dictionary  server  port  secure  dictionary  server  port  implementation  single  pas  load  dictionary  key  creation  done  driver  executor  communication  external  port  communication  happen  tcp  communication  secure  encrypted  case  spark  turn  security  parameter  carbon  dictionary  port  also  follows  authentication  encryption  ie  communicate  sasl  authentication  protocol  digestmd5  encryption  pr  make  dictionary  server  client  communication  secure  encrypted  case  spark  turn  security  authentication  parameter  carbon  communication  also  becomes  secure  default  communication  still  non  secure  parameter  sparkauthenticate  true  sparkauthenticateenablesaslencryption  true  sparkauthenticatesecret,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1
41,added  tableprovider  supply  carbontable  wherever  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
42,add  blocklet  info  index  file  make  datamap  distributable  job  add  blocklet  info  index  file  make  datamap  distributable  job  1  add  blocklet  info  carbonindex  file  datamap  required  read  carbondata  file  footer  blocklet  information  make  datamap  loading  faster  2  make  data  map  distributable  add  spark  job  datamap  pruning  could  happen  distributable  pruned  blocklet  list  would  sent  driver,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
43,use  carbontableinputformat  presto  integration  use  carbontableinputformat  presto  integration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
44,add  value  based  compression  decimal  data  type  decimal  stored  int  long  added  value  based  compression  decimal  data  type  decimal  stored  int  long  decimal  precision  9  decimal  value  stored  4  byte  compressed  based  min  max  value  compared  primitive  data  type  compression  therefore  based  min  max  value  decimal  data  falling  integer  range  compressed  byte  short  decimal  precision  18  decimal  value  stored  8  byte  compressed  based  min  max  value  compared  primitive  data  type  compression  therefore  based  min  max  value  decimal  data  falling  long  range  compressed  byte  short  int  advantage  reduce  storage  space  thereby  decreasing  io  time  reading  decompressing  data,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0
45,carbondata  unsupport  boolean  data  type  sparkhive  table  support  boolean  data  type  internal  table  also  support  boolean  data  type  boolean  data  type  range  true  false  use  quotation  mark  around  true  false  literal  value  write  literal  value  uppercase  lowercase  mixed  case  value  queried  table  always  returned  lowercase  true  false  implementing  function  employ  endcoding  rle  data  expression  byte  array  carbondata  support  boolean  data  type  following  aspect  create  table  support  boolean  data  type  insert  table  value  support  insert  boolean  column  insert  overwrite  insert  table  select  another  table  select  table  load  data  local  csv  file  filter  including  describle  show  boolean  data  type  also  add  test  case  booleantype  directory  spark2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
46,support  timestamp  68  year  enhance  nodictionary  datatypes  int  long  problem  current  implementation  support  timestamp  direct  dictionary  dictionary  always  integer  68  year  range  supported  solution  issue  support  timestamp  default  dictionaryexclude  allowing  store  internally  unix  long  timestamp  problem  int  bigintlong  type  supported  dictionary  include  measure  allowed  dictionary  exclude  solution  support  int  bigintlong  dictionary  exclude  also  sort  column  support  intlong  bigint  resolved  carbondata1485,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
47,presto  integration  performance  improvement  presto  integration  performance  improvement  implemented  better  handling  null  stream  reader  added  short  timestamp  reader  resolve  properly  optimized  filter  ensure  better  push,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
48,get  detailed  blocklet  information  using  default  blockletdatamap  datamaps  detail  information  blocklet  need  exceuting  query  present  blockletdatamap  actually  default  datamap  new  datamap  added  give  information  blocklet  blockid  insuffucient  information  exceute  query  please  add  functionality  retrieve  detailed  blocklet  information  blockletdatamap  based  block  blocklet  id,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0
49,support  database  location  configuration  creating  database  support  creation  carbon  table  database  location  support  creation  carbon  table  database  location  please  refer  design  discussion  httpapachecarbondatadevmailinglistarchive1130556n5nabblecomdiscussionsupportdatabaselocationconfigurationwhilecreatingdatabasetd23492html,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
50,add  event  listener  interface  carbondata  add  event  listener  interface  carbondata  allow  extending  current  functionality  various  command  perform  various  operation  example  completion  load  process  aggregate  table  created  table  data  load  operation  need  done  aggregate  table  also  case  create  listener  aggregateloadlistener  register  event  bus  listener  called  load  operation  completed  take  care  loading  aggregate  table,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
51,add  scale  decimal  decimaltype  decimaltype  include  scale  precision  scale  precision  class  member  outside  decimaltype  removed,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
52,merging  carbonindex  file  segment  hi  problem  firsttime  query  carbon  becomes  slow  reading  many  small  carbonindex  file  cache  driver  first  time  many  carbonindex  file  created  case  loading  data  large  cluster  example  cluster  size  100  node  load  100  index  file  created  per  segment  100  load  number  carbonindex  file  becomes  10000  slower  read  file  driver  since  lot  namenode  call  io  operation  solution  merge  carbonindex  file  two  levelsso  reduce  io  call  namenode  improves  read  performance  merge  within  segment  merge  carbonindex  file  single  file  immediately  load  completes  within  segment  would  named  carbonindexmerge  file  actually  true  data  merging  simple  file  merge  current  structure  carbonindex  file  change  reading  read  one  file  instead  many  carbonindex  file  within  segment,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
53,rename  aggtype  measuretype  many  aggtype  code  meaning  clear,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
54,make  arraytype  structtype  contain  child  datatype,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
55,filter  optimization  include  filter  give  u  60  block  data  include  filter  converted  exclude  filter,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
56,clean  store  path  interface  many  getstorepath  api  unified  one  place,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
57,count  star  optimization  since  carbon  record  number  row  metadata  count  star  query  leverage  improve  performance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
58,generivectorizedreader  presto  write  generic  vectorized  reader  presto  remove  dependency  spark,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,1,0
59,create  configuration  sparksession  data  loading  create  configuration  form  sparksession  data  loading,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
60,make  fileoperations  pluggable  1  refactor  filefactory  based  filetype  support  pluggable  file  handler  custom  file  handler  specific  logic  example  user  provide  implementation  extending  existing  filetypes,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
61,extract  carbontablebuilduniquename  method  refactory  code  invoke  method  extract  carbontablebuilduniquename  method  refactory  code  invoke  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
62,reusing  old  row  reduce  memory  consumption  data  converting  process  data  loading  carbondata  convert  row  another  row  batch  currently  create  new  batch  store  converted  row  think  optimized  reuse  old  row  batch  space  thus  reduce  memory  consumption  gc  overhead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
63,refactor  sortsteprowutil  make  readable  refactor  optimize  sortrowsteputil  make  efficient  readable,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
64,support  specify  tablepath  creating  table  user  able  specify  table  path  creating  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
65,add  support  tasksegment  level  pruning  add  support  tasksegment  level  pruning  add  code  compute  task  level  minmax  helpful  tasksegment  level  pruning,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
66,add  dictionary  path  support  carbondata  add  dictionary  path  support  carbondata  dictionary  framework  need  enhanced  support  reading  dictionary  file  given  dictionary  file  location  support  new  table  property  tablepropertiesdictionarypathxxx  allow  providing  external  dictionary  path  table  ex  preaggregate  table  share  dictionary  path  main  table  dictionary  need  created,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
67,add  transaction  support  preaggregation  table  load  currently  load  process  like  1  load  main  table  2  load  preagg1  write  table  status  3  load  preagg2  write  table  status  4  write  table  status  maintable  improved  process  1  load  main  table  2  load  preagg1  3  load  preagg2  4  write  table  status  preagg2  5  write  table  status  preagg1  6  write  table  status  maintable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
68,optimization  readingwriting  sort  temp  row  data  loading  scenario  currently  carbondata  data  loading  sort  process  step  record  sorted  partially  spilled  disk  carbondata  read  record  merge  sort  since  sort  step  cputense  writingreading  record  optimize  serializationdeserialization  row  reduce  cpu  consumption  parsing  row  enhance  data  loading  performance  resolve  pick  unsorted  field  row  pack  byte  array  skip  paring  result  ive  tested  cluster  seen  8  performance  gained  74mbsnode  81mbsnode,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,1
69,enhancement  merge  index  compaction  feature  support  creation  merge  index  file  old  store  index  file  contain  blocklet  info  enhancement  merge  index  compaction  feature  support  creation  merge  index  file  old  store  index  file  contain  blocklet  info  old  store  created  carbondata  11  version  contain  blocklet  info  index  file  store  merge  index  file  created  blocklet  information  present  merge  index  file  first  time  query  carbondata  file  footer  read  blocklet  information  retrieval  benefit  1  support  merge  index  file  creation  old  store  2  improve  first  time  query  performance  note  first  time  query  performance  improved  merge  index  file  created  running  first  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
70,optimization  data  loading  skewed  data  one  case  carbondata  load  skewed  data  file  size  data  file  range  1kb  5gb  current  implementation  carbondata  distribute  file  blockssplits  among  node  maximum  data  locality  data  evenly  distributed  call  blocknodeassignment  short  however  current  implementation  problem  assignment  block  number  based  goal  make  sure  node  deal  amount  number  block  skewed  data  scenario  described  block  small  file  block  big  file  different  size  1kb  v  64mb  result  difference  total  data  size  assigned  data  node  large  order  solve  problem  size  block  considered  blocknodeassignment  one  node  deal  block  another  long  total  size  block  almost,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
71,skip  writing  final  data  file  local  disk  save  disk  io  data  loading  currently  data  loading  carbondata  write  final  data  file  local  disk  copy  hdfs  saving  disk  io  carbondata  skip  procedure  directly  write  file  hdfs,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
72,store  carbondata  location  datamap  make  datamap  retrieval  faster  store  carbondata  location  datamap  make  datamap  retrieval  faster,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
73,add  compaction  listener,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
74,refactored  code  segregated  process  meta  process  data  load  command  h1  refactored  code  segregated  process  meta  process  data  load  compaction  command  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
75,enhance  data  loading  performance  specifying  range  bound  sort  column  currently  carbondata  data  loading  using  nodesort  also  known  localsort  following  procedure  convert  input  data  batch  convert  sort  batch  write  sort  temp  file  tempsort  combine  sort  temp  file  merge  sort  get  bigger  ordered  sort  temp  file  mergesort  combine  sort  temp  file  final  sort  result  feed  next  procedure  finalsort  get  row  order  convert  row  carbondata  columnar  format  page  produce  write  bundle  page  file  write  corresponding  index  file  consume  step1step3  done  concurrently  using  multithread  step4  done  using  one  thread  step5  done  using  multithread  step4  bottleneck  among  procedure  observing  data  loading  performance  see  cpu  usage  step3  low  â  enhance  data  loading  performance  parallelizing  step4  â  user  specify  range  bound  sort  column  carbondata  internally  distributes  record  different  range  process  data  concurrently  different  range,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
76,refactor  query  scan  process  improve  readability,1,0,1,0,1,0,1,1,1,0,1,0,0,0,0,1,1
77,presto  integration  code  refactoring  presto  integration  code  refactoring  remove  unnecessary  class  improve  performance,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
78,remove  carbonspark  dependency  sdk  module  storesdk  module  depend  carbonspark  module,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
79,restructure  partition  folder  per  standard  hive  folder,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
80,stream  sometime  carbontable  null  executor  side,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
81,access  tablestatus  file  many  time  query  problem  currently  carbondata  single  query  access  tablestatus  file  7  time  definitely  slow  query  performance  especially  file  remote  cluster  since  reading  file  purely  client  side  operation  â  â  step  reproduce  1  add  logger  atomicfileoperationsimplopenforread  printout  file  name  read  2  run  query  carbondata  table  ran  testloaddatageneraltesttest  data  loading  csv  file  without  extension  name  3  observe  output  log  search  keyword  tablestatusâ  â  â,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
82,add  path  table  path  store  lock  file  delete  useless  segment  lock  file  loading  pr1984httpsgithubcomapachecarbondatapull1984  merged  doesnt  delete  lock  file  unlock  many  useless  lock  file  table  path  especially  segment  lock  file  grow  every  batch  loading  solution  1  add  child  path  table  path  called  lock  lock  file  stored  path  2  loading  get  useless  segment  lock  file  delete  segment  lock  file  grow  lock  file  dosent  grow,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
83,optimization  unsafe  sort  data  loading  inspired  batchsort  enough  memory  localsort  unsafe  property  hold  row  page  memory  possible  spill  page  disk  sort  temp  file  memory  unavailable  spilling  page  inmemory  merge  sort  page  time  request  unsafe  row  page  memory  unavailable  trigger  merge  sort  inmemory  page  spill  result  disk  sort  temp  file  incoming  page  held  memory  instead  spilling  disk  directly  implementation  data  size  spilling  bigger  benefit  disk  io,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
84,support  write  jsonavro  data  carbon  file  sdk  user  able  write  json  avro  data  carbon  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
85,collect  sql  execution  information  driver  side,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
86,support  sdk  api  read  schema  data  file  schema  file,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
87,save  datamaps  system  folder  warehouse  problem  currently  datamap  schema  saved  inside  main  table  schema  approach  cannot  satisfy  datamap  belongs  one  table  suppose  need  create  datamap  joining  2  table  cannot  keep  datamap  schema  one  table  also  accessing  datamaps  required  read  main  table  schema  every  time  well  optimized  need  create  multiple  datamaps  table  datamaps  need  store  schema  table  size  main  table  schema  grows  impact  performance  solution  make  datamap  schema  independent  main  table  schema  store  schema  underâ  systemfolder  location  location  configurable  using  carbon  propertyâ  carbonsystemfolderlocationâ  default  store  store  location  created  datamap  schema  json  format  better  readability  interface  store  database  madeâ  table  tablenameâ  datamap  ddl  optional  user  createdrop  show  datamaps  withoutâ  tableâ  option,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
88,enhance  compaction  performance  enabling  prefetch  compaction  carbondata  query  segment  retrieve  rowï¼œ  sort  row  produce  final  carbondata  file  currently  find  poor  performance  retrieving  row  adding  prefetch  row  surely  improve  compaction  performance  local  test  compacting  4â  segment  100  thousand  row  cost  30  prefetch  50  without  prefetch  test  larger  cluster  compacting  6  segment  18gb  raw  data  cost  45min  prefetch  57min  without  prefetch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
89,refactored  code  improve  distributable  interface,1,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,1
90,distributed  search  mode  using  grpc  user  give  sql  statement  includes  projection  filter  use  rpc  call  distributed  scan  carbon  file  directly  instead  using  rdd  query  mode  rdd  overhead  like  rdd  construction  dag  scheduling  avoided,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
91,page  level  uncompress  query  performance  improvement  unsafe  dictionary  page  level  decoder  query  add  page  level  demand  decoding  current  code  page  blocklet  getting  uncompressed  memory  footprint  high  causing  oom  added  code  support  page  level  decoding  one  page  decoding  record  processed  next  page  data  decoded  improve  query  performance  example  limit  query  unsafe  dictionaryunsafe  variable  length  optimized  getrowfor  vector  processing  putarray  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
92,add  cache  datamap  schema  provider  avoid  io  read  add  cache  datamap  schema  provider  avoid  io  read  â,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
93,add  queryexecutor  searchmode  rowbased  carbonrecordreader,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0
94,add  profiler  output  explain  command  information  give  explain  command  show  effeteness  datamap,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
95,add  cg  prune  fg  prune  cg  prune  fg  prune  pass  pruned  segment  indexfiles  fg  datamap  pruning,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
96,improve  lucene  datamap  performance  eliminating  blockid  writing  reading  index  currently  datamap  interface  implementation  use  blockid  blockletid  writing  index  file  actually  blockid  needed  store  index  file  requires  blockletid  add  memory  disk  size  write  index  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
97,support  visibleinvisible  datamap  performance  tuning  invisible  datamap  used  query  used  verify  whether  remove  datamap  future  â  feature  similar  invisible  indexed  mysql  httpsdevmysqlcomdocrefman80eninvisibleindexeshtml,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
98,search  mode  support  lucene  datamap  carbon  doesns  support  codejava  180423  061214  error  carbonsession  exception  executing  search  mode  error  resolving  filter  expression  fallback  sparksql  180423  061214  error  carbonsession  exception  executing  search  mode  error  resolving  filter  expression  fallback  sparksql  code  carbon  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
99,datamap  support  refresh  command  currently  lucenedatamap  support  refresh  command  user  create  bloomfilter  datamap  trigger  refresh  datamap  ignoring  command  make  datamap  usage  lot  confusion,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
100,index  datamap  support  immediate  load  deferred  load  creating  datamap  preaggregate  timeseries  datamap  carbon  loading  datamap  soon  user  creates  lucene  bloomfilter  behavior  aligned  otherwise  user  confused  better  option  creating  datamap  let  user  choose  whether  load  datamap  immediately  deferred  manually  refresh  later,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
101,support  flat  folder  structure  carbon  1  flat  folder  make  carbondata  file  store  flat  table  path  2  controlled  table  property  flatfolder  default  false  3  cannot  hybrid  user  cannot  change  property  table  created  4  segment  file  created  loadingand  segment  file  created  metadata  folder  table  path  5  segment  number  added  part  carbondata  index  file  6  datamap  file  create  directly  table  path  tablepathdmnamesegmentnumbertasknamedm  iud  support  list  file  iud  may  hit  performance  compaction  support  delete  segment  impact  clean  file  impact  alter  table  impact  pre  agg  property  need  inherited  child  also  support  flat  folder  structure  partition  impact  feature  already  flat  folder  structure  streaming  handoff  support  flat  folder  structure  streaming  segment  location  change  â,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
102,support  flat  folder  structure  carbon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
103,remove  unnecessary  tableprovider  interface,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
104,support  cache  bloom  datamap  currently  query  using  bloom  filter  datamap  slow  root  cause  loading  bloom  filter  index  cost  much  time  implement  driver  side  cache  accelerate  loading  index  procedure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
105,improve  lucene  datamap  size  performnace  improved  lucene  datamap  size  performance  using  following  parameter  new  dm  property  flushcache  size  cache  maintain  lucene  writer  specified  try  aggregate  unique  data  till  cache  limit  flush  lucene  best  suitable  low  cardinality  dimension  splitblocklet  made  true  store  data  blocklet  wise  lucene  mean  new  folder  created  blocklet  thus  eliminates  storing  blockletid  lucene  also  make  lucene  small  chunk  data,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
106,chnage  bloom  implementation  hadoop  better  performance  compression  current  implementation  bloom  give  better  performance  compression  also  add  new  guava  dependency  carbon  remove  guava  dependency  add  hadoopâ  bloom,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
107,order  different  write  read  data  type  schema  sdk  order  different  write  read  data  type  schema  sdk,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
108,support  streamsql  streaming  job  currently  carbon  support  creating  streaming  job  via  spark  streaming  api  requires  user  use  sparksubmit  create  streaming  job  make  easier  sql  user  carbon  support  streamsql  manage  streaming  job,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
109,carbon  support  spark  23  version  1  column  vector  columnar  batch  interface  compatibility  issue  2  compatibility  issue  related  spark  23  version  carbon  method  parameter  type  changed  class  got  renamed,1,0,1,0,1,0,0,1,0,0,1,0,0,0,0,0,1
110,implement  lru  cache  bloom  filter  based  carbon  lru  cache  interface  currently  bloom  cache  implemented  using  guava  cache  carbon  lru  cache  interface  complete  sysytem  control  cache  intstead  controlling  feature  wise  replace  guava  cache  carbonâ  lruâ  cacheâ,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0
111,optimize  carbon  schema  reader  interface  sdk  optimize  carbon  schema  reader  interface  sdk,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
112,introduce  configurable  lock  path  currently  table  level  lock  file  prepared  table  path  system  level  lock  created  inside  store  supporting  s3  locking  cannot  done  using  s3  file  s3  support  onlyâ  eventual  consistency  user  chose  different  hdfs  location  configure  lock  data  s3  lock  hdfs  user  also  chose  zookeeper  lockâ  hdfs  location  soâ  require  support  configuration  pathâ  carbonlockpath  â,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
113,presto  stream  reader  performance  enhancement  background  present  system  create  carboncolumnvectorimpl  object  carbonvectorbatch  carbon  core  fill  vector  data  one  one  column  matched  data  type  array  later  time  presto  block  builder  call  read  stream  reader  based  data  type  iterated  fill  block  returned  presto  solution  eliminate  extra  iteration  carboncolumnvectorimpl  object  vectorarray  extending  create  directstreamreaders  fill  carboncore  vector  data  one  one  directly  blockpresto  call  block  builder  return  block  presto,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
114,remove  dead  code  carbondata  due  enhancement  functionality  change  many  dead  code  left  carbondata  leading  unnecessary  maintenance  effortremove  method  code  required,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0
115,fixed  data  loading  performance  issue  problem  data  loading  taking  time  number  record  high35  billion  record  root  cause  case  final  merge  sort  temp  row  conversion  done  main  thread  final  step  processing  became  slower  solution  mode  conversion  logic  prefetch  thread  parallel  processing,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
116,support  standard  spark  fileformat  interface  carbon  current  carbondata  deep  integration  spark  provide  optimization  performance  also  support  feature  like  compaction  iud  data  map  metadata  management  etc  type  integration  force  user  use  carbonsession  instance  use  carbon  even  read  write  operation  user  want  spark  datasource  integration  support  read  write  data  carbon  support  fileformat  interface  exposed  spark,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
117,support  avro  datatype  conversion  carbon  format  1support  avro  complex  type  enum  union  fixed  carbon  2support  avro  logical  type  timemillis  timemicros  decimal  carbon  â  please  find  design  document  link  httpsdocsgooglecomdocumentd1jne8vnz3osymj72htik5i4eeivtxgne5mnhblnveedituspsharing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
118,rename  method  byteutil  class  avoid  misuse  method  tobytes  execute  xor  operation  data  result  byte  array  theâ  real  value  better  rename  method  byteutil  class  avoid  misuse,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
119,adaptive  encoding  primitive  data  type  currently  encoding  decoding  present  dictionary  measure  column  dictionary  primitive  type  encoding  absent  encoding  technique  used  reduce  storage  size  â  encoding  result  compressed  snappy  compression  reduce  storage  size  feature  support  encoding  dictionary  primitive  data  type  also,1,1,1,0,1,1,1,0,0,0,1,1,0,0,0,0,1
120,support  carboncli  tool  data  summary  tuning  carbon  performance  often  want  check  metadata  carbon  file  without  launching  spark  shell  sql  order  writing  tool  print  metadata  information  given  data  folder  currently  planning  like  usage  carboncli  aall  print  information  btblproperties  print  table  property  ccolumn  column  name  column  print  statistic  cmd  command  name  command  execute  supported  command  summary  ddetailsize  print  blocklet  size  hhelp  print  message  mshowsegment  print  segment  information  ppath  path  path  contains  carbondata  file  nested  folder  supported  sschema  print  schema  first  phase  think  â€œsummaryâ€\x9d  command  high  priority  developer  add  command  future,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
121,streamsql  support  ingest  kafka,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
122,adaptive  encoding  support  timestamp  dictionary  refactor  columnpagewrapper,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
123,support  float  byte  datatypes  sdk  datasource  currentlyâ  floatâ  supported  internally  storing  data  double  changing  data  type  double  pose  problem  using  sparkcarbonfileformat  reading  theâ  floatâ  type  data  internally  data  type  changed  fromâ  floatâ  double  therefore  data  retrieved  double  page  instead  ofâ  floatâ  user  tried  create  table  using  file  format  specifying  datatype  asâ  floatâ  column  query  fail  user  isâ  restricted  use  double  retrieve  data,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
124,simplify  sdk  api  interface  carbondata2961  simplify  sdk  api  interface  problem  current  sdk  api  interface  simpler  dont  follow  builder  pattern  new  feature  added  become  complex  solution  simplify  sdk  interface  per  builder  pattern  refer  latest  sdkguide  added  change  carbon  writer  public  carbonwriterbuilder  withthreadsafeshort  numofthreads  public  carbonwriterbuilder  withhadoopconfconfiguration  conf  public  carbonwriterbuilder  withcsvinputschema  schema  public  carbonwriterbuilder  withavroinputorgapacheavroschema  avroschema  public  carbonwriterbuilder  withjsoninputschema  carbonschema  public  carbonwriter  build  throw  ioexception  invalidloadoptionexception  change  carbon  reader  public  carbonreaderbuilder  withhadoopconfconfiguration  conf  public  carbonwriter  build  throw  ioexception  invalidloadoptionexception  removed  change  carbon  writer  public  carbonwriterbuilder  istransactionaltableboolean  istransactionaltable  public  carbonwriterbuilder  persistschemafileboolean  persist  setaccesskey  setaccesskey  setsecretkey  setsecretkey  setendpoint  setendpoint  public  carbonwriter  buildwriterforcsvinputschema  schema  configuration  configuration  public  carbonwriter  buildthreadsafewriterforcsvinputschema  schema  short  numofthreadsconfiguration  configuration  public  carbonwriter  buildwriterforavroinputorgapacheavroschema  avroschemaconfiguration  configuration  public  carbonwriter  buildthreadsafewriterforavroinputorgapacheavroschema  avroschemashort  numofthreads  configuration  configuration  public  jsoncarbonwriter  buildwriterforjsoninputschema  carbonschema  configuration  configuration  public  jsoncarbonwriter  buildthreadsafewriterforjsoninputschema  carbonschema  short  numofthreadsconfiguration  configuration  change  carbon  reader  public  carbonreaderbuilder  istransactionaltableboolean  istransactionaltable  public  carbonwriter  buildconfiguration  conf  throw  ioexception  invalidloadoptionexception,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
125,support  scan  performance  benchmark  tool,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
126,support  dumping  column  chunk  meta  carboncli,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
127,change  bloom  query  model  proceed  multiple  filter  value,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
128,data  mismatch  compaction  measure  sort  column  problem  data  mismatch  compaction  measure  sort  column  root  cause  compaction  flow  dictionarybasedresultcollector  columnpagewrapper  inverted  index  mapping  handled  row  dictionary  dimension  column  get  data  form  row  hence  data  mismatch  â  solution  handle  inverted  index  mapping  forâ  dictionarybasedresultcollector  flow  columnpagewrapper  â,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
129,refactor  columnpagewrapper,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
130,implement  lru  cache  btree  lru  cache  btree  proposed  ensure  avoid  memory  many  number  table  exit  frequently  used  problem  carbondata  maintaining  two  level  btree  cache  one  driver  level  another  executor  level  currently  carbondata  mechanism  invalidate  segment  block  cache  invalid  table  segment  eviction  policy  unused  cached  object  instance  complete  memory  utilized  system  able  process  new  request  solution  cache  maintained  driver  level  executor  must  object  cache  currently  use  therefore  system  mechanism  mechanism  1  set  max  memory  limit  till  object  could  hold  memory  2  configured  memory  limit  reached  identify  cached  object  currently  use  required  memory  could  freed  without  impacting  existing  process  3  eviction  done  till  required  memory  meet  detail  please  refer  attachment,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
131,added  performance  statistic  query  execution  driver  executor  added  performance  statistic  query  execution  driver  executor  phase  query  execution,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
132,make  zookeeper  lock  default  zookeeper  url  configured  make  lock  type  zookeeper  zookeeper  url  present  spark  conf  sparkdeployzookeeperurl  property  set  sparkdefaultconf  need  take  zookeeper  locking,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
133,entity  tab  switching  new  entity  creation  new  dbobj  entity  created  entity  editor  switch  entity  tab  name  field  acquiring  focus  thing  minor  cause  lot  irritation  new  project  lot  entity  created,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
134,add  confirmation  dialog  delete  action  apparently  im  foolish  enough  constantly  confuse  entity  level  attributerelationship  level  delete  button  result  constantly  delete  wrong  thing  undo  support  mean  closing  modeler  reopening  redoing  work  hadnt  save  beforehand  wholly  acknowledge  popup  confirmation  dialog  may  well  get  ignored  big  chunk  thesis  revolved  around  adding  extra  step  may  least  help  prevent  deletion  due  inadvertent  click  became  particularly  annoying  could  add  switch  globally  disable  confirmation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
135,something  tomany  prefetch  limitation  httpcayenneapacheorgdocprefetchinghtml  prefetch  limitation  tomany  relationship  prefetched  query  qualifier  potentially  reduce  number  related  object  resulting  incorrect  relationship  list  bite  unsuspecting  user  either  1  address  core  limitation  building  correct  prefetch  query  use  subselect  2  detect  case  throw  exception  3  detect  case  silently  drop  prefetch  note  debugging  problem  hard  look  totally  random  get  cause,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
136,make  pk  metadata  available  via  obj  api  case  would  nice  pk  metadata  available  rop  client  since  data  currently  available  via  db  api  issue  rop  client  cannot  access  db  item  making  data  available  via  obj  api  via  limited  objattribute  needed  data  could  handled  server  client  likewise  could  cleanup  existing  code  db  wrangling  get  access  metadata  please  see  following  thread  detail  httpmarkmailorgmessageyvhyhlmi7kiasamg,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
137,aligning  query  capability  1  ejbqlquery  support  datarows  pagination  cache  group  like  selectquery  2  procedurequery  support  sqlresultsetmapping  setcolumnnamescapitalization  like  sqltemplate,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
138,cm  allow  multiple  item  selection  allow  multiple  item  selection  lefthand  project  tree  righthand  attribute  panel  common  operation  like  delete  work  multiple  object  gsoc  2008  task,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
139,add  support  start  indexoffset  query  cayenne  already  allows  u  programatically  set  query  fetch  limit  would  nice  could  also  specify  fetch  indexfetch  offset  query  make  simple  fetch  eg  100th  150th  result  database,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
140,objrelationship  mapping  dialog  improvement  gsoc  2008  task  biggest  complaint  objrelationship  mapping  dialog  often  unclear  operates  especially  new  user  ie  empty  list  dbrelationships  displayed  white  area  giving  hint  need  done  map  relationship  thats  confusing  thing  add  1  path  component  hint  chain  path  component  flattened  relationship  minimum  may  add  hint  text  select  next  dbrelationship  grey  next  available  dropdown  ideally  implement  path  browser  similar  selectquery  prefetch  ordering  browser  operate  similar  o  x  finder,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
141,support  copypaste  entitiesattributesrelationships  support  copypaste  entitiesattributesrelationships  gsoc  2008  task  idea  follow  implement  copypaste  two  way  first  buffer  valid  within  sole  project  open  another  project  copied  data  lost  second  buffer  stored  whole  modeler  application  even  system  buffer  allows  copy  data  different  project  complex  need  create  shallow  copy  entity  attrs  etc  personally  use  one  cayennexml  currently,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0
142,cm  datanode  panel  reorg  pull  password  encoding  option  tab  currently  datanode  editor  display  much  stuff  driverdatasourcefactory  selected  related  password  encoding  mechanism  clutter  view  organize  better  idea  following  1  add  password  encoding  tab  right  adapter  tab  2  move  password  encoder  password  encoder  key  password  location  password  source  main  datanode  tab  new  tab  3  make  sure  new  tab  active  datasource  factory  driverdatasourcefactory  active  factory,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
143,cayennecontext  support  threadlocal  operation  cayennecontext  lack  threadlocal  utility  method  datacontext  plan  add  basecontext  class  derive  make  functionality  common  subclass,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
144,nested  context  rop  nested  context  avaliable  via  cayennecontext  also  lead  moving  method  datacontext  basecontext  even  objectcontext,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
145,move  user  property  api  objectcontext  basecontext  move  user  property  api  objectcontext  basecontext  getsetuserproperty  method  declaration  moved  objectcontext  implementation  basecontext,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0
146,generated  datamap  class  contain  public  constant  query  name  new  datamap  class  great  accessing  named  query  typesafe  manner  additional  improvement  would  add  public  static  final  string  every  named  query  object  select  query  similar  dataobjects  generated  constant  reference  property  name  entity,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
147,modeler  search  improvement  search  dialog  improved  number  way  prevent  search  string  disappearance  search  dialog  opened  search  could  rerun  multiple  time  allow  keyboard  search  result  selection  one  result  found  open  dialog  go  result  directly,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
148,default  class  generation  folder  wrong  default  class  generation  folder  modeler  tool  generate  class  output  directory  selected  folder  cayennexml  stored  user  change  saved  user  preference  next  attempt  generate  class  old  folder  shown  another  related  improvement  project  maven  folder  layout  cayennexml  often  srcmainresources  case  must  select  default  folder  ot  srcmainjava  srctestresources  srctestjava  ie  smarter  dealing  predictable  maven  structure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
149,expression  api  boolean  support  string  representation  need  ability  specify  boolean  constant  true  false  expression  string  representation  eg  something  like  expressionfromstringaborttrue  currently  valid,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
150,undoredo  support  modeler  modeler  support  undoredo  history  include  addremoveeditsync  operation  reset  major  operation  like  reverseengineer,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
151,auto  load  schema  startup  feature  would  allow  cayenne  bootstrap  db  schema  startup  needed  see  following  option  schema  update  1  skip  schema  update  current  behavior  2  create  existing  table  found  reliable  le  powerful  option  skip  schema  creation  least  one  table  modeled  cayenne  already  exist  db  exception  thrown  maybe  info  log  message  use  dbgenerator  3  create  existing  table  found  throw  partial  schema  detected  check  schema  change  compared  model  throw  exception  difference  found  table  mapped  datamap  ie  table  mapped  cayenne  throw  use  merge  package  wonder  4  attempt  merge  schema  change  make  sense  modeler  component  dropdown  datanode  level  listing  schema  generation  strategy  saved  xml  schemaupdatestrategy  attribute  node  element  runtime  component  consist  strategy  instantiation  intercept  db  operation  run  datanode  passing  appropriate  strategy  still  undecided  whether  strategy  datanode  attribute  dbadapter  attribute  prolly  datanode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
152,ant  task  reverse  engineering  please  add  ant  task  perform  reverse  engineering  operation  cayennemodeler  cgen  task  already  generate  last  part  thats  practical  small  change  however  small  database  change  made  entire  project  cant  simply  build  command  line  requires  manual  cm  operation  reverse  engineering  step,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
153,merge  way  set  value  null  madatory  column  adding  null  column  table  row  setting  column  null  way  tell  dbmerger  value  used  instead  null  existing  row  information  merger  create  sql  like  following  setting  column  null  update  table  set  colthe  value  col  null,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
154,cayenne  support  enum  type  qualifier  statementsexpression  handling  currently  cayenne  doesnt  support  java  enums  expression  syntax  extension  qualifier  statement  make  impossible  use  enum  type  class  descriminator  inheritance  enum  expression  would  look  like  propertyname  somepackagetypeconstant  make  consistent  jpa,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
155,implement  qualifier  dbentities  much  like  objentities  qualifier  applied  dbentities  level  instance  mean  inserted  needed  join  select  thus  allowing  use  restricting  qualifier  eg  middle  table  manytomany  flattened  relationship  issue  includes  core  change  modeler  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
156,allow  providing  custom  insert  update  delete  query  builder  feature  allow  user  incercept  cayenne  delete  insert  update  behavior  something  else  simple  sqlinserts  update  deletes  instance  many  case  update  set  deleted  field  true  useful  simple  delete  issue  includes  core  change  modeler  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
157,add  method  expressionfactory  match  primary  key  object  list  object  would  helpful  method  expressionfactory  build  expression  using  matchdbexp  match  object  primary  key  helpful  excluding  single  list  known  object  result  query,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
158,memorize  userselected  column  width  preference  modeler  using  swing  table  notably  attribute  relationship  width  column  table  hardcoded  user  adjustment  reset  back  default  selected  entity  changed  need  persist  restore  user  preference  per  table  type  dbattribute  dbrelationship  objattribute  objrelationship  based  new  preference  mechanism  developed  per  cay1327,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
159,merge  primary  key  change  dbmerger  detect  create  token  change  primary  key  definition,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
160,replace  defaulttype  dedicated  type  shove  millisecond  large  result  set  processing  loop  replacing  defaulttype  us  reflection  resultset  ugh  bright  idea  dedicated  per  type  extended  type  wont  improve  thing  dramatically  however  change  straightforward  definitely  worth,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
161,use  result  optional  directive  column  query  show  problem  select  artistid  artistname  artist  working  properly  select  resultartistid  javalanginteger  resultartistname  javalangstring  artist  also  working  properly  select  artistid  resultartistname  javalangstring  artist  first  column  returned  null  nice,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
162,update  ordering  take  enums  instead  boolean  flag  ordering  class  currently  take  booleans  indicate  ascendingdescending  case  sensitiveinsensitive  reading  code  impossible  know  true  false  actually  mean  unless  familiar  api  update  class  use  descriptive  enums  instead  boolean  flag,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
163,add  deleteobjects  objectcontext  datacontext  deleteobjects  method  objectcontext  doesnt  documentation  show  using  deleteobjects  httpcayenneapacheorgdocdeletingobjectshtml  hassle  using  cayenneobjectgetobjectcontextdelete  instead  cayenneobjectgetdatacontext  getdatacontext  deprecated  30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
164,implement  memorized  sorting  modeler  column  per  cay1251  column  various  table  modeler  resized  reordered  user  selection  saved  local  preference  another  related  improvement  allow  user  click  column  header  sort  item  table  first  click  sort  ascending  second  descending  one  column  used  sorting  time  sort  selection  memorized  prefrences  table  type  note  table  sortable  displayed  ordering  significant  cayenne  namely  callback  listener  method  stored  procedure  parameter  left  unchanged,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
165,ability  use  terminating  size  nested  property  collection  approved  could  ask  apply  attached  patch  cayennejava  31  trunk  allow  use  size  property  collection  tomany  relationship  know  commonly  used  webobjects  keypaths  authorbookscount  change  similar  thing  possible  cayenne  data  object  authorbookssize  discussion  decided  size  would  better  approach  take  order  avoid  naming  conflict,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
166,method  readnestedproperty  resolve  iterative  invocation  onto  dataobject  complete  within  cayennereadnestedproperty  come  email  discussion  andrus  another  thing  may  help  implement  use  readnestedproperty  method  iteratively  applied  dataobjects  rather  eventually  hit  cayennereadnestedproperty  iterate  entire  nested  property  currently  parsed  start  iterated  readnestedproperty  method  data  object  first  part  nested  property  could  parsed  number  string  created  parsing  nested  property  would  2x  number  compared  current  implementation  taken  quick  look  much  impetus  implement  right  try  come  back  bit  later  submit  patch,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
167,implement  crossdb  functional  expression  per  datacontextejbqlfunctionalexpressions  test  renamed  datacontextejbqlfunctionalexpressionstempjava  sql  generated  cayenne  doesnt  work  least  db  derby  need  test  across  db  implement  appropriate  syntax,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
168,deprecate  datacontextobjectfromdatarow  method  unused  refresh  parameter  datacontextobjectfromdatarow  method  refresh  parameter  isnt  used  deprecate  method  provide  replacement  make  internal  code  use  replacement  version,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
169,querylogger  di  jdbceventlogger  migration  migration  deprecated  querylogger  di  enabled  jdbceventlogger,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
170,implement  constructor  injection  support  defaultadhocobjectfactory  currently  defaultadhocobjectfactory  doesnt  support  constructor  injection  might  useful  u  eg  cay1603  suppose  future  let  implement,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0
171,objectcontext  api  use  varargs  quite  annoying  wrap  object  collection  invalidate  object  easily  solved  varargs  symmetry  deleteobjects  well  end  void  invalidateobjectscollection  object  void  invalidateobjectsobject  object  void  deleteobjectscollection  object  void  deleteobjectsobject  object  deprecated  redundant  deleteobjectobject  object,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
172,transient  object  work  rop  apps  addition  problem  referenced  cay1624  transient  object  dont  work  using  rop  client  template  relationship  value  toone  tomany  null  initialized  nonnull  value  added  objectcontext  modifying  template  initialize  relationship  value  something  nonnull  transient  object  worked  locally  still  saved  dont  know  best  solution  here  basically,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
173,patch  datacontextfactory  cumbersome  customize  datacontextfactory  cumbersome  customize  want  use  custom  subclass  datacontext  probably  customization  ever  needed  right  order  copy  complete  source  datacontextfactory  replace  datacontext  mycontext  made  much  easier  refactoring  constructor  call  overridable  method  cayennecontextfactory  problem,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
174,patch  cant  disable  validation  cayennecontext  validation  cant  disabled  cayennecontext  like  datacontext  using  setvalidatingobjectsoncommitfalse  probably  isnt  generally  problem  since  outofthebox  entity  template  client  object  dont  implement  validating  interface  validation  doesnt  happen  default  cayennecontext  already  validation  implement  interface  make  object  implement  validating  validation  way  turn  dont  want  time  solution  1  pull  validatingobjectsoncommit  property  basecontext  used  cayennecontext  well  datacontext  2  check  validatingobjectsoncommit  property  validation  cayennecontext,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
175,cayennelifecycle  dont  call  string  representation  objectid  uuid  uuid  term  used  loosely  cayennelifecycle  per  httpenwikipediaorgwikiuniversallyuniqueidentifier  uuid  16  byte  number  uuid  string  like  artist1  need  call  something  else  renamed  corresponding  lifecycle  class  made  ga  release  yet  sure  good  short  term  might  essentially  talking  objectid  serialized  string,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,1,1
176,consistent  concise  property  name  aggregated  one  place  one  final  thing  need  31  take  possible  property  name  di  collection  name  definition  scattered  around  various  java  class  define  single  place  string  constant  follow  simple  naming  convention  constant  location  orgapachecayenneconfigurationconstants  naming  convention  trying  cayennetiernameorlogicalmodulenameundescoreseparatedlowercasepropertydescriptionoptionalprojectordatanodequalifier  list  property  legacy  property  name  parenthesis  di  collection  cayenneproperties  orgapachecayenneconfigurationdefaultruntimepropertiesproperties  cayenneserveradapterdetectors  orgapachecayenneconfigurationserverdefaultdbadapterfactorydetectors  cayenneserverdomainfilters  orgapachecayenneconfigurationserverdatadomainproviderfilters  cayenneserverprojectlocations  orgapachecayenneconfigurationserverdatadomainproviderlocations  cayenneserverdefaulttypes  orgapachecayennedbajdbcadapterdefaultextendedtypes  cayenneserverusertypes  orgapachecayennedbajdbcadapteruserextendedtypes  cayenneservertypefactories  orgapachecayennedbajdbcadapterextendedtypefactories  cayenneserverropeventbridgeproperties  orgapachecayenneremotehessianservicehessianserviceproperties  jdbc  property  cayennejdbcdriverdomainnamenodename  cayennejdbcurldomainnamenodename  cayennejdbcusernamedomainnamenodename  cayennejdbcpassworddomainnamenodename  cayennejdbcminconnections  cayennejdbcminconnectionsdomainnamenodename  cayennejdbcmaxconnections  cayennejdbcmaxconectionsdomainnamenodename  notice  typo  n  missing  old  property  name  crosstier  property  cayennequerycachesize  cayennemapquerycachefactorycachesize  server  property  cayenneservercontextssyncstrategy  orgapachecayennesynccontexts  cayenneserverobjectretainstrategy  orgapachecayennecontextobjectretainstrategy  cayenneadapterdomainnamenodename  removed  unused  rop  property  cayenneropserviceurl  cayenneconfigropserviceurl  cayenneropserviceusername  cayenneconfigropserviceusername  cayenneropservicepassword  cayenneconfigropservicepassword  cayenneropsharedsessionname  cayenneconfigropservicesharedsession  cayenneropchannelevents  cayenneconfigropclientchannelevents  cayenneropcontextchangeevents  cayenneconfigropclientcontextchangeevents  cayenneropcontextlifecycleevents  cayenneconfigropclientcontextlifecycleevents  cayenneropservicetimeout  cayenneconfigropservicetimeout  cayenneserverropeventbridgefactory  cayenneremoteserviceeventbridgefactory,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,0,0
177,get  rid  shared  lock  datadomain  metadata  lookup  improve  performance  using  concurrent  collection  instead  synchronizing  hashmap  includes  datadomainproperties  datadomainnodes  datadomainnodesbydatamapname  also  instead  reindexing  failed  lookup  simply  lazyfill  collection  given  datamap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
178,injectable  pkgenerator  sometimes  useful  define  pkgenerator  independently  dbadapter  would  cool  ability  inject  maybe  even  decouple  dbadapter  course  need  preserve  default  adapter  override  exists,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
179,patch  rename  datadomaingetnode  getdatanode  datadomaingetnodestring  nodename  called  getdatanode  instead  better  consistency  discoverability,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
180,split  long  disjointbyid  prefetch  query  several  smaller  query  improvement  cay1681  andrus  comment  one  thing  probably  implement  breaking  query  get  long  real  problem  repeatedly  mentioned  context  paginated  query  fact  solved  incrementalfaultlist  see  incrementalfaultlistresolveinterval  check  number  clause  qualifier  maxfetchsize  may  need  make  maxfetchsize  container  property  used  incrementalfaultlist  well  prefetch  strategy  take  account  later,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
181,cdbimport  improvement  finally  started  using  dbfirst  hopefully  ormmodeling  free  approach  project  word  maven  profile  executes  cdbimport  cgen  refresh  xml  java  class  current  db  state  31  version  cdbimport  rather  basic  need  extend  significantly  produce  reliable  complete  result  cover  task  improvement  open  subtasks  individual  thing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
182,real  support  dbentity  catalog  dbentity  catalog  property  sort  ignore  presence  dont  include  catalog  generated  sql  advise  user  enter  schema  field  however  practical  aspect  catalog  v  schema  became  obvious  started  using  cdbimport  mysql  see  cay1759  mysql  single  notion  database  table  namespace  unit  within  given  server  instance  map  catalog  mysql  jdbc  driver  see  1  2  explanation  schema  v  catalog  across  db  using  schema  place  catalog  fine  manual  mapping  became  problem  reverseengineered  datamaps  left  schema  empty  generated  sql  based  datamaps  would  use  bare  table  name  catalog  part  jdbc  url  namespace  conflict  would  occur  need  1  honor  catalog  setting  generated  sql  2  add  default  catalog  datamap  catalog  dbentity  field  modeler  1  httpforumsmysqlcomreadphp39137564137629msg137629  2  httpstackoverflowcomquestions7942520relationshipbetweencatalogschemauseranddatabaseinstance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
183,flatten  object  entity  many  many  relationship  reverse  engineering  need  remove  temporary  object  entity  many  many  relationship  reverse  engineering  make  flattened  relationship  direct  table  take  part  relation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
184,selectqueryt  datarows  consider  example  selectqueryartist  query  new  selectqueryartistartistclass  querysetfetchingdatarowstrue  listartist  object  contextselectquery  query  actually  return  listdatarow  appears  return  listartist  look  like  need  something  like  selectquerydatarow  drquery  selectquerydatarowqueryartistclass,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
185,lockfree  entityresolver  need  improve  entityresolver  make  lockfree  possible  there  reason  reuse  modeler  keeping  synchronized  startup  essentially  readonly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
186,optimize  expression  conversion  string  ejbql  expressiontostring  pretty  heavy  override  public  string  tostring  stringwriter  buffer  new  stringwriter  printwriter  pw  new  printwriterbuffer  encodeasstringpw  pwclose  bufferflush  return  buffertostring  didnt  bother  much  wasnt  supposed  called  runtime  well  sometimes  selecttranslatorjava  433  string  labelprefix  pathexptostringsubstringdblength  seeing  line  occasionally  app  profiling  report  need  override  tostring  least  astobjpath  astdbpath  lighter  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
187,merge  entity  attribute  relationship  tab  together  one  toolbar  convenient  display  attribute  relationship  two  tab  integrate  objentityattributetab  objentityrelationshiptab  one  dbentityattributetab  dbentityrelationshiptab  using  new  class  objentityattrrelationshiptab  dbentityattrrelationshiptab  toolbar  formed  new  class  use  one  toolbar  attribute  relationship  made  new  class  mediator  copyattrrelationshipsaction  cutattrrelationshipsaction  removeattrrelationshipsaction  also  modified  button  edit  relationship  incorrectly  became  active  new  patch  renamed  class  objentityattributetab  objentityrelationshiptab  dbentityattributetab  dbentityrelationshiptab  objentityattributepanel  objentityrelationshippanel  dbentityattributepanel  dbentityrelationshippanel  mediator  class  replaced  static  currentselectedpanel  field,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
188,make  resultiterator  implement  iterablet  create  objectcontextiterate  method  1  make  resultiterator  implement  iterablet  simplify  use  loop  2  create  objectcontextiterator  method  available  rop  server  stack  cayennecontext  simply  something  stupid  like  iterating  regular  list  3  create  callback  flavor  objectcontextiterateselect  resultiteratorcallback  4  move  resultiterator  orgapachecayenne  available  layer  5  stop  throwing  cayenneexception  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
189,conditionally  log  slow  longrunning  query  wanted  add  logging  slow  longrunning  query  without  log  every  single  query  made  patch  lot  implementation  question  general  design  question  jdbclogger  1  added  property  control  logging  threshold  seems  like  go  constant  already  property  defined  jdbcadapter  working  put  also  im  sure  property  naming  convention  exactly  called  cayenneserverqueryexecutiontimeloggingthreshold  2  jdbclogger  currently  message  info  level  cant  add  new  logging  level  wouldnt  able  see  longrunning  query  would  still  see  none  added  generic  warn  method  us  warn  level  wonder  semantic  method  would  better  like  loglongquery  something  also  wonder  would  better  push  existing  sql  logging  debug  level  leave  connection  opening  info  level  could  see  log  something  wanted  3  logging  sql  string  parameter  wasnt  easy  way  access  params  logger  ideally  params  would  logged  also  4  project  wonder  functionality  like  exists  allows  pair  log  level  query  running  time  could  log  warn  level  query  longer  one  second  log  error  level  query  longer  five  second  dont  think  important  complicates  property  api  thought  would  throw  idea,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
190,make  converterfactory  extensible  make  orgapachecayennereflectconverterfactory  extensible  injected  via  di  app  im  looking  add  support  joda  time  class  need  able  extend,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
191,straighten  thread  model  synchronization  modeler  lot  synchronization  modeler  code  point  earlier  misunderstanding  swing  singlethread  gui  update  model  1  remove  synchronized  block  ui  code  time  ensure  swingutilitiesinvokelater  used  thread  updating  gui  notably  projectwatchdog  thread  1  httpdocsoraclecomjavasetutorialuiswingconcurrencydispatchhtml,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0
192,iterated  paginated  query  must  print  result  count  regular  query  print  log  info  returned  5  row  took  5  m  iterated  query  dont  paginated  query  based  iterated  query  internally  dont  either  rather  inconvenient  let  add  result  count  method  resultiteratorclose  method,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
193,inmemory  matching  dataobjects  objectid  int  bring  inmemory  expression  eval  closer  db  equivalent  consider  expression  artist  1  dataobject  work  inmemory  executed  db  part  selectquery  qualifier  2  objectid  work  part  query  doesnt  work  inmemory  3  number  work  part  query  doesnt  work  inmemory  need  fix  case  2  3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
194,mysql  allow  specifying  length  timestamp  time  column  mysql  allow  specifying  length  timestamp  time  column  since  mysql  564  support  determines  number  decimal  place  use  fractional  second  see  httpdevmysqlcomdocrefman56enfractionalsecondshtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
195,porting  osgi  environment  cayenne  framework  doesnt  run  osgi  environment  classloading  problem  arise  dynamic  loading  autogenerated  class  cayenne  modeler,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
196,allow  datanode  name  used  root  sqltemplate  able  route  datarow  sqltemplate  datanode  name  datanode  name  missing  attempt  route  default  node  current  requirement  specify  datamap  root  adhoc  query  annoying,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
197,configfree  serverruntime  often  useful  cayenne  stack  raw  sql  operation  via  sqltemplate  friend  may  orm  mapping  present  often  externally  managed  datasource  provided  currently  serverruntime  wont  start  without  xml  descriptor  implement  method  serverruntimebuilder  allow  assemble  basic  part  stack  well  tweak  serverruntime  allow  starting  xml  configs  usage  example  serverruntime  localruntime  new  serverruntimebuilder  jdbcdrivercomfoodriver  urljdbcfoo  passwordxxxx  useruser  minconnections1  maxconnections2  build,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
198,implement  resolving  db  path  dataobjects  expression  using  db  path  dont  support  inmemory  evaluation  dataobjects  todo  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
199,replace  oracle  lob  hack  jdbc  40  api  jdbc  40  included  java  6  provides  method  blobclob  manipulation  work  latest  oracle  driver  ojdbc6jar  remove  oracle  lob  hack  among  thing  make  interception  batchactions  pain  per  oracle  doc  11series  driver  work  db  version  back  9x  httpdocsoraclecomcde1188201java112e10589getstahtmjjdbc28046  possibly  go  wrong,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,1,0
200,split  datanode  creation  separate  datanodefactory,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
201,di  add  support  decorator  decorator  cheap  alternative  aop  di  advantage  plain  java  code  ever  seen  typical  aop  interceptor  insane  unreadable  mess  good  performance  reading  resultset  using  proxybased  strategy  going  painful  adding  simple  construct  used  di  module  binderbindi1classtoc1class  binderdecoratei1classafterd1classbefored2class  decorator  declares  access  decorated  delegate  using  normal  inject  annotation  either  constructor  via  field  mentioned  decorator  simply  class  implementing  given  interface  clean,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
202,improved  handling  scalar  parameter  converting  expression  ejbql  toejbql  method  expression  object  work  well  case  fails  parameter  type  employed  ejbql  literal  used  serialize  object  string  resultant  ejbql  string  obvious  case  use  date  object  take  example  comparison  object  path  date  parameter  current  code  outputting  something  like  noformat  asomethingcreatetimestamp  25  mar  2014  122334  noformat  tostring  date  object  generate  valid  ejbql  far  able  ascertain  timestamp  literal  ejbql  reason  toejbql  method  expression  able  generate  broken  ejbql  string  solution  keep  existing  toejbql  method  method  fail  runtime  exception  encounter  situation  able  serialize  ejbql  correctly  another  method  toejbqllistobject  parameteraccumulator  provided  new  method  populate  parameter  accumulator  time  encounter  parameter  able  express  literal  instead  use  positional  parameter  ejbql  string  caller  use  captured  parameter  feed  back  ejbqlquery  object,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
203,cdbimport  improvement  weâ€™ve  experimented  automated  dbfirst  approach  cayenne  modeling  year  set  client  project  roughly  approach  mean  db  evolution  managed  via  external  tool  eg  liquibase  cayenne  artifact  managed  using  following  pom  configuration  plugin  groupidorgapachecayennepluginsgroupid  artifactidmavencayennepluginartifactid  configuration  configuration  execution  execution  iddefaultcliid  goal  goalcdbimportgoal  goalcgengoal  goal  execution  execution  plugin  â€œcdbimportâ€\x9d  ensures  cayenne  model  always  sync  db  â€œcgenâ€\x9d  java  class  sync  model  zero  problem  â€œcgen  â€œcdbimport  control  schema  get  decently  named  java  classesproperties  95  case  trying  address  remaining  5  make  thing  ugly  inability  generate  meaningful  relationship  name  many  case  inability  customize  attributerelationship  name  data  type  solve  proposing  merge  algorithm  would  preserve  customizations  obj  layer  made  user  addition  special  descriptor  used  advanced  filtering  customization  cdbimport  process  improvement  hopefully  result  â€œcdbimportâ€\x9d  becoming  tool  choice  cayenne  work  many  user  httpsdocsgooglecomdocumentd1df5mmdcuh7iufhefdm2qebvespgvoaymho88ywj0editpli1,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
204,deprecate  sqltemplate  parameter  batch  one  hurdle  creating  cleaner  api  sqltemplate  support  parameter  batch  sqltemplate  template  mapstring  object  params  new  map2  params0  params1  sqltemplatesetparamsparams  there  small  performance  benefit  using  batch  preparedstatement  precompiled  batch  binding  switching  form  instance  querychain  going  much  effect  speed  make  thing  cleaner  sqltemplate  template  query  query  new  query2  queries0  templatequeryquerywithparameters  queries1  templatequeryquerywithparameters  querychain  chain  new  querychainqueries  going  deprecate  parameter  batch,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
205,sqlselect  cleanup  omission  clean  refactor  sqlselect  api  shorter  style  chainable  api  1  rename  uselocalcache  localcache  2  rename  sharedcache  sharedcache  misc  3  uselocalcache  void  must  return  sqlselectt  4  cachestrategy  take  cache  group  vararg  5  cachegroups  collection  variant,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
206,variant  propertylike  contains  startswith  endswith  httpmarkmailorgmessagecx7dzla46lcykkzq  idea  analyzing  boilerplate  code  client  cayenne  apps  argument  propertylike  second  argument  expressionfactorylikeexp  requires  full  pattern  match  people  would  often  write  utility  code  wrap  string  sign  cayenne  easily  take  care  via  extra  method  addition  new  method  proper  symbol  escaping  making  like  much  safer  use  propertycontainsstring  propertylike  string  propertyicontainsstring  case  insensitive  version  propertystartswithstring  propertylikestring  propertyistartswithstring  case  insensitive  version  propertyendswithstring  propertylike  string  propertyiendswithstring  case  insensitive  version,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
207,property  override  datasources  multimodule  project  situation  collectionstring  configs  configs  random  changing  order  serverruntime  runtime  new  serverruntimebuilderaddconfigsconfigsbuild  resulting  runtime  multiple  datanodes  development  need  provide  connection  data  datanodes  using  property  per  1  due  random  order  configs  collection  domain  name  resulting  stack  also  change  invocation  cant  use  cayennejdbcdriverdomainnamenodename  property  reliably  need  easy  way  fix  domain  name  multiproject  config  internally  achieved  via  new  di  property  cayenneserverdomainname  public  api  use  existing  serverruntimebuilderstring  constructor  redefining  argument  name  domain  config  upgrade  note  user  multiconfig  project  may  used  serverruntime  behavior  name  result  domain  equal  name  last  project  config  trying  move  away  behavior  serverruntimebuilder  use  config  name  name  project  there  one  config  override  otherwise  use  override  set  cayenne  default  name  1  httpcayenneapacheorgdocs31cayenneguideconfigurationpropertieshtml,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0
208,add  support  iterators  select,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
209,speeding  propertyutils  propertyutils  slow  especially  multithreaded  apps  working  pojos  every  call  getproperty  result  javabeansintrospector  call  synchronized  slow  hoping  replacing  internal  cache  accessors  per  path  would  improve  situation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
210,saving  display  state  project,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
211,objectselect  selectbyid  eliminating  method  reset  query  state  discussion  objectselect  selectbyid  api  confusing  contains  method  append  existing  option  well  method  reset  option  state  start  fresh  httpmarkmailorgmessagef4dsghqzp6ges6ya  consensus  seems  get  rid  resetting  method  unfortunately  preserve  long  term  api  sanity  well  make  change  compatible  40m2  namely  get  rid  add  method  redefine  existing  reset  method  append  query  state  namely  addorderby  gone  orderby  append  instead  reset  addprefetch  gone  prefetch  merge  instead  reset  behave  instead  reset,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
212,inmemory  evaluation  db  expression  nonid  attribute  minor  improvement  cayenne  db  expression  evaluation  capability  evaluating  db  expression  persistent  object  something  like  dbid  currently  return  value  pk  column  db  column  name  part  id  eg  dbname  evaluates  null  todo  astdbpath  extent  let  support  evaluation  path  corresponding  dbattributes,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
213,cdbimport  detect  fk  constraint  defined  twice  table  defines  two  constraint  exact  fkpk  pair  mistake  cleaned  since  never  le  mysql  treat  valid  definition  create  table  origin  id  int11  unsigned  null  autoincrement  a2teamid  int11  unsigned  default  null  primary  key  id  unique  key  name  name  key  a2teamid  a2teamid  constraint  originibfk1  foreign  key  a2teamid  reference  a2team  id  constraint  fkorigintoteam  foreign  key  a2teamid  reference  a2team  id  engineinnodb  autoincrement175  default  charsetutf8  cdbimport  maven  got  following  exception  log  error  migration  error  cant  apply  change  token  add  relationship  a2team  origina2teamid  id  javalangillegalargumentexception  attempt  override  relationship  a2team  orgapachecayennemapentityaddrelationshipentityjava193  orgapachecayennemergeaddrelationshiptomodelexecuteaddrelationshiptomodeljava43  orgapachecayennetoolsdbimportdbimportactionexecutedbimportactionjava218  orgapachecayennetoolsdbimportdbimportactionexecutedbimportactionjava118  orgapachecayennetoolsdbimportermojoexecutedbimportermojojava257  orgapachemavenplugindefaultbuildpluginmanagerexecutemojodefaultbuildpluginmanagerjava106  orgapachemavenlifecycleinternalmojoexecutorexecutemojoexecutorjava208  info  migration  complete  warning  migration  finished  following  problem  ignored  warning  validation  failure  javalangillegalargumentexception  migration  error  cant  apply  change  token  add  relationship  a2team  origina2teamid  id  exception  caught  build  ultimately  succeeded  stack  trace  default  maven  log  made  think  something  wrong  build  perhaps  reduce  log  level  stack  trace  debug  warning  enough  perhaps  dont  log  stack  trace  situation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
214,java  7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
215,serverruntimebuilder  use  datadomain  name  default  datanode  datanode  created  implicitly  serverruntimebuilder  assigned  hardcoded  name  cayenne  turned  problem  sometimes  eg  linkmove  data  copy  framework  httpsgithubcomnhllinkmove  separate  cayenne  stack  used  rdbms  source  one  extra  stack  used  data  target  using  default  configs  source  target  source  stack  bind  transaction  processing  thread  source  connection  leak  target  operation  corresponding  datanode  name  match  probably  way  fix  linkmove  split  producer  consumer  separate  thread  still  good  idea  hardcode  datanode  name,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
216,applying  new  reverse  engineering  modeler  want  apply  new  reverse  engineering  feature  modeler  feature  already  applied  cdbimport  could  follow  development  process  via  httpsgithubcomapachecayennepull81  reach  reverse  engineering  1  tool  reengineer  database  schema  2  reverse  engineering  tab  located  datamaptabbedview  perfoming  first  option  datamap  lead  required  tab  reverse  engineering  connected  current  datamap  performing  first  option  project  lead  creation  new  datamap  switching  required  tab  reverse  engineering  write  reverse  engineering  file  possibility  look  current  state  reverse  engineering  clicking  sync  buttonit  simplifies  writing  xml  perform  reverse  engineering  clicking  execute  button  execute  reverse  engineering  performed  reverse  engineering  included  current  project  state  reverse  engineering  file  created  clicking  save  button  want  navigate  different  datamaps  last  change  window  saved  returning  problem  continue  work,1,0,1,0,1,0,0,0,1,1,1,0,0,1,1,1,0
217,replace  query  object  datamap  query  descriptor  help  build  cleaner  named  query  api  untie  query  metadata  actual  query  object  instance,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
218,mappedselect  mappedexec  fluent  query  api  need  fluent  query  api  replace  existing  namedquery  calling  query  mapped  data  map  mappedselect  query  designed  used  mapped  selecting  query  codejava  listartist  artist  mappedselectqueryartistselectquery  artistclassparamname  artist1selectcontext  code  mappedexec  query  designed  used  non  selecting  mapped  query  codejava  int  updated  mappedexecqueryartistupdatequeryparamname  artist2updatecontext  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
219,procedurecall  fluent  query  api  implement  fluent  api  executing  mapped  stored  procedure  example  new  procedurecall  query  syntax  codejava  select  listartist  artist  procedurecallqueryselectstoredprocedure  artistclass  paramname  artist  parampaintingprice  3000  limit2selectcontext  update  int  updated  procedurecallqueryupdatestoredprocedure  parampaintingprice  3000updatecontext  call  get  parameter  int  outparam  procedurecallqueryoutstoredprocedure  paramname  artist  callcontextgetoutparamartistout  code,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1
220,add  supporting  generated  key  postgresql,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
221,cayennecrypto  lazy  initialization  crypto  subsystem  deployment  scenario  secret  key  available  app  startup  user  unlock  keysource  later  time  id  still  like  cayenne  stack  operational  entity  require  encryption  currently  possible  defaultvaluetransformerfactory  defaultbytestransformerfactory  initialized  eagerly  requires  working  keysource  possible  solution  lazy  initialization  defaultvaluetransformerfactory  defaultbytestransformerfactory  achieved  via  decoration  di  injects  decorated  instance  provider,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
222,expose  callback  performintransaction  transactionmanager  api  added  per  cay1778  nice  batch  bunch  operation  single  transaction  missing  api  control  transaction  parameter  though  back  api  similar  old  transactiondelegate  except  callback  applied  individual  operation  delegate  inconveniently  stack  singleton  new  api  look  like  serverruntimeperformintransactiontransactionoperation  transactionlistener  allow  customize  connection  isolation  level  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
223,dbloader  allow  loading  datamap  without  obj  layer  cdbimport  load  map  merge  existing  map  make  sense  load  obj  later  refactor  dbloader  api  support  optimization,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
224,objectnamegenerator  refactoring  unifying  relationship  name  generation  need  refactor  objectnamegenerator  api  mainly  focusing  relationship  name  generation  new  api  generate  obj  db  relationship  name  single  method  longer  distinguish  two  dbrelationship  name  correspond  actual  name  found  database  might  well  use  object  layer  name  main  visible  change  algorithm  objrelationship  name  based  dbrelationship  semantics  dbrelationship  name  future  prof  limiting  might  split  separate  dbrelationship  name  generator  allow  avoid  passing  exportedkey  object  strategy  make  private  part  task  remove  legacyobjectnamegenerator  us  different  assumption,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
225,explicit  contribution  api  easier  expansion  di  collection  map  currently  extending  cayenne  via  contribution  di  collection  map  easy  locating  corresponding  mapcollection  transparent  requires  knowledge  string  key  given  collection  doesnt  tell  user  type  object  collection  eg  noformat  binder  bindlistconstantsserverdefaulttypeslist  addnew  localdatetype  addnew  localtimetype  addnew  localdatetimetype  noformat  let  wrap  static  contribution  api  similar  developed  bootiqueio  eg  noformat  bqcoremodulecontributeextendedtypesbinderaddadd  noformat  way  user  explicit  api  access  module  collection  map  know  type  object  expect,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
226,autoloading  cayenne  module  need  borrow  central  modularity  feature  bootiqueio  module  autoloading  based  java  serviceloader  1  module  cayenne  custom  module  user  desire  ship  metainfservicesorgapachecayennedispimoduleprovider  file  contain  name  provider  class  2  provider  contain  factory  method  module  well  method  return  collection  module  module  override  3  loader  class  load  provider  via  javautilserviceloader  create  module  provider  sort  order  override  dependency  4  serverruntimebuilder  contain  method  turn  autoloading  default,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
227,extensible  cacheinvalidationfilter  logic  improve  cacheinvalidationfilter  done  bootique  make  flexible  see  httpsgithubcombootiquebootiquecayenneblobmasterbootiquecayennejcachesrcmainjavaiobootiquecayennejcacheinvalidationinvalidationfilterjava,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
228,deprecate  multiple  cache  group  caching  query  api  drop  support  multiple  cache  group  little  practical  sense  available  caching  provider  proper  support  o  cache  obsolete  actually  deprecated  required  api  change  replace  internally  multiple  cache  group  single  group  deprecate  corresponding  31  api  warn  multiple  cache  group  provided  remove  corresponding  40  api  completely  eg  fluent  query  api,1,0,0,0,0,0,1,0,0,0,1,0,1,0,0,0,1
229,objectselect  improvement  column  full  entity  change  api  add  new  expression  astfullobject  marker  desired  logic  expression  later  post  40  version  used  orderby  method  act  objectid  thus  fill  another  gap  hack  like  dbobjectid  used  add  new  method  property  code  static  extends  persistent  propertyt  createselfclass  super  type  extends  persistent  propertyt  flatclass  super  tclass  code  prohibit  direct  usage  property  mapped  tomany  relationship  following  code  throw  cayenneruntimeexception  code  listobject  result  objectselectqueryartistclass  columnsartistartistname  artistpaintingarray  selectcontext  code  usage  example  selecting  root  object  plus  related  field  code  propertyartist  artistself  propertycreateselfartistclass  listobject  result  objectselectqueryartistclass  columnsartistself  artistartistname  artistpaintingarraycount  selectcontext  code  selecting  toone  relationship  code  listobject  result  objectselectquerypaintingclass  columnspaintingpaintingtitle  paintingtoartist  paintingtogallery  selectcontext  code  selecting  tomany  relationship  result  sql  query  code  propertyartist  artist  propertycreateselfartistclass  propertypainting  artistpainting  artistpaintingarrayflatpaintingclass  propertygallery  artistpaintinggallery  artistpaintingarraydotpaintingtogallery  listobject  result  objectselectqueryartistclass  columnsartist  artistpainting  artistpaintinggallery  selectcontext  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
230,di  typesafe  binding  list  map  goal  improvement  add  compile  time  typesafety  dependency  injection  list  map  proposed  change  di  api  add  following  method  binder  interface  code  mapbuildert  bindmapclasst  valuetype  mapbuildert  bindmapclasst  valuetype  string  bindingname  listbuildert  bindlistclasst  valuetype  string  bindingname  listbuildert  bindlistclasst  valuetype  code  deprecate  non  typesafe  method  code  mapbuildert  bindmapstring  bindingname  listbuildert  bindliststring  bindingname  code  incompatibility  cayenne  di  used  thirdparty  code  custom  module  cayenne  modification  code  updated  binding  listobject  mapstring  object  used  code  broken,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
231,module  autoloading  make  following  module  autoloadable  cache  invalidation  module  postcommit  module  rop  clientruntimebuilder  question  requires  serverruntime  modeler  tool,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
232,jdbceventlogger  replace  deprecated  method  logquerystring  list  logstring,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
233,di  refactor  listbuilder  api  ambiguity  binding  problem  ambiguity  api  adding  ordered  dependency  call  without  adding  anything  first  cause  npe  right  order  call  clear  addafter  afteradd  suggested  api  modification  remove  unorderedlistbuilder  keep  everything  listbuilder  add  method  explicit  beforeafter  parameter  code  listbuildert  addafterclass  extends  interfacetype  class  extends  aftertype  listbuildert  addaftert  value  class  extends  aftertype  listbuildert  addallaftercollectiont  value  class  extends  aftertype  listbuildert  insertbeforeclass  extends  interfacetype  class  extends  beforetype  listbuildert  insertbeforet  value  class  extends  beforetype  listbuildert  insertallbeforecollectiont  value  class  extends  beforetype  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
234,add  support  datetime  component  extraction  expression  function  add  support  following  datetime  componentextracting  function  year  month  week  dayofyear  day  andor  dayofmonth  dayofweek  hour  minute  second  however  db  support  function  eg  sqlite  vision  datetime  function  frontbase  dont  support  function  completely,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
235,update  function  support  expression  parser  need  following  enhancement  expression  parser  add  missing  support  current  datetimetimestamp  function  javastyle  camelcase  naming  expression  function  make  function  name  case  sensitive  one  break  little  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
236,rename  postcommit  module  content  commitlog  postcommit  module  name  clarifies  purpose  clash  postcommit  callback  proposed  change  name  commitlog  requires  braking  change  namely  introduce  new  annotation  commitlog  instead  auditable  move  postcommit  module  code  new  package  orgapachecayennecommitlog  rename  postcommit  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
237,limit  input  numeric  field  10  digit  issue  affect  following  field  wherewhat  dbentity  property  tabmax  length  scale  procedure  parameter  tabmax  length  precision  currently  enter  10  digit  message  appears  incorrect  meaning  situation  see  1png,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
238,field  based  data  object  see  thread  httpslistsapacheorgthreadhtml75b19bd03a6849aea1d65b687e49e5dc1f56675fd10a4f9b0d9e37ec3cdevcayenneapacheorg3e  devlist  original  idea  discussion  short  definitely  good  idea  least  experiment  storing  data  plain  field  instead  map  current  default  implementation  lower  memory  consumption  boost  performance,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
239,cgen  option  force  run  mavengradle  currently  cgen  check  file  modification  skip  class  generation  completely  data  map  file  hasnt  changed  lead  minor  annoyance  case  need  generate  new  class  template  changed  whatever  reason  user  might  plus  bug  mechanic  additionally  behavior  mentioned  doc  offered  change  simple  adding  new  option  cgen  config  force  complete  java  code  regeneration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
240,remove  commonscollections  usage  completely  task  final  part  effort  removing  external  dependency  cayenneserver  keeping  cayenne  free  outer  dependency  allow  easier  integration  cayenne  project  reducing  issue  case  dependency  incompatibility  commonscollections  code  used  cayenne  replaced  plain  java  require  java  8  easier  maintain  commonscollections  v321  used  security  vulnerability  see  issuehttpsissuesapacheorgjirabrowsecollections580  negative  impact  cayenne  use  tricky  collection  lib  require  deal  replacement  collection  lrumap  seamlessly  replaced  already  used  concurrentlinkedhashmap  compositecollection  copied  cayenne  code  base  almost  dependency  relatively  small  referencemap  implemented  cayenne  copying  lead  copying  significant  part  commonscollections  code  base  luckily  cayenne  actually  use  two  variant  map  strong  key  weak  value  strong  key  soft  value,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
241,clean  build  script  code  support  java  7  dropped  cayennejava8  module  included  core  remove  conditional  compilation  java8  module  tutorial  rop  setup  java  8  support  module  check  deprecation  macos  modeler,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
242,cdbimport  add  option  skip  userdefined  relationship  problem  cdbimport  tool  user  define  relationship  backed  foreign  key  db  may  required  link  table  view  case  dbrelated  optimization  currently  option  keep  relationship  deleted  next  cdbimport  run  workaround  may  excluding  table  relationship  add  relationship  runtime,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
243,cdbimport  add  option  create  project  file  cdbimport  tool  already  pretty  advanced  stable  still  need  modeler  create  new  project  really  slows  start  new  project  moreover  complicates  new  user  transition  cayenne  world  new  option  cbimport  config  like  codexml  configuration  cayenneprojectprojectbasedirsrcmainresourcescayennecayenneprojectxmlcayenneproject  mapprojectbasedirsrcmainresourcescayennedatamapmapxmlmap  cdbimport  cdbimport  configuration  code  logic  like  without  cayenneproject  option  result  cayenneproject  set  file  exists  created  datamap  linked  cayenneproject  file  already  exists  datamap  linked  new  update  existing  one,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
244,add  prefetchrelated  api  sqlselect  one  selfdescriptory  prefetch  capability  sqlselect  queryâ  shouldâ  pretty  straightforwardâ  underlying  sqltemplate  already  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
245,modeler  add  prefetch  support  sqltemplate  query  recommended  way  using  query  defined  modeler  mappedselectâ  mappedexec  however  cant  define  prefetch  selecting  object  underlying  query  sqltemplate  one  way  resolving  problem  add  prefetch  setting  sqltemplateâ  editor  modeler,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
246,add  prefetch  type  support  sqltemplate  query  selectquery  add  prefetch  type  support  sqltemplate  query  selectquery  add  prefetch  type  modeler  add  prefetch  type  support  datamap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
247,make  sqltemplate  sqlexec  possible  return  generated  key  make  sqltemplate  sqlexec  possible  return  generated  key  httpslistsapacheorglisthtmlusercayenneapacheorgâ,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
248,run  disjoint  id  query  outside  synchronized  block  researching  lock  contention  readonly  mode  found  query  run  disjoinbyid  prefetches  inside  contextwide  lock  objectstore  lead  really  huge  lock  contention  thread  concurrently  reading  context  â,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
249,implement  quoting  identifier  say  table  t0  attribute  attrib  0  correct  objattribute  instance  myattrib0  dbattribute  still  attrib  0  try  run  query  t0  generated  query  look  like  select  t0my  attrib  0  dbot0  t0  obviously  cant  possibly  work  correct  sql  would  select  t0my  attrib  0  dbot0  t0  notice  square  bracket  arround  attribute  table  name  make  string  valid  attribute  table  name  valid  improvement  might  add  database  name  select  t0my  attrib  0  dbnamedbot0  t0  mention  use  quantum  plugin  database  access  plugin  complained  table  called  dbotablename  believe  well  used  mydbnamedbotablename,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
250,add  progresslog  view  andrus  adamchik  andrusobjectstyleorg  replyto  cayenneuserobjectstyleorg  cayenneuserobjectstyleorg  subject  detailed  logprogress  view  date  fri  2  sep  2005  101738  0400  1617  cest  care  file  improvement  request  jira  httpobjectstyleorgcayennebugsfeatureshtml  andrus  sep  2  2005  1001  ã˜yvind  harboe  wrote  writeup  cayenne  experience  follows  ive  using  cayenne  modeler  couple  project  thing  miss  detailed  logprogress  view  see  everything  attempted  glory  detail  exceptionserror  message  connecting  database  give  limited  feedback  fails  eg  misconfigured  m  sql  server  cayenne  gave  something  went  wrong  error  message  whereas  exception  jdbc  hello  world  program  contained  much  information  translating  error  message  corrective  action  using  google  little  piece  information  matter  insignificant  may  seem  time  vital  importance  reengineering  m  sql  database  atomic  user  interface  operation  crucial  configuration  step  must  place  sqlserver  end  eg  accidentally  created  user  without  enough  access  right  access  table  wanted  reverse  engineer  didnt  give  error  message  rather  nothing  reverse  engineered  zero  feedback  frustrating  trying  figure  whats  going  wrong  cayenne  modeler  report  ambiguously  schema  generation  complete  ive  clicked  generate  put  message  even  failed  eg  try  generate  schema  contains  field  called  position  whsqldb  cause  hsqldb  choke  exception  contain  enough  information  clue  whats  wrong  modeler  seems  sensor  information  weird  error  message  switching  database  business  usual  tricky  part  error  message  propagated  user  valuable  information  tucked  away  cayennemodelerlog  generated  column  supported  cayenne  underlying  jdbc  driver  database  adapter  support  however  system  somehow  misconfigured  generated  flag  silently  ignored  sort  feedback  herepossibly  via  logprogress  view  would  nice  im  currently  investigating  work  sql  server  jdts  cayenne  12m5  ã˜yvind  harboe  httpwwwzylincom,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
251,collection  arent  supported  inmemory  filtering  would  good  able  filter  object  based  property  property  collection  ie  able  filter  name  anotherclass  class  classtobefiltered  arraylistanotherclass  list  new  arraylistanotherclass  class  anotherclass  string  name  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
252,dataobjectutils  objectforpk  work  client  dataobjectutilobjectforpk  take  objectcontext  argument  using  remote  client  possible  following  exception  happen  various  overloaded  call  1  require  method  signature  change  dataobjectutilsobjectforpk  c1new  objectidmttable1  table1id  1  javalangclasscastexception  orgobjectstylecayennedataobjectutilsobjectforpkdataobjectutilsjava276  orgobjectstylecayenneremoteclientchanneleventststtestsyncsimplepropertyclientchanneleventststjava93  2  issue  query  instead  dbentity  lookup  dataobjectutilsobjectforpk  c2  clientmttable1class  1  orgobjectstylecayennecayenneruntimeexception  vcayenneversion  cayennebuilddate  dbentity  objentity  mttable1  orgobjectstylecayennedataobjectutilsbuildiddataobjectutilsjava352  orgobjectstylecayennedataobjectutilsobjectforpkdataobjectutilsjava167,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
253,modeler  doesnt  manage  fk  constraint  mysql  hello  used  cayennemodeler  design  table  class  would  like  generate  corresponding  sql  update  mysql  database  unfortunately  create  fk  support  option  doesnt  make  difference  foreign  key  sql  statement  generated  example  relation  want  appear  db  dbrelationship  nametocountry  sourceaddress  targetcountry  tomanyfalse  dbattributepair  sourcecountry  targetid  dbrelationship  dbrelationship  nametostate  sourceaddress  targetstate  tomanyfalse  dbattributepair  sourcestate  targetid  dbrelationship,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
254,sqltemplate  improvement  api  control  capitalization  data  row  label  select  sqltemplates  sometimes  mess  capitalization  label  returned  datarow  cant  converted  object  properly  user  would  follow  naming  convention  table  name  alluppercase  alllowercase  unfortunately  mapping  work  consistemtly  across  different  database  select  query  suggested  mailing  list  1  address  problem  avoid  using  result  workaround  api  force  capitalization  result  set  label  preliminary  test  solution  work  extremely  well  1  httpobjectstyleorgcayennelistscayenneuser2007060044html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
255,split  expression  default  cayenne  qualifier  translator  remove  duplicate  join  add  syntax  cayenne  expression  parser  qualifier  translator  indicate  expression  split  expression  removed  duplicate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
256,incrementalfaultlist  performance  improvement  reported  paginated  query  slow  big  list  httpobjectstyleorgcayennelistscayenneuser2007060168html  httpobjectstyleorgcayennelistscayennedevel2007050058html  issue  used  track  various  optimization  make  optimization  1  removing  synchronization  element  array  fillin  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
257,improve  readnestedproperty  handle  tomany  relationship  path  improve  readnestedproperty  handle  tomany  relationship  path  resolve  documented  limitation  read  tomany  relationship  middle  path  throw  exception  string  name  stringartistreadnestedpropertypaintingarraypaintingname  allow  list  name  list  artistreadnestedpropertypaintingarraypaintingname  succeed  im  sure  feature  added  writenestedproperty  see  httpsissuesapacheorgcayennebrowsecay815  improvement  feature  though,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
258,datacontext  datadomain  must  support  lifecycle  callback  box  without  wrapping  wrapping  cayenne  stack  object  interceptor  lifecycle  callback  counterintuitive  requires  extra  code  actually  cause  change  behavior  cay797  need  incorporate  callback  logic  main  stack  class  datacontext  datadomain,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
259,ejbql  delete  statement  support  implement  support  ejbql  delete  statement,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
260,ejbql  update  statement  support  implement  support  ejbql  update  statement,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
261,support  combination  persistent  object  scalar  query  result  recently  introduced  sqlresultsetmapping  would  allow  mix  object  scalar  result  object  dumb  query  like  possible  select  countp  p  painting  p  group  p  need  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
262,ejbql  subquery  support  support  ejbql  subqueries  exists  construct,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
263,remove  arbitrary  reverse  relationship  mapping  limitation  mailing  list  post  remove  two  rule  related  relationship  mapping  really  well  without  1  dbrelationship  always  requires  reverse  dbrelationship  2  tomany  objrelationship  without  reverse  toone  effectively  read  ive  done  work  project  weve  used  generic  persistent  class  occurred  two  thing  indeed  property  cayenne  runtime  user  dont  worry  low  level  detail  cayenne  automagically  add  missing  reverse  relationship  runtime  corresponding  entity  without  user  ever  noticing  simple  dont  know  nobody  thought  btw  make  2  painless  cayennedataobject  store  arbitrary  data  back  pointer  toone  side  tomany  site  stored  wont  work  case  pojos  without  extra  enhancement  normal  cayenne  get  functionality  box,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
264,ejbql  support  functional  expression  support  string  arithmetic  datetime  function  ejbqlquery  committing  shortly  function  except  thatll  require  work  size  requires  correlated  subquery  trim  char  requires  crossdb  testing  there  jdbc  standard  syntax,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1
265,support  mapping  tomany  map  set  collection  per  jpa  spec  support  mapping  tomany  relationship  list  collection  set  map  currently  list  need  add  stuff  cayenne  classic  map  jpa  see  following  subtasks  support  explicit  tomany  semantics  mapping  objrelationship  collection  class  map  key  map  modeler  allow  specify  choice  objrelationship  inspector  class  generation  template  use  correct  collection  type  guess  map  addremove  semantics  list  sure  need  removefromobject  key  runtime  support  including  reverse  relationship  support  prefetching  testing  bridging  jpa  mapping,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
266,deprecate  eventmanagergetdefaultmanager  stop  using  eventmanagergetdefaultmanager  used  map  package  update  mapping  dependent  mapping  object  change  rest  cayenne  runtime  us  eventmanager  belongs  configuration  deprecate  getdefaultmanager  stop  using  singleton  runtime,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
267,cayennemodeler  freetext  search  working  huge  model  finding  needed  entitiesattributes  challenging  modeler  would  nice  search  field  either  bottom  frame  firefox  style  top  right  corner  next  menu  bar  ctrlf  shortcut  commandf  mac  search  present  list  selectable  matched  model  object  automatically  jumping  first  one  project  scanning  navigation  search  result  probably  copied  validation  action  except  would  nice  avoid  modal  popup  window,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
268,merge  change  model  db  want  able  migrate  schema  change  datamap  database  mainly  two  reason  1  make  easier  dba  developer  keep  track  db  related  change  project  2  make  simpler  developer  keep  db  schema  sync  model,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
269,cm  usability  object  select  query  improvement  object  select  query  ui  smarter  usable  1  qualifier  field  shouldnt  dummy  text  filed  smarter  validation  even  sort  completion  live  checking  user  quickly  want  sure  ok  dummy  field  error  prone  many  cm  user  avoid  named  query  must  admint  even  always  type  something  wrong  2  selecting  queryroot  eg  person  query  name  changed  personquery  case  user  hasnt  manually  changed  field  something  else  default  generated  cm  dialog  open  user  friendly  many  ides  offer  variable  suggestion  3  ordering  prefetches  tab  pane  use  jsplitpane  separte  upper  lower  zone  entity  many  field  user  always  scroll  one  cant  simply  drag  split  pane  adapt  size,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
270,cm  usability  welcome  screen  panel  add  welcome  screen  panel  cm  project  open  make  application  look  professional  give  new  user  confidence  contrast  big  blank  green  screen  course  first  impression  method  practiced  even  ides  eclipse  intellij  also  desktop  application  want  look  professional  eg  httpwwwproductivemecomdoctutorial1png,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
271,cm  usability  jcombobox  autocompletion  please  use  jcombox  autocompletion  cm  least  place  repetitive  like  selecting  field  type  simple  implement  several  extremly  well  documented  example  eg  httpwwworbitalcomputerdejcombobox,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
272,refactoring  class  generator  class  going  renaming  code  refactoring  make  class  generator  code  easier  extend  point  planning  work  1  naming  cayennegenerator  classgenerator  mapclassgenerator  independent  class  none  inheriting  looking  name  impossible  tell  cayennegenerator  ant  task  classgenerator  template  processor  mapclassgenerator  controller  multiple  template  2  version  11  v  version  12  ideally  get  rid  version  would  nice  may  nice  split  different  version  handler  different  subclass  dont  clear  idea  yet,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
273,selecttranslator  support  standard  sql  join  syntax  including  outer  join  currently  select  translator  generates  join  syntax  old  fashion  way  add  participating  table  clause  query  add  join  condition  clause  among  thing  limit  u  inner  join  almost  db  except  maybe  oracle  need  change  translator  generate  modern  crossdb  explicit  join  syntax  place  table  condition  clause  eg  old  select  artist  t0  painting  t1  t0artistid  t1artistid  new  select  artist  t0  join  painting  t1  t0artistid  t1artistid  thing  consider  check  dbadapters  see  override  join  generation  method  therefore  need  updated  feature  change  fact  selectquery  still  support  explicit  outer  join  qualifier  still  new  api  join  allow  caller  specify  kind  join  want  could  use  prefetches  line,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
274,database  schema  migration  create  fk  constraint  itd  nifty  database  schema  migration  tool  could  detect  fk  relationship  need  set  db  generation  function  set  fk  relationship  hopefully  great  stretch  make  work  migration  tool  well,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
275,add  getentitygetcolumn  addcolumntodb  add  certain  column  need  perform  conversion  need  know  entity  column  added,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
276,add  extended  enumeration  support  current  cayenne  support  java  15  enumeration  relatively  simplistic  given  enum  color  red  green  blue  cayenne  store  0  1  2  respectively  numeric  column  red  green  blue  string  column  way  specify  value  enumeration  especially  important  mapping  existing  schema  also  case  numeric  type  order  declared  fragile  someone  later  sort  color  blue  green  red  value  blue  red  swapped  incorrect  future  read  database  cayenne  need  able  support  explicitly  mapping  enumeration  database  value,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
277,scaling  paginated  list  idea  scaling  incrementalfaultlist  store  massive  amount  object  like  hundred  thousandsthis  pertains  serverside  incrementalfaultlist  problem  solve  speed  initial  list  initialization  overall  memory  use  1  simplify  id  representation  even  unresolved  list  take  significant  amount  memory  unresolved  object  slot  currently  store  datarow  n  number  entry  n  number  pk  column  entity  ie  often  1  entry  memory  use  calculation  various  representation  unresolved  entry  based  single  int  pk  dbentity  datarow  120  byte  b  hashmap  104  byte  c  object  32  byte  javalanginteger  16  byte  primitive  int  even  better  complicates  implementation  wed  need  parallel  int  long  double  etc  may  get  gain,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
278,curatorframeworkbuilder  allow  adding  multiple  auths  currently  one  add  single  authentication  schemebytes  building  curatorframework  would  handy  add  multiple,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
279,treecache  implement  maxdepth,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
280,sharedvalue  limited  utility  improved  currently  sharedvalue  limited  utility  internally  managed  version  always  used  trysetvalue  good  improvement  would  add  api  get  current  value  current  version  b  add  alternate  trysetvalue  take  new  value  expected  version,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
281,make  zkpaths  accept  one  child  zkpaths  currently  accepts  one  parent  one  child  node  would  useful  able  create  path  depth,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
282,pathchildrencache  close  executor  always  pathchildrencacheclose  call  shutdownnow  executor  always  generally  reuse  executor  passing  constructor  wrap  executor  something  ignores  shutdownnow  call  order  work  around  end  world  little  annoying,1,0,1,0,1,0,0,1,0,0,1,0,0,0,0,0,0
283,pathchildrencache  wastefully  creates  thread  per  monitored  node  pathchildrencache  creates  singlethreaded  executor  aggregate  mean  thread  every  monitored  node  company  use  case  use  servicecache  us  pathchildrencache  monitor  service  discovery  node  location  many  sharded  immutable  keyvalue  store  used  service  saw  excess  250  thread  devoted  pathchildrencaches  used  servicecache  thread  parked  negligible  cpu  impact  still  memorystack  impact  many  idle  thread  would  like  avoid  impact  id  like  modify  pathchildrencache  take  executorservice  alternate  threadfactory  currently  take  would  allow  pas  thread  pool  company  use  case  issue  concerned  concerning  pathchildrencaches  use  separate  thread  nonreentrancy  watcherinvoked  code  binary  compatibility,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
284,current  method  managing  hung  zk  handle  need  improvement  v130  major  change  added  whereby  curator  state  change  lost  flag  set  next  time  curator  need  get  zookeeper  instance  current  instance  closed  new  zookeeper  instance  allocated  session  expired  turned  optimum  instead  session  timeout  elapses  sysconnected  received  treat  failed  session  dispose  reallocate  zookeeper  handle  shown  superior  internally  netflix,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
285,optimize  treecache  fix  possible  concurrency  issue  hi  looking  treecache  impl  question  doesnt  look  right  there  separate  atomic  ref  node  data  stat  seems  stat  childdata  object  obtained  getcurrentdata  might  correspond  data  could  problematic  conditional  state  change  given  assumption  data  obvious  simple  solution  would  single  atomicreferencechilddata  field  instead  would  additional  significant  benefit  eliminating  childdata  obj  creation  every  cache  access  pathchildrencache  work  way  understanding  treecache  intended  flexible  replacement  furthermore  id  propose  data  field  childdata  final  byte  instead  atomicreference  would  avoid  needing  two  volatile  read  get  data  mean  sharing  per  bit  safer  childdata  byte  atomicreference  used  pathchildrencachecleardatabytes  currently  used  treecache  capability  could  easily  maintained  pathchildrencache  use  simple  subclass  childdata  containing  atomic  reference  similar  capability  added  treecache  id  suggest  would  better  replace  node  childdata  object  copy  byte  field  nulled  stat  ref  im  fairly  new  code  apology  there  something  ive  missedmisunderstood  agreement  id  also  happy  prepare  pr  regard  nick,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
286,recursive  delete  currently  ability  recursive  create  parent  znodes  create  node  however  ability  recursively  delete  hierarchy  zookeeper  already  provides  zkutiljava  package  seems  like  curatorish  thing  perform  well  potential  difficulty  involved  guarantee  functionality  workable,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0
287,expose  extra  metric  tracerdriver  currently  tracerdriver  exposed  latency  zk  operation  multitenant  environment  extra  metric  required  help  tracing  monitoring  byte  sent  received  monitor  client  usage  scenario  ensemble  participant  client  talking  used  find  problematic  zk  server  issue  happened  znode  path  easily  find  znode  caused  problem  like  high  load  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
288,handle  graceful  close  zookkeeper  client  waiting  resource  released  th  idea  leverage  new  zookeeperclosetimeoutms  method  introduced  zookeeper2697  new  method  wait  internal  thread  finish  way  client  sure  internal  resource  handled  lowlevel  zookeeper  client  released  useful  test  user  wait  test  environment  cleared  case  want  return  close  method  soon  possibile  zookeeper  new  specific  method  added  order  let  user  ask  specific  behaviour,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
289,include  curator  framework  state  error  message  looking  apache  fluo  1004httpsgithubcomapachefluopull1004â  seeing  error  message  like  followingâ  â  â  noformat  20180122  025723383  leaderleaderselector  error  leader  threw  exception  javalangillegalstateexception  instance  must  started  calling  method  comgooglecommonbasepreconditionscheckstatepreconditionsjava149  orgapachecuratorframeworkimpscuratorframeworkimplgetdatacuratorframeworkimpljava363  orgapachefluocoreoracleoracleservertakeleadershiporacleserverjava426  truncatednoformat  â  see  error  message  know  theâ  curatorframeworkstatehttpscuratorapacheorgapidocsorgapachecuratorframeworkimpscuratorframeworkstatehtmlâ  startedâ  however  dont  know  latent  stoppedâ  debugging  standpoint  information  would  usefulâ  example  code  generates  error  message  curatorframeworkimpljava  line  408httpsgithubcomapachecuratorblob3f7b610ad5c5a0c6a7b0331f02294bd433a54554curatorframeworksrcmainjavaorgapachecuratorframeworkimpscuratorframeworkimpljaval408â  code  could  changed  call  internal  method  like  following  â  codejava  private  void  checkstate  curatorframeworkstate  state  getstate  store  state  local  var  avoid  race  condition  since  may  read  twice  preconditionscheckstatestate  curatorframeworkstatestarted  instance  state  must  calling  method  however  curatorframeworkstatestarted  state  code  â  â,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
290,jaxws  first  pas  server  side  java  bean  dispatcher  im  working  first  pas  code  used  dispatch  request  server  side  java  bean  endpoint  first  iteration  endpoint  based  doclit  wrapped  wsdls  supported,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1
291,operation  enpointinterface  description  metdata  improvement  improvement  metadata  processing  including  package  protect  method  accessing  annotation  directly  provide  default  per  jaxws  spec  annotation  provide  getters  metadata  associated  jaxws  annotation  also  provide  additional  test  refactoring  proxydescriptor  based  patch  submit  shortly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
292,java2wsdl  need  extra  class  support  axis  1  java2wsdl  support  extraclasses  allows  wsdl  generate  complex  type  subclass  possible  return  type  method  return  abstract  class  interface  example  one  might  abstract  class  commycofruitfruitjava  subclass  commycofruitfruitapplejava  commycofruitfruitorangejava  method  service  interface  public  fruit  getusersfavoritefruituser  user  return  fruitservicegetfavoritefruituser  want  wsdl  definition  fruit  also  fruitorange  fruitapple  client  able  handle  type  axis  1  could  add  something  ant  task  like  extraclassescommycofruitfruitapplejava  commycofruitfruitorangejava  possibility  getting  feature  axis2  thanks  matt,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
293,add  metadata  support  webserviceprovider  related  annotation  providerbased  service  implementation  class  add  support  metadata  layer  refactor  endpointcontroller  javabeandispatcher  providerdispather  class  providerbased  annotation  webserviceprovider  servicemode  bindingtype  working  patch  submit  shortly,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
294,dispatcher  support  servicemodemessage  annotation  dispatcher  currently  assumes  servicemodepayload  eg  body  message  message  mode  support  providert  type  source  soapmessage  string  need  added  working  patch  submit  shortly,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0
295,adding  support  handle  bare  wsdl  java  bean  endpoint  adding  support  java  bean  endpoint  handle  non  wrap  bare  wsdl  also  adding  test  case  created  wrapped  wsdl  using  binding  file  enablewrapperstyle  false,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
296,wsdl2java  create  extensionmapper  package  axis2apacheorg  wsdl2java  creates  class  called  extensionmapper  belongs  package  axis2apacheorg  please  changed  created  package  class  type  aka  applicationspecific  package  least  change  package  orgapacheaxis2  instead  axis2apacheorg  however  cant  think  reason  extensionmapper  belong  applicationspecific  package  class  actually  specific  application  created  thanx,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
297,provide  way  expose  interface  client  instead  concrete  class  may  instance  service  author  interface  need  generate  wsdl  separate  service  impl  class  current  axis2  impl  way  achieve  goal  think  solve  problem  adding  one  optional  parameter  servicesxml  parameter  nameserviceinterfacequalified  name  service  interface  parameter  addition  parameter  nameserviceclassqualified  name  service  class  parameter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
298,improved  yahooservices  sample  improved  yahooservices  sample  facilitate  ui  user  convenience,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
299,orgapacheaxis2handlersaddressingaddressinghandler  class  provides  nothing  value  code  refactored  allow  deleted  0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
300,need  save  restore  axis2  messagecontext  axis2  requirement  save  message  context  point  handler  chain  store  away  restore  later  requirement  also  includes  need  let  handler  manage  messagespecific  data  message  context  saved  restored  particular  feature  used  wsreliablemessaging  implementation  persist  resend  message  recover  server  restart  idea  save  message  context  later  restore  message  context  pick  message  processing  point  message  context  saved  without  completely  restart  message  beginning  refer  wiki  page  httpwikiapacheorgwsfrontpageaxis2messagecontextsaverestore  description  proposal  accomplish  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
301,add  rpclit  methodmarshaller  support  rich  rpc  update  jaxws  message  model  need  methodmarshaller  support  go  along,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
302,proper  error  message  given  user  returned  option  list  providing  invalid  option  servicelifecycle  client  currently  system  return  exception  user  provides  wrong  option  library  client  servicelifecycle  sample  please  return  proper  error  message  provide  user  option  list  heshe  enters  wrong  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
303,small  change  debug  information  formatting  making  small  change  debug  formatting  commit  change  soon,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
304,add  spi  allow  naviation  servicedelegate  associated  endpointdescription  bindingprovider  add  abilility  navigate  bindingprovider  servicedelegate  endpointdescription  bindingprovider  implemented  proxy  handler  dispatch  returned  client  middleware  via  new  spi  cast  dispatch  proxy  handler  returned  proxygetinvocationhandler  spi  bindingprovider  inteface  retrieve  servicedelegate  endpointdescription  see  test  modulesjaxwstestorgapacheaxis2jaxwsdescriptiongetdescfrombindingproviderjava  example  also  refactor  portinfodata  endpointdescription  added  protocol  return  portinfo  object  endpointdescription,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0
305,implementation  notyetimplemented  soapbinding  method  method  soapbinding  yet  implemented  patch  provides  implementation  required  change  part  code  please  review  prior  committing  patch  created  modulesjaxwssrc  directory  level  thanks,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
306,jaxws  xmlhttp  support  add  support  xmlhttp  rest  first  step  upgrade  jaxws  message  subsystem  handle  rest  second  step  add  support  dispatch  provider  mode  final  step  add  support  xmlhttp  proxy  issue  remain  open  add  various  layer  code,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
307,add  soap  12  support  jaxws  dynamic  proxy  current  dynamic  proxy  client  implementation  support  creating  soap  12  request  message  infrastructure  message  model  need  wire  proxy  also  requires  fixing  metadata  layer  read  soap  binding  transport  url  wsdl  working  code  drop  later  afternoon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
308,jaxws  cache  improve  xmlrootelement  related  annotation  lookup  jaxws  doclit  wrapped  marshalling  code  need  query  annotation  xmlrootelement  xmllist  xmltype  etc  defect  opened  savecache  resulting  information  operationdescription  possibly  static  weakhashtable  improve  performance,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
309,fix  enable  test  added  jira  axis21830  fix  enable  test  added  jira  axis21830,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
310,duplicate  code  operationclient  glen  went  client  side  code  base  found  multiple  place  duplicate  code  solution  came  listed  convert  operationclient  interface  abstract  class  move  constructor  code  abstract  class  move  duplicate  code  inside  execute  method  utility  class  somewhere,1,1,1,0,1,1,0,0,0,0,0,1,1,0,0,0,0
311,duplicate  code  axis2  went  code  found  several  place  code  duplicate  fixed  create  path  patch  address  code  duplicate  axis2  path  create  patch  path  soon  attach,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
312,upgrade  simplehttpserver  httpcore  40alpha3  folk  upgraded  simplehttpserver  use  newest  version  httpcore  40a3  also  refactored  axis  specific  class  got  somewhat  messy  also  would  like  little  refactoring  work  simplehttpserver  coming  day  know  much  could  interfere  plan  please  let  know  think  oleg,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1
313,saaj  13  implementation  two  patch  attached  module  saaj  saajapi  include  part  saaj  13  implementation  integrated  tested  latest  source  trunk,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
314,reading  class  array  jar  file  creating  jaxbcontext  adding  code  update  jaxbutils  read  class  jar  file  order  collect  list  class  create  jaxbcontext  per  current  logic  read  context  path  anvobjectfactory  defined  given  package  read  class  file  system  directory  jar  file  given  package,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
315,wsdl  generation  work  message  receiver  currently  wsdl  work  specific  set  message  receiver  imo  work  message  receiver  info  available  schema  message  generate  xsany  message  way  always  get  wsdl  service  wsdl  course  usefulness  wsdl  vary  depending  much  info  available  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
316,reduce  trace  message  object  serialization  improve  performance  trace  enabled  extensive  tracing  performed  message  context  serialization  related  code  helpful  quickly  debugging  problem  amount  trace  message  need  reduced  improve  performance  tracing  enabled  since  much  readwrite  stream  done  utility  class  improvement  made,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
317,allow  w  protocol  fault  thrown  client  code  clearer  message  wsa  spec  defined  reason  string  confusing  majority  user  would  good  axisfaults  thrown  received  included  information,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
318,new  jsonbadgerfishmessageformatter  patch  includes  jsonbaderfishmessageformatter  format  json  message  using  badgerfish  json  writer  user  map  correct  message  formatter  content  type  axis2xml  also  improvement  jsonintegrationtest  included  patch,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
319,method  httpsender  send  get  message  new  message  formatter  concept  axis2  soapoverhttpsender  name  changed  something  else  become  common  sender  format  including  rest  restsender  removed  soon  message  formatter  rest  situation  json  response  sent  using  get  method  reason  method  httpsender  send  message  using  get  method  implemented  patch  attached,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
320,introduce  reflection  based  dbc  tool  mdq  introduce  ability  create  set  descriptionbuildercomposite  object  reflecting  web  service  implementation  sei  class  eventually  remove  need  mdq  separate  code  path  dbc  class  related  object,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
321,improve  trace  correlation  message  context  serialization  debugging  complicated  application  scenario  become  clear  better  correlation  trace  message  among  object  message  context  object  graph  helpful  determining  failure  point  following  need  done  make  use  logcorrelationidstring  messagecontext  add  logcorrelationidstring  operationcontext  add  logcorrelationidstring  option  add  trycatch  block  around  use  objectstateutilswriteobject  object  addition  clean  following  remove  commented  systemoutprintln  line  move  check  needstobereconciled  flag  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
322,class  orgapacheaxis2uitlbuilder  refactored  improve  usability  improve  object  orientation  slightly  improve  performance  method  public  static  ombuilder  getbuilderinputstream  instream  string  charsetenc  string  soapnamespaceuri  class  orgapacheaxis2uitlbuilder  take  three  parameter  look  code  last  two  parameter  optional  object  oriented  way  handling  would  method  overloaded  handle  difference  scenario  right  method  two  null  check  get  executed  every  time  due  navigate  calling  stack  realize  every  time  caller  well  aware  whether  optional  parameter  available  passing  null  scenario  since  overloaded  method  external  interface  parameter  really  required  implementors  passing  default  value  making  null  check  redundant  also  one  overloaded  method  take  parameter  type  reader  provides  functionality  imo  method  redundant  since  difference  handle  input  responsibility  caller  utility  class  like,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
323,improvement  json  support  minor  improvement  json  module,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
324,rename  soapoverhttpsender  httpsender  refractor  support  http  method  introduction  messageformatters  get  rid  restsender  add  four  http  method  httpsender  used  soapoverhttpsender  introduce  two  messageformatters  applicationxmlformatter  serializes  data  applicationxml  xformurlencodedformatter  serializes  data  applicationxwwwformurlencoded  thanks  keith,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
325,jaxws  cache  postconstruct  method  unnecessary  reflection  currently  endpointlifecycle  manager  performing  reflection  service  instance  determine  method  postconstruct  one  time  save  information  away  injection  description  currently  testing  patch  problem  discovered  david  strite  part  ibms  performance  analysis  team  thanks  david,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
326,adding  configurable  parameter  metadata  exchange  jira  add  configrable  parameter  metadata  exchange  function  following  two  configuration  requirement  currently  identified  metadataexchange  module  engaged  globally  axis2xml  need  way  disable  getmetadata  request  service  b  getmetadata  request  issued  mexmetadata  element  return  multiple  mexmetadatasection  unit  metadatsection  could  either  embedded  xml  inline  endpoint  reference  metadata  resource  ie  metadatareference  url  ie  location  element  wsmex  spec  define  output  form  inline  location  metadatareference  returned  getmetadata  request  currently  mexmessagereceiver  default  generating  metadata  section  3  possible  output  form  stated  spec  need  way  configure  metadata  section  content  return  getmetadata  request  example  large  amount  data  large  amount  inline  xml  might  desirable  outputform  allows  configure  getmetadata  response  metadata  section  metadata  reference  location  instead  actual  information  solution  implemented  adding  metadataexchange  element  parameter  configuration  axis2xml  servicesxml  allows  support  configuration  need  well  future  need  following  configurables  item  enable  attribute  possible  value  false  used  disable  mex  support  service  disabled  mexdisabledexception  returned  sender  getmetadata  request  outputform  element  contains  optional  dialect  attribute  required  form  attribute  possible  value  form  inlinelocationreferenceif  configured  default  inlinelocation  reference  note  outputform  avoided  unnessary  processing  creating  metadata  section  data  format  needed  example  parameter  namemetadataexchange  lockedfalse  outputform  dialecthttpschemasxmlsoaporgwsdl  formsinlinelocation  outputform  formsreferencelocation  parameter  configuration  added  axis2xml  mean  getmetadata  response  contain  metadata  section  actual  wsdl  data  url  wsdl  dialect  dialect  policy  schema  etc  metadata  section  metadatareference  location  included  response  order  precedence  output  form  similar  data  locator  lookup  dialect  specific  service  level  ie  configured  servicesxml  b  service  level  ie  without  dialect  attribute  specified  c  dialect  specific  global  level  ie  configured  axis2xml  service  level  ie  without  dialect  attribute  specified  e  default  output  form  inline  location  reference  summary  code  change  new  class  orgapacheaxis2mexmexdisabledexception  modified  class  mexconstants  adding  constant  configurable  item  refere  metadataexchange  parameter  mexmessagereceiver  access  parameter  axis  configuration  service  configuration  check  mex  disabled  processing  call  mexutildetermineoutputform  instead  default  3  output  form  mexutil  added  apis  determineoutputform  checkmexdisabled,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
327,annotationbased  support  metadata  layer  doclitbare  bodybased  routing  doclitbare  routing  incoming  message  operation  input  axismessage  element  qname  must  set  part  name  operation  need  added  axisservice  messageelementqnametooperationmapping  done  metadata  layer  axisoperations  created  based  annotation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
328,change  jaxws  messagecontext  use  endpointdescription  jaxws  messagecontext  hold  reference  endpointdescription  rather  servicedescription  jira  used  change  place  referenced  also  needed  axis22218  integration  handler,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
329,axiom  expose  interface  function  implementation  detail  omnode  interface  includes  function  like  public  void  setnextsiblingomnode  node  public  void  setprevioussiblingomnode  previoussibling  public  void  setparentomcontainer  element  public  void  setcompleteboolean  state  public  void  settypeint  nodetype  throw  omexception  omcontainer  includes  public  void  setcompleteboolean  state  public  void  setfirstchildomnode  omnode  availability  function  interface  mean  client  accidentally  intentionally  misbehave  corrupt  data  structure  example  intentional  corruption  omnode  next  omgetnextsibling  omdetach  nextsetprevioussiblingom  accidental  omelement  parent  theparent  omnode  lastchild  parentgetlastchild  lastchildsetnextsiblingthenewsibling  might  reasonably  think  insert  parent  possible  function  ought  defined  package  visible  interface  particular  implementation  package  implementation  alter  crucial  detail  affect  integrity  tree  structure,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
330,handler  integration  round  2  applying  next  round  handler  integration  code  nick  gallardo  follow  fix  jaxwsproxyhandler  already  aware,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
331,omnode  omdocument  use  omoutputimpl  violating  package  encapsulation  following  function  omnodeserializewithcacheomoutputimpl  omoutput  omnodeserializeomoutputimpl  omoutput  omdocumentserializeomoutputimpl  omoutput  omdocumentserializeomoutputimpl  omoutput  boolean  includexmldeclaration  omdocumentserializewithcacheomoutputimpl  omoutput  omdocumentserializewithcacheomoutputimpl  omoutput  boolean  includexmldeclaration  reference  omoutputimpl  found  omimpl  package  rather  om  package  seems  perhaps  interface  called  omoutput  something  like,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
332,add  implementation  logicalmessagecontextlogicalmessage  use  handler  need  implementation  apis  used  logicalhandler  flow  completed  already  contributing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
333,handler  integration  test  enabled  handler  fully  integrated  test  enabled,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
334,xmlprettyprinterextension  suggest  turn  xmlprettyprinterextension  file  srcorgapacheaxis2wsdlcodegencodegenconfigproperties  example  servicexml  white  space  trimmed  parameter  namemodifyuserwsdlportaddress  lockedfalse  trueparameter  true  equal  true  turn  xmlprettyprinterextension  generated  code  work  fine  parameter  namemodifyuserwsdlportaddress  lockedfalsetrueparameter,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
335,listingagent  support  service  name  composite  path  currently  listingagent  assumes  last  part  uri  correspond  servicename  eg  get  axis2servicesservicename  attached  patch  allows  listingagent  function  properly  composite  service  name  eg  get  axis2servicespathtoservice  composite  name  useful  expand  namespace  possible  endpoint  composite  service  name  common  project  apache  ode  bpel  engine,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
336,add  progress  bar  idea  axis2  wsdl2java  plugin  currently  axi2  eclipse  plugin  progressbar  attaching  patch  idea  plugin  add  progressbar,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
337,minor  extensibility  improvement  factored  call  separate  method  certain  class  make  easier  extend  change  behavior,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
338,service  lifecycle  httpwwwnabblecomjavalangnosuchmethodexceptiontf3886972html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
339,override  handlerchain  annotation  attached  patch  enables  handlerchain  annotation  overridden  thats  needed  app  server  handler  specified  deployment  descriptor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
340,callback  interface  change  discussion  httpmarcinfot117858969600039r1w2,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
341,improve  axis  idea  plugin  wizard  resizable  wizard  wsdl2java  wizard  patch  provide  select  wsdl  option  wizard  panel  wsdl2java  wizard,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
342,allow  http  connection  without  keystore  normally  connect  http  server  sends  u  certificate  well  known  specify  keystore  using  system  property  systemsetpropertyjavaxnetssltruststorepath  keystore  systemsetpropertyjavaxnetssltruststorepasswordapache  allow  client  either  provide  certificate  mean  hardcoding  byte  allow  client  disregard  certificate  trust  server  client  sometimes  deployed  system  developer  access  file  system  therefore  cannot  configure  keystores,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
343,messagecontext  persistence  performance  improvement  messagecontext  persistence  performance  improvement  background  messagecontext  persisted  reliable  messaging  messagecontext  object  associated  object  written  objectoutput  messagecontext  hydrated  read  inputobject  utility  class  objectstateutils  provides  static  utility  function  provide  safety  mechanism  write  read  data  problem  ibm  performance  team  profiled  code  found  writing  reading  object  time  consuming  performance  penalty  due  use  static  method  thus  hindering  ability  reuse  byte  buffer  penalty  due  way  determine  object  safely  written  jira  issue  address  number  concern  scope  change  important  change  amend  existing  writeexternal  readexternal  support  impact  code  use  method  additional  logic  apis  added  changed  specific  concern  solution  original  logic  writes  object  buffer  serialization  error  occurs  algorithm  safely  accommodates  error  downside  expensive  write  object  temporary  buffer  solution  new  marker  interface  safeserializable  introduced  object  ie  messagecontext  marker  interface  lang  wrapper  object  ie  string  object  written  directly  objectoutput  eliminating  extra  buffer  write  increase  throughput  similar  change  made  read  algorithm  new  algorithm  detects  whether  object  written  directly  whether  written  byte  buffer  case  written  directly  extra  buffering  needed  reading  b  buffer  needed  write  read  object  objectstateutils  class  creates  new  buffer  excessive  allocation  buffer  subsequent  garbage  collection  hinder  performance  solution  code  refactored  use  two  new  class  safeobjectoutputstream  safeobjectinputstream  class  wrap  objectoutput  objectinput  object  provide  similar  logic  objectstateutils  key  difference  static  utility  class  therefore  buffer  used  writing  reading  reused  life  stream  object  one  series  test  reduced  number  buffer  40  2  persisting  messagecontext  c  outbound  messagecontext  persisted  associated  inbound  messagecontext  present  also  persisted  problem  inbound  messagecontext  may  large  message  writing  message  impact  performance  case  cause  logic  error  solution  code  hydrate  outbound  messagecontext  never  need  message  soapenvelope  associated  inbound  messagecontext  solution  persist  inbound  message  current  code  marker  string  persisted  along  data  marker  string  may  contain  lengthy  correlation  id  extra  information  impact  performance  file  size  solution  reduced  number  marker  string  remaining  marker  string  changed  common  name  object  persisted  case  log  correlation  id  longer  present  marker  string  addition  made  change  create  log  correlation  id  demand  log  correlation  code  us  synchronized  uuidgenerator  creating  log  correlation  id  demand  limit  unnecessary  locking  e  miscellaneous  spent  time  fine  tuning  algorithmic  logic  safeobjectinputstream  safeobjectoutputstream  eliminate  extra  buffer  ie  bytearrayoutputstream  optimization  localized  change  nonperformance  related  change  externalize  related  code  refactored  life  new  orgapacheaxis2contextexternalize  package  ii  objectstateutils  class  retained  legacy  reason  didnt  want  remove  apis  implementation  objectstatutils  changed  delegate  new  class  iii  new  test  added  iv  added  class  debugoutputobjectstream  debugobjectinputstream  class  installed  logisdebugenabled  true  class  log  method  call  underlying  objectoutput  objectinput  thus  helpful  debugging  error  v  andy  gatford  provided  code  us  context  classloader  reading  persisted  data  vi  high  level  logic  used  write  read  object  generally  implementation  algorithm  changedimproved  case  required  change  format  persisted  data  example  object  preceded  boolean  indicates  whether  object  written  directly  written  byte  buffer  increased  revision  id  changed  format  kudos  much  thanks  following  people  contributed  work  helped  brainstorming  helped  testing  provided  performance  profile  ann  robinson  andy  gatford  dan  zhong  doug  larson  richard  slade  next  step  attaching  patch  jira  committing  patch  next  day  two  please  let  know  question  concern  thanks  rich  scheuerle,1,1,1,1,1,0,0,0,1,0,1,0,0,0,0,0,1
344,reason  httpslistener  inner  class  orgapacheaxis2transporthttphttpslistener  innerr  class  orgapacheaxis2transporthttplistingagent  therefore  must  instantiated  diffrently  using  reflection  axisconfigbuilderprocesstransportreceivers  case  need  transportreceiverinstead  changing  implementation  axisconfigbuilderprocesstransportreceivers  inner  class  removed  listing  agent  defined  normal  java  class  packagei  provide  patch  aceptedi  personally  see  reason  class  inner,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
345,patch  upgrade  simple  http  nio  http  transport  httpcore  40alpha6  number  improvement  bug  fix  axis2  simple  nio  http  transport  pick  1  attaching  patch  upgrade  axis2  latest  httpcore  api  test  case  pas  oleg  1  httpwwwapacheorgdistjakartahttpcomponentshttpcorereleasenotestxt,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
346,control  whether  wsdl  returned  wsdl  come  service  level  global  level  need  ability  suppress  returning  wsdl  document  wsdl  wsdl2  url  come  axis2  engine  mainly  security  ground  proposal  would  ability  globally  ie  via  axis2xml  file  service  level  ie  servicesxml  file  servicesxml  file  override  global  switch  see  problem  naming  property  configuration  file  something  like  exposewsdldocument  value  true  false,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
347,jaxws  jaxb  processing  improvement  history  jaxws  layer  message  component  delegate  axiom  data  model  message  component  simplifies  marshalling  unmarshalling  step  layer  developed  axiom  omdatasource  omsourcedelement  abstraction  fully  implemented  result  brittle  code  message  component  goal  goal  decompose  message  layer  code  redesigned  jaxbdatasource  xmlstringdatasource  sourcedatasource  abstraction  message  block  abstraction  simply  delegate  datasource  object  breaking  jaxbdatasource  would  allow  jaxb  processing  outside  jaxws  module  first  step  jira  introducing  jaxbdatasource  xmlstringdatasource  sourcedatasource  abstraction,1,0,1,0,1,0,0,0,1,1,1,1,1,0,0,0,0
348,modify  blockimpl  avoid  double  unmarshalling  blockimplgetbusinessobject  creates  buisiness  object  axiom  trying  create  buisiness  object  jaxwsreceiver  set  buisiness  object  omsoucedelement  current  blockimplgetbuisinessobject  aware  blockimpl  wrap  omsourcedelement  omstaxwrapper  create  buisiness  object  patch  modifies  blockimpl  able  aware  omsoucedelement  buisiness  object  set  buisiness  object  blockimpl,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
349,provide  enabling  support  jaxws  soapjms  currently  validating  description  hierarchy  throw  webserviceexception  encounter  transport  http  feature  allow  soapjms  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
350,support  jaxws  metadata  clientside  sparse  composite  override  certain  annotation  member  add  support  jaxws  client  use  sparse  descriptionbuildercomposite  override  certain  annotation  value  specified  client  artifact  perserivcedelegate  basis  support  basis  supporting  additional  clientside  metadata  deployment  descriptor  information  added  additional  test  verify  new  functionality,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
351,abstractcontext  lazily  create  propertydifferences  map  problem  summary  abstractcontext  maintains  propertydifferences  map  record  addtionremoval  property  extra  processing  necessary  cluster  environment  degrades  perfromance  noncluster  environment  solution  suggestion  lazily  create  propertydifferences  map  created  clustering  enabled  kudos  david  strite  suggesting  change  working  fix,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
352,jaxws  21  support  mtom  mtomfeature  jaxws  21  add  new  config  option  enabling  mtom  along  adding  new  capability  mtom  function  mostly  leverage  existing  infrastructure  also  require  additional  functionality  coordination  message  model  quick  summary  work  done  1  done  update  metadata  apis  reflect  whether  mtom  configuration  found  endpoint  2  done  update  annotation  processing  code  pick  mtom  annotation  included  endpoint  3  done  update  client  creation  code  servicedelegate  set  appropriate  value  mtomfeature  configured  client  instance  4  change  marshalling  code  read  threshold  toggle  mtom  appropriate  example  new  way  mtom  configured  webservice  bindingtypesoapbindingsoap11httpmtom  public  class  myserviceimpl  webservice  mtom  public  class  myserviceimpl  additionally  threshold  configured  webservice  mtomenabledtrue  threshold2000  public  class  myserviceimpl  client  side  configuration  change  little  bit  well  example  done  mtomfeature  mtom  new  mtomfeature  mtomsetenabledtrue  mtomsetthreshold2000  service  service  servicecreatemyservicewsdl  servicename  myproxy  proxy  servicegetportportname  myproxyclass  mtom,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1
353,jaxws  21  support  respectbinding  respectbindingfeature  respectbinding  feature  added  jaxws  21  allows  endpoint  ignore  binding  defined  wsdlbinding  element  word  endpoint  could  support  soap  11  soap  12  even  though  wsdl  may  indicate  soap  11  support  endpoint  here  quick  summary  work  done  1  update  metadata  apis  expose  respectbinding  data  available  2  update  annotation  processing  code  descriptionbuilder  process  respectbinding  annotation  3  update  webservicefeature  processing  code  account  respectbindingfeature  4  change  endpointcontroller  toggle  point  check  respectbinding  property  5  update  provider  processing  code  providerdispatcer  handle  scenario  return  type  invalid  according  input  described  check  exists  endpointcontroller,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
354,merge  inbound  wsaddressing  handler  single  handler  currently  addressinginhandler  class  plus  two  subclass  ie  addressingfinalinhandler  addressingsubmissioninhandler  subclass  dont  really  much  functionality  moved  addressinginhandler  class,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
355,make  definition  custom  anonymous  uris  configurable  wsaddressing  specification  define  anonymous  uris  used  wsareplyto  wsafaultto  header  indicate  response  sent  synchronously  using  backchannel  twoway  transport  occasionally  need  may  arise  define  additional  uris  semantics  described  one  occasion  implementing  wsrm  defined  anonymous  uri  currently  supported  axis2  hardcoding  value  kernel  code  would  better  allow  uris  configured  dynamic  way,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
356,axisservlet  abstracting  initialization  configurationcontext  wondering  current  maintainer  axisservlet  could  review  following  change  axisservlet  refactoring  aimed  improving  extensibility  axisservlet  allowing  override  initconfigcontext  usecase  trying  support  obtain  configurationcontext  jndi  instead  directly  loading  file  system  share  configurationcontext  looselycoupled  component  different  classloading  hierarchy  andor  configuration  repository  deployed  servlets  webinf  directory  im  open  approach  anyone  better  idea  abstract  initialization  configurationcontext  enhancing  configurationcontextfactory  going  simplest  solution  support  kind  extensibility,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
357,plugin  jaxws  ri  wsgen  generate  dynamic  wsdlxsds  one  deploys  jaxws  annotated  service  using  pojodeployer  dynamic  wsdl  xsd  generated  dont  use  annotation  present  class  quick  way  plugin  wsgen  tool  jaxws  jaxws  ri  jar  classpath  pick  use  generate  wsdl  tactic  already  used  quite  successfully  geronimo  folk  thanks  dims,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
358,introduce  support  jaxws  oasis  xml  catalog  note  following  jsr109  jaxws  requires  support  oasis  xml  catalog  11  specification  used  resolving  web  service  document  part  description  web  service  specifically  wsdl  xml  schema  document  refer  section  44  jaxws  specification  take  crack,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
359,jaxb  custombuilder  support  jaxws  layer  problem  want  unmarshall  soap  body  payload  omsourcedelement  backed  jaxb  object  solution  proposed  solution  create  new  class  jaxbcustombuilder  jaxbcustombuilder  registered  staxombuilder  automatically  demarshall  payload  omsourcedelement  backed  jaxb  object  quick  summary  1  receive  first  message  2  jaxws  unmarshalling  code  build  jaxbcontext  unmarshalls  payload  3  jaxws  unmarshalling  code  build  jaxbcustombuilder  jaxbcontext  4  jaxbcustombuilder  placed  servicecontext  5  receive  second  message  6  dispatch  code  associate  servicecontext  messagecontext  6a  event  intercepted  trigger  jaxbcustombuilder  registered  staxombuilder  7  stax  event  payload  pulled  jaxb  object  automatically  unmarshalled  note  defect  requires  change  made  part  wscommons303  thanks  rich,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
360,refactor  threadcontextmigratorutil  class  use  parameter  instead  property  implementation  threadcontextmigrator  interface  currently  managed  using  threadcontextmigratorutil  class  implementation  represent  static  configuration  information  runtime  state  would  better  store  parameter  axisconfiguration  would  also  allow  u  extend  axisconfigurationbuilder  recognize  threadcontextmigrators  axis2xml  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
361,improve  structure  jaxws  endtoend  tet  based  proposal  nick  gallardo  goal  improve  structure  function  ie  endtoend  test  added  jaxws  test  framework  currently  modulesjaxwstest  bucket  mix  unit  test  function  test  split  introduce  new  module  jaxwsintegration  contains  function  test  organized  framework  exists  today  remove  burden  run  unit  test  jaxwstest  driver,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
362,add  support  action  faultaction  complete  support  new  annotation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
363,localtransportsender  used  multithread  changed  localtrasportsender  multithread  localtransportsender  mutlithread  using  attached  code  please  check  attached  code  hoped  enhanced  added  next  release  thanks,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
364,fixing  interop  test  itest  interop  test  integrationitest  fail  due  various  reason  ive  started  fixing  interop  test  used  xmlcomparatorinterop  compare  returned  soap  envelope  expected  response  since  class  contains  error  decided  use  anymore  instead  compare  method  whitemesainterop  class  changed  new  method  comparexml  added  remove  xmlcomparatorinterop  since  used  anymore,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
365,jaxws  support  binding  property  access  soapheaders  background  jaxws  specification  defines  property  setget  attachment  dispatchproxy  example  create  dispatch  payload  dispatchstring  dispatch  svccreatedispatchportname  stringclass  servicemodepayload  get  request  context  mapstring  object  requestcontext  dispatchgetrequestcontext  get  attachment  nonpayload  also  sent  mapstring  datahandler  attachmentmap  new  hashmap  attachmentmapputjavaxxmlwsbindingattachmentsoutbound  mydatahandler  attach  attachment  request  context  dispatchgetrequestcontextputjavaxxmlwsbindingattachmentsoutbound  attachmentmap  javaxxmlwsbindingattachments  property  make  convenient  getreceive  attachment  proposal  proposal  add  kind  functionality  getset  soap  header  example  create  dispatch  payload  dispatchstring  dispatch  svccreatedispatchportname  stringclass  servicemodepayload  get  request  context  mapstring  object  requestcontext  dispatchgetrequestcontext  create  new  outbound  header  mapqname  liststring  headermap  new  hashmap  liststring  myheaderslist  new  arrayliststring  myheaderslistaddpresample  xmlnsprehttpsamplehellopresample  qname  myheaderqname  new  qnamehttpsample  sample  pre  headersmapputmyheaderqname  myheaderslist  attach  header  map  request  context  dispatchgetrequestcontextputjaxwsbindingsoapheadersoutbound  headermap  detail  proposed  name  jaxwsbindingsoapheadersoutbound  jaxwsbindingsoapheadersinbound  similar  naming  convention  existing  attachment  property  proposed  value  mapqname  liststring  qname  qname  header  liststring  list  xml  value  normally  one  string  xml  string  single  header  object  string  jaxws  user  familiar  om  may  want  build  saaj  soapheader  semantics  jaxwsbindingsoapheadersoutbound  prior  dispatchproxy  invocation  customer  set  outbound  map  requestcontext  dispatchproxy  invocation  outbound  jaxws  engine  add  header  message  semantics  jaxwsbindingsoapheadersinbound  dispatchproxy  invocation  engine  provide  mapqname  liststring  responsecontext  dispatchproxy  invocation  customer  access  inbound  header  map  responsecontext,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
366,extract  inittransport  method  axisservletinit  servletconfig  extracting  inittransport  method  allows  accurate  subclassing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
367,axis2  kernel  currently  direct  dependency  common  httpclient  31  1  seems  conceptually  wrong  kernel  ought  dependency  transport  specific  library  2  practical  reason  matter  time  httpclient  31  superceded  httpclient  40  support  common  httpclient  discontinued  agreement  indeed  issue  resolved  happily  invest  time  looking  take  decouple  httpclient  axis2  kernel  oleg,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
368,jaxws  store  exception  thrown  web  method  implementation  property  queried  outbound  jaxws  handler  scenario  jaxws  webservice  server  throw  exception  checked  unchecked  jaxws  engine  convert  exception  message  containing  soap  fault  outbound  jaxws  application  handler  installed  handlefault  method  customer  want  work  related  exception  example  customer  may  want  log  exception  information  database  problem  conversion  exception  soap  fault  lossy  information  exception  lost  example  stack  trace  exception  captured  captured  soap  fault  java  information  also  lost  solution  store  exception  new  property  outbound  jaxws  application  handler  access  exception  directly  query  java  specific  information  next  step  coded  solution  verification  test  change  minimal  committing  change  later  today,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
369,refactored  change  made  improving  faulty  service  handling  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
370,adding  function  support  respectbinding  change  jaxws22  client  server  adding  code  add  support  respectbinding  change  jaxws22  client  server  side  make  modification  respectbindingconfiguration  client  server  also  add  unit  test  case  verify  functionality  provide  patch  change,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
371,implicit  sei  restiction  static  final  method  exposure  webservice  jaxws  22  specification  restricts  exposure  static  final  method  implicit  sei  webservice  making  change  allow  u  compliant  requirement  also  adding  new  test  case  prove  restriction  static  final  operation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
372,jaxws  support  option  allow  invalid  xml  character  removed  outbound  jaxb  serialization  background  jaxws  engine  us  jaxb  data  object  jaxb  data  object  marshaled  xml  using  jaxb  provided  marshaler  marshaler  writes  information  xmlstreamwriter  axiom  provided  mtomxmlstreamwriter  problem  customer  populates  jaxb  bean  nonxml  character  0x15  jaxb  marshaler  write  illegal  character  without  error  however  soap  node  receiving  message  fail  solution  provide  jaxws  property  customer  set  using  webservicecontext  recognize  remove  illegal  character  solution  axiom  axis2  contribution,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
373,jaxws  minor  performance  improvement  scrub  scrubbing  jaxws  code  looking  minor  performance  improvement  related  property  access,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
374,support  new  soapjms  binding  id  w3c  soapjms  binding  specification  located  httpwwww3org2002wssoapjms  nearing  first  approved  version  defined  date  binding  id  use  bindingtype  annotation  jaxws  endpoint  impl  class  within  soapbinding  transport  attribute  within  wsdl  document  previously  soapjms  spec  defined  binding  id  httpwwwexampleorg200606soapbindingsjms  placeholder  spec  amended  new  binding  id  httpwwww3org2010soapjms  ive  made  minor  change  jaxws  axis2  code  reflect  new  binding  id  ive  also  run  test  found  problem  fixed  well  im  attaching  patch  file  change  purpose  jira  request  someone  apply  change  since  im  committer,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
375,small  improvement  avoid  unnecessary  map  lookup  background  axixs2  engine  based  context  programming  model  thus  code  highly  depends  hierarchical  getproperty  setproperty  call  problem  doug  larson  ibm  identify  several  minor  issue  jaxws  kernel  code  unnecessary  getproperty  call  performed  cause  unnecessary  map  call  removing  call  provides  small  boost  performance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
376,provide  support  complex  object  type  possible  pas  complex  type  object  via  web  service  invocation  following  error  thrown  attempting  error  exception  occurred  trying  invoke  service  method  echoarray  orgapacheaxis2axisfault  unknow  type  httpwwww3org2001xmlschemastring  orgapacheaxis2databindingutilsbeanutildeserializebeanutiljava349  orgapacheaxis2databindingutilsbeanutilprocessobjectbeanutiljava827  orgapacheaxis2databindingutilsbeanutilprocesselementbeanutiljava717  orgapacheaxis2databindingutilsbeanutildeserializebeanutiljava655  orgapacheaxis2rpcreceiversrpcutilprocessrequestrpcutiljava153  orgapacheaxis2rpcreceiversrpcutilinvokeserviceclassrpcutiljava206  orgapacheaxis2rpcreceiversrpcmessagereceiverinvokebusinesslogicrpcmessagereceiverjava117  orgapacheaxis2receiversabstractinoutmessagereceiverinvokebusinesslogicabstractinoutmessagereceiverjava40  orgapacheaxis2receiversabstractmessagereceiverreceiveabstractmessagereceiverjava110  orgapacheaxis2engineaxisenginereceiveaxisenginejava181  orgapacheaxis2transporthttphttptransportutilsprocesshttppostrequesthttptransportutilsjava172  orgapacheaxis2transporthttphttpworkerservicehttpworkerjava296  orgapacheaxis2transporthttpserveraxishttpservicedoserviceaxishttpservicejava281  orgapacheaxis2transporthttpserveraxishttpservicehandlerequestaxishttpservicejava187  orgapacheaxis2transporthttpserverhttpserviceprocessorrunhttpserviceprocessorjava82  javautilconcurrentthreadpoolexecutorworkerruntaskthreadpoolexecutorjava886  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava908  javalangthreadrunthreadjava662,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
377,runtime  processing  schema  generation  consistent  javautillist  axis2  generate  schema  javautillist  correctly  identical  array  schema  run  time  expect  additional  wrapping  element  list  impact  client  generated  wsdl  file  usable  service  hence  need  changed  possible  use  schema  list  array  return  listarray  instance  depend  actual  service  method  signature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
378,add  getsimpletypeobjectclass  parameter  string  text  method  orgapacheaxis2databindingtypemappingsimpletypemapper  currently  orgapacheaxis2databindingtypemappingsimpletypemapper  class  getsimpletypeobjectclass  parameter  omelement  value  method  usage  omelement  parameter  method  retrieve  text  encapsulated  calling  valuegettext  method  getsimpletypeobjectclass  parameter  string  text  would  apiwise  cleaner  version  method  introducing  getsimpletypeobjectclass  parameter  string  text  useful  since  converting  string  simple  type  int  long  etc  common  requirement  fact  many  place  apache  synapse  project  sort  conversion  done  using  newly  written  code  getsimpletypeobjectclass  parameter  string  text  method  introduced  simpletypemapper  class  reused  number  place  including  code  apache  synpase  project  without  writing  new  code  purpose,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
379,wsdl  customization  api  axis2  stabilize  wsdl  20  feature  project  idea  consists  collection  axis2  issue  related  wsdl  feature  mainly  focus  following  two  area  1  introduce  api  customize  default  wsdl  generation  behavior  axis2  need  supported  wsdl  11  wsdl  20  2  stabilize  wsdl  20  feature  add  missing  feature  following  set  issue  identified  compulsory  task  project  required  provide  detailed  technical  design  proposal  axis23492  wsdlsupplier  configuration  andor  check  properobvious  axis25278  wsdlsupplier  support  wsdl  11  wsdl  20  axis23653  customization  dynamic  wsdl  creation  axis25240  provide  apimechanism  setting  parameter  runtime  java2wsdl  generation  axis23114  control  wsdl  binding  returned  via  servicesxml  axis25191  axis2  support  use  useoriginalwsdl  property  wsdl  20  following  optional  task  identified  expected  complete  issue  well  required  fix  following  complete  list  issue  axis24976  axis2  wsdl2code  code  generation  bug  caused  localname  axis24407  axis  2  pick  wsdl20  modified  include  whttplocation  whttpmethod  restful  service  axis24193  wsdl2java  setter  adbbean  axis23768  wsdl20toaxisservicebuilder  read  policy  wsdl  20  doc  axis23108  broken  wsdl  operation  added  module  axis24734  issue  schema  import  wsdl  file  axis24985  nullpointerexception  axis2aarmavenplugin  fileset  specified  axis24747  possible  bug  generating  code  livebookings  wsdl  axis24521  wsdl504could  locate  schema  document  tomcat  start  axis24436  woden  attempt  load  httpwwww3org2001xmlschemaxsd  every  time  par  wsdl  document  axis2  instructs  woden  axis24978  copying  data  inputstream  ouputstream  need  appropriate  buffer  size  axis24065  policy  attached  input  operation  wsdl  get  copied  stub  operation  wsdl2java,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
380,servicebuilderextension  axis2  deployers  refer  following  discussion1  find  objective  idea  servicebuilderextension  take  following  api  public  interface  servicebuilderextension  public  void  init  configurationcontext  configurationcontext  public  mapstringaxisservice  buildaxisservicesdeploymentfiledata  deploymentfiledata  throw  deploymentexception  possible  register  deployers  follows  deployer  extension  directory  class  servicebuilderextension  name  jwsbuilderext  classorgapacheaxis2jaxwsframeworkjaxwsservicebuilderextension  deployer  one  deployer  number  servicebuilderextensions  invoke  order  defined  axis2xml  file  given  deploymentfile  servicebuilderextensions  fail  create  axisservice  base  deployer  take  care  deployment  particular  deploymentfile  given  deploymentfile  servicebuilderextension  could  create  axisservice  stop  execution  servicebuilderextensions  registered  return  axisservice  immediately  base  deployer  processing  axis2  abstractdeployer  implement  necessary  helping  method  idea  extended  deployer  abstractdeployer  easily  utilise  servicebuilderextension  concept  immediate  goal  support  jaxws  artefact  servicedeployer  1  httpaxismarkmailorgthreadkvhvcvfufpo6zfe3  2  httpaxisapacheorgaxis2javacoreapiorgapacheaxis2deploymentabstractdeployerhtml,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
381,fix  small  issue  causing  null  pointer  exception  fix  typo  add  javadoc  comment  fix  spelling  axis2steram  axis2stream  axisurl  null  case  would  set  axisconfig  gave  null  pointer  error  old  line  81  fix  spelling  unablehttp  enablehttp  add  warning  message  could  find  axis2xml  anywhere  using  default  one  classpath  resource  externalize  init  parameter  string  constant  provide  documentation  add  javadoc  comment  class  method,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
382,improve  simplehttpserver  code  structure  configuraiton  cookie  use  remove  unused  class  need  clean  code  new  httpcore  based  simplehttpserver  per  oleg  still  would  like  clean  thing  little  least  old  class  httpclient  testing  framework  removed  would  also  like  refactor  session  context  management  code  improve  cookie  handling  presently  setcookie2  header  generated  httpworker  spec  compliant  per  commit  message  still  1  identify  remove  common  class  longer  referenced  2  extend  httpfactory  config  parameter  additional  option  3  document  xdocs,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
383,allow  wsaddressing  action  set  client  without  also  setting  soap  action  modify  option  class  allow  user  set  wsaddressing  action  without  also  setting  soap  action  important  according  wsaddressing  10  soap  binding  spec  allow  ability  obscure  action  soaplevel  security  mechanism  without  resort  transport  level  security  mechanism  patch  follow,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
384,jaxws  fix  invokeoneway  invokeasync  callback  implementation  axisinvocationcontroller  ive  implemented  invokeoneway  invokeasynccallback  method  axisinvocationcontroller  sync  already  implemented  previous  defect  also  ive  updated  basedispatch  use  rather  original  axiscontroller  brings  u  much  closer  removing  axiscontroller  api  favor  axisinvocationcontroller  change  async  impl  requires  update  callback  used  specifically  asyncresponseasyncresponseprocessor  renamed  little  intuitive  asynclistener  task  wait  async  response  come  back  wrapped  asynclistenerwrapper  control  starting  stopping  asynclistenerwrapper  used  jaxws  client  determine  response  available,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
385,jaxws  update  axisinvocationcontroller  use  operationclient  instead  serviceclient  purpose  greater  flexibility  axisinvocationcontroller  use  axis2  operationclient  api  rather  using  serviceclient  ive  started  little  bit  work  sandbox  hopefully  patch  post  later  today  also  work  dependant  upon  patch  posted  jira  issue  909,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
386,jaxws  dynamic  proxy  new  update  test  case  update  dynamic  proxy  added  new  functionality  refactored  proxyhandler  code  also  created  proxydescriptorfacotory  proxyhandlerfactory  added  test  case  proxy  invocation  updated  mavenxml  jaxb  schema  generated  build  time  functionality  proxy  come,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,1
387,adding  oneway  asynchronous  callback  functionality  dynamic  proxy  new  feature  dynamic  proxy  extended  proxy  doclit  wrapped  support  make  async  method  call  baseproxyhandler  look  signature  return  type  method  determine  asynchronous  call  also  check  method  name  end  async  return  type  future  response  also  modified  proxy  implemented  new  feature  invocationcontroller  get  jaxb  block  directly  rather  reading  messageasom  next  adding  holder  functionality  proxy,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
388,need  way  build  axisservices  portsservices  wsld  wsdl  11  allows  multiple  service  per  wsdl  file  multiple  port  per  service  currently  unless  service  port  name  specified  wsdl11toaxisservicebuilder  return  first  port  first  service  would  like  provide  extension  wsdl11toaxisservicebuilder  would  take  wsdl  file  return  list  axisservice  object  one  port  wsdl  make  efficient  need  make  minor  change  orgapacheaxis2descriptionwsdl11toaxisservicebuilderjava  ie  restructuring  populateservice  method  processing  specific  axisservice  done  one  time  move  code  new  method  setup  setup  code  include  reading  wsdl  file  processing  policy  import  etc  make  method  field  protected  instead  private  accessed  subclass  new  extension  proposed  orgappacheaxis2descriptionwsdl11toallaxisservicesbuilder  public  method  popluateallservices  operates  follows  call  setup  method  parent  iterates  service  port  wsdl  setting  servicename  portname  parent  call  populateservice  parent  return  axisservice  specific  service  port  name  specified  change  name  axisservice  port  name  instead  service  name  uniquely  identified  return  list  axisservice  object  one  port  wsdl  also  make  corresponding  change  wsdl  20  orgapacheaxis2descriptionwsdl20toaxisservicebuilderjava  create  wsdl20toallaxisservicesbuilderjava,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
389,initial  annotation  processing  metadata  abstraction  layer  associated  refactoring  jaxws  proxy  jaxws  proxy  annotation  processing  directly  move  annotation  processing  metatdata  abstraction  layer  ie  description  package  also  provide  associated  test  verify  metdata  layer  annotation  processing  sei  class  initial  pas  adding  metadata  processing  description  package  need  refactoring  create  serverside  metadata  remove  annotation  class  reference  proxy  move  wsm  jsr181  annotation  processing  work  done  subsequent  jiras  attach  patch  file  shortly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
390,add  description  test  utility  class  refactor  existing  test  refactor  utility  method  used  description  test  accessing  private  attribute  servicedelegate  verify  test  result  utility  class  attach  patch  shortly,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
391,adding  simple  content  restriction  adb  submitted  patch  regarding  implementation  simple  content  restriction  comment  appreciated,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
392,move  ibm  contrib  code  war  wab  conversion  trunk  provide  default  bundleconverter  war  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
393,improvement  war  wab  converter,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
394,introduce  aries  enabled  daytrader  apache  geronimo,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
395,override  subsystem  name  description,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
396,add  persistence  context  support,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
397,small  refactorings,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
398,update  blueprint  integration  test  pax  exam  340,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
399,update  jmx  integration  test  pax  exam  340,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
400,update  web  integration  test  pax  exam  3,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
401,upgrade  subsystem  test  pax  exam  3,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
402,upgrade  jpa  itests  pax  exam  3,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
403,switch  sample  pax  exam  3,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0
404,jaas  jee  annotation  based  authorization,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0
405,implement  new  bundletracker  automatically  filter  event  related  framework  bundle  composite  bundle,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
406,support  jpa  20  21  code  base,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
407,support  custom  content  subsystemsesa  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
408,add  monitoring  capability  via  mbean  aries  transaction  jdbc,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
409,implement  jndi  url  scheme  according  osgi  enterprise  specification,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
410,improve  blueprintmavenplugin  inherited  annotation  qualifier,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
411,support  jpa2  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
412,also  scan  parent  class  jpa  annotation,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,1
413,support  multiple  entitymanager  injection  per  class,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1
414,support  jpa  annotation  method  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
415,getinstance  method  core  activator  show  jvisualvm  sampling  performance  analysis,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
416,make  equal  hashcode  comparison  within  header,1,0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0
417,compute  service  requirement  capability  bundlerevisionresource,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
418,provide  efficient  implementation  system  repository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
419,extend  ariestrader  sample  include  support  jpa  application  managed  persistence,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
420,refactor  blog  sample  able  swap  persistence  layer  add  comment  service,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
421,maven  plugin  longer  includes  nonbundle  artifact,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
422,ariesapplicationresolver  backed  obr,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
423,ariestrader  create  unique  package  entity  implementation  class,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
424,separate  isolated  shared  bundle  content  deploymentmetadatajava,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
425,add  jpa  oersistence  layer  blog  sample,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
426,separate  blueprint  integration  container  context  management,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
427,update  frameworkmbean  api  method  name,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
428,various  application  api  improvement,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
429,improve  filter  generation  manifestheaderprocessor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
430,ariestrader  update  ariestrader  groupids,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
431,add  support  precedence  multiple  transaction  element  selected,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
432,ariestrader  ensure  java  package  begin  artifactid  bundle,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
433,blog  ensure  java  package  name  begin  artifactid  bundle,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
434,bundletrackercustomizers  recurse  bundle  added  compositebundle  composite  bundle  started,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
435,implement  framework  mbean,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
436,implement  bundle  state  mbean,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
437,mbean  exception,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
438,sample  test,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
439,check  refactored  version  samplessandboxdemo  sample,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
440,implement  user  admin  mbean,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
441,override  applicationversion  ebamavenplugin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
442,update  obr  application  resolver  use  obr  16,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
443,goat  move  implementation  relationshipinfoprovider  componentinfoprovider  web  bundle  api  bundle,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
444,update  tranaction  strategy  transaction  attribute  blueprint  transaction  project,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
445,web  itests  cleanup,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
446,make  jndi  proxy  creation  flexible,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
447,implement  isolated  application  runtime,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
448,provisioning  change  required  support  application  isolation,1,1,1,1,1,0,0,1,0,1,0,0,0,0,0,0,1
449,jpa  quiesce  participant  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
450,move  subsystem  use  orgapachefelixbundlerepository  instead  orgosgiserviceobr,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
451,add  update  function  plug  point  application  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
452,restructure  spi  package  sensibly  split,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
453,injecting  entity  manager  using  factory  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
454,add  generic  jndi  allow  flexible  mechanism  plug  url  objectfactories,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
455,wordassociation  assembly  broken  instruction  improvement,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
456,improve  behaviour  osgi  keeping  osgi  way,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
457,efficiency  problem  method  listbundles  class  orgapacheariesjmxframeworkbundlestate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
458,invoke  namespace  handler  custom  scope  element,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
459,create  common  proxy  creation  service  share  proxying  blueprint,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
460,support  multiple  namespace  handler  schema  use  compatible  one  wrt  class  loader,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
461,allow  use  different  blueprint  bundle  tracker  customizer  based  different  osgi  framework,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
462,blueprintcompcomponentname  jndi  namespace  handler,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
463,improved  parsing  application  metadata,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
464,use  platformrepository  resolvers  need  flexible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
465,create  common  utility  method  service  unregistration,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
466,expose  modelledbundleresource,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,0
467,make  optional  reference  sane,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
468,provide  hook  point  different  blueprint  transaction  interceptor  similar  jpa  hook  point  persistence  unit,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
469,update  application  component  use  extdefault  capability  default  service  implementation,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
470,add  test  ensure  process  fragment  correctly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
471,improve  proxy  support  final  class  final  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
472,blueprint  extender  process  bundle  associated  composite  bundle  detecting  compositebundlefactory  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
473,replace  scope  admin  region  digraph,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
474,improvement  ifile  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
475,proxy  code  memory  usage  high  generated  interface  proxy,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
476,make  aries  bundle  modelling  api  consumable  nonosgi  client,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
477,custom  component  metadata  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
478,implement  jmx  spec  mbeans  using  whiteboard  pattern,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
479,add  test  eclipselink  possibly  include  fragment  eclipselink  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
480,dry  itests,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
481,support  using  scheduledexecutorservice  blueprint  service  registry,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
482,allow  plugins  extend  aries  application  modeller,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
483,ejb  support  apache  aries,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
484,check  initial  baseline  subsystem  implementation  based  latest  rfcs,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
485,provide  initial  support  embedded  subsystem,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
486,subsystem  update  code  based  latest  resource,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
487,extend  parser  parserservice  also  accept  inputstream,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
488,usage  configuration  admin  service  within  isolated  application  framework,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
489,implement  extender  detecting  persitence  unit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
490,add  ejb  modeller  code  standalone  application  modeller,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
491,provide  persistence  unit  metadata  parser,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1,0
492,upgrade  asm  4  java  7  support,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
493,allow  mixture  interface  class  proxy,1,0,1,0,1,0,0,1,1,0,1,0,1,0,0,0,0
494,update  subsystem  latest  subsystem,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
495,modify  default  exportejb  header  empty  string,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
496,refactor  make  proxying  code  common,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1
497,add  field  injection  blueprint,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
498,implement  application  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
499,create  sample  project,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
500,add  ability  update  sharing  policy  composite  subsystem,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
501,improve  performance  saving  entity  using  insert  possible  mongo  template  method  bulk  insert  basic  repository  interface  extend  mongorepository  considerably  much  slower  saving  using  6000  item  took  minute  write  concern  set  journaled  expected  ability  save  matter  millisecond  using  workaround  created  customimpl  repository  class  call  mongooperation  much  faster  hoping  insert  would  builtin  feature  next  release,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
502,correctly  evaluate  contains  keyword  collection  property  currently  create  regex  keyword  containing  property  collection  like  could  also  go  check  requested  parameter  contained  collection  value  document,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
503,sort  use  metamodel  class  generated  querydsl  working  querydsl  would  like  able  sort  query  typesafe  way  building  query  able  sort  metamodel  class  generated  using  querydsl  method  getkeyforpath  class  must  improved  order  allow  dealing  metadata  name  like  customer  lastname  customermetadatacreationdate  metadata  embedded  document  metadata  name  generated  using  metamodel  class  follows  metamodel  generated  sample  project  support  sorting  embedded  document  would  also  welcomed  note  special  care  must  taken  querydsl  creates  intermediate  useless  class  must  ignored  creating  real  path  desired  field  used,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
504,add  support  push  sort  update  part  datamongo832,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
505,add  dbobject  geojson  converter  spring  data  mongodb  project  provides  geo  converter  especially  geo  json  db  object  converter  db  object  geo  json  converter  provided  write  custom  spring  converter  manage  feature  think  could  useful  spring  data  mongodb  provide  maybe  could  also  good  idea  move  class  spring  data  common  project  spring  project  could  use  type  thank,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
506,support  partial  filter  expression  indexing  introduced  mongodb  32  mongodb  32  introduced  new  index  option  allows  index  document  given  expression  matchessee  would  nice  indexed  extended,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
507,add  support  filter  aggregation  see,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
508,support  missing  aggregation  pipeline  operator  expression  support  operator  present  method  reference  node  see  note  pipeline  aggregation  stage  group  accumulator  operator  already  supported  dsl  need  operator  support  group  week  year  week  start  monday,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
509,add  missing  aggregation  operator,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
510,add  support  map  aggregation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
511,add  new  mongodb  aggregation  operator  like  index  array  reverse  array  reduce,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
512,add  replace  root  aggregation  stage,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
513,add  facet  bucket  bucket  auto  aggregation  stage,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
514,add  facet  bucket  bucket  auto  aggregation  stage,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
515,able  set  server  selection  time  mongo  client  option  using  mongo  client  option  factory  bean  hello  im  using  springdatamongo  xml  namespace  configure  mongo  client  used  application  id  like  set  server  selection  timeout  attribute  underlying  mongo  client  option  way  set  attribute  using  xml  namespace  deal  default  value  30  plain  mongo  client  option  way  long  usecase  could  possible  add  serverselectiontimeout  attribute  xml  clientoptions  tag  server  selection  timeout  method  mongo  client  option  factory  bean  timeout  set  thanks,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
516,able  set  server  selection  timeout  mongo  client  option  using  mongo  client  option  factory  bean  hello  im  using  springdatamongo  xml  namespace  configure  mongo  client  used  application  id  like  set  server  selection  timeout  attribute  underlying  mongo  client  option  way  set  attribute  using  xml  namespace  deal  default  value  30  plain  mongo  client  option  way  long  usecase  could  possible  add  serverselectiontimeout  attribute  xml  clientoptions  tag  server  selection  timeout  method  mongo  client  option  factory  bean  timeout  set  thanks,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
517,allow  usage  projection  interface  fluent  mongo  operation  read  currently  allow  mapping  document  back  dto  type  using  projection  factory  within  mongo  template  enable  support  interface  dynamic  projection,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
518,query  example  find  one  probe  type  mongo  example  mapper  inspects  probe  type  writes  type  restriction  according  known  type  mapping  context  type  assignable  probe  get  included  operator  probe  type  different  document  mongo  collection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
519,add  support  aggregation  operator  date  string  date  part  date  part,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
520,exception  trying  instantiate  entity  primitive  constructor  argument  according  document  field  data  mongo  add  one  new  primitive  type  parameter  constructor  java  class  spring  data  throw  exception  reading  old  data  case  non  primitive  parameter  pass  null  value  case  primitive  type  doesnt  pas  default  value  type,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
521,username  password  authentication  support  mongo  log  appender  java  sd  mongo  db  log  appender  currently  support  unauthenticated  db  link  let  change,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
522,refactor  entity  metadata  access  mongo  query  method  currently  mongo  query  method  us  entity  information  creator  create  entity  information  instance  used  query  execution  engine  top  determine  collection  query  collection  determined  sole  inspection  mapping  metadata  get  collection  name  rather  entity  metadata  extension  would  result  simpler  lookup  metadata  entity  information  creator  api  obsolete  entirely,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
523,polish  bean  definition  parser  avoid  warning  sts,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
524,remove  performance  hotspot,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
525,projection  follow  mongodb  convention  precisely  present  projection  sd  mongodb  aggregation  framework  support  defined  project  rendered  order  comply  mongo  db  convention  rather  rendered  like  note  projection  produce  result,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
526,grid  f  template  get  resource  location  throw  npe  dont  find  file  grid  f  template  get  resource  file  name  throw  npe  db  stored  file  name  file  name,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
527,allow  usage  criterion  within  update  usage  criterion  possible  update  allow  fine  grained  statement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
528,improve  cycle  detection  dbrefs,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
529,improve  performance  saving  entity  using  insert  possible  mongo  template  method  bulk  insert  basic  repository  interface  extend  mongo  repository  considerably  much  slower  actual  saving  using  item  took  minute  write  concern  set  journaled  expected  ability  save  matter  millisecond  using  mongo  operation  insertcollection  extends  object  batch  save  class  entity  class  workaround  created  custom  impl  repository  class  call  mongo  operation  much  faster  hoping  insert  would  builtin  feature  next  release,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
530,sort  use  metamodel  class  generated  query  dsl  working  querydsl  would  like  able  sort  query  typesafe  way  building  query  able  sort  meta  model  class  generated  using  query  dsl  method  get  key  path  class  must  improved  order  allow  dealing  metadata  name  like  customer  ast  name  customer  metadata  creation  date  metadata  embedded  document  metadata  name  generated  using  meta  model  class  follows  meta  model  generated  sample  project  support  sorting  embedded  document  would  also  welcomed  note  special  care  must  taken  creates  intermediate  useless  class  must  ignored  creating  real  path  desired  field  used,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
531,add  implementation  new  query  dsl  predicate  executor  find  order  specifier  order,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
532,add  support  min  distance  near  query,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
533,add  support  geometry  support  geo  json  query  allow  shape  converted  geo  json  format  using  geometry  operator  within  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
534,use  geo  within  instead  within  geo  query  within  deprecated  24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0
535,add  exists  method  querdsmongrepository  accepts  querdsl  predicate,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0
536,add  support  java  8  stream  return  type  repository  since  dont  provide  abstraction  stream  result  mongodb  query  client  implement  functionality  via  block  fetching  manually  deal  really  large  result  provide  way  stream  large  result  blockwise  consumer,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1
537,use  org  bson  type  instead  com  mongo  db  use  org  bson  document  mean  incomplete  list  query  query  query  basic  db  object  collection  insert  insert  collection  replace  replacing  update  collection  update  update  update  option  eg  specifying  upsert,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
538,improve  dbref  resolution  collection  currently  instance  resolved  one  one  even  collection  property  currently  cause  resolution  done  perelement  basis  cause  additional  unnecessary  database  lookup  maybe  improve  collection  handling  bit  database  lookup  done  per  property  resolution  batched,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
539,deprecate  non  mongo  client  related  configuration  option  xml  namespace  deprecate  xml  element  currently  create  mongo  instance  favor  one  creating  mongo  client  instance  attribute  create  simple  mongo  db  factory  mongo  client  uri  mongo  dutils  skip  authentication  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
540,add  support  query  example  provide  mean  allow  using  partially  filled  domain  object  pattern  actual  query  list  person  result  repository  find  example  new  example  person  sample  code  provide  example  wrapper  one  able  define  null  value  string  handling  offer  find  example  repository  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
541,add  support  query  example  provide  mean  allow  using  partially  filled  domain  object  pattern  actual  query  list  person  result  repository  find  example  new  example  person  sample  code  provide  example  wrapper  one  able  define  null  value  string  handling  offer  find  example  repository  method,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
542,provide  collectionname  mongo  mapping  event  use  repository  event  update  search  index  search  index  name  correspond  collection  name  database  often  im  able  recognize  collection  name  based  object  saved  im  unable  someone  pull  object  directly  mongo  template  change  save  back  imho  event  contain  info  collection  name  object  saved  removed  look  difficult  see  attachment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
543,provide  read  lifecycle  event  loading  dbrefs  lifecycle  event  fired  dealing  root  document  although  using  query  dsl  support  missing  see  think  would  useful  trigger  load  convert  event  loading  related  document  assume  one  use  kind  relation  dbref  relation  derives  root  entity  document  far  seen  change  minimal  provided  sample  project  github  custom  mapping  mongo  converter  fire  event  two  junits  one  fails  using  default  mapping  mongo  converter  one  us  customized  mapping  mongo  converter  relevant  part  custom  mapping  mongo  converted  start  3  method  rest  pure  cp  could  make  pr  desired  feature,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
544,add  option  specify  cursor  batch  size  repository  method  returning  stream  would  great  provide  option  set  case  etl  process  lot  gb  streaming  result  already  heaven  earth  compared  paging  mongo  db  cursor  default  implementation  set  0  mean  database  chooses  configuration  batch  size  seems  small  could  observe  fetch  data  remote  database  java  mongo  db  driver  batch  size  couldnt  verify  overriding  batch  size  give  expected  performance  boost,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
545,add  support  validator  creating  collection  note  investigate  usage  jsr303  defining  validation  propagated  collection,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
546,add  support  lookup  aggregation  performs  left  outer  join  another  collection  database,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
547,remove  package  cycle  core  core  index  index  creator  refers  mongo  db  error  code  currently  contained  mongo  exception  translator  move  mongo  db  error  code  utility  package  break  package  cycle  introduced,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
548,add  support  projection  repository  query  method,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
549,add  converter  currency,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
550,add  support  operand  aggregation  special  operator  save  aggregation  data  output  collection  get  work  spring  data  following  trick  think  new  aggregation  operation  required  going  fix,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
551,add  overload  mongo  operation  stream  take  explicit  collection  name  right  playing  spring  data  mongodb  need  multiple  collection  consisting  object  class  collection  possibly  large  even  use  mongo  template  mongo  template  stream  query  class  also  allow  specify  collection  name  also  also  mean  stream  method  definition  inconsistent  find  variant  allowing  specify  collection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
552,reactive  support  spring  data  mongo  db  investigate  reactive  paradigm  support  spring  data  mongodb  using  reactivestreams  create  prototype  includes  native  support  mongodb  reactivestreams  driver,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
553,add  support  match  mode  query  example,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
554,add  db  object  geo  json  converter  spring  data  mongodb  project  provides  geo  converter  especially  geo  json  db  object  converter  db  object  geo  json  converter  provided  write  custom  spring  converter  manage  feature  think  could  useful  spring  data  mongodb  provide  maybe  could  also  good  idea  move  class  spring  data  common  project  spring  project  could  use  type  thank,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
555,support  partial  filter  expression  indexing  introduced  mongo  db  mongo  db  32  introduced  new  index  option  allows  index  document  given  expression  match  see  would  nice  indexed  extended,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
556,abstract  mongo  configuraton  allow  multiple  base  package  document  scanning  upon  enabling  enable  mongo  auditing  getting  following  failure  unsupported  entity  com  get  risk  registration  registration  could  determine  new  strategy  happening  abstract  mongo  configuration  get  initial  entity  set  allows  scanning  one  package  package  designed  feature  based  rather  layer  based  pojos  document  annotation  various  package  solved  issue  overriding  abstract  mongo  configuration  get  initial  entity  set  main  change  addition  get  mapping  base  package  community  move  towards  package  feature  design  think  change  would  benefit  lot  people,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
557,add  support  cursor  timeout  query  mongodb  provides  cursor  option  cursor  cursor  timeout  allows  cursor  continue  exhausted  closed  beyond  mongo  default  10  minute  timeout  option  option  could  exposed  query  meta  class  added  cursor  option  query  cursor  preparer  prepare,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
558,add  support  filter  aggregation,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
559,add  support  collation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
560,add  new  mongodb  34  aggregation  operator  like  index  array  reverse  array  reduce,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
561,add  facet  bucket  bucketauto  aggregation  stage,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
562,add  template  wrapper  reduce  method  overload  mongo  template  use  indirection  provide  meaningful  fluent  api  call  like,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
563,add  templatewrapper  reduce  method  overload  mongotemplate  use  indirection  provide  meaningful  fluent  api  call  like,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
564,able  set  serverselectiontimeout  mongo  client  option  using  mongo  clien  toptions  factory  bean  hello  im  using  springdatamongo  xml  namespace  configure  mongo  client  used  application  id  like  set  server  selection  timeout  attribute  underlying  mongo  client  option  way  set  attribute  using  xml  namespace  deal  default  value  30  plain  mongo  client  option  way  long  usecase  could  possible  add  server  selection  timeout  attribute  xml  clientoptions  tag  server  selection  timeout  method  mongo  client  option  factory  bean  timeout  set  thanks,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
565,add  support  aggregation  result  streaming  would  great  option  stream  result  set  aggregation  operation  stream  option  find  operation  worked  working  issue  limitation  explain  option  cant  used  streaming  result  custom  option  support  streaming  result  operation  work  correctly  also  return  stream  used  fetch  result  whereas  original  method  mapping  result  empty  would  great  could  review  code  tell  anything  changed  improved  whats  wrong  creating  pull  request  id  edit  created  pull  request  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
566,support  reactive  aggregation  streaming  add  support  stream  aggregation  result  flux  reactive  mongo  operation  aggregate,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
567,add  partial  index  support  reactiveindexoperations,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
568,add  fluent  alternative  reactive  mongo  operation  big  fan  new  fluent  api  provided  part  datamongo1563  think  api  would  useful  reactive  mongo  operation  well  contribute  related  kotlin  extension  could  allow  demonstrate  new  fluent  api  application  since  would  perfect  use  case,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0
569,fix  dependency  cycle  cycle  package  nothing  config  depend  repository,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
570,allow  usage  projection  interface  fluent  mongo  operation  read  currently  allow  mapping  document  back  dto  type  using  projection  factory  within  mongo  template  enable  support  interface  dynamic  projection,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
571,move  fluent  api  repository  query  execution  moving  new  fluent  api  mongo  operation  able  optimize  thing  repository  query  execution  able  define  type  read  query  mapping  type  produce  allow  u  get  rid  additional  step  dto  mapping  read  fluent  api  returning  new  instance  intermediate  step  allow  u  set  broad  coordinate  type  read  e  keep  around  rather  deciding  late  execution  lifecycle,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
572,query  b  yexample  find  one  probe  type  mongo  example  mapper  inspects  probe  type  writes  type  restriction  according  known  type  mapping  context  type  assignable  probe  get  included  operator  probe  type  different  document  mongo  collection,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
573,add  support  mongo  db  change  stream  mongodb  36  introduces  new  feature  called  change  stream  emits  change  particular  collection  mongo  collection  create  change  stream  publisher  change  stream  publisher  get  resume  token  last  document  saw  previous  change  stream  cursor  bson  document  resume  token  change  stream  document  get  resume  token  pas  resume  token  resume  function  continue  change  stream  cursor  publisher  watch  accepts  aggregation  pipeline  filter  transform  element,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
574,support  bitwise  query  operator  criterion  builder  support  mongodb  bitwise  query  operator  introduced  32  allow  match  field  given  bitmasks  feature  would  good  addition  existing,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
575,allow  document  replacement  via  mongo  collection  fin  one  replace  mongo  collection  find  modify  method  seems  find  one  update  used  replacement  find  modify  allows  field  value  update  find  one  update  break  ability  find  modify  replacement  document,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
576,allow  document  replacement  via  mongo  collection  findone  replace  mongo  collection  find  modify  method  seems  find  one  update  used  replacement  find  modify  allows  field  value  update  find  one  update  break  ability  find  modify  replacement  document,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
577,migrate  document  apibased  querydsl  implementation  querydsl  support  spring  data  mongodb  us  legacy  dbobject  api  going  eol  point  time  consider  move  towards  document  apibased  querydslcomponent  query  creationexecution  lose  querydsl  capability  dbobject  longer  supported  driver  moving  document  api  allows  cleanup  code  get  rid  legacy  apibridge  code  time  querydsl  provide  documentapi  based  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
578,add  support  mapreduce  reactivemongooperations,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
579,decouple  reactive  mongo  bit  blocking  mongoclient,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
580,provide  additional  option  setting  write  concern  per  operation  basis  default  write  concern  normal  wait  server  error  update  method  return  lazy  version  write  result  ie  get  update  result  another  call  database  thus  update  result  check  one  call  database  performance  problem  application  work  write  concern  normal  default  effective  way  update  result  checking  call  write  concern  safe,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
581,support  geting  index  information  collection  mapped  class  see  getting  list  index  collection  json  data  structure  returned  query  mapped  java  class  easy  accesstypesafe  usage,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
582,change  package  name  class  mongo  log  appender  change  package  name  remove  document  part,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
583,allow  collection  parameter  query  using  query  annotation  repository  id  like  something  like  currently  try  run  query  obviously  fails  string  quoted  believe  could  easily  fixed  adding  code  properly  handle  collection  specifically  collection  string,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
584,enums  cant  used  criterion  give  json  object  serialization  error  message  make  criterion  work  use  name  method  enum  thanksdonny,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
585,nin  method  criterion  take  collection  like  method  criterias  method  take  variable  argument  well  collection  however  nin  method  accept  variable  argument  make  le  useful  thing  like  finding  list  lost  value  using  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
586,lazy  load  dbref  dbrefs  appear  loaded  eagerly  would  nice  support  storing  dbrefs  document  able  lazy  manually  load,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
587,adapt  new  entity  instantiation  api  spring  data  common,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
588,support  keywords  query  creation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
589,improve  mongodbutils  api  mongo  db  api  still  us  low  level  string  char  parameter  capture  username  password  rather  take  user  credential  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
590,username  password  authentication  support  mongo  log  appender  java  sd  mongo  db  log  appender  currently  support  unauthenticated  db  link  let  change,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
591,improve  query  dsl  implementation  internals  currently  spring  data  mongo  db  query  constructor  take  mongo  operation  well  mongo  db  serializer  latter  actually  spring  data  mongo  db  serializer  turn  take  mongo  converter  obtained  mongo  operation  instance  thus  second  argument  spring  data  mongo  db  query  obsolete  internalized,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
592,javaconfig  support  mongo  repository,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
593,support  calling  mongo  db  stored  javascripts  support  calling  mongodb  stored  javascripts,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1
594,polish  namspace  implementation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
595,grid  f  template  setting  file  content  type  hello  cant  find  way  set  value  content  type  key  db  f  file  collection  using  grid  f  template  class  possible  setting  value  overloaded  version  store  method  something  like  make  sense  thanks  carlo  micieli,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
596,querymapper  correctly  transform  association  currently  query  mapper  transform  value  dbref  object  value  actually  represents  association,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
597,unify  usage  sort  apis  query  api  query  api  currently  work  dedicated  sort  class  different  way  sort  class  work  spring  data  common  allow  query  api  used  sort  spring  data  common  deprecate  custom  one  remove  entirely  next  major  release,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
598,add  background  attribute  indexed  compound  index  mongodb  accept  since  version  22  background  indexation  please  add  function  annotation  indexed  compound  index,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
599,provide  support  remove  bydelete  method  like  find  repository  interface  repository  interface  define  method  like  want  method  deleting  eg  implement  custom  repository  please  provide  also  automatic  interface  method  support  like  already,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0
600,refactor  entity  metadata  access  mongo  query  method  currently  mongo  query  method  us  entity  information  creator  create  entity  information  instance  used  query  execution  engine  determine  collection  query  collection  determined  sole  inspection  mapping  metadata  get  collection  name  rather  entity  metadata  extension  would  result  simpler  lookup  metadata  entity  information  creator  api  obsolete  entirely,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
601,add  support  new  aggregation  framework  mongo  22  new  aggregation  framework  feature  could  add  query  criterion  support,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
602,fix  architecture  inconsistency  created  mongo  data  integrity  violation  exception  mongo  data  integrity  violation  exception  creates  package  dependency  core  creates  cyclic  dependency  root  core  package  move  exception  core  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
603,projection  follow  mongodb  convention  precisely  present  projection  sd  mongodb  aggregation  framework  support  defined  project  rendered  order  comply  mongo  db  convention  rather  rendered  like  note  projection  produce  result,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
604,repository  find  field  ignore  case  doesnt  work  create  simple  user  document  email  field  getter  setter  provided  repository  working  find  user  document  working  don’t  find  user  document  also  try  first  name  also  doesn’t  work  log  using  springdatamongo  db  131  try  debug  springdatacommon  handle  find  strategy  lookup  right  using  query  dsl  handle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
605,support  spel  expression  define  arithmetical  projection  operation  aggregation  framework,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0
606,create  geospatial  index  type  2d  geo  spatial  indexed  annotation  geo  spatial  indexed  field  create  2d  index  would  fine  able  create  index  type  geo  haystack  2d  sphere,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
607,adapt  change  spring  data  common  triggered  repository  initialization  change,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
608,grid  f  template  getresource  location  throw  npe  dont  find  file  grid  f  template  get  resource  file  name  throw  npe  db  stored  file  name  file  name,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
609,allow  usage  criterion  within  update  usage  criterion  possible  update  allow  fine  grained  statement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
610,add  support  common  geospatial  structure,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,1
611,add  support  cond  null  operator  aggregation  operation  add  support  cond  operator  group  project  operation  conditional  operator  describe,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
612,add  new  field  naming  strategy  make  configurable  xml  java  config  company  need  insert  record  mongo  java  app  read  nodejs  app  keeping  existing  data  model  mongo  wed  like  keep  field  name  lower  case  underscore  snake  case  ive  added  xml  java  config  attribute  field  naming  strategy  created  class  lower  case  underscore  field  naming  strategy  pull  request  forthcoming  via  github  ill  happy  make  change  see  fit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
613,overhaul  automatic  index  creation  index  creation  consider  property  path  creating  index  lead  broken  index  creation  nesting  entity  might  require  index  structure  assume  following  structure  proposed  solution  entity  annotated  document  shall  inspected  traversing  property  structure  path  used  index  creation  resolved,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
614,add  support  bulk  operation  introduced  mongodb  26  latest  version  spring  data  mongo  db  support  bulk  operation  introduced  mongodb  26  mongo  db  recommends  using  new  write  protocol  new  bulk  api  bulk  operation,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
615,add  support  creating  text  index,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
616,add  support  query  modifier  support  query  modifies  across  board  eg  would  like  limit  query  x  m,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
617,allow  pas  option  aggregation  pipeline  sometimes  necessary  pas  additional  configuration  aggregation  pipeline  example  circumvent  memory  limit  100  mb  aggregation  pipeline  stage  writing  one  pas  allow  disk  use  true  option  allow  sorting  disk  larger  datasets,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
618,add  support  deriving  full  text  query  possible  combine  full  text  search  criterion  definition  query  possible  indentify  full  text  parameter  create  accoring  query,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,0
619,add  support  date  time  operator  aggregation  framework  mongo  db  aggregation  framework  support  range  date  time  operator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
620,add  support  reading  meta  projection  textscore  document  using  text  search  allows  add  meta  projection  eg  text  score  value  must  written  storing  document  shall  mapped  reading,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
621,add  support  spel  expression  query  adapt  spel  support  spring  data  jpa  spring  data  mongodb  well,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0
622,enable  directory  scanning  java  7  feature  watchservice  would  like  offer  implementation  defaultdirectoryscanner  extended  class  listeligiblefiles  im  listening  o  event  java  7  feature  watchservice  way  1i  sure  im  handling  file  timethere  one  create  event  file  2a  reliable  way  pick  file  directory  3for  existing  file  directory  implemented  initmethod  scan  directory  fileswalkfiletree  also  java  7  feature  first  time  call  listeligiblefiles  im  handling  existing  file  next  time  treat  create  event  came  watchservice  4in  initmethod  iregistered  subdirs  root  directory  supplied  directory  property  java  7  feature  fileswalkfiletree,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
623,add  ability  customize  spel  evaluation  context  used  throughout  framework  example  custom  propertyaccessors,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
624,jms  dslxml  inconsistent  receivetimeout  xml  parser  set  default  nowait  dsl  leaf  default  infinite  wait  consistent  dont  think  nowait  correct  reason  discussed  end  answer  infinite  wait  incorrect  maybe  1000  second  thought  perhaps  nowait  1  cachingconnectionfactory  cacheconsumers  otherwise  1000,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
625,filter  defined  scanner  get  overwritten  one  defined  filereadingmessagesource  described  httpstackoverflowcomquestions28087753cantsetadifferentfilterinfileinboundchanneladapterandscanner  confirmed  artem  cant  define  2  different  filter  scanner  inboundchanneladapter  look  documentation  misleading  feeling  use  2  independent  component  actually  filereadingmessagesource  overwrites  scanner  filter  config,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
626,add  pseudotransaction  support  pollers  inbound  channel  adapter  inherently  transactional  1  almost  every  business  case  requirement  never  lose  message  2  adapter  poll  input  message  usually  want  persist  progress  server  restarts  doesnt  reprocess  everything  scratch  preventduplicatestrue  currently  useless  progress  persisted  way  achieving  delete  input  fileemailwhatever  committed  outboundadapter  messagestore  aftercommit  inputdeletion  transactionsynchronization  proposed  mark  fisher  difficult  setup  supported  directly  si  many  way  couple  example  full  example  could  easily  expressed  file  poller,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
627,add  support  tcp  endpoint  sendreceive  entire  message  add  attribute  extractpayload  defaulttrue  similar  jms  endpoint  tcp  connection  factory  supporting  transfer  complete  message  note  extractpayload  false  switch  default  deserializer  bytearraycrlfserializer  defaultdeserializer  java  serialization  assign  new  message  id  deserializing  complete  message  put  id  transmitted  message  header  tcpremotemessageid  support  udp  covered  separate  jira  int1808  complex  adapter  dont  currently  support  pluggable  serializers,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
628,add  buffer  pool  abstractbytearrayserializer  ip  deserializers  used  xd  module  shell  processor  byte  array  created  discarded  message  add  pooling  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1
629,messagehistory  applied  component  registered  run  time  eg  dynamic  integration  flow,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
630,make  errormessagesendingrecoverer  generic  introduce  errormessagestrategy  customization,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
631,filetransferringmessagehandler  add  support  deleting  source  file  succesful  transfer  would  nice  handler  delete  source  file  written  successfully  remote  file  adapter  sftp  ftp  etc  file  outbound  adapter  transformer  already  support  deleting  source  file  created  customized  filetransferringmessagehandler  handle  case  interested  change  made  original  class  please  let  know,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
632,add  scripting  support  inboundchanneladapter  inboundchanneladapter  currently  support  expression  ref  nested  bean  support  nested  script  element  spel  doesnt  support  escape  character  would  useful  able  use  workaround,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
633,adding  support  securitycontext  propagation  lot  case  necessary  use  securitycontext  async  mesage  flow  inside  web  application  principal  appeared  httprequest  springsecurityfilterchain  stored  threadlocal  holder  first  propose  add  supoprt  global  channelinterceptor  propagetes  securitycontext  async  mesasge  flow  solution  sorry  groovy  code  well  always  place  application,1,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,1
634,cannot  use  kotlin  spring  integration  504  java  still  working  integration  flow  dsl  notation  compiled  fail  run  time  spring  integration  cannot  find  method  use  route  config  rewritten  java  working  one  thing  kotlins  lambda  synthetic  class  java  spring  integration  see  lambda  another  hand  worked  dsl  thing  transform  still  work  kotlin  lambda  avoided  explicit  method  name  ugly  anyone  knew  solution  except  apply  shifting  configuration  sp  int  java,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
635,add  objecttojsontransformerresulttypebytes  downstream  add  mode  better  efficient  downstream  component  based  like,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
636,expose  message  id  generation  strategy,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
637,add  metadatavaluestrategy  allow  determine  value  metadatastore  key,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
638,update  redis  collection  updating  class  name  consistent  xml  element  naming  element  named  storeoutboundchanneladapter  classnames  rediscollection  consistent,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,1,1
639,set  abstractpersistentacceptoncefilelistfilter  default  filter  abstractremotefilestreamingmessagesource  abstractinboundfilesynchronizer  right  default  therefore  poll  try  consider  remote  file  candidate  local  copy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
640,improve  eventinboundchanneladapter  perfomance  according  comment  linked  pr  overhead  accepts  filter  provided  type,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1
641,amqp  outbound  support  contenttypedelegatingmessageconverter  converter  invoked  empty  objectuse  mapped  property  invoking  message  converter  delegating  converter  decide  converter  use  change  method  conversion  adapter  instead  template  case  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
642,provide  annotation  configuration,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
643,add  support  resource  loading  inbound  channel  adapter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
644,jpa  adapter  improve  flush  behavior  typical  flush  behavior  jpa  operation  executes  flush  actual  execution  sql  query  transaction  commit  current  implementation  sufficient  regard  certain  scenario  example  want  poll  database  record  time  want  delete  fetched  data  sourcepollingchanneladapter  configured  transaction  interceptor  transctional  behavior  wrapped  around  dopoll  method  sourcepollingchanneladapter  may  may  issue  user  architecture  flush  state  synchronization  database  currently  occur  message  sent  outputchannel  thus  may  lead  unexpected  behavior  issue  even  pronounced  using  directchannels  thread  mean  transaction  commit  including  flush  may  occur  execution  1  component  downstream  order  improve  situation  provide  flexibility  user  need  implement  following  additional  logic  jpa  adapter  add  attribute  flush  default  true  mean  jpa  adapter  automatically  synchronize  persistence  state  database  actual  commit  happen  think  flush  shall  happen  adapter  level  individual  jpa  operation  eg  case  selectsubsequent  delete  one  flush  shall  occur  believe  attribute  added  case  user  want  use  multiple  jpa  adapter  flow  likely  dont  want  flush  session  adapter  may  lead  inefficiency  need  make  sure  document  behavior  various  usecases  exhaustively  reference  manual  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
645,add  support  compilestatic  compiler  option  groovy  script  component  supported  already  methodlevel  hint  instead  make  bit  easier  le  verbose  could  utilize  outofthebox  feature  groovy  script  component  attempt  compile  statically  see  information  blog  post  script  still  one  line  based  java  runtime  groovy  already,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
646,improve  messaging  annotation  handling  abstractreplyproducingmessagehandler  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
647,support  reactive  webclient  currently  support  thus  blocking  io  suggest  add  support  thus  unblocking  io  like  via  using  constructing  scalable  io  sending  http  request  many  destination  like  100,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1
648,add  outputchannel  late  binding  support  see  related  discussion  java  dsl  assumes  channel  autocreation  phase  doesnt  even  feature  closer  consumer  component  hurt  create  channel  inbound  channel  adapter  perspective  treated  based  channel  autocreation  logic  xml  component,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
649,jackson2jsonobjectmapper  consistent  similar  spring  core  around  objectmapper  configuration  javadocs  well  code  configure  default  way,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
650,move  springintegrationmqtt  extension  core  move  module  polish  add  doc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
651,consider  adding  headerpropagationaware  interface  arpmh  also  implement  interface  propagating  message  handler  extend  abstractmessageproducinghandler  directly  aggregator  chain,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
652,expressionevaluatingadvice  send  advicemessage  errormessage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
653,provide  enablepublisher  support  although  publisherannotationbeanpostprocessor  defined  integration  infrastructure  publisher  default  hook  configure  defaultchannel  ruther  configure  manually  bean  definition,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
654,add  inputstream  support  filewritingmessagehandler  could  useful  filewritingmessagehandler  accept  inputstream  datainput  bytebuffer  path  message  payloud,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
655,merge  messaging  metaannotation  attribute  using  messaging  metaannotations  eg  annotated  framework  currently  considers  attrbutes  framework  annotation  provide  increased  flexibility  consider  attribute  name  user  annotation  supplementoverride  framework  annotation  would  allow  user  annotation  specify  common  attribute  individual  use  annotation  supply  attribute,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
656,add  iterator  ability  xpathmessagesplitter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
657,support  timeout  amqp  pollablechannel  since  support  timeout  receive  refactor  pollable  channel,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
658,implement  closeableflushable  propertiespersistingmetadatastore,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
659,come  unique  bean  name  logic  component  defined  inside  chain  register  additional  bean  eg  jpaexecutor  retrievingjpaoutboundgatewayparser  since  handler  arent  registerd  bean  defined  inside  chain  issue  registration  internal  additional  component  bean  whose  beanid  based  result  nonregistered  future  current  main  issue  end  define  several  similar  component  eg  jparetrievingoutboundgateway  jpaupdatingoutboundgateway  etc  one  inside  last  one  overwrites  registered  additional  bean  us  result  suffix  jpaexecutor  register  bean  last  one  orgspringframeworkintegrationjpaoutboundjpaoutboundgatewayfactorybean0  result,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
660,rotate  sftp  serversdirectories  poll  add  smart  poller  advice  rotate  across  multiple  directoriesservers  several  policy  standard  rotate  file  found  fair  rotate  every  poll  custom,1,1,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0
661,add  support  lazyload  messagegroupmessages  persistent  messagestore  proposed  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
662,ftp  directtocontents  message  source  scst  sftp  source  option  read  file  load  content  emit  individual  line  content  text  fact  really  viable  option  cf  since  leaf  payload  file  reference  add  also  consider  linebased  splitter  option,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
663,add  support  messagegroupstore  redis  module,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
664,refactor  global  interceptor  added  list  channel  interceptor  currently  relying  directfieldaccessor  get  list  add  interceptor  list  really  clean  also  created  problem  channel  proxied  int1896  although  solved  approach  clean  would  like,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
665,add  spel  support  continuousquerymessageproducer  add  ability  set  payload  expression  similar  already  cachelisteningmessageproducer,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1
666,match  exception  hierarchy  errormessageexceptiontyperouter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
667,implement  mongodb  prioritycapablechannelmessagestore,1,1,1,0,1,1,1,0,1,1,1,0,0,0,0,0,1
668,introduce  enablemessagehistory,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
669,add  support  groovyobjectcustomizer  groovy  script  executing  processor  groovy  control  bus,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
670,make  expressionevaluatingrequesthandleradvice  dslfriendly  add  support  channel  name,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
671,integrationevaluationcontextawaresetintegrationevaluationcontext  invoked  afterpropertiesset  bean  implementing  integrationevaluationcontextaware  expect  integrationevaluationcontext  set  part  bean  initialization  process  due  current  approach  setting  context  integrationevaluationcontextawarebeanpostprocessoraftersingletonsinstantiated  afterpropertiesset  called  initialization  take  place  reconsider  current  approach  reconcile  need  preventing  early  beanfactory  access  expectation  initializingbean,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
672,extend  integration  mbean  export  include  endpoint  integrationmbeanexporter  currently  expose  mbeans  messagesource  messagehandler  messagechannel  object  certain  gateway  behave  similar  fashion  messagesource  object  configured  return  reply  give  inconsistent  picture  via  jmx  example  switching  mean  one  loses  ability  startstop  adapter  using  jconsole  endpoint  control  via  work  fine  case  us  different  mechanism  reach  lifecycle  method  would  nice  could  also  expose  abstractendpoint  instance  first  class  citizen  mbeans  even  lifecycle  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
673,allow  configure  messaging  annotation  method  level  messagasource  messagehandler  component  eg  filereadingmessagesource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
674,gatewayproxy  keep  track  method  triggered  message  flow  want  try  avoid  manually  define  method  gateway  bean  current  setup  gateway  method  multiplexed  use  http  outbound  gw  order  unnecessarily  create  bunch  http  gateway  make  happen  need  pas  along  url  unique  per  method  usual  way  would  define  method  xml  config  setup  static  header  there  way  create  static  header  via  annotation  read  http  outbound  gateway  would  leave  defining  method  messy  interface  want  able  say  something  likeand  later  header  enricher  read  annotation  there  one  thing  missing  gateway  bean  keep  track  method  trigged  message  originatingmethodcall  methodinvocation  reference  would  trivial  thought  aside  1  worked  around  making  aspect  storing  wanted  threadlocal  look  unclean  approach  aside  2  would  necessary  possible  define  static  header  per  method  annotation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
675,dsl  consider  making  final  log  terminal  flow  end  perhaps  could  logging  adapter  rather  wiretap  automatically  set  output  channel,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
676,use  annotatedelementutils  instead  annotationutils  wherever  feasible  issue  spring  integration  equivalent  spring  framework  issue  following  copied  status  quo  spring  framework  42  introduced  support  explicit  annotation  attribute  override  via  however  due  historical  reason  spring  code  base  typically  us  lookup  method  support  attribute  override  h2  deliverable  migrate  lookup  method  aswherever  feasible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
677,add  support  bridgefrom  bridgeto  messagechannel  bean  level  annotation  configuration  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
678,add  transactionsynchronizationfactorybuilder  fluent  usage  javaconfig,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
679,provide  mechanism  configure  spel  propertyaccessors  function  java  configuration  add  pa  user  code  would  late  many  case  component  already  gotten  evaluation  context  would  done  run  early  application  context  lifecycle  open  jira  issue  might  find  easier  small  xml  snippet  one  class,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
680,ftp  outbound  gateway  support  nlst  operation  l  command  ftp  outbound  gateway  command  used  file  name  option  ftp  command  supported  alternative  way  get  file  name  issue  production  ftp  server  could  list  directoriesfiles  command  used  return  empty  directory  file  listaccording  understanding  implementation  command  post  operation  extract  list  ftp  file  name  retrieved  file  list  based  command  case  return  nothing  file  name  could  extracted,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
681,expose  serializers  redis  store  inbound  adapter  kind  outbound  inbound  stil  need  done,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
682,ftp  outbound  adapter  append  command  support  would  nice  able  append  existing  remote  file,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0
683,global  wire  tap  pattern  matching  improvement  option  add  regex  support  add  negation  simple  pattern  like  done  recently  subsequently  add  property  simple  pattern  combination,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
684,using  one  channel  different  gateway  configuration  project  tcpgateway  interface  send  method  use  gwajbsendreuest  get  response  thirdparty  service  change  logic  implement  different  timeout  connection  depending  response  internal  information  decided  create  another  gateway  different  timeout  find  wont  work  far  understoof  gateway  use  channel  best  practice  problem  ive  found  publishsubscribechannel  may  solve  problem,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
685,orgspringframeworkintegrationwsmarshallingwebserviceoutboundgateway  field  uri  doesnt  work  way  deafulturi  work  orgspringframeworkwsclientcorewebservicetemplate  webservicetemplate  field  defaulturi  understand  uri  http  field  uri  understands  http  uri  one  need  use  jms  uri  need  implement  properly  documented  would  great  could  make  uri  field  understands  jms  uris  update  documentation  user  easily  find  need  implement  destinationprovider,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
686,way  tcpoutboundgateway  use  concept  pool  tcp  connection  certain  case  need  connect  tcp  server  keep  number  connection  subsequent  use  similar  way  jdbc  pool  work  despite  fact  tcpconnectionfactory  singleuse  attribute  set  false  tcpconnectionfactory  one  one  tcp  connection  therefore  connection  pooling  possible  besides  tcpoutboundgateway  request  acquires  semaphore  handlerequestmessage  method  mean  one  thread  send  outgoing  tcp  request  single  point  time  proposal  introduce  concept  connection  pooling  tcpconnectionfactory  would  let  user  define  pool  parameter  initial  maximum  number  connection  wait  timeout  etc  factory  might  use  common  pool  technique  implement  pooling  moment  order  use  one  tcp  connection  came  workaround  creating  2  instance  tcpoutboundgateway  2  instance  tcpconnectionfactory  since  tcpoutboundgateways  listen  directchannel  roundrobin  balancing  trick,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
687,cover  new  applicationevent  support  spring  framework  42,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
688,jmx  counter  use  atomicinteger  small  roll  leading  inaccurate  statistic  use  atomicinteger  class  jmx  osimonitor  package  mean  application  consume  lot  event  counter  roll  relatively  short  space  time  atomiclong  would  better  replacement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
689,consider  adding  headerpropagationaware  interface  arpmh  also  implement  interface  propagating  message  handler  extend  directly  aggregator  chain,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
690,add  gpfbs  integration  graph,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
691,sftp  adapter  doc  sftp  adapter  documentation  could  use  enhancement  sftp  outbound  channel  adapter  section  described  stackoverflow  reference  url  include  working  example  setremotedirectoryexpression  method  show  one  dynamically  compute  directory  path  based  data  message  either  payload  header,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
692,httprequestexecutingmessagehandler  contenttype  header  httprequestexecutingmessagehandler  via  httpoutboundchanneladapter  populates  contenttype  header  http  request  even  applicable  eg  get  contenttype  meant  identify  message  body  post  put  request  make  sense  populate  http  method  get  head  delete  trace  optional  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
693,use  channelresolvers  instead  beanfactory  support  java  dsl  several  component  set  allow  late  binding  channel  name  code  access  directly  instead  using  precludes  configuration  alternative  channel  resolver  example  xd  might  want  configure  route  discarded  message  named  channel  order  xd  could  configure  bean  found  module  deployment  way  thing  applies  possibly  component  however  generalize  use  channel  resolver  everywhere  late  channel  binding  added  could  even  consider  backporting  41x  given  low  risk  change,1,0,1,0,1,0,0,0,1,0,0,0,1,0,0,0,0
694,tcp  add  mechanism  allow  connection  subclass  provide  something  like  user  return  subclass  example  wrap  socket  input  stream,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
695,jvm  npe  selectorclose  circumstance  perhaps  unregistered  selector  jvm  throw  npe  closing  selctorwe  currently  catch  check  selector  registered  change  catch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
696,extend  groovyscript  tag  support  scriptvariablegenerator  strategy  see  forum  topic  discussion  patch,1,0,0,0,0,0,0,0,1,1,1,1,0,0,0,1,1
697,file  synchronizer  suppress  interruptedexception  stack  trace  stop  problem  occurred  synchronizing  remote  local  directory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
698,coordinate  json  transformer  amqp  jsonmessageconverter  amqp  adaptes  use  jsonmessageconverter  converter  createsrequires  type  information  messageproperties  add  functionality  adapter  make  messageproperties  first  class  amqp  header  add  functionality  json  transformer  createunderstand  type  header  usedcreated  amqp  jsonmessageconverters,1,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,0
699,implement  concurrentmetadatastore  extend  adding  method  change  implement  change  use  return  existing  object  file  timestamp  check  timestamp  remote  file  timestamp  match  ignore  file  dont  match  use  method  update  key  value  hasnt  changed  enable  sftp  inbound  adapter  work  clustered  environment  one  instance  process  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
700,channelinterceptoraware  support  removal  individual  interceptor  see  xd  perhaps  2  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
701,make  userdefined  prefix  configurable  defaulthttpheadermapper  setting  custom  header  httpoutboundgateway  appending  x  header  making  call  boolean  variable  enablesdisables  behaviour,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
702,extend  groovyscript  tag  support  scriptvariablegenerator  strategy  setting  custom  header  httpoutboundgateway  appending  x  header  making  call  boolean  variable  enablesdisables  behaviour,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
703,developer  want  able  supply  resttemplate  used  httpoutboundchanneladaptergateway  unfortunately  connection  related  item  configure  requestfactory  pain  butt  even  try  mock  sanely  work  around  get  something  clean  readable  exposing  resttemplate  including  example  along  pattern,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
704,jmsmessagedrivenendpoint  contains  method  getcomponettype  rather  getcomponenttype  class  contains  method  method  named  believe  methodname  contains  typo  instead  note  additional  n  final,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
705,tcp  provide  option  separate  connection  establishment  message  flow  summary  provide  option  configure  tcp  client  receive  data  without  sending  data  server,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
706,defaultconfiguringbeanfactorypostprocessor  create  default  bean  provided  parent  application  context  would  make  easier  provide  resource  shared  thread  pool  error  channel  parent  context  currently  achieved  declaring  alias  child  context  causing  report  true,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
707,add  info  message  p2p  channel  one  subscriber,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
708,imap  inbound  channel  adapter  could  allow  move  folder  processed  message  looking  requirement  around  imap  something  im  intending  implement  contribute  extension  existing  imap  channel  adapter  currently  processed  message  either  delete  mark  read  id  like  suspect  use  case  many  mail  scenario  file  successfully  processed  message  specified  folder  different  folder  message  attempted  processed  failed  would  work  scenario  validation  transformation  occur  queue  involved  luxury  would  provide  strategy  interface  determining  destination  folder  based  thrown  exception,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
709,jmschannel  support  contextpropertyplaceholder  property  concurrency  setting  par  value  concurrency  property  assign  concurrentconsumers  maxconcurrentconsumers  underlying  container  however  happens  postprocessors  run  therefore  propertyplaceholder  hasnt  yet  substituted  possible  solution  jmschannel  concurrentconsumers  maxconcurrentconsumers  property  passed  straight  container  allowing  later  substitution  property,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
710,add  pseudotransaction  support  pollers  inbound  channel  adapter  inherently  transactional  almost  every  business  case  requirement  never  lose  message  adapter  poll  input  message  usually  want  persist  progress  server  restarts  doesnt  reprocess  everything  scratch  preventduplicatestrue  currently  useless  progress  persisted  way  achieving  delete  input  fileemailwhatever  committed  outboundadapter  messagestore  aftercommit  inputdeletion  transactionsynchronization  proposed  mark  fisher  difficult  setup  supported  directly  si  many  way  couple  example  full  example  could  easily  expressed  file  poller,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
711,bytearraylengthheaderserializer  accept  twobyte  header  connecting  legacy  system  use  tcp  socket  least  experience  twobyte  header  norm  message  delimitation  despite  provided  4bytelength  powerful  testing  si  patched  bytearraylengthheaderserializer  adding  constructor  support  way  patch  attached  imho  would  really  useful  functionality  distribution,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
712,polish  test  intermittently  break  ci  failed  error  seem  intermittent  failure  fixed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
713,outboundchanneladapter  support  expression  attribute  mutually  exclusive  refmethod  inner  bean,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
714,add  wildcards  support  headerfilter  header  filter  component  configured  providing  array  string  wildcards  currently  allowed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
715,httprequestexecutingmessagehandler  contenttype  header  populates  contenttype  header  http  request  even  applicable  eg  get  contenttype  meant  identify  message  body  post  put  request  make  sense  populate  http  method  get  head  delete  trace  optional  option,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
716,add  support  messagestore  redis  module,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
717,simplify  cookie  handling  httpoutbound  gateway  consider  following  server  return  setcookie  header  containing  currently  defaulthttpheadermapper  map  header  possible  mean  without  intervention  cookie  sent  back  setcookie  header  instead  cookie  header  integration  flow  wish  implement  work  flow  would  use  custom  header  mapper  otherwise  manipulate  header  move  next  request  consider  making  cooky  first  class  citizen  scenario  providing  automated  configurable  mechanism  perhaps  subclass  dhhm  handle  cooky  appropriately,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
718,add  namespace  support  gemfire  inboundoutbound  channel  adapter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
719,clean  ip  module  sonar  code  rule  violation,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
720,add  namespace  support  continuous  query  inbound  channel  adapter,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
721,provide  way  catchhandle  tcp  adapter  sockettimeoutexception  using  tcpconnectionfactory  tcpinboundchanneladapter  listen  data  arriving  socket  port  configured  sotimeout  attribute  tcpconnectionfactory  time  socket  timeout  interval  log  following  message  debug  message  look  something  like  debug  read  exception  sockettimeoutexceptionnullread  timed  able  get  hold  handle  catch  exception  perform  application  logic  please  provide  way  catch  handle  exception  tcpadapter  via  event  way,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
722,add  ability  limit  connection  ftpsessionfactory  destination  ftp  server  limit  concurrent  ftp  connection  use  taskexecutor  parallelize  file  transfer  router  number  different  destination  server  thus  unacceptable  limit  concurrent  connection  taskexecutor  result  im  getting  following  exception  caused  f  response  421  received  server  closed  connection  itd  great  maximal  concurrent  ftp  connection  limit  side,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
723,add  ssl  support  tcp  connectionfactories  jdk  ssl  support  built  around  blocking  provided  implementation  sslengine  used  support  ssl  nio,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
724,ip  module  code  improvement  continued  improvement  code  style,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
725,add  python  scripting  support  add  pythonscriptexecutor  provides  special  handling  required  pyhon  work  scripting  framework,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1
726,messagegroupqueue  load  message  messagestore  memory  upon  first  call  poll,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
727,filetransferringmessagehandler  add  support  writing  file  temporary  directory  current  implementation  writes  file  configurable  suffix  directory  current  sftp  customersusers  prefer  use  temporary  directory  file  must  moved  temporary  directory  destination  directory  written  successfully  handle  case  created  customized  filetransferringmessagehandler  interested  change  made  please  let  know,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
728,improve  simplemessagestore  address  concurrency  issue  resulted  int2221  placeholder  provide  detail  later  simple  fix,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
729,come  strategy  handling  serialization  temp  channel  see  comment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
730,add  ability  supply  procedure  name  message  header  andor  using  spel  would  possible  supply  stored  procedure  name  one  stored  procedure  adapter  stored  procedure  gateway  dynamically  instead  predefining  configuration  example  would  possible  supply  one  message  header  extract  message  using  spel  need  able  run  different  stored  procedure  exactly  signature  integer  return  value  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
731,add  support  full  restful  requestmappings  http  inbound  adapter  info  see  springmvc  reference  manual,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
732,parameterize  filetransferringmessagehandler  also  need  remove  warning  several  test  method  change  made  filetransferringmessagehandler,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
733,ammr  add  managedoperation  setchannelmappings  would  useful  could  used  replace  mapping  dynamic  router  consider  supported  command  processor  using  control  bus  consider  adding  simply  adding  enables  capability  using  custom  converter  fix  test  sure  want  include  robust  version  converter  perhaps  converter  candidate  core,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
734,add  containerclass  option  messagedrivenchanneladapter  container  definition  jms  module,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
735,tcp  client  connectionfactory  failover  provide  mechanism  say  comma  delimited  list  allow  client  tcpconnectionfactory  fail  alternative  host  option  missing  use  port  port  attribute,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
736,allow  message  id  set  using  custom  deserializer  created  mailing  gateway  application  configured  follows  working  fine  transformer  creating  serializable  able  serialize  deserialize  entire  however  order  send  html  email  common  requirement  need  replace  serializable  answer  replace  deserializer  custom  implementation  custom  implementation  populate  serializable  object  property  need  along  serialized  deserialize  need  create  new  set  payload  new  restore  header  currently  doesnt  work  create  new  specifying  new  id  get  generated  mean  existing  message  database  doesnt  get  removed  picked  poller  outbound  mail  adaptor  keep  sending  fix  must  allow  id  specified  need  code  say  suggests  set  complete  deserialization  message  header  together  done  therefore  seems  reasonable  custom  deserializers  supplied  also  able  restore  id  cloned  github  repo  made  following  code  change  however  cause  test  failure  clearly  considered  important  id  cannot  set  said  last  reply  forum  functionality  seems  odds  allowing  flexible  custom  deserializers,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
737,file  outboundchanneladapter  add  ability  append  file  filename  given  already  exists  application  read  xml  message  queue  writes  flat  file  naming  convention  use  flat  file  limit  u  writing  one  file  per  second  file  allowed  multiple  commadelimited  line  filename  included  datetime  second  dictated  third  party  application  practical  rewrite  entire  application  spring  batch  change  made  configure  fileoutboundchanneladapter  allow  append  file  name  generated  filenamegenerator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
738,increase  timeoutdiagnostics  gemfire  wont  start  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
739,support  objectname  pattern  jmx  notificationlisteningchanneladapter  currently  listens  single  mbean  given  payload  message  produced  adapter  notification  object  normally  contains  objectname  source  object  single  adapter  could  create  listener  multiple  mbeans  using  method  find  mbeans  matching  supplied  pattern,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
740,provide  way  pas  variable  line  script  currently  way  pas  custom  variable  bind  inline  script  reason  element  contains  value  cannot  also  child  currently  need  bind  variable  payload  header  create  external  script  reference  would  convenient  injecting  resolved  property  placeholder  bean  simple  script  im  thinking  something  along  line  p  namespace  note  component  groovy  support  scripting  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
741,additional  orderly  shutdown  behavior  implemented  orderly  shutdown  many  component  three  known  remaining  issue  1  tcp  adapter  stopped  hard  socket  closed  mean  inflight  tcp  requestresponse  scenario  fail  reply  cannot  written  2  udp  adapter  may  cause  error  message  executor  thread  may  interrupted  3  attempt  made  orderly  shutdown  message  running  external  eg  container  thread  http  inbound  endpoint  suggest  adding  two  method  orderlyshutdowncapable  interface  used  inform  endpoint  http  tcp  accept  incoming  request  leaving  inflight  request  process  time  quiesce  called  shutdown  delay  attempt  force  stop  tcp  endpoint  report  http  request  still  inflight,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
742,improve  groovy  control  bus  avoid  overhead  script  variable  initialization  managed  bean,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
743,add  transaction  management  support  delayhandlers  schedule  task,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
744,use  webservicetemplate  marshalling  method  marshallingwebserviceoutboundgateway  testing  spring  integration  application  us  getting  unable  internalize  message  error  service  request  sent  able  fix  error  overriding  method  call  method  addition  fixing  problem  would  also  eliminate  need  class  essentially  duplicating  functionality  already  available,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
745,improve  file  overwrite  handling  file  outbound  channel  adapter  recently  added  support  file  appends  order  improve  behavior  remove  append  attribute  replace  new  enumeration  called  mode  providing  following  option  replace  default  setting  append  functionality  fail  raise  exception  file  already  exists  new  ignore  silently  ignore  message  payload  file  destination  file  already  exists  new,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
746,reply  destination  expression  jmsoutboundgateway  possible  set  reply  destination  jms  outbound  gateway  expression  like  requestdestinationexpression,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
747,add  support  uri  templating  wsoutboundgateway  transport  supported  spring  w,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
748,expose  serializer  setting  redis  outbound  channel  adapter,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
749,core  xsd  schema  allow  id  attribute  element  within  chain  allow  id  attribute  noncore  component  within  element  however  core  xsd  schema  allow  id  attribute  set  need  relax  requirement,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
750,redis  zset  support  score  increment,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
751,make  stringredistemplate  default  outbound  channel  adapter  update  collection  current  default  redistemplate  us  jdk  serialization  key  value  hashkeys  hashvalues  stringredistemplate  seems  like  better  default  especially  key  considering  enduser  always  reference  redistemplate  update  various  serializers  default  instance  ie  providing  one  explicitly  using  stringredistemplate  default  convenient,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
752,support  transaction  synchronization  polled  channel  factory  currently  ignored  configured  poller  used  poll  channel,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
753,queuechannel  method  available  jmx  enabled  enabling  imbe  wrap  proxy  hide  queuebased  method  clear  purge  channel  injected  pollablechannel  consider  adding  another  interface  eg  defining  method  implement  given  framework  class  subclassing  create  subinterface  implement,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
754,fix  code  tangle,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
755,add  support  jackson  21  jsontoobjecttransformer  objecttojsontransformer  add  support  jackson,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1
756,add  support  addingremoving  individual  recipient  recipientlistrouter  need  support  adding  removing  recipient  dynamically  well  possibly  support  rlr  recipient  initial  state  typical  use  case  registering  interest  something  part  message  example  dynamic  recipient  could  created  following  selector  expression  also  copying  email  content  regarding  seems  like  simplest  thing  could  provide  addrecipient  method  although  wed  probably  want  expose  take  string  expression  string  channel  name  opposed  current  recipient  object  pair  messagechannel  instance  messageselector  instance  string  would  better  also  add  let  driven  via  control  bus  although  maybe  wed  even  want  parse  single  string  maybe  extend  recipientlistrouter  new  dynamicrecipientlistrouter  class  provide  one  explicit  channel  dynamic  configuration  command  probably  need  support  removal  list  also  far  rlr  0  recipient  think  message  would  dropped  way  dropped  pubsub  channel  subscriber  essentially  rlr  play  role  selectorbased  pubsub  channel  logic  selector  channel,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
757,improve  tcp  socket  timeout  handling  used  gateway  gateway  socket  may  time  prematurely  consider  outbound  gateway  connection  factory  creates  socket  sotimeout  10  second  gateway  remotetimeout  10  second  t0  client  sends  message  immediately  receives  response  t5  client  sends  message  server  take  6  second  respond  sotimeout  cause  socket  throw  sockettimeoutexception  t10  client  timeout  t15  reply  t11  fail  written  used  requestreply  scenario  tcpconnection  wait  2  sotimeout  interval  last  send  socket  occurred  within  first  interval,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
758,support  localdirectoryexpression  sftp  outbound  gateway  currently  use  gateway  l  recursively  list  remote  file  get  command  flatten  directory  locally  adding  support  expression  localdirectory  could  support  reconstructing  directory  tree  locally,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
759,filter  shouldnt  discarding  within  requesthandleradvicechain  configure  something  like  surprised  advice  waiting  discardflow  completed  gary  assign  dont  see  right  solution  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
760,conditional  expression  evaluation  within  loggerchanneladapter  better  evaluate  expression  logginghandler  corresponding  log  level  enabled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
761,enhance  dispatcher  subscriber  channel  xxx  include  context  id  application  us  multiple  context  channel  name  challenging  determine  context  exception  occurred  adding  context  id  message  allow  easier  debugging  application  set  context  id,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
762,make  abstractreplyproducingmessagehandleroninit  final  custom  method  like  docustominit  make  final  custom  method  like  noop  abstract  class  prevent  mistake  created  user  extending,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
763,add  rename  mv  sftp  gateway,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
764,add  phase  abstract  adapter  parser  currently  parsed  also  parse  even  consider  pulling  given  would  benign  subclass  par  adapter  doesnt  declare  attribute,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
765,consider  adding  mechanism  control  number  subscriber  directchannel  globally  number  feature  might  benefit  ability  set  default  behavior  even  application  level  example  see  int2285  globally  limit  number  subscriber  1  instead  effectively  infinity  also  default  behavior  late  reply  arrive,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
766,add  redis  queue  channel  adapter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
767,add  header  enrichment  enricher  allows  expression  individual  header  allow  invoking  subflow  like  retrieve  multiple  value  multiple  header  consider  enhancing  allow  header  set  well  payload  property  might  overlap  simple  headerenricher  seems  logical  allow  enrichment  entire  message  including  payload  header  single  component  pojo  transformer  example,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
768,http  outbound  gateway  missing  uri  variable  provider  currently  http  outbound  gateway  expects  hardcoded  map  uri  variable  multiplexing  different  message  currently  way  declaring  variable  dynamically  invoking  spel  expression  providing  factory  method  scenario  gateway  method1  setting  header  url  feeding  http  outbound  gateway  current  system  requires  http  outbound  gateway  preset  uria  urib  improved  version  would  make  httpgateway  ask  helper  method  provide  uri  variable  dynamically  run  time  fashion  similar  able  craft  uri  via  urlexpression,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
769,abstractremotefileoutboundgateway  add  support  put  currently  upload  file  supported  implement  put  mput,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
770,imapidlechanneladapter  possibility  add  new  feature  imapidlechanneladapter  throw  exceptionerror  reconnection  happned  mailimapstimeout  given  timeperiod  writing  integration  component  read  email  2010  exchange  server  creates  service  ticket  behalf  customer  initially  used  inboundchanneladapter  read  email  exchange  server  working  fine  day  facing  issue  time  exchange  server  available  due  infrastructure  issue  time  seeing  connection  issue  exchange  server  cluster  configuration  two  situation  channel  adapter  facing  issue  read  message  inbox  see  log  position  say  went  wrong  support  team  doesnt  know  happening  come  added  configuration  using  errorchannnel  message  able  notify  support  team  imapidlechanneladapter  rich  feature  started  using  imapidlechanneladapter  using  able  recive  errormessage  connection  dropped  imapidlechanneladapter  currently  writing  warn  message  trying  reconenct  possibility  add  new  feature  imapidlechanneladapter  throw  exceptionerror  reconnection  happned  given  timeperiod,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
771,provide  hook  easily  configure  custom  propertyaccessors  spel  evaluationcontext  even  look  easy  add  custom  via  need  configure  registered  ac  frameworkand  need  hook  inherit  custom  parent  ac,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
772,add  outofthebox  jsonpath  spel  function  add  spel  function  provide  test  show  used,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
773,mongodbmessagestore  provide  setter  messagetemplate  would  really  usefull  could  provide  setter  since  common  set  singleton  messagetemplate  configured  custom  convertor  mongo  writeconcern  policy,1,1,1,0,1,1,0,0,1,1,1,0,1,0,0,0,0
774,add  support  maxnumberofresultsexpression,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
775,improve  groovyscriptexecutingmessageprocessor  performance  avoid  synchronization  possible,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
776,recursive  lsmget  sftp  gateway  remote  file  gateway  support  use  retrieving  file  get  mget  would  useful  able  recursive  mget  remote  directory  also  support  retrieval  full  directory  tree  l  add  recursive  l  mget  command,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
777,expose  redisqueuemessagedrivenendpointrecoveryinterval  property  namespace  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
778,add  simple  get  remotefileoperations  current  method  requires  message  callback  add  case  message  available  rather  forcing  creation  message  purpose,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
779,provide  integration  configuration  abstraction  using  springfactoriesloader,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
780,abstractmessagechannelunicastingdispatcher  improvement  channel  move  payload  conversion  interceptor  inside  try  block  exception  wrapped  messagingexception  necessary  iterate  empty  datatypes  iterate  empty  interceptor  dispatcher  remove  readwrite  lock  around  load  balancer  needed  optimize  single  handler  skip  load  balancer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
781,add  messagebuilderfactory  strategy  add  strategy  add  context  default  return  existing  wont  renamed  provide  backwards  compatibility  provide  optional  return  createsmodified  normal  user  application  continue  use  default  specialized  use  case  high  volume  ingestion  use  care,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,1
782,add  reference  documentation  jdbc  ica  selectsqlparametersource  currently  undocumented  aside  schema,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
783,add  listbacked  redis  message  group  store  queuechannel  use  current  maintains  message  group  single  key  group  id  particularly  efficient  store  used  back  especially  message  accumulate  channel  implement  specialized  purpose  backed  key  ed  similar  optimization  previously  made  jdbc,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
784,provide  globalchannelinterceptor  support,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
785,provide  integrationconverter  support,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
786,provide  enableintegrationmbeanexport  support  similat  registration  bean,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
787,provide  factorybean  builder  javaconfig  analog  securedchannels,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
788,implicit  channel  creation  channel  interceptor  eagerly  instantiates  interceptor  provided  constructor  injection  mean  thisdoesnt  work  bpp  created  run  doesnt  exist  yet  change  bpp  lazily  load  interceptor  first  instantiated  also  make  sure  bpp  fetch  ensure  run  first  channel  initializer  run  channel  created  using  configuration,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
789,improve  mongodbmessagestore  properly  storerestore  existing  message  implementation,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
790,add  gemfire  metadatastore,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
791,rework  jmsxml  module  xsd  enumeration  requires  good  deal  rework  parser  jms  acknowledge  cache  mode  xmlresult  type  deferred  41,1,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0
792,improve  aggregator  performance  avoid  fetching  message  consideration  release  strategy  subclass  aggregator  either  wire  reference  consider  using  swap  class  name  bean  definition,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
793,consider  lazy  resolving  messagechannels  integration  component  lifecycle  start  afterpropertiesset,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
794,pointtopointsubscribableamqpchannel  declare  queue  queuename  provided,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
795,add  statuscodeexpression  attribute  http  inboundchanneladapter  add  statuscodeexpression  attribute  http  inboundchanneladapter  would  allow  developer  override  default  200  returned  channel  adapter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
796,orderly  shutdown  improvement  using  orderly  shutdown  dont  stop  scheduler  executor  beginning  might  midflow  polled  channel  stop  inbound  endpoint,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
797,support  outputchannel  abstractcorrelatingmessagehandler  refd  service  activator  original  title  refactor  aggregatorresequencer  arpmh,1,1,0,0,0,1,1,0,0,0,0,1,1,0,0,0,0
798,implement  support  async  paho  client  mqtt  adapter  see  question,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
799,add  reactor  promise  gateway  return  type  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
800,remove  final  modifier  abstractendpointstoprunnable  callback  callback  invoked  immediately  preventing  subclass  deferring  callback  invocation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
801,jmx  counter  use  atomicinteger  small  roll  leading  inaccurate  statistic  use  atomicinteger  class  jmx  osimonitor  package  mean  application  consume  lot  event  counter  roll  relatively  short  space  time  atomiclong  would  better  replacement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
802,adding  support  packetextension  xmpp  outbound  adapter  currently  format  xmpp  message  hard  coded  handlemessageinternal  method  chatmessagesendingmessagehandler  would  useful  expose  support  custom  formatting  message  currently  smack  support  packetextension  workaround  exploit  behaviour  handlemessageinternal  simple  pas  message  payload  type  orgjivesoftwaresmackpacketmessage  however  explicitly  cited  documentation  may  change  future,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
803,add  expression  setter  component  string  expression  variant  exist,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
804,spca  invoke  lifecyclestart  stop  messagesource  implement  lifecycle  support  flushing,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
805,optimize  performance  filewritingmessagehandler  performance  slow  setting  would  helpful  class  could  optimized  perform  better  use  case  user  always  want  write  file  timestampbased  file  name  multiple  message  given  flow  info  specific  use  case  performance  timing  found  reference  url  jira  thing  perhaps  consider  offering  expose  attribute  let  user  tweak  optimization  expose  attribute  expose  attribute  global  setting  default  value  documentation  added  method  newly  exposed  method  make  user  aware  risk  data  loss  event  power  failure  data  buffered  memory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
806,use  channelresolvers  instead  beanfactory  support  java  dsl  several  component  set  allow  late  binding  channel  name  code  access  directly  instead  using  precludes  configuration  alternative  channel  resolver  example  xd  might  want  configure  route  discarded  message  named  channel  order  xd  could  configure  bean  found  module  deployment  way  thing  applies  possibly  component  however  generalize  use  channel  resolver  everywhere  late  channel  binding  added  could  even  consider  backporting  41x  given  low  risk  change,1,0,1,0,1,0,0,0,1,0,0,0,1,0,0,0,0
807,publish  atcpserverconnectionexceptionevent  server  socket  error  currently  published  exception  occur  established  socket  even  published  server  socket  error  bind  error  add  new  event  type  publish  exception,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
808,remove  selfclosing  tcp  behavior  move  singleuse  connection  closing  connection  user  connection  endpoint,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
809,add  process  barrier  component  several  use  case  come  desirable  suspend  thread  eg  container  thread  delay  message  acknowledgement  async  activity  completed  see  referenced  stack  overflow  questionanswer  one  use  case  consider  adding  new  component  eg  whereby  thread  suspended  message  correlation  arrives  case  suspended  thread  need  message  could  say  send  collection  two  message  output  channel  course  cited  use  case  output  aggregator  would  sent  barrier  release  container  thread  need  mechanism  signaling  message  cause  suspended  thread  throw  exception  perhaps  payload  releasing  message,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
810,bridgehandler  dont  create  new  message  override  returning  false,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
811,add  property  disable  log  level  checking  channel  handler  extreme  data  flow  call  show  highest  cpu  cost  passing  channel  message  handler  since  management  feature  stats  etc  outside  jmx  could  add  boolean  object  used  avoid  call  setting  would  effectively  disable  framework  logging  component  could  still  enabled  runtime,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
812,transaction  configuration  nonpolling  inbound  adaptersgateways  reference  documentation  appendix  c  read  6  mechanism  initiate  message  flow  could  split  2  general  category  message  flow  initiated  user  process  example  scenario  category  would  invoking  gateway  method  explicitly  sending  message  messagechannel  word  message  flow  depend  third  party  process  eg  code  wrote  initiated  message  flow  initiated  daemon  process  example  scenario  category  would  poller  polling  message  queue  initiate  new  message  flow  polled  message  scheduler  scheduling  process  creating  new  message  initiating  message  flow  predefined  time  clearly  gateway  belong  1st  category  inbound  adaptersgateways  scheduler  poller  belong  2nd  documentation  say  user  process  initiated  message  flow  transaction  context  reasonably  started  process  daemon  process  initiated  one  way  tell  spring  integration  start  new  transaction  context  process  triggered  needed  transaction  configured  pollers  perfectly  reasonable  however  inbound  adaptersgateways  per  statement  considered  daemonlike  process  message  flow  initiator  push  adaptersgateways  pull  one  hence  work  poller  concrete  example  receives  incoming  request  exposed  web  service  example  might  http  inbound  gatewayadapter  jms  one  however  jms  concept  transacted  acknowledgement  protocol  level  two  something  like  concrete  chain  like  soap  message  w  inboundgateway  directchannel  jdbc  outbound  gateway  receive  soap  message  store  database  make  si  start  transaction  soon  soap  message  received  think  two  possibility  insert  gateway  two  adapter  nothing  except  starting  transaction  write  good  amount  xml  configuration  set  aop  advice  start  transaction  upon  call  receiving  method  w  inbound  gateway  first  solution  sound  like  workaround  second  one  quite  complex  least  introduces  lot  noise  simple  scenario  think,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
813,http  inbound  gateway  timeout  currently  http  inbound  gateway  return  200  ok  invoke  error  flow  present  timeout  return  500  default  allow  customization  eg  504,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
814,dmlc  set  sessiontransacted  true  default  dmlc  without  transacted  session  cause  message  loss,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
815,upgrade  smack  41  see  linked  jira  intext195,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
816,stomp  adapter  improvement  see  aftermerge  discussion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
817,udp  output  unicast  communication  server  datagram  socket  given  spring  application  work  udp  server  using  udp  inbound  channel  adapter  client  application  work  behind  nat  server  sends  unicast  message  client  behind  nat  client  behind  nat  receives  unicast  message  order  achieve  scenario  udp  outbound  channel  adapter  must  use  udp  inbound  adapter  server  socket  outgoing  packet  source  port  incoming  packet  destination  port,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
818,ftpsession  allow  list  listnames  without  path  requires  path  passed  list  listnames  method  path  must  text  underlying  apache  ftp  client  allows  file  listing  performed  without  path  performed  default  folder  logging  ftp  server  ftp  protocol  also  allow  list  command  performed  without  explicit  folder  path  currently  integrating  two  commercial  ftp  server  require  list  performed  without  folder  path  cant  achieve  current  version  ftpsession  im  happy  make  code  enhancement  perform  pull  request  reference  would  change  line  66  75,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
819,add  simpleskippolladvice,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
820,inthttpinbound  contenttype  hello  imported  springintbasichttp  example  ran  request  using  fiddler  url  request  header  snapshotreceivegateway  response  blank  add  request  header  contenttype  textplain  get  response  server  please  help  client  application  hitting  url  without  passing  contenttype  hence  unable  read  request  body,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
821,jms  springintegration  use  spring  boot  autoconfigured  connectionfactory  actual  behavior  spring  boot  detects  jms  implementation  autoconfigures  bean  named  however  spring  integration  expect  bean  search  bean  named  expected  behaviour  spring  integration  detect  created  spring  boot  autoconfig,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
822,add  preservetimestamp  filewritingmessagehandler,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
823,expose  runtime  object  model  map  see  barrier  sample  add  getters  needed  avoid  need  reflection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
824,update  remote  file  permission  sftp  file  adapter  using  spring  integration  sftp  outbound  adapter  sftp  file  remote  server  receiver  mentioned  file  ftp  need  readwrite  permission  currently  supported  spring  integration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
825,support  extract  payload  map  header  amqpbacked  channel  currently  amqpbacked  channel  dont  provide  option  map  message  serialize  entire  message  work  serializable  payload,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
826,get  rid  explicit  script  class  name  rely  groovyclassloader  logic  class  name  isnt  provided,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
827,logginghandler  add  level  variant  ctor  provide  expression  variant  setter  better  javaconfig  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
828,globalchannelinterceptor  property  placeholder  add  bean  definition  wrapper  ppc  run  ensure  run  property  resolved  document  limitation  use  spel  instead  see  referenced  question,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
829,directory  repeatly  defined  watchservicedirectoryscanner  intfileinboundchanneladapter  requires  defined  constructor  scanner  injected  attribute  defined  think  checking  rule  relaxed  developer  defined,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
830,consider  adding  errorchannel  source  object  map  gateway  messageproducers  pollers,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
831,let  wiretap  resolve  target  message  channel  later  via  provided  channelname  isntead  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
832,add  chainnode  polledchainnode  object  graph  include  list  name  type  pair  handler  chain  property,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
833,add  router  support  graph,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
834,consider  improvment  idempotentreceiverinterceptor  java  config  usage  update  distinguish  advice  apply  properly  handlemessage,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1
835,rmioutboundgateway  need  facilitate  propagation  security  context  spring  security  remoting  provides  class  factory  similar  custom  implementation  injected  spring  security  context  propagated  rmi  client  remote  rmi  server  thread  allow  configuration  security  context  propagated,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
836,ease  customization  jdbc  message  store  make  simpler  customize  query,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0
837,abstractinboundfilesynchronizer  doesnt  restore  remote  path  local  file  case  aws  s3  protocol  may  treelike  structure  actually  nested  path  artificial  complex  key  target  file  anyway  would  good  let  restore  structure  locally  even  cant  sftp  scan  current  directory  without  recursion  solution  look  like  fully  similar  one  case  aws  s3  protocol  may  treelike  structure  actually  nested  path  artificial  complex  key  target  file  anyway  would  good  let  restore  structure  locally  even  cant  sftp  scan  current  directory  without  recursion  solution  look  like  fully  similar  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
838,file  synchronizer  fetch  one  file  per  poll  remote  file  synchronizer  pull  file  polled  large  file  would  helpful  synchronizer  configured  limit  number  file  retrieves  poll,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
839,imap  message  rendering  consistency  pop3  render  mail  body  imap  render  header  since  22  wrapped  message  done  eagerly  fetch  message  cause  imap  mail  rendering  body  like  pop3  exacerbated  new  43  feature  use  header  mapper  cause  original  message  performed  mime  message  rendering  additional  information  payload  consider  delegating  field  restore  normal  imap  behavior  imap  message  also  add  option  eg  mail  receiver  allow  reverting  current  state  value  providing  consistency  across  pop3  imap  flag  set  also  change  rendering  header  mapper  consistent  mode  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
840,dsl  add  integrationflowsfrommygatewayclass  allow  flow  begin  simplifying  configuration  avoiding  need  find  gateway  something  like  bpp  build  gpfb,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
841,spca  source  proxy  applied  method  source  already  proxy  advise  method  advise  method  incorrect  would  improvement  consistently  use  remove  conditional  method  name  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
842,pagination  mongodb  inbound  adapter  would  like  new  numeric  property  pagesize  set  limit  find  query  default  1  limit  would  welcome  pull  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
843,messagingmethodinvokerhelper  error  message  improvement  following  result  exception  thread  main  unable  access  property  message  getter  method  caused  javalangillegalstateexception  invalid  method  parameter  message  expecting  single  payload  work  fine  issue  match  interpreted  collection  invocation  expression  possible  attempt  determine  element  process  simple  payload  thats  possible  least  log  meaningful  error  log  warning  tell  user  use,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
844,make  expressionevaluatingrequesthandleradvice  dslfriendly  add  support  channel  name,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
845,ftp  inbound  adapteroutbound  gateway  support  spel  filenameregex  use  case  filename  regular  expression  constructed  fly  existing  attribute  could  allowed  static  pattern  possible  support  spel  expression  attribute  ftp  inbound  adapter  ftp  outbound  gateway  similar  following,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
846,compiled  spel  improvement  mmih  xml  one  define  exceptiontyperouter  create  easy  routing  based  type  exception  currently  easy  using  spring  integration  java  dsl  havent  checked  groovy  scala  version  expected  able  use  default  route  problematic  problematic  exception  wrapped  1  messagingexception  depending  level  occurred  fix  one  would  manually  define  pas  function  although  isnt  hard  would  nicer  could  use  dsl  instance  function,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
847,messagingmethodinvokerhelper  improvement  introduced  preference  use  spel  whenever  possible  invocation  fails  certain  known  reason  fall  back  using  spel  add  failure  counter  give  threshold  similar  spel  compiler  give  hardcoded  100  attempt  compile  threshold  exceeded  set  flag  permanently  use  spel  point  fail  log  failure  log  every  failure  like  current  failure  log  log  method  since  invoke  trycatch  appears  certain  exception  cause  spel  invoked  twice  ie  fall  back  spel  used  spel  first  place,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
848,provide  mechanism  configure  spel  propertyaccessors  function  java  configuration  add  pa  user  code  would  late  many  case  component  already  gotten  evaluation  context  would  done  run  early  application  context  lifecycle  open  jira  issue  might  find  easier  small  xml  snippet  one  class,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
849,add  json  representation  fileinfo  file  streaming  inbound  adapter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
850,jsonpropertyaccessor  cannot  return  array  value  used  retrieve  specific  indexed  value  json  array  doesnt  really  support  returning  whole  array  eg  used  subsequent  expression  iteration  result  returned  list  specifically  wrap  doesnt  offer  listlike  functionality  wrapped  instead  seems  work  workaround  specifying  array  index  string  isnt  needed  note  found  trying  use  thymeleaf  might  much  concern  spring  integration  anyway  prototype  fix  create  cleanedup  pull  request  test  like,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
851,support  custom  bean  naming  configuring  flow  would  like  able  set  bean  name  generated  listener  container  bean  andor  related  flow  bean  name  allow  end  bean  name  like,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
852,provide  dsl  version  intexceptiontyperouter  xml  one  define  create  easy  routing  based  type  exception  currently  easy  using  spring  integration  java  dsl  havent  checked  groovy  scala  version  expected  able  use  default  route  problematic  problematic  wrapped  1  messagingexception  depending  level  occurred  fix  one  would  manually  define  pas  function  although  isnt  hard  would  nicer  could  use  dsl  instance  function,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
853,provide  stream  flux  splitting  support  jdk  9  support  would  great  si  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
854,allow  additive  header  black  listing  small  enhancement  current  solution  allows  set  header  add  header  existing  configuration  user  overwrite  existing  list  least  possible  consult  existing  set  excluded  header  user  merge  additional  header  existing  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
855,allow  additive  header  black  listing  small  enhancement  current  solution  allows  set  header  add  header  existing  configuration  user  overwrite  existing  list  least  possible  consult  existing  set  excluded  header  user  merge  additional  header  existing  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
856,add  support  webflux  server  side,1,1,1,0,1,1,0,0,0,1,0,1,1,0,0,0,1
857,support  configuring  abstractinboundfilesynchronizingmessagesource  custom  scanner  example  allow  injection  custom  expose  scanner  changed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
858,allow  user  set  id  defaultlockrepository  via  constructor  currently  id  set  random  instance  initialization  time  good  feature  allow  id  set  via  constructor  allows  user  lock  repository  set  something  meaningful,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
859,provide  mechanism  configure  messagehandlermethodfactory  currently  created  annotated  operation  need  single  instance  create  annotated  operation  could  nice  improvement  si  probably  also  exposed  bean  allow  framework  especially  world  spring  boot  interact  andor  override  example  one  framework  build  si  spring  cloud  stream  since  defines  set  annotation  data  handling  operation  creates  instance  set  match  one  provided  si  time  producing  different  result  simply  based  operation  annotated  would  nice  si  either  expose  look  bean  thus  allowing  shared,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
860,revisit  header  propagation  service  activator  2  year  developing  spring  integration  main  issue  came  across  multiple  time  summary  current  behavior  service  activating  handler  make  sense  use  case  service  activator  return  payload  course  header  incoming  message  propagated  service  activator  return  object  propagated  next  handler  without  change  proposed  change  remove  member  necessary  change  simply  decide  propate  input  message  header  payload  returned  handler  returned  message  propagated  change  amongst  others  scenario  would  solved  service  activator  would  able  user  able  ot  would  possible  split  message  collection  without  header  contained  message  synced  header  triggering  message  topic  discussed  opinion  need  revisited,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
861,add  delivery  attempt  header  add  header  adapter  embedded  retry  template  add  header  increment  sending  message,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
862,apply  metricsfactory  latebound  component  apply  perations  component  registered  context,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
863,cannot  use  kotlin  spring  integration  504  java  still  working  integration  flow  dsl  notation  compiled  fail  run  time  spring  integration  cannot  find  method  use  route  config  rewritten  java  working  one  thing  kotlins  lambda  synthetic  class  java  spring  integration  see  lambda  another  hand  worked  dsl  thing  transform  still  work  kotlin  lambda  avoided  explicit  method  name  ugly  anyone  knew  solution  except  apply  shifting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
864,messageheadersid  could  automatically  mapped  amqpheadersmessageid  currently  sent  amqp  outbound  adapter  value  two  field  get  discarded  altought  id  could  fixed  turning  implicit  id  generation  descendant  come  side  effect  difficult  debug  id  sent  received  message  defer  take  time  debug  call  hierarchy  understand  said  id  propose  map  id  timestamp  field  automatically  add  option  defining  transient  field,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
865,rotate  sftp  serversdirectories  poll  add  smart  poller  advice  rotate  across  multiple  directory  server  several  policy  standard  rotate  file  found  fair  rotate  every  poll  custom,1,1,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0
866,consider  use  unlink  method  redistemplate  doremove  method  redismessagestore  method  called  key  removed  redis  upon  releasing  messagegroup  removing  key  form  redis  alternative  redistemplates  unlink  method  allow  performant  operation  used  purpose  however  unlink  operation  available  redis  40  backwardcompatibleness  prioritized  stay  preferably  unlink  supported  redis  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
867,jms  dslxml  inconsistent  receivetimeout  xml  parser  set  default  nowait  dsl  leaf  default  infinite  wait  consistent  dont  think  nowait  correct  reason  discussed  end  answer  infinite  wait  incorrect  maybe  1000  second  thought  perhaps  nowait  1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
868,enhancement  spring  integration  dsl  able  declaratively  handle  contenttype  used  define  handler  spring  cloud  stream  environment  spring  cloud  stream  performs  deserialization  byte  consumer  endpoint  method  argument  handler  annotated  used  determine  class  type  convert  byte  received  determined  class  type  becomes  argument  converter  also  selected  value  contenttype  message  header  runtime  actual  deserialization  performed  converter  mime  type  unknown  vanilla  setup  converter  mime  type  need  provided  mean  defining  bean  configuration  auto  configuration  process  springcloudstreamschema  one  auto  configured  handler  implemented  using  java  config  style  programming  one  write  annotated  method  argument  used  framework  registering  component  perform  byte  object  conversion  behindthescenes  since  developer  need  take  care  define  method  nothing  else  properly  setting  springcloudstreamschema  module  relevant  property  one  say  converter  defined  configured  declarative  manner  however  using  spring  integration  dsl  style  converter  need  configured  imperatively  example  using  spring  integration  dsl  building  mechanic  message  flow  become  much  intuitive  perspective  programmer  become  preferable  way  define  message  flow  java  config  request  enhance  spring  integration  dsl  handle  mimetype  conversion  declaratively,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
869,roo  generated  spring  mvc  apps  deployable  gae  currently  gae  raise  compilation  exception  roo  generated  jspx  file  gae  environment  problem  use  jasper  runtime  current  version  gae  alongside  geronimo  mean  gae  api  allows  jsp  implementation  jasper  support  jsp  20  spring  roo  generated  mvc  apps  use  number  jspfeatures  mostly  el  related  supported  current  web  container  gae  gae  deployment  currently  supported  roo  generated  spring  mvc  application  however  contact  google  resolve  issue  soon  possible  workaround  roo  could  ship  custom  tag  library  potentially  reduced  functionality  support  jsp  another  issue  need  resolved  full  support  default  gae  data  store  require  change  outlined  fully  support  reference  domain  object,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
870,improve  addon  creation  support  developer  introducing  different  addon  generation  option  improve  addon  creation  support  developer  introducing  different  addon  generation  option  current  simple  addon  template  moved  new  addon  one  option  developer  choose  starting  new  spring  roo  addon  currently  three  addon  type  envisioned  simple  addon  command  operation  advanced  addon  command  operation  metadata  itd  generation  trigger  annotation  addon  specialized  addon  add  new  i18n  bundle  existing  mvc  addons,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
871,ensure  exception  description  always  rendered  development  false  roos  defaultprocessmanager  responsible  rendering  exception  message  occur  process  executing  message  highly  detailed  development  mode  true  development  mode  false  currently  result  throwable  get  message  rendered  however  throwable  getmessage  null  empty  text  displayed  result  confusion  user  may  encounter  bug  addon  particularly  null  pointer  exception,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
872,allow  separate  installation  new  language  mvcjsp  scaffolded  application  based  comment  desirable  install  additional  language  mvcjsp  scaffolded  application  via  separate  command  implementation  flexible  enough  support  easy  addition  support  new  language,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
873,roo  shell  inform  user  addons  may  offer  missing  command  work  preparation  able  display  meaningful  message  user  invoke  command  installed  locally  may  available  specific  addon  known  via  roo  addon  repository  task  implement  search  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
874,request  factory  naming  convention  tweak  watching  bob  confusion  figuring  requestfactory  he  suggested  name  change  would  like  get  rayc  amit  big  change  land  last  informal  name  object  hang  right  request  factory  mostly  show  generated  java  doc  source  request  factory  generator  eg  request  employee  find  employee  employee  return  called  request  builder,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
875,move  obrrelated  service  dedicated  module  currently  simpleparsercomponent  load  obr  index  us  automatic  resolution  available  command  desirable  functionality  moved  dedicated  module  becomes  available  searchrelated  use  case,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
876,install  web  flow  command  requires  prior  generated  spring  mvc  artifact  current  version  webflow  add  roo  build  top  spring  mvc  framework  therefore  requires  spring  mvc  artifact  installed  first  controller  form  backing  object  least  roo  hidden  install  web  flow  command  spring  mvc  artifact  available  project,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
877,allow  flash  message  handled  without  necessarily  loaded  shell  instance  currently  class  use  flash  message  api  jdk  url  input  stream  service  require  shell  instance  available  start  prevents  certain  lowlevel  infrastructure  using  flash  message  startup  appropriate  offer  abstract  class  provide  flash  message  shell  available  still  operate  gracefully  shell  yet  loaded,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0
878,replace  velocity  template  engine  hapax  addongwt  reduce  size  roo  distribution  hapax  used  instead  velocity  template  engine,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
879,support  multi  module  maven  project  feature  would  like  see  future  layout  think  initially  roo  create  parent  core  webapp  project  parent  project  pom  project  place  call  roo  shell  use  command  create  module  module  name  format  something  like  project  name  module  project  name  plugin  module  list  project  pom  handled  roo  generator  list  contains  core  module  webapp  project  module  inside  inherit  parent  project  pom  project  also  dependency  application  framework  like  spring  jpa  maybe  use  project  build  run  full  test  core  project  contains  main  application  context  reusable  code  shared  module  project  helper  utils  base  class  general  auditing  aspect  like  logger  module  project  one  many  jar  module  project  contains  main  component  like  controller  model  service  daos  template  resource  belong  controller  module  module  project  core  project  default  dependency  dependency  module  project  managed  developer  webapp  project  war  contains  web  configuration  doesnt  contain  component  code  template  contains  web  resource  shared  module  project  dependency  webapp  automatically  handled  roo  generator  module  project  creation  dependency  webapp  includes  core  module  project  packaging  module  project  jared  stored  webinf  lib  war,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
880,label  applicationproperties  getting  overwritten  roo  startup  info  forum  thread  got  entity  named  ai  document  avoid  collision  dom  document  class  fine  dandy  label  roo  come  controller  scaffolding  want  displayed  ui  displaying  ai  document  instead  document  manually  go  update  label  text  applicationproperties  file  roo  doesnt  complain  roo  start  next  time  scan  project  see  line  displayed  aargh  roo  went  reverted  labelsi  noticed  behavior  several  label  application  property  file  label  aidocument,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
881,hide  property  public  api  closely  related  property  least  become  implementation  detail  private  api  ray  talked  bug  could  tractable  day  step  involved  move  property  requestfactoryshared  impl  class  delete  property  proxy  class  requestfactorygenrator  generate  proxy  impl  class  easy  delete  reference  ui,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,1,0
882,implement  support  reference  field  entity  addongwt,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
883,post  code  refactor  clean,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
884,roo  update  destructive  particular  possible  move  activity  view  way,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
885,consolidate  3  public  subclass  requestobject  one  death  recordlistrequest  long  live  request  object  list  employee  proxy  bonus  point  get  named  request  instead  requestobject,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
886,create  new  type  location  service  implementation  locate  java  type  based  annotation  type  contains  new  typelocationservice  interface  implementation  created  locate  type  contain  supplied  annotation  service  dbretyperesolutionservice  impl  new  jsf  operation  impl  controller  operation  impl  class  simplified  avoid  repetition  code  class,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
887,integration  roo  bundlor  install  bundlor  associated  command  attached  patch  extends  roo  bundlor  add  root  command  install  bundlor  generates  template  mf  file  update  pom  include  use  bundlor  packaging  step  bundlor  installed  project  set  command  become  available  manage  template  full  command  list  install  bundlor  bundlor  nonexported  package  control  package  private  bundlor  version  package  export  bundlor  configure  import  bundlor  add  explicit  import  ome  note  patch  adding  bundlor  project  required  updating  dependency  also  updating  build  plugins  ive  extended  core  project  model  cope  current  version  bundlor  drag  snapshot  dependency  add  new  repository  master  pom  file  bundlor  get  m5  longer  needed  addon  bundlor  project  depends  couple  external  library  outside  spring  roo  project  explicitly  add  dependency  bootstrap  project  order  roodev  classpath  properly  generated  better  way  bundlor  command  update  template  mf  file  time  execute  roo  put  managed  root  template  mf  message  time  doesnt  file  always  correctly  updated  sure  bundlor  currently  doesnt  work  due  maven  snapshot  hell  run  mvn  package  get  noclassdeffounderror  roo  addon  right  thing  issue  bundlor  fixed  m5  patch  revision  156  trunk  note  build  roo  also  noticed  roo  create  project  foo  followed  mvn  package  cause  build  failure  web  xml  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
888,dbre  multiple  schema  support  moment  allow  one  database  schema  per  project  dbre  problem  support  multiple  instance  moment  second  script  command  wipe  generated  artifact  created  first  command,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
889,dbre  include  exclude  specified  table  would  totally  helpful  something  like  andor  moment  dbre  take  table  strip  one  need  directly  changing  dbre  xml  right  since  every  next  call  database  reverse  engineer  overwrites  dbrexml,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0
890,dbre  generate  proper  nullable  length  precision  scale  column  already  information  available  dbre  xml  need  push  accordingly  appropriate  column  annotation  attribute,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
891,bad  api  instance  method  realized  convention  firing  instance  method  leaving  lot  corner  case  bug  going  fix  fact  one  creates  new  proxy  rf  rather  request  object  besides  confusing  easy  misuse  example  new  instance  returned  fix  actually  simple  requires  change  wire  format  little  change  requestfactorygenerator  servlet  move  create  request  factory  request  introduce  new  interface  interfacerequest  nice  side  effect  fixing  might  well  fix  time,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
892,add  addon  deploy  run  roo  project  google  app  engine  infrastructure,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
893,allow  creating  multiple  flow  definition  web  flow  addon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
894,make  file  converter  respect  shell  get  home  convention  report  issue  caused  file  converter  respect  shell  get  home  convention  required  sts  embedded  roo  feature  file  converter  changed  accordingly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
895,refactor  gwtaddon  produce  gwt  application  better  reflect  gwt  structure  guideline  reorganise  generated  gwt  app  closer  guideline  outlined,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
896,significant  performance  improvement  per  current  metadata  infrastructure  slow  extreme  use  case  need  improve,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
897,roobot  client  new  roobot  client  addon  provides  interface  roobot  addon  registration  service  spring  roo  addons  several  new  command  introduced  add  also  contributes  add  finder  implementation  support  suggestion  addons  currently  unknown  command,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
898,introduce  jpa  type  annotation  via  aspectj  itds  currently  adding  new  entity  entity  roo  entity  annotation  well  table  type  annotation  created  java  file  unncessary  confusing  add  clutter  java  file  change  cause  roo  entity  annotation  trigger  creation  jpa  type  annotation  entity  itd  instead  new  attribute  added  roo  entity  annotation,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
899,gwts  valueboxeditordecorator  isnt  ready  primetime  editviews  shouldnt  use,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
900,add  support  firebird  database  jaybird  issue  posible  support  firebird  database  make  test  include  manually  can´t  work  properly  create  project  hibernate  mysql  support  change  pomxml  put  jaybird  maven  central  library  replacement  mysql  lib  add  dependency  pom  dependency  correctly  added  en  webinf  lib  next  chage  persistencexml  change  database  property  add  line  database  property  database  password  masterkey  compile  project  succefull  run  much  error  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
901,allow  specification  parent  pom  roogenerated  pom  extremely  verbose  make  solid  build  somewhat  difficult  read  compromise  would  nice  could  specify  parent  artefact  run  create  project  parent  contains  plugin  management  dependency  management  section  would  need  explicitly  specify  version  plugins  dependency  project  pom  leading  smaller  pom  could  use  standard  gav  notation  something  like  create  project  parent  orgexamplesuperpom1  make  association,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
902,add  dbre  support  firebird  database  use  dbre  firebird  database  driver  need  osgi  wrapped  note  also  latest  version  firebird  maven  central  requires  due  dependency  java  sql  sql  client  info  exception  class  part  jdk  5  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
903,post  release  code  refactor  clean,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
904,project  database  reverse  engineering  lock  roo  shell  restart  database  reverse  engineering  create  controller  restart  roo  shell  unresponsive  apparently  trying  create  class  deleted  deleted  deleted  welcome  spring  roo  assistance  press  tab  type  hint  hit  enter  felix  dispatch  queue  deleted  springsource  reverse  engineering  many  message  like  follow  process  start  fast  becomes  slow  shell  blocked  apparently  everything  fine  database  reverse  engineering  ie  controller  class  also  created  process  fast  attached  dumb  mysql  database  using  spring  roo  log  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
905,performance  improvement  dbre  refactor  dbre  database  listener  impl  class  process  table  efficient  manner,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
906,simpleparser  report  error  user  present  command  option  unwanted  command  currently  possible  user  enter  command  command  option  command  doesnt  actually  use  example  illegal  command  simple  parser  detect  option  presented  resolved  command  doesnt  use  report  error  user  without  executing  command  message  probably  suggest  use  tab  assist  help  command  view  legal  option  command  initially  assigned  alan  done  recent  simple  parserrelated  work,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
907,enhance  binding  information  javatype  useful  store  additional  metadata  within  java  type  concerning  whether  resolved  java  type  represented  known  type  variable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
908,convert  dbre  xml  format  use  torque  dtd  optional  custom  keyvalue  element  torque  dtd  dbre  changed  use  format  instead,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
909,scope  option  dependency  add  command  simple  obvious  feature  request  able  apply  standard  maven  dependency  configuration  add  optional  scope  parameter  dependency  add  command  roo  shell  default  value  course  compile  optional  value  test  provided  runtime  need  manually  set  scope  test  library  pom,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
910,add  includetables  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
911,provide  import  management  within  generated  itds  generated  itds  presently  rely  fully  qualified  type  name  make  feel  unnatural  human  look  also  make  unpleasant  experience  using  ajdts  push  refactoring  generated  itds  therefore  automatically  manage  import  statement  correctly,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
912,improve  display  addon  information  various  addon  command  improve  display  add  information  various  add  command  addon  list  addon  info,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
913,improve  display  addon  information  various  addon  command  improve  display  addon  information  various  addon  command  addon  list  addon  info,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
914,add  addon  search  command  allow  flexible  addon  discovery  new  addon  search  command  following  attribute  facilitate  roo  addon  discovery  requiresdescription  comma  separated  list  search  term  required  linesperresult  maximum  number  line  per  addon  optional  max  result  maximum  number  result  option  trustedonly  display  trusted  addons  search  result  optional  compatibleonly  display  compatible  addons  search  result  optional  requires  command  display  addons  offer  specified  command  optional,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
915,improve  performance  dbre,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1
916,roo  core  change  facilitate  number  change  made  roo  core  order  complete  include  arent  limited  inner  type  initializers  parameter  varargs  complete  import  model  parsing  type  directly  string  nested  type,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
917,clean  gwt  addon  source  gwt  addon  source  formatting  place  reformatted,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
918,dbre  map  mysql  tinyint1  bit  sql  type  javalangboolean  gwt  dbre  map  mysql  tinyint  bit  type  boolean  requires  java  lang  boolean  request  factory  request  option  support  scenario,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
919,refactor  roobot  client  needed  take  adjusted  xml  roobot  xml  schema  account  allows  registration  individual  version  addons  furthermore  roobot  xml  file  available  zip  increased  bandwidth  efficiency,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
920,boost  performance  persistence  setup  command  persistence  setup  command  completes  unacceptable  time  due  number  xml  read  write  operation  improvement  request  improve  efficiency  said  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
921,itdtype  detail  providing  metadata  item  physical  type  metadata  adopt  parameterized  extends  member  holding  type  detail  superclass  get  member  holding  type  detailst  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
922,add  metadatacacheputmetadataitem  method  use  roo  infrastructure  type,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
923,improve  metadata  tracing  feature,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
924,infinite  metadata  loop  detection  retry  completion  current  metadata  retrieval  stack,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
925,introduce  notify  generic  listene  rstring  method  allow  abstract  itd  metadata  provider  gracefully  handle  generic  listener,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
926,conversion  service  observe  metadata  immutability  dependency  injection  convention,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
927,add  beaninfoutils  static  method  assist  eliminate  use  bean  info  metadata,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
928,modify  orgspringframeworkroosupportutilwebxmlutilsaddfilteratposition  allow  adding  dispatcher  tag  filtermappings  roo  addon  developer  want  easy  way  add  dispatcher  tag  filtermappings  please  modify  web  xml  utils  add  filter  position  allow  would  generate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
929,improve  roo  message  generated  persistence  setup  command  roo  output  message  like  updated  root  pomxml  message  indicate  actually  changed  improvement  add  actual  type  change  message  example  updated  root  pomxml  added  filter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
930,abstract  itd  metadata  provider  permit  flexible  classlevel  downstream  dependency  resolution  currently  abstractitdmetadataprovider  support  dependency  registration  downstream  instance  specific  meaning  target  downstream  mid  notification  known  advance  presented  part  metadata  notification  metadata  dependency  registry  null  downstream  dependency  presented  via  generic  listener  handled  new  mechanism  however  approach  mean  metadata  event  system  pas  metadata  provider  inefficient  particular  subset  known  advance  metadata  notification  desired  class  level  downstream  dependency  metadataprovider  get  provides  type  upstream  dependency  physicaltypeidentifier  notification  case  abstractitdmetadataprovider  unwraps  upstream  notification  mid  ie  physical  type  identifier  convert  local  metadata  provider  instance  specific  mid  sometimes  desirable  listen  metadata  notification  particular  type  physical  type  identifier  every  metadata  notification  pas  instance  specific  mid  first  approach  listed  work  fine  upstream  metadata  physical  type  identifier  last  approach  accommodate  however  presently  handled  upstream  non  physical  type  identifier  downstream  instancespecific  add  new  method  abstractitdmetadataprovider  subclass  override  resolve  classlevel  downstream  instancespecific  downstream  third  scenario  occurring  abstractitdmetadataprovider  code  handle  physicaltypeidentifier  use  case  available  super  call  desired,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
931,remove  jointable  class  dbre  join  table  class  necessary  simple  boolean  flag  added  table  class  indicate  whether  table  many  many  join  table  reduce  amount  code  dbre,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
932,introduce  addon  component  upgrade  functionality  roo  shell  currently  fairly  inconvenient  user  determine  newer  version  installed  addons  component  available  roobot  set  newly  introduced  command  addon  upgrade  address  follows  upgrade  specific  spring  roo  addon  component  upgrade  specific  spring  roo  addon  component  search  result  id  upgrade  relevant  spring  roo  addons  component  addon  upgrade  available  list  available  spring  roo  addon  component  upgrade  addon  upgrade  setting  setting  addon  upgrade  operation  allows  user  set  preferred  addon  stability  level  furthermore  roo  shell  list  number  upgradable  addons  upon  startup  roobot  xml  zip  successfully  downloaded,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
933,remove  bean  info  metadata  addonfinder  replace  member  detail  scanner  member  detail  scanner  new  pattern  used  roo  also  allow  finder  created  method  introduced  itds,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,1
934,refactor  jspmetadata  listener  handle  i18n  property  efficiently  refactor  jsp  metadata  listener  handle  property  efficiently,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
935,composite  primary  key  support  mvc  scaffolding  table  relation  db  build  roo  git  ok  show  spring  roo  112buildsnapshot  mvn  tomcatrun  run  ok  show  web  list  entity  table  ok  tee  table  error  show  data  access  failure  sorry  problem  occurred  accessing  database  exception  message  exception  stack  trace  java  lang  thread  run  database  struct  attachment  open18sql,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
936,java  parser  mutable  class  interfacetypedetailsupdatetypeannotation  flush  change  disk  twice  normal  operation  invocation  method  cause  two  consecutive  updating  filename  java  operation  associated  message  development  mode  inefficient  disk  writing  perspective  also  confusing  addon  developer  development  mode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
937,abstract  itd  metadataprovider  offer  create  local  method  difficult  create  local  mid  meaning  mid  specific  metadata  provider  member  holding  type  detail  object  type  detail  would  useful  superclass  particularly  useful  abstract  member  discovering  itd  metadata  provider  subclass,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
938,make  dbre  database  class  fully  immutable  destination  package  mutator  database  java  removed  field  introduced  via  constructor,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
939,refactor  dbre  database  introspector  schema  introspection  separate  class  improve  immutability  encapsulation  splitting  schema  introspection  code  database  introspector  new  schema  introspector  class  also  create  abstract  parent  class  process,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
940,remove  metadataservice  class  path  operation  java  bean  metadata  change  back  bim  make  java  bean  metadata  immutatable  reference  metadata  service  claspath  operation  need  pushed  back  java  metadata  bean  provider,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
941,decimal  max  constraint  honored  roo  data  demand  test  define  entity  following  field  generate  dod  driven  integration  test  next  run  integration  test  test  persist  method  fail  constraint  violation  test  us  integermax  value  value  index  getrandomentityname  dod  class  us  index  construct  bigdecimal  even  though  annotation  set  max  decimal  amount  happen  integer  field  annotation  used  limit  maximum  value  value  specified  maximum  value,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
942,make  data  demand  metadata  immutable  removing  metdataservice  metadatadependencyregistry  lookup  collaborating  metadata  done  provider  change,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
943,refactor  classpath  operation  method  typelocationservice  new  type  management  service  currently  classpathoperations  injected  dbre  mvc  service  roo  operation  class  called  operation  class  change  refactor  method  classpathoperations  existing  typelocationservice  new  type  management  service  also  entity  specific  command  moved  classpath  command  new  entity  command  class  corresponding  entity  operation  interface  impl  class  located  addonentity  method  remaining  classpathcommands  specific  class  interface  classpath  operation  classpath  operation  removed  mvc  dependency  changed  use  type  location  service  type  management  service  background  ben  alex  change  general  pattern  utils  statless  public  abstract  class  public  static  method  cannot  instantiated  injected  anything  ok  pas  thing  method  help  fairly  unusual  pas  service  complex  object  given  utility  method  simple  command  contain  shell  annotation  generally  call  operation  call  service  well  usually  deal  formatting  user  io  also  ensure  type  intended  format  successful  method  invocation  operation  stateless  type  respond  ui  command  offer  method  operation  type  point  different  command  didnt  deal  user  io  preparing  method  argument  etc  deal  complex  lifecycles  requiring  state  listener  model  like  metadata  infrastructure  service  something  quite  simple  returned  ongoing  lifecycle  obligation  allowed  call  service  operation  object  arent  allowed  call  command  service  called  anyone  including  control  flow  unrelated  ui  command  control  flow  instigated  due  metadataprovider  event  service  never  call  operation  command  object  listener  really  special  type  service  time  socalled  service  actually  implement  one  listener  metadataproviders  metadata  infrastructure  call  metadata  infrastructure  service  theyre  really  special  type  service  due  ability  identify  invoke  notify  stringbased  mids  follow  rule  service  namely  cannot  call  operation  command  time  gone  complex  addons  needed  complex  thing  logic  moved  operation  service  make  sophisticated  generally  available  happened  case  starting  get  point  question  value  keeping  operation  concept  sure  theyre  stateless  listener  aside  seem  negligible  distinction  versus  service  maybe  rename  operation  service  consistency  critical  thing  one  cannot  call  command  silly  reconvert  missing  argument  figure  default  etc  like  command  converter  infrastructure,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
944,dataondemand  integration  test  support  composite  primary  key  ticket  combine  existing  related  ticket  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
945,change  dependency  listening  approach  conversionservicemd  remove  use  beaninfometadata  change  dependency  listening  approach  conversion  servicemd  remove  use  bean  info  metadata,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
946,boost  performance  gwt  setup  command  similar  change  gwt  operation  impl  class  changed  add  dependency  etc  rather  expensive  operation  one  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
947,provide  overloaded  constructor  abstract  identifiable  annotated  java  structure  builder  instance  construct  new  field  metadata  builder  attribute  existing  field  except  declared  metada  tid  builder  must  constructed  first  id  attribute  copied  manually  new  set  constructor  added  easily  facilitate  eg  field  metadata  builder  declared  metadatid  existing  constructor  immediate  use  gwt  addon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
948,remove  reference  path  resolver  declaration  class  retrieve  path  resolver  project  metadata  instead  pathresolver  supposed  abstract  away  project  specific  path  used  project  build  system  reference  mean  one  possible  implementation  instantiated  osgi  injected  ie  similr  autowirebytype  constraint  spring  support  say  ant  maven  concurrently  mavenpathresolver  implement  pathresolver  would  prohibited  service  really  shouldnt  service  reason  reference  private  pathresolver  shouldnt  really  declaration  instead  get  projectmetadata  thats  tedious  least  projectoperations  aka  projectservices  centralised  switching  logic  give  back  correct  pathresolver  instance  might  also  exemplify  abstractprojectoperations  intended  allow  multiple  build  system  easily  time  progressed  many  method  mavenspecific  dont  see  realistic  recommendation  repetitious  code  going  retrieving  projectmetadata  replaced  nice  projectoperations  method  reference  private  pathresolver  field  disappear  least  search  count  massive  undertaking  private  helper  method  retrieve  projectmetadata  get  pathresolver  away,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
949,remove  reference  path  resolver  declaration  class  retrieve  path  resolver  project  metadata  instead  deprication  bean  info  metadata  major  refactoring  mvc  addon  family  required  part  work  new  web  metadata  utils  type  introduced  eventually  take  care  metadata  scanning,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,0
950,improve  consistency  roo  code  base,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
951,merge  maven  addon  project  module  project  currently  heavily  tied  maven  build  system  make  reasonable  amount  sense  combine  maven  addon  project,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
952,add  extra  column  attribute  composite  key  field  rooidentifier  itd  currently  attribute  columndefinition  added  roo  db  managed  itd  field  roo  identifier  itd  change  add  attribute,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
953,post  112release  code  refactor  clean,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
954,dbre  break  java  portability  default  dbre  generates  column  annotation  setting  column  definition  attribute  column  definition  set  problem  scenario  db  migration  could  possibility  example  volume  data  could  grow  column  jpa  annotation  defines  attribute  columndefinition  override  sql  ddl  fragment  particular  column  non  portable  could  ommited  property  hibernate  hbm2ddlautoin  persistencexml  must  commented  order  disable  schema  validation  application  startup  inclussion  option  command  database  reverse  engineer  setting  include  columndefinition  column  mapping  interesting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
955,move  test  integration  dod  command  addontest  addondod  respectively  addontest  addondod  dependency  addonentity  test  integration  command  moved  rightful  place  addontest  dod  command  addondod,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
956,remove  dependency  entitymetadata  dbre  change  remove  reference  entitymetadata  addondbre  dependency  addonentity  still  remain  dbre  database  listener  impl  implement  identifier  service  addon  entity,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
957,custom  data  tag  get  lost  itd  supplied  field  method  get  pushed  corresponding  java  source  metadata  producing  type  tag  field  method  member  already  available  corresponding  governor  tagged  md  lost  favour  original  md  likely  javaparsermd  tagged  md  lost  abstract  member  holding  type  detail  builder,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1
958,create  entityannotation  value  consistency  addons  roo  entity  annotation  many  attribute  stored  referenced  abstract  annotation  value  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
959,move  get  member  detail  javatype  type  method  metadata  provider  abstract  itd  metadata  provider  parent,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
960,roo  git  addon  verbose  roo  git  addon  work  good  store  lot  verbose  thing  like  quit  help  hint  command  emit  code  stored  git,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
961,refactor  mvc  controller  addon  currently  mvc  controller  addon  produce  monolythic  itd  contains  spring  mvc  controller  functionality  finder  configured  json  functionality  configured  lead  large  itd  rather  hard  read  developer  desirable  separate  three  functionality  separate  itds  core  mvc  finder  json  change  also  allow  internal  refactoring  webscaffoldmetadata  creation  webjsonmetadata  webfindermetadata  respective  package,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
962,refactor  webmetadatautils  service  improvement  would  change  web  metadata  utils  web  metadata  service  removing  static  method  previously  passed  service  injected,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
963,modification  roo  command  enhance  usability  consistency  addons  roos  current  command  name  evolved  lengthy  period  new  addons  created  existing  addons  addressed  additional  requirement  addition  wider  audience  people  tried  roo  reported  experience  learning  command  intuitively  understanding  present  command  mean  invariably  evolution  resulted  better  understanding  usage  pattern  provides  considerable  scope  revisiting  existing  command  name  improving  consistency  expressiveness  memorisation  ease  issue  result  existing  command  name  changing  command  option  ie  portion  command  prefixed  doublehyphen  hand  reviewed  part  task  command  option  nearly  critical  learning  roo  command  name  command  name  established  tabcompleting  shell  interface  guide  user  mandatory  optional  command  option  intelligent  easytouse  manner  anyway  main  area  intended  improvement  identify  desired  output  artifact  beginning  command  example  create  controller  would  become  controller  create  similar  addition  possible  differentiation  installation  postinstallation  setup  removed  install  jpa  would  become  persistence  setup  update  jpa  would  removed  task  deferred  detailed  understanding  version  100  command  would  reached,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
964,turbo  charge  performance  persistence  setup  command,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
965,enhance  file  manager  create  update  xml  file  currently  client  required  create  mutablefile  instance  read  xml  file  convert  dom  document  file  manager  xmlutils  enhanced  work  reducing  need  much  code  caller,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
966,findxxxid  use  querygetsingleresult  instead  querygetresultlist  currently  order  get  single  result  findxxx  get  resultlist  get  first  element  list  requires  method  transactional  transactional  resultssize  would  throw  exception  stating  session  manager  closed  using  querygetsingleresult  efficient  require  transaction  instead  generated  currently  generated  nonuniqueresultexception  one  result  propagate  masked  error  occurs  would  identify  lack  database  integrity  currently  lack  integrity  would  hidden,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
967,web  view  json  view  inconsistent  json  view  use  deepserialize  allow  option  example  however  view  inconsistent  normal  get  normal  get  deep  aka  see  user  one  many  property  authority  etc  generated  json  code  underlying  object  otherwise  roo  provide  mechanism  however  consistent  might  want  consider  deep  default  otherwise  data  delivered  default  get  view,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
968,remove  maven  project  listener  artifact  listener  dependency  listener  plugin  listener  etc  removed  project  module  redundant  use  user  edits  pom  manually,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
969,performance  enhancement  relating  member  detail  scanner  type  location  service  impl,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
970,change  typelocationservicegetsrcmainjavatypes  getprojectjavatypespath  path  pas  path  attribute  method  make  generic  eg  allow  test  java  type  returned  required,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
971,upgrade  solrj  driver  version  141  upgrade  solrj  driver  version,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
972,improve  performance  roo  shell  large  project  project  entity  web  controller  roo  take  long  time  load,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
973,parameterise  orgspringframeworkrooshellconverter  refactoring  internal  interface  affect  roo  user  addon  developer  org  spring  framework  roo  shell  converter  interface  currently  signature  improved  type  safety  parameterise  interface  type  instead  returning  object  accepting  class,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
974,create  abstractoperations  class  containing  common  method  addon  operation  implementation  abstract  class  abstract  operation  created  classpath  module  operation  class  jsfoperations  impl  jsp  operation  impl  inherit  method  common,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
975,create  javabeanannotationvalues  consistency  addons,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
976,creating  javautilset  url  slow  unreliable  return  set  url  set  rely  upon  equal  hashcode  method  contained  object  performant  correct  url  class  fails  count  documented  notably  method  require  dns  lookup  slow  return  different  result  depending  upon  whether  internet  connection  available  inconsistent  change  method  return  set  either  plain  string  uris  problem  based  need  calling  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
977,create  interface  dataondemandprovider  integrationtestprovider  conform  pattern  addons  dod  addontest  interface  provider  existing  provider  suffixed  impl  well  extending  respective  interface,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
978,minor  change  addon  roobot  operation  api  accommodate  sts  requirement  minor  change  addon  roobot  operation  api  accommodate  sts  requirement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
979,controller  shouldnt  call  findall  request  explained  forum  thread  using  pet  entity  example  controller  code  generated  roo  call  findallpets  upon  every  request  thanks  presence  method  wasteful  given  controller  request  handling  method  show  delete  dont  even  use  returned  list  pet  list  method  obtains  list  pet  usually  via  create  update  method  need  list  pet  pet  class  pet  pet  field  make  scaffolded  controller  performant  obtaining  list  pet  actually  required  meantime  workaround  follows  push  populate  pet  method  return  null  save  time  list  method  entity  field  type  collection  thereof  push  create  update  method  modify  explicitly  put  pet  list  model  example  showing  create  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
980,improve  support  classifier  element  maven  dependency  element  classifier  element  part  equal  hashcode  compareto  method  dependency  make  sense  add  option  dependency  add  remove  command  enable  user  able  add  remove  dependency  source  jar  example,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
981,allow  filemanager  explain  deleting  file  currently  method  take  canonical  file  path  noted  abstractitd  metadata  provider  would  useful  overloaded  version  method  also  took  reason  deletion  message  displayed  console  appended  existing  rather  laconic  message  would  boon  anyone  debugging  roo  addons,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
982,display  id  first  item  using  rooentity  rootostring  since  jpa  entity  id  would  nice  display  id  first  item  generated  string  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
983,field  jms  template  command  add  jmsoperations  jmstemplate  roo  command  add  field  specified  java  class  follows  spirit  programming  interface  field  declared  instead  allow  user  deploy  alternative  implementation  desired,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
984,improve  thread  safety  mail  message  run  script  bean  definition  two  problem  bean  singleton  every  entity  class  simple  mail  message  field  receive  instance  class  stateful  possible  different  thread  interfere  eg  one  thread  set  address  used  different  thread  even  bean  made  prototype  given  instance  given  entity  might  conceivably  used  multiple  thread  causing  thread  safety  issue  solution  use  field  genuine  template  follows  workaround  make  change  manually,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
985,upgrade  databasecom  vmforce  jpa  provider  roo  using  old  version  database  om  vmforce  jpa  provider  upgrade  version  well  jpa  configuration,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
986,new  roojpaentity  annotation  manage  core  jpa  entity  concern  existing  annotation  responsible  number  jparelated  concern  id  field  gettersetter  version  field  desired  getter  setter  annotation  annotation  necessary  crud  method  implement  active  record  pattern  core  finder  dynamic  finder  layering  change  support  jpa  repositoriesdaos  make  desirable  item  list  managed  new  roojpa  entity  annotation  associated  jpa  entity  metadata  provider  create  new  itd  entity  user  project  maintain  backward  compatibility  metadata  provider  triggered  presence  either  existing  project  domain  type  latter  attribute  value  taking  precedence  entity  shell  command  continue  apply  rooentity  annotation  continue  introduce  code  listed  user  wishing  remove  crud  method  retain  core  jpa  entity  support  use  jpa  repository  able  replacing  rooentity  roojpaentity  point  future  scope  may  rename  something  accurate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
987,merge  jpa  addons  addonjpa  addonentity  jpa  baked  addons  make  sense  merge,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
988,update  dbre  use  persistencememberlocator,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
989,introduce  new  trigger  annotation  mvc  json  integration  introduce  new  trigger  annotation  mvc  json  integration  change  deprecate  disable  roo  web  scaffold  exposejson  attribute  used  far  trigger  integration  json  support  mvc  application,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
990,current  type  parsing  implementation  tightly  coupled  roo  issue  encompasses  number  problem  current  parsing  type  manipulation  implementation  roo  heart  problem  would  difficult  replace  parsing  type  manipulation  implementation  roo  currently  us  javaparser  parse  manipulate  type  disk  done  via  classpathjavaparser  module  first  issue  parsing  type  manipulation  tied  metadata  model  via  physicaltypemetadataprovider  instead  reimplementable  service  interface  would  nicer  default  physicaltypemetadataprovider  lived  standard  classpath  package  used  parsing  service  instead  current  situation  classpathjavaparser  provides  reference  physicaltypemetadataprovider  via  javaparsermetadataprovider  would  also  remove  javaparser  implementation  physicaltypemetadata  leave  standard  defaultphysicaltypemetadata  second  issue  classpathjavaparser  module  representation  standard  type  model  provides  enough  detail  build  model  parsed  compilation  unit  turn  said  model  back  javaparser  compilation  unit  standard  type  model  used  roo  found  classpath  module  detail  package  model  used  represent  type  memory  problem  two  model  needle  duplication  implementation  need  kept  sync  whilst  isnt  much  issue  regard  interface  rarely  change  keeping  additional  model  sync  roo  pattern  mutablemodelbuilder  immutablemodel  tedious  two  concrete  representation  essentially  thing  arent  able  easily  implement  equal  compareto  thus  dont  consistent  strategy  comparing  example  one  fieldmetadata  another  finally  also  duplication  mutableclassorinterfacetypedetails  essentially  provides  mutable  class  interfacetype  detail  alters  type  disk  would  better  type  manipulation  service  would  used  manipulate  type  disk  explicitly  passing  standard  class  interface  type  detail,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,1,1
991,introduce  new  trigger  annotation  mvc  finder  integration  introduce  new  trigger  annotation  mvc  finder  integration,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
992,change  package  structure  jpa  repository  addon  change  package  structure  jpa  repository  addon  org  springframework  roo  addon  layer  repository  jpa,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
993,make  test  transaction  integration  optional  make  test  transaction  integration  optional  transaction  integration  desired  persistence  provider  making  use  optional  generated  test  allow  provider  leverage  integration  test  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
994,reduce  need  reparse  reevaluate  z  attribute  xml  file  xml  round  tripping  work  comparing  element  applying  z  attribute  hash  detect  something  changed  process  somewhat  resource  intensive  le  type  operation  performed  better,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
995,provide  mechanism  see  itds  associated  specific  type  changed  roo  representation  itds  project  maintained  retrieved  metadata  item  troublesome  trying  maintain  cache  take  account  change  itds  disk  persistencememberlocatorimpl  another  potential  improvemen  itd  store  would  memberdetailsscannerimpl  reduction  mindless  metadata  retrieval  could  achieved  using  already  produced  itdtypedetails  subsequent  metadata  production  initial  prototype  developed  member  detail  scanner  impl  reduced  metadata  request  80  work  needed  ready  prime  time,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
996,issue  warning  deprecated  mvc  command  issue  warning  deprecated  mvc  command,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
997,dont  update  database  upon  switching  jpa  provider  entity  dbremanaged  internal  bike  shop  test  project  us  mysql  hibernate  creating  project  change  jpa  provider  eg  follows  persistence  setup  database  mysql  provider  eclipselink  provider  configured  update  database  schema  desirable  project  dbremanaged  entity  definition  corresponding  table  never  updated  would  better  property  set  update  schema  none  case  eclipselink  would  mean  creating  updating  required  table  nondbre  entity  lesser  two  evil,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
998,dataondemand  lookup  integrationtestmetadataprovider  rigid  integration  test  metadata  provider  base  search  entity  data  demand  based  type  name  roo  know  everything  project  lookup  made  much  flexible  inspecting  type  roodataondemand  annotation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
999,create  addon  displaying  prettyprint  representation  class  new  addon  addon  displayname  created  provide  method  returning  string  representation  owning  class  similar  addontostring  however  new  addon  produce  string  used  display  uis  well  aid  conversion  method  name  exact  field  customised  via  new  roo  display  name  annotation,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1000,standardise  roo  annotation  value  read  metadata  provider  read  roo  annotation  using  subclass  abstract  annotation  value  two  harmonise  use  pattern  others  metadata  provider  read  annotation  value  subclass  abstract  annotation  value  pass  instance  metadata  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1001,add  thirdparty  addon  creation  management  infrastructure  support  third  party  addons  including  addon  creating  addon  assist  user  creating  addons,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
1002,implement  new  feature  interface  allow  addons  advise  installation  project  currently  operation  class  must  detect  artifact  generated  addons  determine  installed  project  example  jsp  addon  try  locate  jsf  facesconfigxml  file  project  found  allow  jsp  installed  change  allow  addons  determine  enabled  project  mean  caller  make  simple  call  projectoperations  method,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
1003,enhance  addontostring  use  commonslang  builder  remove  addondisplaystring  two  addons  generate  tostringstyle  method  ideal  improvement  modify  output  roo  string  compatible  display  ui  view  well  removing  need  addondisplaystring  jsf  mvc  addons  simply  use  string  method  display  entity  data  table  well  jsf  converter  string  addon  make  use  commonslang  reflectiontostringbuilder  generate  string  method  handle  null  collection  etc  without  need  addon  handle  condition  course  entity  string  method  pushed  customized,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1004,allow  dbre  make  db  connection  via  jndi,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1005,decouple  primefaces  reference  jsfoperationsimpl  currently  prime  face  hard  coded  jsf  operation  impl  class  improvement  add  new  optional  library  option  web  jsf  setup  command  treat  prime  face  similarly  userselectable  implementation  option,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1006,choose  data  access  pattern  time  aspect  j  generated  aspect  entity  class  follow  active  record  pattern  would  nice  could  choose  pattern  data  access  object  without  spring  dao  support  way  configure  would  persistence  setup  database  accesspattern  active  record  dao,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1007,use  apache  common  library  roo  roo  internally  used  copy  class  available  apache  common  lang  common  io  common  collection  common  codec  library  ticket  add  common  dependency  roo  remove  roo  managed  equivalent  test  class  string  utils  common  library  small  well  tested  already  osgi  compatible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1008,update  addontailor  supplied  patch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1009,add  selenium  addon  roo  generate  selenium  test  case  mvc  application,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1010,second  web  gwt  setup  produced  wrong  pomxml  execute  web  gwt  setup  secound  time  existing  project  update  newer  versionnumers  example  resulting  pom  xml  wrong  gwt  dependency  deleted  gwt  projectnature  duplicated  plugins  updated  gwtmavenplugin  twice  reproduce  behavior  run  expense  include  comment  gwtmavenplugin  exec  maven  plugin  see  updated  run  web  gwt  setup,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1011,provide  option  spring  roo  managed  xml  configuration  service  controller  gwt  locator  etc  environment  notably  gae  preferable  use  xml  configuration  instead  annotation  reduces  amount  time  required  application  start  environment  like  gae  application  frequently  created  destroyed  using  xml  configuration  greatly  increase  performance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1012,roo  creates  new  compilation  unit  entity  change  reported  parse  library  problem  comment  javadoc  found  roo  take  part  bug  problem  type  management  service  impl  create  update  type  disk  always  creates  new  file  based  roo  compilationunit  metadata  roo  metadata  support  comment  javadoc  metadata  new  java  file  none  solve  problem  propose  modify  typemanagementserviceimplcreateorupdatetypeondisk  check  file  exists  exists  call  getcompilationunitcontents  generate  new  java  content  create  exists  call  new  typeparsingservice  method  generates  java  content  based  original  compilationunit  updated  classorinterfacetypedetails  information  update  new  method  modify  typeparsingservice  declare  new  method  string  updateandgetcompilationunitcontentsstring  fileidentifier  classorinterfacetypedetails  cidthis  must  parse  fileidentifier  load  original  compilationunit  information  update  compilationunit  information  contained  cid  return  string  content  new  compilationunit  implement  java  parser  type  parsing  service  update  get  compilation  unitcontents,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1013,make  gae  gwt  version  property  setting  gwt  gae  version  hard  coded  throughout  pomxml  file  would  easier  upgrade  new  version  version  property,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1014,generate  json  method  deserialize  date  iso  8601  format  understand  json  spec  explicitly  call  date  serialised  accordance  iso  8601  javascript  tojson  method  make  assumption  offering  option  would  helpful  many  language  also  human  reading  debugging  support  backwards  compatibility  propose  addition  command  line  annotation  option  default  preserve  existing  serialisation  millis  since  start  epoch  enabled  new  option  modify  generation  performed  json  metadata  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1015,improve  method  level  security  spring  roo  service  including  permissionevaluator  add  ability  use  permissionevaluators  service  managed  spring  roo,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1016,spring  roo  doesnt  start  jdk  18  using  spring  roo  java  version  try  start  roosh  get  ton  unresolved  constraint  log  file  attached  searching  web  found  tried  replace  felijar  spring  roo  distribution  could  start  shell  successfully,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1017,menuoperations  make  use  filemanagerfindmatchingantpath  update  message  bundle  currently  menuoperations  update  message  roperties  file  individually  insert  label  name  menu  item  requires  u  register  every  new  message  property  file  make  sense  use  filemanager  find  matching  ant  path  antpath  ant  path  match  message  property,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1018,update  available  command  converter  bundle  change  want  work  subsystem  roo  addon  suite  necessary  update  available  command  available  converter  new  bundle  installation  bundle  status  change,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
1019,roo  addon  suite  support  include  roo  addon  suite  support  spring  roo  shell  related  roo  addon  suite  great  way  package  distribute  set  addons  together  example  want  distribute  roo  custom  distribution  roo  addon  suite  based  osgi  r5  subsystem  provides  really  convenient  deployment  model  without  compromising  modularity  roo,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1020,roo  command  refactoring  analyze  sping  roo  component  really  necessary  apply  following  change  addon  create  wrapper  command  must  appear  project  setup  equal  command  must  appear  project  setup  remove  flash  test  command  implementation  focus  command  must  appear  project  setup  maven  command  must  appear  project  setup  metadata  command  must  appear  project  setup  rename  project  command  project  setup  rename  poll  command  project  scan  project  scan  command  must  appear  project  setup  process  manager  command  must  appear  development  mode  reference  guide  command  must  appear  development  mode  web  mvc  json  setup  command  must  appear  project  setup  rename  osgi  framework  command  remove  spring  roo  osgi  command  addon  install  id  must  deleted  addon  info  id  must  deleted  create  new  command  addon  install  url  install  bundlesaddons  url  create  new  command  addon  repository  introspect  list  installed  addons  add  repository  parameter  list  addons  specific  repository,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0
1021,search  wrapping  default  osgi  repository  roobot  implemented  component  searched  osgi  r5  repository  update  wrapping  search  jdbc  driver  library  etc  use  repository  structure  instead  roobot  structure  repository  structure  spring  roo  addons,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1022,create  visual  component  manage  spring  roo  repository  addons  manage  osgi  repository  addons  important  feature  goal  task  create  new  visual  application  using  javafx  manage  spring  roo  repository  addons  using  graphical  mode  simple  spring  roo  command  like  addon  repository  manager  graphical  application  launched  allow  developer  manage  installed  repository  addons  easily  using  command,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1023,add  support  generate  generic  method  extend  spring  roo  method  builder  api  include  functionality  generates  generic  method,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
1024,switch  servicetracker  utility  detected  service  cycle  reference  initialization  time  solved  moving  automatic  service  dependency  resolution  manual  way  calling  service  registry  bundle  context  get  service  reference  get  service  reference  needed  solved  cycle  reference  problem  solution  doesnt  manage  dynamic  nature  osgi  service  task  consist  migrating  service  tracker  utility  hide  complexity  listening  consuming  dynamic  service  moment  migrate  service  reference  used  activate  method,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
1025,create  new  command  make  push  declared  method  field  itds  java  file  create  new  command  make  pushin  declared  method  field  itds  java  file  command  create  push  package  class  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1026,annotation  based  configuration  use  spring  boot  move  class  configuration  spite  xml  configuration  unfamiliar  configuration  class  think  pure  java  equivalent  spring  xml  file  since  spring  configuration  approach  provides  truly  firstclass  option  wish  configure  application  without  xml  spring  boot  well  suited  web  application  development  make  easy  create  standalone  productiongrade  spring  based  application  favor  javabased  configuration  generally  recommends  primary  source  configuration  class  spring  boot  autoconfiguration  attempt  automatically  configure  spring  application  based  jar  dependency  added  autoconfiguration  noninvasive  point  start  define  configuration  replace  specific  part  autoconfiguration  free  use  standard  spring  framework  technique  define  bean  injected  dependency  allows  externalize  configuration  work  application  code  different  environment  spring  profile  provide  way  segregate  part  application  configuration  make  available  certain  environment  spring  boot  us  common  logging  internal  logging  leaf  underlying  log  implementation  open  spring  security  classpath  web  application  secure  default  ‘basic’  authentication  http  endpoint  work  company  develops  shared  library  work  opensource  commercial  library  might  want  develop  autoconfiguration  autoconfiguration  class  bundled  external  jar  still  pickedup  spring  boot  spring  boot  includes  number  additional  feature  help  monitor  manage  application  it’s  pushed  production,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1027,generate  command  include  property  default  configuration  file  develop  new  command  include  spring  boot  others  property  default  application  config  file  default  configuration  file  located  could  modified  using  spring  roo  shell  configuration  feature  command  delegate  applicationconfigservice  command  take  mind  force  parameter  command  take  mind  profile  parameter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1028,create  new  indicator  clioptionautocompleteindicator  auto  completing  command  option  value  take  count  dependency  command  option  order  provide  right  value,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1029,update  repository  jpa  command  update  repository  jpa  command  support  new  spring  boot  project  structure  check  starterdatajpa  instead  persistence  doesnt  include  configuration  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1030,generate  repository  read  read  write  entity  developer  try  generate  new  repository  using  repository  command  need  define  entity  want  generate  repository  take  mind  entity  could  read  read  write  readonly  entity  roo  generates  interface  entity  custom  repository  include  dynamic  query  roo  creates  empty  implementation  previous  interface  extends  query  dsl  repository  support  roo  generates  interface  called  read  repository  extends  repository  like  following  roo  creates  interface  extends  interface  entity  custom  repository  read  repository  annotated  email  protected  read  write  entity  roo  generates  interface  entitycustomrepository  include  dynamic  query  roo  creates  empty  implementation  previous  interface  extends  query  dsl  repository  support  roo  generates  interface  extends  entity  custom  repository  jparepository  annotated  email  protected,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1031,remove  active  record  support  spring  roo  finder  developer  try  generate  new  repository  using  repository  command  need  define  entity  want  generate  repository  take  mind  entity  could  read  read  write  readonly  entity  roo  generates  interface  entity  custom  repository  include  dynamic  query  roo  creates  empty  implementation  previous  interface  extends  query  dsl  repository  support  roo  generates  interface  called  read  repository  extends  repository  like  following  roo  creates  interface  extends  interface  entity  custom  repository  read  repository  annotated  email  protected  read  write  entity  roo  generates  interface  entitycustomrepository  include  dynamic  query  roo  creates  empty  implementation  previous  interface  extends  query  dsl  repository  support  roo  generates  interface  extends  entity  custom  repository  jparepository  annotated  email  protected,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
1032,remove  active  record  support  spring  roo  finder  active  record  support  removed  update  finder  generation  new  spring  data  repository  system  update  finder  name  use  following  spring  data  nomenclature,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1033,refactoring  service  command  offer  command  manage  service  layer  generates  new  service  entity  current  project  generates  new  service  specific  entity  update  command  parameter  follow  spring  roo  analysis  new  command  like  following  generates  new  service  entity  current  project,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1034,update  aspectj  188  us  spring  io  platform  manage  spring  third  party  dependency  spring  io  platform  provides  last  version  aspectj  could  see  version  appendix  update  generated  include  last  version  aspectj  aspectj  maven  plugin,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1035,improve  multimodule  project  generation  day  multimodule  project  generation  little  bit  limited  update  current  process  able  generate  better  multimodule  project  using  spring  roo  shell,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
1036,install  spring  security  using  spring  boot  autoconfiguration  install  spring  security  generated  project  using  spring  boot  autoconfiguration  include  new  command  remove  deprecated  command  include  new  annotation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1037,generate  dtos  using  spring  roo  command  add  new  feature  spring  roo  shell  provide  necessary  command  generate  data  transfer  object  inside  generated  project  also  update  field  command  able  add  new  field  inside  dtos  update  finder  command  able  change  return  type  generated  finder  use  dtos,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
1038,include  spring  mvc  using  spring  boot  starter  include  spring  mvc  library  using  spring  boot  starter  update  command  related  item  able  install  spring  mvc  generated  project  using  spring  boot  autoconfiguration  feature,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1039,generate  controller  different  responsetypes  generate  new  controller  inside  current  project  add  parameter  provided  command  allow  developer  select  responsetype  new  controller,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
1040,generate  formatters  generate  formatters  inside  spring  roo  project  formatters  used  presentation  layer  format  registered  entity,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1041,generate  view  file  using  freemarker  template  engine  day  spring  roo  generates  view  file  static  format  structure  format  structure  editable  developer  developer  doesnt  take  decision  view  generation  provide  system  based  template  engine  allows  developer  customize  view  generation  content  format  structure  free  marker  first  template  engine  included  spring  roo  shell  template  engine  read  developer  custom  template  process  generate  final  view,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1042,use  jquery  datatables  list  view  spring  roo  shell  use  freemarker  template  engine  generate  view  include  necessary  element  configuration  able  use  jquery  datatables  component  list  view  instead  static  table,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1043,generate  masterdetail  view  default  using  datatables  component  generate  masterdetail  view  default  using  datatables  component  datatables  component  implemented  feature  allow  user  display  relation  entity,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1044,maintain  generated  thymeleaf  view  first  version  thymeleaf  view  generation  included  spring  necessary  improve  including  maintenance  generated  view  check  new  view  generate  exists  current  project  exists  include  new  one  exists  merge  content  old  one  new  one  take  mind  attribute  attribute  allow  spring  roo  shell  necessary  update  element,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1045,include  dependency  database  driver  repository  module  spring  roo  includes  maven  dependency  database  driver  application  module  execution  however  necessary  include  driver  every  module  contains  repository  command  executed  dependency  included  test  purpose  included  using  scope,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1046,create  fieldcreatorprovider  implementation  embeddable  class  allow  addition  new  field  embeddable  class  necessary  create  new  implementation  field  creator  provider  interface  work  embeddable  class  cover  embeddable  class  requirement,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1047,update  addondto  generate  projection  class  update  addon  addondto  included  spring  roo  register  new  command  separate  projection  generation  dto  generation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1048,update  finder  command  using  dtos  projection  update  finder  command  finder  return  entity  projection  andor  receive  dtos  entity,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1049,improve  findall  finder  method  generation  support  class  querydsl  repository  custom  implementation  use  clear  way  querying  redo  implementation  find  finbreference  finder  make  use  new  method  query  dsl  repository  support  ext,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1050,implement  command  generates  detail  controller  implement  command  generates  detail  controller  independlty  web  mvc  controller  command,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1051,create  view  web  mvc  finder  command  implement  new  view  using  finder  web  layer  finder  two  view  form  view  make  request  list  view  show  response,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
1052,improve  relationship  management  model  level  improve  entity  relationship  management,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1053,include  spring  security  include  spring  security  generated  project  using  spring  roo  shell  provide  two  different  way  use  security  security  using  auto  configuration  provided  spring  boot  security  using  domain  model,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1054,improve  relationship  management  repository  level  improve  entity  relationship  management,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1055,improve  relationship  management  repository  level  improve  entity  relationship  management,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1056,add  default  value  javapackage  parameter  possible  modify  command  using  java  package  type  autocomplete  default  value  possible  mandatory  javapackage  parameter  turned  optional  possible  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1057,include  dependency  springtx  include  dependency  springtx  check  transactional  annotation  generated  correctly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1058,improve  i18n  command  improve  command  able  select  default  language  current  application,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1059,improve  relationship  management  service  level  improve  relationship  management  service  level,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1060,move  finder  jpa  repository  move  finder  feature  repository  jpa  add  current  implementation  support  type  repository  also  make  easier  manage  generation,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
1061,improve  dependency  plugin  management  day  developer  includes  new  dependency  necessary  take  count  project  multimodule  multimodule  necessary  include  manually  dependency  dependency  management  pom  element  problem  plugins  need  added  plugin  management  developer  need  define  dependency  plugin  without  version  child  module  process  really  dangerous  could  produce  error  developer  forgots  include  dependency  plugins  update  operation  add  dependency  add  build  plugin  project  operation  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1062,improve  relationship  management  controller  level,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1063,add  support  send  receive  email  add  support  send  receive  email  using  service  java  mail  sender  project  springlets,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1064,generate  soap  web  service  using  spring  roo  shell  include  new  command  spring  roo  shell  able  generate  new  soap  web  service  generate  new  soap  web  service  client,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1065,improve  relationship  management  view  level,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1066,add  support  send  receive  jms  message  add  support  send  receive  jms  message,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1067,update  integration  test  support  update  integration  test  support  use  spring  boot  improvement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1068,improve  help  system  usability  help  info  confusing  combine  user  info  internal  roo  info  understand  user  hand  text  format  hard  reading  help  system  like  bash  man  command  writes  readable  help  text  improve  roo  help  system  similar  man  help  system  term  readability  usability  take  man  example  avoid  reinvent  wheel,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1069,implement  controller  url  generation  using  new  support  springlets  due  new  use  thymeleaf  utility  create  application  link  behavior  described  needed  another  way  easily  generate  url  controller  generated  view  using  springlets  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1070,new  entity  visualization  support  using  new  format  annotation  modify  generated  code  implement  new  visualization  system  entity  datatables  selector,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1071,specify  view  detail  displayed  great  developer  could  specify  master  view  new  detail  displayed  include  parameter  web  mvc  detail  command  specify  separated  comma  list  master  view  include  new  detail  list  show  view  valid  include  detail  list,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1072,included  field  private  included  field  private  method  use  accessor  mutator  method  instead  use  field  reference  directly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1073,generated  report  show  projection  field  defined  report  column  builder  building  projection  field  selected  show  entity  field,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1074,change  dod  test  implementation  use  entitymanager  instead  spring  data  repository  new  dod  implementation  using  factory  entity  obtain  instance  externalize  configuration  dod  class  using  new  configuration  class  change  unit  test  command  operation  generate  unit  test  entity  test  relation  make  lazy  loading  service  deserializers  avoid  loading  service  testing  controller,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
1075,create  new  integration  test  using  latest  spring  boot  support  modify  test  integration  operation  create  new  integration  test  using  latest  change  spring  boot,0,1,0,1,0,0,0,0,1,1,1,0,0,0,0,0,0
1076,unify  javabens  aj  file  improve  compilation  big  project  could  good  addon  javabean  metadata  generates  method  unique  file  affected  metadata  roo  string  roo  equalsand  roo  java  bean,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,1
1077,prefers  define  implement  java  file  aj  file  sometimes  aspectj  cant  compile  class  implement  declaration  defined  related  file  ever  possible  generate  implement  declaration  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1078,improve  javabean  addon  improve  javadoc  addon  return  setter  improve  javadoc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1079,improve  readability  message  resource  managed  roo  currently  roo  us  default  jdk  java  util  property  api  handle  message  resource  implementation  however  little  limiting  regard  formatting  preserve  formatting  order  key  value  pair  may  useful  handle  property  file  simple  util  class  preserve  formatting  order,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1080,change  shell  prompt  provide  current  entity  path  interesting  idea  guy  attended  roo  demo  today  stockholm  change  roo  shell  prompt  show  current  entity  youre  working  memorize  start  adding  field  prompt  could  provide  feedback  like  normal  shell  prompt  liked  idea  im  logging  jira  issue  forget,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1081,expose  generated  method  dynamic  finder  addon  controller  view  artifact  currently  dynamic  finder  addon  integrate  custom  finder  method  domain  object  leave  developer  expose  controller  view  layer  could  automated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1082,introspect  existing  database  support  simple  automatic  jpa  entity  real  world  enterprise  application  built  one  two  way  starting  relational  schema  building  application  top  starting  required  web  view  building  application  support  would  nice  roo  offered  extended  support  many  people  existing  database  wish  introspect  web  expose  usage  scenario  would  roo  command  like  example  database  reverse  would  scan  table  localhost  db  database  create  entity  table  unlike  normal  entity  though  field  would  added  entity  name  roo  reverse  itd  benefit  adding  field  itd  database  reverse  automatically  remove  update  entity  nam  roo  reverse  subsequent  execution  useful  database  changing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1083,introspect  existing  database  support  simple  automatic  jpa  entity  real  world  enterprise  application  built  one  two  way  starting  relational  schema  building  application  top  starting  required  web  view  building  application  support  would  nice  roo  offered  extended  support  many  people  existing  database  wish  introspect  web  expose  usage  scenario  would  roo  command  like  example  database  reverse  would  scan  table  localhost  db  database  create  entity  table  unlike  normal  entity  though  field  would  added  entity  name  roo  reverse  itd  benefit  adding  field  itd  database  reverse  automatically  remove  update  entity  nam  roo  reverse  subsequent  execution  useful  database  changing,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1
1084,need  support  embeddedid  way  specify  rooentity  want  use  embeddedid  order  use  composite  primary  key  eg  want  use  following  want  roo  managed  entity  edge  look  like  following  want  following  way  rooentity  great  something  called  embeddedidentifier  true  false  option  false  default  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1085,move  command  jline  shell  allow  usage  different  shell  implementation  several  command  method  jline  shell  make  reusing  command  hard  shell  implementation  like  sts  eclipse  shell  could  move  command  reusable  component  also  please  allow  override  command  completion  hint  version  error  text  maybe  using  system  property,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
1086,jsf  addon  create  roo  addon  jsf  view  facelets  template  instead  jsps,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1087,simplify  webxml  builder  editing  webxml  could  simplified  suggested  forum  post  maybe  something  like  would  seem  resolve  number  hickups  encountered  development  addons  date  like  filterfiltermapping  ordering  semantics  might  better  put  metadata  object  instead  provide  builder  also  appropriate  review  webxml  fragmentation  capability  considered  servlet  spec  3  building  metadata  object,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1088,itds  avoid  superflous  whitespace  end  generated  line  currently  roo  generates  itds  contain  various  indentrelated  space  end  line  error  creates  source  code  unnecessarily  larger  need  term  byte  look  unpleasant  developer  edit  file  roo  put  whitespace  end  line,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1089,reduce  duplicate  reference  data  code  generated  controller  imagine  domain  car  make  model  colour  generated  car  controller  roo  controller  file  createform  create  updateform  update  method  contain  code  populating  form  reference  data  violation  mean  want  tweak  reference  data  go  model  example  offer  nonmetallic  colour  push  four  public  method  roo  could  instead  generate  resuable  private  addreferencedata  model  map  method  called  four  method  developer  wanting  tweak  reference  data  need  push  one  private  method  example  would  look  like  default  course  four  public  method  listed  would  also  need  changed  example,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1090,scaffolded  controller  use  plural  referring  collection  resource  scaffolded  controller  map  resource  singular  path  owner  controller  map  owner  instead  use  plural  referring  collection  resource  owner  owner,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1091,improvement  addreferencedata  method  genrated  controller  instead  one  add  reference  data  method  add  reference  data  could  one  mehtod  reference  data  method  dont  called  controller  method  could  annotated  model  attribute  like  petclinic  example  would  allow  better  customization  get  reference  data  example  sometimes  appropriate  use  findall  reference  data  something  like  kind  customization  possible  current  add  reference  data  methodanother  issue  adreferencdata  method  seems  get  much  data  example  pet  entity  always  get  pet  controller  need  pet  reference  data  usually  pet  select  box  pet  form,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1092,patch  move  compilationunit  creation  method  javaparsermutableclassorinterfacetypedetails  right  compilationunit  creation  associated  physical  file  creation  code  java  parser  mutable  class  interface  type  detail  createtype  file  manager  filemanager  final  class  interface  type  detail  cit  string  fileidentifier  would  like  reuse  compilationunit  creation  obtain  string  java  code  way  compare  string  existing  file  use  case  want  generate  metadata  class  associated  original  class  created  metadata  provider  listens  source  code  modification  condition  met  creates  update  java  file  file  already  exists  compare  content  generated  java  code  different  file  updated  generate  java  code  want  reuse  code  java  parser  mutable  class  interfacetype  detailsi  attach  patch  java  parser  mutable  class  interface  type  detail  file  solution  moving  code  createtype  public  static  string  get  output  class  interface  type  detail  cit  reusing  method  inside  createtype,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1093,mappedsuperclass  implementation  think  roos  implementation  mappedsuperclass  could  improved  seems  suggested  way  create  mappedsuperclass  inheritance  structure  however  result  problem  mappedsuperclass  generated  entity  annotation  dont  think  correct  result  orm  creating  db  table  mappedsuperclass  doesnt  seem  right  never  populated  data  also  sun  doc  say  mappedsuperclass  shouldnt  entity  annotation  test  fail  alex  observes  asserterror  kind  kill  advantage  auto  generated  test  cant  build  project  mvn  something  may  preferable  time  possible  solution  could  maybe  mappedsuperclass  option  moved  roo  class  command  may  better  fit  mappedsuperclass  isnt  standard  entity  manually  remove  entity  annotation  mappedsuperclass  roo  make  make  test  work  hibernate  longer  make  redundent  superclass  table  suggestion  welcome,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1094,add  integration  enum  type  would  love  able  something  like  new  java  enum  name  domainentreeoption  add  value  chicken  add  value  steak  add  value  vegetarian  new  persistent  class  jpa  domain  guest  add  field  enum  jpa  entreeoption  type  domainentreeoption  would  create  enum  entreeoption  jpa  entity  guest  add  field  guest  type  entreeoption,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1095,convert  entitymetadataprovider  interface  allow  exposure  osgi  service  convert  entity  metadata  provider  interface  allow  exposure  osgi  service,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
1096,convert  webscaffoldmetadataprovider  interface  allow  exposure  osgi  service  convert  webscaffoldmetadataprovider  interface  allow  exposure  osgi  service,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1097,google  web  toolkit  gwt  integration  roo  support  gwt,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1098,table  tag  allow  nested  column  tag  define  desired  column  name  label  scaffolded  mvc  jsp  view  table  tag  allow  nested  column  tag  define  desired  column  name  label  scaffolded  mvc  jsp  view  current  use  proposed  use,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0
1099,review  templating  approach  flexible  allow  better  custom  branding  generated  application  generated  view  artifact  currently  allow  customization  generated  application  via  cs  header  jsp  footer  jsp  opportunity  simplify  enduser  branding,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1100,roo  addons  manipulate  webxml  use  new  webxmlutils  roo  addons  manipulate  webxml  use  new  webxmlutils,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1101,new  viewcontroller  command  user  id  like  viewcontroller  command  generate  mvcviewcontroller  element  select  view  rendering  proposed  syntax  viewname  required  path  optional  run  mvcviewcontroller  element  added  view  template  added  example,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1102,provide  ability  abstractitdmetadataprovider  discover  java  type  nonphysicaltypeidentifier  notification  presently  abstract  itd  metadata  provider  support  notified  classlevel  notification  received  unless  upstream  dependency  physical  type  identifier  fallback  model  apply  classlevel  notification  received  physical  type  identifier  upstream  dependency  fallback  locate  java  file  file  system  request  subclass  provide  metadata  practical  term  allows  subclass  notified  projectwide  metadata  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1103,refactor  addons  dependency  xml  file  generic  allow  maven  plugins  repository  plugin  repository  property  addons  dependency  xml  file  changed  configuration  xml  maven  artifact  added  repository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1104,add  tab  support  hint  command  please  add  tab  support  hint  command  noticed  type  hint  contab  nothing  happens  would  nice  tab  expansion  using  hint,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1105,add  history  support  generated  gwt  scaffold  app  add  history  support  generated  gwt  scaffold  app  absolute  stopship  m2  ajax  app  without  crawlable  without  entire  architecture  extremely  suspect,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1106,setup  gitsvn  building  new  project  user  creates  new  project  optional  switch  local  git  repo  could  created  git  repo  used  store  state  action  performed  roo  script  user  could  hand  well  option  would  make  best  practice  storing  thing  repo  easier  command  change  file  git  commit  could  done  relevant  comment  command  field  string  blah  git  store  adding  field  blah  entity  blah  done  manually  effort  make  easy  implement  undo  functionality  ie  going  step  back  branching  step  getting  rid  change  done,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1107,merge  roo  mvc  menu  addon  roo  mvc  jsp  addon  functionality  provided  current  mvc  menu  integral  part  mvc  jsp  addon  make  sense  merge  menu  addon  functionality  mvc  jsp  addon  alongside  merge  number  structural  organizational  change  mvc  jsp  addon  planned,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1108,refactor  support  module  better  support  nonosgi  usage  requirement  presently  support  module  depends  osgi  jar  two  method  support  module  actually  require  jar  roo  module  depend  support  module  desirable  two  method  relocated  dedicated  supportosgi  module  way  nonosgi  usage  requirement  better  supported  old  support  module  extend  osgibundle  still  package  osgi  bundle  new  supportosgi  module  also  extend  osgibundle  require  special  scrroo  maven  plugin  service,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1109,refactor  shell  module  better  support  nonosgi  usage  requirement  currently  shell  shelljline  module  depend  osgi  jar  limit  usability  outside  osgi  container  task  separate  osgi  usage  dedicated  module  assist  sts  integration  osgi  usage  broken  two  different  module  shellosgi  provide  osgi  service  shell  type  simpleparser  various  converter  implementation  shelljlineosgi  module  provide  osgi  service  shelljline  project  make  simpler  sts  simply  load  shelljline  shelljlineosgi  module,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1
1110,add  implement  keyword  class  command  currently  class  command  support  extends  extend  class  add  developer  productivity  add  implement  parameter  creating  interfacedriven  spring  bean  automate  creation  interface  implementing  class,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
1111,require  explicit  enabling  targeturlparameter  parameter  abstractauthenticationtargeturlrequesthandler  possible  authenticationsuccesshandler  class  extending  class  may  used  scenario  isnt  desirable  parameter  used  determine  redirect  location  though  invoked  login  request  shouldnt  problem  user  might  create  subclass  use  simpleurlauthenticationsuccesshandler  without  realising  parameterbased  functionality  exists  would  therefore  probably  preferable  require  functionality  explicitly  enabled  use  referer  header,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1112,support  naming  filter  chain  namespace  allow  easier  integration  external  service  like  oauth  since  namespace  support  multiple  filter  chain  allow  id  added  list  filter  bean  registry  make  easier  service  oauth  specify  filter  chain  want  integrate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1113,add  crypto  module  import  keiths  pull  request  crypto  module  code  used  greenhouse  oauth  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
1114,package  crypto  class  core  requires  core  depends  crypto  counterintuitive  would  make  sense  move  crypto  class  core  even  continue  supply  latter  separate  library,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
1115,haspermission  method  authorizetag  moment  check  permission  object  jsp  page  use  think  would  good  idea  call  method  book  variable  provided  page  context  call  method  throw  defined,1,0,1,0,1,0,0,0,0,1,0,1,1,0,0,0,0
1116,excessive  misleading  logging  delegatingmethodsecuritymetadatasource  switch  global  method  security  spring  security  add  custom  pointcut  matcher  delegate  code  class  log  every  method  ebery  bean  context  9as  far  tell  whether  going  intercepted  9999  log  attribute  empty  according  matcher  mean  match  could  log  level  changed  trace  also  message  changed  analyzing  matching  instead  adding,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1117,cannot  override  protected  defaultmethodsecurityexpressionhandlercreatesecurityexpressionroot  inconsistent  visibility  internals  protected  return  instance  package  private  class  would  fine  except  make  assumption  root  precise  type  therefore  actually  cannot  overridden  would  quite  useful,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1118,defensively  invoke  securitycontextholderclearcontext  filterchainproxy  situation  application  try  obtain  globally  may  cause  memory  leak  application  us  securitynone  even  read  similar  situation  occur  user  manually  create  filter  chain  properly  add  order  defensive  memory  leak  would  good  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1119,code  cleanup  bcrypt  implementation  situation  application  try  obtain  globally  may  cause  memory  leak  application  us  securitynone  even  read  similar  situation  occur  user  manually  create  filter  chain  properly  add  order  defensive  memory  leak  would  good  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1120,support  servlet  3031  asynchronous  request  processing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1121,basicauthenticationfilter  invoke  error  dispatch  configured  following  security  element  set  custom  error  page  webxml  example  authentication  fails  401  page  displayed  client  sends  invalid  basic  value  filter  chain  find  call  401  page  tomcat  unfortunately  filter  chain  proxy  know  one  request  error  forward  fire  entire  chain  maintains  property  tell  observe  check  property  treat  whole  new  request  response  get  reset  twice  output  written  client  could  set  error  page  securitynone  want  maintain  security  context  page  whether  protected,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1122,adding  new  constructor  advanced  parameter  rootdn  class  activedirectoryldapauthenticationprovider  different  domainname  dcinfodclocal  meet  problem  auth  domain  user  modifiyng  activedirectoryldapauthenticationprovider  adding  new  contructor  work  need  possibility  set  different  domainname  rootdn  work  properly  u  next  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1123,implement  servlet  3  httpservletrequest  authentication  method  need  investigation  deal  fact  often  time  spring  security  may  commit  response  item,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1124,spring  cache  abstraction  based  usercache  implementation  spring  cache  abstraction  since  31  would  nice  spring  security  took  advantage  appropriate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1125,update  bcrypt  best  practice  tutorial  javadoc  updated  reflect  using  bcrypt  recommended  best  practice,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1126,support  servlet  31s  httpservletrequestchangesessionid  alternate  session  fixation  protection  strategy  servlet  31  specification  set  release  next  month  two  add  new  method  support  changing  id  session  approach  session  fixation  protection  ideal  approach  spring  security  current  approach  creating  new  session  copying  part  content  current  session  new  session  invalidating  old  session  using  method  spring  security  current  strategy  would  likely  achieve  performance  improvement  especially  highload  scenario  developer  using  spring  security  need  s  support  calling  alternate  session  fixation  protection  strategy  would  glad  implement  submit  pull  request  big  change  id  like  discussion  get  buyin  planned  design  set  work  first  timeline  consideration  dont  know  product  roadmap  spring  security  based  previous  release  cycle  im  guessing  youre  targeting  320m2  march  1  m3  april  1  ga  may  3  putting  5  month  behind  spring  320ga  saying  thats  bad  thing  laying  observation  timeline  hold  true  im  guessing  expect  spring  security  40  time  next  year  maybe  little  later  id  love  see  support  second  technical  consideration  belief  would  technically  work  new  option  would  added  namespace  attribute  currently  none  argument  sake  let  call  new  option  believe  documentation  clearly  stated  option  required  servlet  31  could  implement  s  3x  option  specified  older  servlet  environment  configuration  exception  would  thrown  could  use  reflection  access  didnt  compile  servlet  31  third  design  consideration  think  largest  roadblock  implementing  s  3x  idea  design  looking  code  sketching  thing  im  hard  time  imagining  changing  without  subtracting  public  interface  problem  code  decides  already  little  confusing  add  changesessionid  option  sessionfixationprotection  would  third  property  mutual  exclusion  among  wanted  avoid  subtracting  public  interface  logic  becomes  sketchy  confusing  would  make  configuration  difficult  simpler  alternative  would  remove  completely  replace  enum  single  property  enum  enums  option  would  newsession  migratesession  changesessionid  would  map  newsession  respectively  second  option  right  way  imo  ignoring  fact  existing  software  people  using  first  option  friendly  doesnt  break  backwards  compatibility  however  impact  second  option  could  lessened  fact  people  use  sessionfixationprotection  namespace  attribute  configure  dont  bother  class  directly  many  people  actually  use  directly  thats  question  dont  answer  alternative  third  option  would  pick  suitable  default  perhaps  migratesession  currently  default  anyway  deprecate  well  change  documentation  say  ignored  default  chosen  dont  use  enum  advantage  breaking  consuming  project  build  likewise  disadvantage  masking  someone  using  method  isnt  supported  anymore  assuming  ignore  compile  warning  know  occasionally  change  interface  x  release  compile  error  upgrading  spring  framework  30  31  question  big  deal  interface  class  change  32  could  always  wait  40  like  said  reaaaalllly  dont  want  wait  long  thought,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,1
1127,handling  multiple  authenticationentrypoint  default  example  dont  handle  following  well  also  handle  case  oauth  involved,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1128,httpauthorizeurls  httpauthorizerequests  descriptive  happening  dont  necessarily  need  match  url,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1129,abstractsecuritywebapplicationinitializer  allow  registration  java  config,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1130,spring  security  provide  handlermethodargumentresolver  authenticationgetprincipal,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1131,add  csrfrelated  tag  tag  library  tag  library  could  use  couple  new  tag  better  support  new  csrf  feature  insert  hidden  form  field  correct  name  value  csrf  token  helpful  support  case  whatever  reason  cant  use  spring  framework  form  tag  library  insert  html  meta  tag  recommended  tutorial  holding  csrf  header  name  form  field  name  token  value  use  javascript  code  additionally  tag  abide  feature  specified  spr10916  assuming  approved,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1132,provide  logical  negated  requestmatchers,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1133,update  java  configuration  sample  use  autowired  authenticationmanagerbuilder  mechanism  us  global  easier  share  authentication  configuration  ie  instance,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1134,csrfauthenticationstrategy  add  valid  token  http  request  clearing  one  http  session  clear  token  stored  http  session  successful  authentication  configured  application  client  redirect  http  301302  token  still  stored  request  invalid  store  new  current  request  clearing  session  something  like,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1135,create  enablewebmvcsecurity  rather  automatically  adding  mvc  integration  annotation  created  allows  user  customize  behavior  creating  bean  definition  desire  java  configuration  requires  annotation,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1136,convert  java  config  sample  thymeleaf  tile  jsps  easier  user  get  started  prevents  reuse  sample  older  technology  update  quite  time  additional  filter  cause  complex  setup  spring  security  save  specific  lesson,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1137,restriction  ldapauthenticationproviderconfigurer  defaultldapauthoritiespopulator  using  define  ldap  authentication  method  cant  define  build  hardcoded  context  use  ldap  process  authentication  database  process  role  passible  xml  configuration  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1138,support  csrf  protection  logout  url  xml  configuration  csrf  protection  work  fine  java  configuration  configured  accepts  post  however  application  using  xml  configuration  configures  take  request  method  account  could  find  way  change  configuration  ignore  get  request  logout  url  might  documentation  problem  looking  code  suspect  currently  supported,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1139,improve  standardpasswordencoder  performance  web  application  us  match  password  basic  authentication  heavy  load  700  http  request  per  second  becomes  major  source  contention  700  http  request  per  second  synchronized  block  average  contention  247  millisecond  maximum  118  second  500  http  request  per  second  synchronized  block  average  contention  28  millisecond  maximum  291  millisecond  wonder  non  synchronized  alternative,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1140,savedrequestawarewrapper  override  cooky  motivation  described,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
1141,ldapauthenticationproviderconfigurer  find  available  port  try  default  port  available  configure  available  port,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1142,support  static  nested  group  ldap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1143,support  authorization  rule  simpmessagetype  initial  security  allows  protecting  destination  without  taking  account  message  type  using  like  stomp  subscription  message  protected  independently  user  may  allowed  subscribe  destination  order  receive  message  allowed  send  message  destination,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1144,consistency  role  updated  description  spring  security  treat  role  consistently  example  java  configuration  allows  perform  something  like  must  restate  role  even  though  already  expressed  role  h1  improve  anytime  see  role  elsewhere  automatically  add  prefix  role  already  help  thing  remain  passive  mean  able  following  equivalent  example  implementation  detail  expression  support  expression  update  automatically  prefix  hasrole  hasanyrole  role  exist  example  support  jsr  250  update  parsed  updating  much  way  expression  ensures  jsr250securityconfig  populated  authority  prefixed  role  default  developer  return  authentication  userdetails  contains  authority  contain  role  prefix  change  introduce  nonpassive  change  might  look  like  fix  fixing  passivity  first  option  fix  thing  change  application  return  authority  prefixed  role  nothing  else  needed  example  memory  based  solution  might  following  obviously  production  system  would  likely  involve  data  migration  alternatively  could  update  userdetailsservice  prefix  role  programatically  option  b  update  configuration  another  option  reconfigure  spring  security  create  beanpostprocessor  look  like  sample  restoring  passivity  find  sample  attached  jira  demonstrate  fixing  passivity  xml  refer  difference  sec2785xmlzip  sec2785xml40zip  java  configuration  refer  difference  sec2785jczip  sec2785jc40zip  observation  working  spring  security  take  leave  different  apis  use  role  differently  mean  certain  part  require  roleuser  part  require  user  frankly  never  sure  one  use  rely  upon  example  deduce  look  following  think  need  somehow  clean  probably  major  breaking  affect  thing  cant  imagine  improvement  happening  major  release  scala  would  retool  apis  either  accept  raw  string  would  roleuser  accept  case  class  like  roleuser  meaning  thing  end  road  perhaps  deprecating  plain  string  walking  back  good  ole  java  im  sure  best  design  choice  would  idea  come  mind  static  import  nice  little  static  import  would  make  work  one  idea  imagine  requires  sticking  string  people  want  create  prefix  lieu  role  perhaps  extend  spring  security  piece  api  inject  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1145,add  httpstatusentrypoint  doesnt  appear  entry  point  sends  401  arbitrary  wwwauthenticate  header  nearly  good  enough  always  sends  basic  might  asking  example  javascript  client  want  detect  401  without  popping  basic  auth  dialog  browser  automatically,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1146,security  http  response  header  configuration  cleanup  currently  mechanism  customizing  http  response  header  number  limitation  example  one  want  include  default  header  modify  xframeoptions  sameorigin  ie  sockjs  support  must  duplicate  lot  configuration  example  java  config  would  look  like  issue  obvious  adding  element  remove  default  header  strive  secure  default  change  make  following  used  include  default  header  modify  xframeoptions  sameorigin  user  really  want  disable  default  header  done  explicitly  example  following  would  include  xframeoptions  sameorigin  header  one  also  disable  single  default  header  example  following  remove  xframeoptions  keep  default,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1147,support  configuring  securityexpressionhandlermessageobject  description  allow  easily  configuring  via  java  configuration  xml  configuration  original  description  work  project  starting  use  websockets  plan  secure  springsecuritymessaging  custom  security  expression  example  bogus  ie  websocket  security  config  class  extends  cant  find  method  either  inject  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1148,add  support  aesgcm  crypto  module  nice  get  something  sensible  box  default  aescbcpkcs5padding  best  choice  aesgcm  available  obviously  existing  apps  break  change  default  would  nice  add  extra  option  tweak  algorithm  assuming  supported  java,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1149,securitycontextholderawarerequestfilter  requestfactory  property  change  update  property  change  ensure  consistent  state,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1150,add  abstractpreauthenticatedprocessingfilter  principalchangedhttpservletrequest  authentication  allow  implementation  override  method  determine  principal  changed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1151,add  different  mutableobject  mode  runtime  currently  runtime  work  strictly  mutable  object  mean  object  possible  typically  one  two  reused  data  record  time  object  clonedrestored  though  various  place  ensure  content  fresh  every  call  rational  behind  reduce  pressure  garbage  collector  fact  run  program  garbage  collection  happens  udfs  written  reuse  object  well  however  lead  bug  notcarefully  written  user  code  propose  add  two  mode  runtime  noobjectreuse  default  mode  new  object  every  record  safe  potentially  slower  objectreusing  mode  object  reused  without  backup  copy  udfs  must  careful  keep  object  state  modify  object,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,1
1152,make  type  call  projection  optional  remove  think  type  call  optional  compiler  also  cast  data  set  directly  result  type  computed  input  type  anyways,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1153,add  mappartition  operator  based  pull  request  kay  fleischmann  httpsgithubcomapacheincubatorflinkpull42,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
1154,support  explicit  shuffling  datasets  right  flink  shuffle  data  required  operation  reduce  join  cogroup  way  explicitly  shuffle  data  set  however  situation  explicit  shuffling  would  helpful  including  rebalancing  computeintensive  map  operation  balancing  random  hash  partitioning  partitionmap  operation  see  flink1053  better  integration  support  hadoopjobs  see  flink838  issue  propose  add  following  method  dataset  datasetpartitionhashbyint  datasetpartitionhashbykeyselector  perform  explicit  hash  partitioning  datasetpartitionrandomly  shuffle  data  completely  random  datasetpartitionroundrobin  shuffle  data  roundrobin  fashion  generates  even  distribution  possible  bias  due  prior  distribution  datasetpartitionroundrobin  might  necessary  think  random  shuffling  balance  good  enough,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1155,type  extraction  lambda  lambda  currently  work  filter  reduceab  lambda  type  extraction  place  right  need  extend  type  extraction  lambda  support  function,1,0,1,0,1,0,0,1,0,1,1,0,0,0,0,0,1
1156,support  functionlevel  compatibility  hadoops  wrapper  function  flink  wrapper  hadoop  map  reduce  task  implemented  httpsgithubcomapacheincubatorflinkpull37  currently  possible  use  hadoopmapfunction  hadoopreducefunction  without  jobconf  woule  useful  could  specify  hadoop  mapper  reducer  combiner  use  seperate  component  flink  job,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1157,add  aggregation  streaming  add  support  summation  mimimum  maximum  aggregation  based  reduce  functionality,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1158,projection  operator  streaming  enable  following  code  usual  semantics  streamproject12typesstringclass  integerclass  consider  whether  providing  type  necessary,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1159,update  streaming  example  become  selfcontained  streaming  example  follow  standard  set  recent  example  refactor  batch  api  testdatautil  removed  object  used  contain  example  data  comment  also  lacking  comparison  batch  counterpart,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
1160,add  serial  collectionbased  execution  mode  summary  mailing  list  thread  issue  based  upon  since  flink  layered  system  program  written  apis  executed  variety  way  case  run  function  singlethreaded  directly  java  collection  instead  firing  memory  management  ipc  parallel  worker  data  movement  etc  give  program  minimal  execution  footprint  like  java8  stream  api  small  data  idea  enable  user  use  program  sort  different  context  collection  execution  sit  common  api  java  scala  api  use,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
1161,move  basic  array  type  information  flinkcore  project  logically  part  common  ground  javascala  api  test  common  api  currently  impossible  type  information  common  project,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1162,add  executestring  jobname  streamexecutionenvironment  way  provide  name  job  currently  lacking  streaming  job,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1163,typeinference  pojos  tuples  currently  use  type  inference  figure  type  output  type  variable  relative  input  type  variable  need  similar  functionality  pojos,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1164,createcollectionsenvironment  java  api  scala  api  executionenvironment  method  createcollectionenvironment  java  api  stick  one  approach  apis,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1165,support  multicharacter  field  delimiters  csvinputformats  csvinputformat  support  multichar  string  line  delimiters  singlechar  char  field  delimiters  issue  proposes  add  support  multichar  field  delimiters,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1166,add  socket  text  stream  data  source  streaming  api  add  sockettextstreamhostnameport  method  streamexecutionenvironment  would  add  datastreamsource  listens  stream  text  input  received  selected  port  streaming  program,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1167,temporal  cross  operator  streaming  provide  operator  cross  produce  cartesian  product  window  data  stream,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1168,store  broadcast  variable  per  taskmanager  currently  copy  broadcast  variable  sent  parallel  task  rather  taskmanager  task  share  sharing  braodcast  variable  would  increase  memory  efficiency  significantly,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1
1169,github  rework  configuration  object  currently  configuration  implemented  hacky  everything  represented  serialized  string  clean  interface  different  flavor  configuration  global  delegatin  default  inconsistent  propose  rework  configuration  map  object  serialized  demand  either  serialization  library  default  serialization  mechanism  factoring  interface  configuration  allows  keep  flavor  consistent  imported  github  url  httpsgithubcomstratospherestratosphereissues12  created  stephanewenhttpsgithubcomstephanewen  label  enhancement  created  mon  apr  29  234311  cest  2013  state  open,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1170,use  program  source  line  invocation  default  function  name  right  default  function  name  getclassgetname  many  case  really  revealing  using  line  source  code  function  invoked  helpful  easily  obtained  code  threadgetcurrentthreadgetstacktrace0  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1171,introduce  typehints  java  api  operator  due  type  extraction  issue  java  8  lambda  many  user  type  erasure  issue  typehints  need  introduced  whole  discussion  found  mailing  list  httpmailarchivesapacheorgmodmboxflinkdev201410mbox3c544fa7d61070708twalthrcom3e,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1
1172,generalize  flinks  distributedfilesystemclass  hadoop  filesystem  wrapper  currently  hadoops  distributedfilesystem  class  somewhat  hardwired  flink  distributedfilesystem  class  actually  necessary  flinks  distributedfilesystem  class  assuming  hadoops  filesystem  class  generalizing  flink  dfs  class  easily  support  file  system  implementing  hadoop  f  class  googlehadoopfilesystem  tachyon  others,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1173,make  execution  mode  configurable  discussed  pr  httpsgithubcomapacheincubatorflinkpull227discussionr20788430  goal  would  make  execution  mode  configurable  order  easily  configure  closure  cleaning  custom  serializers  object  reuse  etc  configuration  could  done  either  via  1  setter  2  configuration  object  vote  2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0
1174,improve  file  input  split  assignment  running  dfs  readintensive  benchmark  found  assignment  input  split  optimal  particular  case  numworker  numdatanodes  replication  factor  low  case  1  particular  example  input  40960  split  4694  read  remotely  spark  2056  remote  read  dataset  replication  factor  increased  2  flink  290  remote  read  usually  user  shouldnt  affected  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1175,add  option  flink  client  start  yarn  session  per  job  currently  flink  user  launch  flink  yarn  yarn  session  meaning  longrunning  yarn  application  run  multiple  flink  job  user  requested  extend  flink  client  allocate  yarn  container  executing  single  job  part  pull  request  would  suggest  refactor  yarn  client  make  modular  object  oriented,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
1176,make  quoted  string  parsing  optional  configurable  csvinputformats  current  implementation  csvinputformat  quoted  string  parsing  kick  first  nonwhitespace  character  field  double  quote  see  two  issue  implementation  1  quoted  string  parsing  cannot  disabled  2  quoting  character  fixed  double  quote  propose  add  parameter  disable  quoted  string  parsing  set  quote  character,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
1177,add  static  code  analysis  udfs  flinks  optimizer  take  information  tell  udfs  field  input  element  accessed  modified  frwardedcopied  information  frequently  help  reuse  partitioning  sort  etc  may  speed  program  significantly  frequently  eliminate  sort  shuffle  costly  right  user  add  lightweight  annotation  udfs  provide  information  adding  constandfields03  1  21  worked  static  code  analysis  udfs  determine  information  automatically  incredible  feature  magically  make  program  faster  recordatatime  operation  map  reduce  flatmap  join  cross  work  surprisingly  well  many  case  used  soot  toolkit  static  code  analysis  unfortunately  soot  lgpl  licensed  thus  include  code  far  propose  add  functionality  flink  form  dropin  addition  work  around  lgpl  incompatibility  al  20  user  could  simply  download  special  flinkcodeanalysisjar  drop  lib  folder  enable  functionality  may  even  add  script  tool  downloads  library  automatically  lib  folder  legally  fine  since  redistribute  lgpl  code  dynamically  link  incompatibility  asl  20  mainly  patentability  remember  correctly  prior  work  done  aljoscha  skunert  could  provide  code  base  start  appendix  hompage  soot  static  analysis  toolkit  httpwwwsablemcgillcasoot  paper  static  analysis  optimization  httpstratosphereeuassetspapersenablingoperatorreorderingsca12pdf  httpstratosphereeuassetspapersopeningtheblackboxes12pdf  quick  introduction  optimizer  httpstratosphereeuassetspapers2014vldbjstratosphereoverviewpdf  section  6  optimizer  iteration  httpstratosphereeuassetspapersspinningfastiterativedataflows12pdf  section  43  53,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1178,add  offheap  variant  managed  memory  nearly  memory  flink  accumulates  form  sort  buffer  hash  table  caching  use  special  way  representing  data  serialized  across  set  memory  page  big  work  lie  way  algorithm  implemented  operate  page  rather  object  core  class  memory  memorysegment  method  set  get  primitive  value  efficiently  somewhat  simpler  faster  variant  heapbytebuffer  straightforward  create  version  memory  segment  backed  heap  byte  memory  allocated  outside  jvm  similar  way  nio  directbytebuffers  netty  direct  buffer  may  multiple  advantage  reduce  size  jvm  heap  garbage  collected  number  size  long  living  alive  object  large  jvm  size  may  improve  performance  quite  bit  utilmately  would  many  case  reduce  jvm  size  13  12  keep  remaining  memory  outside  jvm  save  copy  move  memory  page  disk  spilling  network  shuffling  broadcasting  forward  piping  change  required  implement  add  unmanagedmemorysegment  store  memory  adress  long  segment  size  initialized  directbytebuffer  allow  memorymanager  allocate  memorysegments  instead  current  one  make  sure  startup  script  pick  mode  configure  heap  size  max  direct  memory  properly  since  memorysegment  probably  performance  critical  class  flink  must  take  care  right  following  critical  consideration  want  solution  heap  offheap  exist  sidebyside  configurable  must  make  base  memorysegment  abstract  implement  two  version  heap  offheap  get  best  performance  need  make  sure  one  class  get  loaded  least  ever  used  ensure  optimal  jit  devirtualization  inlining  carefully  measure  performance  variant  previous  micro  benchmark  remember  individual  byte  access  directbytebuffers  offheap  slightly  slower  onheap  larger  access  equally  good  slightly  better,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,1,1
1179,rework  constant  field  annotation  constant  field  annotation  used  optimizer  determine  whether  physical  data  property  sorting  partitioning  retained  user  defined  function  current  implementation  limited  extended  several  way  field  copied  position  field  definition  nontuple  data  type  pojos  pull  request  83  go  direction  extended,1,0,1,0,1,0,1,1,0,0,1,0,0,0,0,1,1
1180,pojo  serializerscomparators  fail  using  subclass  interface  0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
1181,allow  setting  custom  file  extension  file  created  fileoutputformat  user  requested  ability  name  avro  file  avro  extension,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1182,akka  cleanup  currently  akka  many  different  timeout  value  user  perspective  would  helpful  deduce  different  timeouts  single  timeout  value  additionally  user  still  able  define  specific  value  different  timeouts  akka  us  akkajobmanagerurl  config  parameter  override  jobmanager  address  port  case  local  setup  mechanism  safe  since  exposed  user  thus  mechanism  replaced  notifyexecutionstatechange  method  allows  object  access  internal  state  taskmanager  actor  cause  nullpointerexceptions  shutting  actor  method  removed  avoid  accessing  internal  state  actor  another  object  latest  akka  change  taskmanager  watch  jobmanager  order  detect  died  lost  connection  taskmanager  behaviour  tested,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1183,automatically  register  nested  type  kryo  currently  generictypeinfo  register  class  type  kryo  order  get  best  performance  recursively  walk  class  make  sure  registered  contained  subtypes,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
1184,commandline  interface  verbose  option  error  reporting  let  run  basic  flink  job  add  verbose  flag  general  option  let  add  first  parameter  flink  v  run  examplesflinkjavaexamples080wordcountjar  hdfsinput  hdfsoutput9  invalid  action  flink  action  generaloptions  argument  general  option  hhelp  show  help  cli  frontend  vverbose  print  detailed  error  message  action  run  compiles  run  program  syntax  run  option  jarfile  argument  run  action  argument  cclass  classname  class  program  entry  point  main  method  getplan  method  needed  jar  file  specify  class  manifest  mjobmanager  hostport  address  jobmanager  master  connect  use  flag  connect  different  jobmanager  one  specified  configuration  pparallelism  parallelism  parallelism  run  program  optional  flag  override  default  value  specified  configuration  action  info  display  information  program  info  action  argument  cclass  classname  class  program  entry  point  main  method  getplan  method  needed  jar  file  specify  class  manifest  eexecutionplan  show  optimized  execution  plan  program  json  mjobmanager  hostport  address  jobmanager  master  connect  use  flag  connect  different  jobmanager  one  specified  configuration  pparallelism  parallelism  parallelism  run  program  optional  flag  override  default  value  specified  configuration  action  list  list  running  finished  program  list  action  argument  mjobmanager  hostport  address  jobmanager  master  connect  use  flag  connect  different  jobmanager  one  specified  configuration  rrunning  show  running  program  jobids  sscheduled  show  scheduled  prorgrams  jobids  action  cancel  cancel  running  program  cancel  action  argument  ijobid  jobid  jobid  program  cancel  mjobmanager  hostport  address  jobmanager  master  connect  use  flag  connect  different  jobmanager  one  specified  configuration  happened  result  lot  output  usually  generated  use  help  option  commandline  tool  terminal  window  large  enough  see  tiny  message  please  specify  action  specify  action  strange  read  help  message  carefully  see  general  option  belong  action  flink  run  v  examplesflinkjavaexamples080wordcountjar  hdfsinput  hdfsoutput9  sake  mitigating  user  frustration  let  u  also  accept  v  first  argument  may  seem  trivial  daytoday  flink  user  make  difference  novice,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1185,typo  fix  fix  typo  also  fix  inconsistent  us  partition  operator  partitioning  operator  codebase,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1186,add  strictly  local  input  split  assignment  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1187,make  akka  timeout  configurable  yarn  client  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1188,modify  inputiterator  streaming  channel  index  last  record  accessible  currently  channel  id  last  received  record  inaccessible  iterator  implement  sorting  operator  stream  need  information,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1189,add  option  switch  avro  kryo  serialization  generictypes  allow  user  switch  underlying  serializer  generictypes,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1190,change  gelly  example  consistent  flink  example  current  gelly  example  work  default  input  data  look  flink  example  eg  connected  component  also  allow  input  data  read  text  file  passed  parameter  main  method  would  nice  follow  approach  example  first  step  direction  sssp  example,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
1191,add  option  pas  configuration  localexecutor  right  possible  user  pas  custom  configuration  value  flink  running  within  ide  would  convenient  able  create  local  execution  environment  allows  passing  configuration  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1192,remove  window  merge  flatten  optimization  window  reduce  map  transformation  always  merge  step  transformation  parallel  grouped  merge  step  removed  windowing  operator  followed  flatten  avoid  unnecessary  bottleneck  program  feature  added  optimization  step  windowingoptimizer  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1193,add  preaggregator  time  window  currently  support  preaggregators  tumbling  policy  preaggregator  added  time  policy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1194,rename  expression  api  operation  representation  right  package  called  flinkexpressions  refer  api  expression  api  equivalent  dataset  datastream  expressionoperation  im  happy  name  find  something  marketable  making  big  announcement,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
1195,add  option  start  flink  yarn  detached  mode  right  expect  yarn  command  line  interface  connected  application  master  time  control  yarn  session  job  long  running  session  job  user  want  fire  forget  jobsession  yarn  stopping  session  still  possible  using  yarn  tool  also  prior  detaching  cli  frontend  could  print  required  command  kill  session  convenience,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
1196,improve  error  handling  partition  found  result  partition  released  concurrently  remote  partition  request  request  might  come  late  result  exception  receiving  task  saying  code  160422499  info  orgapacheflinkruntimetaskmanagertask  chain  partition  map  map  testrestartmultipletimessimplerecoveryitcasejava200  14  switched  failed  javaioioexception  orgapacheflinkruntimeionetworkpartitionqueueillegalqueueiteratorrequestexception  remote  input  channel  intermediate  result  partition  already  released  orgapacheflinkruntimeionetworkpartitionconsumerremoteinputchannelcheckioerrorremoteinputchanneljava223  orgapacheflinkruntimeionetworkpartitionconsumerremoteinputchannelgetnextbufferremoteinputchanneljava103  orgapacheflinkruntimeionetworkpartitionconsumersingleinputgategetnextbufferoreventsingleinputgatejava310  orgapacheflinkruntimeionetworkapireaderabstractrecordreadergetnextrecordabstractrecordreaderjava75  orgapacheflinkruntimeionetworkapireadermutablerecordreadernextmutablerecordreaderjava34  orgapacheflinkruntimeoperatorsutilreaderiteratornextreaderiteratorjava59  orgapacheflinkruntimeoperatorsnoopdriverrunnoopdriverjava91  orgapacheflinkruntimeoperatorsregularpacttaskrunregularpacttaskjava496  orgapacheflinkruntimeoperatorsregularpacttaskinvokeregularpacttaskjava362  orgapacheflinkruntimeexecutionruntimeenvironmentrunruntimeenvironmentjava205  javalangthreadrunthreadjava745  code,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
1197,detect  tumbling  policy  trigger  eviction  match  windowing  api  automatically  detect  matching  trigger  eviction  policy  apply  optimization  tumbling  policy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1198,refactor  task  registrationunregistration  h4  current  control  flow  task  registration  jm  submits  taskdeploymentdescriptor  tm  tm  register  required  jar  file  librarycachemanager  return  user  code  class  loader  tm  creates  task  instance  register  task  runningtasks  map  tm  creates  taskinputsplitprovider  tm  creates  runtimeenvironment  set  environment  task  tm  register  task  network  environment  tm  sends  async  msg  profiler  monitor  task  tm  creates  temporary  file  file  cache  tm  try  start  task  operation  12  fails  tm  call  taskfailexternally  tm  remove  temporary  file  file  cache  tm  unregisters  task  network  environment  tm  sends  async  msg  profiler  unmonitor  task  tm  call  unregistermemorymanager  task  11  fails  unregister  librarycachemanager  h4  runtimeenvironment  task  taskmanager  separation  runtimeenvironment  reference  certain  component  task  manager  like  memory  manager  accecssed  task  furthermore  implement  runnable  creates  executing  task  thread  task  instance  essentially  wrap  runtimeenvironment  allows  asynchronous  state  management  task  running  finished  etc  way  state  update  affect  task  obvious  state  change  trigger  message  tm  final  state  trigger  msg  unregister  task  way  task  unregistered  depends  state  task  would  propose  refactor  make  way  state  handlingregistrationunregistration  handled  transparent,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
1199,change  split  createrun  vertexcentric  iteration  currently  vertexcentric  api  gelly  look  like  codejava  graph  inputgaph  create  graph  vertexcentriciteration  iteration  inputgraphcreatevertexcentriciteration  configure  iteration  graph  newgraph  inputgaphrunvertexcentriciterationiteration  code  createrun  split  order  expose  iteration  object  able  call  public  method  vertexcentriciteration  however  nice  might  lead  error  create  run  mistakenly  called  different  graph  object  one  suggestion  change  following  codejava  vertexcentriciteration  iteration  inputgraphcreatevertexcentriciteration  configure  iteration  graph  newgraph  iterationresult  code  go  single  run  call  add  iterationconfiguration  object  parameter  dont  expose  iteration  object  user  codejava  iterationconfiguration  parameter  graph  newgraph  inputgraphrunvertexcentriciterationparameters  code  also  simplified  method  configuration  passed  think  personally  like  second  option  bit  vasia,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1200,add  test  kafka  streaming  connector  add  test  flink  streaming  kafka  connector  using  integrated  kafka  zookeeper  server,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,1,1
1201,add  test  kafka  connector  current  kafkaitcase  single  test  need  refactor  test  brings  kafkazookeeper  server  performs  various  test  test  include  topology  nonstring  type  merged  359b39c3  topology  custom  kafka  partitioning  class  merged  359b39c3  topology  testing  regular  kafkasource  merged  359b39c3  kafka  broker  failure  merged  cb34e976  test  large  record  30  mb  merged  354922be  flink  taskmanager  failure,1,0,1,0,1,0,1,1,0,0,0,0,0,0,0,0,1
1202,add  support  submitting  single  job  detached  yarn  session  need  test  ensuring  processing  slot  set  properly  starting  flink  yarn  particular  per  job  yarn  session  feature  also  yarn  test  detached  yarn  session  per  job  yarn  cluster  polluting  local  homedirectory,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
1203,rename  function  name  getcurrentyactiveconnections  getcurrentactiveconnections  orgapacheflinkruntimeblob  think  function  name  getcurrentyactiveconnections  orgapacheflinkruntimeblob  wrong  spelling  getcurrentactiveconnections  better  also  add  comment  function  test,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1204,extend  table  api  allow  logical  plan  optimisation  right  plan  translated  dataset  datastream  program  could  modify  logical  query  plan  table  api  program  could  perform  optimisation  generating  program,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1205,add  type  hint  streaming  api  streaming  operator  currently  dont  support  type  hint  batch  api  return  method  functionality  essentially  provided  already  settype  method  replaced  modified  fully  provide  necessary  functionality,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1206,refactor  streaming  scala  api  use  return  adding  typeinfo  currently  streaming  scala  api  us  transform  pas  extracted  type  information  instead  return  lead  lot  code  duplication,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1207,split  submittask  method  two  phase  receive  tdd  instantiation  tdd  user  reported  job  time  submitting  task  taskmanager  reason  jobmanager  expects  taskoperationresult  response  upon  submitting  task  tm  tm  downloads  required  jar  jm  block  actor  thread  take  long  time  many  tm  download  jm  due  submittask  future  throw  timeoutexception  possible  solution  could  tm  eagerly  acknowledges  reception  submittask  message  executes  task  initialization  within  future  future  upon  completion  send  updatetaskexecutionstate  message  jm  switch  state  task  deploying  running  mean  handler  submittask  future  execution  wont  change  state  task,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1208,add  configuration  option  gellygsa  currently  possible  configure  gsa  iteration  similarly  vertexcentric  allow  setting  iteration  name  degree  parallelism  aggregator  broadcast  variable  whether  solution  set  kept  unmanaged  memory  doc  updated  accordingly,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,1,0
1209,make  python  test  le  verbose  currently  python  test  print  lot  log  message  stdout  furthermore  seems  println  statement  clutter  console  output  think  log  message  required  test  thus  suppressed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1210,task  failure  error  handling  issue  keep  track  subtasks  error  handling  task  failure  design  doc  found  httpscwikiapacheorgconfluencedisplayflinktaskfailuresanderrorhandling,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1211,introduce  eventtime  streaming  requires  introducing  timestamp  streaming  record  change  source  add  timestamps  record  also  introduce  punctuation  low  watermark  allow  window  work  correctly  unordered  timestamped  input  data  process  windowing  subsystem  also  need  adapted  use  punctuation  furthermore  operator  need  made  aware  punctuation  correctly  forward  new  operator  must  introduced  allow  modification  timestamps,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,1,1
1212,allowing  user  decorate  input  stream  user  may  unforeseeable  operation  file  input  stream  used  actual  input  format  logic  eg  exotic  compression  format  preamble  byte  order  mark  therefore  would  useful  provide  user  hook  decorate  input  stream  order  handle  issue,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
1213,integrate  flink  apache  mesos  user  asking  integration  flink  mesos  also  pending  pull  request  adding  mesos  support  flink  httpsgithubcomapacheflinkpull251  update  may  16  new  effort  underway  building  recent  resourcemanager  work  update  oct  16  core  functionality  master  branch  new  subtasks  track  remaining  work  first  release  design  document  google  dochttpsdocsgooglecomdocumentd1witafbmgbjlabbp8of5pafoh9gujqxf5s4hjeupchuuedituspsharing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1214,rework  example  use  parametertool  flink1525  introduced  parametertool  port  example  use  tool  example  could  look  like  maybe  discus  first  mailing  list  code  public  static  void  mainstring  args  throw  exception  parametertool  pt  parametertoolfromargsargs  boolean  fileoutput  ptgetnumberofparameters  2  string  textpath  null  string  outputpath  null  iffileoutput  textpath  ptgetrequiredinput  outputpath  ptgetrequiredoutput  set  execution  environment  final  executionenvironment  env  executionenvironmentgetexecutionenvironment  envgetconfigsetuserconfigpt  code,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
1215,add  outerjoin  strategy  hashtable  inner  side  flink  natively  support  outer  join  moment  issue  proposes  implement  hash  outer  join  algorithm  cover  left  right  outer  join  implementation  based  regular  hash  join  iterators  example  reusingbuildfirsthashmatchiterator  nonreusingbuildfirsthashmatchiterator  see  also  matchdriver  class  reusing  nonreusing  variant  differ  whether  object  instance  reused  new  object  created  would  start  nonreusing  variant  safer  user  point  view  also  easier  implement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
1216,string  delimiter  sockettextstream  sockettextstreamfunction  us  character  delimiter  despite  part  api  using  string  delimiter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1217,access  number  vertex  within  gsa  function  similarly  vertexcentric  approach  would  like  allow  user  access  number  vertex  gather  sum  apply  function  respectively  property  become  available  setting  setoptnumvertices  numvertices  option  true  number  vertex  accessed  gather  sum  apply  function  using  getnumberofvertices  method  option  set  configuration  method  return  1,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
1218,allow  gsa  gather  perform  operation  one  direction  time  vertex  gather  information  inedges  similarly  vertexcentric  approach  would  like  allow  user  gather  data  edge  well  property  set  using  setdirection  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1219,simplify  gelly  jaccard  similarity  example  gelly  jaccard  similarity  example  simplified  replacing  groupreduceonedges  method  simpler  reduceonedges,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1220,add  stateful  streaming  sequence  source  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1221,missplaced  class  flinkjava  sortpartitionoperator  class  sortpartitionoperator  flinkjava  api  facing  missplaced  go  operator  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1222,configure  number  vcores  currently  number  vcores  per  yarn  container  set  1  desirable  allow  configuring  value  simple  heuristic  make  sense  least  set  number  slot  per  container,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1223,fail  yarn  application  failed  singlejob  yarn  cluster  user  find  confusing  job  submitted  singlejob  yarn  cluster  mode  leave  flink  yarn  application  state  succeeded  job  fails,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1224,remove  reduceaggregation  datastream  currently  reduce  aggregation  method  nongrouped  datastreams  well  produce  local  aggregate  depending  parallelism  operator  behaviour  neither  intuitive  useful  produce  sensible  result  user  specifically  set  parallelism  1  encouraged  would  like  remove  method  datastream  api  keep  groupeddatastreams  windoweddatastream  aggregation  either  executed  perkey  perwindow,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
1225,make  grouped  reducefoldaggregations  stateful  using  partitioned  state  currently  inner  state  grouped  aggregation  persisted  operator  state  operator  reimplemented  use  newly  introduced  partitioned  state  abstraction  make  fault  tolerant  scalable  future  suggested  implementation  would  use  stateful  mapper  implement  desired  behaviour,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1226,add  named  attribute  access  storm  compatibility  layer  currently  bolt  running  flink  access  field  index  enabling  named  index  access  possible  whole  topology  tupletype  well  pojo  type  input  embedded  bolt,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1227,add  support  named  stream  storm  compatibility  layer  currently  layer  work  single  stream  ignores  stream  name  ie  stream  treated  default  stream  declaration  multiple  output  stream  ignored  tuples  emitted  stream  multiple  input  stream  consumed  tuples  merged  single  stream  feature  allows  operator  declare  multiple  named  output  stream  emit  tuples  different  stream  furthermore  enables  bolt  distinguish  incoming  tuples  different  stream  stream  name  storm  tuple  meta  information,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
1228,make  streaming  file  source  persistent  streaming  file  source  participate  checkpointing  track  byte  read  file  checkpoint  one  look  sequence  generating  source  function  example  checkpointed  source,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1229,rename  operatorstate  method  value  update  rename  operatorstate  method  value  update  getstate  updatestate  make  clear,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1230,rework  partitioned  state  storage  partitioned  state  currently  stored  perkey  statehandles  alright  inmemory  storage  inefficient  hdfs  logic  behind  current  mechanism  approach  provides  way  repartition  state  without  fetching  data  external  storage  manipulating  handle  come  solution  achieve,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1
1231,rework  iteration  construction  streamgraph  currently  node  representing  extra  sink  source  incrementally  added  streamgraph  user  creates  iterative  part  program  make  difficult  enforce  different  partitioning  scheme  feedback  edge  also  make  virtually  impossible  handle  iteration  head  different  parallelism  actual  node  streamgraph  iteration  sinkssources  created  program  finalized  user  call  execute  create  jobgraph,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
1232,new  jobmanager  runtime  web  frontend  need  improve  rework  job  manager  web  frontend  current  web  frontend  limited  lot  design  issue  display  progress  operator  running  especially  problematic  streaming  job  graph  representation  data  flow  allow  look  execution  attempt  hook  deal  upcoming  live  accumulator  architecture  modularextensible  propose  add  new  jobmanager  web  frontend  based  netty  http  lightweight  using  reststyle  url  job  vertex  integrating  d3  graph  renderer  preview  runtime  monitor  detail  execution  attempt  first  class  visualization  record  processed  byte  processed,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1233,implement  kafka  connector  using  new  kafka  consumer  api  kafka  released  new  consumer  api  provide  connector  version  release  probably  called  09  083  connector  mostly  compatible  kafka  082x  except  committing  offset  broker  new  connector  expects  coordinator  available  kafka  work  around  provide  configuration  option  commit  offset  zookeeper  managed  flink  code  09083  fully  compatible  compatible  081  mismatching  kafka  message,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1234,decouple  streamgraph  building  api  currently  building  streamgraph  intertwined  api  method  datastream  know  streamgraph  keep  track  splitting  selected  name  union  lead  problem  hard  understand  streamgraph  built  code  place  also  make  hard  extendchange  part  streaming  system  propose  introduce  transformation  transformation  hold  information  one  operation  input  stream  type  name  operator  api  method  creates  transformation  instead  fiddling  streamgraph  directly  new  component  streamgraphgenerator  creates  streamgraph  tree  transformation  result  program  specification  using  api  method  would  relieve  datastream  knowing  streamgraph  make  union  splitting  selection  visible  transformation  instead  scattered  across  different  api  class  field,1,0,1,0,1,0,1,1,1,0,1,0,0,0,0,1,1
1235,py  refactor  planbinderoperationinfo  two  class  deserve  restructuring  become  readable  consistent  pythonplanbinderpythonoperationinfo,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1
1236,cleanup  gelly  example  per  discussion  dev  mailing  list  issue  proposes  following  change  gelly  example  library  1  keep  following  example  euclideangraphweighing  graphmetrics  incrementalsssp  jaccardsimilarity  musicprofiles  2  keep  1  example  show  use  library  method  3  add  1  example  vertexcentric  iteration  4  keep  1  example  gsa  iteration  move  redundant  gsa  implementation  library  5  improve  example  documentation  refer  functionality  demonstrates  6  port  modify  existing  example  test  accordingly,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0
1237,expose  attemptnumber  runtimecontext  would  nice  expose  attemptnumber  task  runtimecontext  would  allow  user  code  behave  differently  restart  scenario,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
1238,rename  remaining  runtime  class  match  join  working  runtime  join  class  saw  many  still  refer  join  match  since  part  consistently  refer  join  adjust  runtime  class  well  make  easier  new  contributor,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1239,py  remove  need  specify  type  transformation  currently  user  python  api  provide  type  argument  using  udf  like  code  d1mapmapper  int  string  code  instead  would  really  convenient  able  code  d1mapmapper  code  intention  behind  issue  convenience  also  really  pythonic  specify  type  ill  go  possible  solution  let  summarize  way  type  argument  currently  used  general  type  handled  type  argument  passed  actually  object  type  represents  int  constant  int  value  whereas  string  constant  string  value  could  well  write  following  would  still  work  code  d1mapmapper  1  imnotatypinfo  code  object  transmitted  java  side  plan  binding  actual  tuple2integer  string  passed  type  extractor  resulting  typeinformation  saved  java  counterpart  udf  implement  resulttypequeryable  interface  typeinformation  object  used  java  api  python  never  touch  instead  runtime  serializers  used  python  java  check  class  value  passed  thus  generated  dynamically  mean  udf  pas  type  claim  pas  python  api  wont  complain  underlying  java  api  serializers  fail  let  talk  solution  discussion  mailing  list  pretty  much  2  proposal  made  add  way  disablecircumvent  type  check  plan  phase  java  api  generate  serializers  dynamically  object  always  serialized  form  java  side  stored  single  bytearray  tuple2  containing  keyvalue  pair  proposal  vary  wildly  change  necessary  system  change  java  api  support  proposal  would  hardly  change  way  python  api  work  even  touch  related  source  code  mostly  deal  java  api  since  im  familiar  plan  processing  lifecycle  java  side  cant  ass  class  would  changed  make  work  within  limit  java  api  exact  opposite  change  nothing  java  api  instead  following  issue  would  solved  alter  plan  extract  key  keyed  operation  hiding  key  udf  exactly  keyselectors  work  generally  solved  fact  solution  would  make  thing  easier  regard  keyselectors  rework  operation  currently  rely  java  api  function  need  deserialized  data  example  projection  upcoming  aggregation  generally  mean  implementing  python  special  java  udfs  could  deserialize  data  within  udf  call  work  serialized  data  change  deserializers  accordingly  implement  reliable  allmemoryconsuming  sorting  mechanism  python  side  personally  prefer  second  option  modify  java  api  work  within  welltested  limit  plan  change  similar  issue  already  worked  keyselectors  sorting  implementation  necessary  anyway  chained  reducer  data  serialized  form  performancerelated  consideration  already  first  option  could  work  likely  require  le  work  feel  like  many  thing  required  option  2  implemented  eventually  anyway,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,1,0
1240,add  retry  socketclientsink  found  socketclientsink  doesnt  use  reconnect  disconnect  socket  server  get  exception  id  like  add  reconnect  like  socket  source  socket  sink,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1241,flinktopologycontext  populated  completely  currently  flinktopologycontext  populated  completely  contains  enough  information  make  wordcount  example  work,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0
1242,csvreader  support  valuetypes  flink  programming  guide  section  data  source  quote  readcsvfilepath  csvinputformat  par  file  comma  another  char  delimited  field  return  dataset  tuples  pojos  support  basic  java  type  value  counterpart  field  type  quote  specifying  valuetype  ie  code  csvreader  csvreader  envreadcsvfilefilename  csvreadertypesintvalueclass  intvalueclass  code  following  error  occurs  basictypeinfo  specifically  requested  csvreadertypes  code  orgapacheflinkclientprogramprograminvocationexception  main  method  caused  error  orgapacheflinkclientprogrampackagedprogramcallmainmethodpackagedprogramjava452  orgapacheflinkclientprogrampackagedprograminvokeinteractivemodeforexecutionpackagedprogramjava353  orgapacheflinkclientprogramclientrunclientjava327  orgapacheflinkclientclifrontendexecuteprogramclifrontendjava608  orgapacheflinkclientclifrontendrunclifrontendjava296  orgapacheflinkclientclifrontendparseparametersclifrontendjava927  orgapacheflinkclientclifrontendmainclifrontendjava977  caused  javalangillegalargumentexception  type  position  0  basic  type  orgapacheflinkapijavatypeutilstupletypeinfogetbasictupletypeinfotupletypeinfojava177  orgapacheflinkapijavaiocsvreadertypescsvreaderjava393  drivermaindriverjava105  sunreflectnativemethodaccessorimplinvoke0native  method  sunreflectnativemethodaccessorimplinvokenativemethodaccessorimpljava62  sunreflectdelegatingmethodaccessorimplinvokedelegatingmethodaccessorimpljava43  javalangreflectmethodinvokemethodjava497  orgapacheflinkclientprogrampackagedprogramcallmainmethodpackagedprogramjava437  6  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1243,clean  streamrecord  watermark  type  streamrecords  watermark  returned  streaming  input  alternatingly  common  super  type  make  code  cleaner  allow  proper  generic  typing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1244,add  abstract  equal  hashcode  tostring  method  typeinformation  flink  expects  implementation  typeinformation  valid  implementation  hashcode  equal  however  api  enforce  implement  method  hence  common  origin  bug  example  flink2633  avoided  adding  abstract  hashcode  equal  method  typeinformation  abstract  tostring  method  could  also  added  change  brake  api  require  fix  couple  broken  typeinformation  implementation,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
1245,untangle  csvinputformat  pojotypecsvinputformat  tupletypecsvinputformat  csvinputformat  currently  allows  return  value  tuple  pojo  type  consequence  processing  logic  work  type  overly  complex  example  csvinputformat  contains  field  used  pojo  returned  moreover  pojo  field  information  constructed  calling  setter  method  called  specific  order  otherwise  fail  eg  one  first  call  setfieldtypes  calling  setorderofpojofields  otherwise  number  field  might  different  furthermore  method  called  return  type  pojo  type  expect  pojotypeinfo  present  think  csvinputformat  refactored  make  code  easily  maintainable  propose  split  pojotypecsvinputformat  tupletypecsvinputformat  take  required  information  via  constructor  instead  using  setfields  setorderofpojofields  approach,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0
1246,clean  naming  statecheckpoint  interface  add  name  cleanup  proposed  httpsgithubcomapacheflinkpull671  refer  internal  interface  implemented  stateful  task  checkpointed  consolidates  three  interface  one  stateful  task  need  implement  three  together  anyways,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1247,consolidate  netutils  currently  two  class  called  netutils  different  networking  related  helper  case  need  class  result  quite  clumsiness,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
1248,add  type  hint  typeextactor  call  hint  type  per  discussion  aljoscha  good  type  safe  way  supply  type  hint  would  following  define  hint  class  take  generic  parameter  code  public  abstract  class  typehintt  code  hint  would  following  method  code  public  datasett  returnstypehintt  hint  code  would  used  like  code  datasetsting  data  data  flatmap  string  str  collectorinteger  outcollectstrlength  return  new  typehintinteger  code  would  create  inline  subclass  hint  type  could  extracted  generic  would  ensure  typesafe,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1249,redirect  leading  jobmanager  web  fronted  nonstandalone  mode  case  nonstandalone  recovery  mode  job  manager  frontend  nonleading  job  manager  print  job  manager  information  associated  job  manager  job  manager  leading  nothing  show  web  frontend  cannot  directly  communicate  leading  job  manager  many  job  manager  structure  like  execution  graph  serializable  work  around  redirect  web  frontend  leading  job  manager  make  sure  interesting  information  presented,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1250,support  blocking  job  submission  job  manager  recovery  submitting  job  blocking  fashion  jobmanager  recovery  failing  jobmanager  fails  client  side  one  submitting  job  job  still  continues  recovered  propose  add  simple  support  reretrieve  leading  job  manager  update  client  actor  wait  result  current  standing  pr  1153  httpsgithubcomapacheflinkpull1153  job  manager  assumes  actor  running  keep  sending  execution  state  update  etc  listening  behaviour  detached,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1251,rework  extend  statehandleprovider  would  like  make  change  mostly  addition  statehandleprovider  ideally  upcoming  release  somewhat  part  public  api  rational  behind  handle  nice  extensible  way  creation  keyvalue  state  backed  various  implementation  f  distributed  kv  store  local  kv  store  f  backup  various  checkpointing  way  full  dump  append  incremental  key  change  would  concretely  1  default  statehandleprovider  set  execution  environment  function  later  specify  statehandleprovider  grabbing  streamoperatorstate  runtime  context  plus  optionally  checkpointer  2  streamoperatorstate  created  statehandleprovider  way  keyvaluestore  state  backend  create  streamoperatorstate  directly  update  data  kv  store  every  access  desired  filter  access  timestamps  show  committed  data  3  statehandleprovider  method  get  output  stream  writes  state  checkpoint  directly  return  statehandle  upon  closing  way  convert  dump  large  state  checkpoint  without  crating  full  copy  memory  lastly  would  like  change  name  statehandleprovider  either  statebackend  statestore  stateprovider  simpler  name  streamoperatorstate  either  state  kvstate,1,0,1,0,1,0,0,0,0,1,1,1,0,0,0,1,1
1252,remove  old  web  interface  default  new  one  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1253,gelly  api  improvement  flink  forward  gelly  school  training  got  really  valuable  feedback  participant  found  hard  grasp  nonintuitive  api  based  propose  make  following  improvement  rename  mapper  creation  method  vertexinitializer  purpose  easier  understand  add  fromtuple2dataset  method  easily  create  graph  tuple2  datasets  ie  edge  value  joinwith  method  hard  understand  parameter  mapper  output  suggest  flatten  try  give  intuitive  name  improve  javadocs  neighborhood  method  hard  understand  argument  edgefunctioniterateedges  reduceedgesfunctionreduceedges  javadocs  parameter  name  could  improved,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1254,add  outerjoin  strategy  hashtable  outer  side  outer  join  currently  supported  two  local  execution  strategy  sortmerge  join  hash  join  hash  table  built  inner  side  hence  strategy  supported  left  right  outer  join  order  support  hashtables  outer  side  need  special  hash  table  implementation  give  access  record  accessed  probe  phase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1255,create  database  state  backend  goal  create  database  state  backend  used  jdbc  supporting  database  backend  support  storage  nonpartitioned  state  also  storage  keyvalue  state  high  throughput  database  provide  advanced  querying  functionality  keyvalue  state  implemented  lazily  fetched  scale  arbitrary  state  size  storing  nonactive  keyvalues  heap  adapter  class  provided  help  bridge  gap  different  sql  implementation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1256,add  periodic  offset  commit  kafka  consumer  checkpointing  disabled  flink  writes  offset  consumer  zk  checkpointing  enabled  similar  feature  kafka  autocommit  consumer  issue  reported  user  httpstackoverflowcomquestions33501574flinkkafkawhyamilosingmessages,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1257,extend  window  operator  allow  efficient  fold  operation  right  window  fold  implemented  windowfunction  get  element  input  preaggregation  performed  window  operator  extended  also  allow  fold  also  preaggregated  requires  changing  signature  windowbuffer  emit  type  input  type,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1258,integrate  either  java  type  typeextractor  integrate  either  java  type  typeextractor  apis  recognize  type  choose  type  info  properly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1259,define  maximum  number  concurrent  inflight  checkpoint  checkpoint  coordinator  define  option  limit  maximum  number  current  inflight  checkpoint  well  checkpoint  timeouts,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
1260,py  remove  combiner  current  combiner  implementation  pythonapi  quite  mess  add  lot  unreadable  clutter  inefficient  time  straight  break  edge  case  revisit  feature  flink2501  resolved  several  change  issue  make  reimplementation  easier,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1261,make  applicationmasterjobmanager  akka  port  configurable  similar  blobserver  yarn  applicationmaster  allow  starting  specified  list  range  port  case  certain  port  allowed  firewall  user  specify  range  port  want  allocate  rpc  port,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1262,rename  either  creation  method  avoid  name  clash  projection  method  currently  method  signature  creating  either  value  eitherleftleft  projection  method  eitherleft  differ  parameter  make  awkward  use  lambda  eitherstreamfiltereitherisleftmapeitherleft  code  currently  impossible  suggest  change  creation  method  eithercreateleftleft  eithercreaterightright  also  directly  expose  left  right  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1263,allow  reading  multiple  topic  one  flinkkafkaconsumer  currently  kafka  consumer  allows  read  one  topic  case  multiple  topic  contain  message  schema  useful  allow  subscribe  many  topic  using  one  flinkkafkaconsumer  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1264,allow  setting  custom  startoffsets  kafka  consumer  currently  kafka  consumer  allows  start  reading  earliest  available  offset  current  offset  sometimes  user  want  set  specific  start  offset,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1265,drop  key  type  record  data  model  key  type  currently  still  used  recordcomparator  moved  test  scope  flinkruntime  range  partitioner  distribution  outdated  anyways  used  value  type  moved  normalizablekey,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1266,add  merging  windowassigner  add  possibility  windowassigners  merge  window  enable  session  windowing  support  similar  google  cloud  dataflow  support  session  window  element  would  initially  assigned  window  triggering  check  window  see  merged  way  element  overlapping  session  window  merge  one  session,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,0
1267,decouple  restart  strategy  executiongraph  currently  executiongraph  support  following  restart  logic  whenever  failure  occurs  number  restart  attempt  arent  depleted  wait  fixed  amount  time  try  restart  behaviour  controlled  configuration  parameter  executionretriesdefault  executionretriesdelay  propose  decouple  restart  logic  executiongraph  bit  introducing  strategy  pattern  way  would  allow  u  define  job  specific  restart  behaviour  also  implement  different  restart  strategy  conceivable  strategy  could  fixed  timeout  restart  exponential  backoff  restart  partial  topology  restarts  etc  change  preliminary  step  towards  restart  strategy  scale  parallelism  job  case  enough  slot  available,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1268,use  partitioned  state  abstraction  windowoperator  right  windowoperator  us  snapshotstate  restorestate  custom  serializationdeserialization  windowing  state  moving  partitioned  state  would  allow  u  rescale  future  also  partitioned  state  support  run  managedmemoryoutofcore  state  windowoperator  would  also  automatically  benefit  allowing  large  window  large  window  state  necessary  step  enhance  state  interface  new  primitive  state  reducablestate  liststate  etc  also  make  state  scoped  namespace  namespaces  necessary  need  state  scoped  key  window  window  would  namespace  case  enhance  timer  interface  also  make  timer  scoped  keynamespace  change  windowoperator  use  new  interface,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
1269,remove  unused  processingtime  eventtime  abstracttime  leftover  time  suffice  specifying  time,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1270,implement  datasetcount  using  single  operator  datasetcount  currently  implemented  using  flatmapfunction  followed  discardingoutputformat  noted  stephanewen  flink2716  done  richoutputformat  change  also  applicable  datasetcollect  utilscollecthelper,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1271,add  option  eagerly  deploy  channel  intermediate  partition  consumed  via  input  channel  channel  instantiated  lazily  partition  producer  emits  first  record  lead  higher  latency  first  record  passing  pipeline  order  decrease  latency  deploy  channel  eagerly  would  like  add  flag  intermediate  result  execution  graph  deployment  task  deploy  input  channel  soon  intermediate  stream  registered  partition  manager,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1272,add  example  reading  writing  kafka  kafka  connector  flink  used  streaming  connector  would  like  add  two  example  showing  read  write  data  kafka  topic,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1273,py  generalize  operationinfo  transfer  set  number  argument  transferred  whenever  user  defines  operation  csv  source  example  delimitersfilepath  map  function  set  id  transferred  operator  separate  routine  defined  governs  argument  transferred  working  flink3275  realized  adding  new  argumentparameter  case  parallelism  straightforward  could  newly  added  operator  require  new  routine  whereas  adding  new  argument  may  require  modification  multiple  routine  time  bound  become  big  mess  argument  stored  operationinfo  object  also  contains  default  value  unused  argument  want  generalize  whole  affair  transferring  argument  used  reduce  clutter  make  easier  add  new  parameter  4  new  line  needed  2  defining  new  field  inside  javapython  operationinfo  class  1  sendingreceiving  new  argument  make  transfer  consistent  across  operation,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1274,auto  type  registration  kryo  buggy  auto  type  registration  relies  static  hash  set  deduplicate  class  type  mean  repeated  run  certain  class  registered,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1275,fix  slot  sharing  streaming  api  right  slot  sharingresource  group  logic  bit  nebulous  slot  sharing  group  operator  put  depends  order  operation  created  example  case  code  source  envsource  source  b  envsource  amapstartnewresourcegroupsink  bmapsink  code  end  two  resource  group  group  1  source  group  2  map  sink  source  b  map  sink  reason  slot  sharing  id  incremented  transforming  startnewresoucegroup  call  operator  transformed  afterwards  graph  traversal  get  new  slot  sharing  id  also  isolateresources  used  isolate  operator  propose  remove  startnewresourcegroup  isolateresouces  replace  slotsharinggroupstring  default  operation  would  slot  sharing  group  default  allows  fine  grained  control  operator  end  slot  sharing  group  example  could  topology  code  source  envsourceslotsharinggroupsources  source  b  envsourceslotsharinggroupsources  amapslotsharinggroupheavy  asinkslotsharinggroupsinks  bmapslotsharinggroupheavy  bsinkslotsharinggroupsinks  code  would  isolate  lightweight  source  sink  group  put  heavy  operation  inside  slot  group  bit  low  level  previous  api  requires  call  simple  startnewresourcegroup  think  many  people  would  use  feature  design  make  clear  operation  end  group,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1276,add  timeout  handler  cep  operator  currently  event  sequence  exceed  defined  pattern  timeout  discarded  however  case  user  might  interested  getting  know  timeout  occurred  return  default  value  event  sequence  thus  pattern  api  extended  able  define  timeout  handler  furthermore  nfa  extended  also  return  discarded  event  sequence  cepoperator  would  call  every  discarded  event  sequence  timeout  handler,1,1,0,0,0,1,0,0,0,1,0,1,1,0,1,0,0
1277,provide  exactlyonce  cassandra  connector  flink3311  adding  cassandra  connector  flink  would  good  also  provide  exactlyonce  c  connector  would  like  first  discus  going  implement  flink,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
1278,create  constructor  fsstatebackend  rocksdbbackens  think  user  understands  supposed  define  backing  state  backend  common  thing  probably  rocksdb  snapshot  backed  hdfs  also  backing  state  backend  simple  constructor  single  uripathstring  configures  time  added  make  accessible  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1279,refactor  timestampextractor  based  lot  user  feedback  current  timestampextractor  seems  confusing  implement  simultaneously  two  mode  generating  watermark  record  pass  decide  cause  watermark  timestamp  extractor  define  certain  watermark  timestamp  periodically  picked  system  trigger  watermark  larger  previous  watermark  figuring  mode  interplay  define  method  use  one  mode  quite  obstacle  several  user  break  class  two  different  class  one  per  mode  generating  watermark  make  easier  understand,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1
1280,kafka  consumer  properly  respecting  autooffsetreset  behavior  currently  data  kafka  topic  expires  reading  cause  unrecoverable  failure  subsequent  retries  also  fail  invalid  offset  might  desired  behaviour  circumstance  would  probably  better  case  automatically  jump  earliest  valid  offset  case,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1281,flink  kafka  consumer  support  autocommit  optouts  currently  kafka  source  commit  consumer  offset  zookeeper  either  upon  checkpoint  checkpointing  enabled  otherwise  periodically  based  autocommitintervalms  possible  optout  committing  consumer  offset  zookeeper  kafka  config  autocommitenable  08  enableautocommit  09,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1282,scramble  hashpartitioner  hash  hashpartitioner  used  streaming  api  apply  hash  scrambling  bad  user  hash  function  apply  murmor  jenkins  hash  top  hash  code  similar  dataset  api,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1283,add  fixed  time  trailing  timestampwatermark  extractor  flink  currently  provides  one  buildin  timestamp  extractor  assumes  strictly  ascending  timestamps  real  world  use  case  timestamps  almost  never  strictly  ascending  therefore  propose  provide  utility  watermark  extractor  generating  watermark  fixedtime  trailing  implementation  keep  track  highest  eventtime  seen  far  subtract  fixed  amount  time  event  time  way  user  example  specify  watermark  always  lag  behind  10  minute,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0
1284,change  interplay  ingestion  time  event  time  currently  eventtime  ingestiontime  completely  happens  following  source  generate  ingestion  time  timestamps  watermark  user  add  manual  timestamp  extractor  watermark  generator  override  ingestion  time  timestamps  watermark  implies  event  time  certain  input  fall  back  ingestion  time  one  forgets  incorrectly  us  timestamp  extractor  also  ingestion  time  event  time  simply  mix  input  timestamp  assigners  others  behavior  quite  tricky  understand  discussion  aljoscha  rmetzger  suggest  change  following  way  1  ingestion  time  timestamps  watermark  generated  2  event  time  default  timestamps  watermark  generated  user  implement  timestamp  extractor  watermark  generator  event  time  operation  fail  fast  3  one  want  use  ingestion  time  event  time  setting  mix  one  use  explicit  wallclocktimetampsandwatermark  generator  4  later  ingestion  time  setting  automatically  disable  userdefined  timestamp  extractor  assigners,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0
1285,bump  kafka  09  connector  dependency  kafka  0901  kafka  project  released  0901  version  saw  issue  integration  test  developing  code  hope  upgraded  version  improve  stability,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1286,add  sbt  build  tool  description  quickstart  documentation  add  documentation  sbt  quickstart  template  quickstart  documentation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1287,add  incremental  fold  nonkeyed  window  operator  right  nonkeyed  fold  constant  space  requirement,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1288,make  clearer  distinction  event  time  processing  time  define  window  easy  mix  time  characteristic  wrong  set  predefined  windowassigners  cannot  use  processing  time  tumblingtimewindows  window  assigner  example  neither  name  tumblingtimewindows  javadocs  clearly  obvious  windowassigner  used  event  time  think  would  better  rename  event  time  window  assigner  something  like  tumblingeventtimewindows  additionally  could  extend  javadocs  bit  since  everyone  know  based  timestamps  mean  based  event  time,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
1289,replace  random  nic  selection  heuristic  inetaddressgetlocalhost  currently  connectionutilsfindaddressusingstrategy  method  return  first  networkinterface  whose  address  loop  back  address  link  local  address  inet4address  returning  address  retried  connect  jobmanager  using  inetaddressgetlocalhost  address  last  time  heuristic  choosing  inetaddressgetlocalhost  often  make  sense  return  random  networkinterface  address  would  better  simply  return  inetaddressgetlocalhost  instead,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1290,reenable  table  api  explain  table  api  explain  temporarily  disabled  port  table  api  top  calcite  reenabled  merge  change  back  master  branch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1291,change  rollingsink  writer  interface  allow  wider  range  output  currently  rollingsink  writer  interface  work  fsdataoutputstreams  precludes  used  existing  library  like  apache  orc  parquet  fix  new  writer  interface  created  receives  filesystem  path  object  instead  fsdataoutputstream  ensure  exactlyonce  semantics  writer  interface  must  also  extended  current  writeoffset  retrieved  checkpointing  time  format  like  orc  requires  footer  written  offset  returned  checkpointing  already  call  flush  writer  either  flush  need  return  current  length  output  file  alternatively  new  method  added  existing  writer  interface  recreated  wrapper  top  new  writer  interface  existing  code  manages  fsdataoutputstream  moved  new  wrapper,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1292,rework  table  api  test  flinktable  component  consists  several  apis  scalaembedded  table  api  stringbased  table  api  java  sql  compiles  two  execution  backends  datastream  api  dataset  api  many  different  translation  path  involved  query  executed  table  api  string  table  api  logical  plan  table  api  scalaexpressions  table  api  logical  plan  table  api  logical  plan  calcite  relnode  plan  sql  calcite  relnode  plan  done  exclusively  via  calcite  calcite  relnodes  dataset  relnodes  dataset  relnodes  dataset  program  calcite  relnodes  datastream  relnodes  datastream  relnodes  datastream  program  calcite  rexnode  expression  generated  code  need  thoroughly  tested  initially  many  test  done  endtoend  integration  test  high  overhead  however  due  combination  apis  execution  backends  approach  cause  many  redundant  test  long  build  time  therefore  propose  following  testing  scheme  1  table  api  string  table  api  expression  stringbased  table  api  tested  comparing  resulting  logical  plan  tablelogicalplan  logical  plan  equivalent  table  program  us  scalaembedded  syntax  logical  plan  table  api  internal  representation  later  converted  calcite  relnode  plan  existing  integration  test  check  java  table  api  ported  unit  test  also  duplicated  test  java  table  api  tested  batch  streaming  necessary  anymore  2  table  api  scalaexpressions  table  api  logical  plan  calcite  relnodes  dataset  relnodes  datastream  relnodes  test  cover  translation  optimization  table  api  query  verify  calcite  optimized  plan  need  distinct  test  dataset  datastream  environment  since  feature  translation  rule  vary  test  also  identify  added  modified  rule  cost  function  result  different  plan  main  test  table  api  extensive  test  implemented  extending  tabletestbase  base  class  unit  test  hence  lightweight  3  sql  calcite  relnodes  dataset  relnodes  datastream  relnodes  test  described  2  table  api  scalaexpressions  dataset  datastream  relnodes  sql  4  dataset  relnode  dataset  program  unfortunately  dataset  api  lack  good  mechanism  test  generated  program  ie  get  plan  traversable  operator  access  userdefined  function  testing  utility  available  propose  test  translation  dataset  program  endtoend  integration  test  however  think  run  test  collection  executionenvironment  start  flink  cluster  run  code  java  collection  make  test  much  lightweight  clusterbased  itcases  goal  test  cover  translation  path  datasetrel  dataset  program  ie  datasetrel  node  translation  logic  test  implemented  extending  tableprogramscollectiontestbase  see  flink5268  moreover  clusterbased  itcases  place  check  execution  path  actual  operator  serializers  comparators  however  limit  test  minimum  keep  build  time  low  test  implemented  extending  tableprogramsclustertestbase  flink5268  located  class  avoid  repeated  instantiation  flink  minicluster  5  datastream  relnode  datastream  program  basically  applies  dataset  program  im  aware  good  way  test  generated  datastream  program  without  executing  testing  utility  would  great  library  built  top  api  propose  use  endtoend  integration  test  unfortunately  datastream  api  feature  collection  execution  mode  test  need  run  minicluster  therefore  keep  test  minimum  test  implemented  extending  streamingmultipleprogramstestbase  located  class  avoid  repeated  instantiation  flink  minicluster  6  scala  expression  stringparsed  expression  sql  expression  rexnode  expression  generated  code  order  avoid  extensive  optimization  test  supported  expression  builtin  function  expressiontestbase  compiles  expression  generated  code  test  correctness  result  supported  expression  builtin  function  tested  extending  expressiontestbase  instead  running  full  integration  test  add  jiras  migrate  existing  test  new  testing  scheme,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
1293,change  access  datasetutilscountelements  public  access  datasetutilscountelements  presently  private  change  public  happened  replicating  functionality  project  realized  method  already  existed  flink,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1294,allow  flinkkafkaproducer  send  data  multiple  topic  currently  flinkkafkaproducer  sending  event  one  topic  defined  creating  producer  could  allow  user  send  message  multiple  topic  extending  keyedserializationschema  method  public  string  gettargettopict  element  override  default  topic  return  value  null,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1295,remove  nephele  reference  still  exist  reference  nephele  removed  code  flinkdocssetuplocalsetupmd  79  tail  logflinkjobmanagerlog  80  info  initializing  memory  manager  409  megabyte  memory  81  info  trying  load  orgapacheflinknephelejobmanagerschedulerlocallocalscheduler  scheduler  82  info  setting  web  info  server  using  webroot  directory  83  info  web  info  server  display  information  nephele  jobmanager  localhost  port  8081  84  info  starting  web  info  server  jobmanager  port  8081  85  118  cd  flink  119  binstartlocalsh  120  starting  nephele  job  manager  121  code  code  flinkflinkruntimesrcmainjavaorgapacheflinkruntimeoperatorstaskcontextjava  70  abstractinvokable  getowningnepheletask  code  code  flinkflinkruntimesrcmainjavaorgapacheflinkruntimeoperatorsbatchtaskjava  1149  param  message  main  message  log  1150  param  taskname  name  task  1151  param  parent  nephele  task  contains  code  producing  message  1152  1153  return  string  logging  1254  1255  suppresswarningsunchecked  1256  public  static  collectort  initoutputsabstractinvokable  nepheletask  classloader  cl  taskconfig  config  1257  listchaineddriver  chainedtaskstarget  1258  listrecordwriter  eventualoutputs  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1296,generalize  clientcluster  communication  note  took  inspecting  clientcluster  class  regard  future  integration  resource  management  framework  addition  yarn  eg  mesos  noformat  1  cluster  client  abstraction  â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90â•\x90  11  status  quo  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  111  flinkyarnclient  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  hold  cluster  configuration  flinkspecific  yarnspecific  â€¢  contains  deploy  method  deploy  cluster  â€¢  creates  hadoop  yarn  client  â€¢  receives  initial  job  manager  address  â€¢  bootstrap  flinkyarncluster  112  flinkyarncluster  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  wrapper  around  hadoop  yarn  client  â€¢  query  cluster  status  update  â€¢  life  time  method  start  shutdown  cluster  â€¢  flink  specific  feature  like  shutdown  job  completion  113  applicationclient  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  act  middleman  asynchronous  cluster  communication  â€¢  designed  communicate  yarn  used  standalone  mode  114  clifrontend  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  deeply  integrated  flinkyarnclient  flinkyarncluster  â€¢  constantly  distinguishes  yarn  standalone  mode  â€¢  would  nice  general  abstraction  place  115  client  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  job  submission  job  related  action  agnostic  resource  framework  12  proposal  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  121  clusterconfig  abstractflinkyarnclient  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  extensible  clusteragnostic  config  â€¢  may  extended  specific  cluster  eg  yarnclusterconfig  122  clusterclient  abstractflinkyarnclient  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  deal  cluster  rm  specific  communication  â€¢  expose  framework  agnostic  information  â€¢  yarnclusterclient  mesosclusterclient  standaloneclusterclient  123  flinkcluster  abstractflinkyarncluster  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  basic  interface  communicate  running  cluster  â€¢  receives  clusterclient  clusterspecific  communication  â€¢  care  specific  implementation  client  124  applicationclient  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  changed  work  clusteragnostic  first  step  already  flink3543  125  clifrontend  â•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œâ•œ  â€¢  clifrontend  never  differentiate  different  cluster  type  determined  cluster  class  load  â€¢  base  class  handle  framework  agnostic  command  line  argument  â€¢  pluggables  yarn  mesos  handle  specific  command  noformat  would  like  createrefactor  affected  class  set  u  flexible  client  side  resource  management  abstraction,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1297,add  interface  time  aware  user  function  suggest  add  interface  udfs  implement  let  notified  upon  watermark  update  example  usage  code  public  interface  eventtimefunction  void  onwatermarkwatermark  watermark  public  class  mymapper  implement  mapfunctionstring  string  eventtimefunction  private  long  currenteventtime  longminvalue  public  string  mapstring  value  return  value  currenteventtime  public  void  onwatermarkwatermark  watermark  currenteventtime  watermarkgettimestamp  code,1,0,1,0,1,0,0,0,1,0,1,1,1,0,0,1,1
1298,replace  guava  precondition  class  flink  precondition  order  reduce  dependency  guava  cause  u  quite  bit  pain  past  version  conflict  suggest  add  flink  precondition  class,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
1299,datastream  api  pojofieldaccessor  doesnt  support  nested  pojos  pojofieldaccessor  used  sumstring  similar  method  doesnt  support  nested  pojos  right  part  flink3697  ill  add  check  nested  pojo  fail  exception,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,0
1300,scala  api  cep  currently  cep  library  support  scala  case  class  typeextractor  cannot  handle  order  support  would  necessary  offer  scala  api  cep  library,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1301,consolidate  timestampassigner  method  kafka  consumer  datastream  method  setting  timestampassignerwatermarkemitter  called  assigntimestampsandwatermarks  flinkkafkaconsumer  called  setpunctuatedwatermarkemitter  setperiodicwatermarkemitter  think  name  matched  also  name  setwatermarkemitter  hint  fact  assigner  primarily  assigns  timestamps,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1302,introduce  key  group  keyvalue  state  support  dynamic  scaling  order  support  dynamic  scaling  necessary  subpartition  keyvalue  state  operator  subpartitioning  produce  set  key  group  allows  easily  scale  flink  job  simply  reassigning  different  key  group  new  set  sub  task  idea  key  group  described  design  document  1  1  httpsdocsgooglecomdocumentd1g1os1z3xeboryd4wsulubcypuwyfd9l3t9wyssq63wedituspsharing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1303,rabbitmq  sourcesink  standardize  connection  parameter  rabbitmq  source  sink  capability  term  establishing  connection  currently  sink  lacking  connection  parameter  available  source  additionally  virtualhost  offered  parameter  multitenant  rabbitmq  cluster  specified  go  vhost  connection  parameter  host  offered  port  source  virtual  host  neither  user  source  password  source  additionally  might  worth  offer  uri  valid  constructor  would  offer  5  parameter  single  string,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0
1304,add  kafka  tablesink  json  serialization  add  tablesink  writes  json  serialized  data  kafka,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1305,native  implementation  hit  algorithm  hyperlinkinduced  topic  search  hit  also  hub  authority  presented  0  described  1  hit  popular  effective  algorithm  rank  document  based  link  information  among  set  document  algorithm  presumes  good  hub  document  point  many  others  good  authority  document  many  document  point  httpspdfssemanticscholarorga8d7c7a4c53a9102c4239356f9072ec62ca5e62fpdf  implementation  differs  flink2044  providing  convergence  outputting  hub  authority  score  completing  half  number  iteration  0  httpwwwcscornelleduhomekleinberauthpdf  1  httpsenwikipediaorgwikihitsalgorithm,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1306,globalconfiguration  doesnt  ensure  config  loaded  default  globalconfiguration  return  empty  configuration  instead  call  get  fail  config  hasnt  loaded  explicitly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1307,directed  clustering  coefficient  directed  clustering  coefficient  algorithm  implemented  using  efficient  triangle  listing  implementation  emits  three  vertex  id  forming  triangle  also  bitmask  indicating  edge  form  triangle  triangle  formed  minimum  three  maximum  six  directed  edge  directed  clustering  coefficient  shatter  triangle  emit  score  either  1  2  vertex,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,1,1
1308,support  kerberos  authentication  keytab  credential  issue  part  series  improvement  detailed  secure  data  accesshttpsdocsgooglecomdocumentd1gqb6uvoyoaxgwtqwqlv8bhdxwimo2wnvzboj8opaasedituspsharing  design  doc  add  support  keytab  credential  associated  flink  cluster  facilitate  kerberosauthenticated  data  access  connector  kerberosauthenticated  zookeeper  access  support  standalone  yarn  deployment  mode,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1309,make  flink  cli  list  savepoint  cancel  stop  work  flinkonyarn  cluster  currently  flink  cli  cant  figure  jobmanager  rpc  location  flinkonyarn  cluster  therefore  list  savepoint  cancel  stop  subcommands  hard  invoke  know  yarn  application  id  improvement  suggest  adding  yid  yarnapplicationid  option  mentioned  subcommands  used  together  yarncluster  flink  cli  would  retrieve  jobmanager  rpc  location  yarn  resourcemanager,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
1310,add  possiblity  rmq  streaming  source  customize  queue  patch  add  possibilty  user  rabbitmq  streaming  connector  customize  queue  used  usecases  want  set  custom  parameter  queue  ie  ttl  message  flink  reboots  possibility  bind  queue  exchange  afterwards  commit  doesnt  change  actual  behaviour  make  possible  user  override  newly  create  setupqueue  method  cutomize  implementation  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1311,add  version  header  savepoints  adding  header  version  information  savepoints  ensures  migrate  savepoints  flink  version  future  example  changing  internal  serialization  format  version  talking  till  propose  add  following  meta  data  magic  number  int  identify  data  savepoint  version  int  savepoint  version  independent  flink  version  data  offset  int  specifies  point  actual  savepoint  data  start  allow  future  flink  version  add  field  header  without  breaking  stuff  eg  flink  11  could  read  savepoints  flink  20  flink  10  savepoint  support  try  reading  savepoints  without  header  failing  dont  find  magic  number,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,1
1312,expose  metric  interface  0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
1313,change  name  ternary  condition  operator  eval  ternary  condition  operator  table  api  named  eval  example  42  5evala  b  lead  imo  eval  function  well  understood  instead  better  choice  think  used  java  condition  operator  clearer  literal  understood  eg  42  5a  b  42  5  b  make  sense  pull  request,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1314,configurable  delimiter  metric  identifier  metric  identifier  currently  hardcoded  separate  component  dot  make  configurable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1315,remove  config  prefix  kinesisconfigconstants  variable  find  static  variable  name  verbose  think  clear  context  refer  kinesis  configuration  since  gathered  class  therefore  would  like  remove  config  prefix  release  code  confputkinesisconfigconstantsawsregion  code  instead  code  confputkinesisconfigconstantsconfigawsregion  code  longer  variable  becomes  even  longer  otherwise  basic  variable  name  might  accessed  frequently  also  long  code  configawscredentialsproviderbasicsecretkey  configawscredentialsproviderbasicaccesskeyid  code  might  suffice  code  awssecretkey  awsaccesskey  code,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1
1316,create  batch  sql  example  currently  runnable  code  example  flinktable  showing  working  batch  sql  query  table  api  scala  java  example  added,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1317,expose  kafka  metric  flink  metric  currently  expose  kafka  metric  flinks  accumulator  use  metric  system  flink  report  kafka  metric,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1
1318,move  metric  api  separate  module  metric  code  currently  resides  flinkcore  user  implement  reporter  want  fat  jar  include  entire  flinkcore  module  instead  could  move  several  interface  separate  module  interface  move  include  counter  gauge  histogramstatistics  metricgroup  metricreporter  scheduled  abstractreporter  addition  new  metricregistry  interface  required  well  replacement  configuration,0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,0,1
1319,start  metric  reporter  default  default  start  jmx  reported  bind  port  come  extra  thread  start  reported  default  keep  overhead  minimum,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1320,metric  naming  improvement  metric  currently  two  part  name  particular  metric  scope  namespace  defined  group  contains  metric  metric  group  actually  always  implicitly  map  naming  tag  like  taskmanagerhost  somehostname  taskmanagerid  id  taskname  map  filter  derive  scope  map  following  defined  scope  format  jmx  user  use  jmx  would  natural  expose  map  tag  user  reconstruct  map  parsing  metric  scope  jmx  expose  metric  like  domain  taskmanagertaskoperatorio  name  numrecordsin  tag  hostname  localhost  operatorname  map  xjava123  many  reporter  formatted  scope  make  lot  sense  since  think  term  scope  metricname  may  even  formatted  scope  jmx  well  domain  want  go  route  jgrier  zentol  think  mdaxini  match  use  metric,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1321,allow  specifying  multiple  metric  reporter  allow  specifying  multiple  reporter  rough  sketch  configuration  look  like  code  metricsreporters  foobar  metricsreporterfooclass  jmxreporterclass  metricsreporterfooport  42117  metricsreporterbarclass  gangliareporterclass  metricsreporterbarport  512  metricsreporterbarwhatever  2  code,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
1322,csvtablesource  support  reading  sqltimetypeinfo  type  table  apis  csvtablesource  support  read  table  api  supported  data  type  example  possible  read  sqltimetypeinfo  type  via  csvtablesource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1323,add  possiblity  rmq  streaming  sink  customize  queue  patch  add  possibilty  user  rabbitmq  streaming  sink  customize  queue  used  adopts  behavior  flink4025  sink  commit  doesnt  change  actual  behaviour  make  possible  user  override  setupqueue  method  customize  implementation  possible  rmqsource  sink  source  offer  functionality  increase  usability  flink4025  httpsissuesapacheorgjirabrowseflink4025,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1324,rename  recoverymode  config  key  highavailability  currently  ha  configured  via  following  configuration  key  code  recoverymode  standalone  high  availability  ha  recoverymode  zookeeper  ha  code  could  straight  forward  simply  renaming  key  highavailability  furthermore  term  standalone  overloaded  already  standalone  cluster  mode  code  highavailability  none  ha  highavailability  zookeeper  ha  via  zookeeper  code  recoverymode  configuration  key  would  deprecated  completely  removing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1325,new  flinkspecific  option  set  starting  position  kafka  consumer  without  respecting  external  offset  zk  broker  currently  start  reading  earliest  latest  position  topic  flink  kafka  consumer  user  set  kafka  config  autooffsetreset  provided  property  configuration  however  way  config  actually  work  might  bit  misleading  user  trying  find  way  read  topic  starting  position  way  autooffsetreset  config  work  flink  kafka  consumer  resembles  kafka  original  intent  setting  first  existing  external  offset  committed  zk  broker  checked  none  exists  autooffsetreset  respected  propose  add  flinkspecific  way  define  starting  position  without  taking  account  external  offset  original  behaviour  reference  external  offset  first  changed  user  option  behaviour  retained  frequent  kafka  user  may  need  collaboration  existing  nonflink  kafka  consumer  application  user  interact  flink  kafka  consumer  added  newly  introduced  flinkstartingposition  config  code  property  prop  new  property  propssetpropertyflinkstartingposition  earliestlatest  propssetpropertyautooffsetreset  ignored  log  warning  propssetpropertygroupid  wont  effect  starting  position  anymore  may  still  used  external  offset  committing  code  reference  external  offset  zk  broker  code  property  prop  new  property  propssetpropertyflinkstartingposition  externaloffsets  propssetpropertyautooffsetreset  earliestlatest  default  latest  propssetpropertygroupid  used  lookup  external  offset  zk  broker  startup  code  thing  would  need  decide  would  default  value  flinkstartingposition  two  merit  see  adding  1  compensates  way  user  generally  interpret  read  starting  position  flink  kafka  connector  somewhat  essentially  highlevel  kafka  consumer  flink  user  think  reasonable  add  flinkspecific  functionality  user  find  useful  although  wasnt  supported  kafka  original  consumer  design  2  adding  idea  kafka  offset  store  zk  broker  used  expose  progress  outside  world  used  manipulate  kafka  topic  read  flink  unless  user  opt  even  definite  solid  discussion  pr  httpsgithubcomapacheflinkpull1690  flink3398  aspect  think  adding  decouples  flinks  internal  offset  checkpointing  external  kafka  offset  store,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1326,add  offset  parameter  windowassigners  currently  window  always  aligned  epoch  basically  mean  day  aligned  gmt  somewhat  problematic  people  living  different  timezones  offset  parameter  would  allow  adapt  window  assigner  timezone,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1327,allow  uploaded  jar  directory  configurable  notice  sometimes  preferable  uploaded  jar  put  configurable  directory  location  instead  runtime  case  preload  directory  jar  docker  image  allows  u  leverage  jobmanager  restful  interface  startkill  job  webruntimemonitorjava  string  uploaddirname  flinkwebupload  uuidrandomuuid  thisuploaddir  new  filegetbasedirconfig  uploaddirname,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1328,unify  checkpointcoordinator  savepointcoordinator  checkpoint  coordinator  functionality  handling  checkpoint  savepoints  difference  checkpoint  savepoints  minimal  savepoints  always  write  root  metadata  checkpoint  savepoints  always  full  never  incremental  commonality  large  job  able  resume  checkpoint  savepoints  job  fall  back  latest  checkpoint  savepoint  subsumes  issue  httpsissuesapacheorgjirabrowseflink3397,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1329,enable  rollingsink  custom  hdfs  client  configuration  optimizing  configuration  hdfs  client  different  situation  iofilebuffersize  make  rolling  sink  perform  better,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1330,provide  support  asynchronous  operation  stream  many  flink  user  need  asynchronous  processing  driven  data  datastream  classic  example  would  joining  external  database  order  enrich  stream  extra  information  would  nice  add  general  support  type  operation  flink  api  ideally  could  simply  take  form  new  operator  manages  async  operation  keep  many  flight  emits  result  downstream  operator  async  operation  complete,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
1331,replace  actorgateways  networkenvironment  interface  networkenvironment  communicates  outside  world  taskmanager  jobmanager  via  actorgateways  bakes  dependency  actor  term  modularization  improved  abstraction  especially  wrt  flip6  propose  replace  actorgateways  interface  expose  required  method  current  implementation  would  simply  wrap  method  call  message  send  via  actorgateway  recipient  flip6  jobmaster  taskexecutor  could  simply  implement  interface  part  rpc  contract,0,0,0,0,0,0,1,1,0,0,1,0,0,0,0,0,0
1332,replace  actorgateway  task  interface  task  communicates  outside  world  jobmanager  taskmanager  via  actorgateways  bakes  dependency  actor  term  modularization  improved  abstraction  especially  wrt  flip6  propose  replace  actorgateways  interface  expose  required  method  current  implementation  would  simply  wrap  method  call  message  send  via  actorgateway  recipient  flip6  jobmaster  could  simply  implement  interface  part  rpc  contract,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1333,make  executiongraph  independent  akka  currently  executiongraph  strongly  depends  akka  requires  actorsystem  create  checkpointcoordinatordeactivator  furthermore  allows  actorgateways  register  job  status  execution  update  order  improve  modularization  abstraction  propose  introduce  proper  listener  interface  would  also  allow  get  rid  checkpointcoordinatordeactivator  simply  implementing  interface  furthermore  pave  way  upcoming  flip6  refactoring  offer  better  abstraction,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1334,remove  forkableflinkminicluster  addressing  flink4424  able  get  rid  forkableflinkminicluster  since  longer  predetermine  port  flink  thus  setting  port  0  letting  o  choose  free  port  longer  conflicting  port  request  consequently  forkableflinkminicluster  become  obsolete,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1335,introduce  slotprovider  scheduler  currently  scheduler  maintains  queue  available  instance  scan  need  new  slot  find  suitable  instance  free  slot  available  allocate  slot  slot  allocation  logic  factored  made  available  via  slotprovider  interface  slotprovider  method  allocate  slot  given  set  location  preference  slot  returned  future  future  slot  allocation  might  happen  asynchronously  flip6  first  version  slotprovider  implementation  simply  encapsulate  existing  slot  allocation  logic  extracted  scheduler  slot  requested  return  completed  failed  future  since  allocation  happens  synchronously  refactoring  advantage  simplify  scheduler  class  pave  way  upcoming  refactorings  flip6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1336,move  jobmaster  taskexecutor  resourcemanager  rpc  package  currently  flip6  branch  still  contains  taskexecutor  jobmaster  resourcemanager  rpc  package  removed  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1337,generalize  taskexecutortoresourcemanagerconnection  reusable  taskexecutortoresourcemanagerconnection  generalized  reusable  across  component  example  jobmaster  requires  similar  connection  assume  jobmaster  run  independently  resourcemanager  pulling  strong  dependency  taskexecutor  resourcemanagergateway  enough  make  taskexecutortoresourcemanagerconnection  reusable,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
1338,duplicateinconsistent  logic  physical  memory  size  class  hardware  environmentinformation  hardware  environmentinformation  logic  determine  size  physical  memory  environmentinformation  class  us  heuristic  maximum  heap  size  consolidate  logic  hardware  class  call  environmentinformation,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
1339,guard  flink  process  blocking  shutdown  hook  resource  manager  like  yarn  send  jvm  sigterm  signal  kill  process  want  terminate  process  sigterm  jvm  shutdown  hook  run  may  cause  process  freeze  shutdown  especially  since  dependency  like  hadoop  may  install  shutdown  hook  flinks  control  make  sure  shutdown  hook  well  behaved  propose  add  guard  forcibly  terminates  jvm  clean  shutdown  succeed  within  certain  time  say  five  second,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1340,separate  configuration  parsing  metricregistry  order  decouple  metricregistry  object  instantiation  global  configuration  could  introduce  metricregistryconfiguration  object  encapsulates  necessary  information  metricregistry  metricregistryconfiguration  could  static  method  generated  configuration,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1341,taskmanager  commit  suicide  cancellation  failure  case  failed  cancellation  eg  task  cannot  cancelled  given  time  taskmanager  kill  way  guarantee  resource  leak  behaviour  act  safetynet  faulty  user  code,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1342,implement  archived  version  execution  graph  order  implement  job  history  server  well  separate  jobmanager  webinterface  require  archived  version  executiongraph  serializable,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0
1343,unify  behaviour  committed  offset  kafka  zk  kafka  08  09  consumer  proper  behaviour  offset  committed  back  kafka  zk  next  offset  consumer  read  kafka  term  position  already  fixed  09  consumer  flink4618  incrementing  committed  offset  back  kafka  09  1  internal  kafkaconsumer  pick  correct  start  position  committed  offset  present  fix  required  start  position  committed  offset  implicitly  determined  kafka  09  apis  however  since  08  consumer  handle  offset  committing  start  position  using  flinks  zookeeperoffsethandler  kafka  highlevel  apis  08  consumer  require  fix  propose  still  unify  behaviour  committed  offset  across  08  09  definition  otherwise  user  case  first  us  08  consumer  read  data  flinkcommitted  offset  zk  us  highlevel  08  kafka  consumer  read  topic  nonflink  application  first  record  duplicate  like  described  kafka  highlevel  consumer  expect  committed  offset  next  record  process  last  processed  record  requires  incrementing  committed  zk  offset  08  also  incremented  1  changing  flink  internal  offset  initialized  accordance  acquired  zk  offset,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1344,port  webfrontend  new  metric  system  webfrontend  access  metric  system  still  relies  older  code  part  taskmanager  metric  still  gathered  using  codahale  library  send  heartbeat  task  related  metric  numrecordsin  etc  still  gathered  using  accumulator  accessed  execution  graph,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1345,introduce  operatoriometricgroup  task  related  io  metric  numbytesinout  instantiated  directly  task  instead  within  iometricgroup  contained  respective  taskmetricgroup  later  accessed  relevant  component  instead  creating  advantage  accessed  several  place  guaranteed  always  instantiated  identically  without  requiring  static  name  constant  propose  operator  also  prerequisite  flink4733,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1346,simplify  access  metricstore  utility  method  added  metricstore  would  make  working  lot  easier  includes  getxmetricstoreargs  method  example  return  appropriate  taskmetricstore  without  requiring  accessor  traverse  structureand  several  null  check  addition  getmetricname  defaultvalue  method  would  ease  issue  metric  updated  yet,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
1347,implement  mini  cluster  task  implement  embedded  mini  cluster  similar  localflinkminicluster  based  new  component  developed  flink  improvement  proposal  6,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
1348,add  mapstate  keyed  stream  many  state  keyed  stream  organized  keyvalue  pair  currently  state  implemented  storing  entire  map  valuestate  liststate  implementation  however  costly  entry  serializeddeserialized  updating  single  entry  improve  efficiency  state  mapstates  urgently  needed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1349,dont  block  buffer  request  broadcastevent  broadcasting  event  like  checkpoint  barrier  record  writer  might  block  buffer  request  although  buffer  needed  next  write  channel  instead  assuming  serializer  buffer  set  change  logic  writer  request  buffer  requires  one,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1350,introduce  non  async  future  method  currently  flinks  future  support  async  method  mean  chained  operation  executed  potentially  different  thread  case  necessary  context  switch  inflict  additional  cost  therefore  propose  add  non  async  method  future,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1351,introduce  safety  net  closing  file  system  stream  stream  opened  filesystem  must  closed  end  life  cycle  however  found  hint  code  forgets  close  stream  introduce  mechanism  close  leaking  unclosed  stream  usage  ii  provides  logging  help  u  track  fi  source  leak,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1352,expose  inputoutput  buffer  bufferpool  usage  metric  task  expose  following  metric  taskiometricgroup  1  buffersinputqueuelength  received  buffer  inputgates  task  2  buffersoutputqueuelength  buffer  produced  resultpartitions  task  3  buffersinpoolusage  usage  inputgates  buffer  pool  task  4  buffersoutpoolusage  usage  produced  resultpartitions  buffer  pool  task,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1353,genericwriteaheadsink  decouple  creating  committing  subtask  pending  checkpoint  far  genericwriteaheadsink  expected  subtask  wrote  pending  checkpoint  state  backend  also  one  commit  thirdparty  storage  system  issue  target  removing  assumption  checkpointcommitter  able  dynamically  take  subtaskidx  parameter  asking  checkpoint  committed  also  change  state  kept  genericwriteaheadsink  also  include  subtask  index  subtask  wrote  pending  checkpoint  change  also  necessary  making  operator  rescalable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1354,add  scala  api  keyedstreamflatmaptimelyflatmapfunction  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1355,allow  abstractstreamoperatortestharness  test  scaling  currently  abstractstreamoperatortestharness  allows  testing  operator  scaling  snapshot  restore  enough  many  interesting  corner  case  arise  scaling  arbitrary  combination  scaling  issue  target  add  functionality  operator  snapshot  state  restore  different  parallelism  later  scale,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1356,extending  window  function  metadata  httpscwikiapacheorgconfluencedisplayflinkflip2extendingwindowfunctionmetadata,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1357,rename  method  managedinitializationcontext  rename  getmanagedoperatorstatestore  getoperatorstatestore  getmanagedkeyedstatestore  getkeyedstatestore  unmanaged  store  extra  word  seems  bit  confusing  plus  make  name  longer,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1358,provide  timestamp  timelyflatmapfunction  right  timelyflatmapfunction  give  timestamp  element  flatmap  signature  currently  code  void  flatmapi  value  timerservice  timerservice  collectoro  throw  exception  code  add  timestamp  would  become  code  void  flatmapi  value  long  timestamp  timerservice  timerservice  collectoro  throw  exception  code  reason  long  long  element  might  timestamp  case  hand  null  becoming  quite  look  could  add  context  parameter  provides  access  timestamp  timer  service,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1359,introduce  streamstatus  stream  element  allow  temporarily  idle  streaming  source  streamstatus  element  informs  receiving  operator  whether  continue  expect  watermark  sending  operator  2  kind  status  namely  idle  active  watermark  status  element  generated  source  may  propagated  operator  topology  using  outputemitwatermarkstatuswatermarkstatus  source  downstream  operator  emit  either  status  element  change  watermarkidle  watermarkactive  state  source  considered  watermarkidle  emit  record  indefinite  amount  time  case  example  flinks  kafka  consumer  source  might  initially  assigned  partition  read  record  read  assigned  partition  source  detects  resume  emitting  data  considered  watermarkactive  downstream  operator  multiple  input  ex  head  operator  oneinputstreamtask  twoinputstreamtask  wait  watermark  upstream  operator  watermarkidle  deciding  whether  advance  operator  current  watermark  downstream  operator  determines  upstream  operator  watermarkidle  ie  input  channel  received  watermark  idle  status  element  operator  considered  also  watermarkidle  temporarily  unable  advance  watermark  always  case  operator  read  single  upstream  operator  operator  considered  watermarkidle  forward  idle  status  inform  downstream  operator  operator  considered  back  watermarkactive  soon  least  one  upstream  operator  resume  watermarkactive  ie  least  one  input  channel  receives  watermark  active  status  element  also  forward  active  status  inform  downstream  operator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1360,rename  timelyflatmap  process  method  keyeddatastream  would  called  process  function  would  called  processfunction  reason  timelyflatmapfunction  bit  mouthful  addition  timer  api  state  processfunction  could  become  basic  lowlevel  userfacing  api  case  user  nowadays  implement  operator,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1
1361,avoid  redundant  serialization  creating  taskdeploymentdescriptor  creating  taskdeploymentdescriptor  extract  information  executiongraph  defined  jobwide  executionjobvertex  defined  operatorwide  extracted  information  serialized  every  subtask  even  though  stay  improvement  serialize  information  give  serialized  byte  array  taskdeploymentdescriptor  reduce  serialization  work  flink  deploying  sub  task,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1
1362,make  bucketingsink  rescalable  aim  integrating  bucketingsink  rescalable  state  abstraction  parallelism  change  restoring  savepoint  without  sacrificing  provided  guarantee,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1363,add  efficient  isevent  check  eventserializer  localinputchannelgetnextbuffer  deserialises  incoming  event  lookout  endofpartitionevent  buffer  code  deserialises  incoming  event  lookout  endofpartitionevent  applies  partitionrequestqueueisendofpartitionevent  instead  eventserializer  offered  function  check  event  type  without  deserialising  whole  event  could  save  resource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1364,make  rollingsink  rescalable  integrate  rollingsink  new  state  abstraction  parallelism  change  restoring  savepoint,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1365,make  testing  function  implement  checkpointedfunction  interface  currently  stateful  function  implement  old  checkpointed  interface  issue  aim  porting  function  new  checkpointedfunction  interface  leverage  new  capability,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1366,make  blobserver  use  distributed  file  system  currently  blobserver  us  local  storage  addition  ha  mode  set  distributed  file  system  eg  hdfs  however  used  jobmanager  taskmanager  instance  request  blob  jobmanager  using  distributed  file  system  well  would  lower  load  jobmanager  increase  scalability,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1367,improved  resource  cleanup  rocksdb  keyed  state  backend  currently  resource  taken  snapshot  iterators  always  cleaned  rocksdb  state  backend  particular  starting  runnable  future  leave  taken  snapshot  unreleased  improve  release  resource  allocated  rocksdb  jni  bridge,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1368,extending  allwindow  function  metadata  following  logic  behind  12  processallwindowfunction  introduced  flink  allwindowedstream  extended  order  support  1  httpscwikiapacheorgconfluencedisplayflinkflip2extendingwindowfunctionmetadata  2  httpsissuesapacheorgjirabrowseflink4997,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1369,make  production  function  rescalable  apart  rollingbucketing  sink  issue  target  porting  function  production  code  new  state  abstraction  function  1  statefulsequencesource  2  messageacknowledgingsourcebase  3  fromelementsfunction  4  continuousfilemonitoringfunction,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1370,make  consumption  input  channel  fair  input  channel  receiver  side  network  stack  queue  incoming  data  notify  input  gate  available  data  notification  currently  determine  order  input  channel  consumed  lead  unfair  consumption  pattern  faster  channel  favored  slower  one,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
1371,consolidate  harmonize  window  translation  test  test  check  whether  api  call  windowedstream  java  scala  result  correct  runtime  operation  scattered  across  timewindowtranslationtest  windowtranslationtest  test  coverage  scala  java  ensure  test  api  call  also  test  scala  api  level  detail,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1372,properly  close  statebackend  streamtask  closingcanceling  right  streamtask  never  call  close  state  backend,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1373,make  abstractudfstreamoperator  aware  wrappingfunction  right  using  wrappingfunction  happens  windowfunction  also  function  scala  api  using  custom  interface  possible  custom  interface  example  checkpointing  function  listcheckpointed  checkpointedfunction  teach  abstractudfstreamoperator  wrapingfunction  correctly  handle  case  wrapped  user  function  implement  interface  also  scala  api  custom  function  mimic  wrappingfunction  behaviour  moved  use  wrappingfunction  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1374,introduce  state  handle  replication  mode  checkpointcoordinator  currently  checkpointcoordinator  support  repartitioning  operatorstatehandles  based  splitanddistribute  strategy  future  state  type  broadcast  union  state  need  different  repartitioning  method  allows  replicating  state  handle  subtasks  first  step  way  implementing  broadcast  union  state,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1375,improve  task  checkpoint  logging  logging  task  checkpoint  logic  could  improved  contain  information  relevant  debugging,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1376,explicit  restore  method  snapshotable  introduce  explicit  restore  method  match  snapshot  method  interface  currently  restore  happens  implicit  backends  ie  state  handle  provided  backends  execute  restore  logic  constructor  behaviour  make  hard  backends  participate  task  lifecycle  closeableregistry  register  backend  object  constructed  result  example  restore  operation  happen  constructor  responsive  cancelation  introduce  explicit  restore  first  create  backend  object  register  run  restore,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
1377,userprovided  hash  operator  could  allow  user  provided  alternative  hash  operator  streamgraph  make  migration  flink  version  easier  case  automatically  produced  hash  version  incompatible  example  user  could  copy  old  hash  web  ui  job,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1378,remove  duplicated  test  test  run  code  4  time  every  run  17  second  need  small  refactoring  remove  duplicated  code,1,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0
1379,try  reuse  resource  location  prior  execution  attempt  allocating  slot  currently  schedule  execution  request  allocate  slot  slotpool  taskmanagerlocation  parameter  empty  collection  task  fail  scenario  new  execution  attempt  may  deployed  different  task  manager  setting  rockdb  state  backend  performance  better  data  restored  local  machine  try  reuse  taskmanagerlocation  prior  execution  attempt  allocating  slot  slotpool  taskmanagerlocation  empty  prior  execution  behavior  current  status,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1380,remove  mesos  dynamic  class  loading  mesos  us  dynamic  class  loading  order  load  zookeeperstatehandlestore  curatorframework  class  replaced  compile  time  dependency,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1381,remove  unused  kvstaterequestserializerserializelist  kvstaterequestserializerserializelist  unused  instead  state  backends  serialisation  function  used  therefore  remove  one  make  sure  kvstaterequestserializerdeserializelist  work  state  backends  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1382,storm  localcluster  cant  run  powermock  strom  localcluster  cant  run  powermock  example  code  commented  wrappersetuphelpertesttestcreatetopologycontext,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1383,create  proper  internal  state  hierarchy  currently  state  interface  like  liststate  valuestate  reducingstate  sparse  contain  method  exposed  user  make  sense  keep  public  stable  api  minimal  time  runtime  need  method  internal  interaction  state  setting  namespaces  accessing  raw  value  merging  namespaces  currently  realized  recreating  reobtaining  state  object  keyedstatebackend  method  cause  quite  overhead  access  state  keyedstatebackend  try  trick  reduce  overhead  partially  induces  overhead  course  root  cause  issue  problem  design  proper  internal  state  abstraction  similar  way  external  state  abstraction  public  state  api  add  similar  hierarchy  state  internal  method  would  look  like  example  code  state  internalkvstate  mergingstate  internalmergingstate  reducingstate  liststate  internalliststate  internalreducingstate  code,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0
1384,queryable  state  execute  queryablestateitcase  three  state  backends  queryablestateitcase  currently  tested  memorystatebackend  seen  past  error  inconsistent  behaviour  appeared  different  state  backends  thus  extended  tested  three  currently  existing  state  backends,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0
1385,add  option  deactivate  kryo  fallback  serializers  user  want  avoid  flinks  serializers  use  kryo  easily  become  hotspot  serialization  user  would  help  flag  deactive  generic  type  user  could  see  type  used  default  kryo  change  type  make  pojos  value  type  write  custom  serializers  two  way  approach  1  simple  make  generictypeinfo  threw  exception  whenever  would  create  kryo  serializer  respective  flag  set  executionconfig  2  static  flag  typeextractor  throw  exception  whenever  would  create  generictypeinfo  approach  downside  introducing  static  configuration  typeextractor  may  helpful  throw  exception  program  point  type  used  serializers  created  may  much  later,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1386,set  uncaught  exception  handler  netty  thread  pas  thread  factory  netty  event  loop  thread  see  nettyserver  nettyclient  dont  set  uncaught  exception  handler  let  add  jvm  terminating  handler  exit  process  cause  fatal  error,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1387,clean  filesystem  filesystem  class  overloaded  method  well  supported  suggest  following  cleanup  pull  safety  net  separate  class  use  writemode  indicate  overwriting  behavior  right  filesystem  class  defines  enum  never  us  feel  weird  remove  createpath  overwrite  blocksize  reolication  method  really  supported  across  file  system  implementation  hdfs  behavior  set  via  configuration  anyways  change  made  nonapibreaking  fashion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1388,move  json  generation  code  static  method  order  implement  historyserver  need  way  generate  json  response  independent  rest  api  suggest  move  main  part  generation  code  jobspecific  handler  static  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1389,make  handler  aware  rest  url  handler  webruntimemonitor  currently  unaware  actual  rest  url  used  handler  simply  registered  given  url  without  guarantee  handler  actually  deal  url  propose  let  handler  specify  url  supposed  reachable  provides  tighter  coupling  url  handler,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1390,add  support  secure  yarn  cluster  kerberos  auth  current  yarn  client  throw  exception  httpsgithubcomstratospherestratospherepull591  detects  secure  environment  imported  github  url  httpsgithubcomstratospherestratosphereissues592  created  rmetzgerhttpsgithubcomrmetzger  label  enhancement  yarn  created  sun  mar  16  110507  cet  2014  state  open,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1391,allow  access  perwindow  state  processwindowfunction  right  state  windowfunction  processwindowfunction  access  scoped  key  window  window  state  global  across  window  given  key  use  case  beneficial  keep  state  scoped  window  example  expect  several  trigger  firing  due  early  late  firing  user  keep  state  per  window  keep  information  firing  perwindow  state  cleaned  way  see  two  option  keep  track  state  user  us  clean  reach  window  gc  horizon  add  method  cleanup  processwindowfunction  called  reach  window  gc  horizon  user  canshould  use  clean  state  api  side  add  method  windowstate  processwindowfunctioncontext  retrieves  perwindow  state  globalstate  would  allow  access  already  available  global  state  context  would  look  like  code  context  holding  window  metadata  public  abstract  class  context  return  window  evaluated  public  abstract  w  window  state  accessor  perkey  perwindow  state  keyedstatestore  windowstate  state  accessor  perkey  global  state  keyedstatestore  globalstate  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1392,let  handler  take  part  job  archiving  key  idea  behind  historyserver  precompute  json  response  webfrontend  could  request  store  file  directory  structure  resembling  restapi  require  mechanism  generate  response  corresponding  rest  url  flink5852  made  easier  reuse  json  generation  code  flink5870  made  handler  aware  rest  url  registered  one  aim  jira  extend  jobrelated  handler  building  jiras  enabling  generate  number  path  json  pair  given  executiongraph  containing  response  could  generate  given  graph  respective  rest  url,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1393,refactoring  duplicate  tokenizer  flinktest  duplicate  code  like  flinktest  think  refactor  better  public  final  class  tokenizer  implement  flatmapfunctionstring  tuple2string  integer  override  public  void  flatmapstring  value  collectortuple2string  integer  normalize  split  line  string  token  valuetolowercasesplitw  emit  pair  string  token  token  tokenlength  0  outcollectnew  tuple2string  integertoken  1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1394,add  support  null  value  java  api  currently  many  runtime  operation  fail  encountering  null  value  tuple  serialization  allow  null  field  suggest  add  method  tuples  called  getfieldnotnull  throw  meaningful  exception  accessed  field  null  way  simplify  logic  operator  dead  null  field  like  key  grouping  aggregation  even  though  sql  allows  grouping  aggregating  null  value  suggest  exclude  java  api  sql  semantics  aggregating  null  field  messy  imported  github  url  httpsgithubcomstratospherestratosphereissues629  created  stephanewenhttpsgithubcomstephanewen  label  enhancement  java  api  milestone  release  051  created  wed  mar  26  002749  cet  2014  state  open,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1395,change  new  java  api  function  sam  order  support  compact  syntax  java  8  lambda  would  need  change  type  function  single  abstract  method  type  sam  implemented  lambda  mean  datasetmapmapfunction  would  accept  interface  mapfunction  abstract  class  use  many  udfs  would  inherit  form  abstractfunction  inheritance  abstractfunction  would  optional  life  cycle  method  open  close  runtime  context  needed  may  also  implication  type  extraction  generic  parameter  generic  superinterfaces  rather  generic  superclass  imported  github  url  httpsgithubcomstratospherestratosphereissues701  created  stephanewenhttpsgithubcomstephanewen  label  enhancement  java  api  user  satisfaction  milestone  release  06  unplanned  created  thu  apr  17  130640  cest  2014  state  open,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1396,extend  jarfilecreator  automatically  include  dependency  simple  jarfilecreator  allows  add  class  jar  file  follows  codejava  jarfilecreator  jfc  new  jarfilecreatorjarfile  jfcaddclassxclass  jfcaddclassyclass  jfccreatejarfile  code  created  file  used  remote  execution  environment  requires  jar  file  ship  propose  following  improvement  use  asmhttpasmow2org  extract  dependency  add  create  jar  file  automatically  old  tutorialhttpasmow2orgdoctutorialasm20html  asm  2  implement  dependencyvisitor  unfortuneately  code  directly  work  asm  5  good  starting  point,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1397,add  support  named  datasets  would  create  api  mix  sql  like  declarativity  power  user  defined  function  example  user  code  could  look  like  codejava  nameddataset  one  nameddataset  two  nameddataset  result  onejointwowherekeyequaltootherkey  projecta  b  c  map  usertypein  return  new  usertypeout  print  code,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1398,throw  exception  solution  set  cogrouped  wrong  key  co  grouping  solution  set  key  solution  set  possible  program  however  cause  error  simply  cause  program  correctly  match  element  patch  coming,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1399,add  yarn  session  parameter  number  task  slot  per  task  manager  order  transparent  elegant  yarn  setup  shell  need  parameter  specify  many  task  slot  task  manager  offer  flag  specified  taskmanager  offer  many  slot  jvm  determines  system  core  may  think  changing  default  one  make  predictable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1400,remove  printing  config  systemout  jobmanager  started  print  global  config  systemout  suggest  remove,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
1401,replace  datainput  dataoutput  ioreadablewritable  datainputview  dataoutputview  datainput  dataoutput  view  well  designed  interface  limited  function  set  therefore  replace  datainput  dataoutput  flink  defined  datainputview  dataoutputview  ioreadablewritable  interface  preparative  step  serializer  inputoutput  abstraction  rework,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1402,nettyconnectionmanager  close  connection  network  connection  created  via  nettyconnectionmanager  closed,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
1403,aggregator  exported  currently  aggregator  value  cannot  saved  giraph  job  way,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1404,data  input  sampling  testing  improvement  would  really  nice  help  debug  application  limiting  input  data  input  split  max  vertex  per  input  split  also  would  nice  worker  provide  little  debugging  info  far  along  processing  input  data,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
1405,support  better  message  config  giraph  various  different  option  sending  message  giraph  whether  going  combiner  messageencodeandstoretype  used  message  factory  etc  want  different  property  different  iteration  currently  set  master  superstepclasses  sent  worker  use  messagestorefactory  example  inmemorywithprimitivesmessagestorefactory  property  missing  cannot  changed  like  message  factorymessageencodeandstoretype,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,1,1
1406,add  block  framework  set  diffs  adding  block  framework  summary  diff  explain  content  context  httpmailarchivesapacheorgmodmboxgiraphdev201506mbox3ccabjn3v24ylzgnmrt3tzt6r8t4vw1hrbcwwtghgxgac3dyqrg40mailgmailcom3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1407,outofcore  mechanism  input  superstep  graph  data  currently  outofcore  mechanism  several  issue  work  properly  input  superstep  several  bug  correctness  performance  graph  data  structure  considering  specialized  message  class  outofcore  message  diff  address  problem  provides  cohesive  mechanism  input  superstep  graph  data  way  outofcore  efficiently  handling  outofcore  message  straightforward  provided  separate  diff  diff  provides  adaptive  mechanism  remove  user  loop  using  outofcore  graph  fit  memory  computation  remains  memory  memory  limited  gc  killing  performance  graph  cannot  fit  memory  outofcore  mechanism  kick  help  improve  performance  many  case  avoids  application  failure  due  outofmemory  exception  related  exception,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1408,adding  outofcore  message  newly  added  adaptive  outofcore  mechanism  giraph1022  implement  adaptive  mechanism  outofcore  capable  handling  graph  data  structure  inputoutput  compute  superstep  diff  add  capability  handling  outofcore  message  well  useful  specially  case  message  combiner  used  large  amount  message  may  cause  job  either  fail  due  oom  related  exception  run  low  performance  due  extensive  gc  call,1,1,1,1,1,0,0,0,1,0,1,1,0,0,0,0,1
1409,remove  zookeeper  input  split  handling  currently  use  zookeeper  handling  input  split  worker  checking  split  lot  split  used  becomes  slow  master  coordinate  input  split  allocation  instead  making  complexity  proportional  split  instead  workerssplits,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
1410,allow  ip  worker2worker  communication  worker2worker  communication  use  on2  dns  lookup  n  number  worker  network  infrastructure  le  reliable  combined  large  number  worker  dns  lookup  occasionally  fail  fortunately  dont  always  need  dns  lookup  many  cluster  host  communicate  directly  using  ip  address  let  add  configuration  option  use  ip  address  instead  host  name,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1411,allow  extending  jobprogresstrackerservice  might  want  perform  additional  action  event  jobprogresstrackerservice  allow  overriding  specifying  another  class  use,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
1412,add  facebookconfiguration  internally  use  lot  different  configuration  default  make  available  anyone  use,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1413,remove  limit  number  partition  currently  limit  many  partition  write  partition  information  zookeeper  instead  send  information  request  remove  hard  limit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1414,use  pool  byte  array  inmemorydataaccessor  pool  byte  array  inmemorydataaccessor  save  byte  array  creation  initialization,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1415,fixed  outofcore  policy  definition  inmemory  partition  clear  fixed  outofcore  policy  relies  definition  inmemory  partition  however  definition  inmemory  partition  clear  lead  bug  fixed  outofcore  policy  currently  partition  called  inmemory  partition  regardless  message  memory  change  policy  partition  current  message  well  partition  data  memory  considered  inmemory  partition,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1416,improve  graph  distribution  giraph  currently  giraph  assumes  data  vertexinputformat  sorted  user  data  sorted  vertex  id  must  first  run  mapreduce  pig  job  generate  sorted  dataset  often  bit  inconvenient  giraph  graph  partitioning  currently  range  based  advantage  disadvantage  approach  proposal  jira  would  allow  range  hash  based  partitioning  provide  flexibility  user  design  goal  graph  distribution  allow  vertex  unordered  unordered  ability  repartition  select  partitioning  scheme  based  user  need  ie  hash  range  based  ability  provide  userspecific  hint  partition  hashbased  partitioning  good  vertex  balancing  across  range  random  data  bad  vertex  id  locality  rangebased  partitioning  good  vertex  id  locality  ability  split  range  easily  cause  hotspot  hot  range,1,0,1,0,1,0,1,0,1,0,1,1,0,0,0,1,1
1417,add  memory  estimation  mechanism  outofcore  new  outofcore  mechanism  designed  adaptivity  goal  mind  meaning  wanted  outofcore  mechanism  kick  necessary  word  amount  data  graph  message  mutation  fit  memory  want  take  advantage  entire  memory  stage  memory  short  enough  minimal  amount  data  go  core  disk  ensures  good  performance  outofcore  mechanism  satisfy  adaptiveness  goal  need  know  much  memory  used  point  time  default  outofcore  mechanism  thresholdbasedoracle  get  memory  information  based  jvms  internal  method  runtimes  freememory  method  inaccurate  pessimistic  meaning  account  garbage  data  purged  gc  using  jvms  default  method  ooc  behaves  pessimistically  move  data  core  even  necessary  instance  consider  case  lot  garbage  heap  gc  happened  case  default  ooc  push  data  disk  immediately  major  gc  brings  back  data  memory  cause  inefficiency  default  core  mechanism  outofcore  used  data  entirely  fit  memory  job  go  core  even  though  going  core  necessary  address  issue  need  mechanism  accurately  know  much  heap  filled  nongarbage  data  consequently  need  change  oracle  ooc  policy  take  advantage  accurate  memory  usage  estimation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1418,port  hcc  algorithm  identifying  connected  component  graph  port  hcc  algorithm  identifies  connected  component  assigns  componented  id  smallest  vertex  id  component  vertex  idea  behind  algorithm  simple  propagate  smallest  vertex  id  along  edge  vertex  connected  component  convergence  number  supersteps  necessary  equal  length  maximum  diameter  component  1  original  hadoopbased  variant  algorithm  proposed  kang  charalampos  tsourakakis  faloutsos  pegasus  mining  petascale  graph  2010  httpwwwcscmueduukangpaperspegasuskaispdf,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1419,make  edgelistvertex  default  vertex  implementation  fix  bug  related  edgelistvertex  think  would  best  new  user  much  memory  efficient  vertex  respect  edge  list  v  hash  map  seem  mostly  iterating  edge  several  others  pointed  earlier  jiras  email  would  provide  early  user  memory  efficient  implementation  without  performance  loss  anyone  disagrees  please  voice  opinion,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1420,clarify  message  behavior  basicvertex  initialize  receive  null  parameter  message  least  thats  edgelistvertex  avoid  pas  empty  iterable  instead  cheap  u  inside  inputformat  passing  static  immutable  empty  list  setmessagesiterablem  changed  putmessagesiterablem  set  prefix  suggests  assignment  setmessages  used  transfer  message  internal  datastructure  user  responsible  putmessages  clarify,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1421,change  extendedbytearraydataoutput  addingâ  new  stream  type  extends  fromâ  comesotericsoftwarekryoioinputoutput  thatâ  used  kryo  serializerâ  improves  performance  kryo  faster  readwrites  unsafe  io  alsoâ  eliminatesâ  need  interim  buffer  convertâ  fromâ  datainput  dataoutput,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1422,adding  faster  serialization  class  change  add  two  new  kryo  serialization  class  kryosimplewritable  kryosimplewrapperâ  disable  reference  tracking  expense  supporting  recursive  nested  structure  disabling  reference  tracking  significantly  improves  serialization  performanceâ  one  sample  pipeline  running  time  reduced  75  minute  5  minute,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1423,investigate  communication  improvement  currently  every  worker  start  thread  communicate  every  worker  hadoop  rpc  used  communication  instance  400  worker  worker  create  400  thread  end  using  lot  memory  even  option  dmapredchildjavaoptsxss64k  would  good  investigate  using  framework  like  netty  custom  roll  improve  situation  moving  away  hadoop  rpc  would  also  make  compatibility  different  hadoop  version  easier,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1424,deduplicate  pagerank  implementation  pagerankbenchmark  currently  pagerankbenchmark  code  pagerank  duplicated  implementation  vertex  noformat  public  static  class  pagerankhashmapvertex  extends  hashmapvertex  longwritable  doublewritable  doublewritable  doublewritable  override  public  void  computeiteratordoublewritable  msgiterator  getsuperstep  1  double  sum  0  msgiteratorhasnext  sum  msgiteratornextget  doublewritable  vertexvalue  new  doublewritable015f  getnumvertices  085f  sum  setvertexvaluevertexvalue  getsuperstep  getconfgetintsuperstepcount  1  long  edge  getnumoutedges  sendmsgtoalledges  new  doublewritablegetvertexvalueget  edge  else  votetohalt  public  static  class  pagerankedgelistvertex  extends  edgelistvertex  longwritable  doublewritable  doublewritable  doublewritable  override  public  void  computeiteratordoublewritable  msgiterator  getsuperstep  1  double  sum  0  msgiteratorhasnext  sum  msgiteratornextget  doublewritable  vertexvalue  new  doublewritable015f  getnumvertices  085f  sum  setvertexvaluevertexvalue  getsuperstep  getconfgetintsuperstepcount  1  long  edge  getnumoutedges  sendmsgtoalledges  new  doublewritablegetvertexvalueget  edge  else  votetohalt  noformat  code  consolidated  private  class  two  implementation  extend,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1425,change  pagerankbenchmark  accessible  via  bingiraph  currently  pagerankbenchmark  main  tool  implementation  difficult  access  bingiraph  script  would  better  everything  accessible  via  bingiraph  benchmark  particularly  problematic  us  inner  class  two  actual  vertex  implementation  specified  command  line  class  nameie  orgapachegiraphbenchmarkpagerankbenchmarkpagerankhashmapvertex  rather  dot  one  would  expect,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0
1426,multigraph  support  giraph  current  vertex  api  support  simple  graph  meaning  ever  one  edge  two  vertex  many  graph  like  road  network  fact  multigraphs  many  edge  connect  two  vertex  time  support  could  added  introducing  iteratoredgewritable  getedgevalue  similar  construct  maybe  introducing  slim  object  like  connector  edge  vertex  also  good  idea  could  something  like  code  final  connectoredgewritable  vertexwritable  conn  getedgevalues  final  edgewritable  edge  conngetedge  final  vertexwritable  othervertex  conngetother  dointerestingstuffothervertex  domoreinterestingstuffedge  code,1,0,1,0,1,0,0,0,0,1,1,1,1,0,0,0,1
1427,allow  creation  graph  adding  edge  span  multiple  worker  currently  graph  created  adding  vertex  typical  way  read  input  text  file  linebyline  line  describing  vertex  value  edge  etc  current  api  allows  creation  vertex  information  vertex  available  single  line  however  common  graph  described  form  edge  edge  might  span  multiple  line  input  file  even  span  multiple  worker  current  api  doesnt  allow  input  superstep  vertex  must  created  single  worker  instead  possible  multiple  worker  mutate  graph  input  superstep  following  implication  1  instead  instantiating  vertex  vertex  reader  able  vertex  addition  edge  addition  request  2  multiple  worker  might  try  create  vertex  conflict  handled  vertexresolver  resolver  instantiated  load  time,1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,1
1428,refactor  bspserviceworkerloadvertices  currently  bspserviceworkerloadvertices  200  line  convoluted  found  difficult  grok  debugging  today,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1429,random  walk  graph  implementing  rwr  giraph  simple  modification  simplepagerankvertex  code  code  myid  sourceid  doublewritable  vertexvalue  new  doublewritable015f  085f  sum  else  doublewritable  vertexvalue  new  doublewritable085f  sum  code  would  nice  make  configurable  possible  using  parametric  damping  factor  preference  vector  strongly  preferential  etc  le  along  line  httplawdsiunimiitsoftwaredocsitunimidsilawrankpagerankhtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1430,move  aggregator  separate  subpackage  since  aggregator  reused  throughout  many  project  algorithm  make  sense  implement  common  one  separate  subpackage  reduce  time  required  user  implement  project  based  giraph  required  aggregator  already  place  implemented  following  one  intlongfloatdouble  min  max  product  sum  overwrite  boolean  overwrite  speak  except  overwrite  one  aggregator  simply  overwrites  stored  value  new  value  aggregated  useful  one  node  way  master  node  example  source  node  routing  algorithm  node  want  broadcast  value  node  attached  patch  trunk  implementing  aggregator  patching  existing  file  use  aggregator  package  instead  example  one,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
1431,move  temporary  test  file  project  directory  shouldnt  use  project  directory  location  temporary  file  generated  test,1,0,1,0,1,0,1,0,0,1,1,0,0,0,0,0,1
1432,remove  hadoop  rpc  keep  netty  given  netty  communication  behaves  faster  rpc  keep  nettybased  drop  older  one,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1433,add  secure  authentication  netty  ipc  gianmarco  de  francisci  morale  asked  user  list  bq  getting  exception  subject  running  giraph  program  bq  cluster  kerberos  authentication  lead  idea  kerberos  authentication  supported  within  giraph  hopefully  would  use  fast  giraph37  ipc  could  also  interoperate  hadoop  security,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1434,make  iteration  edge  explicit  particular  reason  basicvertex  implement  iterable  seems  codejava  neighbor  vertex  code  explicit  codejava  neighbor  code  get  even  obscure  may  example  codebase  explicitly  instantiate  iterator  call  next  propose  explicit  codejava  iteratori  outedgesiterator  code  also  convenient  codejava  iterablei  outedges  code  example  algorithm  use  codejava  intwritable  neighbor  outedges  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1435,add  metric  system  giraph  currently  lot  giraphs  operation  transparent  hadoop  job  giraph  logging  mercy  hadoops  logging  system  disappear  one  encounter  memory  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1436,vertex  api  redesign  effort  rationalize  giraph  api  ive  put  together  issue  weve  talked  lately  im  focusing  making  giraph  development  even  intuitive  le  errorprone  fixing  potential  source  bug  im  sorry  big  patch  issue  intertwined  think  might  easier  review  integrate  here  account  change  vertex  api  renamed  basicvertex  vertex  understand  used  vertex  removed  switched  iterables  instead  iterators  edge  message  make  code  concise  implementors  need  call  iterator  collection  user  use  foreach  syntax  see  also  giraph221  added  simplevertex  simplemutablevertex  class  edge  value  iterable  implemented  getneighbors  donâ€™t  multiple  inheritance  way  could  think  simplevertex  extend  vertex  simplemutablevertex  extend  mutablevertex  duplicate  code  edge  iterables  also  due  type  erasure  one  still  deal  edge  object  simplemutablevertexinitialize  overall  think  still  improvement  current  situation  added  id  value  field  base  vertex  class  class  either  writing  boilerplate  using  primitive  field  creating  writables  fly  inefficient  even  todo  actually  useful  customizations  iâ€™ve  yet  see  also  removed  redundant  â€œvertexâ€\x9d  getterssetters  compare  vertexgetid  vertexgetvertexid  made  halt  private  field  added  wakeup  method  reactivate  vertex  ishaltedvotetohaltwakeup  semanticallycharged  gettersetters  renamed  number  verticesedges  graph  gettotalnum  previous  naming  getnumedges  arguably  confusing  one  suck  please  suggest  better  one  default  implementation  hasedge  getedgevalue  getnumedges  readfields  write  tostring  implementor  still  optimize  good  opportunity  currently  duplicating  lot  code  see  giraph238  potentially  introducing  bug  see  giraph239  hashmapvertex  switched  representation  mapi  edgei  e  mapi  e  giraph242  override  method  optimized  edgelistvertex  switched  representation  two  sorted  list  one  list  edgei  e  see  giraph243  mainly  make  iteration  edge  target  id  value  linear  instead  log  n  mutation  still  slow  generally  discouraged  override  method  optimized  small  nit  code  convention  say  try  avoid  abbreviation  eliminated  req  request  msg  message  unilaterally  refer  endpoint  edge  targetvertex  mix  destvertex  targetvertex  notice  rearranged  import  thatâ€™s  ide  trying  helpful  see  giraph230,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,1,1
1437,move  part  graph  outofcore  memory  low  talk  giraphs  scaling  limitation  due  keeping  whole  graph  message  ram  need  investigate  method  fall  back  disk  running  memory  gracefully  degrading  performance  issue  graph  storage  message  probably  separate  issue  although  interplay  two  crucial  also  discus  primary  goal  completing  job  albeit  slowly  instead  failing  graph  big  still  encouraging  memory  optimization  highmemory  cluster  restructuring  giraph  efficient  possible  disk  mode  making  almost  standard  way  operating,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1438,partitioning  outgoing  graph  data  inputsuperstep  vertex  result  wide  variance  rpc  message  size  relates  giraph247  unfortunately  named  maxverticesperpartition  fooled  thinking  value  regulating  size  initial  partition  object  composed  inputsuperstep  inputsplits  worker  read  fact  configuration  option  regulates  size  outgoing  rpc  message  stored  locally  partition  object  decomposed  collection  basicvertex  transfer  eventual  home  another  worker  combined  actual  partition  exist  job  run  partitioning  outgoing  message  vertex  metric  load  test  shown  size  average  message  well  regulated  create  overload  either  side  transfer  important  1  throughput  memory  premium  inputsuperstep  2  one  crashed  worker  giraph  job  cause  cascading  job  failure  even  otherwise  healthy  workflow  jira  renames  offending  variablesconfig  option  regulates  outgoing  graph  data  inputsuperstep  edge  vertex  candidate  transfer  much  effectively  regulates  message  size  typical  social  graph  data  show  testing  greatly  improve  amount  loadin  data  giraph  handle  without  failure  given  fixed  memory  worker  limit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1439,netty  optimization  handle  request  locally  whenever  possible  add  optimization  handle  request  locally  possible  rather  go  network  original  description  follows  see  related  jiras  item  besides  make  netty  default  instead  hadooprpc  added  optimization  handle  request  locally  possible  rather  go  network  added  timedlogger  print  within  given  time  period  added  optimization  using  multiple  channel  clientsservers  bandwidth  limited  per  connection  added  bytecounter  track  bandwidth  across  netty  later  integrated  giraph232  upgraded  rat  08  excluded  iml  file  intellij  idea,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1440,mutable  static  global  state  vertexjava  refactored  vertexjava  bunch  static  method  gettingsetting  global  graph  state  total  number  vertex  edge  reference  graphmapper  etc  refactoring  graphstate  object  every  vertex  hold  onto  reference  yes  tiny  bit  memory  per  vertex  comparison  whats  already,1,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0
1441,aggregator  shouldnt  use  zookeeper  use  zookeeper  znodes  transfer  aggregated  value  worker  master  back  zookeeper  supposed  used  coordination  also  memory  limit  prevents  user  aggregator  large  value  object  reason  implement  aggregator  gathering  distribution  different  way,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
1442,text  vertex  inputoutput  format  base  class  overhaul  current  way  implementing  vertexinputformat  vertexreader  bad  smell  required  user  understand  two  class  glued  together  forced  similar  code  duplicated  every  new  input  format  similarly  vertexoutputformat  vertexwriter  anyone  want  create  new  format  create  underlying  record  reader  writer  right  moment  delegate  call  seemed  unnecessary  detail  exposed  besides  type  parameter  appear  every  new  format  code  extremely  annoying  reading  existing  code  writing  new  one  frustrated  writing  first  format  code  especially  compared  writing  new  vertex  code  thought  writing  new  inputoutput  format  simple  vertex  refactored  textvertexinputformat  outputformat  new  form  difference  interface  remove  lot  burden  subclassing  instead  providing  static  vertexreader  base  class  made  nonstatic  innerclass  format  class  help  eliminate  repeated  code  gluing  two  already  tightly  coupled  class  additional  advantage  eliminating  generic  type  variable  vertexreader  side  make  overall  code  much  concise  added  several  useful  textvertexreader  base  class  save  effort  implementing  lineoriented  format  please  comment  see  proposed  change  impact  aspect  im  unsure  additional  layer  abstraction  could  affect  performance,1,0,0,0,0,0,0,0,1,0,1,0,1,0,0,1,1
1443,add  option  limit  number  open  request  mentioned  discussion  mailing  list  giraph45  patch  wasnt  enough  run  job  amount  message  data  thing  still  happen  many  send  message  request  didnt  get  reply  yet  request  use  memory  adding  limit  number  open  request  fix  last  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1444,add  thread  channel  pooling  nettyclient  nettyserver  add  thread  channel  pooling  nettyclient  nettyserver  instead  nettyclients  addresschannelmap  address  channel  address  channelrotater  originally  part  giraph262  extracted,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1445,improve  netty  reliability  retrying  failed  connection  tracking  request  threadsafe  hash  partitioning  upgrade  recent  stable  version  netty  353final  try  multiple  connection  attempt  n  failure  track  request  throughout  system  keeping  track  request  id  matching  request  id  response  minor  refactoring  writablerequest  make  request  simpler  support  request  id  improved  handling  netty  exception  dumping  exception  stack  help  debug  failure  fix  bug  hashworkerpartitioner  making  partitionlist  threadsafe  cause  divide  zero  exception  real  life  currently  netty  connection  failure  cause  issue  75  worker  setup  allows  u  reach  200  reasonably  reliable  network  doesnt  kill  connection  code  pass  local  hadoop  regression  single  node  hadoop  instance  regression  also  succeeded  large  run  200  worker  real  hadoop  cluster,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1
1446,inputsplit  reservation  clumping  leaving  many  worker  asleep  process  many  split  get  overloaded  recent  addition  codebase  user  noticed  many  worker  able  load  input  split  extremely  quickly  altered  behavior  giraph  inputsuperstep  using  current  algorithm  split  reservation  worker  process  multiple  split  often  overwhelming  netty  getting  gc  error  attempt  offload  much  data  quick  many  often  others  sleep  superstep  never  successfully  participating  essentially  current  algo  1  scan  input  split  list  skipping  node  marked  finsihed  2  grab  first  unfinished  node  list  reserved  check  reserved  status  3  reserved  attempt  reserve  return  successful  4  first  one  check  already  taken  sleep  way  long  wake  another  worker  finish  split  contend  worker  another  split  majority  split  list  might  sit  idle  actually  checked  claimed  anyone  yet  work  making  simple  change  acknowledging  zk  read  cheap  writes  patch  able  get  every  worker  involved  keep  game  ensuring  inputsuperstep  pass  quickly  painlessly  without  overwhelming  netty  spreading  memory  load  split  reader  bear  evenly  giraphsplitmb  w  option  set  correctly  behavior  exactly  one  would  expect  also  result  inputsuperstep  passing  quickly  survive  inputsuperstep  given  data  load  le  hadoop  memory  slot,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1447,netty  request  reliable  implement  exactly  semantics  one  biggest  scalability  challenge  getting  giraph  run  reliably  large  number  task  ie  200  several  problem  exist  1  connection  fails  initial  connection  made  job  die  2  request  must  completed  exactly  difficult  implement  required  since  cannot  multiple  retried  request  succeed  ie  vertex  get  message  expected  3  sometimes  unresolved  address  causing  failure  patch  address  issue  reestablishing  failed  connection  keep  tracking  every  request  sent  every  worker  request  fails  pass  timeout  resent  server  keep  track  request  succeeded  insure  request  wont  processed  structure  keeping  track  succeeded  request  server  efficient  handling  increasing  request  id  increasingbitset  handling  unresolved  address  added  retry  logic  keep  trying  resolve  problem  patch  also  add  several  unit  test  use  fault  injection  simulate  lost  response  closed  channel  exception  server  also  unittests  increasingbitset  insure  working  correctly  efficiently  pass  unittests  including  new  one  additionally  experience  result  well  previously  unable  run  reliably  200  worker  change  reliably  run  500  worker  also  ran  600  worker  successfully  really  big  reliability  win  u  see  code  working  reconnections  reissue  request  necessary  cool  ie  20120818  001652109  info  orgapachegiraphcommnettyclient  checkandfixchannel  fixing  disconnected  channel  xxxxxxxxxxxxxxxxxxxx30455  open  false  bound  false  20120818  001652111  info  orgapachegiraphcommnettyclient  checkandfixchannel  connected  xxxxxxxxxxxxxxxxxxxxxxxx30455  20120818  001652123  info  orgapachegiraphcommnettyclient  checkandfixchannel  fixing  disconnected  channel  xxxxxxxxxxxxxxxxxxxxxxxx  open  false  bound  false  20120818  001652124  info  orgapachegiraphcommnettyclient  checkandfixchannel  connected  xxxxxxxxxxxxxxxxxxxxxxxx30117,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1448,inputsplit  list  long  many  worker  locality  info  recreated  every  time  worker  call  reserveinputsplit  instrumenting  inputsuperstep  watching  various  run  see  input  split  list  generated  every  time  worker  call  reserveinputsplit  intent  purpose  immutable  per  job  therefore  save  fair  amount  memory  recreating  list  requerying  zookeeper  pas  claim  another  split  reserved  finished  child  list  ever  mutated  input  phase  job,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1449,hide  sortedmapi  edgeie  vertex  client  visibility  impl  detail  replace  appropriate  accessor  method  discussed  list  giraph28  sortedmapi  edgeie  implementation  detail  need  exposed  application  developer  need  iterate  edge  possibly  access  onebyone  remove  mutable  case  dont  need  sortedmap  creating  primitiveoptimized  basicvertex  implementation  hampered  fact  client  expect  map  exist,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1450,open  netty  client  server  master  giraph273  first  thing  need  open  netty  communication  master  make  connection  worker  make  connection  worker  master  since  already  significant  amount  code  im  opening  separate  issue,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0
1451,add  subpackages  comm  package  comm  became  big  would  nice  add  subpackages,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
1452,outgoing  message  current  superstep  grouped  sender  owning  worker  partition  currently  outgoing  message  created  vertexcompute  cycle  worker  stored  grouped  partitionid  destination  worker  message  belong  result  message  duplicated  wire  per  partition  given  receiving  worker  delivery  vertex  message  partitioning  outgoing  currentsuperstep  message  destination  worker  split  partition  insertion  messagestore  destination  worker  trade  come  compute  time  inserting  receiver  side  gain  fine  grained  control  real  number  message  worker  cache  outbound  given  worker  flushing  flush  message  aggregated  delivery  well  potentially  allows  great  reduction  duplicate  message  sent  situation  like  vertexsendmessagetoalledges  see  giraph322  giraph314  get  idea  might  poor  idea  certainly  use  additional  refinement  pass  mvn  verify  may  even  run  interoperates  disk  spill  code  well  could  consider  request  comment  idea  approach  rather  finished  product  commentsideashelp  welcome  thanks,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1
1453,improve  zookeeper  issue  currently  zookeeper  process  fails  little  information  happened  patch  address  keeping  last  100  log  line  dump  map  fails  runtimeexception  example  master  task  failure  invalid  jvm  argument  passed  zookeeper  error  much  obvious  20121004  150528916  warn  orgapachegiraphzkzookeepermanager  logzookeeperoutput  dumping  last  100  line  zookeeper  process  stdout  stderr  20121004  150528916  warn  orgapachegiraphzkzookeepermanagerstreamcollector  unrecognized  option  badopt  20121004  150528916  warn  orgapachegiraphzkzookeepermanagerstreamcollector  could  create  java  virtual  machine  20121004  150528919  info  orgapachehadoopmapredtasklogstruncater  initializing  log  truncater  mapretainsize1  reduceretainsize1  20121004  150528959  warn  orgapachehadoopmapredchild  error  running  child  javalangillegalstateexception  run  caught  unrecoverable  exception  onlinezookeeperservers  failed  connect  5  try  orgapachegiraphgraphgraphmapperrungraphmapperjava591  orgapachehadoopmapredmaptaskrunnewmappermaptaskjava763  orgapachehadoopmapredmaptaskrunmaptaskjava369  orgapachehadoopmapredchild4runchildjava259  javasecurityaccesscontrollerdoprivilegednative  method  javaxsecurityauthsubjectdoassubjectjava396  orgapachehadoopsecurityusergroupinformationdoasusergroupinformationjava1059  orgapachehadoopmapredchildmainchildjava253  caused  javalangillegalstateexception  onlinezookeeperservers  failed  connect  5  try  orgapachegiraphzkzookeepermanageronlinezookeeperserverszookeepermanagerjava721  orgapachegiraphgraphgraphmappersetupgraphmapperjava328  orgapachegiraphgraphgraphmapperrungraphmapperjava573  7  20121004  150528963  info  orgapachehadoopmapredtask  runnning  cleanup  task,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1454,rename  package  formatio  giraphformatscontrib  consistency  main  package  0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1455,ensure  subclassing  basicvertex  possible  user  apps  original  assumption  giraph  user  would  subclass  vertex  extended  mutablevertex  extended  basicvertex  class  wish  application  specific  data  structure  ie  treemapi  edgeie  may  need  extend  either  mutablevertex  basicvertex  unfortunately  vertexrange  extends  arraylistvertex  place  assumption  vertex  class  either  vertex  least  mutablevertex  let  make  sure  internal  apis  allow  basicvertex  base  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1456,implement  nettybacked  ipc  giraph12  considered  replacing  current  hadoop  based  rpc  method  netty  didnt  went  another  direction  think  still  value  approach  also  look  finagle,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1457,write  worker  address  zookeeper  move  address  resolution  nettyclient  preparation  giraph273  need  address  worker  available  write  zookeeper  along  master  address  since  address  resoultion  needed  nettyworkerclient  nettymasterclient  moved  nettyclient  also  added  map  taskidaddress  nettymasterclient  nettyworkerclient  dont  need  take  care  inetsocketaddresses  task  id  want  send  message,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
1458,multithreading  input  split  loading  compute  cleaned  workerclient  hierarchy  workerclientrequestprocessor  request  cache  every  thread  input  split  loading  compute  rpc  gone  got  rid  ugly  workerclientserver  nettyworkerclientserver  sendpartitioncache  made  graphstate  immutable  multithreading  added  multithreading  loading  input  split  added  multithreading  compute  added  threadlevel  debugging  option  added  additional  testing  number  vertex  edge  optimization  hashworkerpartitioner  use  copyonwritearraylist  instead  sychronized  list  bottleneck  added  multithreaded  testpagerank  test  case  ran  pagerankbenchmark  20  worker  10m  vertex  1b  edge  supersteps  time  compared  superstep  0  every  test  compute  performance  gain  quite  nice  even  little  faster  one  thread  actual  gain  depend  heavily  number  core  possible  parallelism  application  code  trunk  thread  compute  time  sec  total  time  sec  1  89  97543  multithreading  1  8670094  92477  2  5041521  57850  4  3807716  50246  8  3863188  45940  16  22999943  48607  24  23649189  45112  32  21412325  44201  code  also  saw  similar  gain  input  split  loading  internal  app  future  work  improve  scalability  multithreading,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
1459,cleaner  mutablevertex  api  currently  mutablevertex  requires  user  instantiate  vertex  creating  request  using  instantiatevertex  also  requires  downcast  mutablevertex  instead  pas  id  value  optionally  edge  addvertexrequest  instantiationinitialization  happen  internally  safely,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1460,improve  way  keep  outgoing  message  per  discussion  giraph357  standard  application  chance  get  use  clientside  combiner  low  experimented  benefit  get  clientside  combiner  turn  lot  map  sendmessagecache  collection  inside  really  hurt  performance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1461,sendmessagecache  improvement  lot  map  sendmessagecache  still  make  slow  another  step  towards  making  faster,1,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0
1462,metric  update  updating  metric  useful  httpsreviewsapacheorgr7900,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1463,refactor  cleanup  general  thought  ive  jotted  going  code  writing  start  tracking  progress  1  refactor  giraphgraph  giraphmaster  giraphworker  whole  giraphgraph  package  name  bad  general  think  2  cleanup  giraphutils  example  move  timer  stuff  giraphtime  3  change  module  name  mavenesque  something  like  giraphroot  giraphcore  giraphformats  4  remove  workerclientserver  needed  anymore  5  cleanup  masterthreadrun  long  convoluted  method  6  cleanup  bspserviceprocess  lot  duplication  use  vector  event  something  7  cleanup  vertex  class  seems  many  method  simpler  interface  maybe  even  eventually  actual  interface  abstract  class  add  something  like  vertexesvertices  class  helper  method  use  use  8  masterworkerobserver  discussed  elsewhere  already  allow  user  easily  plug  code  various  point  system  essentially  cleaner  implementation  eg  workercontext  9  cleanup  graphmapper  dont  see  even  call  map  method  seeing  overriding  run  clearly  particularly  mapreducey  make  entry  point  clear  map  also  think  something  like  workerthread  similar  masterthread  clean  creare  whichever  thread  node  assigned  role  10  move  example  anything  else  needed  giraph  library  package  like  giraphexamples  someone  1  idea  ill  work  patch  feel  free  add  cleanup  thing  well,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
1464,create  binarycombiner  ands  specialized  message  store  current  combiner  interface  general  also  doesnt  provide  best  performance  combiners  currently  binary  combiners  ie  combine  two  message  one  list  around  simple  concept  make  slower  requires  object  creation  adding  binarycombiner  specialized  message  store  used  message  store  one  message  per  vertex  instead  collection  per  vertex,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1,1,1
1465,refactor  cleanup  hadoop  counter  httpsreviewsapacheorgr7980,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1466,masterobserver  user  postapplication  customization  httpsreviewsapacheorgr7981,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1467,serialize  graphmessage  cache  byte  improving  memory  usage  compute  speed  entire  graph  currently  stored  java  object  memory  added  option  keep  representative  vertex  serializesdeserializes  fly  used  new  bytearraypartition  conjunction  serialized  clientside  message  cache  memory  usage  loading  shrink  almost  110  trunk  load  input  split  almost  3x  faster  see  input  superstep  time  added  serializer  based  sun  unsafe  method  enables  memory  saving  small  performance  hit  maybe  15  slower  compared  trunk  serializing  message  faster  serializer  compute  time  improves  significantly  well  trunk  167  1231  25b  edge  297  161  250m  edge  still  improvement  made  server  side  still  store  message  inmemory  someone  else  later  patch  also  significantly  reduces  gc  time  le  object  gc  improves  byte  serialization  signficantly  added  extendeddatainputextendeddataoutput  interface  allow  additional  method  needed  byte  serializationdeserialization  add  extendedbytearraydatainputextendedbytearraydataoutput  serializedeserialize  writables  byte  added  dynamicchannelbufferoutputstreamdynamicchannelbufferinputstream  serializedeserialize  writables  dynamicchannelbuffer  give  choice  partition  implementation  simplepartition  default  bytearraypartition  serialized  vertex  added  new  method  partition  called  savevertex  also  serialization  back  bytearraypartition  nothing  using  simplepartition  give  choice  unsafe  serialization  using  sun  unsafe  class  default  regular  serialization  serializes  message  client  cache  byte  save  memory  also  serializes  faster  created  new  bytearrayvertexidmessagecollection  support  serialized  message  sendvertexrequest  sends  partition  object  rather  collection  add  2  option  pagerankbenchmark  try  representationvertex  representationvertex  unsafe  serialization  fixed  bug  longdoublefloatdoublevertexs  readfields  edge  arent  cleared  deserializing  added  new  unittests  replaced  testedgelistvertex  testmutablevertex  test  generic  mutablevertex  implementation  added  serialization  test  different  serialization  testpartitionstores  testing  unsafe  serializationdeserialization  testing  unittests  pas  distributed  unittests  pas  except  two  also  fail  trunk  lot  pagerankbenchmark  run  cluster  benchmark  result  25  edge  vertex  10m  vertex  10  worker  trunk  info  20121108  144355855  load0  orgapachegiraphgraphinputsplitscallable  call  loaded  1  input  split  22475897  sec  v1000000  e25000000  44492105  verticessec  11123026  edgessec  info  20121108  144400411  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  1  totalmem  817286875m  maxmem  817286875m  freemem  7658054187774658m  info  20121108  144405254  compute7  orgapachegiraphgraphcomputecallable  call  computation  took  29732208  sec  1  partition  superstep  0  flushing  started  info  20121108  144411180  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  superstep  0  message  25000000  totalmem  817286875m  maxmem  817286875m  freemem  747819575881958m  total  millisecond  62413  0  62413  superstep  3  millisecond  2417  0  2417  setup  millisecond  2731  0  2731  shutdown  millisecond  50  0  50  superstep  0  millisecond  10654  0  10654  input  superstep  millisecond  27484  0  27484  superstep  2  millisecond  9475  0  9475  superstep  1  millisecond  9599  0  9599  total  time  gc  millisecond  225052  0  225052  25  edge  vertex  10m  vertex  10  worker  simplepartition  edgelistvertex  rebase  info  20121108  143315907  load0  orgapachegiraphgraphinputsplitscallable  call  loaded  1  input  split  25431986  sec  v1000000  e25000000  39320562  verticessec  98301406  edgessec  info  20121108  143317501  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  1  totalmem  817286875m  maxmem  817286875m  freemem  7629028507995605m  info  20121108  143320175  compute2  orgapachegiraphgraphcomputecallable  call  computation  took  20086238  sec  1  partition  superstep  0  flushing  started  info  20121108  143326667  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  superstep  0  message  25000000  totalmem  817286875m  maxmem  817286875m  freemem  7371620901489258m  trunk  rebase  total  millisecond  68113  0  68113  superstep  3  millisecond  2057  0  2057  setup  millisecond  9765  0  9765  shutdown  millisecond  59  0  59  superstep  0  millisecond  9180  0  9180  input  superstep  millisecond  27525  0  27525  superstep  2  millisecond  9600  0  9600  superstep  1  millisecond  9924  0  9924  total  time  gc  millisecond  216345  0  216345  250  edge  vertex  10m  vertex  10  worker  bytearraypartition  unsaferepresentativevertex  reuse  vertexdata  buffer  unsafe  serialization  rebase  info  20121108  143309822  load0  orgapachegiraphgraphinputsplitscallable  call  loaded  1  input  split  93217535  sec  v1000000  e25000000  10727595  verticessec  26818988  edgessec  info  20121108  143310900  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  1  totalmem  817286875m  maxmem  817286875m  freemem  7997463636779785m  info  20121108  143313213  compute7  orgapachegiraphgraphcomputecallable  call  computation  took  16110481  sec  1  partition  superstep  0  flushing  started  info  20121108  143313972  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  0  totalmem  817286875m  maxmem  817286875m  freemem  7822854064941406m  total  millisecond  47061  0  47061  superstep  3  millisecond  2175  0  2175  setup  millisecond  3018  0  3018  shutdown  millisecond  1050  0  1050  superstep  0  millisecond  8780  0  8780  input  superstep  millisecond  10952  0  10952  superstep  2  millisecond  10450  0  10450  superstep  1  millisecond  10633  0  10633  250  edge  vertex  10m  vertex  10  worker  trunk  info  20121108  144625304  load0  orgapachegiraphgraphinputsplitscallable  call  loaded  1  input  split  16702779  sec  v1000000  e250000000  5987028  verticessec  14967570  edgessec  info  20121108  144635558  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  1  totalmem  817286875m  maxmem  817286875m  freemem  3844711888885498m  info  20121108  144652963  compute14  orgapachegiraphgraphcomputecallable  call  computation  took  16770031  sec  1  partition  superstep  0  flushing  started  info  20121108  144653074  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  0  totalmem  817286875m  maxmem  817286875m  freemem  24629869369506836m  total  millisecond  568094  0  568094  superstep  3  millisecond  2344  0  2344  setup  millisecond  2748  0  2748  shutdown  millisecond  47  0  47  superstep  0  millisecond  67853  0  67853  input  superstep  millisecond  177722  0  177722  superstep  2  millisecond  247518  0  247518  superstep  1  millisecond  69856  0  69856  total  time  gc  millisecond  2741892  0  2741892  250  edge  vertex  10m  vertex  10  worker  simplepartition  edgelistvertex  rebase  info  20121108  141957774  load0  orgapachegiraphgraphinputsplitscallable  call  loaded  1  input  split  17217258  sec  v1000000  e250000000  5808126  verticessec  14520315  edgessec  info  20121108  142004864  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  1  totalmem  817286875m  maxmem  817286875m  freemem  370259013671875m  info  20121108  142017453  compute6  orgapachegiraphgraphcomputecallable  call  computation  took  11959192  sec  1  partition  superstep  0  flushing  started  info  20121108  142017606  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  0  totalmem  817286875m  maxmem  817286875m  freemem  21953103630065918m  total  millisecond  470845  0  470845  superstep  3  millisecond  2595  0  2595  setup  millisecond  1774  0  1774  shutdown  millisecond  54  0  54  superstep  0  millisecond  59609  0  59609  input  superstep  millisecond  179665  0  179665  superstep  2  millisecond  165848  0  165848  superstep  1  millisecond  61296  0  61296  total  time  gc  millisecond  2480260  0  2480260  250  edge  vertex  10m  vertex  10  worker  bytearraypartition  unsaferepresentativevertex  reuse  vertexdata  buffer  unsafe  serialization  rebase  info  20121108  132650334  load0  orgapachegiraphgraphinputsplitscallable  call  loaded  1  input  split  6922095  sec  v1000000  e250000000  14446494  verticessec  36116235  edgessec  info  20121108  132652511  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  1  totalmem  817286875m  maxmem  817286875m  freemem  7539374648284912m  info  20121108  132706441  compute5  orgapachegiraphgraphcomputecallable  call  computation  took  12318953  sec  1  partition  superstep  0  flushing  started  info  20121108  132706483  main  orgapachegiraphgraphbspserviceworker  finishsuperstep  waiting  request  superstep  0  totalmem  817286875m  maxmem  817286875m  freemem  623032106552124m  total  millisecond  301720  0  301720  superstep  3  millisecond  4759  0  4759  setup  millisecond  2887  0  2887  shutdown  millisecond  50  0  50  superstep  0  millisecond  72625  0  72625  input  superstep  millisecond  75797  0  75797  superstep  2  millisecond  72245  0  72245  superstep  1  millisecond  73353  0  73353  total  time  gc  millisecond  716930  0  716930,1,0,1,0,1,0,0,0,1,1,1,0,0,1,1,0,1
1468,aggregate  metric  master  see  httpsreviewsapacheorgr8042,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
1469,missing  progress  call  stopping  netty  server  end  long  running  job  got  exception  reporting  progress  last  log  line  stop  halting  netty  server  suspect  awaituninterruptibly  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1470,max  message  request  size  byte  initialize  buffer  expected  size  message  request  kept  serialized  format  limit  size  request  number  byte  instead  number  message  sizing  message  buffer  expected  size  gave  10  speedup  large  application  run,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1471,cleanup  configuration  related  thing  diff  1  create  conf  package  configuration  related  thing  2  create  giraphclasses  object  member  immutableclassesgiraphconfiguration  use  class  inside  immutableclassesgiraphconfiguration  3  use  giraphclasses  test  cleanup  internalvertexrunner  bspcase  remove  lot  method  many  parameter  make  thing  type  safe  remove  lot  null  calling  code  4  extract  constant  giraphconfiguration  separate  giraphconstants  personally  think  constant  moved  place  used  ie  zkmanager  hold  configuration  related  constant  think  step  right  direction  generally  make  thing  cleaner  imo  httpsreviewsapacheorgr8437,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
1472,improve  way  keep  outgoing  message  discussed  giraph12httpgooglce32u  think  potential  problem  cause  memory  rate  message  generation  higher  rate  message  flush  network  bandwidth  overcome  problem  need  eager  strategy  message  flushing  approach  spill  message  disk  link  dmitriys  suggestion  httpsissuesapacheorgjirabrowsegiraph12focusedcommentid13116253pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment13116253,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1473,cleanup  mapfunctions  mapfunctions  simple  enum  code  using  convoluted  instead  use  java  magic  making  enum  smarter  cleanup  code  us,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1474,make  vertex  interface  made  vertex  interface  defaultvertex  implementation  httpsreviewsapacheorgr11682,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
1475,cleanup  graphmapper  dont  see  even  call  map  method  seeing  overriding  run  clearly  particularly  mapreducey  make  entry  point  clear  map  also  think  something  like  workerthread  similar  masterthread  clean  creare  whichever  thread  node  assigned  role  link  review  board  httpsreviewsapacheorgr8898,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1476,export  worker  contextstate  vertex  prepostapplicationsuperstep  would  quite  useful  vertex  reach  workerrelated  information  stored  ie  graphstate  class  information  could  exported  parameter  prepostapplicationsuperstep  like  public  void  preapplicationconfigurable  workerobject  public  void  postapplicationconfigurable  workerobject  public  void  presuperstepconfigurable  workerobject  public  void  postsuperstepconfigurable  workerobject  public  configurable  getworkerobject  another  possibility  add  context  inner  class  basicvertex  store  information,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1477,refactor  mapfunctions  enum  general  preparation  refactors  like  giraph469  let  make  boilerplate  code  around  graphmapper  general  behaviororiented  le  hadoopy  end  let  make  mapfunctions  enum  something  general  make  use  multiple  driver  implementation  including  based  mrv1  graphmapper  pass  mvn  verify  today  trunk  giraphaccumulo  part  build  fails  grepping  accumulo  code  dont  see  anything  affected  mapfunctions  im  assuming  unrelated  matter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1478,add  convergence  detection  orgapachegiraphexamplesrandomwalkvertex  propose  add  convergence  detection  randomwalkvertex  convergence  achieved  overall  absolute  change  l1  norm  difference  current  previous  probability  vector  becomes  le  given  threshold  convergence  detection  implemented  via  additional  aggregator  check  master  compute  function  change  would  make  class  much  easier  use  user  dont  worry  number  supersteps  execute  simply  specify  high  number  maxsupersteps  sure  algorithm  convergence  acceptable  quality  result  reached,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1
1479,observer  job  launch  lifecycle  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1480,refactor  job  launch  code  graph  package  job  package  there  many  class  graph  become  catchall  sort  stuff  im  moving  4  class  relate  job  launch  new  orgapachegiraphjob  package  left  giraphtaskmanager  graph  since  beginning  nowadays  real  bspgiraphonly  activity  relate  got  point  hadoop  mapper  running  yarn  resource  request  whatever  job  run  preliminary  stuff  live  oagjob  also  left  giraphrunner  toplevel  source  tree  since  easy  new  folk  find  way  dont  break  anyones  existing  command  line  move  future  jira,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1481,workerobserver  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1482,refactor  platformindependent  cli  argument  parsing  giraphrunner  separate  class  order  run  non  hadoop  mr  platform  need  populate  giraphconfiguration  job  platformindependent  way  config  option  available  whatever  driver  class  initiate  giraph  job  giraphrunnergiraphjob  also  serf  clean  giraphrunner  general  pass  mvn  clean  install  review  board  url  httpsreviewsapacheorgr9350,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
1483,create  partitioncontext  right  workercontext  accessible  vertexcompute  thread  safe  usually  want  use  multithreaded  computation  use  synchronization  instead  create  computecontext  going  one  instance  per  compute  thread,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0
1484,factor  aggregatorusage  posting  issue  patch  colleague  make  common  aggregatorusage  interface  workeraggregatorusage  masteraggregatorusage,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1485,efficient  flexible  edgebased  input  current  implementation  edgebased  input  using  mutation  memoryefficient  could  also  cant  used  immutable  vertex  class  adhoc  code  path  edge  sent  input  superstep  achieve  memory  efficiency  eliminate  current  restriction,1,0,1,0,1,0,0,0,1,0,1,1,1,0,0,1,0
1486,rangepartitioning  edge  locality  benchmark  rangebased  partitioning  drastically  reduce  network  communication  using  vertex  id  space  close  id  correspond  vertex  likely  connected  currently  incomplete  implementation  rangebased  partitioning  try  generic  allowing  arbitrarily  different  partition  size  talking  avery  thought  better  add  simpler  version  try  split  evenly  possible  leave  current  class  case  someone  want  implement  complex  logic  nicetohave  also  extending  pseudorandom  format  generate  required  ratio  partitionlocal  edge  order  estimate  impact  locality  benchmark,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
1487,open  request  log  worker  sent  waiting  request  processed  useful  know  worker  open  request  sent,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1488,allow  inplace  modification  edge  somewhat  long  term  item  optimized  edge  storage  implementation  byte  array  primitive  array  contract  user  edge  object  returned  getedges  readonly  one  concrete  example  inplace  modification  would  useful  weighted  version  pagerank  store  weight  sum  normalize  message  sent  could  efficiently  normalize  outedges  superstep  0  pregel  paper  describes  outedgeiterator  allows  inplace  modification  edge  see  would  easy  implement  c  need  reuse  object  giraph  unofficially  support  one  using  generic  collection  represent  edge  eg  arraylist  hashmap  may  trickier  optimized  implementation  principle  doable  one  way  would  special  mutableedge  implementation  call  back  edge  data  structure  order  save  modification  code  edgei  e  edge  getedges  edgesetvaluenewvalue  code  another  option  would  add  special  set  method  edge  iterator  one  replace  current  edge  code  edgeiteratori  e  getedgesiterator  ithasnext  edgei  e  edge  itnext  edgesetvaluenewvalue  itsetedge  code  could  actually  implement  first  version  syntactic  sugar  top  second  version  special  mutableedge  would  need  reference  iterator  order  call  setthis,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
1489,make  possible  use  different  outedges  data  structure  input  computation  case  property  want  vertexedges  implementation  input  may  differ  one  want  computation  two  example  1  input  want  keep  top  k  edge  according  weight  use  fixedsize  minheap  computation  algorithm  need  fast  random  access  use  hashmap  2  vertexedges  implementation  thats  optimized  space  andor  iteration  speed  slow  insertion  use  different  data  structure  fast  insertion  input  add  option  specify  different  vertexedges  class  used  edgestore  input,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1490,autoset  hive  reusing  object  option  httpsreviewsapacheorgr10148,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
1491,create  option  output  computation  application  get  partial  result  computation  able  keep  around  end  job  would  good  add  option  write  vertex  output  computation  instead  end  application  first  step  future  might  want  allow  output  output  supersteps  different  output  per  superstep,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1492,clean  benchmark  benchmark  class  lot  duplicate  option  duplicate  code  handle  commandline,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
1493,add  support  multithreaded  output  output  format  like  giraphhive  stuff  write  output  parallel  provide  option  choose  number  thread  use  storing  output,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0
1494,decouple  vertex  edge  diskbackedpartitionstore  avoid  writing  back  edge  algorithm  change  topology  many  algorithm  work  static  graph  case  running  outofcore  graph  end  writing  back  edge  changed  since  read  decoupling  vertex  edge  write  back  freshly  computed  vertex  value,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1495,rename  vertexedges  outedges  discussed  mailing  list  current  naming  bit  confusing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1496,initialize  compute  outedges  directly  input  outedges  compute  vertexedges  example  immutable  better  performance  adding  edge  adding  one  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1497,add  support  multiple  vertexedge  input  example  sometimes  want  read  input  several  table  currently  possible  allow  number  vertex  edge  input  format  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1498,allow  io  format  add  parameter  configuration  currently  heavily  rely  runner  hcatgiraphrunner  hivegiraphrunner  prepare  configuration  application  start  way  using  hcathive  io  without  runner  would  better  flexible  io  format  would  add  whats  needed  underlying  io  configuration  httpsreviewsapacheorgr10690,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1499,decouple  vertex  data  computation  make  computation  combiner  class  switchable  currently  vertex  class  hold  lot  stuff  shouldnt  related  global  graph  worker  state  decouple  vertex  computation  vertex  provided  infrastructure  user  implement  computation  many  realworld  application  several  different  stage  different  kind  computation  done  different  type  message  sent  done  currently  complicated  compute  encoding  message  type  inside  message  much  better  would  provide  way  change  computation  used  giraph  application  considered  piece  put  together  pipeline  coordinated  master,1,0,1,0,1,0,1,1,1,0,1,0,0,0,0,1,1
1500,input  superstep  support  aggregator  like  superstep  add  aggregator  vertexreader  allow  user  aggregate  value  input  superstep,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1501,clean  message  store  hierarchy  message  store  complex  moment  message  store  required  implement  method  used  infrastructure  like  addmessagesmessagestore  readfieldswrite  getnumberofmessages  outofcore  store  need  im  working  optimized  message  store  decided  clean  first,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
1502,communication  improvement  using  onetoall  message  sending  using  onetoall  message  sending  send  one  message  copy  multiple  target  vertex  worker  enable  feature  use  confenableonetoallmsgsending  pagerank  benchmarking  partition  640  edge  per  vertex  500  vertex  200000000  worker  40  show  time  per  superstep  reduced  40,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
1503,specialized  message  store  investigating  timecpu  going  application  receiving  message  server  side  turned  one  expensive  thing  provide  better  implementation  using  primitive  map  whenever  thats  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1504,giraph  application  master  move  new  stable  yarn  api  giraph  early  adopter  hadoop  yarn  eli  successfully  wrote  giraph  based  hadoop  20xalpha  however  last  month  yarn  significantly  overhauled  apis  associated  coding  pattern  new  beta  version  21x  told  yarndev  current  apis  change  much  circumstance  need  substantially  overhaul  giraph  well  accommodate  new  yarn  api  moreover  newer  yarn  api  supporting  kerberos  security  becomes  easier  transparent  potential  impact  upcoming  girpah  work  earlier  alpha  hadoop  version  203  im  sure  anyone  using  giraph  production  however  prevalent  way  giraph  processing  mrbased  continue  work,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1505,efficient  dense  matrix  aggregator  application  matrix  needed  efficient  aggregator  per  entry  update  provides  functionality  aggregator  per  matrix  row  implementation  us  array  per  row  efficient  matrix  dense,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0
1506,improve  graphpartitionerfactory  usage  usage  graphpartitionerfactory  improved  defining  custom  partitioner  need  extending  3  classesinterfaces  defining  multiple  function  complex  needed  range  partitioners  randomly  assigning  excess  instead  partitionworker  1  consecutive  range  maxpartitions  reached  might  creating  number  partition  divisible  number  worker,1,0,0,0,0,0,0,0,0,0,1,1,1,0,0,1,0
1507,print  job  progress  command  line  currently  print  nothing  job  progress  command  line  track  stage  far,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
1508,dont  expose  list  holding  message  basicvertex  im  currently  trying  implement  memory  efficient  vertex  similar  longdoublefloatdoublevertex  ran  problem  getmsglist  method  return  list  pointing  message  vertex  modified  externally  basicrpccommunications  call  clear  addall  eg  make  hard  use  something  else  javautillist  internally  longdoublefloatdoublevertex  hacked  around  generally  dangerous  internal  state  object  modified  externally  also  make  code  harder  read  understand  id  suggest  change  api  let  vertex  handle  modification  internally  eg  add  something  like  pushmessages,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1509,upgrade  netty  4  late  netty  4  earned  much  praise  community  example  httpsblogtwittercom2013netty4attwitterreducedgcoverhead  switch  netty  4  enables  significant  reduction  gc  pressure  also  huge  performance  gain  started  working  last  sunday  patch  show  performance  gain  order  1525  total  execution  time  application  facebook  however  tested  hadoopfacebook  might  issue  sasl  path  release  patch  today  want  open  discussion  anyone  using  secure  feature  anymore  deprecate,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,1
1510,allowing  plain  computation  type  configurable  type  configurable  via  vertexidclass  constant  giraphconstants  still  required  match  computation  type  unless  code  jython  allowed  pas  provided  type  subtypes  computation  type  also  possible  change  incoming  outgoing  message  class  without  need  explicit  computation  class  appropriate  compile  time  defined  type,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1511,specialized  edge  store  performance  tuning  discovered  loading  edge  store  expensive  operation  similar  giraph704  use  primitive  map  provide  significant  performance  benefit  part  benefit  come  lower  memory  overhead  associated  primitive  map  however  larger  benefit  come  fact  dont  release  reconstruct  vertexid  object  every  time  new  vertex  encountered  processing  large  graph  4b  vertex  5b  edge  3b  edge  loaded  via  edgeinputformat  worker  edge  request  taking  15  second  implementing  suggestion  number  dropped  subsecond,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
1512,trim  edge  giraph  many  giraph  application  graph  immutable  edge  never  trimmed  proper  size  input  phase  mean  average  often  use  15x  memory  storing  considering  often  memory  bounded  adding  option  trim  edge  input  phase  help  reduce  excess  memory  usage  mutable  graph  also  provide  option  method  called  superstep  review  request  httpsreviewsapacheorgr21119,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1513,add  option  dump  live  object  jmap  able  dump  live  object  jmap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1514,largememory  improvement  memory  reduced  vertex  implementation  fast  failure  added  setting  current  vertex  implementation  us  hashmap  storing  edge  quite  memory  heavy  large  graph  default  setting  giraph  need  improved  large  graph  heap  20g,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1515,support  succinct  representation  message  messagestores  currently  onetoall  message  useful  reducing  network  transfer  server  side  processingrequest  message  broken  bytearrayvertexidmessages  thus  message  still  stored  many  time  number  vertex  sent  task  implement  two  messagestores  represent  message  succinct  way  especially  useful  message  significant  size  fanout  low  note  useful  combiners  used  depends  giraph907  giraph908,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
1516,fix  checkpointing  need  make  checkpoiting  giraph  functional  miss  lot  data  many  addition  weve  making  giraph  like  information  workercontextmastercompute  proper  integration  per  superstep  output  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1517,checkpointing  improvement  need  address  issue  checkpointing  1  worker2worker  message  saved  2  bspserviceworker  compile  hadoop023  profile  3  would  nice  able  manually  checkpoint  stop  job  point  time,1,0,1,0,1,0,0,0,0,1,0,0,0,1,0,0,0
1518,allow  state  aggregator  currently  aggregator  specified  via  classaggregator  created  empty  constructor  make  extremely  hard  arrayaggregatorint  n  aggregatora  elementaggregator  specific  instance  need  defined  class  goal  allow,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1519,loosen  modifier  needed  loosen  package  protectedprivate  protected  place  found  need  also  add  immutableclassesgiraphsettable  setconf  getconf  method  since  many  case  one  time  extraction  configuration  needed,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1520,improve  job  tracking  command  line  currently  job  client  connects  zookeeper  us  information  report  progress  command  line  mean  job  fails  way  app  communicate  back  job  client  failed  also  bunch  zookeeper  exception  get  thrown  instead  use  swift  channel  communication  job  client  masterworkers  also  allow  mastercomputeworkercontext  print  info  directly  command  line  useful  report  app  related  progress  debugging,1,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0
1521,upgrade  gora  05  recently  released  gora  05  httpwwwmailarchivecomdev40goraapacheorgmsg05236html  giraph  upgrade  05  better  support  added  module  giraph  take  advantage,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
1522,add  way  ignore  thread  exception  add  way  fail  mapper  exception  happens  non  core  thread  default  still  fail  every  exception,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1523,inproc  zookeeper  server  master  process  currently  default  zookeeper  run  separate  java  process  server  master  run  prevents  u  seeing  zookeeper  log  make  harder  debug  memory  issue  able  run  zookeeper  inside  master  process  perhaps  default,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
1524,command  line  logging  add  logging  command  line  worker  fails  log  worker  failed  worker  low  memory  warn  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1525,way  disable  checkpoint  particular  job  particular  supersteps  currently  impossible  disable  checkpoint  particular  job  example  job  output  computation  support  checkpointing  attempt  made  checkpoint  job  use  case  exist  need  manually  specify  supersteps  checkpointable  particular  job  need  generic  way  configure  job  ability  checkpoint,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1526,improve  naming  reduceoperation  reducesinglereducepartial  slightly  confusing  also  onsamereduceoperation  named  better,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1527,organize  source  code  apache  initial  import  complete  need  organize  source  code  apache  namespace  convention  thing  move  package  name  orgapachegora  add  license  header  edit  readme,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
1528,datastore  goradynamodb  per  comment  gora  dev  mailing  list  per  application  submission  1  idea  page  2  issue  track  start  finish  development  montoring  reviwing  testing  eventual  implementation  goradynamodb  module  gora  1  httpscwikiapacheorgconfluencedisplaygoragsoc2012  2  httpscwikiapacheorgconfluencedisplaygoragsoc2012ideaspage,1,0,1,0,1,0,0,0,1,0,0,0,1,0,0,0,1
1529,change  cassandraclientinit  cassandraclientinitialize  consistency  datastores  make  drawing  comparison  different  datastores  easier  kept  consistent  start  anyway,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1530,goracassandra  array  type  support  order  support  array  goracassandra  two  scenario  follows  1  super  column  family  like  current  map  implementation  2  single  column  store  element  array  senario  pro  con  id  prefer  1  implemented  prototype  1  super  column  family  pro  consistent  map  column  store  primitive  type  value  con  array  cannot  contained  record  map  2  single  column  pro  complex  type  record  map  array  value  con  large  size  array  requres  huge  single  column  value  difficult  implement  string  byte  variable  length  currently  super  column  used  complex  type  record  map  consistent  use  super  column  array  considering  rule  complex  type  cannot  complex  type  value  seems  reasonable  limitation  make  rule  simple  take  1  senario  super  column  family  provide  patch  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1531,creates  orgapachegoracassandraserializers  package  order  clean  code  store  query  package  support  additional  type  future  discussed  gora81  kind  fix  committed  part  gora138  patch  since  one  main  functionality  goracassandra  handle  serializers  seems  good  idea  separate  code  store  query  package  attaching  patch  shortly  1  utf8serializer  make  simple  handle  typestring  2  goraserializertypeinferer  single  point  go  get  serializer  extensible  support  additional  type  future  3  typeboolean  supported,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1532,merge  gora94  gora  trunk  final  issue  merge  gora94  trunk  ill  get  patch  attached  provides  diff  people  apply  gora  trunk  code  base  within  scope  patch  proposing  release  goradynamodb  04  additional  thought  required  get  working  renato2099  discussing  apachecon  address  due  course  would  like  personally  thank  contributor  gora94  branch  recent  month  became  bit  monster  major  contribution  apache  gora,1,1,1,1,1,0,1,0,1,0,1,0,0,0,0,1,1
1533,removal  gdirty  field  allfields  array  field  enum  persistent  class  autogenerated  persistent  class  create  array  field  called  allfields  know  array  also  contains  gdirty  field  stored  field  maybe  remove  gdirty  field  array  since  array  used  getting  field  stored  table  also  remove  field  enum  user  know  gdirty  field,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1534,refactor  goradynamodb  support  avro  serialization  currently  goradynamodb  module  support  dynamodb  serialization  also  support  avro  based  serialization,1,0,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1
1535,upgrade  hbase  098  hbase  098  release  current  stable  release  gora  built  based  hbase  098,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1536,configure  mongodb  readpreference  writeconcern  h5  actual  behavior  current  mongostore  implementation  doesnt  allow  configuration  read  preferencehttpdocsmongodborgmanualcorereadpreference  write  concernhttpdocsmongodborgmanualcorewriteconcern  mongodb  java  driver  h5  proposed  improvement  add  goramongodbreadpreference  goramongodbwriteconcern  property  allow  configuration  store  initialization  please  review  pr  httpsgithubcomapachegorapull28,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
1537,remove  unused  method  parameter  remove  unused  method  parameter  make  api  signature  clean,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1538,avoid  hbase  minicluster  restarts  shorten  gorahbase  test  currently  hbase  test  taking  forever  day  shorten  time  avoiding  minicluster  restarts  implement  cluster  singleton  clean  table  test  scan  deletes  row  much  faster  restarting  cluster  code  referenece  please  see  implementation  here1  class  hbaseclustersingleton  need  refactoring  think  enough  speed  test  thanks  ioan  head  1  httpsvnapacheorgreposasfjamesmailboxtrunkhbasesrctestjavaorgapachejamesmailboxhbase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1539,upgrade  apache  avro  17x  sure  involves  yet  small  feeling  going  reasonably  major  work,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1540,add  support  multiple  distinct  operator  query  block  impala  allows  single  distinct  column  expression  query  colorrednote  need  precise  accuracy  produce  estimate  distinct  value  column  specifying  ndvcolumn  query  contain  multiple  instance  ndvcolumn  make  impala  automatically  rewrite  countdistinct  expression  ndv  enable  appxcountdistinct  query  option  color  code  impala21000  select  countdistinct  iclassid  item  query  select  countdistinct  iclassid  item  query  finished  fetching  result  16  returned  1  row  151s  code  code  impala21000  select  countdistinct  iclassid  countdistinct  ibrandid  item  query  select  countdistinct  iclassid  countdistinct  ibrandid  item  error  comclouderaimpalacommonanalysisexception  analysis  exception  select  countdistinct  iclassid  countdistinct  ibrandid  item  comclouderaimpalaanalysisanalysiscontextanalyzeanalysiscontextjava133  comclouderaimpalaservicefrontendcreateexecrequestfrontendjava221  comclouderaimpalaservicejnifrontendcreateexecrequestjnifrontendjava89  caused  comclouderaimpalacommonanalysisexception  distinct  aggregate  function  need  set  parameter  countdistinct  iclassid  deviating  function  countdistinct  ibrandid  comclouderaimpalaanalysisaggregateinfocreatedistinctagginfoaggregateinfojava196  comclouderaimpalaanalysisaggregateinfocreateaggregateinfojava143  comclouderaimpalaanalysisselectstmtcreateagginfoselectstmtjava466  comclouderaimpalaanalysisselectstmtanalyzeaggregationselectstmtjava347  comclouderaimpalaanalysisselectstmtanalyzeselectstmtjava155  comclouderaimpalaanalysisanalysiscontextanalyzeanalysiscontextjava130  2  code  hive  support  code  hive  e  select  countdistinct  iclassid  countdistinct  ibrandid  item  logging  initialized  using  configuration  fileetchiveconfdisthivelog4jproperties  hive  history  filetmpgrahnhivejobloggrahn2013030522341625576708txt  total  mapreduce  job  1  launching  job  1  1  number  reduce  task  determined  compile  time  1  order  change  average  load  reducer  byte  set  hiveexecreducersbytesperreducernumber  order  limit  maximum  number  reducer  set  hiveexecreducersmaxnumber  order  set  constant  number  reducer  set  mapredreducetasksnumber  starting  job  job2013020815140073  tracking  url  httpimpala50030jobdetailsjspjobidjob2013020815140073  kill  command  usrlibhadoopbinhadoop  job  dmapredjobtrackerm0525mtvclouderacom8021  kill  job2013020815140073  hadoop  job  information  stage1  number  mapper  1  number  reducer  1  20130305  223443255  stage1  map  0  reduce  0  20130305  223449323  stage1  map  100  reduce  0  cumulative  cpu  481  sec  20130305  223450337  stage1  map  100  reduce  0  cumulative  cpu  481  sec  20130305  223451351  stage1  map  100  reduce  0  cumulative  cpu  481  sec  20130305  223452360  stage1  map  100  reduce  0  cumulative  cpu  481  sec  20130305  223453370  stage1  map  100  reduce  0  cumulative  cpu  481  sec  20130305  223454379  stage1  map  100  reduce  0  cumulative  cpu  481  sec  20130305  223455389  stage1  map  100  reduce  100  cumulative  cpu  858  sec  20130305  223456402  stage1  map  100  reduce  100  cumulative  cpu  858  sec  20130305  223457413  stage1  map  100  reduce  100  cumulative  cpu  858  sec  20130305  223458424  stage1  map  100  reduce  100  cumulative  cpu  858  sec  mapreduce  total  cumulative  cpu  time  8  second  580  msec  ended  job  job2013020815140073  mapreduce  job  launched  job  0  map  1  reduce  1  cumulative  cpu  858  sec  hdfs  read  0  hdfs  write  0  success  total  mapreduce  cpu  time  spent  8  second  580  msec  ok  16  952  time  taken  25666  second  code,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
1541,allow  creating  avro  table  without  column  definition  allow  compute  stats  always  work  impalacreated  avro  table  trying  run  compute  stats  table  created  without  column  definition  column  come  avro  schema  partition  key  fails  following  error  messagecode  query  compute  stats  mytable  error  analysisexception  cannot  compute  stats  avro  table  mytable  column  definition  match  avro  schema  missing  column  definition  corresponding  avroschema  column  thefirstcolumn  type  string  position  0  please  recreate  table  column  definition  eg  using  result  show  create  tablecode  feel  somewhat  related  impala867httpsissuesclouderaorgbrowseimpala867  also  understand  workaround  proposed  error  message  thing  proposed  comment  impala867httpsissuesclouderaorgbrowseimpala867  documentation  statesquoteoriginally  impala  relied  user  run  hive  analyze  table  statement  method  gathering  statistic  proved  unreliable  difficult  use  impala  compute  stats  statement  built  ground  improve  reliability  userfriendliness  operationquote  recreate  table  column  definition  hive  metastore  userfriendly  since  compute  stats  built  ground  get  column  list  schema  partition  rather  use  hive  metastore  otherwise  keep  recreating  table  case  use  workaround  efficiently  transfer  partition  new  table  update  per  impala  14  create  table  find  column  avro  schema  still  required  update  column  schema  evolves  least  alter  table  used  change  schema  url  possibly  also  file  hdfs  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1542,compute  stats  new  partitionscolumns  compute  stats  absolutely  necessary  join  query  even  finish  run  extremely  long  completely  understandable  given  table  1000  partition  100  column  frustrating  part  running  compute  stats  twice  second  run  really  faster  first  usecase  add  partition  every  day  rarely  change  schema  would  absolutely  lovely  able  optionally  specify  incremental  option  compute  stats  behavior  skip  computing  stats  partitionscolumns  already  computed  stats  short  would  like  way  tell  impala  trust  stats  computed  past  still  valid  added  data,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1543,pull  common  conjuncts  disjunction  see  tpch  tpcds  predicate  look  like  col  1  col  1  col  1  ands  predicate  col  1  could  pulled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1544,unioning  query  subqueries  could  supported  query  rejected  analysis  could  allowed  noformat  query  select  count  alltypestiny  intcol  select  1  union  select  intcol  alltypestiny  error  analysisexception  unsupported  statement  containing  subqueries  select  count  functionalalltypestiny  intcol  select  1  union  select  intcol  functionalalltypestiny  noformat  noformat  query  select  count  functionalalltypestiny  left  semi  join  select  1  c1  a1  intcol  a1c1  union  select  intcol  functionalalltypestiny  count  4  1  0  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1545,slow  ddl  statement  table  large  number  partition  impala  user  sometimes  report  ddl  statement  eg  alter  table  partition  set  location  taking  multiple  second  5  partitioned  table  large  number  partition  operation  significantly  faster  hive  subsecond  response  time  use  case  2  node  cluster  single  table  24  column  3  partition  key  2500  partition  alter  table  foo  partition  fooi  set  location  hdfs  take  approximately  56sec  02  hive  1  sec  delay  alter  stmt  caused  httpsissuesapacheorgjirabrowsehive5524,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1546,sql  support  cached  replica  impala  support  increasing  cache  replication  factor  table  partition  currently  proposed  way  set  cached  pool  replication  xxx,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1547,impala  need  support  operator  drop  partition  like  hive  hive  alter  table  foo  drop  partitionds  date  also  drop  partition  range  operator  httpsissuesapacheorgjirabrowsehive2908  feature  impala,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
1548,netezza  compatibility  function  math  math  function  improved  netezza  compatibility  cot  dceil  dexp  dfloor  dlog10  dpow  dround  dsqrt  dtrunc  factorial  fpow  radian  see  attachment  link  information,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1549,expand  ctas  allow  partition  clause  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1550,impala  support  cross  join  getting  error  message  attempting  cross  join  error  comclouderaimpalacommonnotimplementedexception  join  requires  least  one  equality  predicate  two  table,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1551,provide  support  registering  permanent  udfs  hive  already  implement  via  hive6047  metastore  support  ready  need  tune  catalog  read  load  startup  otherwise  udfs  lost  catalogd  restart,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1552,consider  replacing  constant  exprs  literal  equivalent  evaluating  expression  every  row  expensive  note  number  taken  debug  build  maybe  issue  release  code  153302desktop  srcclouderaimpala  cdh5trunk  impalashellsh  q  select  12345678  tpchlineitem  b  21  devnull  fetched  6001215  row  6133s  153406desktop  srcclouderaimpala  cdh5trunk  impalashellsh  q  select  cast12345678  double  tpchlineitem  b  21  devnull  fetched  6001215  row  7486s  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1553,support  insert  load  data  s3  impala  query  s3  write  s3  mechanical  change  needed  make  insertload  data  code  use  correct  filesystem  rather  table  base  dir  see  also  impala1816  however  bigger  issue  need  decided  operation  rely  filesystemrename  coordinator  narrow  crash  consistency  window  s3  doesnt  natively  support  rename  rename  actually  copy  delete  slow  prone  failure  defeating  purpose  couple  option  consideredexplored  simply  document  s3  doesnt  give  amount  crash  consistency  b  try  use  multipart  uploading  simulate  effect  since  part  hidden  multipart  committed  c  enhance  metastore  atomically  add  file  ie  s3  object  table  also  region  provide  eventual  consistency  though  maybe  thats  writes  rather  object  creation  maybe  issue,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1554,bad  plan  choice  due  incorrect  number  estimated  host  number  host  plan  node  estimated  run  plan  generation  actual  number  host  query  run  could  different  following  scenario  1  query  accessing  table  nonhdfs  remote  storage  eg  s3  isilon  2  query  aggressive  partition  pruning  3  large  cluster  relative  size  table  scanned  discrepancy  number  estimated  host  actual  number  host  lead  suboptimal  plan  choice  particular  bad  join  strategy  broadcast  v  partitioned  determine  whether  query  running  slow  due  bad  planning  decision  examine  host  field  query  plan  profile  contrast  actual  host  execution  summary,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1555,implement  show  create  function  request  implement  show  create  user  defined  function  originated  customer  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1556,add  support  nested  loop  join  add  support  nested  loop  join  impala  primarily  used  conjunction  nested  type  case  nonequity  join  predicate  used  certain  join  type  example  query  currently  supported  could  executed  nested  loop  join  implemented  code  select  functionalalltypestiny  t1  left  outer  join  functionalalltypessmall  t2  t1intcol  t2intcol  code  also  context  nested  type  following  query  could  executed  using  nested  loop  join  code  select  customer  c  left  outer  join  corders  code,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,1,1
1557,include  database  comment  showing  database  create  databaseschema  statement  allows  one  include  comment  database  however  doesnt  seem  ever  get  displayed  anywhere  within  impala  would  useful  show  database  statement  showed  comment  associated  database  also  hue  metadata  browser  similarly  show  comment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1558,add  percentrank  ntile  cumedist  analytic  window  function  add  common  percentilebased  analytic  function  percentrank  ntile  cumedist  able  implemented  rewrite  planner,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1559,support  nullsafe  equalis  distinct  ansi  sql  distinct  comparison  operator  mysql  called  nullsafe  equal  essence  implement  null  distinct  b  b  null  b  null  distinct  b  b  null  b  null  null  b  null  add  support  variant  httpswikipostgresqlorgwikiisdistinctfrom  httpdevmysqlcomdocrefman50encomparisonoperatorshtmloperatorequalto,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1560,add  support  describe  database  similar  hive  impala  doesnt  seem  currently  support  either  describe  database  dbname  describe  schema  schemaname  syntax  available  hive  httpscwikiapacheorgconfluencedisplayhivelanguagemanualddllanguagemanualddldescribedatabase  would  useful  retrieving  comment  location  additional  metadata  may  added  database,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1561,make  idlesessiontimeout  query  option  currently  processwide  session  timeout  see  idlesessiontimeout  would  useful  also  ability  set  persession  timeouts  taking  parameter  hs2  opensession  call  already  map  property  changing  session  timeout  logic  impalaservercc  could  set  lower  value  client  eg  hue  close  query  automatically  want  ensure  query  arent  left  open  long  time  without  requiring  client  session  timeout,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1562,add  purge  option  drop  table  prior  using  hdfs  encryption  create  encryption  zone  used  hold  data  file  impala  table  would  see  expected  behaviour  drop  table  removing  data  file  table  encryption  used  drop  table  command  succeeds  however  data  file  removed  hive  metastore  log  show  cant  moved  encryption  zone  attempting  remove  data  file  using  hdfs  dfs  rm  produce  message  however  adding  skiptrash  allows  file  removed  basis  adding  purge  option  drop  table  alter  table  drop  partition  result  skiptrash  used  deletion  data  file  would  useful,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1563,extrapolate  number  row  scan  based  rowsbyte  ratio  jira  intended  address  following  problem  partition  may  missing  row  stat  partition  may  row  stat  stale  file  addeddropped  since  computing  row  stat  main  idea  use  available  row  stats  extrapolate  missing  stats  store  additional  statistic  rowsbyte  tblproperties  table  could  also  rowskbyte  whatever  seems  suitable  statistic  computed  part  compute  incremental  stats  impalad  side  shipped  catalogd  stored  metastore  query  planning  use  rowsbyte  statistic  estimate  number  row  scanned  partition  regardless  whether  partition  row  rationale  row  partition  may  outdated  using  rowsbyte  ratio  robust  data  change  augment  show  table  stats  display  stored  row  well  extrapolated  row  way  reporting  stored  rowsbyte  ratio  debugging  purpose  maybe  show  table  stats  explain  additional  consideration  table  could  mixed  format  even  table  format  file  could  compressed  differently  seems  reasonable  ignore  issue  first  cut  nongoals  estimate  statistic  stats  eg  purely  based  file  size  without  knowing  row  extrapolate  column  stats  like  ndv  similar  fashion  much  invasive  change  smaller  impact,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1564,add  endtime  impalad  lineage  output  currently  include  start  time  timestamp  lineage  endtime  useful,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1565,minmax  value  partition  column  tableau  run  minmax  value  column  selected  filtering  determine  filter  range  ui  filter  partition  column  would  great  able  use  partition  metadata  instead  running  full  scan,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1566,introduce  clustered  plan  hint  insert  statement  h4  add  new  clustered  plan  hint  insert  statement  example  code  create  table  dst  partitioned  year  int  month  int  insert  dst  partitionyearmonth  clustered  select  src  code  hint  specifies  data  fed  table  sink  clustered  based  partition  column  well  use  local  sort  achieve  clustering  plan  look  like  scan  sort  yearmonth  table  sink  h4  syntax  behavior  code  insert  dst  partitionyearmonth  clustered  select  src  code  support  legacyhint  style  bracket  codeclusteredcode  hint  obeyed  target  table  partitioned  hdfs  kudu  table  otherwise  ignored  warning  kudu  table  sorting  done  primary  key  h4  making  clustered  default  plan  eventually  want  make  clustered  plan  default  robust  large  insert  many  partition  mind  also  add  corresponding  noclustered  hint  remove  sort  course  hint  anything  change  default  behavior  add  nevertheless  hint  complete,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1567,runtime  filter  forwarding  operator  although  planner  much  reduce  output  cardinality  operator  possible  eg  predicate  pushdown  situation  planner  cannot  apply  selectivitybased  optimisation  execution  engine  based  output  operator  runtime  one  example  dynamic  partition  pruning  filter  computed  join  key  partition  column  build  side  hash  table  propagated  probe  side  scan  scan  simply  skip  partition  dont  appear  filter  opportunity  optimisation  based  runtimecomputed  filter  jira  track  adding  general  mechanism  filter  computation  propagation  backend  corresponding  work  planner  identify  valid  optimisation  opportunity,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1568,impala  read  java  udfs  created  hive  0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1569,complete  alter  ddl  command  support  kudu  supported  operation  include  add  column  nullable  column  may  null  nonnull  default  drop  column  rename  column  rename  table  adddrop  range  partition,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1570,remove  distinction  valueexpr  expr  parser  parseranalyzer  requires  cleanup  regarding  treatment  exprs  predicate  need  unify  type  exprs  including  predicate  expr  production  task  require  moving  work  parser  analyzer  careful  testing,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
1571,raw  param  debug  web  ui  varz  others  similar  query  profile  raw  text  html  param  raw  would  make  easier  people  copy  paste  debug  web  ui  without  formatting  problem  would  personally  like  see  varz  especially  metric  would  useful  probably  worth  adding  url,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1572,add  variant  alter  table  manually  add  column  stats  current  sqls  add  row  stats  partitionednonpartitioned  table  ex  noformat  alter  table  analysisdata  set  tblpropertiesnumrows1001000000  nonpartitioned  alter  table  partitioneddata  set  tblproperties  numrows1030000  partitioned  noformat  something  similar  column  stats,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
1573,consider  changing  arithmetic  conversion  produce  decimal  case  conversion  rule  mixing  decimal  integer  little  confusing  code  select  100  3  code  result  double  decimal  literal  nondecimal  literal  argument  code  select  100  30  code  result  decimal  two  decimal  literal  argument  part  justification  decimal  significantly  slower  double  didnt  want  user  see  sudden  performance  regression  however  weve  since  improved  decimal  performance  lot  consider  revisiting  behaviour  relevant  code  exprconvertnumericliteralsfromdecimal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1574,kudu  connector  use  new  scan  token  api  kudu  09  include  new  feature  called  scan  token  simplify  planning  java  side  creating  scanner  c  side  api  designed  impala  mind  built  serialization  method  scan  token  created  java  side  serialized  rehydrated  scanner  see  design  dochttpsgithubcomapacheincubatorkudublobmasterdocsdesigndocsscantokensmd  high  level  intro  api  mr  input  formathttpsgithubcomapacheincubatorkudublobmasterjavakudumapreducesrcmainjavaorgkududbmapreducekudutableinputformatjava  spark  rddhttpsgithubcomapacheincubatorkudublobmasterjavakudusparksrcmainscalaorgkududbsparkkudukudurddscala  usage  example,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1575,range  based  pruning  inpredicate  inpredicates  long  inlists  tpcdsq8  may  benefit  finding  min  max  list  use  prune  unqualified  scan  range  filter  row  dont  fall  range,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1576,support  virtual  view  using  create  view  statement  add  support  virtual  view  using  syntax  similar  mysqls  httpdevmysqlcomdocrefman50encreateviewhtml,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
1577,support  kudu  upsert  impala  add  upsert  impala  also  includes  addingupdating  relevant  functional  test  stress  test  query  generator  test  may  impact  statistic  story  tbd  stats  work  tracked  impala2830  add  syntax  work  like  insert  kudu  table  specifying  kudu  perform  upsert  rather  insert  code  upsert  table  column  value  valueexpression  upsert  table  column  select  selectexpression  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1578,add  support  load  data  statement  would  good  support  load  data  command  impala  load  operation  transformation  data  pure  copymove  operation  syntax  code  load  data  local  inpath  filepath  overwrite  table  tablename  partition  partcol1val1  partcol2val2  code  local  specified  command  move  data  given  location  tablepartition  storage  location  local  specified  data  copied  local  file  system  impala  need  support  loading  hdfs  location  loading  local  path  may  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
1579,support  clause  factor  subqueries  main  query  example  using  clause  code  t1  select  c1  c2  x  t2  select  b  c  select  t1  t2  t1c1  t2a  code  t1  t2  essentially  subqueries  written  clause  support  recursive  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1580,support  column  permutation  insert  would  good  support  following  code  insert  tblbcda  select  code  ie  permutation  column  select  make  easier  write  correct  insert  statement,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
1581,tuning  parameter  impala  hbase  integration  impala  hbase  integration  tuning  query  sent  hbase  particular  particular  scan  cache  size  disabling  block  cache  parameter  documented  performance  query  also  wider  hbase  platform  disabling  block  cache  result  prevents  churn  region  server  heap  scanner  cache  reduces  round  trip  normally  set  via  setcacheblocks  setcaching  method  scanner  api,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1582,make  refresh  command  sql  statement  rather  rpc  would  good  make  refresh  firstclass  sql  statement  rather  rpc  would  allow  user  submit  refreshes  outside  impalashell  example  via  jdbcodbc  initially  would  need  support  full  catalog  refresh  well  tablelevel  refresh  refresh  refresh  table  name  impala339  may  introduce  additional  syntax  choose  reload  refresh  covered  well  part  change  impalashell  updated  submit  refreshes  using  regular  query  api  rather  calling  resetcatalogresettable,1,0,1,0,1,0,1,1,0,0,0,0,0,0,0,0,1
1583,catalogservicecatalogextractfunctions  log  underlying  exception  failing  load  function  code  path  httpsgithubcomclouderaimpalablobcdh5trunkfesrcmainjavacomclouderaimpalacatalogcatalogservicecatalogjaval437l442  log  reason  failure  copy  look  like  httpsgithubcomclouderaimpalablobcdh5trunkfesrcmainjavacomclouderaimpalacommonfilesystemutiljaval374l382  swallow  exception  make  harder  find  root  cause,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1584,impala  show  create  table  statement  currently  show  create  table  statement  impala  would  useful  thanks  hari,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1585,add  support  user  authorization  currently  hdfs  table  access  done  impala  user  even  kerberized  environment  impala  need  support  different  way  control  access  data  cluster  different  area  includes  1  sql  statement  authorization  server  object  database  table  uris  etc  need  mechanism  restrict  access  set  different  access  level  user  cluster  2  need  ability  user  impersonation  similar  hive  well  acl  control  different  table  different  usersgroups  cover  use  case  multiple  group  within  biz  sharing  hdfs  cluster  impala  without  lack  access  control  table  deal  breaker  could  provide  rough  timeline  think  feature  could  implemented,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,1,1
1586,introduce  sort  clause  create  table  statement  issue  intended  usability  improvement  impala4163  sort  column  specified  directly  table  definition  like  code  create  table  day  int  hour  int  partitioned  year  int  month  int  sort  day  hour  code  table  creation  effect  insert  table  implicit  sortbydayhour  plan  hint  applied  see  impala4163  detail  hint  like  sortby  hint  sort  clause  contain  nonpartition  column  hdfs  table  nonprimary  key  column  kudu  table  following  benefit  user  remember  put  sortby  hint  insert  statement  sort  column  physical  design  choice  make  sense  store  part  table  metadata  convenience  feature  effect  sortby  hint  insert  statement  doesnt  require  user  remember  include  hint  every  insert  statement  challenge  hive  metastore  sort  concept  well  need  store  information  generic  tblproperties  map  engine  hive  spark  understand  table  property  mean  data  written  engine  require  explicit  sorting  hint  far  thats  available,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1587,support  insert  plan  hint  create  table  select  order  tune  etl  process  also  support  plan  hint  create  table  select  ctas  statement  already  support  insert  statement  otherwise  convenience  ctas  may  somewhat  lost  generated  data  may  efficient  could  create  insert  hint  placement  hint  oracle  syntax  code  create  clustered  sortdayhour  table  select  src  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1588,adopt  oraclestyle  hint  placement  insert  statement  consistency  oracle  consider  accepting  hint  place  sql  statement  example  current  insert  statement  accepts  hint  right  select  portion  code  insert  partitionedyearmonth  hint  select  src  code  proposal  accept  hint  immediately  insert  like  oracle  code  insert  hint  partitionedyearmonth  select  src  code  ideally  would  accept  hint  multiple  place  avoid  confusion  reduce  code  testing  burden  ceasing  recognize  old  hint  placement  backwards  incompatible  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1589,impala  build  latest  hadoop  component  hive  2  hadoop  3  hbase  3  made  breaking  api  change  issue  track  progress  getting  impala  build  new  apis,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1590,dont  abort  catalog  startup  quickly  hm  present  catalog  daemon  cant  contact  hm  startup  fail  catalog  constructor  metastoreclientpooladdclients  might  consider  instead  retry  longer  time  allow  catalog  hm  started  concurrently,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1591,introduce  expr  rewrite  phase  address  issue  like  impala1286  introduce  new  expr  rewrite  phase  analyzed  exprs  transformed  rule  new  phase  could  similar  subquery  rewrite  phase  transform  exprs  inplace  reset  analyze  whole  statement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1592,specify  option  adding  new  kudu  column  currently  due  limitation  kudu  api  impala  imposes  number  constraint  new  column  1  nullable  column  cant  default  value  kudu1747  2  encodingcompressionblock  size  specified  kudu1746  kudu  jiras  resolved  remove  constraint  impala  side,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1593,remove  duplication  isconstant  isconstant  frontend  backend  currently  exprisconstant  exprisconstant  frontend  backend  duplicate  logic  exactly  analysis  need  kept  exactly  sync  avoid  problem  plumb  value  isconstant  frontend  avoid  duplication  need  little  careful  frontend  alex  behn  mentioned  storing  state  exprs  risky  also  naively  calling  isconstant  expr  node  problematic  since  could  result  traversing  expr  tree  many  time,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1594,support  changing  kudu  default  storage  attribute  add  impala  support  code  kudu861  support  changing  default  storage  attribute  patch  add  support  adding  changing  removing  column  default  changing  storage  attribute  column  change  column  encoded  columnschemadelta  merged  columnschema  change  changing  type  nullability  column  still  unsupported  failure  100  iteration  altertablerandomizedtest  also  ran  issue  altering  rle  column  1  add  rleencoded  column  table  2  alter  column  3  scan  column  3  cause  check  failure  scanning  po  0  empty  rle  block  test  fix  included  changeid  i457d99ba2188ef6e439df47c0d94f2dc1a62ea6c  reviewedon  httpgerritclouderaorg80804310  testedby  kudu  jenkins  reviewedby  dan  burkert  danburkertapacheorg  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1595,add  dictionary  filtering  parquet  scanner  efficiently  process  highly  selective  scan  query  using  partition  pruning  coarse  grain  due  limit  number  partition  selective  scan  often  impala  simply  check  value  parquet  dictionary  page  determine  whole  row  group  thrown,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1596,impalad  open  21000  21050  port  till  catalog  received  currently  impalads  open  frontend  connection  result  query  failure  preferred  behaviour  would  port  remain  closed  till  catalog  received  reason  s  connectivity  established  reasonable  attempt  timeouts  impalad  simply  shut  code  impaladinfoi1216  173940437333  10463  jniutilcc166  comclouderaimpalacommonanalysisexception  impala  daemon  ready  accept  user  request  status  waiting  catalog  update  statestore  impaladinfoi1216  173940438743  10463  statuscc112  analysisexception  impala  daemon  ready  accept  user  request  status  waiting  catalog  update  statestore  impaladinfoi1216  173940918184  10464  jniutilcc166  comclouderaimpalacommonanalysisexception  impala  daemon  ready  accept  user  request  status  waiting  catalog  update  statestore  impaladinfoi1216  173940918994  10464  statuscc112  analysisexception  impala  daemon  ready  accept  user  request  status  waiting  catalog  update  statestore  impaladinfoi1216  173944129482  10465  jniutilcc166  comclouderaimpalacommonanalysisexception  impala  daemon  ready  accept  user  request  status  waiting  catalog  update  statestore  code  help  especially  multiple  impalad  behind  lb  connection  directed  daemon  catalog  serversimpala  service  restarted  reason,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1597,hdfs  scan  operate  constrained  number  io  buffer  hdfs  scan  node  able  operate  fixed  number  io  buffer  case  excluding  large  row  modify  claim  reservation  upfront  use  disk  io  probably  also  requires  switching  diskiomgr  allocate  memory  bufferpool,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1598,simplify  code  fileblock  metadata  loading  manually  calling  listlocatedstatus  partition  fix  impala4172impala3653  us  hadoops  filesystemlistfiles  api  recursively  list  file  hdfs  table  parent  directory  map  file  corresponding  partition  however  use  listfiles  associated  code  filetopartition  mapping  really  make  sense  listfiles  recursive  wrapper  around  listlocatedstatus  table  10k  partition  10k  rpcs  listlocatedstatus  simplify  code  loop  partition  call  listlocatedstatus  following  benefit  simper  code  would  avoided  bug  like  impala4789  faster  code  need  map  file  partition  easier  parallelize  future  easier  decouple  table  partition  loading  future  keep  mind  s3  table  want  use  listfiles  api  avoid  throttled  s3  relevant  link  httpsgithubcomapachehadoopblobbranch260hadoopcommonprojecthadoopcommonsrcmainjavaorgapachehadoopfsfilesystemjaval1720  httpsgithubcomapachehadoopblobbranch260hadoophdfsprojecthadoophdfssrcmainjavaorgapachehadoophdfsdistributedfilesystemjaval766,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1599,evaluate  parquetstatistics  skip  data  nested  type  impala2328  add  read  support  minmax  statistic  scalar  column  also  add  support  skipping  row  group  based  predicate  nested  field,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1600,add  support  dictionary  filtering  nested  field  parquet  dictionary  filtering  currently  support  nonnested  data  would  useful  able  filter  nested  data  filtering  happen  value  nested  data  required  nonempty,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1601,missed  opportunity  static  partition  pruning  coalesce  tbh  im  sure  general  issue  rather  attempting  express  abstractly  possible  ill  start  specific  example  apology  advance  formattinghorrible  jira  artist  code  create  two  table  main  point  t1  2  partition  create  table  t1  int  partitioned  part  int  create  table  t2  int  partitioned  part  int  insert  t1  part  value  1  1  2  2  insert  t2  part  value  1  1  2  2  query  1  coalesce  t1  partition  column  literal  value  â€”  partition  pruning  kick  explain  result  select  coalescet1i  t2i  coalescet1part  666  part  t1  full  outer  join  t2  t1i  t2i  select  result  part  1  query  explain  result  select  coalescet1i  t2i  coalescet1part  666  part  t1  full  outer  join  t2  t1i  t2i  select  result  part  1  explain  string  snip  00scan  hdfs  defaultt1  partitions12  files1  size2b  note  partition  scanned  query  2  coalesce  t1  partition  column  dynamic  value  â€”  partition  pruning  kick  explain  result  select  coalescet1i  t2i  coalescet1part  t2part  part  t1  full  outer  join  t2  t1i  t2i  select  result  part  1  query  explain  result  select  coalescet1i  t2i  coalescet1part  t2part  part  t1  full  outer  join  t2  t1i  t2i  select  result  part  1  explain  string  snip  00scan  hdfs  defaultt1  partitions22  files2  size4b  note  partition  scanned  code  query  applying  filter  predicate  column  defined  follows  coalescet1part  since  t1part  partition  column  t1  every  row  t1  nonnull  value  t1part  furthermore  t1part  appears  first  parameter  coalesce  every  row  result  set  contains  data  t1  get  part  value  t1  thus  t1  data  result  set  subject  filter  predicate  t1part  ie  t1  partition  part1  could  pruned  query  planning  question  wrong  reasoning  missing  something  fundamentalobvious  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1602,improve  concurrency  ddldml  operation  catalog  update  currently  long  running  ddldml  operation  block  operation  making  progress  run  concurrently  getcatalogobjects  call  creates  catalog  update  reason  getcatalogobjects  hold  lock  entire  duration  also  try  acquire  lock  table  process  operation  blocked  another  operation  table  unrelated  catalog  write  operation  cannot  make  progress  cannot  acquire  catalog  lock  held  getcatalogobjects  usersâ  point  view  concurrent  ddldml  operation  executed  serially  consequently  latency  ddldml  operation  may  vary  significantly  fix  issue  concurrent  ddldml  operation  allow  run  concurrently  throughput  operation  increase  significantly  time  latency  ddldml  operation  depend  operation  running  time  important  note  talk  latency  operation  respect  coordinator  initiate  operation  fix  doesnt  anything  improve  latency  broadcasting  metadata  change  statestore  common  user  case  fix  applicable  following  concurrent  refresh  operation  onâ  different  tablesâ  concurrent  alter  table  operation  onâ  different  table,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
1603,reduce  number  kudu  client  get  created  creating  kudu  client  expensive  fetch  metadata  kudu  master  reduce  load  kudu  master  reusing  kudu  client  possible  start  use  single  client  entire  another  entire  fe  dependent  metadata  invalidation  improvement  kudu  httpsgerritclouderaorgc6719,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1604,simplify  remaining  constant  conditionals  recent  change  impala1861  added  simplifyconditionalsrule  simplifies  conditional  function  constant  condition  eg  true  0  1  0  rule  currently  cover  case  decode  extend  cover  conditionals  coalesce  ifnull  istruefalse  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1605,coalesce  chain  condition  predicate  would  nice  implement  exprrewriterule  coalesces  multiple  compatible  condition  predicate  eg  code  c1  c2  c3  c4  c  1  2  3  4  code  long  chain  generally  unwieldy  transforming  following  benefit  predicate  long  value  list  evaluated  olog  n  lookup  easier  extract  minmax  value  predicate  parquet  minmax  filtering  predicate  may  faster  codegen  deep  binary  tree  or  note  new  rule  complement  existing  rule  yield  interesting  improvement  eg  code  c11  c2a  c12  c2a  c13  c2a  c2a  c1  1  2  3  code  ive  attached  relevant  query  profile  one  mostafas  experiment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1606,add  query  option  control  join  strategy  table  stats  impala5120  join  strategy  changed  bcast  shuffle  table  stats  adding  query  option  specify  behavior  lower  risk  user  may  come  rely  behavior  would  allow  revert  back  previous  behavior  query  option  proposal  noformat  defaultjoindistributionmode  broadcast  shuffle  noformat  ideally  default  would  shuffle  spirit  preserving  existing  behavior  stay  broadcast  reevaluate  choice  compatibilitybreaking  release,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1607,consider  automatically  disabling  codegen  entire  query  based  planner  estimate  consider  automatically  disabling  codegen  entire  query  relatively  row  processed  would  improve  response  time  query  big  single  node  optimisation  dont  benefit  codegen,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1608,improve  join  cardinality  estimation  robust  fkpk  detection  jira  tracking  improvement  joincardinality  estimation  particular  improve  handling  manytomany  join  multicolumn  join  understood  case  cannot  reliably  detected  limited  metadata  statistic  try  best  given  limitation  improving  cardinality  estimation  new  metadata  statistic  tracked  elsewhere  eg  impala2416  impala3531,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1609,join  inversion  avoid  reducing  degree  parallelism  degree  internode  parallelism  join  determined  left  input  inverting  join  planner  mindful  inversion  affect  parallelism  example  left  join  input  may  reduced  joining  several  dimension  table  much  becomes  smaller  right  handside  another  small  dimension  table  inverting  join  degree  parallelism  may  reduced  one  node  based  many  node  righthand  size  executed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1610,disallow  managed  kudu  table  explicitly  set  kudu  tbl  name  create  table  there  reason  allow  behavior  managed  table  create  kudu  table  name  kudu  impaladbnametablename  renaming  impala  managed  kudu  table  result  renaming  underlying  kudu  table  eg  rename  tablename  newtable  name  result  changing  kudu  table  impaladbnamenewtablename  allowing  new  table  specify  kudu  table  name  inconsistent  renaming  behavior  introduces  opportunity  confusion  code  private  void  analyzemanagedkudutableparamsanalyzer  analyzer  throw  analysisexception  kudu  table  name  specified  tblproperties  generate  one  using  current  database  prefix  avoid  conflict  kudu  todo  disallow  setting  manually  managed  table  gettblpropertiescontainskeykudutablekeytablename  gettblpropertiesputkudutablekeytablename  kuduutilgetdefaultcreatekudutablenamegetdb  gettbl  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1611,support  orc  format  file  hulu  supported  orc  format  file  version  impala  accept  feature  weâ€™re  willing  contribute  community,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1612,create  table  validate  directory  permissionsexistence  part  location  path  analysis  check  create  table  statement  validate  existence  permission  location  path  path  exist  impala  cannot  access  likely  typo  ddl  stmt,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1613,dont  synthesize  block  metadata  catalog  s3adls  today  catalog  synthesizes  block  metadata  s3adls  breaking  splittable  file  block  filesystems  default  block  size  rather  carrying  block  around  catalog  distributing  impalads  might  well  generate  scan  range  onthefly  planning  would  save  memory  network  bandwidth  block  mean  planner  instantiate  call  filesystem  get  default  block  size  filesystems  thats  matter  reading  config  perhaps  done  hdfs  erasure  coding  though  depends  block  location  actually  mean  context  whether  contain  useful  info,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1614,endtoend  compression  metadata  metadata  large  table  become  quite  big  making  costly  hold  statestore  disseminate  coordinator  impalads  metadata  even  get  big  fundamental  limit  like  jvm  2gb  array  size  thrift  4gb  hit  lead  downtime  reducing  statestore  metadata  topic  size  existing  compactcatalogtopic  flag  lz4  compress  metadata  payload  c  codepaths  catalogdstatestore  statestoreimpalad  unfortunately  metadata  compressed  way  febe  transition  catalogd  befe  transition  impalad  goal  change  enable  endtoend  compression  full  path  metadata  dissemination  existing  code  path  also  need  significant  cleanupstreamlining  ideally  new  code  provide  consistent  size  limit  everywhere,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1615,update  describe  statement  respect  column  level  privilege  currently  user  granted  select  subset  column  table  describe  command  show  column  describe  formattedextended  allowed  change  would  update  describe  command  user  select  subset  column  show  data  column  user  access  toâ  describe  formattedextended  user  column  access  column  location  view  text  would  removed  additional  metadata  purpose  change  increase  consumability  allowing  tool  allow  user  browse  data  creating  report  present  column  access  toâ  also  security  aspect  fix  exposing  additional  dataâ  statement  show  column  stats  handled  separate  jira  opened  â,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1616,profile  statement  contain  query  compilation  timeline  statement  seem  include  query  compilation  timeline  query  profile  repro  code  create  table  int  describe  load  table  fe  timeline  profile  invalidate  metadata  alter  table  set  tbpropertiesnumrows10  load  table  fe  timeline  profile  code  statement  include  planner  timeline,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1617,support  select  values1122  might  consider  postgres  support  select  value  list  tuples  way  avoid  writing  laborious  union  clause  issue  probably  implemented  parser  rewrite  httpsissuesclouderaorgbrowseimpala66,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1618,clean  test  authorizationtest  test  authorizationtest  refactored  condensed  also  need  increase  code  coverage  also  good  idea  refactor  test  provideâ  flexibility  supporting  test  userlevel  privilege  futureâ  httpsissuesapacheorgjirabrowseimpala6794,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1619,remove  builtins  db  catalogd  currently  builtinsdb  created  catalogd  initialization  later  catalogd  call  reset  catalogd  replace  dbcache  db  hm  result  delete  builtinsdb  operation  always  initial  catalog  update  sent  statestore  though  statestore  doesnt  send  impalad  initial  catalog  delta  doesnt  include  delete  operation  potential  problem  remove  builtins  db  catalogd  needed,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
1620,add  jvm  pause  monitor  impala  process  impala3114  added  pause  monitor  impala  addition  portborrow  hadoops  jvmpausemonitor  httpsgithubcomapachehadoopblobtrunkhadoopcommonprojecthadoopcommonsrcmainjavaorgapachehadooputiljvmpausemonitorjavaâ  believe  jvm  aggressively  gcing  c  thread  continue  get  scheduled  wont  log  java  one  log  ive  definitely  seen  jvmpausemonitor  accurate  many  time  bharathv  testing  able  reproduce  triggering  jvm  half  gc  hell,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1621,include  number  required  thread  explain  plan  impala  internal  notion  required  thread  execute  fragment  eg  fragment  execution  thread  first  scanner  thread  possible  compute  number  required  thread  per  fragment  instance  based  plan  include  resource  profile  expose  explain  plan  could  step  toward  implementing  something  like  impala6035,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1622,remove  impalaminiclusterprofile2  based  discussion  httpslistsapacheorgthreadhtml49f9b68ed3d6d2c0fdee16a877b259922545e4824e1233479227a6573cdevimpalaapacheorg3e,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1623,automatically  choose  memlimit  based  estimate  clamped  range  add  admission  control  support  intelligently  choosing  much  memory  give  query  based  memory  estimate  currently  require  set  single  memlimit  per  pool  instead  would  better  allowed  configuring  minmax  guardrail  within  admission  control  chose  amount  memory  allow  good  performance  initially  think  memlimit  backends  eventually  could  make  sense  different  limit  per  backend  depending  fragment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1624,intern  hdfsstoragedescriptors  every  partition  currently  hdfsstoragedescriptor  attached  case  number  unique  storage  descriptor  warehouse  pretty  low  partition  use  escaping  file  format  etc  example  functional  test  data  load  24  unique  sd  across  10k  partition  object  take  32  byte  compressed  oops  40  without  get  small  memoryobjectcount  saving  interning,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1625,least  one  equality  predicate  error  message  need  improvement  get  error  message  join  equality  predicate  comclouderaimpalacommonnotimplementedexception  join  requires  least  one  equality  predicate  two  table  two  problem  query  select  aboolcol  alltypessmall  alltypessmall  b  aintcol  bintcol  aboolcol  bboolcol  least  one  equality  predicate  since  part  disjunction  accepted  impala  would  good  print  name  table  since  multiway  join  often  complex  pinpointing  missing  predicate  tricky,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1626,make  num  retries  inconsistentmetadatafetchexception  configurable  currently  hardcoded  10  inconsistentmetadatanumretries,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1627,improve  partition  pruning  time  impala  roughly  prune  10k  partition  per  sec  huge  table  might  30k  partition  query  tight  sla  partition  pruning  time  significant  hive  partition  pruning  faster  impala,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1628,clean  riotreader  riotreader  lot  deprecated  function  historical  reason  visible  public  api  package  1  migrate  deprecated  function  riotparsers  oajriotlang  2  use  rdfdatamgr  ever  possible  3  clean  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1629,algebra  execution  join  library  jira  refactoring  adding  join  algorithm  join  library  join  result  intermediate  pattern  join  solve  basic  graph  pattern  normal  use  index  join  algorithm  requirement  variable  scope  arq  fall  back  general  join  mechanism  scoping  requirement  arent  met  unusual  general  join  code  good  example  hash  join  possible  relation  jena266  hashbased  antijoin  code  orgapachejenasparqlengineindex  support  minus  proposal  combine  code  join  library  immediately  clear  code  cover  case  inner  join  left  join  antijoin  really  good  idea  lead  excessively  complicated  code,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
1630,clean  riot  iri  handling  general  cleaning  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1631,add  support  sparql  11  list  sugar  format  add  ability  process  clause  like  b  c  foo  bar  per  httpwwww3orgtr2013recsparql11query20130321collections,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1632,iter  add  document  add  takewhile  clean  improvement  iter  related  iterators  documentation  takewhile  takeuntil  dropwhile  dropuntil  deprecate  operation  collection  better  done  java8  stream  rework  iteratortruncate  use  iteratorslotted  equivalent  machinery,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1633,remove  datasetgraphcaching  class  seems  nothing  much  add  complexity  caching  datasetimpl  competes  caching  nowadays  jena  storage  system  using  graphview  lightweight  caching  creation  graph  beneficial  cache  concurrent  transaction  safe  internal  class  datasetgraphcachinghelper  used  sdb  helper  could  moved  sdb,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1634,improve  jenabase  libtuple  tuples  immutable  valueequality  fixed  length  sequence  instance  type  accessed  index  like  immutable  equal  based  content  could  improved  work  independently  original  use  tdb  proposal  make  tuple  interface  simpler  current  special  implementation  low  number  element  columnmap  tuplemap  sort  naming  much  possible  use  way  manage  index  mapping  rewriting  tuples  intermediate  step  move  columnmap  tdb  proposal  add  triple  quad  triple  3length  tuplenode  triple  element  accessed  name  getsubject  etc  index  spo  one  possible  order  think  triple  special  status,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1635,support  alternative  queryparsers  jenatext  jenatext  currently  hardwired  use  lucene  queryparser  parser  intentionally  limited  doesnt  analyze  wildcard  query  instead  expanded  directly  problem  want  accentinsensitive  wildcard  query  using  asciifoldingfilter  wildcard  query  rely  special  analyzer  however  lucene  offer  alternate  parser  analyzingqueryparser  could  used  case  id  like  extend  jenatext  configuration  parameter  allows  using  analyzingqueryparser  instead  standard  queryparser  example  configuration  could  look  like  noformat  indexlucene  texttextindexlucene  textdirectory  filelucene  textqueryparser  textanalyzingqueryparser  textqueryanalyzer  textconfigurableanalyzer  texttokenizer  textkeywordtokenizer  textfilters  textasciifoldingfilter  textlowercasefilter  textentitymap  entmap  noformat  ive  written  preliminary  code  implement  im  yet  satisfied  bit  problematic  parser  cannot  constructed  advance  must  dynamically  created  separately  query  need  parameter  differ  query  thus  textindexconfig  must  store  information  parser  variant  use  actual  queryparseranalyzingqueryparser  instance  isnt  rocket  science  though  maybe  kind  factory  pattern  would  work  background  needed  see  skosmos  issue  httpsgithubcomnatlibfiskosmosissues424,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1636,provide  uniondefaultgraph  graph  provide  uniondefaultgraph  graph,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1637,riot  command  provide  exit  code  validating  see  discussion  user  httpslistsapacheorgthreadhtmlf2ec45ff2ddf91b39270b2c23062b92af1817c8d0ac42af928cbdb5b3cusersjenaapacheorg3e,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1638,independently  configurable  bulitinregistry  jena  rule  engine  appealing  case  jena  rule  engine  use  rule  trigger  set  action  rule  head  create  side  effect  java  universe  consider  1  constructing  populating  java  data  structure  rule  head  2  use  rule  engine  reactive  scenario  change  outside  world  inserted  graph  fact  triggering  action  distributed  system  head  case  like  creation  new  set  builtins  could  occur  somewhat  frequently  efficiency  matter  dont  like  idea  registered  central  registry  pas  builtin  parameter  resource  factory  advised  method  configuration  add  setter  genericrulereasoner  concern  orderofoperations  involving  initialization  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0
1639,provide  embedded  fuseki  server  use  java  command  line  standalone  server  launched  java  full  server  embedded  server  would  without  dependency  filing  system  run  area  run  without  ui  web  page  admin  servlets  external  configuration  file  word  service  datasets  configured  java,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1640,control  flushing  commit  log  based  journal  size  see  discussion  thread  httpslistsapacheorgthreadhtmlb992db7e843e1444d2c4835ac9ece41bee2b251a60785d8881452b953cusersjenaapacheorg3e  tdb  batch  commits  save  overhead  small  update  however  application  continually  making  large  commits  batching  save  little  cause  temporary  resource  consumption  ram  especially  may  also  cause  jitter  performance  due  large  update  main  database,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1641,provide  transaction  promotion  jira  add  ability  read  transaction  promote  write  transaction  api  change  necessary  expose  feature  properly  uniformly  pr  161  provides  machinery  tdb  avoid  general  api  change  outside  tdb  happens  automatically  datasetgraphtransactiongetw  enabled  default  isnt  pr  make  change  behaviour  tdb  default  need  enabled  datasetgraphtransactionpromotion  true  pr161  contain  internal  change  eg  datasetgraphwrapper  outside  tdb  lead  towards  general  begin  transaction  jira  cover  discussion  api  record  change  subsystem,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
1642,add  method  resource  class  look  property  specific  language  would  convenient  orgapachejenardfmodelresource  interface  method  code  public  statement  getproperty  property  p  string  lang  public  statement  getrequiredproperty  property  p  string  lang  code  theyd  work  like  much  like  orgapachejenardfmodelmodelconliststatementsresource  property  string  string  would  simplify  query  resource  languagespecific  property,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1643,upgrade  text  search  latest  lucene  currently  lucene  491  quite  outdated  compared  latest  lucene  621  note  project  add  simple  completion  feature  addition  existing  simple  search  would  better  updated  lucene  dependency,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1644,add  support  value  selectbuilder  seems  querybuilder  lacking  support  building  value  block  obvious  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1645,elastic  search  support  apache  jena  text  jira  track  development  jena  text  elasticsearch  implementation  goal  extend  jena  text  capability  index  scale  elasticsearch  implementation  would  similar  lucene  solr  implementation  use  e  version  521  implementation  following  functionality  would  supported  indexing  literal  value  updating  indexed  value  deleting  indexed  value  custom  analyzer  support  configuration  using  assembler  well  java  technique,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1646,provide  detailed  setup  riot  parsing  parser  builder  provide  parser  builder  detailed  setup  rdfparser  new  low  level  interface  parsing  process  replaces  extends  machinery  hidden  inside  rdfdatamgr  process  getreader  rdfparserregistryreaderriotlang  aligns  change  httpop  specific  optional  httpclient  jena576  related  work  allows  application  control  http  setup  without  resorting  direct  use  httpop  detailed  control  exposed  including  language  specific  specialized  need  example  pr211  preserve  id  blanknodes  jsonldhttpsgithubcomapachejenapull211  rdfdatamgr  function  involving  context  deprecated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1647,languagespecific  collation  arq  discussedhttpmarkmailorgmessagev2bvsnsza5ksl2cv  user  mailing  list  october  2016  would  like  change  arq  collation  literal  value  languageaware  respect  languagespecific  collation  rule  would  probably  involve  changing  least  nodeutilscompareliteralsbysyntaxhttpsgithubcomapachejenablobmasterjenaarqsrcmainjavaorgapachejenasparqlutilnodeutilsjaval199  method  currently  sort  lexical  value  first  language  tag  since  collation  order  need  stable  across  possible  literal  value  think  safest  way  would  sort  language  tag  first  lexical  value  according  collation  rule  language  subtags  like  enus  ptbr  different  collation  rule  main  language  would  bit  strange  enus  literal  sorted  en  literal  would  good  check  dydra  possibly  take  approach  see  message  linked  backgound  ive  talking  kinow  may  interested  implementing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1648,provide  detailed  setup  riot  output  writer  builder  companion  jena1306  rdfparserbuilder  current  writing  process  flexible  parsing  initially  basic  placeholder,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1649,queryiterroot  overloaded  initial  binding  queryiterroot  also  used  initial  binding  code  sometimes  assumes  root  binding  join  identity  iterator  one  row  column  queryiterroot  reserved  case  queryiterator  could  method  isjoinidentity  iterator  tested  without  peeking  without  assuming  java  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1650,fuseki  maintenance  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1651,embedded  fuseki  testing  usage  provide  serverctl  see  full  server  fuseki1  test  cycle  support  enable  possibility  security  embedded  fuseki  testing  purpose,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1652,performance  regression  modelremovemodel  method  modelremovemodel  work  slow  large  model  propagates  graphutildeletefromgraph  graph  computes  size  target  graph  iterating  triple  computation  take  nearly  100  time  modelremovemodel  operation  seems  commit  introduced  issue  httpsgithubcomapachejenacommit781895ce64e062c7f2268a78189a777c39b92844difffbb4d11dc804464f94c27e33e11b18e8  due  bug  deletion  concept  scheme  large  ontology  may  take  several  minute,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1653,configurable  resultset  reading  writing  pattern  rdfparser  rdfwriter,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,1
1654,transaction  promotion  expose  transaction  promotion  capability  tim  tdb  tdb2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1655,refactor  fuseki  configuration  make  faciities  available  embedded  server  allow  fuseki  basic  server  process  server  section  full  fuseki  configuration  file,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
1656,working  blank  node  fuseki  able  work  blank  node  client  fuseki  server  ticket  mainly  pulling  together  existing  mechanism  would  new  rdfconnectionfactory  function  return  rdfconnection  right  setting  presevring  blank  node  id  new  rdfconnectionfuseki  subclass  rdfconnectionremote  handle  right  setting  simply  option  rdfconnectionremote  place  future  fusekispecific  operation  â  working  fuseki  remote  use  rdf  thrift  rdf  result  set  form  efficiency  preserve  blank  node  id  â,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1657,allow  setting  rdfxml  reader  property  using  riot  riot  currently  mechanism  setting  arp  jena  rdfxml  parser  property  parser  arp  property  set  riotarp  bridge  readerriotrdfxml  mechanism  passing  propertyvalue  setting  arp,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1658,add  configurable  filter  tokenizers  support  jena1488httpsissuesapacheorgjirabrowsejena1488  issue  proposes  add  feature  allow  including  definedâ  filter  tokenizers  similar  definedanalyzer  configurableanalyzer  allowingâ  configurableâ  argument  excludechars  ive  looked  configurableanalyzer  assembler  straightforward  would  add  tokenizer  filter  definition  textindexlucene  similar  support  adding  analyzer  codejava  textdefinefilters  textdefinefilter  foo  textfilter  textgenericfilter  textclass  fifintofoldingfilter  textparams  textparamname  excludechars  textparamtype  texttypestring  textparamvalue  whatevercharstoexclude  code  genericfilterassembler  generictokenizerassmbler  would  make  use  much  code  genericanalyzerassembler  change  configurableanalyzer  configurableanalyzerassembler  straightforward  mostly  involve  retaining  resource  uri  rather  extracting  localname  addition  willâ  make  easy  create  new  tokenizers  filter  could  dropped  adding  class  onto  jenafuseki  classpath  referring  one  already  included  jena  via  lucene  otherwise  putting  appropriate  assembler  bit  configuration,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
1659,allow  addition  transaction  component  initial  setup  currently  tdb1  set  transactionlifecycle  component  fixed  tdb2  set  transactioncomponents  frozen  creation  dataset  order  able  add  text  index  transaction  handling  allow  new  item  added  carefully  transaction  subsystem  dataset  necessary  jena1302,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1660,support  bz2  compression  parsing  loading  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1661,include  javacc  based  turtle  parser  riot  turtle  basis  additional  language  rdf  shacl  shex  compact  form  main  riot  turtle  parser  written  speed  tuned  tokenizer  directly  written  java  grammar  parser  make  harder  reuse  extend  ticket  proposes  including  another  rdf  11  compliant  turtle  parser  based  javacc  provide  easier  route  additional  language  providing  detail  turtle  token  prefix  name  handling  form  suitable  base  new  language  still  copy  parser  system  class  inheritance  rdf  11  turtle  sparql  11  aligned  working  group  share  token  several  grammar  rule  would  active  default  ie  registered  lang  parser  factory  registered  automatic  initialization  test  suite  would  run  build  pas  rdf  11  turtle  test  suite  â  nonrdf11  javacc  turtle  parser  jenacore  based  prerdf11  state  turtle  sufficient  assembler  test  read  turtle  file  could  moved  test  area  except  appear  legacy  application  use  jenacore  â,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1662,rdfconnectionremote  pas  original  string  remote  server  possible  place  passing  string  endtoend  â,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1663,split  module  jenafusekicore  engine  separate  webapp  module  jenafusekicore  core  fuseki  data  registry  service  servlets  servlet  filter  webapp  code  needed  full  server  ui  embedded  fuseki  need  webapp  separating  two  aspect  separate  module  cleaner  avoids  risk  webapp  assumption  leaking  nonwebapp  embedded  server  â  key  difference  embeddedbase  server  make  assumption  disk  given  datasets  manage  webapp  fullui  server  ondisk  configuration  database  area,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
1664,tdb2  loader  print  progress  overall  load  logging  output  per  file  would  better  logged  count  whole  load  per  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1665,support  dynamic  function  invocation  arq  per  suggestion  sparql  working  group  proposing  new  built  call  used  sparql  query  dynamic  function  invocation  call  argument  return  null  call  argument  evaluates  first  argument  see  result  uri  error  try  generate  function  invoke  argument  invocation  remaining  argument  call  implemented  prototype  implementation  arq  language  committed  trunk  others  knowledge  expression  function  evaluation  arq  may  suggestion  improve  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1666,respect  query  timeouts  tdb  implementation  general  use  sometimes  see  query  throw  querycancelledexception  several  secondsminutes  expected  timeout  acceptable  degree  appears  case  rogue  query  could  execute  unmitigated  attached  testcase  example  query  execute  consume  cpuheap  outofmemoryerror  thrown  example  following  query  10  timeouts  executed  7  minute  throwing  oome  aug  3  2012  101819  executing  query  limit1000  timeout110s  timeout210s  select  b  c  c  e  javalangoutofmemoryerror  gc  overhead  limit  exceeded  javautilhashsetinithashsetjava86  orgopenjenaatlasiteratorfilteruniqueinitfilteruniquejava26  orgopenjenaatlasiteratoriterdistinctiterjava438  comhphpljenatdbsolverstagematchtuplemakenextstagestagematchtuplejava116  comhphpljenatdbsolverstagematchtuplemakenextstagestagematchtuplejava44  orgopenjenaatlasiteratorrepeatapplyiteratorhasnextrepeatapplyiteratorjava49  orgopenjenaatlasiteratoriter4hasnextiterjava295  comhphpljenasparqlengineiteratorqueryiterplainwrapperhasnextbindingqueryiterplainwrapperjava54  comhphpljenasparqlengineiteratorqueryiteratorbasehasnextqueryiteratorbasejava108  comhphpljenasparqlengineiteratorqueryiterslicehasnextbindingqueryiterslicejava76  comhphpljenasparqlengineiteratorqueryiteratorbasehasnextqueryiteratorbasejava108  comhphpljenasparqlengineiteratorqueryiteratorwrapperhasnextbindingqueryiteratorwrapperjava40  comhphpljenasparqlengineiteratorqueryiteratorbasehasnextqueryiteratorbasejava108  comhphpljenasparqlengineiteratorqueryiteratorwrapperhasnextbindingqueryiteratorwrapperjava40  comhphpljenasparqlengineiteratorqueryiteratorbasehasnextqueryiteratorbasejava108  comhphpljenasparqlengineiteratorqueryiteratorwrapperhasnextbindingqueryiteratorwrapperjava40  comhphpljenasparqlengineiteratorqueryiteratorbasehasnextqueryiteratorbasejava108  comhphpljenasparqlengineresultsetstreamhasnextresultsetstreamjava72  comhphpljenasparqlresultsetresultsetapplyapplyresultsetapplyjava41  comhphpljenasparqlresultsetxmloutputformatxmloutputjava52  comhphpljenaqueryresultsetformatteroutputasxmlresultsetformatterjava482  comhphpljenaqueryresultsetformatteroutputasxmlresultsetformatterjava460  testtimoutmaintesttimoutjava84  aug  3  2012  102541  finished,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1667,transformfilterequality  handle  starting  optional  well  one  case  test  stuck  slow  query  execution  transformfilterequality  failed  optimize  problem  optimizer  give  whenever  clause  start  optional  clause  reason  generated  algebraic  formula  start  tableunit  handled  correctly  attached  patch  fix  problem,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1668,xsdhexbinary  xsdbase64binary  share  code  via  xsdbinarybase  0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1
1669,support  http  auth  sparql  update  request  arq  support  http  basic  authentication  read  query  setbasicauthentication  queryenginehttp  cant  find  authentication  support  sparql  update  though  responsible  class  updateprocessremote  us  httpop  abstraction  httpop  turn  encapsulates  httpclient  apache  http  component  guess  way  go  would  extend  httpop  support  auth  expose  httpclient  object  order  set  auth  option  described  1  im  happy  help  get  hint  preferred  way  include  auth  support  1  httphcapacheorghttpcomponentsclientgatutorialhtmlauthenticationhtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1670,remove  damloil  support  remove  legacy  damloil  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1671,include  fuseki  request  count  header  fuseki  logging  request  us  unique  number  query  would  useful  number  included  header  query  response  would  make  slightly  easier  trace  back  error  fuseki  log,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1672,rete  patch  faster  forward  rule  execution  httpmailarchivesapacheorgmodmboxjenadev201303mbox3c20130317072414327a09b7tyrannoxfritzbox3e  would  like  like  submit  patch  speed  forward  rule  execution  rete  engine  us  slightly  memory  reduces  time  needed  dataset  100000  triple  beyond  measuring  5  minute  pass  test  far  missing  something,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
1673,tdb  statsbase  reordering  nees  treat  rdf  type  differently  rdftype  like  predicate  large  dataset  small  number  type  throw  stats  planner  instead  collect  rdftype  actual  type  statistic,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
1674,remote  update  respect  srvservicecontext  follow  issue  prompted  jena405  issue  requested  support  respecting  service  context  remote  sparql  query  allowed  setting  certain  parameter  centralized  place  rather  every  time  wanted  access  service  seems  reasonable  update  looked  code  appears  existing  way  inject  authentication  parameter  update  lacking  feature  since  would  seem  likely  credential  would  needed  update  query,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1
1675,arq  able  optimize  implicit  join  implicit  left  join  class  useful  optimization  currently  arq  even  attempt  apply  usually  referred  implicit  join  trivial  example  follows  select  x  p1  o1  p2  o2  filterx  currently  requires  u  compute  cross  product  apply  filter  even  streaming  evaluation  extremely  costly  aim  optimization  produce  query  like  following  select  x  p1  o1  x  p2  o2  bindx  optimization  also  applied  left  join  implicit  join  applies  across  join  eg  select  x  p1  o1  optional  p2  o2  filterx  thought  generalization  transformfilterequality  except  covering  case  item  variable  since  thing  variable  need  careful  apply  optimization  since  used  need  guarantee  substituting  one  variable  alter  semantics  query  believe  optimization  safe  apply  providing  guarantee  far  possible  one  variable  nonliteral  done  inspecting  position  mentioned  variable  used  ensuring  least  one  variable  occurs  graph  subject  predicate  position  safety  left  join  little  complex  since  must  ensure  least  one  variable  occurs  rh  make  substitution  rh  otherwise  change  join  semantics,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1676,unify  http  usage  authentication  mechanism  arq  currently  arq  us  mixture  httpclient  httpurlconnection  perform  various  http  operation  eg  sparql  query  sparql  update  sparql  graph  store  protocol  effect  making  code  somewhat  awkward  maintain  make  certain  operation  like  authentication  complex  need  different  part  system  support  different  mode  authentication  example  currently  sparql  query  support  basic  auth  always  preauthenticate  cannot  proxy  auth  use  kind  auth  method  hand  sparql  update  use  httpclient  capable  performing  basic  digest  ntlm  spnego  kerberos  normal  proxy  auth  never  preauthenticates  task  proposes  unifying  http  operation  arq  use  apache  httpclient  since  flexible  introducing  extensible  framework  authentication  term  http  unification  need  convert  following  httpquery  use  httpclient  locatorurl  use  httpclient  term  http  authentication  idea  follows  introduce  new  interface  httpauthenticator  provides  applyabstracthttpclient  client  uri  target  method  system  may  permit  http  auth  allow  use  authenticator  providing  generic  interface  authenticator  allow  u  introduce  authenticator  auth  scheme  eg  form  based  logins  also  provide  authenticator  leverage  existing  mechanism  eg  storing  credential  service  context  would  used  default  existing  method  accept  username  password  would  use  simpler  authenticator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1677,datasetgraphtdbdeleteany  us  loop  delete  leading  scaling  problem  datasetgraphtdbdeleteany  relying  datasetgraphcaching  default  implementation  work  nodeids  also  use  batching  seen  graphtdbremoveworker  move  graphtdbremoveworker  code  datsetgraphtdb  consolidate  using,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
1678,fuseki  use  dataset  transaction  available  parse  intermediate  datastructure  fuseki  detect  update  operation  real  transactional  dataset  avoid  parsing  data  ram  validation  step  especially  case  graph  store  protocol  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0
1679,add  initial  binding  support  update  query  sparql  update  query  lost  ability  specify  initial  binding  patch  add  functionality  note  initial  binding  meaningful  insertdeletewhere  deletewhere  update  query  note  change  api  3rd  party  updateengine  implementers,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1680,improve  fusekitdb  transaction  memory  usage  tdb  buffer  memory  modified  block  transaction  committing  cause  memory  exception  attempting  add  large  number  statement  single  transaction  easy  way  fix  would  copy  write  block  content  memory  mapped  file  instead  heap  memory  â€  provide  three  user  specified  option  controlling  location  temporary  block  jvm  heap  default  currently  use  direct  memory  process  heap  jvm  memory  mapped  temporary  file  see  jena  thread  httpmarkmailorgthreadckeevvhl2luevixw  additional  discussion  â€  harder  way  would  involve  writing  old  block  journal  writing  new  block  directly  index  tombstone  pointing  old  block  journal  reader  could  still  retrieve  old  version  however  would  seem  require  substantial  refactor  well  change  ondisk  database  format,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1681,get  rid  log4j  dependency  jenacore  apache  jena  core  seems  pull  log4j  slf4jlog4j12  since  use  slf4j  would  suppose  plug  logging  backend  hard  dependency  log4j  least  make  optional  dont  force  core  jena  component  ultimately  avoids  kind  issue  slf4j  class  path  contains  multiple  slf4j  binding  slf4j  found  binding  jarfiletargetuniversalstagelibchqoslogbacklogbackclassic1013jarorgslf4jimplstaticloggerbinderclass  slf4j  found  binding  jarfiletargetuniversalstageliborgslf4jslf4jlog4j12164jarorgslf4jimplstaticloggerbinderclass  slf4j  see  httpwwwslf4jorgcodeshtmlmultiplebindings  explanation  slf4j  actual  binding  type  chqoslogbackclassicutilcontextselectorstaticbinder,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1682,add  readreader  general  readerriot  interface  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1683,improve  filter  placement  optimization  0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
1684,remove  jmx  support  arq  arq  jmx  support  jmx  unavailable  verions  environment  osgi  glassfish  google  app  engine  system  using  classloader  restriction  ant  jmx  cant  started  arq  operates  normal  without  static  information  eg  version  live  query  count  proposal  remove  jmx  arq  assumption  library  information  better  obtained  using  application  one  system  might  fuseki  already  management  information  framework  expose  statistic  http,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1685,possible  optimisation  filtervar  constant  idea  possible  optimisation  query  following  general  form  noformat  select  pattern  filtervar  httpconstant  noformat  pattern  crop  surprisingly  often  real  sparql  workload  since  often  used  either  limit  variable  exclude  certain  possibility  avoid  self  referential  link  data  case  seems  like  could  safely  rewritten  follows  noformat  select  pattern  minus  bindhttpconstant  var  noformat  perhaps  generalised  form  like  noformat  select  pattern  minus  value  var  httpconstant1  httpconstant2  noformat  would  nicely  deal  case  stating  variable  equal  multiple  constant  value  pointed  earlier  would  apply  every  case  specifically  think  least  following  must  true  variable  must  guaranteed  bound  similar  existing  filter  equality  implicit  join  optimisation  also  potential  spot  case  variable  always  unbound  thus  expression  always  error  replace  entire  subtree  table  empty  already  equality  implicit  join  filter  plan  taking  look  implementing  new  year  anyone  thought  especially  wrt  restriction  apply  optimisation  considered  safe  please  comment,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1686,constant  folding  part  query  optimisation  currently  jena  automatically  simplify  expression  constant  folding  even  though  function  api  actually  support  already  baked  issue  track  work  integrate  transform  standard  optimiser,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1687,generate  json  sparql  directly  capability  generate  json  directly  sparql  extended  sparql  query  would  enable  creation  json  data  api  published  linked  data  project  would  cover  design  publication  design  refinement  design  based  community  feed  implementation  including  testing  refinement  implementation  based  community  feed  skill  required  java  parser  work  design  discussion  user  community  basic  understanding  http  content  negotiation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1688,optimization  orderbydistinctapplication  enable  better  topn  optimization  new  opportunity  transformation  sliceorder  topn  execution  currently  orderbydistinctapplication  done  topn  orderbydistinctapplication  done  topn  optimization  algebra  may  form  sliceorderdistinctproject  executed  topn  query  form  appear  algebra  expression  directly  query  modifier  order  slicedistinctprojectorder  general  safe  topn  execution  however  orderbydistinctapplication  pick  condition  optimization  leaf  resultant  algebra  transformable  topn  currently  noformat  select  distinct  z  p  z  order  z  limit  5  noformat  compiled  algebra  noformat  slice  5  distinct  project  z  order  z  bgp  triple  p  z  noformat  optimization  topn  apply  noformat  slice  5  order  z  distinct  project  z  bgp  triple  p  z  noformat  possible  noformat  top  5  z  distinct  project  z  bgp  triple  p  z  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1689,make  tdb  datasets  harder  corrupt  rfe  come  discussion  person  andy  earlier  week  mailing  list  qa  site  see  steady  stream  question  people  corrupted  tdb  database  would  nice  could  put  place  feature  make  harder  two  main  thing  long  term  see  make  using  tdb  nontransactonally  difficult  put  place  mechanism  make  difficult  multiple  jvms  access  tdb  dataset  simultaneously  andy  think  first  could  achieved  making  tdb  datasets  operation  autocommit  rather  nontransactional  mode  default  order  allow  likely  need  upgradeable  read  transaction  supported  part  change  nontransactional  mode  would  still  supported  user  would  explicitly  set  dragon  style  flag  order  user  arent  using  transaction  currently  would  likely  merely  see  performance  drop  since  suddenly  getting  autocommits  every  operation  complain  tell  using  transaction  properly  ensure  tdb  database  remain  uncorrupted  far  second  point  go  could  likely  way  lot  application  code  write  lock  file  disk  database  opened  contains  owning  process  pid  whenever  go  open  database  presence  lock  file  checked  present  pid  validated  code  refusing  open  database  pid  match  would  likely  need  code  cope  case  lock  file  get  left  around  owning  pid  alive  shouldnt  complicated  since  may  considered  substantial  behavioural  change  tdb  may  likely  go  jena  3,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1690,wire  xsd  duration  accessor  operation  sparql  keyworks  arq  support  xsddurations  function  fnyearsmonthsdayshoursminutessecondsfromduration  accessed  fn  uri  function  year  hour  etc  etc  overloaded  provide  function  called  xsddurations,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1691,use  alternative  implementation  fruleenginei  give  possibility  use  alternative  fruleenginei  implementation  proposition  introduce  singleton  factory  fruleengineifactory  codetitlecomhphpljenareasonerrulesysimplfruleengineifactoryjavaborderstylesolid  public  class  fruleengineifactory  private  static  fruleengineifactory  instance  new  fruleengineifactory  public  static  void  setinstancefruleengineifactory  instance  fruleengineifactoryinstance  instance  public  fruleengineifactory  getinstance  return  instance  public  fruleenginei  createfruleengineiforwardruleinfgraphi  parent  listrule  rule  boolean  userete  fruleenginei  engine  rule  null  userete  engine  new  reteengineparent  rule  else  engine  new  fruleengineparent  rule  else  userete  engine  new  reteengineparent  else  engine  new  fruleengineparent  return  engine  code  factory  used  existing  class  codetitlecomhphpljenareasonerrulesysbasicforwardruleinfgraphborderstylesolid  override  protected  void  instantiateruleenginelistrule  rule  engine  fruleengineifactorygetinstancecreatefruleengineithis  rule  false  code  codetitlecomhphpljenareasonerrulesysfbruleinfgraphborderstylesolid  override  protected  void  instantiateruleenginelistrule  rule  engine  fruleengineifactorygetinstancecreatefruleengineithis  rule  userete  code  codetitlecomhphpljenareasonerrulesysreteruleinfgraphborderstylesolid  override  protected  void  instantiateruleenginelistrule  rule  engine  fruleengineifactorygetinstancecreatefruleengineithis  rule  true  code  could  replace  factory  instance  instance  code  fruleengineifactorysetinstancenew  customfruleengineifactory  code  propose  patch  soon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1692,remove  tablematchrightleft  tablematchrightleft  join  code  table  rather  inflexible  form  part  table  interface  put  necessary  code  library  long  term  general  library  inner  outer  join  algorithm  introduced,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
1693,reduce  costly  string  operation  utility  class  enclosed  patch  improves  performance  kind  stringserialization  rdf  graph  patch  improves  performance  updaterequestoutput  approx  30  make  remote  sparql  query  fair  bit  faster  patch  probably  improve  performance  across  board,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1694,read  payload  error  httpop  sparql  server  virtuoso  return  http  entity  error  message  command  go  wrong  combined  setup  using  fuseki  virtuso  jena  client  cannot  used  since  ignores  proper  error  virtuoso  enclosed  patch  add  response  payload  error  existing  behaviour  throw  away  payload  upon  error,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1695,make  queryexecution  implement  autocloseable  jdk  7  closeable  used  trywithresources  convenient  programming  structure  compatible  jdk  6  desired  however  closeableclose  throw  ioexception  hope  approved  least  next  major  jena  arq  version  212,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1696,sparql  replace  user  email  report  replace  doesnt  error  pattern  match  zero  length  stringshttpmailarchivesapacheorgmodmboxjenausers201407mbox3cca2bq4jn3dqos85ycpgexqx2blfkx4dw8qsqmblq2kt052btvj0xksa40mailgmailcom3e  replaceabc  x  return  xx  us  java  matcherreplaceall  one  match  whole  abc  greedy  pattern  one  match  trailing  empty  string  java  return  x  empty  string  xx  nonempty  string  place  abc  fo  call  case  make  error  httpwwww3orgtrxpathfunctionsfuncreplace  quote  error  raised  errforx0003  pattern  match  zerolength  string  expression  fnmatches  pattern  flag  return  true  error  however  captured  substring  zerolength  quote,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1697,provide  registry  result  set  reader  writer  cf  rdfdatamgr  graph  dataset  io,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
1698,transforms  interact  better  custom  operator  already  discussed  briefly  mailing  list  thread  safely  apply  transforms  custom  algebra  operator  httpsapacheorgcustomalgebratransform  making  transforms  pas  correctly  custom  algebra  operator  transformcopy  defers  copyopext  ext  implementation  back  apply  method  opext  mean  custom  operator  something  simple  like  following  noformat  override  public  op  applytransform  transform  required  order  block  optimization  return  new  customoperatortransformertransformtransform  thissubop  thiscustomparams  noformat  work  correctly  stateless  transforms  fails  transforms  like  algebratoquadform  rely  external  state  specific  case  quad  form  transformation  external  state  tracked  visitor  applied  applytransformvisitor  work  algebra  state  used  actual  transform  come  back  algebra  however  passed  custom  operator  way  pas  external  state  tracker  inside  custom  operator  transform  may  accessing  incorrect  state  couple  option  fixing  fix  specific  case  rewriting  quad  form  transform  rely  external  state  tracking  sure  even  feasible  revise  api  transforming  opext  external  state  also  passed  necessary  option  difficulty  may  possible  make  simpler  change  allow  specific  case  quad  form  transformation  fixed  without  changing  public  api  another  approach  would  quad  form  transform  public  class  provided  public  accessors  external  state  custom  operator  could  specifically  recognise  special  case  external  state  tracking  passed  onwards  generally  perhaps  marker  interface  statefultransform  could  added  would  provide  standard  way  recognise  transforms  may  problem  provide  access  state  tracker  necessary  pas  custom  operator  correctly  additionally  could  overload  transformertransformtransform  ie  transformertransformstatefultransform  would  wire  thing  appropriately  allowing  existing  basic  approach  custom  operator  outlined  continue  work  without  special  case,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1699,add  streamrdfwriter  place  streambased  writer  found  provide  place  get  streaming  writer  rdfdatamgr  guarantee  know  writer  streaming,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1700,filter  placement  able  break  extend  following  query  demonstrates  query  plan  seen  internally  considered  suboptimal  consider  following  query  noformat  select  distinct  domainname  uri  p  union  sub  p  uri  filterisiriuri  bindstruri  filterstrstartss  http  bindiriconcathttp  strbeforesubstrs8  domainname  noformat  arq  optimises  follows  noformat  distinct  project  domainname  filter  strstarts  http  extend  str  uri  domainname  iri  concat  http  strbefore  substr  8  union  bgp  triple  uri  p  filter  isiri  uri  bgp  triple  sub  p  uri  noformat  make  query  engine  lot  work  computes  bind  expression  lot  possible  solution  rejected  many  would  necessary  compute  first  simple  bind  function  would  better  query  planned  follows  noformat  distinct  project  domainname  extend  domainname  iri  concat  http  strbefore  substr  8  filter  strstarts  http  extend  str  uri  union  bgp  triple  uri  p  filter  isiri  uri  bgp  triple  sub  p  uri  noformat  essentially  try  push  filter  extend  determine  cannot  push  extend  see  split  extend  instead  thus  resulting  partial  pushing  note  user  rewrite  original  query  yield  plan  make  second  bind  project  expression  like  noformat  select  distinct  iriconcathttp  strbeforesubstrs8  domainname  uri  p  union  sub  p  uri  filterisiriuri  bindstruri  filterstrstartss  http  noformat,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
1701,handling  simple  literalslanguage  literal  xsdstring  rdf  11  rdf  11  simple  literal  language  tag  mentioned  datatype  datatype  xsdstring  literal  language  tag  datatype  rdflangstring  output  explicitly  use  xsdstring  datatype  nodefactory  catch  datatype  set  xsdstring  rdflangstring  appropriate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1702,blank  node  output  hadoop  cause  identifier  diverge  multistage  pipeline  writing  documentation  rdf  tool  hadoop  enumerating  possible  issue  blank  node  imply  discovered  issue  hadnt  previously  considered  single  job  input  output  format  ensure  blank  node  consistently  given  identifier  syntactic  id  file  done  even  file  read  multiple  chunk  multiple  map  task  however  nature  reduce  task  create  output  file  potentially  end  blank  node  spread  multiple  file  however  read  file  subsequent  job  blank  node  may  spread  across  multiple  file  even  though  node  originally  allocation  policy  cause  identifier  diverge  become  distinct  blank  node  incorrect  behaviour  since  clear  universal  fix  considering  instead  introducing  configuration  setting  allow  file  path  ignored  purpose  blank  node  identifier  allocation  within  job  mean  identifier  purely  allocated  basis  job  id  thus  syntactic  id  file  result  blank  node  identifier  user  hopefully  left  turned  first  job  even  start  syntactic  id  different  file  normal  allocation  policy  first  job  ensure  unique  id  later  job  next  step  implement  failing  unit  test  temporarily  ignore  demonstrates  issue,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1703,need  generic  assembler  securityevaluators  securedassembler  assemble  secured  model  generic  securityevaluator  assembler  work  securityevaluator  implementation  improvement  cover  building  generic  assembler  pas  parameter  constructor  instance  securityevaluator,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
1704,make  cache  lpbruleengine  bounded  avoid  outofmemory  class  comhphpljenareasonerrulesysimpllpbruleengine  us  inmemory  cache  named  tabledgoals  limit  sizenumber  entry  stored  noformat  table  mapping  tabled  goal  generator  goal  partial  goal  state  shared  across  multiple  query  protected  hashmaptriplepattern  generator  tabledgoals  new  hashmap  noformat  experienced  outofmemory  issue  cache  filled  million  entry  day  normal  query  usage  condition  heap  memory  set  3gb  setup  dataset  containing  multiple  graph  actual  data  graph  backed  tdb  two  ontology  model  using  transitivereasoner  owlmicrofbrulereasoner  respectively  typical  query  may  run  graph  dataset  including  ontology  one  see  query  template  eventhough  ontology  graph  would  yield  additional  result  data  query  fine  mentioned  cache  would  still  fill  new  entry  noformat  select  p  graph  g  resource  interest  p  noformat  upper  bound  cache  soon  later  available  heap  memory  consumed  cache  giving  rise  outofmemory  criticial  error,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1705,use  java8  construct  jenacore  iterators  example  httpsgithubcomapachejenapull54,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1706,add  bind  support  querybuilder  clause  querybuilder  currently  support  bind  statement  add  functionality,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1707,rename  updatedeniedexception  noted  discussion  dev  list  andy  update  rename  current  updatedeniedexception  accessdeniedexception  extend  newly  created  operationdeniedexception  adddeniedexception  deletedeniedexception  extend  accessdeniedexception  jenapermissions  extend  accessdeniedexception  create  readdeniedexception  read  restriction  updatedeniedexception  update  restriction  modifying  triple  already  exists  opposed  adding  new  triple  allow  fuskei  properly  respond  case  jenapermissions  place  update  restriction  place  currently  fuseki  return  500  error  common  permission  denied  exception  return  either  authentication  required  access  denied  appropriate,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1708,refactor  graphpermissions  interface  layer  jenapermissions  package  originally  designed  graph  implementation  agnostic  end  layer  translates  jena  based  node  triple  statement  object  slightly  different  format  jenapermissions  part  apache  jena  proper  layer  factored  improve  performance  result  refactoring  visible  probably  disruptive  early  adopter  done  part  30  release,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
1709,remove  json  registration  rdfjson  avoid  confusion  jsonld  remove  json  registration  rdfjson,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1710,new  consumer  checklist  use  jira  track  list  issue  resolve  get  working  new  consumer  client  consumer  client  work  phase  1  add  new  consumer  apis  configs  2  refactor  sender  need  use  common  apis  senderjava  httpsissuesapacheorgjirabrowsekafka1316  3  add  metadata  fetch  refresh  functionality  consumer  require  httpsissuesapacheorgjirabrowsekafka1316  4  add  functionality  support  subscribetopicpartitionpartitions  add  simpleconsumer  functionality  new  consumer  include  group  management  related  work  5  add  ability  commit  offset  kafka  include  adding  functionality  commitcommitasynccommitted  apis  still  include  group  management  related  work  6  add  functionality  offsetsbeforetime  api  7  add  consumer  coordinator  election  server  add  new  module  consumer  coordinator  necessarily  logic  group  management  point  fully  functional  standalone  consumer  server  side  coordinator  module  good  time  start  adding  group  management  functionality  server  consumer  8  add  failure  detection  capability  consumer  group  management  used  include  rebalancing  logic  ability  detect  failure  using  sessiontimeoutms  9  add  rebalancing  logic  server  consumer  tricky  potentially  large  change  since  involve  implementing  group  management  protocol  10  add  system  test  new  consumer  11  add  metric  12  convert  mirror  maker  use  new  consumer  13  convert  perf  test  use  new  consumer  14  performance  testing  analysis  15  review  fine  tune  log4j  logging,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,0,1
1711,extend  wire  protocol  allow  crc32c  howdy  currently  building  number  kafka  consumer  go  based  patched  version  sarama  library  shopify  released  back  reasonably  fast  serialization  protocol  capn  proto  10g  network  lot  core  various  consumer  computing  kind  aggregate  reasonably  high  volume  access  log  stream  11e6  messagessec  peak  500600  byte  per  message  uncompressed  profiling  consumer  single  hottest  function  disabled  crc32  checksum  validation  since  deserialization  aggregation  consumer  pretty  cheap  believe  thing  could  improved  extending  wire  protocol  support  crc32c  castagnoli  since  sse  42  instruction  accelerate  calculation  httpsenwikipediaorgwikisse4sse42  might  hard  use  java  consumer  written  language  benefit  lot  give  idea  benchmark  go  crc32  function  running  intelr  coretm  i73540m  cpu  300ghz  core  benchmarkcrc32kb  90196  nsop  36330  mb  benchmarkcrccastagnoli32kb  3404  nsop  962442  mb  believe  benchmarkcrc32  written  c  would  600700  mbsec  crc32c  speed  close  one  achieves  go  met  todd  clark  meetup  last  night  thanks  great  presentation,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
1712,integrate  checkstyle  java  code  lot  little  style  layering  problem  tend  creep  code  especially  external  patch  lax  reviewer  usual  style  suspectscapitalization  spacing  bracket  placement  etc  personal  pet  peave  lack  clear  thinking  layer  layering  problem  crept  quite  fast  sad  say  number  accidentally  caused  thing  like  oakcommon  depending  oakclients  consumer  depending  producer  patch  integrates  checkstyle  catch  issue  build  time  corrects  known  problem  fair  number  small  change  patch  trivial  checkstyle  slightly  annoying  least  couple  minor  bug  around  anonymous  inner  class  formatting  find  98  real  style  issue  mostly  worth,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0
1713,bound  fetch  response  size  kip74  currently  bound  fetch  response  size  maxpartitionfetchbytes  numpartitions  two  problem  1  first  bound  often  large  may  chose  maxpartitionfetchbytes1mb  enable  message  1mb  however  also  need  consume  1k  partition  mean  may  receive  1gb  response  worst  case  2  actual  memory  usage  unpredictable  partition  assignment  change  actually  get  full  fetch  amount  behind  full  chunk  data  ready  mean  application  seems  work  fine  suddenly  oom  partition  shift  application  fall  behind  need  decouple  fetch  response  size  number  partition  proposal  would  add  new  field  fetch  request  maxbytes  would  control  maximum  data  byte  would  include  response  implementation  server  side  would  grab  data  partition  fetch  request  hit  limit  send  back  data  partition  fit  response  implementation  would  need  start  random  position  list  topic  included  fetch  request  ensure  case  backlog  fairly  balance  partition  avoid  first  giving  first  partition  exhausted  next  partition  etc  setting  make  maxpartitionfetchbytes  field  fetch  request  much  le  useful  discus  getting  rid  believe  also  solves  thing  trying  address  kafka598  maxbytes  setting  becomes  new  limit  would  need  compared  maxmessage  size  much  largereg  setting  50mb  maxbytes  setting  would  okay  whereas  set  50mb  may  need  allocate  50mbnumpartitions  require  evolving  fetch  request  protocol  version  add  new  field  kip,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1714,expose  partitioner  interface  new  producer  new  producer  pas  key  hard  code  partition  part  producerrecord  internally  using  class  code  class  partitioner  public  int  partitionstring  topic  byte  key  integer  partition  cluster  cluster  code  class  us  specified  partition  one  us  hash  key  isnt  partition  key  simply  chooses  partition  round  robin  neither  partition  key  however  several  partitioning  strategy  could  useful  dont  support  box  example  would  producer  periodically  choose  random  partition  tends  efficient  since  data  go  one  server  us  fewest  tcp  connection  however  produce  good  load  balancing  many  producer  course  user  setting  partition  manually  bit  inconvenient  need  across  bunch  apps  since  need  remember  set  partition  every  time  idea  would  expose  configuration  set  partitioner  implementation  like  code  partitionerclassorgapachekafkaproducerdefaultpartitioner  code  would  default  existing  partitioner  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1715,add  request  timeout  networkclient  currently  networkclient  timeout  setting  request  response  received  request  due  reason  broker  request  never  completed  request  timeout  also  used  implicit  timeout  method  kafkaproducerflush  kafkaproducerclose  kip19  created  public  interface  change  httpscwikiapacheorgconfluencedisplaykafkakip19addarequesttimeouttonetworkclient,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1716,merge  kafkautilstime  kafkacommonutilstime  currently  2  different  version  time  client  core  need  merged  worth  noting  kafkautilsmocktime  includes  scheduler  used  test  oakafkacommonutilstime  either  need  add  functionality  change  test  need  anymore,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1717,add  kafkaconsumer  pause  capability  use  case  stream  processing  helpful  able  pause  consumption  topic  example  joining  two  topic  may  need  delay  processing  one  topic  wait  consumer  topic  catch  new  consumer  currently  doesnt  provide  nice  way  skip  call  poll  unsubscribe  rebalance  triggered  partition  reassigned  another  consumer  desired  behavior  instead  keep  partition  assigned  simply  one  way  achieve  would  add  two  new  method  kafkaconsumer  code  void  pausetopicpartition  partition  void  resumetopicpartition  partition  code  expected  behavior  pauseresume  partition  paused  call  kafkaconsumerpoll  initiate  new  fetch  partition  partition  resumed  fetch  begin  partition  paused  seek  position  still  used  advance  query  current  position  rebalance  preserve  pauseresume  state,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1718,allow  certain  sensor  garbage  collected  inactivity  currently  metric  cannot  removed  registered  implement  feature  remove  certain  sensor  certain  period  inactivity  perhaps  configurable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1719,fix  capitalization  ssl  class  notice  ssl  class  using  convention  sslchannelbuilder  sslconfigs  etc  kafka  always  used  convention  sslchannelbuilder  sslconfigs  etc  see  eg  kafkaapis  apiutils  leaderandisrrequest  clientidandtopic  etc  fix,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1
1720,new  consumer  commit  every  rebalance  autocommit  enabled  consumer  may  see  duplicate  even  normal  rebalances  since  always  reset  previous  commit  rebalancing,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1721,add  metric  record  total  number  metric  sound  recursive  weird  would  useful  debugging  kafka2664,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1722,add  support  listgroups  describegroup  apis  since  new  consumer  currently  persistence  zookeeper  pending  outcome  kafka2017  way  administrator  investigate  group  status  including  getting  list  member  group  partition  assignment  therefore  propose  modify  groupmetadatarequest  previously  known  consumermetadatarequest  return  group  metadata  received  respective  group  coordinator  received  another  broker  request  handled  returning  coordinator  host  port  information  code  groupmetadatarequest  groupid  includemetadata  groupid  string  includemetadata  boolean  groupmetadataresponse  errorcode  coordinator  groupmetadata  errorcode  int16  coordinator  id  host  port  id  int32  host  string  port  int32  groupmetadata  state  protocoltype  generation  protocol  leader  member  state  string  protocoltype  string  generation  int32  protocol  string  leader  string  member  member  membermetadata  memberassignment  member  memberip  clientid  memberip  string  clientid  string  membermetadata  byte  memberassignment  byte  code  request  schema  includes  flag  indicate  whether  metadata  needed  save  client  read  group  metadata  trying  find  coordinator  important  reduce  group  overhead  use  case  involve  large  number  topic  subscription  eg  mirror  maker  tool  use  protocol  type  determine  parse  metadata  example  protocoltype  consumer  tool  use  consumerprotocol  parse  member  metadata  topic  subscription  partition  assignment  detailed  proposal  found  httpscwikiapacheorgconfluencedisplaykafkakip403alistgroupsanddescribegroup,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1723,standardize  new  consumer  exception  purpose  ticket  standardize  cleanup  exception  thrown  new  consumer  ensure  1  exception  raised  reasonable  way  handling  internally  2  raised  exception  documented  properly  3  exception  provide  enough  information  handling  blocking  method  following  exception  possible  authorizationexception  thrown  cluster  configured  authorization  wakeupexception  thrown  explicit  call  wakeup  apiexception  invalid  session  timeout  invalid  groupid  inconsistent  assignment  strategy  etc  additionally  following  method  special  exception  poll  serializationexception  problem  deserializing  keysvalues  invalidoffsetexception  thrown  reset  policy  defined  includes  offsetoutofrange  nooffsetforpartition  commit  commitfailedexception  thrown  group  management  enabled  rebalance  completed  commit  could  finish  position  invalidoffsetexception,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1724,implement  maxpollrecords  new  consumer  kip41  currently  consumerpolltimeout  return  message  acked  since  last  fetch  way  process  single  message  throw  away  first  message  list  would  mean  required  fetch  message  memory  coupled  client  threadsafe  ie  cannot  use  different  thread  ack  message  make  hard  consume  message  order  message  arrival  important  large  number  message  pending  consumed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1725,connect  parallelize  task  startstop  herder  implementation  currently  iterate  connectorstasks  sequentially  startstop  parallelize  le  critical  standaloneherder  pretty  important  distributedherder  since  generally  managing  task  delay  startingstopping  single  task  impact  every  task  node  ultimately  result  incorrect  behavior  case  single  offset  commit  one  connector  taking  long  preventing  rest  committing  offset,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
1726,rename  sinktaskonpartitionsassignedonpartitionsrevoked  clarify  contract  purpose  onpartitionsrevoked  onpartitionsassigned  method  exposed  kafka  connects  sinktask  interface  seems  little  unclear  closely  tied  consumer  semantics  javadoc  apis  used  openclose  perpartition  resource  would  suggest  always  get  one  call  onpartitionsassigned  writing  record  corresponding  partition  one  call  onpartitionsrevoked  finished  however  method  consumer  used  indicate  phase  rebalance  operation  onpartitionsrevoked  called  rebalance  begin  onpartitionsassigned  called  completes  particular  consumer  guarantee  final  call  onpartitionsrevoked  mismatch  make  contract  method  unclear  fact  workersinktask  currently  guarantee  initial  call  onpartitionsassigned  final  call  onpartitionsrevoked  instead  task  implementation  must  pull  initial  assignment  sinktaskcontext  make  confusing  call  commit  offset  following  onpartitionsrevoked  cause  flush  partition  already  revoked  make  difficult  use  api  suggested  javadocs  fix  clarify  behavior  method  consider  renaming  avoid  confusion  method  consumer  api  onpartitionsassigned  meant  opening  resource  maybe  rename  open  similarly  onpartitionsrevoked  renamed  close  fix  code  ensure  typical  openclose  contract  enforced  would  also  mean  removing  need  pas  initial  assignment  sinktaskcontext  would  give  following  api  code  void  opencollectiontopicpartition  partition  void  closecollectiontopicpartition  partition  code  could  also  consider  going  little  instead  depending  onpartitionsassigned  open  resource  task  could  open  partition  resource  demand  record  received  general  connector  need  way  close  partitionspecific  resource  might  need  pas  full  list  partition  close  since  open  resource  received  writes  since  last  rebalance  case  single  method  code  void  close  code  downside  difference  close  stop  becomes  little  unclear  obviously  compatible  change  connector  would  updated,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
1727,keep  track  connector  task  status  info  expose  via  rest  api  relate  kafka3054  keep  track  status  connector  task  startup  execution  handle  exception  thrown  connector  task  user  able  fetch  information  rest  api  send  necessary  commandsreconfiguring  restarting  pausing  unpausing  connector  task  rest  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1728,kip42  add  producer  consumer  interceptor  jira  main  part  kip42  implementation  includes  1  add  producerinterceptor  interface  call  callback  appropriate  place  kafka  producer  2  add  consumerinterceptor  interface  call  callback  appropriate  place  kafka  consumer  3  add  unit  test  interceptor  change  4  add  integration  test  mutable  consumer  producer  interceptor  running  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1729,support  single  message  transforms  kafka  connect  user  able  perform  light  transformation  message  connector  kafka  needed  transformation  must  performed  data  hit  kafka  eg  filtering  certain  type  event  pii  filtering  also  useful  light  singlemessage  modification  easier  perform  inline  data  importexport,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,1,1
1730,kip31kip32  cleanup  review  found  thing  could  potentially  improved  important  enough  block  pr  merged,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1731,improve  consumer  rebalance  error  messaging  common  problem  new  consumer  message  processing  take  longer  session  timeout  causing  unexpected  rebalance  unfortunately  happens  error  message  often  cryptic  eg  something  illegal  generation  contain  clear  advice  eg  increase  session  timeout  pas  error  message  ensure  user  receive  clear  guidance  problem  possible  solution,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1732,stream  stop  using  job  terminology  rename  jobid  applicationid  background  stopped  using  terminology  job  context  kafka  stream  example  upcoming  stream  doc  refer  job  anymore  otherwise  confusing  reader  familiar  job  hadoop  spark  storm  etc  there  equivalent  concept  job  stream  update  stream  code  see  cd  stream  git  grep  job  starting  point  reflect  accordingly  notably  configuration  option  jobid  changed  applicationid,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1733,improve  protocol  type  error  invalid  size  received  currently  dont  perform  much  validation  size  value  read  protocol  type  mean  end  throwing  exception  like  bufferunderflowexception  negativearraysizeexception  etc  schemaread  catch  exception  add  useful  information  like  code  throw  new  schemaexceptionerror  reading  field  fieldsiname  egetmessage  null  egetclassgetname  egetmessage  code  could  even  better  throwing  schemaexception  user  friendly  message,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1734,support  session  window  stream  dsl  currently  provide  session  window  dataflow  model  seen  common  use  case  feature  better  adding  support  asap  httpscwikiapacheorgconfluencedisplaykafkakip94sessionwindows,1,0,1,0,1,0,0,0,1,0,1,1,1,0,0,0,1
1735,kip146  support  perconnectorpertask  classloaders  connect  currently  use  default  classloader  connect  however  limit  compatibly  load  conflicting  connector  plugins  ideally  would  use  separate  class  loader  per  connectortask  instantiated  avoid  potential  conflict  note  also  open  option  way  provide  jar  instantiate  connector  example  spark  us  dynamically  publish  class  defined  repl  load  via  url  httpsardoriswordpresscom20140330howsparkdoesclassloading  much  simpler  example  include  url  connector  class  instead  class  name  also  possible  could  nice  way  support  dynamic  set  connector  multiple  version  connector  etc,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1736,kafka  connect  task  restart  api  cover  connector  task  restart  apis  documented  kip52  httpscwikiapacheorgconfluencedisplaykafkakip523aconnectorcontrolapis,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1737,task  creation  time  taking  long  rebalance  callback  currently  kafka  stream  create  stream  task  upon  getting  newly  assigned  partition  rebalance  callback  function  code  onpartitionassigned  code  involves  initialization  processor  state  store  well  including  opening  rocksdb  restore  store  changelog  etc  take  time  large  number  state  store  initialization  time  could  take  ten  second  usually  larger  consumer  session  timeout  result  callback  completed  consumer  already  treated  failed  coordinator  rebalance  need  consider  optimize  initialization  process  move  callback  function  initializing  store  onebyone  use  poll  call  send  heartbeat  avoid  kicked  coordinator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1738,add  capability  specify  replication  compact  option  stream  store  currently  state  store  replication  always  go  compact  kafka  topic  state  store  eg  joinwindow  duplicate  store  much  benefit  using  compacted  topic  problem  using  compacted  topic  record  stay  kafka  broker  forever  use  case  key  adid  incrementing  time  bounded  worried  disk  space  broker  topic  go  forever  think  either  need  capability  purge  compacted  record  broker  allow  u  specify  different  compact  option  state  store  replication,1,0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1
1739,consolidate  tumbling  window  hopping  window  currently  two  separate  implementation  tumbling  window  hopping  window  even  though  tumbling  window  simply  specialization  hopping  window  thus  consolidatemerge  two  separate  implementation  new  timewindows  timewindow,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1
1740,consolidate  duplicate  code  kgroupedtableimpl  implementation  aggregate  reduce  kgroupedtableimpl  essentially  identical  current  implementation  share  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1741,make  kafka  producersconsumers  injectable  kafkastreams  playing  kafka  stream  found  there  case  want  take  control  kafka  producerconsumers  instantiation  inside  streamthread  significant  case  impl  kafka  producer  built  provide  much  reliable  message  delivery  there  way  inject  instance  streamtask  atm  another  example  wanna  observe  result  producersend  done  inside  recordcollector  provide  callback  instance  there  way  inject  callback  recordcollector  id  like  suggest  kafkastreams  giving  interface  inject  client  considered  various  approach  like  passing  constructor  make  instantiation  method  overridable  eventually  tried  simply  intorude  another  argument  kafkastreams  constructor  responsible  supplying  client  instance  incomplete  pr  filled  show  changeset  mind  please  give  feedback  followup  pr  quickly  get  positive  feedback,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1742,move  kafkastreams  test  fixture  published  package  kstreamtestdriver  related  fixture  defined  streamssrctestjavaorgapachekafkatest  would  useful  developer  building  application  top  kafka  stream  currently  exposed  package  propose  moving  directory  live  streamsfixturessrcmain  creating  new  streamsfixtures  project  gradle  configuration  publish  separate  package  kip  httpscwikiapacheorgconfluencedisplaykafkakip2473aaddpublictestutilsforkafkastreams,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1743,add  method  check  stream  initialised  currently  stream  initialised  started  streamsstart  way  caller  know  initialisation  procedure  including  starting  task  complete  hence  caller  forced  guess  long  wait  would  good  way  return  state  stream  caller  one  option  would  follow  similar  approach  kafka  server  brokerstatesscala  would  good  example  keep  track  whether  kafka  stream  startingrunningrebalancing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1744,higher  granularity  stream  metric  originally  proposed  guozhang  httpsgithubcomapachekafkapull1362issuecomment218326690  consider  adding  metric  process  punctuate  commit  rate  granularity  processor  node  addition  global  rate  mentioned  helpful  debugging  consider  adding  rate  total  cumulated  metric  contextforward  indicating  many  record  forwarded  downstream  processor  node  well  helpful  debugging  consider  adding  metric  stream  partition  timestamp  helpful  debugging  besides  latency  metric  also  add  throughput  latency  term  source  record  consumed,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
1745,allow  setting  default  topic  configs  via  streamsconfig  kafka  stream  currently  allows  specify  replication  factor  changelog  repartition  topic  creates  also  allow  specify  topicconfig  used  default  creating  internal  topic  default  overridden  configs  provided  statestoresuppliers  etc,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1746,close  recordbatchrecords  append  batch  fails  close  existing  recordbatchrecords  create  new  recordbatch  topicpartition  would  mean  would  retain  temporary  resource  like  compression  stream  buffer  one  recordbatch  per  partition  significant  impact  producer  dealing  slow  broker  see  kafka3704  detail,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1747,add  support  saslscram  mechanism  salted  challenge  response  authentication  mechanism  scram  provides  secure  authentication  increasingly  adopted  alternative  digestmd5  obsolete  scram  described  rfc  httpstoolsietforghtmlrfc5802  good  add  support  scramsha256  httpstoolsietforghtmlrfc7677  sasl  mechanism  kafka  see  kip84httpscwikiapacheorgconfluencedisplaykafkakip843asupportsaslscrammechanisms  detail,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1748,unify  store  downstream  caching  stream  umbrella  story  capturing  change  processor  caching  stream  first  described  kip63  httpscwikiapacheorgconfluencedisplaykafkakip633aunifystoreanddownstreamcachinginstreams,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,1,0
1749,warn  kafkaconnect  groupid  must  conflict  connector  name  groupid  value  happens  value  connector  name  following  error  issued  quote  attempt  join  group  connectelasticsearchindexer  failed  due  group  member  supported  protocol  incompatible  existing  member  quote  maybe  documentation  distributed  worker  configuration  groupid  could  worded  quote  unique  string  identifies  connect  cluster  group  worker  belongs  value  must  different  connector  configuration  name  property  quote,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1750,add  helper  function  testutils  per  guidance  guozhang  pr  1477  move  helper  function  regexsourceintegrationtest  getproducerconfig  getconsumerconfig  getstreamsconfig  testutils  parameterize  appropriate  also  look  adding  waituntilcondition  condition  type  construct  wait  condition  met  without  relying  using  threadsleep,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1751,support  perconnector  converter  good  default  configuration  reducing  total  configuration  user  need  inconvenient  requiring  connector  cluster  need  use  converter  definitely  good  idea  stay  consistent  occasionally  may  need  special  converter  eg  one  source  data  happens  come  json  despite  standardizing  avro  note  configs  connectorlevel  sense  entire  connector  use  single  converter  type  since  converter  used  task  config  need  automatically  propagated  task  effectively  public  api  change  adding  builtin  config  connectorstasks  probably  requires  kip,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1752,connect  record  type  include  timestamps  timestamps  added  record  previous  release  however  get  propagated  automatically  connect  us  custom  wrapper  add  field  rename  clarity  addition  timestamps  trivial  really  useful  eg  sink  connector  would  like  include  timestamp  info  available  stored  value  public  api  need  kip  despite  uncontentious,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1753,allow  consumer  send  heartbeat  background  thread  kip62  ticket  cover  implementation  kip62  documented  httpscwikiapacheorgconfluencedisplaykafkakip623aallowconsumertosendheartbeatsfromabackgroundthread,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,1,1
1754,consumer  use  internal  topic  information  returned  broker  currently  hardcodes,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
1755,split  producerbatch  resend  received  recordtoolargeexception  recently  see  case  recordtoolargeexception  thrown  compressed  message  sent  kafkaproducer  exceeded  max  message  size  root  cause  issue  compressor  estimating  batch  size  using  estimated  compression  ratio  based  heuristic  compression  ratio  statistic  quite  work  traffic  highly  variable  compression  ratio  example  batch  size  set  1mb  max  message  size  1mb  initially  producer  sending  message  message  1mb  topic1  whose  data  compressed  110  original  size  estimated  compression  ratio  compressor  trained  110  producer  would  put  10  message  one  batch  producer  start  send  message  message  also  1mb  topic2  whose  message  compress  15  original  size  producer  would  still  use  110  estimated  compression  ratio  put  10  message  batch  batch  would  2  mb  compression  exceeds  maximum  message  size  case  user  many  option  resend  everything  close  producer  care  ordering  especially  issue  service  like  mirrormaker  whose  producer  shared  many  different  topic  solve  issue  probably  add  configuration  enablecompressionratioestimation  producer  configuration  set  false  stop  estimating  compressed  size  close  batch  uncompressed  byte  batch  reach  batch  size,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1756,configdeftorst  create  section  group  currently  ordering  seems  bit  arbitrary  logical  grouping  connector  able  specify  group  field  use  section  header  also  would  good  generate  ref  section,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1757,ssl  support  connect  rest  api  currently  connect  rest  api  support  http  also  add  ssl  support  access  rest  api  secured,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1758,allow  per  streamtable  timestamp  extractor  moment  timestamp  extractor  configured  via  streamconfig  value  kafkastreams  mean  single  timestamp  extractor  per  app  even  though  may  joining  multiple  streamstables  require  different  timestamp  extraction  method  able  specify  timestamp  extractor  via  kstreambuilderstreamtable  like  specify  key  value  serdes  override  streamconfig  default  kip  httpscwikiapacheorgconfluencepagesviewpageactionpageid68714788  specifying  perstream  extractor  possible  source  intermediate  topic  papi  cannot  enforce  dsl  allow  set  custom  extractor  user  contrast  regard  kafka4785  must  internally  set  extractor  return  record  metadata  timestamp  order  overwrite  global  extractor  streamsconfig  ie  set  failoninvalidtimestampextractor  change  done  kafka4785  though,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
1759,decouple  flush  offset  commits  desirable  addition  timebased  flush  interval  volume  sizebased  commits  eg  sink  connector  buffering  term  number  record  may  want  request  flush  buffer  full  sufficient  amount  data  buffered  file  method  like  say  requestflush  sinktaskcontext  would  allow  connector  flexible  policy  around  flush  would  addition  time  interval  based  flush  controlled  offsetflushintervalms  clock  reset  kind  flush  happens  probably  also  support  requesting  flush  via  sourcetaskcontext  consistency  though  usecase  doesnt  come  mind  bat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1760,add  record  header  currently  header  natively  supported  unlike  many  transport  messaging  platform  standard  add  support  header  kafka  jira  related  kip  found  httpscwikiapacheorgconfluencedisplaykafkakip82addrecordheaders,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,0
1761,enable  jaas  configuration  kafka  client  without  config  file  see  kip85  detail  httpscwikiapacheorgconfluencedisplaykafkakip853adynamicjaasconfigurationforkafkaclients,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1762,kip86  configurable  sasl  callback  handler  implementation  kip86  httpscwikiapacheorgconfluencedisplaykafkakip863aconfigurablesaslcallbackhandlers,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,1,0
1763,simplify  ktablesource  new  interactive  query  feature  source  table  always  materialized  thus  remove  stale  flag  ktablesourematerialized  always  true  simply  code,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
1764,rocksdb  checkpoint  file  lost  kill  9  right  checkpoint  file  logged  rocksdb  store  written  graceful  shutdown  removed  upon  restoration  unfortunately  mean  scenario  process  forcibly  killed  checkpoint  file  rocksdb  store  rematerialized  scratch  next  launch  way  good  simulates  bootstrapping  new  node  example  good  way  see  much  io  used  rematerialize  store  however  lead  longer  recovery  time  nongraceful  shutdown  occurs  want  get  job  running  seems  two  possible  thing  consider  simply  remove  checkpoint  file  restoring  way  kill  9  result  repeating  restoration  data  generated  source  topic  since  last  graceful  shutdown  continually  update  checkpoint  file  perhaps  commit  would  result  least  amount  overheadlatency  restarting  additional  complexity  may  worth  httpscwikiapacheorgconfluencedisplaykafkakip1163aaddstatestorecheckpointintervalconfiguration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1765,kafka  stream  resetter  slow  join  group  topic  resetter  joining  group  topic  take  10secs  testing  make  reset  slow  lot  topic,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1766,remove  caching  dirty  removed  key  storechangelogger  storechangelogger  currently  keep  cache  dirty  removed  key  batch  changelog  record  dont  send  record  update  however  kip63  unnecessary  batching  deduping  done  caching  layer  storechangelogger  relies  contexttimestamp  likely  incorrect  caching  enabled,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1767,replace  messageset  usage  clientside  equivalent  currently  two  separate  implementation  kafka  message  format  log  structure  one  client  side  one  server  side  kafka2066  merged  using  client  side  object  direct  serializationdeserialization  request  apis  still  using  serverside  messageset  object  everywhere  else  ideally  update  code  use  client  object  everywhere  future  message  format  change  need  made  one  place  would  eliminate  potential  implementation  difference  give  u  uniform  api  accessing  lowlevel  log  structure,1,0,1,0,1,0,1,0,1,0,1,0,0,1,0,1,1
1768,refactor  connect  backing  store  threadsafety  kafka  connect  already  significant  provisioning  multithreaded  execution  respect  class  implementing  backing  store  interface  requirement  kafka3008httpsissuesapacheorgjirabrowsekafka3008  tighten  threadsafety  guarantee  implementation  especially  configbackingstore  statusbackingstore  focus  current  ticket,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1769,add  consumerclosetimeout  unit  graceful  close  timeout  kafka3703  implement  graceful  close  consumer  hardcoded  timeout  5  second  consistency  producer  add  close  method  configurable  timeout  consumer  quote  public  void  closelong  timeout  timeunit  unit  quote  since  public  interface  change  change  requires  kip,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
1770,recordslag  zero  fetchresponse  empty  fetcher  record  recordslag  term  number  record  partition  currently  metric  value  updated  number  parsed  record  empty  mean  consumer  already  fully  caught  new  data  topic  metric  value  negative  infinity  user  rely  metric  know  consumer  caught  fix  problem  assuming  lag  zero  fetchresponse  empty,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1771,add  codec  zstandard  compression  zstandard  httpsgithubcomfacebookzstd  httpfacebookgithubiozstd  use  v10  recently  released  hadoop  httpsissuesapacheorgjirabrowsehadoop13578  others  adopting  done  initial  trial  seen  good  result  zstd  seems  give  great  result  gzip  level  compression  lz4  level  cpu,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1772,create  topic  policy  would  useful  able  validate  create  topic  request  detail  kip  httpscwikiapacheorgconfluencedisplaykafkakip1083acreatetopicpolicy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1773,kip72  allow  putting  bound  memory  consumed  incoming  request  issue  track  implementation  kip72  outlined  httpscwikiapacheorgconfluencedisplaykafkakip723aallowputtingaboundonmemoryconsumedbyincomingrequests,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1774,per  listener  security  setting  override  kip103  followup  kafka4565  kip103  implemented  quote  missing  bit  kip  finally  make  possible  provide  different  security  ssl  sasl  setting  listener  name  adding  normalised  prefix  listener  name  lowercased  config  name  example  wanted  set  different  keystore  client  listener  would  set  config  name  listenernameclientsslkeystorelocation  config  listener  name  set  fallback  generic  config  ie  sslkeystorelocation  compatibility  convenience  sasl  case  configs  provided  via  jaas  file  consists  one  entry  broker  currently  look  entry  named  kafkaserver  extend  broker  first  look  entry  lowercased  listener  name  followed  dot  prefix  existing  name  client  listener  example  broker  would  first  look  clientkafkaserver  fallback  kafkaserver  necessary  kip  link  detail  httpscwikiapacheorgconfluencedisplaykafkakip1033aseparationofinternalandexternaltraffic,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0
1775,parametrize  stream  benchmark  run  scale  stream  benchmark  simplebenchmarkjava  triggered  kafkatestskafkatestbenchmarksstreamsstreamssimplebenchmarktestpy  run  singleinstance  simple  1  broker  kafka  cluster  need  parametrize  test  run  scale  eg  10100  kafkastreams  instance  similar  number  broker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1776,error  message  structvalidate  include  name  offending  field  take  look  repro  code  test  public  void  structvalidate  schema  schema  schemabuilderstruct  fieldone  schemastringschema  fieldtwo  schemastringschema  fieldthree  schemastringschema  build  struct  struct  new  structschema  structvalidate  code  one  field  could  causing  issue  following  exception  thrown  make  troubleshooting  missing  field  connector  much  difficult  code  orgapachekafkaconnecterrorsdataexception  invalid  value  null  used  required  field  code  error  message  include  field  field  error  message,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1777,handle  disk  failure  jbod  kip112  see  httpscwikiapacheorgconfluencedisplaykafkakip1123ahandlediskfailureforjbod  motivation  design,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1778,improve  diagnostics  sasl  authentication  failure  moment  broker  close  client  connection  sasl  authentication  fails  client  see  connection  failure  get  feedback  reason  connection  closed  producer  consumer  retry  attempting  create  successful  connection  treating  authentication  failure  transient  failure  log  entry  clientside  indicate  connection  failure  due  authentication  failure  jira  aim  improve  diagnosis  authentication  failure  change  described  kip152httpscwikiapacheorgconfluencedisplaykafkakip152improvediagnosticsforsaslauthenticationfailures  jira  also  change  handling  ssl  authentication  failure  javaxnetdebug  provides  sufficient  diagnostics  case  ssl  change  harder  preserving  backward  compatibility,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1779,exploit  peek  implement  print  method  httpsgithubcomapachekafkapull2493pullrequestreview22157555  thing  think  print  writeastest  special  impl  peek  kstreamprint  etc  removed  consider  collapse  kstreampeek  kstreamforeach  flag  parameter  indicating  acted  keyvalue  pair  still  forwarded,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1780,expose  state  active  task  public  api  httpscwikiapacheorgconfluencedisplaykafkakip1303aexposestatesofactivetaskstokafkastreamspublicapi,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1781,stream  roundrobin  scheduler  inneficient  currently  streamthreadrunloop  us  simple  roundrobin  scheduler  single  request  taken  task  processing  followed  poll  followed  process  example  app  2  task  3  record  ready  processed  wed  following  sequence  poll  process  1  request  task  t1  process  1  request  task  t2  poll  process  1  request  task  t1  process  1  request  task  t2  poll  process  1  request  task  t1  process  1  request  task  t2  poll  quite  inefficient  instead  better  round  robin  scheduler  would  poll  process  3  request  task  t1  process  3  request  task  t2  poll,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1782,add  exactlyonce  semantics  stream  httpscwikiapacheorgconfluencedisplaykafkakip1293astreamsexactlyoncesemantics,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1783,allow  dynamic  routing  output  record  currently  used  output  topic  must  know  beforehand  thus  possible  send  output  record  topic  dynamic  fashion  couple  request  feature  consider  adding  many  open  question  however  regard  topic  creation  configuration  replication  factor  number  partition  etc  kip  httpscwikiapacheorgconfluencedisplaykafkakip3033aadddynamicroutinginstreamssink,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1784,log  invalid  user  configs  overwrite  correct  one  stream  allow  overwrite  config  parameter  eg  enableautocommit  currently  throw  exception  actually  required  stream  ignoreoverwrite  user  provided  value  thus  instead  throwing  log  warn  message  overwrite  config  value  suit  stream  atm  one  parameter  enableautocommit  exactlyonce  going  cf  kafka4923  thus  scope  ticket  depends  implemented  ie  kafka4923  ticket  also  include  javadoc  update  explain  parameter  cannot  specified  user,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1785,improve  internal  task  apis  currently  internal  interface  task  clean  hard  reason  control  flow  task  get  close  suspended  resumed  etc  make  exception  handling  particularly  hard  want  refactor  part  code  get  clean  control  flow  interface,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1786,kip145  expose  record  header  kafka  connect  httpscwikiapacheorgconfluencedisplaykafkakip145exposerecordheadersinkafkaconnect  kip82  introduced  header  core  kafka  product  would  advantageous  expose  kafka  connect  framework  connector  replicate  data  kafka  cluster  messaging  product  kafka  would  want  replicate  header,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1787,add  option  dry  run  stream  application  reset  tool  want  add  option  stream  application  reset  tool  allow  dry  run  ie  print  topic  would  get  modifieddeleted  without  actually  applying  action,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1788,range  scan  windowed  state  store  windowed  state  store  currently  support  key  range  scan  even  though  seems  reasonable  able  –  least  given  window  –  operation  would  keyvalue  store,1,0,1,0,1,0,0,1,1,0,1,0,0,1,0,0,1
1789,application  reset  tool  need  seek  internal  topic  kafka4456  got  resolved  modify  offset  internal  topic  application  reset  tool  offset  deleted  anyway,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1790,new  short  serializer  deserializer  serde  short  serializerdeserializer  current  client  component  could  useful  using  kafkaconnect  write  data  database  smallint  field  similar  avoiding  conversion  int  improving  bit  performance  term  memory  network,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1791,change  punctuate  semantics  kip138  ticket  track  implementation  kip138  change  punctuate  semanticshttpscwikiapacheorgconfluencedisplaykafkakip1383achangepunctuatesemantics,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1792,sticky  assignor  cache  calculated  assignment  kip54  followup  followup  kip54  remove  dependency  sticky  assignor  previously  calculated  assignment  dependency  required  consumer  participating  rebalance  notifies  group  leader  assignment  prior  rebalance  leader  compile  previous  assignment  whole  group  information,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1793,support  extendeddeserializer  kafka  stream  kip82  introduced  concept  message  header  introduced  extendeddeserializer  interface  allowed  deserializer  access  message  header  change  kafka  stream  support  use  extendeddeserializer  provide  compatibility  kafka  client  use  new  header  functionality,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1794,add  ability  batch  restore  receive  restoration  stats  currently  restoring  state  store  kafka  stream  application  put  one  keyvalue  time  store  task  aim  make  recovery  efficient  creating  new  interface  restoreall  functionality  allowing  bulk  writes  underlying  state  store  implementation  proposal  also  add  beginrestore  endrestore  callback  method  potentially  used  tracking  bulk  restoration  process  begin  end  keeping  track  number  record  last  offset  restored  kip  httpscwikiapacheorgconfluencedisplaykafkakip1673aaddinterfaceforthestatestorerestorationprocess,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1795,stream  suspend  task  twice  currently  stream  suspends  task  rebalance  close  suspended  task  reassigned  close  suspend  called  second  time  also  calling  processorclose  node  would  safer  call  suspend  case  user  nonidempotent  operation  processorclose  method  might  thus  fail  cf  kafka5167,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1796,formatting  verifiable  producerconsumer  output  similar  fashion  hi  following  proposal  verifiable  producerconsumer  providing  similar  output  timestamp  always  first  column  followed  name  event  specific  data  event  includes  verifiable  producer  refactoring  way  verifiable  consumer  thanks  paolo,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1797,extend  consumer  group  reset  offset  tool  stream  application  kip  documentation  httpscwikiapacheorgconfluencedisplaykafkakip171extendconsumergroupresetoffsetforstreamapplication,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1798,reduce  class  needed  leaderandisrpartitionstate  metadatapartitionstate  cleaner  replace  leaderandisrpartitionstate  metadatapartitionstate  leaderandisrscala  orgapachekafkacommonrequestspartitionstate  updatemetadatarequestpartitionstate  respectively,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
1799,kip182  reduce  stream  dsl  overload  allow  easier  use  custom  storage  engine  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1800,refactor  streamthread  separate  concern  enable  better  testability  streamthread  lot  stuff  ie  managing  creating  task  getting  data  consumer  updating  standby  task  punctuating  rebalancing  etc  current  design  extremely  hard  reason  quite  tightly  coupled  need  start  tease  separate  concern  streamthread  ie  taskmanager  rebalancelistener  etc,1,1,1,1,1,0,1,0,1,0,1,0,0,0,0,0,1
1801,kafkaconsumersubscribe  overload  take  pattern  without  consumerrebalancelistener  request  provide  subscribepattern  pattern  overload  similar  subscribecollectionstring  topic  today  consumer  subscribe  topic  based  regular  expression  ie  pattern  method  option  also  requires  pas  consumerrebalancelistener  userfriendly  require  second  argument  seems  new  noopconsumerrebalancelistener  used  use  case  multi  datacenter  allowing  easier  subscription  multiple  topic  prefixed  datacenter  name  using  pattern  subscription,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1802,add  cumulative  count  attribute  kafka  rate  metric  add  cumulative  count  attribute  kafka  rate  metric  make  downstream  processing  simpler  accurate  flexible  see  kip187httpscwikiapacheorgconfluencedisplaykafkakip187addcumulativecountmetricforallkafkaratemetrics  detail,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1803,add  new  metric  support  health  check  useful  additional  metric  support  health  check  detail  kip188httpscwikiapacheorgconfluencedisplaykafkakip188addnewmetricstosupporthealthchecks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1804,refactor  stream  use  logcontext  added  logcontext  object  automatically  add  log  prefix  every  message  written  logger  constructed  much  like  logging  mixin  available  server  code  use  consumer  ensure  message  always  contain  consumer  group  client  id  helpful  multiple  consumer  run  instance  kafka  stream  requires  similar  contextual  logging  including  prefix  manually  log  message  would  better  take  advantage  new  logcontext,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1805,refactor  producer  use  logcontext  added  logcontext  object  automatically  add  log  prefix  every  message  written  logger  constructed  much  like  logging  mixin  available  server  code  use  consumer  ensure  message  always  contain  consumer  group  client  id  helpful  multiple  consumer  run  instance  something  similar  producer  always  include  client  id  one  provided  transactional  id,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1806,implement  kafkaprincipalbuilder  interface  support  sasl  kip189  issue  cover  implementation  kip189httpscwikiapacheorgconfluencedisplaykafkakip1893aimproveprincipalbuilderinterfaceandaddsupportforsasl,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
1807,handle  sasl  authentication  failure  nonretriable  exception  client  produce  consumer  change  avoid  retries  authentication  failure  detail  kip152httpscwikiapacheorgconfluencedisplaykafkakip152improvediagnosticsforsaslauthenticationfailures,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1808,add  adminclientcreatepartitions  possible  increase  partition  count  using  adminclient  see  kip195httpscwikiapacheorgconfluencedisplaykafkakip1953aadminclientincreasepartitions,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1809,introduce  deliverytimeoutms  producer  config  kip91  propose  adding  new  timeout  deliverytimeoutms  window  enforcement  includes  batching  accumulator  retries  inflight  segment  batch  config  user  guaranteed  upper  bound  record  either  get  sent  fail  expire  point  send  return  word  longer  overload  requesttimeoutms  act  weak  proxy  accumulator  timeout  instead  introduce  explicit  timeout  user  rely  without  exposing  internals  producer  accumulator  see  kip91httpscwikiapacheorgconfluencedisplaykafkakip91provideintuitiveusertimeoutsintheproducer  detail,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1810,handle  ssl  authentication  failure  nonretriable  exception  client  kip152  improves  diagnostics  sasl  authentication  failure  propagates  sasl  authentication  failure  producer  consumer  ssl  authentication  cant  protocol  change  try  adopt  behaviour  possible,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,0
1811,avoid  call  fetchprevious  flushlisteners  caching  turned  window  session  store  upon  storeput  cache  may  get  flushed  trigger  dirty  flush  listener  calling  maybeforward  call  fetchprevious  unfortunately  fetchprevious  could  expensive  call  make  sometimes  necessary  1  kstreamwindowaggregateprocess  already  get  previous  value  aggregating  could  passing  old  value  tuple  forwarder  without  calling  fetchprevious  2  know  sendoldvalues  flag  turned,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1812,handle  authentication  failure  transactional  producer  kafkaadminclient  follow  kafka5854  handle  authentication  failure  better  transactional  producer  api  kafkaadminclient,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1813,improve  quota  throttle  communication  currently  client  throttled  duet  quota  violation  broker  send  back  response  client  throttle  time  passed  case  client  dont  know  long  response  throttled  might  hit  request  timeout  response  returned  result  client  retry  sending  request  result  even  longer  throttle  time  scenario  could  happen  large  client  group  sending  record  broker  saw  mapreduce  job  push  data  kafka  cluster  improve  broker  return  response  throttle  time  immediately  processing  request  broker  mute  channel  client  correct  client  implementation  back  long  sending  next  request  client  ignored  throttle  time  send  next  request  immediately  channel  muted  request  wont  processed  throttle  time  passed  kip  follow  detail,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1814,kip222  add  describe  consumer  group  list  consumer  group  kafkaadminclient  kafkaadminclient  allow  get  information  consumer  group  feature  supported  old  kafkaadminadminclient  though  add  kafkaadminclientdescribeconsumergroups  kafkaadminclientlistconsumergroup  associated  kip  kip222,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
1815,provide  custom  error  handling  kafka  stream  fails  produce  issue  related  following  kip  httpscwikiapacheorgconfluencedisplaykafkakip210provideforcustomerrorhandlingwhenkafkastreamsfailstoproduce,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1816,postpone  normal  processing  task  within  thread  restoration  task  completed  let  say  stream  thread  host  multiple  task  b  beginning  b  assigned  thread  thread  state  tasksassigned  thread  start  restoring  two  task  state  using  restore  consumer  using  normal  consumer  heartbeating  task  restoration  completed  earlier  task  b  thread  start  processing  immediately  even  still  tasksassigned  phase  processing  task  slow  restoration  task  b  since  singlethread  thread  transition  running  assigned  task  completed  restoring  processed  delayed  note  stream  instance  state  transit  running  thread  transit  running  instance  transition  also  delayed  scenario  wed  better  start  processing  ready  task  immediately  instead  focus  restoration  tasksassigned  state  shorten  overall  time  instance  state  transition,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1817,make  repartition  topic  transient  unlike  changelog  topic  repartition  topic  could  shortlived  today  user  different  way  configure  short  retention  enforce  short  retention  period  use  appendtime  repartition  topic  would  cumbersome  stream  user  one  way  use  “purgedata”  admin  api  kip107  offset  input  topic  committed  input  topic  actually  repartition  topic  would  purge  data  immediately,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,1
1818,add  adminclient  stream  kafkaclientsupplier  add  java  adminclient  kafka  stream  order  replace  internal  streamskafkaclient  detail  found  kip220  httpscwikiapacheorgconfluencedisplaykafkakip2203aaddadminclientintokafkastreams27clientsupplier,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
1819,report  metric  lag  consumer  offset  start  offset  log  currently  consumer  report  metric  lag  high  watermark  log  consumer  offset  useful  report  similar  lag  metric  consumer  offset  start  offset  log  latter  lag  get  close  0  indication  consumer  may  lose  data  soon,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1820,dns  alias  support  secured  connection  seems  client  cant  use  dns  alias  front  secured  kafka  cluster  application  specify  list  host  ip  bootstrapservers  instead  alias  encompassing  cluster  node  using  alias  bootstrapservers  result  following  error  javaxsecuritysaslsaslexception  error  javasecurityprivilegedactionexception  javaxsecuritysaslsaslexception  g  initiate  failed  caused  gssexception  valid  credential  provided  mechanism  level  fail  create  credential  63  service  cred  occurred  evaluating  sasl  token  received  kafka  broker  kafka  client  go  authfailed  state  caused  javaxsecuritysaslsaslexception  g  initiate  failed  caused  gssexception  valid  credential  provided  mechanism  level  fail  create  credential  63  service  cred  using  saslkerberos  authentication  kafka  server  principal  form  kafkakafkabroker1hostnamecomexamplecom  kerberos  requires  host  resolved  fqdns  sasl  handshake  client  create  sasl  token  send  kafka  auth  create  sasl  token  client  first  need  able  validate  broker  kerberos  valid  one  3  potential  option  1  creating  single  kerberos  principal  linked  host  alias  reference  broker  jaas  file  think  kerberos  infrastructure  would  refuse  validate  sasl  handshake  would  still  fail  2  modify  client  bootstrap  mechanism  detect  whether  bootstrapservers  contains  dns  alias  resolve  expand  alias  retrieve  hostnames  behind  add  list  node  could  done  modifying  parseandvalidateaddresses  clientutils  3  add  clusteralias  parameter  would  handled  logic  another  parameter  avoid  confusion  bootstrapservers  work  behind  scene  thought  would  happy  contribute  change  option  believe  ability  use  dns  alias  instead  static  list  broker  would  bring  good  deployment  flexibility,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
1821,state  store  restore  initializing  toplogy  stream  restore  state  store  needed  initializing  topology,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1822,introduce  incremental  fetchrequests  increase  partition  scalability  introduce  incremental  fetchrequests  increase  partition  scalability  see  httpscwikiapacheorgconfluencedisplaykafkakip2273aintroduceincrementalfetchrequeststoincreasepartitionscalability,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1823,change  logsegmentdelete  deleteifexists  harden  log  recovery  fix  kafka6194  delete  open  issue  kafka6322  kafka6075  make  code  robust,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1824,improve  stream  metric  skipped  record  copy  kip210  discussion  thread  quote  note  currently  two  metric  skippedrecords  different  level  1  highest  level  threadlevel  skippedrecords  record  skipped  record  due  deserialization  error  2  lower  processornode  level  skippedduetodeserializationerror  record  skipped  record  specific  source  node  due  deserialization  error  see  1  cover  scenario  thought  aggregate  2  across  task  source  node  however  place  cause  record  dropped  example  1  httpsissuesapacheorgjirabrowsekafka5784  record  could  dropped  due  window  elapsed  2  kip210  record  could  dropped  producer  side  3  record  could  dropped  usercustomized  processing  error  quote  guozhang  sure  mean  3  record  could  dropped  usercustomized  processing  error  btw  also  drop  record  null  key  andor  value  certain  dsl  operation  included  well  kip  httpscwikiapacheorgconfluencedisplaykafkakip2743akafkastreamsskippedrecordsmetrics,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1825,queryablestateintegrationtestqueryonrebalance  accept  raw  text  using  queryablestateintegrationtestqueryonrebalance  performance  test  adding  sentence  inputvalues  found  sentence  contains  upper  case  letter  test  would  timeout  get  around  limitation  calling  sentencetolowercaselocaleroot  split  ideally  specify  path  text  file  contains  text  test  read  text  file  generate  input  array,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1826,allow  timestamp  manipulation  processor  api  atm  kafka  stream  defined  contract  timestamp  propagation  processor  api  level  processor  within  subtopology  see  timestamp  input  topic  record  timestamp  used  result  record  writing  topic  dsl  also  custom  operator  would  desirable  allow  timestamp  manipulation  processor  level  individual  record  forwarded  kip251  httpscwikiapacheorgconfluencedisplaykafkakip2513aallowtimestampmanipulationinprocessorapi,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0
1827,add  mockprocessorcontext  public  testutils  kip247  added  public  testutils  artifact  topologytestdriver  class  using  test  driver  single  processortransformervaluetransformer  required  specify  whole  topology  source  sink  plus  processortransformervaluetransformer  unit  testing  might  convenient  mockprocessorcontext  used  test  processortransformervaluetransformer  isolation  ie  test  creates  new  processortransformervaluetransformer  object  call  init  manually  passing  mockprocessorcontext  public  api  change  requires  kip  httpscwikiapacheorgconfluencedisplaykafkakafkaimprovementproposals,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1828,use  singlepoint  query  range  query  windowed  aggregation  operator  today  windowed  aggregation  stream  dsl  underlying  implementation  leveraging  fetchkey  api  get  related  window  single  record  update  however  inefficient  operation  significant  amount  cpu  time  iterating  window  store  hand  since  operator  implementation  full  knowledge  window  spec  actually  translate  operation  multiple  singlepoint  query  accurate  window  start  timestamp  would  largely  reduce  overhead  proposed  approach  add  single  fetch  api  windowedstore  use  kstreamwindowedaggregate  kstreamwindowedreduce  operator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1829,kip255  oauth  authentication  via  sasloauthbearer  kip255  oauth  authentication  via  sasloauthbearer  httpscwikiapacheorgconfluencepagesviewpageactionpageid75968876  proposes  adding  ability  authenticate  kafka  oauth  2  bearer  token  using  oauthbearer  sasl  mechanism  token  retrieval  token  validation  pluggable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1830,add  timeoutexception  kafkaconsumerposition  kafka4879  kafka  consumer  hang  indefinitely  due  fetchers  timeout  set  longmaxvalue  fixing  issue  pointed  timeout  added  method  commits  offset  synchronously  stricter  control  time  could  achieved  httpscwikiapacheorgconfluencepagesviewpageactionpageid75974886,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1831,rewrite  simple  benchmark  system  test  jmxtool  current  simplebenchmark  recording  numrecords  actively  order  compute  throughput  latency  introduces  extra  cost  plus  le  accurate  benchmarking  purpose  instead  better  use  jmxmixin  simplebenchmark  record  metric,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
1832,delay  initiating  txn  producer  initializetopology  eos  turned  stream  eos  implementation  created  producer  task  initiate  txn  immediately  created  constructor  streamtask  however  task  may  process  data  hence  producer  may  send  record  started  txn  long  time  restoration  process  default  txnsessiontimeout  valued  60  second  mean  restoration  take  amount  time  upon  starting  producer  immediately  get  error  producer  epoch  already  old  fix  consider  instantiating  txn  restoration  phase  done  although  may  caveat  producer  already  fenced  notified  initializetopology  think  correctness  issue  since  restoration  process  make  change  processing  state,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1833,trogdor  coordinator  track  task  status  trogdor  coordinator  track  task  status,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1834,simplify  state  store  recovery  current  code  base  restore  state  store  main  thread  contrast  older  code  restore  state  stored  rebalance  call  back  multiple  advantage  allows  u  simplify  restore  code  original  code  base  long  restore  phase  possible  instance  miss  rebalance  drop  consumer  group  detect  case  apply  check  restore  phase  endoffset  changelog  topic  change  changed  offset  implies  missed  rebalance  another  thread  started  write  changelog  topic  ie  current  thread  taskstorechangelogtopic  anymore  new  code  restores  mainloop  ensured  poll  called  regularly  thus  rebalance  detected  automatically  make  check  changing  changelogendoffset  unnecessary  simplify  restore  logic  consuming  poll  return  data  case  fetch  endoffset  see  fully  restore  yes  resume  processing  continue  restore,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1835,kafka  connect  handling  bad  data  kafka  connect  connector  task  fail  run  unexpected  situation  error  framework  provide  general  bad  data  handling  option  including  perhaps  among  others  fail  fast  today  assuming  connector  actually  fails  doesnt  eat  error  retry  possibly  configs  limit  drop  data  move  dead  letter  queue  need  addressed  way  handle  error  connector  eg  connectivity  issue  system  convertersserializers  bad  data  unexpected  format  etc  smts  ideally  framework  well  though  obviously  want  fix  known  bug  anyway,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1836,reduce  kafka  stream  footprint  persistent  storage  footprint  kafka  stream  application  contains  following  aspect  internal  topic  created  kafka  cluster  side  materialized  state  store  kafka  stream  application  instance  side  question  reducing  footprint  especially  since  many  necessary  example  redundant  internal  topic  well  unnecessary  state  store  take  space  also  affect  performance  people  pushing  stream  production  high  traffic  issue  would  common  severe  reducing  footprint  stream  clear  benefit  reducing  resource  utilization  kafka  stream  application  also  creating  pressure  broker  capacity,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
1837,connect  rest  extension  plugin  cover  connect  rest  extension  plugin  covered  kip285  httpscwikiapacheorgconfluencedisplaykafkakip285connectrestextensionplugin,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1838,remove  deprecated  apis  kip120  kip182  stream  move  next  major  release  20  consider  removing  deprecated  apis  kip120  kip182,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1839,add  transformvalues  method  ktable  add  transformvalues  method  ktable  interface  semantics  function  name  kstream  interface  detail  kip292httpscwikiapacheorgconfluencedisplaykafkakip2923aaddtransformvalues2829methodtoktable,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1840,kip244  add  record  header  support  kafka  stream  processor  api  add  support  header  stream  processor  api  kip  documentation  httpscwikiapacheorgconfluencedisplaykafkakip2443aaddrecordheadersupporttokafkastreamsprocessorapi,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1841,externalize  secret  kafka  connect  configuration  kafka  connects  connector  configuration  plaintext  password  connect  store  cleartext  either  filesystem  standalone  mode  internal  topic  distributed  mode  connect  store  transmit  cleartext  password  connector  configuration  secret  stored  connector  configuration  allowed  replaced  reference  value  stored  external  secret  management  system  connect  provide  extension  point  adding  customized  integration  well  provide  filebased  extension  example  second  connect  runtime  allowed  configured  use  one  extension  allow  connector  configuration  use  placeholder  resolved  runtime  passing  complete  connector  configuration  connector  allow  existing  connector  see  difference  configuration  connect  provides  startup  third  connects  api  changed  allow  connector  obtain  latest  connector  configuration  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1842,consolidate  extendedserializerserializer  extendeddeserializerdeserializer  javadoc  extendeddeserializer  state  code  prefer  link  deserializer  access  header  required  kafka  drop  support  java  7  code  deserialize  method  introduced  interface  added  deserializer  default  implementation  backwards  compatibility  maintained  interface  may  deprecated  happens  code  since  dropped  java  7  support  figure  compatibility  implication  kip  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1843,reduce  npath  exception  connect  recent  upgrade  checkstyle  move  java  8httpsgithubcomapachekafkapull5046files1a83b7d04bd3cecbb68d033211b1bcdfbe085d47diff6869a8c771257f000c3cefb045e9d289  caused  existing  code  pas  npath  rule  look  class  see  might  need  changed  remove  class  suppression  rule  abstractstatusconnectrecordconnectschemadistributedherderfilestreamsourcetaskjsonconverterkafkaconfigbackingstore,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1844,add  getter  abstractstream  class  make  internaltopologybuilder  accessible  outside  package  currently  abstractstream  class  defines  copyconstructor  allow  extend  kstream  ktable  apis  new  method  without  impacting  public  interface  however  adding  new  processor  orand  store  topology  made  throught  internaltopologybuilder  accessible  abstractstream  subclass  defined  outside  package  package  visibility,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1845,make  stream  window  retention  time  strict  currently  configured  retention  time  window  lower  bound  actually  keep  window  around  time  roll  new  segment  time  drop  window  oldest  segment  long  window  still  segment  continue  add  latearriving  record  also  serve  iq  query  sort  nice  make  optimistic  use  fact  window  live  time  retention  expires  however  also  source  apparent  nondeterminism  arguably  better  programability  adhere  strictly  configured  constraint  therefore  new  behavior  retention  time  window  pass  stream  drop  laterarriving  record  warning  log  metric  likewise  iq  first  check  whether  window  younger  retention  time  answering  query  change  need  made  underlying  segment  management  purely  make  behavior  strict  wrt  configuration,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
1846,remove  caching  wrapper  store  cachesize  configured  zero  byte  user  disable  caching  globally  setting  cache  size  zero  config  however  effectively  disable  caching  layer  code  still  place  consider  remove  caching  wrapper  completely  case  tricky  part  insert  caching  layer  compile  time  ie  calling  streamsbuilderbuild  –  point  dont  know  configuration  yet  thus  need  find  way  rewrite  topology  passed  kafkastreams  case  caching  size  set  zero  kip  kip356  add  withcachingdisabled  storebuilderhttpscwikiapacheorgconfluencedisplaykafkakip3563aaddwithcachingdisabled2829tostorebuildersrcjira,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1847,overloaded  streamsbuilder  build  method  accept  javautilproperties  add  overloaded  method  streamsbuilder  accepting  javautilsproperties  instance  kip  found  httpscwikiapacheorgconfluencedisplaykafkakip3123aaddoverloadedstreamsbuilderbuildmethodtoacceptjavautilproperties,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1848,decrease  consumer  request  timeout  30  per  kip266  discussion  lower  request  timeout  also  add  new  logic  override  timeout  joingroup  request,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
1849,adminclient  handle  findcoordinatorresponse  error  currently  kafkaadminclientdeleteconsumergroups  listconsumergroupoffsets  method  implementation  ignoring  findcoordinatorresponse  error  cause  admin  client  request  timeouts  incase  authorization  error  handle  error,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1850,reduce  number  rebalance  large  consumer  group  topic  created  group  200  mirrormaker  consumer  pattenbased  topic  subscription  single  topic  creation  caused  50  rebalances  consumer  5  minute  period  cause  mm  significantly  lag  behind  5  minute  period  cluster  may  considerably  outofsync  period  ideally  would  like  trigger  1  rebalance  mm  group  topic  created  conceptually  doable  explanation  repeated  consumer  rebalance  based  consumer  rebalance  logic  latest  kafka  code  1  topic  10  partition  created  cluster  match  subscription  pattern  mm  consumer  2  leader  mm  consumer  group  detects  new  topic  metadata  refresh  trigger  rebalance  3  time  t0  first  rebalance  finish  10  consumer  assigned  1  partition  topic  190  consumer  assigned  partition  topic  moment  newly  created  topic  appear  consumercoordinatorsubscriptionssubscription  consumer  assigned  partition  consumer  refreshed  metadata  time  t0  4  common  case  half  consumer  refreshed  metadata  leader  consumer  group  refreshed  metadata  thus  around  100  10  110  consumer  newly  created  topic  consumercoordinatorsubscriptionssubscription  90  consumer  topic  consumercoordinatorsubscriptionssubscription  5  90  consumer  consumer  refreshes  metadata  add  topic  consumercoordinatorsubscriptionssubscription  cause  consumercoordinatorrejoinneededorpending  return  true  trigger  another  rebalance  consumer  refresh  metadata  almost  time  jointly  trigger  one  rebalance  otherwise  trigger  separate  rebalance  6  default  metadatamaxagems  5  minute  thus  worse  case  probably  also  average  case  number  consumer  group  large  latest  consumer  refresh  metadata  5  minute  t0  rebalance  repeated  5  minute  interval,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1851,add  support  custom  sasl  extension  oauth  authentication  kip  herehttpscwikiapacheorgconfluencedisplaykafkakip3423aaddsupportforcustomsaslextensionsinoauthauthentication  kafka  currently  support  nonconfigurable  sasl  extension  scram  authentication  protocol  delegation  token  validation  would  useful  provide  configurable  sasl  extension  oauthbearer  authentication  mechanism  well  client  could  attach  arbitrary  data  principal  authenticating  kafka  way  custom  principal  hold  information  derived  authentication  mechanism  could  prove  useful  better  tracing  troubleshooting  example  done  way  allows  easier  extendability  future  sasl  mechanism,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1852,kip328  add  window  grace  period  deprecate  window  retention  described  httpscwikiapacheorgconfluencedisplaykafkakip3283aabilitytosuppressupdatesforktables  ticket  cover  grace  period  portion  work,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1853,migrate  stream  api  duration  instead  longms  time  right  stream  api  unversally  represents  time  mssinceunixepoch  there  nothing  wrong  per  se  duration  ergonomic  api  dont  want  present  heterogeneous  api  need  make  sure  whole  stream  api  term  duration  implementation  note  duration  potentially  worsen  memory  pressure  gc  performance  internally  still  use  longms  representation  kip  httpscwikiapacheorgconfluencedisplaykafkakip3583amigratestreamsapitodurationinsteadoflongmstimes,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1854,stream  fencingsensitive  task  suspension  eos  eos  turned  stream  following  step  1  inittxn  task  creation  2  begintxn  topology  initialization  3  aborttxn  clean  shutdown  4  committxn  commit  called  suspend  well  consider  situation  two  thread  ta  tb  one  task  1  originally  ta  owns  task  consumer  generation  1  2  ta  unresponsive  send  heartbeat  get  kicked  new  generation  2  formed  tb  task  migrated  tb  ta  know  3  ta  finally  call  consumerpoll  aware  rebalance  rejoins  group  forming  new  generation  3  rebalance  leader  decides  assign  task  back  ta  4a  ta  call  onpartitionrevoked  task  suspending  call  commit  however  data  ever  sent  since  begintxn  commit  call  become  noop  4b  ta  call  onpartitionassigned  task  resuming  call  begintxn  encountered  producerfencedexception  incorrectly  root  cause  ta  trigger  inittxn  claim  im  newest  txnid  going  fence  everyone  else  txnid  mistakenly  treated  old  client  tb  note  issue  common  since  need  encounter  txn  send  data  make  committxn  call  noop  hence  fenced  earlier  one  proposal  issue  close  producer  recreates  new  one  suspend  committxn  call  succeeded  startnewtxn  false  new  producer  always  inittxn  fence  others,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1855,naming  join  grouping  repartition  topic  help  make  stream  compatible  topology  change  need  give  user  ability  name  operator  adjusting  topology  rolling  upgrade  possible  jira  first  effort  allow  giving  operator  deterministic  name  kip372  httpscwikiapacheorgconfluencedisplaykafkakip3723anamingrepartitiontopicsforjoinsandgrouping,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1856,improve  stream  close  timeout  semantics  see  httpsgithubcomapachekafkapull5682discussionr221473451  current  timeout  semantics  little  magical  0  mean  block  forever  negative  number  cause  close  complete  immediately  without  checking  state  think  would  make  sense  reject  negative  number  make  0  signal  return  immediately  checking  state  want  wait  forever  use  ofyears1  ofmillislongmaxvalue  intuitively  long  enough  forever  value  instead  magic  value  part  httpscwikiapacheorgconfluencedisplaykafkakip3583amigratestreamsapitodurationinsteadoflongmstimes,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1857,make  lensclient  implement  javalangautoclosable  would  allow  user  use  lens  client  trywithresources  clause  without  worrying  closing  manually  httpsdocsoraclecomjavasetutorialessentialexceptionstryresourceclosehtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1858,driverqueryhook  support  postselect  option  also  driverqueryhook  prelaunch  method  called  launching  query  also  option  interact  hook  postselect  called  query  accepted  lens  server  appropriate  driver  selected  also  prelaunch  called  individual  driver  moved  server  driver  manage  operation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1859,convert  dimension  filter  fact  filter  perfomace  improvement  outer  join  query  filter  like  following  converted  fact  filter  help  improving  query  performance  pushing  filter  driving  table  ie  fact  eg  dimname  x  becomes  factdimid  select  dimid  dim  dimname  xy,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1860,add  option  kill  query  timeout  api  timeout  right  execute  timeout  api  query  time  query  still  running  people  pull  report  provide  option  kill  query  upon  timeout  user  interested  result  beyond  timeout,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1861,expose  session  interface  serverapi  server  module  manage  session  extension  need  made  available  serverapi,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1862,multi  storage  query  written  properly  storage  start  end  time  configured  storage  s1  start  end  time  s2  namecubestoragetableendtimes  value20160331  s3  namecubestoragetablestarttimes  value20160401  s4  namecubestoragetablestarttimes  value20160401  query  cube  select  burn  mycube  timerangeindtime  2016033000  2016040123  async  storage  skipped  case  expected  union  s2  s3,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1863,isolate  submission  driver  need  isolate  query  submitter  driver  different  seen  scenario  hive  submission  take  time  interactive  query  jdbc  queued  querysubmitter  busy  also  driver  pool  submitter  benefit  interactive  query  immediate  submission  especially  one  submitted  executewithtimeout,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1864,ability  load  different  instance  driver  class  currently  loading  one  driver  instance  per  class  able  load  multiple  different  instance  driver  class  example  multiple  hivedrivers  talking  different  hiveservers  sitting  colo  different  jdbcdrivers  talking  different  db,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1865,support  asynchronous  status  update  driver  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1866,resolve  issue  case  aggregate  expression  dimattributes  condition  right  user  write  query  like  following  select  sumcase  dim1x  msr1  else  0  end  msr2  cube  timerangein  dim1  msr2  queryable  query  fails  saying  field  cannot  queried  together  query  accepted  work  fine  created  cube  expression,1,0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,1
1867,improve  scheduler  api  message  patch  includes  clearer  scheduler  apis,1,0,1,0,1,0,1,1,0,0,1,0,0,0,0,1,1
1868,thread  ability  wait  event  processed  thread  notifies  event  service  process  event  way  wait  finished  code  lensevent  event  new  lensevent  synchronizedevent  eventservicenotifyeventevent  eventwait  code  eventhandler  notifyall  event  done  handling  code  public  void  run  try  class  extends  lensevent  evtclass  eventgetclass  call  listener  directly  listening  event  type  handleeventeventlistenersgetevtclass  event  class  superclass  evtclassgetsuperclass  call  listener  listen  super  type  event  type  lenseventclassisassignablefromsuperclass  eventlistenerscontainskeysuperclass  handleeventeventlistenersgetsuperclass  event  superclass  superclassgetsuperclass  finally  synchronized  event  eventnotifyall  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1869,query  resource  lens  server  offer  limited  information  getallqueries  call  code  listqueryhandle  getallqueriessessionid  state  user  driver  queryname  fromdate  todate  code  currently  provides  limited  information  query  handle  upon  call  consuming  service  tabulate  minimal  information  query  history  call  getallqueries  followed  series  code  lensquery  getstatussessionid  queryhandle  code  would  helpful  resource  method  provide  richer  set  information  additional  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1870,add  data  completeness  checker  though  lens  partition  registration  done  whenever  data  available  guarantee  partition  registered  complete  different  way  know  data  complete  partition  one  option  could  partition  property  saying  whether  complete  could  http  call  another  hosted  service  proposal  add  interface  datacompletenesschecker  check  resolving  partition  capability  would  like  add  lens  lens  check  partition  existence  first  exists  check  completeness  percentage  completeness  percentage  le  configured  threshold  default  98  99  even  100  lens  fail  query  lens  accept  query  partial  data  accept  incomplete  data  well  lens  also  option  override  completeness  percentage  threshold  value  query  level  lens  still  look  ahead  capability  daily  incomplete  union  hourly  measure  two  different  fact  lens  pick  one  higher  availability  case  completeness  percentage  threshold  missed  lens  respond  back  available  percentage,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
1871,support  fact  fact  union  currently  lens  support  unioning  data  across  different  storage  single  fact  jira  lens  server  able  union  data  across  fact,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
1872,support  drop  partition  specific  update  period  facilitate  dropping  partition  based  update  period,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1873,add  example  execution  ml  create  utility  read  ml  params  test  table  etc  conf  execute  via  script,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1874,add  distinct  keyword  column  projected  dimension  query  currently  dimension  query  give  duplicate  row  joining  fact  specified  date  range  query  adding  distinct  keyword  projected  column  list,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1875,session  lifecycle  event  service  maintaining  session  specific  data  event  like  session  started  session  closed  would  useful  initcleanup  resource  would  also  useful  maintaining  session  history,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
1876,provide  option  list  resource  added  session  provide  command  lenscli  list  resource  added  particular  session,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1877,allow  start  end  time  column  fact  table  column  promoteddemoted  one  aggregate  fact  usage  column  report  need  following  use  case  field  moved  lower  cost  fact  since  fact  lower  cost  picked  processing  life  column  queried  fit  range  queried  higher  level  fact  picked  lower  level  fact  picked  would  lead  wrong  result  field  moved  higher  cost  fact  ie  life  ending  lower  cost  fact  depending  range  queried  either  lower  higher  level  fact  picked  like  optimization  case,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
1878,allow  timed  dimension  cube  nonpartitioned  column  well  use  case  say  cube  timed  dimension  et  query  come  et  storage  partitioned  et  fail  query  currently  notion  etit  plus  minus  10  storage  partitioned  timerange  et  resolved  partition  et  direct  column  along  partition  mapping  et  filter  also  need  applied  along  partition  lookup  requirement  accept  cube  definition  timed  dimension  resolve  corresponding  partition  storagetableresolver,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1879,driver  specific  configuration  set  query  context  driver  specific  query  conf  merged  currently  multiple  place  code  consolidating  driverselectorquerycontext,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
1880,minor  refactoring  change  query  rewriter  interface  queryrewrite  interface  need  moved  serverapi  minor  method  signature  change,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1881,add  support  user  query  rewriter  chain  cube  rewrite  need  add  support  configurable  query  rewriter  plugged  cube  rewrite  invoked,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1882,lenscli  use  single  parameter  two  value  code  like  following  many  place  cli  noformat  clicommandvalue  update  storage  help  update  storage  public  string  updatestorage  clioptionkey  storage  mandatory  true  help  storagename  path  storagespec  string  specpair  iterablestring  part  splitteron  trimresultsomitemptystringssplitspecpair  noformat  take  separate  parameter  value  split  space,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1883,add  latency  metering  resolver  cube  query  rewriter  since  cube  query  rewriter  go  many  resolvers  sequentially  want  find  much  time  taken  resolver  phase,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
1884,add  latency  metering  metric  api  exposed  rest  understand  latency  provided  lens  server  want  include  metering  api  explore  meter  httpsdropwizardgithubiometrics310manualcoremeters,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
1885,use  algorithm  instead  trainer  apis  currently  algorithm  trainer  used  interchangeably  could  cause  confusion  rename  class  method  use  algorithm  place,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1
1886,use  cube  query  context  setting  priority  avoid  explain  call  olap  query  using  cubequerycontext  setting  priority  proposal  extract  queryplan  information  cubequerycontext  use  directly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1887,use  prepare  statement  query  syntax  semantic  validation  currently  using  select  roughly  query  validation  jdbc  driver  rough  query  take  time  based  query  complexity  cant  guarantee  finish  50ms  hand  prepare  query  light  weight  expect  finish  defined  threshold  supported  major  dbms,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1888,add  api  adding  partition  batch  jira  adding  api  performance  improvement  taken  care  separate  jira,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
1889,timeouts  rest  api  call  lens  client  handle  case  server  responding  slow  response  need  put  timeouts  api  call  lens  client  need  see  one  value  suffice  api  call  specific  timeout  value  required  api  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1890,driver  side  rewrite  happening  twice  execute  call  jdbcdriver  seeing  driver  side  rewrite  happening  twice  jdbcdriver  one  estimate  driverexecute  done,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1891,provide  way  distinguish  field  reached  multiple  path  need  way  distinguish  field  reachable  different  path  example  country  field  reachable  two  different  attribute  value  different,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1892,lens  cli  given  dimension  find  dimtables  currently  able  get  dimension  dimtable  opposite  add  lens  cli  given  dimension  figure  dimtables  belonged  dimension,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1893,configurability  queryexecutionserviceimpl  driverselector  right  hard  coded  minquerycostselector  making  configurable  via  conf  query  acceptor  loaded  server  conf  renamed  variable  acceptedqueries  queuedqueries  test  case  acceptor,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1894,lens  service  health  status  provide  way  know  lensservices  health  right  rest  end  point  queryapi  metastore  simply  return  service  much  useful  ex  querysubmitter  died  server  way  know  another  end  point  exposed  adminhealthstatus  implemented  right  use  report  status  service  anything  loaded,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1895,modifying  concept  latest  partition  dimtables  0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
1896,add  cli  command  print  query  detail  command  print  detail  per  lensquery  cli,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1897,add  maxcoveringfactresolver  fact  partition  resolved  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1898,add  jar  able  take  regex  path  able  add  multiple  jar  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1899,addition  identifier  every  log  line  segregating  log  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1900,lens  cli  doesnt  provide  option  drop  db  cascade  set  true  way  dropping  db  lens  cli  empty  please  provide  option  drop  db  cli  cascade  set  true,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1901,move  hive  dependency  apache  hive  creating  wish  moving  apache  hive  dependency  instead  forked  hive  dependency  create  follow  issue  lens  hive  make  link,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1902,add  cli  command  show  queryable  field  description  cube  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
1903,union  support  across  storage  table  multi  fact  query  need  support  union  across  storage  table  oneall  fact  table  taking  part  multi  fact  query,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
1904,add  presubmit  hook  userconfigloader  call  driver  right  hadoop  queue  hive  job  triggered  fixed  need  dynamic  one  requirement  yarn  cluster  hierarchical  queue  based  job  priority  need  capability  able  choose  right  queue  based  priority  job,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1
1905,add  cli  command  getting  timeline  fact  single  fact  single  factstorage  pair  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1906,add  start  time  fact  fact  property  new  fact  added  populated  data  time  onwards  start  time  property  fact  help  picking  eligible  fact  given  range  without  property  light  fact  added  later  time  lightest  fact  first  flag  query  cannot  answered  older  range  cause  query  fail  similarly  add  end  time  well  fact  also  could  fact  data  valid  relative  start  time  example  90  day  data  valid  accepting  relative  start  time  allow  even  drop  partition  uptodate  query  pick  proper  fact,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1907,many  set  param  key  session  restoration  upon  restart  seeing  may  set  param  key  log  session  restoration  upon  restrat  set  param  involving  io  disk  turn  increase  restart  time  log  snippet  noformat  21  may  2015  060550806  main  info  orgapachelensserversessionhivesessionservice  set  param  keylensqueryoutputenablecompression  valuetrue  21  may  2015  060550806  main  info  orgapachelensserversessionhivesessionservice  request  set  param  keyhivemetastoreclientsockettimeout  value600  21  may  2015  060550806  main  info  orgapachehiveserviceclioperationoperation  putting  temp  output  file  tmplens260645777a384279ad730daa4a32a7671862119368791234528pipeout  21  may  2015  060550806  main  info  orgapachelensserversessionhivesessionservice  set  param  keyhivemetastoreclientsockettimeout  value600  21  may  2015  060550806  main  info  orgapachelensserversessionhivesessionservice  request  set  param  keyhivemetastoreconnectretries  value5  21  may  2015  060550806  main  info  orgapachehiveserviceclioperationoperation  putting  temp  output  file  tmplens260645777a384279ad730daa4a32a7671862119368791234528pipeout  21  may  2015  060550806  main  info  orgapachelensserversessionhivesessionservice  set  param  keyhivemetastoreconnectretries  value5  21  may  2015  060550806  main  info  orgapachelensserversessionhivesessionservice  request  set  param  keylensqueryenablemailnotify  valuetrue  21  may  2015  060550806  main  info  orgapachehiveserviceclioperationoperation  putting  temp  output  file  tmplens260645777a384279ad730daa4a32a7671862119368791234528pipeout  21  may  2015  060550807  main  info  orgapachelensserversessionhivesessionservice  set  param  keylensqueryenablemailnotify  valuetrue  21  may  2015  060550807  main  info  orgapachelensserversessionhivesessionservice  restored  session  260645777a384279ad730daa4a32a767  21  may  2015  060550807  main  info  orgapachehadoophiveqlsessionsessionstate  tez  session  required  point  hiveexecutionenginemr  21  may  2015  060550808  main  info  orgapachehadoophiveqlsessionsessionstate  tez  session  required  point  hiveexecutionenginemr  21  may  2015  060550808  main  info  orgapachelensserversessionhivesessionservice  request  set  param  keyhivemetastorefailureretries  value3  21  may  2015  060550810  main  info  orgapachehiveserviceclioperationoperation  putting  temp  output  file  tmplens4d63f0f8699c4a3eae2d6eaf03a5a3437220243919237070139pipeout  21  may  2015  060550810  main  info  orgapachelensserversessionhivesessionservice  set  param  keyhivemetastorefailureretries  value3  21  may  2015  060550810  main  info  orgapachelensserversessionhivesessionservice  request  set  param  keyhivemetastoreclientconnectretrydelay  value1  21  may  2015  060550811  main  info  orgapachehiveserviceclioperationoperation  putting  temp  output  file  tmplens4d63f0f8699c4a3eae2d6eaf03a5a3437220243919237070139pipeout  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1908,flattened  column  include  reachable  field  join  chain  right  flattened  column  returned  construct  reachable  field  reference  change  show  reachable  field  join  chain  expanding  reachable  field  join  chain  optional  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1909,add  time  dimension  supported  fact  prune  cause  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1910,support  single  column  expression  like  alias  right  seeing  issue  single  column  expression  putting  aggregate  around  column  expression  also  replacing  alias  correctly  alias  passed,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1911,refactoring  testquerycommands  test  case  many  test  case  running  testquerycommands  test  case  considerably  time  consuming  debug  failing  test  case  within  testquerycommands  test  case  modularized  broken  separate  test  case  much  helpful  faster  debugging  code  test  public  void  testquerycommands  throw  exception  client  new  lensclient  clientsetconnectionparamlensqueryenablepersistentresultsetindriver  false  setupclient  lensquerycommands  qcom  new  lensquerycommands  qcomsetclientclient  resdir  new  filetargetresults  asserttrueresdirexists  resdirmkdirs  testexecutesyncqueryqcom  testexecuteasyncqueryqcom  testsyncresultsqcom  testexplainqueryqcom  testexplainfailqueryqcom  testpreparedqueryqcom  testshowpersistentresultsetqcom  testpurgedfinishedresultsetqcom  testfailpreparedqueryqcom  run  query  command  query  metric  enabled  client  new  lensclient  clientsetconnectionparamlensqueryenablepersistentresultsetindriver  false  clientsetconnectionparamlensqueryenablemetricsperquery  true  qcomsetclientclient  string  result  qcomgetallpreparedqueriesall  1  1  assertequalsresult  prepared  query  testexecutesyncqueryqcom  testexecuteasyncqueryqcom  testsyncresultsqcom  testexplainqueryqcom  testexplainfailqueryqcom  testpreparedqueryqcom  testshowpersistentresultsetqcom  testpurgedfinishedresultsetqcom  testfailpreparedqueryqcom  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1912,applying  query  launching  constraint  allowing  query  launched  lens  always  accept  new  query  user  put  scheduling  queue  processing  next  candidate  query  picked  scheduling  queue  processing  launched  query  constraint  evaluated  candidate  query  launched  query  allows  candidate  query  launched  otherwise  candidate  query  added  waiting  query  launched  query  finished  waiting  query  selector  select  waiting  query  rescheduling  using  list  waiting  query  selection  policy  every  waiting  query  selection  policy  return  list  eligible  waiting  query  rescheduled  query  selector  calculate  intersection  multiple  list  eligible  waiting  query  add  result  intersection  scheduling  queue  reprocessing  initialization  query  constraint  waiting  query  selection  policy  configured  using  configuration  value  new  query  constraint  waiting  query  selection  policy  added  runtime  without  rebuilding  deploying  lens  module  driver  allowed  add  query  constraint  waiting  query  selection  policy  waiting  query  persisted  across  server  restarts  query  constraint  1  allow  candidate  query  launched  cumulative  query  cost  current  query  launched  user  submitted  candidate  query  le  cumulative  query  cost  ceiling  launching  new  query  waiting  query  selection  policy  1  select  waiting  query  user  whose  query  finished  query  constraint  2  allow  candidate  query  launched  current  concurrent  query  launched  selected  driver  le  max  concurrent  query  allowed  driver  waiting  query  selection  policy  2  select  waiting  query  driver  whose  query  finished,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1913,using  duration  fact  weight  based  query  cost  calculator  hive  driver  along  add  new  field  querycost  return  query  cost  calculated  implementation  normalizedquerycost  could  one  name  field,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,1
1914,file  name  suggestion  cli  path  expected  httpsgithubcomspringprojectsspringshellblobmastersrcmainjavaorgspringframeworkshellcommandsscriptcommandsjava  path  args  string  making  file  enable  suggestion,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1915,move  presubmit  hook  user  config  loader  separation  concern  pre  submit  hook  need  separate  user  config  loader  code  made  part  user  config  loader  need  originated  gap  user  config  loader  solution  could  separate  creating  jira  address  issue,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
1916,update  partition  command  lens  requirement  able  change  path  existing  partition,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
1917,query  get  purged  db  soon  finish  query  result  mail  working  finished  query  set  zero  query  immediately  going  db,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1918,ability  inspect  get  post  request  submitted  lens  server  want  application  based  handshake  including  secret  key  part  header  several  hook  available  lens  server  inspect  request  thus  giving  opportunity  accept  reject  request  however  request  coming  lensclient  doesnt  hook  able  modify  request  common  location  jira  track  creating  hook  javaxwsrsclientclientrequestcontext  user  opportunity  add  header  every  outgoing  request  lensclient,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1919,allow  column  name  mapping  fewall  column  underlying  storage  table  improvement  proposed  accept  column  mapping  column  underlying  storage  table  allows  column  different  underlying  storage  column  factdimtable  example  fact1  col1  s1fact1  col1  s2fact2  col1variant  s2fact2  column  mapping  property  specified  col1col1variant  s2fact2  becomes  eligible  storage  table  query  written  col1variant  col1  queried,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1920,allow  chain  ref  column  multiple  chain  destination  right  allow  referencedimattribute  chain  ref  column  specifies  chainname  refcol  chain  improvement  proposed  allow  different  chainname  refcol  pair  accepted  usecase  multiple  time  dimension  table  say  hourdim  daydim  monthdim  timestamp  field  mapped  time  field  cube  three  different  chain  associated  reference  attribute  optionally  referring  column  different  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1921,support  predicate  elastic  search  driver  0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1922,allow  fact  start  time  specified  storage  update  period  specify  absolute  relative  start  time  fact  improvement  request  add  ability  override  start  time  fact  storage  update  period,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1923,remove  accepting  tablereferences  referencedimattribute  joinchains  defined  reference  dim  attribute  tablereferences  joinchains  confusing  user  remove  support  table  reference  allow  reference  dimattribute  defined  chained  column  simplify  spec  user  also  remove  lot  code,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,1,0
1924,query  failure  retries  transient  error  retries  query  failure  transient  error  like  network  error  hive  server  reachable  metastore  reachable  db  reachable  retries  available  phase  submission  execution  updating  status  fetching  result  formatting  right  failure  result  marking  query  failed,1,0,1,0,1,0,0,1,0,1,1,0,0,0,0,0,1
1925,rename  logicaltablecrudcommand  conceptualtablecrudcommand  physicaltablecrudcommand  logicaltablecrudcommand  accordance  httplensapacheorguserolapcubehtmlconceptualtables,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1926,option  flattening  column  bridge  table  later  support  flatten  aggregate  column  bridge  table  join  added  lens752  enhancement  apply  aggregate  later  applying  filter  expression  column  ex  schema  example  given  lens752  user  query  revenue  filter  cube  select  usersportname  revenue  timerangeindtxy  usersportname  cricket  query  option  apply  filter  aggregate  similarly  cube  select  case  usersportnamecricket  ckt  usersportnamefootball  fb  else  na  end  revenue  timerangeindtxy  query  option  apply  expression  aggregate,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
1927,slow  response  time  metastorenativetables  api  obtain  list  native  table  cubemetastoreservice  following  1  fetch  list  table  one  metastoreclient  call  2  filter  cube  table  list  filtering  happens  looking  table  property  table  object  table  object  obtained  another  metastore  call  n  table  n  metastore  call  code  snippet  private  liststring  gettablesfromdblenssessionhandle  sessionid  string  dbname  boolean  prependdbname  throw  metaexception  unknowndbexception  hivesqlexception  texception  lensexception  liststring  table  getsessionsessionidgetmetastoreclientgetalltables  dbname  liststring  result  new  arrayliststring  table  null  tablesisempty  iteratorstring  tablesiterator  ithasnext  string  tblname  itnext  orgapachehadoophivemetastoreapitable  tbl  getsessionsessionidgetmetastoreclientgettabledbname  tblname  tblgetparametersgetmetastoreconstantstabletypekey  null  prependdbname  resultadddbname  tblname  else  resultaddtblname  return  result  instead  directly  fetch  list  table  object  list  table  name  single  api  call  using  getmetastoreclientgettableobjectsbyname  method  currently  one  database  contain  8000  table  lead  long  response  time,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1928,add  relative  end  time  fact  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1929,expression  pushdown  query  optimisation  jdbc  currently  columnar  rewriter  skip  rewrite  case  expression  used  select  query  ticket  add  improvement  rewriter  rewrite  pushdown  fact  subquery,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1930,query  result  two  storage  table  fact  unioned  row  aggregated  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1931,refactor  public  static  inner  class  joinresolver  separate  class  right  joinresolver  class  huge  many  static  class  inside  issue  move,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
1932,allow  perqueue  driver  max  launched  query  constraint  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1933,enable  streaming  result  query  user  application  would  want  persist  also  stream  result  query  finish  fast  produce  small  result  set  jira  track  support  feature,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
1934,session  close  result  queued  query  failure  current  scenario  query  queued  lens  side  throttling  query  fails  session  close,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1935,add  error  code  jdbc  query  execution  exception  part  lens750  implemented  hive  error  code  query  table  column  doesnt  exist  need  implemented  jdbc  well  ideally  rename  lenshiveerrorcode  lensdrivererrorcode  driver  use,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
1936,make  cube  keyword  optional  query  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1937,update  cli  show  streaming  result  taken  lens901  committed,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1
1938,persist  query  priority  lens  db  query  priority  persisted  query  detail  api  show  query  priority  query  memory  purged  info  available,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0
1939,cli  allow  query  execution  without  prefix  query  execute  0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
1940,skip  partition  registration  old  future  date  fact  table  currently  fact  partition  registration  scheme  date  flowing  source  oldepoch  start  time  future  date  dont  check  skip  rather  accept  partition  fact  start  time  ignore  older,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1941,add  suport  join  chain  dimension  table  currently  join  chain  supported  cube  need  supported  dimension  table  well  dimension  query,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1
1942,add  cubesegmentation  base  cube  cube  segmentation  cube  multiple  cube  child  cube  together  make  cube  complete  cubesegmentation  cubefacttable  sit  together  mean  belong  one  base  cube  base  cube  one  cube  segmentation  field  segmentation  intersection  column  cube  segmentation  weight  compare  buddy  fact  segmentation  also  start  end  time  defined  derive  underline  fact  eg  basecube  fact1  fact2  cubesegment1  cube1  fact11  fact12  cubesegment2  cube2  fact21  fact22,1,1,1,1,1,0,0,0,1,0,1,1,0,0,0,0,1
1943,querycontextprioritycomparator  compare  priority  instead  cost  right  comparing  query  query  cost  query  priority  change  position  queue  cost  value  different  instead  compare  priority  instead  cost  sothat  position  query  change  within  priority  bucket,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1
1944,query  optimization  findroute  dequeuemessage  query  matcher  job  execution  matcher  job  correlationkeyset  used  contain  pre  initialised  correlation  key  httpsgithubcomapacheodeblobode13xbpelruntimesrcmainjavaorgapacheodebpelruntimepickjaval87  httpsgithubcomapacheodeblobode13xbpelruntimesrcmainjavaorgapacheodebpelruntimeeheventjaval120  hence  directly  use  correlationkeysets  canonical  value  instead  subset  findroute  dequeuemessage  method  call  within  matcherevent  avoids  use  sql  clause  findroute  dequeuemessage  query  improves  execution  time  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1945,move  hot  deployment  runtime  hot  deployment  handled  axis2  module  isnt  right  want  make  common  jbi  il  implementation  move  bpelruntime  clean  fix  couple  additional  thing  needed  comply  deployment  spec,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,1
1946,extensionactivity  extensionassignoperation  support  parser  compiler  bpels  extension  mechanism  powerful  ease  data  manipulation  debugging  aim  task  bring  implementation  correctly  parsing  compiling  extensionactivitys  extensionassignoperations  therefore  api  need  slightly  extended  plugin  mechanism  extension  bundle  bundle  related  specific  extension  namespace  consist  extensionactivity  extensionassignoperation  implementation  bundle  registered  engine  using  odeconfiguation  property  file  parser  compiler  extended  cope  extension  extension  extensionactivity  extensionassignoperation  element  runtime  part  need  discussion  addressed  task,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1947,extensionactivity  extensionassignoperation  runtime  support  ticket  address  development  runtime  support  pluggable  extensionactivities  extensionassignoperations,0,1,0,1,0,0,0,0,1,1,1,0,0,0,0,0,0
1948,expose  process  management  api  jbi  bus  expose  process  management  api  jbi  bus,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
1949,httpbinding  support  add  support  httpbinding  ode  solution  could  extract  interface  orgapacheodeaxis2externalservice  current  externalservice  would  become  soapbinding  implementation  new  interface  jira  provide  httpbinding  implementation  instantiation  one  implementation  would  take  place  orgapacheodeaxis2odeservercreateexternalservice  information  required  pick  right  implementation  passed  method  already  httpwwww3orgtrwsdlhttp,1,0,1,0,1,0,0,0,0,1,1,0,0,1,1,0,0
1950,deployment  using  web  service  interface  allow  remote  deployment  using  web  service  deployment  package  basically  zip  containing  directory  necessary  file  sent  attachment  message,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
1951,axis2testbase  centralize  server  management  base  class  orgapacheodeaxis2axis2testbase  raison  detre  embed  ode  server  test  purpose  concrete  test  class  may  deploy  process  invoke  operation  etc  however  today  server  management  base  class  level  subclass  responsible  startingstopping  server  test  case  stop  server  next  test  case  executed  fail  start  server  since  port  already  used  etc  moreover  management  interface  kind  fuzzy  call  start  start  serverstop  shutdown  fix  aim  centralize  server  management  base  class  server  startedstopped  junit  setupteardown  method  subclass  worry  anymore  course  subclass  perform  custom  setupteardown  step  responsability  call  super  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1952,dynamic  config  axis2  external  service  one  might  want  apply  specific  setting  external  endpoint  used  process  instance  http  timeout  http  redirections  security  setting  ode  service  concerned  page  place  holder  material  project  seems  relevant  reuse  axis2  configuration  mechanism  soapbound  service  need  reinvent  wheel  however  homemade  mechanism  implemented  httpbound  service  axis2  service  config  file1  might  dropped  deployment  unit  directory  external  service  involved  process  file  name  pattern  localservicenameaxis2  file  change  creationdeletionupdates  polled  regularly  applied  epr  1  httpwsapacheorgaxis210axis2confightmlserviceconfiguration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1953,support  put  delete  method  0,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1
1954,fix  inmemory  daos  fix  inmemory  dao  implementation  principally  implementing  new  message  exchange  method  bpeldaoconnectionimpl  testing,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1955,xpath  function  restful  bpel  combineurl  composeurl  expandtemplate  provide  2  new  xpath  function  described  ode  wiki  combineurlbase  relative  take  relative  url  combine  base  url  return  new  absolute  url  relative  parameter  absolute  url  return  instead  composeurltemplate  name  value  composeurltemplate  pair  expands  template  url  substituting  place  holder  template  example  orderid  id  5  return  order5  substitute  value  either  namevalue  pair  passed  separate  parameter  nodeset  returning  element  name  mapping  value  function  applies  proper  encoding  mapped  value  undefined  variable  replaced  empty  string  basically  uri  always  returned  compliant  uri  template  spec  1  expandtemplatetemplate  name  value  expandtemplatetemplate  pair  behavior  composeurl  except  undefined  variable  replaced  empty  string  corresponding  expansion  pattern  replaced  immediate  coensquence  function  may  return  template  1  httpbitworkingorgprojectsuritemplatesspecdraftgregoriouritemplate03html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1956,epr  configuration  abstract  add  support  external  service  configuration  runtime  setting  like  timeout  proxy  header  etc  may  defined  dynamically  servicebasis  could  done  property  file  per  deployment  unit  detail  issue  add  mechanism  pas  property  processconf  integration  layer  leverage  configure  external  service  processconf  interface  method  mapstring  string  getpropertiesstring  method  meant  expose  property  integration  layer  property  specific  process  configuration  implementor  responsability  define  property  used  string  array  received  argument  may  used  specify  filter  criterion  get  subset  property  default  implementation  default  implementation  use  first  two  parameter  service  name  port  name  method  backed  property  file  named  integrationlayerproperties  file  must  placed  deployment  unit,1,0,0,0,0,0,0,0,1,0,0,1,1,0,0,1,1
1957,rest  connector  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1958,allow  bpel  process  provided  jms  general  requirement  follows  allow  two  process  provide  service  jms  queue  endpoint  b  allow  two  process  provide  port  type  different  service  jms  queue  endpoint  c  allow  two  process  provide  service  jms  topic  endpoint  allow  two  process  provide  port  type  different  service  jms  topic  endpoint  e  allow  process  invoke  service  process  jms  endpoint  work  following  assumption  operation  provided  jms  topic  must  oneway  avoid  multiple  response  per  request  b  operation  provided  jms  queue  may  either  oneway  twoway  c  per  axis2  protocol  nondurable  nonexistent  destination  name  qualified  either  dynamicqueues  dynamictopics  limitation  existing  code  base  name  assign  axis  service  derived  soaplocation  endpoint  assumed  follow  http  scheme  b  possible  two  process  provide  service  lead  naming  conflict  c  default  jms  transport  enabled  axis2  proposed  verified  solution  testing  purpose  enable  jms  transport  axis2xml  note  default  turned  configuration  jms  axis2  setup  jms  broker  left  exercise  userdeveloper  b  derive  service  name  jms  endpoint  without  making  assumption  made  http  endpoint  qualify  jms  endpoint  bundle  diagram  process  name  make  unique  necessary  avoid  naming  conflict  precise  jms  uri  template  follows  deployserverurldeploybasesoapservicesurldeploybundlencnamediagramrelativeurlprocesslocalnamejmsdestinationname  c  extract  jms  destination  name  service  name  set  value  jmsconstantsdestparam  axis  service  required  jms  connection  factory  creates  right  destination  endpoint  store  axis  service  odeserver  unique  name  derived  use  name  destroying  service  well  e  far  requirement  e  believe  work  box  f  far  assumption  believe  constraint  enforced  modeler  also  modeler  enforce  assumption  c  proper  provisioning  process  jms,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1959,list  deployed  package  process  provide  way  management  api  list  package  deployed  process  included  package  package  process  belongs,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
1960,publishsubscribe  across  process  default  soap  request  targeted  specific  bpel  process  ode  time  though  one  might  want  publish  request  simultaneously  multiple  bpel  process  especially  invocation  oneway  issue  describes  implementation  feature  bpel  runtime  way  agnostic  integration  layer  transport  binding  order  facilitate  message  publishing  process  must  way  subscribe  message  many  way  register  subscription  chose  implicit  mechanism  subscription  wherein  new  deployment  artifact  required  approach  two  process  provide  ie  shared  service  message  targeted  endpoint  service  essentially  fan  subscribing  process  general  two  path  need  considered  outofprocess  invocation  shared  service  follows  path  outlined  bpelservercreatemessageexchange  method  shared  service  create  new  kind  brokered  mex  clone  push  message  subscribing  process  b  inprocess  invocation  shared  service  follows  path  outlined  bpelprocessinvokepartner  method  bypass  mexs  creates  mexdaos  directly  clone  push  message  subscribing  process  registration  service  associated  list  process  provide  could  potentially  size  endpoint  physically  activated  integration  layer  first  process  register  physically  deactivated  last  process  deregisters  care  must  taken  though  remove  older  version  process  server  map  also  order  handle  twoway  pubsubs  gracefully  take  response  one  process  return  endconsumer  ideally  designtime  tooling  take  care  prevent  pubsub  across  service  whose  operation  oneway,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1961,support  wssecurity  external  service  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1962,process  instance  cleanup  add  ability  automatically  remove  process  instance  data  instance  completesterminates,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1963,support  multiple  matching  correlation  set  imas  wsbpel  20  spec  specifies  multiple  matching  correlation  set  handled  section  92  multiple  correlation  set  used  ima  initiateno  message  must  match  correlation  set  message  delivered  activity  given  process  instance  currently  ode  support  multiple  initiating  correlation  set  support  one  matching  correlation  set  change  includes  1  ima  multiple  correlation  set  specified  initiating  correlation  set  created  newly  remaining  correlation  set  bound  correlation  key  used  combined  key  match  instance  2  instead  single  correlationkey  object  set  correlationkeys  used  serializing  key  set  database  comparing  set  correlation  set  value  incoming  message,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
1964,improve  rakefile  enable  testing  different  dbms  1  user  setting  make  database  property  overridable  2  build  testing  environment  dbms  tested  nightly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1965,enable  easier  extensibility  ode  custom  implementation  simulation  could  done  providing  axis2  integration  adapter  even  proving  extensibility  engine  code  idea  people  implement  hook  trace  execution  alter  standard  behavior  work  directly  forementioned  job  make  easier,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1966,instance  replayer  imagine  situation  client  deployed  process  lot  active  long  running  instance  find  there  bug  process  simple  bugfix  needed  current  versioning  rule  new  version  used  new  instance  created  there  simple  way  bufixes  usually  possible  eg  java  application  using  database  connection  blocking  argument  deploying  ode  bpel  solution  instead  regular  java  application  think  best  way  deal  situation  add  serializedeserialize  tofrom  xml  operation  process  instance  management  api  also  pauseresume  ode  operation  would  useful  bugfix  procedure  would  look  like  pause  ode  serialize  instance  deploy  newer  version  deserialize  instance  fix  manually  import  error  resume  ode  would  also  benefit  able  migration  older  newer  ode  hibernatejpa  daos  saw  already  bug  report  think  regard,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1967,support  initiatejoin  receives  createinstance  initiatejoin  value  correlation  supported  receives  createinstancetrue  implement  case  well  correlation  comparison  logic,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1968,ability  override  httpaddress  wsdl  using  server  global  configuration  usecase  moving  project  development  production  often  necessary  change  service  url  reflect  production  system  make  easy  override  httpaddress  wsdl  service  using  ode  global  configuration  support  usecase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1969,rejecting  inout  operation  immediately  there  route  found  related  discussion  httpmarkmailorgthreadethxp3y7373x72h3  goal  implement  handling  inout  operation  immediately  resulting  failure  there  route  registered  inonly  operation  queue  message  later  dispatching  like,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
1970,process  hydrationdehydration  improvement  better  control  memory  footprint  present  bpel  server  stash  metadata  deployed  process  inmemory  unbounded  cache  given  unbounded  nature  cache  server  bound  eventually  run  memory  presented  sufficiently  large  process  set  graceful  way  handle  situation  would  place  bound  cache  either  term  total  size  number  process  may  contain  given  point  time  throttling  server  way  may  effectively  reduce  throughput  certainly  far  lesser  evil  compared  alternative  end  define  following  configurable  property  benefit  administrator  processhydrationthrottledmaximumsize  value  property  specifies  maximum  size  metadata  process  currently  inuse  may  cached  inmemory  process  metadata  hydrated  least  server  instance  size  calculated  traversing  object  model  estimate  inmemory  size  based  size  cbp  file  serialized  byte  persisted  b  processhydrationthrottledmaximumcount  value  property  specifies  maximum  number  process  currently  inuse  whose  metadata  may  cached  inmemory  process  stored  disk  loaded  inmemory  said  unhydrated  server  receives  message  targeted  unhydrated  process  must  decide  whether  sufficient  free  memory  cache  select  least  recently  used  process  victim  evict  dehydrate  check  balance  performed  sufficient  memory  case  may  hydrate  process  hand  cache  capacity  exceeded  process  message  based  exchange  pattern  described  message  oneway  asynchronous  queue  back  job  scheduler  retried  later  hope  given  sufficient  amount  delay  number  retries  cache  enough  room  targeted  process  ii  message  twoway  synchronous  cannot  simply  reschedule  back  client  doubt  timeout  logical  thing  return  soap  fault  message  force  client  handle  retries  desire  furthermore  administrator  may  use  following  property  enable  control  lazyloading  c  processhydrationlazy  value  property  specifies  whether  process  metadata  lazyloaded  server  immediately  load  process  metadata  upon  startup  deployment  fact  process  hydrated  server  receives  message  demand  process  loaded  inmemory  global  property  may  overriden  processbyprocess  basis  specifying  value  namesake  process  deployment  descriptor  deployxml  file  processhydrationlazyminimumsize  value  property  specifies  approximate  minimum  size  process  metadata  lazyloading  enabled  server  calculates  approximate  size  process  metadata  based  serialized  file  size  le  value  specified  herein  load  process  eagerly  way  dont  suffer  time  delay  hydration  message  dont  deal  largesized  process  lastly  introduce  following  property  throttle  number  instance  process  may  handle  e  processinstancethrottledmaximumcount  value  property  specifies  maximum  number  instance  may  simultaneously  active  given  process  global  property  may  overriden  processbyprocess  basis  specifying  value  namesake  process  deployment  descriptor  deployxml  file  note  assume  process  already  hydrated  time  perform  check  property  directly  related  caching  however  may  indirect  effect  cache  virtue  fact  likely  cause  process  dehydrate  sooner  rather  later  dehydration  policy  p  note  inmemory  representation  process  metadata  made  wsdl  bpel  object  model  cache  refer  deal  specifically  bpel  object  purpose  issue  caching  wsdl  object  considered  scope,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1971,improve  process  versioning  jbi  time  redeploy  service  assembly  servicemix  there  new  process  version  registered  ode  also  old  entry  old  cbp  deleted  cause  old  instance  throw  error  reloading  compiled  process  error,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1972,better  error  reporting  w  client  currently  process  called  error  happens  processing  error  communicated  back  client  instead  client  get  timeout  exception  confusing  example  20090305  193006873  error  orgapacheodeaxis2odeservice  timeout  execution  error  waiting  response  mex  myrolemex632  client  96038a4514094bdaab3381fd29de4a483  calling  httpwwwintaliocombpmsworkflowib4p20051115uifwservicecompletetask  javautilconcurrenttimeoutexception  message  exchange  orgapacheodebpelenginemyrolemessageexchangeimplresponsefuturee8b20a  timed  waiting  response  javautilconcurrenttimeoutexception  message  exchange  orgapacheodebpelenginemyrolemessageexchangeimplresponsefuturee8b20a  timed  waiting  response  orgapacheodebpelenginemyrolemessageexchangeimplresponsefuturegetmyrolemessageexchangeimpljava241  orgapacheodeaxis2odeserviceonaxismessageexchangeodeservicejava152  orgapacheodeaxis2hooksodemessagereceiverinvokebusinesslogicodemessagereceiverjava67  orgapacheodeaxis2hooksodemessagereceiverinvokebusinesslogicodemessagereceiverjava50  orgapacheaxis2receiversabstractmessagereceiverreceiveabstractmessagereceiverjava96  orgapacheaxis2engineaxisenginereceiveaxisenginejava145  proposal  report  back  client  error  processing  request  default  feature  could  turned  security  reason  since  may  create  risk  information  disclosure,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1973,placeholder  endpoint  property  endpoint  property  1  support  placeholder  placeholder  use  property  value  avoid  repeating  common  value  general  placeholder  pattern  placeholdername  three  type  placeholder  shall  separated  1  environment  placeholder  placeholder  environment  variable  follow  naming  convention  ala  ant  envjavahome  retrieve  javahome  env  var  2  system  placeholder  placeholder  system  property  follow  naming  convention  systemlog4jconfiguration  access  system  property  log4jconfiguration  system  placeholder  might  point  environment  placeholder  3  local  placeholder  placeholder  defined  one  endpoint  property  file  use  prefix  mytimeout  replaced  value  mytimeout  placeholder  local  placeholder  value  might  used  2  previous  placeholder  type  env  var  sys  property  mytimeoutenvtimeout  valid  replaced  env  variable  timeout  local  placeholder  defined  one  file  used  another  defined  twice  last  loaded  value  precedence  example  placeholder1placeholder1value  testplaceholder1placeholder1  nsaliasmyserviceodehttpsockettimeoutsystemtestsystemproperty  nsaliasmyserviceodemextimeoutenvtestdummyenvvar  see  orgapacheodeutilshierarchicalpropertiestest  1  httpodeapacheorguserguidehtmluserguideendpointconfiguration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1974,unpack  detail  blob  odejob  table  related  discussion  httpmarkmailorgthreadiiy6utvsqew6nn6m,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
1975,support  setting  mutliple  message  mapper  currently  engine  support  multiple  message  mapper  registered  however  way  user  configure  add  way  user  specify  multiple  mapper,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1976,implement  immediate  transaction  retries  addition  presistent  retries  currently  ode  engine  reschedules  job  odejob  table  job  fails  job  picked  later  job  scheduler  node  2  reason  want  prepend  immediate  transaction  retry  logic  persistent  retries  1  current  way  scheduling  job  involves  deleting  job  insertingselecting  new  job  retry  system  heavy  load  failure  due  deadlock  database  overload  want  put  even  load  2  interval  retries  could  pretty  long  case  like  database  deadlock  resolved  retrying  transaction  relatively  short  time  repeat  transaction  configurable  number  try  configuration  interval  try  still  fail  schedule  job  persistent  retries,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1977,denormalizing  large  data  currently  hibernate  implementation  process  data  access  object  dao  interface  large  read  blob  value  stored  table  belongs  rather  detached  table  called  largedata  example  dependent  table  include  hold  state  bpel  instance  bpel  event  soap  message  wsdl  partner  link  xml  variable  among  thing  inevitably  largedata  table  end  becoming  bottleneck  force  u  execute  large  number  join  also  hold  many  lock  result  hibernate  dao  layer  take  longer  readwritedelete  process  data  may  potentially  deadlock  largedata  table  obvious  way  mess  move  blob  column  largedata  table  table  currently  referenced  foreign  key  however  care  must  taken  migrate  schema  data  existing  server  time  upgrade  upgrade  path  described  dependent  table  refers  table  currently  foreign  key  reference  parent  ie  largedata  table  foreign  key  dependent  table  add  corresponding  blob  column  dependent  table  b  foreign  key  dependent  table  copy  blob  value  corresponding  row  parent  corresponding  column  dependent  added  step  c  drop  foreign  key  dependent  table  refer  largedata  table  largedata  table  finally  increment  version  ode  schema  indicate  schema  changed  needle  say  must  prepared  scenario  wherein  server  upgraded  schema  wasnt  whatever  reason  checking  ode  schema  version  time  server  startup  failing  gracefully  doesnt  match  expected  value  note  consciously  chose  automate  upgrade  path  part  migration  handler  primarily  due  longrunning  nature  transaction  result  change  observed  significant  improvement  performance  hibernatebased  process  server  3040  however  individual  result  may  vary  note  downside  moving  blob  column  dependent  table  may  inadvertently  end  reading  blob  property  sideeffect  unrelated  query  table  may  guessed  motivation  introducing  largedata  table  first  place  fortunately  way  mitigate  case  include  using  lazy  fetching  blob  property  problematic  dependent  table  b  reintroducing  large  data  table  specifically  problematic  dependent  table  using  join  fetching  work  around  n1  select  problem  plan  implementing  optimization  casebycase  basis  required,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
1978,implement  process  context  propagation  implementation  feature  specified  httpodeapacheorgprocesscontextshtml,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1979,implement  classpath  resolved  xsd  wsdl  import  currently  ode  jbi  requires  wsdl  xsds  unpacked  service  unit  required  restriction,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1980,separate  configuration  runtime  process  representation  right  processdao  mix  configuration  information  deploy  date  custom  property  activeretired  serialized  compiled  process  runtime  information  instance  correlators  isnt  nice  also  source  many  deployment  problem  duplicate  information  filesystem  deployed  process  bundle  database  clean  im  going  introduce  sort  process  configuration  store  still  havent  found  really  impressive  name  would  handle  process  deployment  maintaining  deployment  time  involves  redeployment  undeployment  could  also  versioning  future  configuration  change  runtime  would  use  get  information  process  currently  deployed  activate  would  introduce  cleaner  separation  runtime  static  process  definition  would  much  line  deployment  specification  would  also  make  clustering  easier  configuration  could  easily  propagated,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
1981,implement  osgi  packaging  ode  implement  osgi  packaging  ode  make  sure  ode  consumable  set  bundle,1,0,1,0,1,0,0,0,1,0,1,0,0,1,1,0,0
1982,speed  listallprocesses  listallprocesses  processandinstancemanagementimpljava  lot  query  database  order  fetch  instance  summary  cause  transaction  timeout  ode  load  disabling  instance  summary  workaround  diff  git  abpelruntimesrcmainjavaorgapacheodebpelengineprocessandinstancemanagementimpljava  bbpelruntimesrcmainjavaorgapacheodebpelengineprocessandinstancemanagementimpljava  index  47ada7a0317864  100644  abpelruntimesrcmainjavaorgapacheodebpelengineprocessandinstancemanagementimpljava  bbpelruntimesrcmainjavaorgapacheodebpelengineprocessandinstancemanagementimpljava  8056  8057  public  class  processandinstancemanagementimpl  implement  instancemanagement  pro  depinfosetdocumentpconfgetbpeldocument  depinfosetdeploydatetocalendarpconfgetdeploydate  depinfosetdeployerpconfgetdeployer  customincludeinstancesummary  tinstancesummary  isum  infoaddnewinstancesummary  geninstancesummaryentryconn  isumaddnewinstances  tinstancestatusactive  pconf  8147  8157  public  class  processandinstancemanagementimpl  implement  instancemanagement  pro  geninstancesummaryentryconn  isumaddnewinstances  tinstancestatussuspended  pconf  geninstancesummaryentryconn  isumaddnewinstances  tinstancestatusterminated  pconf  getinstancesummaryactivityfailureconn  isum  pconf  customincludedocumentlists  tprocessinfodocuments  docinfo  infoaddnewdocuments,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1983,document  function  xsl  script  resolve  remote  document  document  function  used  xsl  script  via  doxsltransform  load  external  document  current  implementation  considering  file  local  file  system  addition  able  also  load  resource  httphttps  endpoint  suggest  convert  uri  url  use  url  connection  fetch  content  cover  file  http  http  internet  protocol,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
1984,fix  circular  dependency  jacob  jacobobject  root  abstraction  pi  calculus  engine  depends  jacobvpu  engine  implementation  need  clean  abstraction  little  bit,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
1985,remove  imageio  dependency  pdpage  converttoimage  bug  creates  white  image  black  white  pdf  file  bug  reported  various  ticket  submitted  attempting  conclusively  prove  issue  need  attended  since  past  ticket  regarding  bug  marked  invalid  attached  video  showing  basic  code  reproduce  issue  also  attached  code  cause  issue  well  pdf  file  work  color  one  black  white  pdf  file  doesnt  main  issue  reading  black  white  pdf  file  see  attached  black  white  pdf  file  following  message  displayed  content  output  image  completely  white  26052011  32014  pm  orgapachepdfboxutiloperatorpagedrawerinvoke  process  warning  getrgbimage  returned  null  use  pdfbox  program  reading  pdf  file  least  50  percent  customer  pdf  file  different  scanner  read  issue  complete  show  stopper  id  happy  help  way  could  resolve,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1986,unit  test  pdfbox  feature  upgrading  pdfbox  use  ensure  arent  regression  also  learning  pdfbox  unit  testing  class  especially  pdf  primitive  object  co  level,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1987,pattern  colorspace  support  pdfbox  doesnt  support  pdpattern  colorspaces,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1988,color  conversion  pdjpegs  using  devicen  colorspace  pdfbox1116  pdfbox1154  already  added  color  conversion  pdjpegs  pdpixelmaps  except  one  handling  devicen  colorspaces,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1989,speed  lzwfilter  decoding  noticed  lzw  decoder  performance  improved  allocating  new  byte  every  byte  visit  stream  actually  on2  cost  n  typically  fairly  small  changed  lzwdictionary  use  private  growable  byte  accumulate  added  byte  also  changed  preenroll  initial  0255  code  instead  add  lazily  demand  code  used  also  randomized  testfilters  test  mixed  predictable  pattern  get  better  testing  filter  test  fails  print  seed  used  random  number  reproduce  failure,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
1990,add  save  image  pdfreader  extend  pdfreader  save  image  function  itd  easy  save  current  page  png,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
1991,adding  basic  job  ticket  schema  add  missing  schema  basic  job  ticket  evolution  make  evolution  parser  enable  array  structured  property  enable  multi  namespace  description  rdfdescription  without  forcing  first  description  schema  description,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1992,improve  xmpbox  code  strength  fix  issue  xmpbox  code  improve  strength  quality  preserve  stack  trace  system  println  loose  coupling  avoid  print  stack  trace  integer  instanciation  constructor  call  overridable  method,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
1993,nonsequential  pdf  parser  patch  currently  pdf  parsing  done  sequential  manner  resulting  problem  stream  parsing  skipping  unused  content  solution  conforming  parser  first  read  xref  table  us  information  parse  required  object  us  length  information  stream  parsing  completely  new  implementation  parser  currently  worked  pdfbox1000  parser  long  term  solution  short  term  solution  based  existing  code  would  desirable  first  incomplete  solution  presented  pdfbox1104  starting  pdfbox1104  implemented  much  possible  conforming  parser  called  nonsequential  parser  handle  pdf  document  even  inlined  object  stream  etc  parser  used  dropinreplacement  pdfparser  subclass  pdfparser  overwrites  method  parse  getpage  method  restriction  currently  need  specify  file  instead  input  stream  order  efficiently  read  file  use  existing  object  parsing  code  developed  randomaccessbufferedfileinputstream  allows  inputstream  operation  combination  seek  operation  cached  read  data  order  use  nonsequentialpdfparser  small  change  addition  existing  class  needed  includes  changing  methodsfields  private  protected  pdfparser  add  parsing  stream  object  information  xref  stream  store  get  information  xreftrailerresolver  object  id  stored  negated  order  distinguish  offset  allow  resetting  offset  pushbackinputstream  change  change  behavior  current  parser  another  requirement  long  offset  patch  pdfbox1196  excluded  patch  set  provided  provided  parser  currently  work  forceparsingfalse  mode  resulting  ioexception  parsing  error  occurs  case  shouldnt  problem  since  use  case  exception  typically  occur  trying  parse  unused  content  stream  new  parser  problem  anymore  setup  use  new  parser  first  parsing  error  occurs  fall  back  sequential  parser  bit  like  acrobat  xref  information  buggy  try  try  first  mostly  standard  conform  parsing  doc  pddocumentloadnonseq  pdffile  rabuf  handledocumentdoc  catch  ioexception  ioe  retry  sequential  parser  force  parsing  doc  pddocumentload  new  fileinputstreampdffile  rabuf  true  handledocumentdoc  new  parser  work  well  large  document  collection  large  step  forward  parse  document  also  accepted  common  pdf  tool  behavior  nearly  conform  nevertheless  need  clean  real  conforming  parser  instance  since  underlying  object  structure  access  parser  necessary  first  parse  object  used  includes  object  might  needed  another  normally  needed  step  copying  content  stream  since  work  file  random  access  would  need  however  parser  fill  hole  full  featured  clean  conforming  parser  available,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1994,refactor  io  interface  patch  new  conforming  pdf  parser  pdfbox1000  pdfbox1199  access  requirement  input  data  current  parser  depending  component  lexer  parser  sequential  read  random  read  needed  order  support  multiple  kind  source  access  defined  via  interface  allows  different  implementation  file  stream  since  pdfbox  already  randomaccess  interface  compatible  solution  split  interface  hierarchy  randomaccess  extends  randomaccessread  extends  sequentialread  attached  new  class  randomaccessread  sequentialread  well  patch  randomaccess,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
1995,adding  style  information  pdf  html  converter  patch  modifies  pdf  html  conversion  order  add  style  information  bold  italic  size  font  resulting  file  moreover  deleted  doctype  header  parser  throw  following  exception  fatal  error  loosedtd313  declaration  entity  htmlversion  must  end  orgxmlsaxsaxparseexception  declaration  entity  htmlversion  must  end,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1996,allow  resolution  defined  calling  imageioutilwriteimage  would  like  call  method  private  static  boolean  writeimagebufferedimage  image  string  imageformat  object  outputstream  int  resolution  private  easiest  solution  mind  would  change  method  public  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1997,split  pdfontencode  discussed  devpdfboxapacheorg  thread  question  tounicode  cmap  need  split  pdfontencode  get  one  method  providing  string  one  providing  cid,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1998,support  decompression  password  protected  pdfs  commandline  utility  writedecodeddoc  try  decrypt  encrypted  pdfs  decompressing  doesnt  work  password  needed  one  cant  pas  password  decrypt  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
1999,extend  commandline  utility  use  non  sequential  parser  choice  id  like  extend  commandline  utility  least  important  one  use  optionally  non  sequential  parser,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2000,refactor  pdfa  parser  fix  pdfbox1274  issue  validation  pdfa  need  refactoring  currently  xref  entry  checked  independently  time  enough  required  information  validate  object  present  object  issue  pdfbox1274  object  validation  access  page  us  object  refactoring  valdiation  unit  pdpage,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2001,update  pdpage  enum  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
2002,xmpbox  refactoring  today  xmp  schema  object  missing  interface  close  jempbox  really  similar  convenience  method  creation  schema  missing  aim  issue  make  interface  similar  create  missing  object  method  clean  useless  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2003,support  lucene  360  fedora  rawhide  updated  lucene  360  trying  compile  pdfbox  get  error  builddirbuildbuildpdfbox170lucenesrcmainjavaorgapachepdfboxluceneindexfilesjava2729  error  cannot  find  symbol  error  symbol  class  htmldocument  location  package  orgapachelucenedemo  look  like  demo  package  lucene  change  quite  lot  including  changing  artifaceid  lucenedemo  diff  pdfbox170lucenepomxmllucene  pdfbox170lucenepomxml  pdfbox170lucenepomxmllucene  20120705  091635056582368  0600  pdfbox170lucenepomxml  20120705  094508069655661  0600  477  477  dependency  dependency  groupidorgapachelucenegroupid  artifactidlucenedemosartifactid  artifactidlucenedemoartifactid  versionluceneversionversion  dependency  dependency,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2004,reduce  memory  consumption  randomaccessbuffer  pdfbox1005  introduced  faster  way  handle  growth  randowaccessbuffer  buffer  expanded  doubling  lead  2n  consumption  memory,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2005,create  nonsequentialparser  inputstream  hi  currently  nonsequentialparser  cant  initialized  using  inputstream  allow  preflightparser  inherit  nonsequentialparser  create  constructor  take  inputstream  parameter  attachment  find  patch  creates  tmpfile  given  inputstream  constructor  method  deletes  tmpfile  end  parse  method  call  parseobjectdynamically  method  trailer  entry  useful  preflight  module  opinion  proposal  regard  eric,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2006,improve  handling  multiline  text  box  current  implementation  setting  appearance  content  added  multiline  text  box  incorrect  number  way  doesnt  position  start  text  correct  location  incorrectly  us  font  size  0  instead  autosizing  font  doesnt  break  long  line  font  size  large  next  line  started  close  previous  line,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2007,pdf  signature  improvement  hallo  signing  improvement  want  contribute  changelog  add  ability  sign  document  xref  stream  big  thanks  funk  significantly  improve  signature  creation  due  fact  document  xref  stream  add  ability  handle  document  hybrid  xref  xref  stream  table  fallback  parsing  incremental  updated  document  offset  xref  entry  doesnt  match  exactly  position  object  conflict  solver  tollerate  object  4  byte  offset  fix  cosstring  parsing  malformed  char  inside  hex  string  removed  confusing  logging  conflict  solver  add  ability  create  sign  signature  field  add  ability  create  pades  signature  timestamps  pades  part4  improved  signature  search  added  new  convenience  method  pddocument  add  new  method  pdsignature  object  seed  value  dict  add  example  signing  pdf  document  basic  signature  try  add  advanced  signing  signatureoptions  maybe  example  visual  signing  hope  dont  forgot  something  change  made  pdfbox  fork  github  pull  request  follow  moment  best  regard  thomas,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2008,add  xml  output  option  preflight  part  recent  spruce  hackathon  httpwikiopflabsorgdisplaysprhome  added  xml  output  preflight  would  good  preflight  able  offer  sort  output  default  example  output  code  httpsgithubcompetecliffpdfehtreemastersamplepreflightoutputs  xml  output  code  httpsgithubcomwillpblpreflightappmod  might  want  implement  way  aside  format  corpus  test  file  httpsgithubcomopenplanetsformatcorpus  use  file  contribution  encouraged  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2009,add  pddocumentsavefile  pddocumentloadnonseqinputstream  patch  add  method  saving  pdf  file  parse  inputstream  using  non  sequential  parser  also  includes  test  case  pddocument  save  load  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2010,overlaypdf  logic  moved  library  class  finding  overlaypdf  command  line  utility  fix  problem  observed  using  overlay  class  however  overlay  class  operate  library  call  overlaypdf  command  line  utility  cant  particularly  given  work  pddocuments  ive  someone  copy  entire  overlaypdf  class  one  modify  accept  preloaded  pddocuments  instead  filename  would  far  constructive  extract  core  logic  library  class  cli  class  drive  proper  clone  method  would  good  create  completely  new  pddocument  serve  new  returned  document  instead  mutating  input,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
2011,replace  external  glyphlisttxt  onw  implementation  according  header  glyphlisttxt  adobe  encourages  people  use  content  file  create  implementation  glyphlist  permission  hereby  granted  free  charge  person  obtaining  copy  documentation  file  create  derivative  work  content  document  use  copy  publish  distribute  sublicense  andor  sell  derivative  work  permit  others  provided  derived  work  represented  copy  version  document  get  rid  external  dependency  follow  advise  create  class  providing  information  glyphlisttxt,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2012,improve  pdfbox  test  id  like  improve  test  rendering  orgapachepdfboxutiltestpdftoimagejava  disabled  pdfboxpomxml  disabled  since  2009  enabled  subdir  rendering  missing  pdfboxtargettestoutput  test  test  fails  rendered  image  identical  detailed  message  appears  console  appears  pdfboxlog  console  setting  pdfboxsrctestresourcesloggingproperties  purpose  please  change  text  pdfboxsrctestjavaorgapachepdfboxutiljava  one  failure  see  test  log  detail  one  failure  see  test  logfile  pdfboxlog  detail  wanted  attach  pdf  ccitt  g4  compression  rendering  created  182  version  doesnt  work  seems  cib  generates  file  rendered  properly  182  however  attach  tiff  g4  file  jbig2  test  file  dont  access  xerox  workcentre  enter  jbig2  google  news  used  free  service  there  watermark  included  pdfboxsrctestresourcesinputrendering  created  image  give  public  domain  suggestion  accepted  would  nice  people  could  create  file  fail  current  version  failed  old  version  release  file  public  domain  added  test,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2013,remove  print  converttoimage  stuff  pdpage  pddocument  move  printingconverttoimage  stuff  pdpage  pddocument  pdpageable  class  removereduce  awtstuff  pdfboxcore  class,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2014,performance  improvement  pdpagecontentstreamdrawstring  simple  way  improving  performance  drawstring  replacing  stringwritepdf  buffer  appendrawcommands  new  string  buffertobytearray  iso88591  appendrawcommands  space  stringwritepdf  buffer  appendrawcommands  buffertobytearray  appendrawcommands  space  appendrawcommandsstring  simple  appendrawcommandsstrgetbytes  iso88591  therefore  optimization  spare  string  creation  well  conversion  back  byte  array,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2015,patch  visible  signature  using  pdfbox  order  sign  document  visible  signature  bad  solution  moment  passing  pdf  inputstream  serf  template  appearance  setting  inconvenient  everything  well  fixed  set  image  location  zoom  width  height  etc  everything  added  automatically  ive  already  done  upload  patch  wrote  example  order  see  use  everything  easy,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2016,automatically  load  isartor  preflight  test  provide  modification  pom  create  new  test  class  isartor  validation  default  isartor  testing  skipped  use  dskipexternalresourcesfalse  command  line  run,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2017,patch  parser  type  1  font  patch  add  parser  type  1  font  fontbox  make  use  pdfbox  rendering  type  1  glyph  fix  various  issue  jvm  crashing  rendering  font  incorrectly  necessary  modify  type1charstringparser  handle  callothersubr  command  correctly  handle  subroutine  likewise  type1charstring  modified  support  flex  patch  remove  awt  fallback  nonembedded  standard  14  font  entirely  new  fallback  system  needed  suitable  font  need  shipped  part  pdfbox  need  discussed  mailing  list  andor  followon  issue  note  keep  patch  small  replaced  existing  adhoc  type  1  parsing  code  pdtype1font  preflight  class  retain  original  code  replaced  subsequent  patchesrefactoring  open  followon  issue  well  patch  file  added  pdfboxsrcmainjavaorgapachepdfboxpdfviewerfonttype1glyph2djava  fontboxsrcmainjavaorgapachefontboxencodingcustomencodingjava  fontboxsrcmainjavaorgapachefontboxtype1tokenjava  fontboxsrcmainjavaorgapachefontboxtype1type1charstringreaderjava  fontboxsrcmainjavaorgapachefontboxtype1type1fontjava  fontboxsrcmainjavaorgapachefontboxtype1type1lexerjava  fontboxsrcmainjavaorgapachefontboxtype1type1mappingjava  fontboxsrcmainjavaorgapachefontboxtype1type1parserjava  file  removed  pdfboxsrcmainjavaorgapachepdfboxpdfviewerfontcffglyph2djava,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1
2018,merge  pdfdecompressor  writedecodeddoc  ccommandline  tool  pdfdecompressor  writedecodeddoc  merged  le,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2019,remove  ant  module  ant  module  consists  one  class  nothing  le  example  create  anttsk  extract  text  using  pdfbox  move  class  pdftotexttask  exmaples  module  remove  th  ant  module,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2020,refactor  color  space  im  currently  working  wanted  open  issue  let  everyone  know  color  space  need  refactored  200  tilman  noticed  slowness  pdfbox1851  due  using  icc  profile  calling  colorspacetorgb  every  pixel  example  file  pdfbox1851  went  rendering  4  second  taking  60  second  solution  use  colorconvertop  convert  entire  bufferedimage  one  go  taking  advantage  awts  native  color  management  module  color  conversion  done  way  almost  instantaneous  even  large  image  current  design  color  space  within  pdfbox  depends  upon  conversion  done  perpixel  basis  significant  refactoring  needed  order  convert  image  using  colorconvertop  without  resort  perpixel  call  case  separation  color  space  us  cmyk  alternate  color  space  via  tinttransform  color  space  handling  code  also  tightly  coupled  image  handling  various  class  read  image  color  handling  code  rely  perpixel  conversion  reason  color  space  refactoring  must  also  included  significant  refactoring  image  handling  code  opportunity  refactor  color  handling  encapsulated  within  color  space  class  allowing  downstream  user  call  torgbfloat  torgbbufferedimage  need  worry  tint  transforms  like  here  summary  change  pdccitt  removed  reading  capability  moved  ccittfaxfilter  writing  capability  moved  ccittfactory  pdjpeg  removed  jpeg  reading  done  new  code  dctfilter  correctly  handle  cmykycck  color  fix  various  file  image  appeared  like  negative  jpeg  writing  done  new  code  jpegfactory  cleaned  jbig2filter  cleaned  jpxfilter  particular  calling  decode  caused  stream  dictionary  updated  unsafe  ive  also  added  special  jpxcolorspace  wrap  embedded  awt  color  space  jpx  bufferedimage  replaces  need  awkward  mapping  colorspace  pdcolorspace  added  better  error  message  missing  jai  plugins  jpx  jbig2  special  exception  missingimagereaderexception  thrown  pdxobjectform  renamed  pdformxobject  match  pdf  spec  pdxobjectimage  renamed  manner  pdinlinedimage  renamed  pdinlineimage  reason  ccittfaxdecodefilter  renamed  ccittfaxfilter  consistency  filter  imageparameters  removed  used  represent  inline  image  parameter  simply  member  pdinlineimage  added  pdcolor  represents  color  value  including  pattern  immutable  ease  use  removed  pdcolorstate  container  color  color  space  almost  every  case  used  represent  color  replaced  pdcolor  occasionally  pdcolorspace  moved  functionality  pdxobject  subclass  rewrote  almost  color  handling  code  pdcolorspace  subclass  including  fixing  calculation  lab  devicen  indexed  color  space  color  space  implement  torgbfloat  function  color  conversion  external  consumer  color  space  longer  know  internals  tint  transforms  image  color  conversion  performed  one  operation  using  colorconvertop  rather  pixelbypixel  speed  icc  transforms  many  order  magnitude  color  space  expose  special  method  toimagergbraster  purpose  fix  known  performance  issue  certain  file  updated  type1  axial  radial  gouraud  shading  context  call  new  torgb  function  interim  measure  better  performance  color  conversion  instead  done  using  toimagergb  entire  gradient  drawn  raster  creation  awt  paint  moved  inside  color  space  hiding  detail  caller  longer  possible  get  awt  color  color  space  paint  may  obtained  removed  pdcolorspacefactory  moved  functionality  pdcolorspace  moved  new  shading  tiling  pattern  code  pdpattern  topaint  encapsulated  color  space  new  pdimage  interface  implemented  pdinlineimage  pdimagexobject  image  xobject  image  reading  masking  stencilling  code  rewritten  resulting  removal  compositeimage  new  sampledimagereader  performs  image  reading  format  including  jpeg  ccitt  format  simply  filter  case  pdf  spec  new  image  reading  handle  decode  array  interpolation  conversion  image  type  efficient  8bpp  raster  replaces  pdpixelmap  well  reading  code  pdjpeg  pdccitt  handling  decod  array  fix  various  issue  image  inverted  especially  inline  image  type  3  font  removed  setnonstrokingiccbasedcolor  setnonstrokingindexed  setnonstrokingpattern  setnonstrokingseparation  setstrokingiccbasedcolor  setstrokingindexed  setstrokingpattern  setstrokingseparation  replaced  setcolor,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
2021,shading  package  move  function  method  base  class  refactoring  im  planning  move  function  method  pdshadingresources  class  reason  1  duplicate  code  partly  introduced  2  allow  handle  function  type  4  5  shading  currently  cant  shading  context  class  use  common  class  gouraudshadingcontext  pdshadingtype  4  5  function  method,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
2022,implement  shading  coon  tensorproduct  patch  mesh  seven  shading  method  described  pdf  specification  type  6  coon  patch  mesh  type  7  tensorproduct  patch  mesh  havent  implemented  done  type  1  4  5  dont  know  math  type  6  7  math  day  decade  away  knowledge  prerequisite  java  although  dont  java  ace  feel  confortable  math  know  cubic  bã©zier  curve  degenerate  bã©zier  curve  bilinear  interpolation  tensorproduct  affine  transform  matrix  bernstein  polynomial  able  learn  maven  basic  svn  basic  ide  like  netbeans  eclipse  intellij  basic  ideally  either  math  student  like  program  computer  science  student  specializing  graphic  first  look  pdfbox  try  command  utility  httpspdfboxapacheorgcommandlinepdftoimage  use  favorite  pdf  pdfs  mentioned  pdfbox615  shading  type  already  implemented  simple  source  code  convert  image  string  filename  blahpdf  pddocument  document  pddocumentloadnonseqnew  filefilename  null  listpdpage  pdpages  documentgetdocumentcataloggetallpages  int  page  0  pdpage  pdpage  pdpages  page  bufferedimage  bim  renderutilconverttoimagepdpage  bufferedimagetypebytebinary  300  imageiowritebim  png  new  filefilenamepagepng  documentclose  starting  scratch  implementation  type  4  5  show  read  parameter  pdf  set  graphic  dont  learn  complete  pdf  spec  15  page  related  two  shading  type  6  page  shading  general  pdf  specification  httpwwwadobecomdevnetpdfpdfreferencehtml  tricky  part  decide  whether  pointxy  inside  outside  patch  decide  color  point  within  patch  get  idea  code  look  class  gouraudtriangle  gouraudshadingcontext  type4shadingcontext  vertex  httpssvnapacheorgviewvcpdfboxtrunkpdfboxsrcmainjavaorgapachepdfboxpdmodelgraphicsshading  download  whole  project  repository  httpspdfboxapacheorgdownloadshtmlscm  want  see  existing  code  debugger  gouraud  shading  try  file  httpasymptotesourceforgenetgallerygouraudpdf  testing  attached  several  example  pdfs  see  one  shading  open  editor  like  notepad  search  shadingtype  without  quote  image  rendering  like  example  pdfs  successful  optional  review  optimize  complete  shading  package  speed  implement  cubic  spline  interpolation  type  0  sampled  function  one  really  lowlow  priority  see  detail  looking  cubic  spline  interpolation  pdf  spec  tell  disregarded  printing  dont  test  pdf  mentor  tilman  hausherr  european  timezone  language  german  english  french,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0
2023,refactor  pagedrawer  operator  clean  code  orgapachepdfboxutiloperatorpagedrawer  formatting  javadoc  etc  make  sure  class  orgapachepdfboxutiloperatorpagedrawer  swallow  exception  except  invoke  remove  setlinepath  pagedrawer  used  combined  stroke  fill  replace  new  strokeandfillpath  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2024,move  pdfboxtools  package  tool  live  module  pdfboxtools  change  namespace  class  orgapachepdfbox  orgapachepdfboxtools,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2025,refactor  package  core  pdfbox  module  want  refactor  core  pdfbox  module  package  longer  dependency  awt  package  moved  outside  orgapachepdfbox  module  need  repackaged  appropriately  eg  orgapachepdfboxrendering  awt  code  could  live  pdfboxrendering  need  think  carefully  eg  filter  use  awt  fontbox  use  case  modularisation  currently  android  google  app  engine  android  seems  support  awt  imageio  somebody  know  provide  information  google  app  engine  seems  blacklist  imageio  awt  class  strong  desire  support  also  fred  discussed  mailing  list  util  package  functionality  shared  across  numerous  part  code  class  either  used  one  package  replaced  new  java  16  construct  end  refactoring  pdfboxutil  package  mostly  empty  containing  handful  true  utility  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2026,pdfimagewriter  doesnt  make  use  pdfstreamengine  pdfimagewriter  subclass  pdfstreamengine  however  never  us  functionality  writeimage  method  could  marked  static  behave  manner  relationship  pdfimagewriter  renderutil  imageioutil  longer  match  historical  origin  need  refactored,1,0,1,0,1,0,1,1,0,1,1,0,0,0,0,0,1
2027,pdfmergerutility  support  merging  using  non  sequential  parser  add  support  pdfmergerutility  merge  document  using  non  sequential  parser  pddocumentloadnonseq,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2028,exception  refactoring  dont  wrap  exception  cosvisitorexception  cosvisitorexception  redundant  simple  wrapper  signatureexception  cryptographyexception  nosuchalgorithmexception  replaced  exception  directly  example  replace  public  void  writepddocument  doc  throw  cosvisitorexception  public  void  writepddocument  doc  throw  ioexception  cryptographyexception,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2029,documentencryption  pdfencryption  deprecated  removed  documentencryption  pdfencryption  orgapachepdfboxencryption  deprecated  removed  200  arcfour  class  made  packageprivate  orgapachepdfboxpdmodelencryption,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
2030,standardise  acroform  field  working  adding  patch  pdfbox1847  noticed  digital  signature  form  field  pdsignature  deprecated  replaced  pdsignaturefield  currently  aspect  field  correspond  pdf  specification  particular  hierarchy  field  naming  currently  43  open  issue  acroform  component  issue  closed  since  2011  ive  attempted  basic  refactoring  give  u  clean  slate  adding  new  feature  fixing  old  bug  here  current  hierarchy  field  pdfbox  pdfield  pdchoicebutton  pdcheckbox  pdradiocollection  pdpushbutton  pdvariabletext  pdchoicefield  pdtextbox  pdsignaturefield  pdunknownfield  here  actual  hierarchy  pdf  specification  field  button  check  box  radio  button  pushbutton  text  choice  list  box  combo  box  signature  note  pdpushbutton  pdtextbox  wrong  place  hierarchy  list  box  combo  box  missing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2031,move  securityhandler  pdencryptiondictionary  pdf  specification  security  handler  defined  encryption  dictionary  pdfbox  security  handler  belongs  document  difficult  move  securityhandler  field  pddocument  pdencryptiondictionary  class  without  introducing  breaking  change  deprecate  method  point  rather  removing  happy  feedback  also  generally  dont  use  postfix  dictionary  class  pd  model  represent  dictionary  anyway  rename  pdencryptiondictionary  pdencryption  luckily  deprecate  old  class  add  new  subclass  desired  name  avoids  breaking  change  happy  new  state  thing,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
2032,support  creating  pdf  lossless  encoded  image  currently  support  insertion  tiff  jpeg  pdf  png  pas  bufferedimage  one  jpeg  compressed  good  thing  graphic  sharp  edge  suggest  support  png  well  possible  flate  filter  support  direction  implementation  coming  minute  rgb  based  start  begs  improvement,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2033,pdseparation  optimization  4  page  black  white  pdf  take  32  second  8  second  page  render  us  separation  color  space  run  numerous  function  per  pixel  causing  slow  patch  pre  calculate  black  white  pixel  cache  instead  calculating  every  time  optimization  get  page  rendering  le  second  page  attach  patch  could  see  going  forward  caching  calculated  colour  float  hash  map  tricky,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2034,testfilters  nondeterministic  followup  pdfbox1977  created  john  testfilters  us  randomnextlong  generate  seed  random  data  mean  nondeterminate  depending  seed  value  test  may  fail  succeed  need  set  deterministic  testshttpmartinfowlercomarticlesnondeterminismhtml  set  nondeterministic  test  see  see  discussion  pdfbox1977,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2035,add  filter  parameter  pdimagexobjectdocument  filteredstream  constructor  adding  third  parameter  code  public  pdimagexobjectpddocument  document  inputstream  filteredstream  code  ie  changing  code  public  pdimagexobjectpddocument  document  inputstream  filteredstream  cosbase  cosfilter  code  code  filter  always  set  afterwards  change  improves  code  clarity  caller  know  filter  used  used  prepare  filteredstream  content  wdyt  also  adding  width  height  bpc  colorspace  constructor  four  parameter  always  used  cool  guy  enter  name  youtube  argument  use  constructor  parameter  instead  setter  httpmiskoheverycom20090219constructorinjectionvssetterinjection  imho  mixing  constructor  initialization  setter  initialization  look  confusing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2036,insert  inline  image  page  content  stream  cant  find  anything  insert  pdinlineimage  page  content  stream  far  understand  spec  p  352355  rather  simple  ie  append  raw  command,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2037,improve  handling  writing  header  trailer  version  msahyoun  pdfbox1922  id  think  instead  setting  version  current  way  replacing  version  information  header  parsing  parsing  keep  version  information  getversion  within  cosdocument  amended  return  correct  information  im  suggesting  keeping  version  inline  spec  ensures  override  current  setting  pdf  opening  saving  cosdocumentjava  code  public  void  setversion  float  versionvalue  update  header  string  versionvalue  version  headerstring  headerstringreplacefirststringvalueofversion  stringvalueofversionvalue  version  versionvalue  code  two  thing  set  version  set  headerstring  first  idea  would  remove  setting  headerstring  1  side  effect  2  already  done  elsewhere  inserted  2011  lehmi  part  pdfbox879  wonder  break  something  removing  lehmi  far  remember  wasnt  aware  fact  pdf  may  version  header  trailer  hindsight  change  wasnt  good  agree  maruan  sahyoun  overhaul  getsetversion  method  must  take  possible  value  account  following  pdf  spec  current  thought  may  need  two  setter  one  inside  job  ie  parsing  set  version  separately  one  higher  application  eg  merging  set  version  header  trailer  time  whatever  change  done  produce  regression  pdfbox879,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2038,implement  transparency  group  attached  pdf  us  transparency  group  blending  soft  mask  create  rounded  corner  shade  behind  image  appears  feature  implemented  pdfbox  implementation  proposal  attached  transparencygrouppatch  basic  idea  create  buffered  image  draw  transparency  group  content  onto  use  result  produce  soft  mask  draw  image  original  g2d  note  author  proposed  change  developed  company  year  ago  source  based  17x  version  pdfbox  mostly  guy  already  left  year  merging  work  done  pdfbox  main  stream  source  base  become  impossible  due  many  refactorings  deep  going  change  done  would  like  go  opposite  way  possible  bring  change  fix  done  pdfbox  main  stream  start  use  installation,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1
2039,support  multipage  tiff  ccittfactory  make  pdfbox  capable  tiff2pdf  created  patch  based  sergey  ushakovs  work  handle  multipage  tiff  allows  fast  efficient  conversion  tiff  pdf  general  approach  provide  new  factory  method  accepts  image  page  number  appropriate  page  number  located  ccitt  stream  extracted  there  minor  inefficiency  approach  seek  start  beginning  page  causing  on2  algorithm  extracting  every  page  maximum  size  file  appears  2  gb  cost  finding  single  page  still  low  bet  never  come  practice  method  tell  many  page  tiff  file  opted  simply  return  null  factory  method  accepts  page  number  page  user  use  condition  break  tiff  pdf  conversion  loop,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2040,optimize  clipping  already  stated  todo  comment  pagedrawer  call  graphics2dsetclip  time  memory  consuming  attached  patch  optimizes  clipping  calling  graphics2dsetclip  clipping  path  changed  effect  depends  document  eg  attached  one  render  105s  without  optimization  55  second  optimized  version  clipping  reapplied  whenever  transform  graphics2d  change  explicitly  checked  implementation  rather  depends  cached  value  reset  manually  currently  needed  one  place  processing  annotation  acroforms  also  implementation  relies  upon  clipping  path  object  stored  pdgraphicsstate  never  change  comparison  using  used  work  fine  need  bit  awareness  future  change  make  design  clean  clipping  path  could  made  private  pdgraphcisstate  thus  really  immutable  outside,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2041,clean  pdfstreamengine  pdftextstripper  pdfstreamengine  pdftextstripper  dont  really  meet  coding  convention  several  unused  method  deprecated  code  safely  removed  clear  way  fixing  bug  pdfstreamengine  pdftextstripper  various  pdfont  class  related  text  encoding,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2042,font  refactoring  fix  bug  pdfbox2140  enable  unicode  ttf  embedding  need  sort  longstanding  fonttext  encoding  issue  main  issue  encoding  done  adhoc  manner  sometimes  pdfont  subclass  sometimes  elsewhere  example  ttfglyph2d  decoding  code  copy  pasted  pdtruetypefont  likewise  pdfont  handle  cmaps  encoding  despite  fact  two  encoding  method  mutually  exclusive  end  result  process  reading  encodingscmaps  often  following  rule  completely  invalid  font  type  mostly  work  luck  phase  1  refactor  pdfont  subclass  remove  setxxx  method  allow  object  corrupted  proper  use  inheritance  remove  case  public  setxxx  method  used  font  loading  clean  ttf  loading  loadttf  anticipation  unicode  ttf  embedding  fontboxs  truetypefont  class  externally  mutable  via  setxxx  method  used  ttfparser  made  packageprivate  encoding  class  encodingmanager  could  cleaning  prior  refactoring  pdsimplefont  anything  functionality  moved  superclass  pdfont  pdfontdetermineencoding  load  cmaps  encoding  applicable  vice  versa  loading  need  pushed  appropriate  subclass  starting  point  relevant  code  least  copied  relevant  subclass  ready  refactoring  ttfglyph2d  decoding  char  code  rather  using  font  encode  method  fair  enough  encode  broken  there  copy  pasted  version  code  pdtruetypefont  need  consolidate  code  pdtruetypefont  belongs  phase  2  refactor  loading  cmaps  encoding  font  dictionary  involve  change  pdfont  subclass  delegate  loading  subclass  properly  encapsulated  may  need  alter  class  hierarchy  wrt  cidfont  facilitate  cidfont  isnt  really  pdfont  parent  type0  font  responsible  cmap  well  see  phase  3  refactor  decoding  character  code  pdfont  subclass  involve  replacing  getcodefromarray  encode  encodetocid  method  fix  decoding  content  stream  character  code  pdfstreamengine  using  newly  refactored  pdfont  using  current  font  cmap  determine  code  width,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2043,graphic  operator  refactoring  im  process  porting  fairly  complex  program  us  18  api  20  way  finding  rough  edge  20  app  im  porting  hook  many  graphic  operator  subclass  pagedrawer  get  access  pdfs  graphic  state  turn  doesnt  work  well  especially  20  pagedrawers  state  private  additional  complexity  transparency  group  main  issue  graphic  operator  coupled  pagedrawer  im  interested  awt  rendering  need  way  hook  graphic  operation  subclassing  operator  proven  poor  solution  case  calling  superprocess  doesnt  provide  enough  flexibility  here  solution  way  text  processing  recently  factoredout  pdftextstreamengine  endusers  subclass  id  like  graphic  operation  instead  graphic  operator  coupled  pagedrawer  one  possible  implementation  graphic  handling  move  method  operator  call  new  subclass  pdfstreamengine  let  call  pdfgraphicsstreamengine  class  subclassed  anyone  interested  hooking  graphic  operation  including  pagedrawer  new  callback  text  handling  already  pdftextstreamengine  addition  new  graphic  callback  pdfgraphicsstreamengine  time  shouldnt  necessary  endusers  need  override  operator  class  get  access  information  need  would  huge  benefit  involve  bunch  change  operator  ill  take  chance  general  cleaning  im  operator  class  havent  received  much  attention  callback  pdfstreamengine  et  al  moving  towards  point  operator  class  becoming  almost  internal  part  pdfbox  api  might  something  think  future,1,0,1,0,1,0,0,1,0,1,1,0,0,0,0,1,1
2044,add  missing  value  pdcomplexfilespecification  class  pdcomplexfilespecification  need  improved  follows  analog  getsetfilexxx  add  missing  getsetembeddedfileunicode  rename  getunicodefile  getfileunicode  inline  getters  add  setter  value  well  according  spec  do  unix  mac  mutation  shouldnt  used  anymore  therefore  rearrange  order  getfilename,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2045,improve  xref  self  healing  mechanism  pdfbox1769  introduced  self  healing  mechanism  repair  corrupt  xref  offset  one  starter  remain  lot  issue  solved  im  planing  solve  least  fix  improvement  targeting  nonsequential  parser  wont  port  change  old  parser,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2046,remove  usage  awt  font  still  using  awt  font  render  standard  14  builtin  font  cause  rendering  problem  encoding  issue  see  pdfbox2140  also  using  awt  fallback  font  removal  awt  font  isnt  difficult  need  load  font  using  existing  pdffontmanager  mechanism  recently  added  missing  truetype  font  loaded  disk  using  systemfontmanager  number  week  ship  sensible  default  font  pdfbox  liberation  font  see  pdfbox2169  pdfbox2263  case  pdffontmanager  cant  find  anything  suitable  rather  falling  back  default  ttf  font  default  well  probe  system  suitable  font,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2047,remove  jempbox  subproject  following  pdfbox2107  im  finally  going  remove  jempbox  subproject  discussed  topic  several  time  imho  always  result  discontinue  jempbox  favor  xmpbox  user  still  prefer  jempbox  might  use  18x  version  still  work  even  combination  20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2048,make  better  use  renderinghints  pagedrawer  doesnt  make  effective  use  java  2ds  renderinghints  situation  little  odd  due  code  moved  around  copied  pasted  time  making  use  higher  quality  rendering  available  u  example  strangeness  drawtilingpattern  set  valuefractionalmetricson  yet  applies  awt  font  drawglyph2d  set  valueantialiason  strokepath  fillpath  set  valueantialiasoff  drawbufferedimage  set  keyinterpolation  valueinterpolationnearestneighbor  lowest  quality  image  scaling  method  shadingfill  set  valueantialiasoff  might  make  sense  painting  otoh  canvas  buffered  already  antialiasing  save  anything  disabling  drawpage  set  valueantialiason  always  overridden  various  drawing  method  currently  missing  antialiasing  path  glyph  getting  lowquality  resizing  image  make  type  3  font  look  particularly  ugly  setting  appropriate  rendering  hint  would  improve  greatly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2049,overhaul  appearance  generation  pdf  form  appearance  handling  form  1x  limited  reflect  setting  possible  form  field  addition  current  code  modular  follow  box  model  used  form  field  unfortunately  basic  form  handling  defined  pdf  spec  detail  like  padding  box  text  placement  etc  determined  looking  adobe  form  generated  update  file  pdfbox2310  bad  rendering  might  related,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2050,remove  property  file  usage  pdfstreamengine  pdfstreamengine  subclass  currently  load  list  operatorprocessor  class  property  file  make  difficult  override  class  property  file  also  need  copied  pasted  change  made  worse  still  subclass  module  known  load  property  file  pdfbox  module  break  osgi  discovered  pdfbox2358  currently  api  registeroperatorprocessor  performs  role  adapted  use  subclass  perhaps  deprecated  replaced  something  le  brittle  doesnt  require  manually  assigning  operator  specific  string  bt,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
2051,improve  highlevel  font  apis  pdfont  type1equivalent  apis  could  expose  higherlevel  detail  consistent  way  get  name  type1equivalent  instance  font  format  could  also  apis  exposing  specific  useful  internals  gids  im  going  add  find  need  development  debugging,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2052,move  caching  outside  pdresources  note  issue  based  discussion  occurred  regarding  pdfbox2301  actually  separate  issue  currently  cache  page  resource  pdresources  belongs  specific  pdpage  cause  two  problem  1  user  want  hold  many  pdpage  object  memory  high  memory  use  often  accident  2  caching  resource  pdpage  get  keep  cache  lifetime  page  eg  pdfrenderer  single  page  mean  font  appears  40  page  parsed  40  time  cause  slow  running  time  also  memory  thrashing  object  destroyed  frequently  recreated  pdfrenderer  really  need  pagewide  caching  documentwide  caching  cache  font  cmaps  color  profile  etc  wont  work  image  theyre  large  beginning  realise  caching  usecase  specific  probably  shouldnt  builtin  pdfboxs  pdmodel  instead  removing  resource  caching  pdpagepdresources  implement  custom  caching  pdfrenderer  downstream  class  pdftextstripper  ill  happily  volunteer  existing  highlevel  pdfbox  apis  continue  work  power  user  get  level  control  appreciate  strategy  could  enhanced  removing  memoryhungry  method  pdresources  getfonts  getxobjects  force  resource  particular  type  loaded  whether  needed  actually  used  content  stream  would  replaced  method  retrieve  single  resource  eg  getfontname  probably  isnt  legitimate  use  case  1  weve  solved  issue  used  image  caching  fact  clearcache  method  actually  longer  need  called  pdfrenderer  though  currently  real  problem  easy  accidentally  retain  pdpage  object  pddocumentgetdocumentcataloggetallpages  method  dangerous  looping  cause  page  retained  processing  like  code  pdpage  page  documentgetdocumentcataloggetallpages  javautillist  idiomatic  pdfbox  18  list  returned  getallpages  kept  scope  bad  code  added  couple  method  ago  avoid  fetching  pdpage  one  time  used  internally  pdfbox  avoid  memory  problem  used  code  int  0  documentgetnumberofpages  pdpage  page  documentgetpagei  new  20  way  current  page  fall  scope  good  code  solve  problem  could  change  getallpages  instead  returning  list  return  iteratorpdpage  would  provide  nicer  api  getpageint  existing  code  continue  work  also  opportunity  also  fix  type  safety  issue  due  pdpagenode  incorrect  handling  page  tree  similar  issue  recently  acroform  field  tree,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2053,move  operator  content  stream  pdfboxutil  refactoring  content  stream  operator  mostly  complete  theyve  outgrown  place  util  package  moved  toplevel  contentstream  package  note  genuine  util  class  pdftextstripper  left  currently,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2054,imageioutil  jpegutil  tiffutil  metautil  needed  pdfbox  class  imageioutil  jpegutil  tiffutil  metautil  needed  pdfbox  module  usage  imageioutil  pdfbox  module  safely  replaced  java  imageio  ive  tested  working  copy  thats  650  line  imaging  code  dont  need  imageioutil  friend  needed  class  tool  module  write  image  file  disk  ultimately  imageioutil  class  bandaid  java  imageios  bug  helpful  isnt  necessary  part  pdfbox  core  obviously  imageioutil  useful  downstream  consumer  pdfbox  doesnt  belong  core  pdfbox  module  introduces  unnecessary  complexity  move  tool  module  along  jpegutil  tiffutil  metautil  might  want  consider  utility  class  probably  dont  belong  pdfbox  core  texttopdf  printpdf  writedecodeddoc  etc  basically  anything  main  method  well  deal  later,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2055,move  printing  class  toplevel  printing  package  new  printing  api  class  20  moved  new  printing  toplevel  package  packageprivate  dependency  class  rendering  package  longer,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2056,move  encoding  class  font  package  various  encoding  class  toplevel  package  encoding  20  encoding  properly  part  font  package  used  pdfont  instance  seeing  pretty  much  method  encoding  api  changed  20  might  well  take  opportunity  move  class  pdmodelfont  belong,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2057,pdpropertylist  belongs  markedcontent  package  pdpropertylist  used  marked  content  markedcontent  package  instead  root  pdmodel  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2058,add  example  code  extract  embedded  file  annotation  expand  extractembeddedfilesjava  include  embedded  file  annotation  see  file  pdfbox2993,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2059,page  tree  handling  need  rewriting  way  pdfbox  handle  page  tree  need  rewritten  preferably  scratch  currently  document  catalog  return  raw  object  page  tree  wrapped  either  pdpage  pdpagenode  need  abstract  page  tree  get  rid  pdpagenode  provide  method  addremove  pdpage  object  existing  lowlevel  access  page  tree  needed  pdlevel  inheritance  page  property  crop  box  resource  rotation  reimplemented  use  whatever  new  page  tree  abstraction  invent  finally  remove  old  broken  method  didnt  look  inheritance  tree  retrieving  value,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2060,make  nonsequential  parser  default  parser  proposed  maruan  dev  make  nonsequentatial  parser  default  parser  different  loadmethods  simplified  context  loadloadnonseq  replaced  load  method,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2061,xref  stream  saved  table  saving  pddocument  pdfbox  seems  always  write  xref  table  even  original  file  contains  xref  stream  reproduce  load  pdf  file  like  one  attached  pddocumentload  pddocumentloadnonseq  result  save  pddocumentsave  another  file  seems  problem  coswriterdowritexref  cosdocumentisxrefstream  true  xref  entry  wrapped  stream  theyre  written  output  one  one  think  part  look  like  counterpart  coswriterdowritexrefinc  made  change  dowritexref  accordingly  seems  work  pdfs  never  incrementally  updated  lead  corrupt  file  pdf  incrementally  updated,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2062,create  testsymmetrickeyencryptionjava  similarly  orgapachepdfboxencryptiontestpublickeyencryption  also  test  password  based  encryption  1  128bit  2  256bit  aes  pdfbox1594,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2063,share  functionality  page  tree  field  tree  pdfs  page  tree  acroforms  field  tree  share  common  functionality  eg  resolving  inheritable  attribute  iterating  leaf  could  combined  pdtree  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2064,improve  non  sequential  parser  used  signing  pdf  removingreplacing  usage  old  parser  see  pdfbox2430  one  purpose  left  still  requires  old  parser  signing  pdf  improve  non  sequential  par  finally  remove  old  one,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2065,align  acroforms  field  pdmodel  pdf  specification  pdmodel  acroforms  field  part  oappdmodelinteractiveform  need  enhanced  sample  issue  radiobutton  checkbox  donâ€™t  support  dv  entry  although  inheritable  attribute  support  inheritance  either  form  parent  root  acroforms  model  inline  specification,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
2066,patch  two  pdfont  create  pdf  document  cjk  noniso88591  language  made  two  pdfont  class  creating  pdf  document  cjk  noniso88591  language  one  pdtype0cjkfont  using  cjk  font  included  asian  font  package  adobe  reader  font  doesnt  require  target  font  time  creating  pdf  documentary  font  us  utf16  text  code  support  surrogate  pair  character  pdtype0unicodefont  using  truetype  type0  font  deal  unicode  character  like  arialunicodems  character  used  actually  document  embedde  realizing  call  pdtype0unicodereloadfont  method  closing  pdpagecontentstream  think  specification  ugly  could  thought  suitable  way  remove  spec  font  us  original  glyph  code  embedded  font  text  code  support  surrogate  pair  character  example  program  using  two  font  also  attached,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1
2067,improve  pdfdebugger  idea  google  summer  code  2015httpswwwgooglemelangecom  command  line  utility  pdfdebugger  part  command  line  pdfboxapp  get  herehttpspdfboxapacheorgdownloadshtml  read  description  herehttpspdfboxapacheorgcommandline  see  source  code  herehttpssvnapacheorgviewvcpdfboxtrunktoolssrcmainjavaorgapachepdfboxtoolspdfdebuggerjavaviewmarkupsortbydate  need  improvement  hex  view  view  non  printable  character  âœ“  saving  stream  binary  copy  paste  âœ“  create  status  line  show  tree  like  window  regedit  âœ“  copy  current  tree  string  clipboard  useful  discussion  detail  pdf  âœ“  optional  sure  easy  jump  specific  place  tree  entering  tree  string  âœ“  ability  search  stream  useful  content  stream  meta  data  âœ“  show  image  stream  âœ“  show  pdindexed  color  lookup  table  show  index  value  base  rgb  color  value  set  mouse  move  âœ“  show  pdseparation  color  âœ“  show  pddevicen  color  optional  idea  developed  bit  show  meaningful  explanation  attribute  eg  appearance  stream  hovering  ap  show  font  encoding  character  âœ“  display  flag  bit  eg  annotation  flag  way  easy  understand  probably  others  assume  main  work  need  done  edit  attribute  possible  enter  value  decimal  hex  binary  edit  stream  keeping  changing  compression  filter  save  altered  pdf  âœ“  color  mark  certain  pdf  operator  especially  qq  text  operator  btet  ideally  help  user  understand  bracketing  operator  ie  understand  sequence  start  end  see  operator  summary  pdf  spec  important  operator  think  matrix  font  color  operator  cool  advanced  thing  would  show  current  color  font  popup  hovering  operator  see  product  similar  purpose  better  pdfdebugger  watch  videohttpswwwyoutubecomwatchvgqcu9b4qmc  im  asking  implement  clone  product  dont  use  know  video  pdfbox  really  need  something  make  pdf  debugging  easier  example  current  pdfdebugger  prevented  finding  bug  quickly  see  pdfbox2401  search  pdfdebugger  prerequisite  java  programming  especially  gui  component  ability  understand  existing  source  code  using  external  software  component  possible  must  apache  license  compatible  one  decided  casebycase  basis  dont  want  get  big  development  strategy  go  easy  difficult  wished  feature  already  sorted  way  mostly  get  introduced  download  source  code  svnhttpspdfboxapacheorgdownloadshtmlscm  build  maven  run  pdfdebugger  view  pdfs  see  component  pdf  start  file  pdfbox2401  read  something  structure  pdf  web  pdf  specificationhttpswwwadobecomdevnetpdfpdfreferencehtml  mentor  tilman  hausherr  european  timezone  language  german  english  french  see  gsoc2014  project  mentored  go  pdfbox1915,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2068,subset  embedded  ttf  font  pdfbox922  fixed  working  ttf  embedding  however  entire  font  embedded  rather  large  already  ttfsubsetter  class  fontbox  never  used  make  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2069,remove  logging  operator  class  ive  trying  get  better  control  logging  occurs  operator  class  easy  ideally  logging  could  pas  pdfstreamengine  subclass  easily  filter  want  using  exception  instead  logging  error  case  allow  finegrained  management  exception  example  code  wish  missing  xobject  terminal  failure  currently  result  log  message  implement  custom  drawobject  operator  copy  paste  code  order  catch  exception  rather  logging  im  therefore  going  move  little  logging  operator  class  pdfstreamengine  throw  custom  exception  eg  missingresourceexception  rather  writing  silently  log  default  implementation  processoperator  pdfstreamengine  catch  custom  exception  simply  write  log  keeping  current  pdfbox  behaviour  unchanged  consumer  pdfstreamengine  override  processoperator  exception  handling  eg  choose  propagate  missingresourceexception  exception  instead  logging  might  useful  preflight  often  want  throw  error  would  otherwise  skip  offending  object  keep  processing  also  probably  mean  longer  need  preflight  implement  operator  case  done  get  stricter  error  handing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2070,improve  example  example  need  improvement  20  released  many  example  using  obsolete  apis  dont  follow  coding  convention  many  simple  complex,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2071,improve  pdpagecontentstream  api  pdpagecontentstream  api  us  method  incorrect  misleading  name  unusual  choice  parameter  fairly  easily  cleaned,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2072,allow  sharing  co  object  different  document  number  user  mailing  list  asked  import  page  pdfs  form  current  solution  layerutility  depends  pdfcloneutility  class  surprisingly  complex  simple  task  two  main  task  class  perform  copying  page  cosstream  cloning  every  relevant  co  object  however  seems  real  need  copying  cloning  there  nothing  co  object  specific  given  document  cosstream  share  backing  file  cosdocument  isnt  problem  coswriter  even  need  make  sure  exception  thrown  cosstream  used  parent  cosdocument  closed  note  one  artificial  dependency  cosdictionary  cosarrays  parent  cosdocument  calling  close  cosdocument  clear  content  child  cosdictionary  cosarrays  however  there  need  seems  come  due  long  past  confusion  regarding  garbage  collection  work  java  know  necessary  set  object  null  clear  list  done  propose  get  rid  unnecessary  object  list  clearing  cosdocumentclose  add  check  cosstream  throw  userfriendly  exception  reading  closed  backing  stream  allow  u  directly  share  co  object  different  cosdocuments  allowing  simple  x  copying  making  layerutility  pdfcloneutility  unnecessary  instead  code  cosstream  pagestream  cosstreampagegetstreamgetcosobject  pdstream  newstream  new  pdstreamtargetdoc  pagestreamgetunfilteredstream  false  pdformxobject  form  new  pdformxobjectnewstream  pdresources  pageres  pagegetresources  pdresources  formres  new  pdresources  pdfcloneutility  cloner  new  pdfcloneutilitydocument  clonerclonemergepageres  formres  formsetresourcesformres  code  could  code  pdformxobject  form  new  pdformxobjectpagegetstream  formsetresourcespagegetresources  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2073,provide  easier  access  acroform  field  tree  current  implementation  acroform  field  retrieval  method  donâ€™t  provide  easy  access  get  field  one  need  retrieve  document  root  field  check  nonterminal  field  retrieve  child  move  terminal  field  retrieved  way  easier  get  access  terminal  field,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
2074,remove  old  parser  making  nonsequential  parser  default  parser  pdfbox2430  enabling  signing  nonsequential  parser  time  remove  old  one,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2075,make  internal  pagedrawer  font  class  packageprivate  still  internal  class  used  pagedrawer  still  public  internal  apis  still  evolving  made  packageprivate  anybody  want  need  functionality  apis  publicly  add  appropriate  pdfont  subclass  thats  belongs,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2076,move  orphaned  cosobjectkey  class  cosobjectkey  orphaned  persistenceutil  module  yet  clearly  part  co  model  indeed  cosdocument  orgapachepdfboxcos  depends  move  cosobjectkey  orgapachepdfboxcos,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2077,move  multipdf  class  util  package  pdfbox2580  maruan  mentioned  rendering  printing  class  unusual  util  package  made  wonder  class  util  might  better  another  package  since  command  line  utility  moved  tool  package  util  become  home  helper  class  matrix  hex  however  also  home  class  related  old  command  line  tool  would  better  elsewhere  text  package  contain  pdftextstripper  pdftextstripperbyarea  pdfmarkedcontentextractor  would  remove  cyclic  dependency  currently  exists  text  util  moving  pdftextstreamengine  text  would  also  allow  cyclic  dependency  contentstream  util  broken  likewise  new  multipdf  package  could  contain  pageextractor  pdfcloneutility  pdfmergerutility  layerutility  overlay  splitter  creates  proper  home  class  handle  multiple  pdfs  part  pd  ensures  separation  concern  helper  util  class  would  give  u  cleaner  foundation  20  moving  forward  reduce  number  sonar  warning  regarding  cyclic  dependency,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2078,remove  signatureinterface  dependency  cosdocument  cosdocument  hold  reference  signatureinterface  signing  moved  somewhere  pdmodel  package  maybe  pddocument,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2079,possibility  use  andor  overwrite  pagedrawer  class  use  pdfbox  render  pdfs  additionally  posibility  add  different  kind  annotation  stamp  mark  free  text  note  like  wysiwygeditor  necessary  paint  annotation  another  reason  paint  part  example  pdf  embedded  picture  behind  picture  ocrtext  picture  text  needed  searching  und  painted  thus  would  useful  use  derived  pagedrawer  see  thing  change  remove  final  pagerdrawerclass  b  make  globalvariables  graphic  xform  pagesize  protected  c  also  method  like  setrenderinghints  protected  maybe  possibility  say  pdfrender  pagedrawer  used,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2080,use  saveincremental  method  document  opened  inputstream  work  seem  possible  use  saveincremental  method  pdf  document  opened  inputstream  instead  file  detail  stackoverflow  httpstackoverflowcomquestions29123436howtosignaninputstreamfromapdffilewithpdfbox200,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2081,support  ttc  font  file  need  support  truetype  collection  ttc  file  shouldnt  difficult  simply  bundle  ttf  file  single  container,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2082,make  easier  work  radiobutton  group  current  implementation  radio  button  pdfbox  20  improved  renaming  getoptions  make  clearer  get  potential  export  value  although  dictionary  entry  called  opt  make  easier  inspect  possible  value  one  set  various  individual  button,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2083,overhaul  font  substitution  improved  font  substitution  mechanism  20  quite  sufficient  handle  pdfs  specifically  cjk  substitution  substitution  ttf  place  cff  font  possible  current  design  cjk  problem  seen  pdfbox2509  pdfbox2563  solve  problem  additional  font  api  weakness  found  pdfbox2578  pdfbox2366  metaissue  aim  address  subissues  current  problem  fontbox  provide  generic  font  type  handle  truetypefont  cfffont  type1font  separately  hinders  crossformat  substitution  externalfonts  knowledge  cidsysteminfo  necessary  cjk  substitution  fontprovider  contains  much  public  logic  internal  pdfbox  eg  substitution  logic  make  brittle  mean  wont  able  add  additional  logic  20  released  eg  cjk  substitution  much  confusion  role  externalfonts  particularly  regard  mapping  builtin  font  definition  substitute  v  fallback  font  externalfonts  black  box  user  cannot  tell  whether  font  returned  exact  match  lastresort  fallback  confusing  font  substitution  api  user  preferred  flat  file  format  pdsimplefontgetencoding  return  null  ttfs  use  builtin  encoding  caused  lot  bug  must  better  way  still  confusing  name  example  customencoding  known  builtin  encoding  spec  fallback  cff  font  resort  adobeblank  instead  rendering,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2084,align  annotation  form  public  api  public  api  annotation  form  differs  visibility  flag  field  method  naming  convention,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2085,improve  performance  using  scratch  file  current  scratch  file  implementation  us  many  direct  io  call  slows  parsing  compared  inmemory  scratch  buffer  considerably,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2086,simplify  cosstream  encoding  decoding  performance  issue  memory  usage  issue  surrounding  stream  one  thing  blocking  release  20  see  pdfbox2301  pdfbox2882  pdfbox2883  though  weve  managed  reduce  memory  used  randomaccessbuffer  take  advantage  buffering  scratch  file  still  problem  amount  memory  cosstream  hold  onto  change  introduced  20  resulted  cosstreams  complex  relationship  class  hold  lot  memory  complex  way  eg  field  tempbuffer  filteredbuffer  unfilteredbuffer  filteredstream  unfilteredstream  scratchfile  access  scratch  file  page  particular  seem  well  regulated  especially  regard  multithreading  avenue  wed  least  like  leave  open  given  recent  flux  im  doubtful  ship  current  api  cosstream  wrt  randomaccess  without  shipping  performance  issue  flaw  unfixable  without  breaking  change  one  recent  change  cosstream  expose  randomaccess  pdfstreamparser  parse  content  stream  well  subclass  handle  xref  object  stream  however  stream  fundamentally  random  access  stream  filter  sequential  consumer  stream  may  wish  buffer  data  memory  scratch  random  access  cosstream  need  expose  elaborate  api  many  piece  gymnastics  performed  inside  cosstream  present  illusion  significant  cost  remove  providing  randomaccess  pdfstreamparser  pdfobjectstreamparser  pdfxrefstreamparser  turn  class  dont  actually  perform  random  io  perform  sequential  io  buffer  peekunread  need  simplify  get  20  fast  lean  maintainable  here  think  1  split  interface  sequential  random  io  introduce  new  sequentialsource  interface  sequential  io  thin  wrapper  randomaccessread  inputstream  baseparser  use  sequentialsource  rather  randomaccessread  inherited  pdfstreamparser  pdfobjectstreamparser  pdfxrefstreamparser  cosparser  use  randomaccessread  pas  sequentialsource  wrapper  superclass  baseparser  2  remove  randomaccess  apis  cosstream  expose  inputstream  outputstream  used  pas  inputstream  pdfstreamparser  using  wrapper  implement  sequentialsource  remove  tempbuffer  filteredbuffer  unfilteredbuffer  cosstream  hold  memory,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,1,1
2087,remove  cosstreamarray  sequencerandomaccessread  tie  cosstream  simplification  pdfbox2893  cosstreamarray  troublesome  abstraction  real  co  object  co  object  generated  parsing  look  implementation  cosstreamarray  method  throw  exception  cosstream  violates  contact  thing  claim  even  pdpagecontentstream  use  instanceof  peer  abstraction  cosstreamarray  there  reason  class  ducktape  flaw  18  apis  namely  pdpagegetstream  return  pdstream  pdfstreamparser  expects  pdstream  yet  may  array  stream  fix  20  getting  rid  erroneous  pdpagegetstream  exposing  array  stream  rather  attempting  hide  hopefully  also  fix  existing  error  may  lurking  throughout  codebase  see  first  comment  associated  mistaking  cosstreamarray  cosstream  still  provide  inputstream  api  abstract  array  stream  there  nothing  wrong  user  simple  convenient  experience  added  benefit  allow  u  remove  sequencerandomaccessread  highly  complex  memoryholding  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2088,replace  pdfreader  pdfdebugger  discussed  mailing  list  quote  here  idea  switch  pdfdebugger  using  view  page  default  longer  confusing  casual  user  ive  found  using  mode  time  anyway  add  page  updown  course  preferably  using  actual  page  page  key  rather  bizarre  choice  key  currently  used  pdfreader  quote,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2089,allow  refresh  acroform  field  appearance  field  widget  style  changed  border  defined  immediately  visible  change  reflected  widget  appearance  stream  possibility  force  refresh  field  appearance  setting  specified,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2090,pdtype3fontgetwidthfromfont  supported  method  still  implemented  anyone  working  issue  happy  contribute  propose  implementation  fact  complicated  task  need  parse  d0  d1  operator  glyph  content  stream  stored  charprocs,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2091,add  capability  flatten  acroform  form  field  capability  flatten  acroform  form  field,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2092,add  support  grouped  checkboxes  checkboxes  grouped  together  longer  act  individually  similar  radio  button  difference  dependent  field  flag,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
2093,make  fontmapper  singleton  interface  discussed  dev  mailing  list  user  want  provide  completely  custom  implementation  fontmapper  seems  easiest  way  make  static  fontmapper  singleton  replaced  entirely  user  implementation,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0
2094,improve  font  handling  layout  print  problem  imported  sourceforge  httpsourceforgenettrackerindexphpgroupid78314atid552832aid1787501  originally  submitted  gjniewenhuijse  20070904  0024  print  attached  file  thing  printed  well  gray  box  top  font  printed  bold  thats  right  solution  later  open  print  file  adobe  reader  everything  fine  pdfbox  ive  got  layout  problem  used  newest  pdfbox  version  also  tested  nightly  build  attachment  sourceforge  httpsourceforgenettrackerdownloadphpgroupid78314atid552832aid1787501fileid244104  orarrppdf  applicationpdf  7871  byte  pdf  print  problem,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2095,right  pdfbox  permit  sign  multiple  file  calling  external  signing  service  since  sign  pdf  forced  implementation  signatureinterface  interface  possible  prepare  n  hash  n  pdf  file  send  signing  service  accepts  multiple  hash  single  signon  example  use  otp  signing  service  would  nice  separate  hash  calculation  signing  instead  implement  interface  would  like  something  like  1  calculate  hash  document  new  signature  dictionary  byte  2  sign  hash  3  insert  signature  pdf  way  could  achieve  sign  example  100  pdf  file  calling  service  right  must  ask  user  sign  100  time  thanks  advance  andrea,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2096,allow  missing  page  type  came  across  pdf  document  missing  type  page  dictionary  according  spec  thats  required  pdfbox  check  throw  illegalstate  page  requested  pdpagetree  acrobat  libs  handle  doc  think  constraint  could  relaxed  little  consider  valid  type  page  missing  consider  invalid  something  else  think,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2097,cache  glyph  table  optimize  concurrent  access  several  thread  convert  several  pdf  png  one  thread  access  single  document  time  contention  lock  glythtable  jstack  show  thread  state  blocked  synchronized  block  getglyph  method  lock  necessary  ok  degrades  performance  patch  cache  glyph  already  read  patch  pdfbox3080  follow  benchmark  compare  1000  pdf  conversion  1  8  50  thread  simulation  pdf  20snapshot  patch  pdfbox3080  1000  conversion  1  thread  120  71  1000  conversion  8  thread  76  28  1000  conversion  50  thread  81  33,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2098,fix  high  memory  usage  signing  hello  requirement  able  sign  huge  pdf  file  consisting  entirely  paper  scan  unfortunately  current  implementation  unnecessary  buffer  entire  pdf  content  signing  procedure  patch  suggests  fix  well  happy  adjust  needed  see  merged,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2099,reduce  amount  intermediate  data  object  reduce  memory  footprintcomplexity  cffparser  hold  lot  intermediate  data  produce  lot  object  idea  reduce  amount  object  data  reduce  memory  footprint  complexity  class  indexdata  hold  intermediate  data  creates  byte  array  everytime  getbytes  called  im  going  replace  class  simple  list  reduce  memory  footprint  complexity  remove  unused  member  private  class  create  list  string  instead  list  byte  array  used  create  string,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2100,add  constructor  bufferedimage  pdvisiblesigndesigner  18  pdvisiblesigndesigner  constructor  took  jpeg  stream  used  one  directly  create  pdjpeg  20  stream  read  bufferedimage  opportunity  create  jpeg  directly  lost  doesnt  matter  jpeg  best  choice  image  sharp  edge  signature  scan  text  printed  image  replace  jpegfactory  losslessfactoory  add  constructor  take  bufferedimage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2101,pdimagexobjectcreatefromfile  relies  header  byte  pdimagexobjectcreatefromfile  currently  relies  file  extension  select  correct  factory  often  file  extension  set  correct  better  use  first  byte  something  similar  help  httpsgithubcomsismicsdocsblobmasterdocscoresrcmainjavacomsismicsutilmimemimetypeutiljaval26,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2102,rename  structure  element  setter  pdoutlineitem  playing  around  library  stumbled  naming  inconsistency  getter  setter  pdoutlineitem  structure  element  getter  named  getstructureelement  whereas  setter  named  setstructuredelement  bit  confusing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2103,cache  font  bounding  box  performance  text  extraction  hi  using  pdfbox  way  tika  text  extraction  pdfs  chance  fire  profiler  recently  found  getboundingbox  pdxxfontjava  class  called  fairly  frequently  particular  pdftextstreamengineshowglyph  ive  attached  patch  cache  boundingbox  object  alongside  pdfont  object  inside  pdtextstate  variety  way  accomplish  thing  caching  inside  various  font  object  etc  wrote  little  test  program  measure  speed  difference  randomly  selected  file  program  us  pdftextstripper  retrieve  raw  text  pdf  here  found  plain  file  bamboocheatsheetpdf  duration  60037555619  rate  816  filessec  file  flupdf  duration  60019978409  rate  3446666666666667  filessec  file  megacliuserguidepdf  duration  60641314800  rate  11833333333333333  filessec  file  odbcperlpdf  duration  60008216404  rate  19466666666666665  filessec  file  verticaarchitecturewhitepaperpdf  duration  60084726865  rate  7433333333333334  filessec  file  writingaresumepdf  duration  60015267784  rate  594  filessec  boundingbox  caching  file  bamboocheatsheetpdf  duration  60005724588  rate  1061  filessec  file  flupdf  duration  60021410660  rate  41916666666666664  filessec  file  megacliuserguidepdf  duration  60107488363  rate  17833333333333334  filessec  file  odbcperlpdf  duration  60017784515  rate  299  filessec  file  verticaarchitecturewhitepaperpdf  duration  60012261509  rate  905  filessec  file  writingaresumepdf  duration  60007995996  rate  765  filessec  cheer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2104,rename  check  box  field  type  match  pdf  20  specification  pdf  20  specification  field  type  splitter  individual  word  check  box  radio  button  pushbutton  match  using  camel  case  various  field  object  field  check  box  named  pdcheckbox  renamed  pdcheckbox,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2105,pdf  creation  slow  compared  older  18x  version  new  20x  branch  awesomely  slow  benchmark  using  multipage  document  image  many  textlines  indiciate  performance  penalty  120  compared  old  18x  branch  profiling  via  visualvm  indicates  new  font  handling  cause  performance  drawback  truetypefontnametogid  31  truetypefonthasglyph  23  pdfontgetwidth  16  pdtype1fontencode  9  workaround  current  setup  creates  10  pdfssecond  compared  200second  18x  branch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2106,refactor  allow  tsa  timestamping  visible  signature  put  tsa  stuff  signaturebase  allow  tsa  parameter,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1
2107,pdbuttongetonvalues  seems  using  wrong  source  getting  allowed  value  process  migrating  itext  pdfbox  noticed  exception  thrown  trying  set  radio  button  pdfieldsetvalue  value  returned  pdbuttongetonvalues  used  pdbuttoncheckvalue  called  pdbuttonsetvalue  returning  01  instead  using  itext  investigating  itexts  source  code  playing  around  pdfbox  able  get  believe  appropriate  allowed  value  using  following  code  code  field  instanceof  pdbutton  final  cosbase  item  fieldgetcosobjectgetitemcosnameopt  item  null  item  instanceof  cosarray  final  cosarray  optarray  cosarrayitem  int  0  optarraysize  item  array  allowed  value  optarraygetstringi  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2108,optimize  cid  glyphid  mapping  ttf  ttf  font  map  codepoints  code  id  glyph  mapping  int  int  jdk  lack  map  class  primitive  type  code  eg  cmapsubtable  currently  us  mapintegerinteger  mapping  inefficient  different  way  autoboxingunboxing  introduces  performance  penalty  boxing  integer  object  memory  overhead  jdk  map  implementation  big  memory  overhead  simple  object  efficiency  execution  time  memory  consumption  would  propose  introduce  simple  intintmap  implementation  work  primitive  integer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2109,move  glyph2d  functionality  pdfont  subclass  glyph2d  class  perform  extra  normalisation  substitution  glyph  path  ready  final  rendering  would  better  functionality  part  various  pdfont  subclass  easy  get  access  final  glyph  bound  weve  user  request  thishttppdfboxdevmarkmailorgsearchqglyph2dqueryglyph2dpage1midww4vslm4xnztxvolstateresults,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
2110,warn  user  use  legacy  code  pdftextstreamengine  cause  confusion  amongst  user  mailing  list  legacy  code  label  clearly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2111,patch  improved  signing  existing  signature  field  short  handling  signing  existing  signature  field  must  improved  patch  part  effort  detail  background  current  implementation  visible  signature  always  add  new  signature  field  signing  document  case  signature  everything  definied  field  property  coordinate  etc  another  quite  common  use  case  use  existing  signature  field  signed  basically  two  different  role  document  creator  creates  document  text  graphic  form  field  creator  know  best  everything  positioned  even  sometimes  bound  certain  regulation  etc  document  creator  defines  intend  usage  right  may  add  usage  right  signature  later  document  user  eg  customer  fill  form  field  sign  predefined  signature  field  case  coordinate  lot  attribute  alrady  defined  need  sometimes  even  forbidden  change  physical  attribute  signature  field  two  thing  interest  set  signature  dictionary  recreate  appearance  current  implementation  however  one  need  define  coordinate  existing  signature  field  enough  since  screen  coordinate  java  pdfbox  pdvisiblesigbuilder  pdf  coordinate  different  origin  one  must  convert  existing  pdf  coordinate  screen  coordinate  later  converted  pdf  coordinate  cumbersome  error  prone  totally  unecessary  supplied  patch  conversion  coordinate  anymore,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2112,read  image  byte  array  create  several  pdf  file  image  lot  time  spend  read  image  file  added  possibility  create  image  byte  array  user  keep  memory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2113,add  cosbooleanfalse  option  pddocumentcatalogs  getopenaction  tika  weve  started  allowing  user  extract  pdactions  recent  regression  test  found  new  exception  trying  get  openaction  pddocumentcatalog  easy  one  fix  noformat  javaioioexception  unknown  openaction  false  orgapachepdfboxpdmodelpddocumentcataloggetopenactionpddocumentcatalogjava261  orgapachetikaparserpdfabstractpdf2xhtmlstartdocumentabstractpdf2xhtmljava460  noformat  object  cosboolean  valuefalse  ill  open  separate  issue  new  u  exception,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2114,improve  refactor  removealltext  example  refactor  double  code  include  pattern  xobject  form  going  resource  better  template  utility  work  content  stream  token  eg  httpsstackoverflowcoma45259160535646,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2115,add  certificate  dictionary  seed  value  signature  field  dictionary  important  give  ability  put  certificate  constraint  signature  field  like  want  signature  signed  specific  issuer  authority  used  field  currently  tested  issuer  constraint  worked  acrobat  reader  ignores  certificate  allow  issuer  given  sign  field  documentation  complete  waiting  initial  acceptance  complete  new  class  pdseedvaluecertificate  added  refers  certificate  pdseedvalue  modified  add  new  dictionary  cosname  modified  add  new  pdf  name  included  dictionary  reference  dictionary  found  pdf  reference  17  section  12745  table  235  page  457  httpwwwadobecomcontentdamacomendevnetpdfpdf320002008pdf  chapter  8  table  884  page  700  httparchimedespalimpsestnetdocumentsexternalpdfreference17pdf  httpswwwadobecomdevnetdocsacrobatetktoolsdigsigacrobatdigitalsignaturesinpdfpdf  first  contribution  hope  everything  go  well,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2116,add  validation  data  signer  document  support  long  term  validation  signature  need  add  valdiationdictionary  document  inside  importantly  ocspresponse  signer  multiple  defined  pades  4httpsenwikipediaorgwikipades  following  element  added  document  ds  document  security  store  linked  vris  signature  first  provide  example,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2117,implement  show  text  positioning  operator  tj  tj  operator  required  properly  implement  text  justification  unicode  font  word  spacing  operator  tw  sufficient  note1  pdf  specification  github  user  backslash47  provided  basic  implementation  help  httpsgithubcombackslash47pdfboxcommit3c528295b16445e58dc9fe895f78384221452be2  thanks  daniel  1  note  word  spacing  applied  every  occurrence  singlebyte  character  code  32  string  using  simple  font  composite  font  defines  code  32  singlebyte  code  apply  occurrence  byte  value  32  multiplebyte  code  example  code  codejava  import  javaioinputstream  import  javautilarraylist  import  javautillist  import  orgapachepdfboxpdmodelpddocument  import  orgapachepdfboxpdmodelpdpage  import  orgapachepdfboxpdmodelpdpagecontentstream  import  orgapachepdfboxpdmodelpdpagecontentstreamappendmode  import  orgapachepdfboxpdmodelcommonpdrectangle  import  orgapachepdfboxpdmodelfontpdfont  import  orgapachepdfboxpdmodelfontpdtype0font  import  orgapachepdfboxutilmatrix  public  class  textwithpositioningexample  public  static  void  mainstring  args  throw  exception  doithello  world  test  justifyexamplepdf  example  show  justify  string  using  showtextwithpositioning  method  first  space  adjusted  every  letter  public  static  void  doitstring  message  string  outfile  throw  exception  document  try  pddocument  doc  new  pddocument  inputstream  pddocumentclassgetresourceasstreamorgapachepdfboxresourcesttfliberationsansregularttf  final  float  fontsize  200f  page  1  pdfont  font  pdtype0fontloaddoc  true  pdfont  font  pdtype1fontcourier  pdpage  page  new  pdpagepdrectanglea4  docaddpagepage  get  nonjustified  string  width  text  space  unit  float  stringwidth  fontgetstringwidthmessage  fontsize  get  string  height  text  space  unit  float  stringheight  fontgetfontdescriptorgetfontboundingboxgetheight  fontsize  get  width  justify  pdrectangle  pagesize  pagegetmediabox  pdpagecontentstream  contentstream  new  pdpagecontentstreamdoc  page  appendmodeoverwrite  false  contentstreambegintext  contentstreamsetfontfont  fontsize  start  top  page  contentstreamsettextmatrixmatrixgettranslateinstance0  pagesizegetheight  stringheight  1000f  first  show  nonjustified  contentstreamshowtextmessage  move  next  line  contentstreamsettextmatrixmatrixgettranslateinstance0  pagesizegetheight  stringheight  1000f  2  show  word  justified  space  make  text  space  unit  float  justifywidth  pagesizegetwidth  1000f  stringwidth  listobject  text  new  arraylist  string  part  messagesplits  float  spacewidth  justifywidth  partslength  1  fontsize  int  0  partslength  0  textadd  positive  value  move  left  negative  right  textaddfloatvalueofspacewidth  textaddpartsi  contentstreamshowtextwithpositioningtexttoarray  contentstreamsettextmatrixmatrixgettranslateinstance0  pagesizegetheight  stringheight  1000f  3  show  letter  justified  text  new  arraylist  justifywidth  pagesizegetwidth  1000f  stringwidth  float  extraletterwidth  justifywidth  messagecodepointcount0  messagelength  1  fontsize  int  0  messagelength  0  textaddfloatvalueofextraletterwidth  textaddstringvalueofcharactertocharsmessagecodepointati  charactercharcountmessagecodepointati  contentstreamshowtextwithpositioningtexttoarray  finish  contentstreamendtext  contentstreamclose  docsaveoutfile  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2118,existing  signature  embedded  signed  timestamp  validation  would  like  contribute  new  example  embedded  timestamping  timestamp  beeing  embedded  existing  signature  prepared  big  enough  document  get  changed  step  preparation  ltv  includes  reorganisation  validationpurposes  codejava  execjava  x  dexecmainclassorgapachepdfboxexamplessignaturevalidationcreateembeddedvalidation  dexecargsinfile  tsa  tsa  code  createsignature  changed  add  signatureoptions  choose  size  signature,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
2119,add  support  flag  disabling  rendering  pdf  annotation  pdfrenderer  regardless  annotation  supposed  printed  pdf  would  interesting  posse  flag  allowing  choose  annotation  printed  top  document  page  â  diff  rough  implementation  â  â  codejava  diff  git  apdfboxsrcmainjavaorgapachepdfboxrenderingpdfrendererjava  bpdfboxsrcmainjavaorgapachepdfboxrenderingpdfrendererjava  apdfboxsrcmainjavaorgapachepdfboxrenderingpdfrendererjava  bpdfboxsrcmainjavaorgapachepdfboxrenderingpdfrendererjava  356  359  public  class  pdfrenderer  protected  final  pddocument  document  todo  keep  rendering  state  cache  parameter  used  know  rendering  include  annotation  private  boolean  renderannotations  true  creates  new  pdfrenderer  param  document  document  render  2244  22714  public  class  pdfrenderer  return  new  pagedrawerparameters  public  void  setrenderannotationsboolean  render  thisrenderannotations  render  public  boolean  renderannotations  return  renderannotations  diff  git  apdfboxsrcmainjavaorgapachepdfboxrenderingpagedrawerjava  bpdfboxsrcmainjavaorgapachepdfboxrenderingpagedrawerjava  apdfboxsrcmainjavaorgapachepdfboxrenderingpagedrawerjava  bpdfboxsrcmainjavaorgapachepdfboxrenderingpagedrawerjava  19511  19513  public  class  pagedrawer  extends  pdfgraphicsstreamengine  processpagegetpage  pdannotation  annotation  getpagegetannotations  showannotationannotation  getrendererrenderannotations  pdannotation  annotation  getpagegetannotations  showannotationannotation  graphic  null  code  exemple  use  caseâ  codejava  pddocument  doc  getpddocument  pdfrenderer  pdfrenderer  new  pdfrendererdoc  pdfrenderersetrenderannotationsfalse  pdfrendererrenderimagepage  â  code  default  would  keeping  behavior  used  aka  print  annotation  posse  optout  feature  â  best  regard  mveron,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2120,vertical  text  creation  needed  output  vertical  japanese  text  stymied  several  limitation  api  load  ttf  identityv  encoding  support  vert  glyph  substitution  support  vertical  metric  vhea  vmtx  table  parsed  used  attached  series  patch  implement  feature  highlight  gsub  glyph  substitution  table  parsed  limitation  type  1  lookup  sufficient  many  feature  including  vertvrt2  vertical  glyph  substitution  cmap  lookup  make  use  gsub  feature  enabled  ttf  vhea  vmtx  metric  applied  pdcidfont  appropriate  embeddedsubsetted  correctly  dw2w2  cidfont  dictionary  api  added  loading  ttf  vertical  font  setting  identityv  encoding  enabling  vertvrt2  substitution  patch  could  approximately  split  separate  ticket  desired  also  attached  sample  code  exercise  patch  illustrates  effect  vertical  glyph  positioning  sample  output  pdf  also  attached,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2121,allow  subsampleddownscaled  rendering  image  rendering  subimages  suggestedcontributed  change  allow  subsampling  image  rendering  subregions  imagesâ  â  need  arises  large  image  highly  compressed  usually  jpeg  jbig2  current  implementation  decodes  entire  image  memory  full  resolution  even  rendering  done  much  lower  resolutionâ  since  change  required  augmenting  way  filter  work  allow  partialsubsampled  decoding  also  includes  partial  fix  forâ  pdfbox3340â  â  â  change  introduces  decodeoptions  currently  applicable  image  include  requesting  metadata  pdimagexobjects  repair  method  subsampling  subregion  similar  javaximagioimagereadparamâ  since  filter  honor  use  option  decodeoptions  class  contains  flag  filter  honor  option  subsample  decode  requested  region  set  true  flag  false  subsampling  cropping  done  decoding  ensure  consistencyâ  pagedrawer  modified  us  subsampling  based  ratio  desired  output  original  imageâ  â,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2122,overlay  class  allow  user  influence  transform  suggested  mkl  comment  linked  issue  offer  user  way  calculation  overlay  position,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2123,patch  support  simple  lossless  compression  16  bit  rgb  image  attached  patch  add  support  write  16  bit  per  component  image  correctly  ive  integrated  test  httpsgithubcomrototorpdfboxgraphics2dcommit8bf089cb74945bd4f0f15054754f51dd5b361fe9  support  16bit  typecustom  datatype  ushort  image  usually  get  read  16  bitâ  pngâ  file  thisâ  would  also  fix  httpsgithubcomdanfickleopenhtmltopdfissues173  patch  209  apply  300  still  room  improvement  writing  lossless  image  image  currently  notâ  efficiently  encoded  ie  could  use  png  encoding  get  better  compression  adding  cosnamedecodeparms  aâ  cosnamepredictor  15  andâ  encoding  image  png  something  later  patch  would  also  need  another  api  tradeoff  speed  v  compression  ratioâ,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2124,add  quality  option  compressed  image  pdfboxapp  add  commandline  optionâ  quality  option  compressed  image  pdfboxapp  ex  quality  075  â  see  pdfboxtoolpatch  â,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2125,refactor  losslessfactory  alpha  looking  code  pdfbox4184  noticed  try  get  alpha  data  different  way  despite  available  main  method  imagegetrgb  called  im  refactoring  side  effect  16  bit  change  pdfbox4184  longer  needed  ill  commit  two  step  1  changing  main  method  remove  one  longer  used  2  split  main  method  gray  color  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2126,expose  tiff  compression  type  user  allow  user  set  compression  type  tiff  file  externally  current  version  class  imageioutil  us  tiffutilsetcompressiontype  set  compression  ccitt  t6  lzw  choice  could  allow  jpeg  compression  efficient  already  todo  code  todo  expose  choice  user  thank,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2127,improve  html  output  would  like  improve  html  output  pdf  file  arabic  rendering  attached  file  change  improve  way  html  option  work  output  file  tagged  html  extension  also  added  doctype  information  well  meta  tag  writes  appropriate  encoding  file  cleaned  lot  code  pdftextstripper  pdftext2html  wasnt  used  added  ability  set  title  tag  html  document  title  given  pdf  document  information  exists  otherwise  guess  title  beginning  first  line  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2128,patch  improvement  bitmap  production  resolution  color  depth  attached  patch  improves  pdftoimage  utility  support  resolution  color  depth  setting  resolution  300dpi  creates  300  dpi  bitmap  color  rgba  creates  rgb  24bit  image  8bit  alpha  channel  color  rgb  creates  rgb  24bit  image  color  gray  creates  8bit  gray  image  color  indexed  creates  8bit  color  image  256  indexed  color  produced  change  color  bilevel  creates  1bit  bilevel  image  patch  also  fix  various  checkstyle  issue  class  touched  ive  tried  preserve  method  backwardscompatibility  however  ive  changed  pdfimagewriterwriteimage  pdfimagewriterwriteimage  method  name  always  start  lowercase  character  pagedrawer  similar  problem  didnt  fix  however  daniel  please  note  change  make  testpdftoimage  test  case  fail  ive  changed  default  setting  pdftoimage  rgb  screen  resolution  usually  96dpi  setting  equivalent  resolution  144  color  indexed  furthermore  output  format  support  resolution  value  standard  imageio  metadata  contain  resolution  information  alone  make  reference  pngs  different  even  set  default  setting  old  setting  effectively  created  image  pixel  level  may  need  decide  setting  test  recreate  reference  bitmap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2129,prepare  pdfbox  release  prepare  pdfbox  release  check  buildprocess  directory  structure  target  etc  check  everything  according  apache  policy,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2130,support  conflictslist  xref  stream  pdf  15  greater  fix  pdfbox183  added  conflictlist  keep  track  duplicate  object  pdf  file  insufficient  pdf  file  include  xref  table  rather  xref  stream,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2131,show  single  page  instead  pdfreader  always  show  page  document  would  better  show  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2132,improved  pdf  text  extraction  note  paragraph  boundary  current  behavior  orgapachepdfboxutilpdftextstripper  class  ignore  paragraph  demarcation  text  basically  render  line  text  discovers  separating  line  equally  line  separator  make  difficult  identify  paragraph  even  page  start  stop  extracted  text  often  necessary  text  processing  need  work  logical  chunk  text  rendering  format  html  xml  facilitated  resolving  document  discrete  logical  text  chunk  request  improved  text  extraction  provides  discrete  instrumentation  parsing  allowing  one  identify  tag  paragraph  start  stop,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2133,pdfbox  performance  issue  pdsimplefont  pdfont  performance  tweak  text  extraction  font  size  descriptor  encoding  attribute  accessed  repeatedly  order  positional  calculation  bytecharacter  conversion  current  code  several  accessors  thing  redo  rather  slow  calculation  time  even  thought  font  object  state  changed  result  calculation  persisted  instance  field  calculated  greatly  improves  performance  ill  attach  new  version  pdfont  pdfontdescriptordictionary  pdsimplefont  tweak,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2134,shfill  operator  need  implementation  pdf  file  yet  release  permission  us  sh  operator  equivalent  postscript  shfill  per  pdf  spec  17  page  987  adobe  provides  implementation  guidance  78page  document  httpwwwadobecomdevnetpostscriptpdfstn5600smoothshadingpdf17  trying  add  functionality  week  anyone  hint  suggestion  etc  certainly  welcome,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2135,fallback  mechanism  broken  cff  font  pdfbox542  proven  sufficiently  foolproof  realworld  pdf  document  pdfbox  fallback  type1  font  appropriate  warning  message  default  behaviour  pdfbox  080  earlier  version  problem  parsinginterpreting  cff  aka  type1c  font,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2136,ensuring  nonnull  fontdescriptor  external  truetype  font  class  pdtruetypefont  assumes  always  nonnull  fontdescriptordictionary  available  however  ive  seen  assumption  failing  nullpointerexception  method  pdtruetypefontdrawstring  trying  render  pdf  document  make  use  external  truetype  font  ive  implemented  small  patch  initializes  empty  fontdescriptordictionary  one  missing  try  fill  information  available  external  ttf  resource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2137,cfffont  management  cidkeyed  hi  im  currently  using  fontbox  100  need  manage  cidkeyed  font  feature  isnt  yet  managed  cffparser  attachment  find  patch  parse  cidkeyed  font  hope  contribution  help  regard  eric,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2138,support  missing  text  rendering  mode  rendering  pdf  7  different  text  rendering  mode  mode  0  fill  text  correctly  implemented  mode  1  stroke  text  fall  back  mode  0  others  implemented  im  looking  implement  missing  mode  least  im  proposing  structural  change  rendering  really  occurs  currently  done  within  pdxxxfont  class  id  rather  implement  awt  text  output  pagedrawer  helper  class  within  package  use  font  class  return  awt  font  adding  getawtfont  method  get  better  separation  pdf  related  stuff  pdxxx  application  like  pagedrawer  current  rendering  specific  code  within  pdxxxfont  class  retained  compatibility  marked  deprecated  later  stage  wdyt,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2139,refactoring  renderingrelated  classesmethods  extensibility  classesmethods  rendering  area  assume  access  graphics2d  object  assumption  break  using  net  version  pdfbox  judicious  refactoring  permit  pagedrawer  extended  net  key  method  overriden  continuing  refactoring  better  rendering  support  net  andreas  recently  asked  code  committed  svn  also  tied  jira  issue  good  idea  really  im  putting  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2140,extract  information  tagged  pdf  imported  sourceforge  httpsourceforgenettrackerindexphpgroupid78314atid552835aid805623  originally  submitted  benlitchfield  20030913  0738  add  ability  extract  information  tagged  pdf  document  see  taggedpdfpdf  example  comment  sourceforge  originally  sent  qumar  logged  yes  userid1468838  hi  parse  pdf  object  structure  tree  structural  element  inside  object  tree  see  eg  pdfreference  14  chapter  96  logical  structure  parse  pdf  page  stream  extract  drawing  text  operationsthese  contain  actual  content  structural  element  content  surrounded  bmcemc  tag  contain  information  element  object  contained  content  belongsthis  got  pdf  reference  regard  qumar  comment  sourceforge  originally  sent  benlitchfield  logged  yes  userid601708  httpwwwirsgovpubirsaccessf1040ezaccessiblepdf  would  good  form  start  notice  putting  label  form  field  label  contain  meta  data  critical  building  tax  software  rapid  fashion  without  meta  data  name  form  field  meaningless  would  nice  extract  information  combine  data  field  name  type  location  etc  already  know  pdfbox  extract  information  field  havent  done  pdfbox  itext  comment  sourceforge  originally  sent  benlitchfield  logged  yes  userid601708  comment  user  tagged  pdf  big  thing  government  federal  government  procurement  acrobat  publishing  technology  fall  section  508  state  likely  follow  see  wwwsection508gov  httpwwwirsgovpubirsaccess  ftpftpirsgovpubirsaccess  comment  sourceforge  originally  sent  qumar  logged  yes  userid1468838  hi  seeing  specification  pdf  came  know  structure  information  pdf  pdsedit  layerpdsedit  layer  give  access  structure  tree  pdf  method  method  object  prefixed  pdsso  get  access  pdsedit  layer  pdf  comment  sourceforge  originally  sent  qumar  logged  yes  userid1468838  would  nice  pdfbox  provide  ability  extract  information  tagged  pdfas  adobre  acrobat  reader  provides  tag  pdf  pdfbox  also  try  get  tagged  pdfs  example  iwe  pdf  file  para1  header1  para2  header  2  table  row  columnssomething  like  header1  para  1  describes  disease  header2  para2describes  remedy  disease  table  b  c  tagged  pdf  look  like  adobe  acrobat  reader  heading  1  header1  normal  para  1  describes  disease  heading  1  header1  normal  para2describes  remedy  disease  heading  1  table  table  tbody  tr  td  normal  td  normal  b  tr  td  normal  c  td  normal  extract  heading1  heading  2  tabular  data  using  pdfbox  good  feature  added  armory  pdfbox  please  provide  feature,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
2141,adding  method  manipulate  current  transformation  matrix  similar  settextmatrix  need  method  manipulate  current  transformation  matrix  within  pdpagecontentstream,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2142,implementation  additional  cmap  format  truetype  font  hi  according  apple  truetype  reference  manual  microsofts  truetype  10  font  file  technical  specification  several  cmap  format  currently  fontbox  implement  format  0  4  6  attachment  find  patch  implement  format  2  8  10  12  13  according  understanding  following  link  httpwwwmicrosoftcomtypographyotspeccmaphtm  opentype  specification  httpdeveloperapplecomfontsttrefmanrm06chap6cmaphtml  patch  includes  change  proposal  jira  issue  pdfbox668  pdfbox670  pdfbox691  hope  patch  help  regard  eric,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
2143,add  current  page  number  page  title  flip  page  pdf  document  using  pdfreader  cant  see  current  page  total  number  page  pdf,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2144,add  support  draw  fill  polygon  add  support  draw  fill  polygon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2145,pdftextstripper  allow  access  currentpageno  variable  ive  extended  orgapachepdfboxutilpdftextstripper  im  using  perform  2pass  extraction  document  however  second  pas  doesnt  happen  unable  alter  variable  currentpageno  maintains  current  page  number  pdf  document  variable  access  modifier  private  get  method  provided  time  currentpageno  set  0  via  writepagepddocument  outputstream  overridingnot  calling  2  possible  resolution  make  currentpageno  protected  instead  private  preferred  add  setcurrentpageno  method  thank  ryan,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2146,loading  ttf  font  file  classpath  currently  pdfbox  110  120  snapshot  ttf  font  file  loaded  file  system  pdtruetypefont  expose  two  load  method  public  static  pdtruetypefont  loadttfpddocument  string  public  static  pdtruetypefont  loadttfpddocument  file  first  wrap  string  javaiofile  object  delegate  second  ttf  reading  file  system  would  useful  able  read  ttf  file  classpath  indeed  arbitrary  stream  could  third  method  public  static  pdtruetypefont  loadttfpddocument  inputstream  would  allow  ttfs  loaded  like  pdtruetypefontloadmydoc  myclassclassgetclassloadergetresourceasstreammyfontttf  worth  here  patch  see  one  uncertainty  use  cosnamelength1  field  seems  used  currently  pdtruetypefont  may  reasonable  push  setting  attribute  pdstream  constructor  index  pdfboxsrcmainjavaorgapachepdfboxpdmodelcommonpdstreamjava  pdfboxsrcmainjavaorgapachepdfboxpdmodelcommonpdstreamjava  revision  948363  pdfboxsrcmainjavaorgapachepdfboxpdmodelcommonpdstreamjava  working  copy  11412  11417  output  streamcreateunfilteredstream  int  bytesininputstream  0  byte  buffer  new  byte  1024  int  amountread  1  amountread  strreadbuffer  1  outputwrite  buffer  0  amountread  bytesininputstream  amountread  set  number  byte  read  input  stream  thisstreamsetint  cosnamelength1  bytesininputstream  finally  index  pdfboxsrcmainjavaorgapachepdfboxpdmodelfontpdtruetypefontjava  pdfboxsrcmainjavaorgapachepdfboxpdmodelfontpdtruetypefontjava  revision  948363  pdfboxsrcmainjavaorgapachepdfboxpdmodelfontpdtruetypefontjava  working  copy  1307  1307  load  ttf  embedding  document  load  ttf  embedded  document  param  doc  pdf  document  hold  embedded  font  param  file  ttf  file  stream  13921  13932  public  static  pdtruetypefont  loadttf  pddocument  doc  file  file  throw  ioexception  return  loadttf  doc  new  fileinputstream  file  load  ttf  embedded  document  param  doc  pdf  document  hold  embedded  font  param  stream  ttf  input  stream  return  pdf  ttf  throw  ioexception  error  loading  data  public  static  pdtruetypefont  loadttf  pddocument  doc  inputstream  stream  throw  ioexception  pdtruetypefont  retval  new  pdtruetypefont  pdfontdescriptordictionary  fd  new  pdfontdescriptordictionary  pdstream  fontstream  new  pdstreamdoc  new  fileinputstream  file  false  fontstreamgetstreamsetint  cosnamelength1  intfilelength  pdstream  fontstream  new  pdstreamdoc  stream  false  fontstreamaddcompression  fdsetfontfile2  fontstream  retvalsetfontdescriptor  fd  inputstream  ttfdata  new  fileinputstreamfile  try  loaddescriptordictionaryretval  fd  ttfdata  loaddescriptordictionaryretval  fd  stream  finally  ttfdataclose  streamclose  support  winansi  encoding  right  really  use  identityh  unicode  mapping,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2147,implementation  function  type  02  3  used  separation  devicen  colorspaces  im  working  implementation  function  type  02  3  used  within  separation  devicen  colorspaces,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2148,move  lucene  ant  code  separate  component  discussed  dev  would  good  get  rid  optional  lucene  ant  dependency  main  pdfbox  jar  easiest  way  without  dropping  existing  code  move  lucene  ant  integration  code  separate  component,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2149,add  utility  class  easily  extract  range  page  pdf  there  currently  utility  extract  range  page  eg  page  37  task  add  pageextractor  class  corresponding  junit  test  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2150,add  writedecodeddoc  standalone  app  standalone  app  see  pdfbox687  doesnt  support  writedecodeddoc  commandline  tool,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2151,optional  content  group  ocgs  aka  layer  initial  support  im  currently  writing  code  client  create  manipulate  optional  content  group  ocgs  aka  layer  pdlayer  goal  overlay  way  various  combined  page  separate  layer  switched  please  note  start  example  include  conditional  rendering  layer  ill  submit  patch  review  couple  day  ive  got  necessary  pd  layer  code  already  upgrade  overlay  utility,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2152,performance  improvement  pdfstreamengine  matrix  patch  included  ive  profiling  pdfbox  text  extraction  large  pdf  document  eg  2000  page  mostly  text  20  mb  file  size  document  take  long  time  process  eg  40  sometimes  lot  im  using  25  ghz  4  gb  mac  o  x  1058  javatm  se  runtime  environment  build  16022b043079m3263  xms256m  xmx1024m  xxpermsize256m  ive  begun  profiling  code  spends  time  text  extraction  see  lot  time  spent  constructing  orgapachepdfboxutilmatrix  object  screenshot  pdfreferencenopatchtiff  show  used  method  pdfbox  text  extraction  large  document  screenshot  taken  percentage  stabilised  matrixinit  account  40  cpu  time  apparently  largest  time  method  surprised  matrix  instance  constructed  within  pdfstreamengineprcoessencodedtextbyte  revision  1035639  pre140  method  construct  one  matrix  object  7  within  loop  called  character  document  thats  lot  matrix  object  attached  patch  refactors  pdfstreamengineprocessencodedtext  creates  5  reusable  matrix  instance  outside  loop  2  within  achieved  adding  new  method  matrix  matrixmultiplymatrix  matrix  allows  multiply  two  matrix  result  stored  specified  matrix  object  effect  reducing  number  temporary  matrix  object  created  multiplication  within  pdfstreamengine  save  garbage  collector  work  profiled  pdfbox  patch  included  matrixinit  account  30  cpu  time  unfortunately  whilst  le  temporary  object  created  doesnt  appreciable  effect  time  take  extract  text  large  document  profiling  continues,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2153,pdf  signing  interface  improvments  first  version  signing  interface  pdfbox  design  issue  could  handle  without  rewriting  much  code  go  incremental  update  support  tested  signature  pdfa  compatibility  compatible  encrypted  document  xrefstreams  co  object  improvment  cosstring  ability  force  writing  hexbin  given  string  cosbase  ability  write  direct  dictionary  mean  set  indirect  object  wrote  sry  hard  explain  mean  actualy  needed  incremental  update  lower  rate  indirect  object  cosbase  ability  force  writing  object  hook  help  coswriter  write  needed  object  inkremental  update  cosname  added  new  name  cosdocument  getter  setter  handling  new  signature  incremental  feature  signatureexception  exception  handling  bunch  new  possible  error  parser  improvments  pdfparser  save  position  last  startxref  visualsignatureparser  hook  parsing  visual  signature  template  prepared  visualisation  merged  document  io  improvments  cosfilterinput  help  find  proper  content  hashed  signed  cosstandardoutputstream  tricky  help  writer  jump  right  place  document  coswriter  got  improvments  incremental  update  coswriterxrefentry  needed  incremental  update  writing  new  xref  table  pddocument  got  new  method  addsignature  needed  implementation  whole  signature  stuff  cleanup  field  annotation  pdsignature  represent  signature  dictionary  pdsignaturefild  annotation  visible  unvisible  signature  representation  signature  interface  option  signatureinterface  interface  shall  implemented  proper  signing  signatureoptions  additional  option  signing  patch  splited  piece  sry  spelling  didnt  include  spellchecker  english,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2154,read  nonconforming  pdfs  attached  without  throwing  javaioioexception  expectedendobj  orgapachepdfboxiopushbackinputstream  happened  using  following  pdf  2mb  httpbibliotecasinbaduaptdisqswsgetaspxfilename2010001615pdfcatalogtesestypepdf  reading  nonconforming  pdfs  like  one  following  exception  thrown  text  extraction  partially  fails  warn  parsing  error  skipping  object  javaioioexception  expectedendobj  firstreadattempt  secondreadattempt  orgapachepdfboxiopushbackinputstream53ab04  orgapachepdfboxpdfparserpdfparserparseobjectpdfparserjava607  orgapachepdfboxpdfparserpdfparserparsepdfparserjava172  orgapachepdfboxpdmodelpddocumentloadpddocumentjava878  orgapachepdfboxpdmodelpddocumentloadpddocumentjava843  orgapachetikaparserpdfpdfparserparsepdfparserjava74  orgapachetikaparsercompositeparserparsecompositeparserjava197  orgapachetikaparsercompositeparserparsecompositeparserjava197  orgapachetikaparserautodetectparserparseautodetectparserjava137  orgapachetikaclitikacliprocesstikaclijava218  orgapachetikaclitikaclimaintikaclijava84,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2155,add  optional  debug  output  extracttext  would  useful  information  time  consumption  different  stage  text  extraction,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2156,rename  strut  action  2  strut  2  discussed  dev  rename  instance  strut  action  2  strut  2  includes  orgapachestrutsaction2  orgapachestruts2  strut  action  framework  2  strut  2  saf2  strut  2  documentation  javadoc  reference  see  also  str2898  rename  strut  action  1  strut  1,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
2157,support  action  name  slash  better  support  reststyle  wildcard  scheme  article123view  default  action  mapper  support  action  name  contain  slash  instead  assuming  everything  last  slash  namespace  configured  namespaces  iterated  explicitly  matched,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2158,redirectaction  able  accept  parameter  wwurl  tag  let  specify  action  parameter  like  wwurl  actionmyactionwwparam  nameid  valuemyparamvaluewwurl  redirectaction  result  type  xworkxml  able  accept  parameter  well  important  especially  using  custom  actionmapper  action  name  url  used  prevents  use  regular  redirect  result  type  see  httpforumsopensymphonycomthreadjspaforumid1threadid25826,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2159,generate  taglib  tld  annotationsxdoclet  tag  previously  webwork  2  taglib  tld  generated  using  xdoclet  xdoclet  tag  source  code  move  maven  2  java  5  ant  task  performed  task  removed  xdoclet  doesnt  work  java  5  source  therefore  either  migrate  process  new  xdoclet  2  plugin  using  java  5  annotation  processing  tool,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2160,provide  hook  filterdispatcher  custom  dispatcher  could  used  provide  hook  protected  method  filterdispatcher  creates  dispatcher  instance  used  filterdispatcher  way  user  plug  custom  dispatcher  useful  testing  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2161,support  strut  1  actionforms  use  common  validator  strut  2  support  actionforms  use  common  validator  validatorform,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2162,use  new  xwork  valuestack  interface  instead  ognlvaluestack  directly  xwork  new  valuestack  interface  used  instead  ognlvaluestack  class  directly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2163,clean  url  reststyle  support  via  action  mapping  strut  support  clean  url  making  possible  use  capability  fully  customize  url  necessary,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2164,refactor  actioncontextcleanup  dispatcherfilter  common  logic  abstract  super  class  refactor  actioncontextcleanup  dispatcherfilter  common  logic  abstract  super  class  see  httpforumsopensymphonycomthreadjspathreadid48630tstart0  info,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1
2165,zero  xml  action  configuration  strut  2  ability  configure  action  package  namespaces  convention  annotation  mean  xml  required  developer  create  fullyfeatured  application,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2166,add  dependency  injection  library  wire  internals  strut  framework  plugins  core  strut  simple  dependency  injection  engine  wire  together  major  strut  component  constantssettings  would  allow  u  support  powerful  selfconfiguring  plugins  simplify  internal  architecture  removing  need  static  factory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2167,add  autocompleter  ajax  tag  create  autocompleter  tag  wrap  dojos  combobox,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2168,add  testng  support  strust  2  builtin  support  testng  well  junit  see  also  httpjiraopensymphonycombrowsexw451,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2169,allow  codebehind  select  starting  directory  point  here  simple  patch  allow  new  default  root  directory  used  searching  template  created  wish  keep  jsp  cs  independent  directory  configuration  property  known  strutscodebehindpathprefix  requires  trailing  slash  set  default  java  strutspluginxml  addendum  per  request  ive  also  added  default  constant  strutscodebehinddefaultpackage  help  codebehind  plugin  remain  selfcontained,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2170,separate  dojorelated  tag  plugin  dojospecific  tag  removed  plugin  includes  simple  wrapper  tag  like  datepicker  also  extension  like  anchor  div  tag  forwarded  message  brown  mrdontwdataorg  date  dec  27  2006  613  pm  subject  proposal  tag  reorganization  strut  developer  list  devstrutsapacheorg  ok  let  put  formal  proposal  propose  extract  dojorelated  tag  behavior  new  tag  library  new  library  could  extend  old  tag  purpose  adding  dojorelated  attribute  however  logical  tag  library  keep  old  themeable  tag  look  speed  simple  theme  probably  java  rendering  engine  new  dojobased  tag  contain  date  picker  rich  text  editor  remote  divloading  tag  extension  existing  tag  add  new  dojorelated  attribute  rendering  isnt  possible  extend  existing  tagscomponents  add  new  parameter  well  make  dojo  well  pull  dojo  file  core  left  original  themeable  tag  tag  still  use  theme  engine  well  keep  xhtml  theme  write  include  simple  tooltip  javascript  library  dont  need  import  dojo  ideally  id  like  see  simple  tag  rendered  java  superior  performance  part  proposal  wait  tag  retain  much  backwards  compatibility  possible  exception  missing  ajax  theme  ajax  functionality  used  dwr  remain  old  tag  moved  xhtml  theme  id  like  move  quickly  completed  within  two  week  thought  see  httpmailarchivecomdev40strutsapacheorgmsg26550html  httpmailarchivecomdev40strutsapacheorgmsg26635html,0,0,0,0,0,0,0,0,1,0,1,0,0,1,1,0,0
2171,move  portlet  support  plugin  forwarded  message  brown  mrdontwdataorg  date  jan  15  2007  1233  subject  s2  experimental  feature  strut  developer  list  devstrutsapacheorg  got  90  way  moving  portlet  support  plugin  couple  hardcoded  reference  url  component  another  internal  class  escape  atm  backed  could  revisited  21  tom  schneider  wrote  ted  husted  whttpwwwnetidentitycomlanding7aspxddailcommpdomainredirectdomainid18855categoryid101521869rote  would  great  portlet  plugin  idea  support  implemented  expect  would  easy  well  portletdispatcher  jsr168dispatcherjava  related  portlet  request  support  class  would  probably  easy  separate  trick  would  form  url  tag  right  specific  portlet  behavior  building  portlet  url  real  question  want  separate  tag  portlet  url  might  possible  subclass  url  form  tag  portlet  environment  wed  either  leave  portlet  support  core  use  portlet  pluginor  find  way  override  url  build  core  via  plugin  issue  see  based  limited  knowledge  portlet  code  tom,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2172,allow  overriding  plugin  property  strutsproperties  currently  strutsproperties  processed  xml  file  meaning  cannot  override  plugin  property  property  file  loading  split  defaultproperties  loaded  first  xml  strutsproperties,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2173,fileuploadinterceptor  localized  message  problem  see  httpjiraopensymphonycombrowseww1379  detail  issue  struts2  well  webwork  question  truely  bug  fileuploadinterceptor  working  designed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2174,separate  name  creation  executeandwaitinterceptor  separate  generation  name  executeandwaitinterceptor  extended  change  association  background  process  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2175,custom  parameter  name  prefix  actionmapper  would  great  defaultactionmapper  made  easy  add  additional  parameteractions  prefixtrie  would  take  making  parameteraction  protected  adding  method  like  protected  void  addparameteractionstring  prefix  parameteraction  parameteraction  prefixtrieputprefix  parameteraction  need  add  prefix  support  redirecting  wo  appending  context  feel  pain  currently  submission  redirect  parameter  doesnt  automatically  include  context  static  final  string  redirectnocontextprefix  redirectnocontext  public  myactionmapper  try  list  parameteractions  private  bust  using  reflection  field  prefixtriefield  defaultactionmapperclassgetdeclaredfieldprefixtrie  prefixtriefieldsetaccessibletrue  prefixtrie  prefixtrie  prefixtrie  prefixtriefieldgetthis  object  sample  prefixtriegetaction  parameteraction  interface  package  protected  use  dynamic  proxy  get  around  class  interface  samplegetclassgetinterfaces  object  parameteractionproxy  proxynewproxyinstance  threadcurrentthreadgetcontextclassloader  interface  new  invocationhandler  public  object  invokeobject  proxy  method  method  object  args  throw  exception  methodgetnameequalsexecute  string  key  string  args0  actionmapping  mapping  actionmapping  args1  servletredirectresult  redirect  new  servletredirectresult  redirectsetprependservletcontextfalse  redirectsetlocation  keysubstring  redirectnocontextprefixlength  mappingsetresultredirect  return  null  else  throw  new  runtimeexception  unknown  parameter  action  method  methodgetname  prefixtrieputredirectnocontextprefix  parameteractionproxy  catch  exception  e  logfactorygetlogmyactionmapperclasserror  failed  add  custom  parameter  action  mapping  e,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
2176,add  highlight  effect  target  ajax  tag  add  following  property  bind  submit  anchor  highlightcolor  highlighduration  highlightcolor  specified  dojolfxhtmlhighlight  applied  target  element,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2177,create  jsonvalidationinterceptor  fix  ajax  tag  use  json  generated  interceptor  perform  ajax  validation  fix  showcase  example,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
2178,url  tag  accept  parameter  iterable  string  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2179,tag  push  value  value  stack  use  var  attribute  specify  name  variable  deprecate  id  tag  using  deprecate  name  set  tag,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0
2180,rework  filterdispatcher  pluggable  currently  majority  strut  handle  action  static  resource  passing  request  filter  chain  handled  fitlerdispatcher  via  protected  method  order  change  functionality  plugins  application  must  write  filter  change  webxml  file  use  would  nice  fitlerdispatcher  completely  pluggable  operation  performed  via  well  defined  interface  plugins  could  inject  different  implementation  interface  allowing  modification  main  handling  http  request  response,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
2181,ability  use  multiple  action  extension  simultaneously  currently  cant  really  use  multiple  action  extension  request  using  multiple  extension  recognized  url  created  framework  use  default  first  extension  happen  framework  remember  original  extension  use  future  url  generation  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2182,jasperreports  plugin  exporter  parameter  via  configuration  currently  there  way  pas  exporter  parameter  jasperreports  plugin  outside  itll  good  specify  map  containing  parameter  strutsxml  plugin  use  setparametersjavautilmap  parameter  set  generating  report  action  namenewapp  classgetmessagesaction  result  namesuccess  typejasper  param  namelocationwwwfirstreporttryjasperparam  param  nameformathtmlparam  param  nameparsefalseparam  param  namedatasourcedsmapparam  param  nameexportparamsexporterparamtermapparam  result  action,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2183,add  filename  argument  acceptfile  method  fileuploadinterceptor  would  quite  usefull  extend  acceptfile  method  fileuploadinterceptor  additional  argument  pass  original  filename  allows  filter  uploads  based  extension  name  merely  content  type,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2184,stext  namekey  ognlevaluates  key  found  resource  bundle  stext  namekey  output  resource  message  designated  key  message  exists  body  tag  empty  reverts  outputting  name  key  unevaluated  string  least  thats  behaviour  tag  described  documentation  fact  however  name  key  evaluated  ognl  expression  turn  valid  whats  printed  view  counterintuitive  probably  counterproductive  consider  case  modeldrivenbook  action  exposing  bookobject  view  normally  stext  nametitle  title  would  yielded  title  great  gatsby  resource  message  title  missing  resource  bundle  thats  bad  outcome  however  key  ognlevaluated  would  get  following  output  great  gatsby  great  gatsby  find  little  puzzling,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2185,paramters  set  jfreechart  plugin  action  namech  classorgsomeorgchartchartaction  result  namesuccess  typechart  param  namewidthwidthparam  param  nameheightheightparam  result  action  case  getting  illegalargumentexception  although  defined  width  height  chartaction  public  class  chartaction  extends  actionsupport  private  static  final  long  serialversionuid  4845276888116145855l  private  integer  width  200  private  integer  height  400  public  string  execute  throw  exception  chart  new  chart  return  success  public  integer  getwidth  return  width  public  void  setwidthinteger  width  thiswidth  width  public  integer  getheight  return  height  public  void  setheightinteger  height  thisheight  height,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2186,make  decision  whether  class  instantiated  overridable  subclass  packagebasedactionconfigbuilder  check  done  see  found  action  class  abstract  interface  enum  annotation  would  like  see  check  moved  protected  method  overridden  case  might  quite  alright  interface  used  action  long  objectfactory  used  able  instantiate  action  really  matter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2187,could  create  application  global  result  converting  previous  webwork  2  project  strut  2  webwork  could  define  global  result  used  default  action  use  convention  plugin  global  result  global  single  action  want  define  result  supper  class  baseaction  eg  expect  sub  class  use  result  could  override  result  name  found  feature  menthioned  httpsissuesapacheorgstrutsbrowseww2443  working  convention  plugin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2188,anchor  tag  able  build  url  like  url  tag  refactoring  needed  urlrenderer  depends  url  class  new  interface  urlprovider  introduced  decouple  urlrenderer  url,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
2189,action  action  able  applied  class  method  determined  runtime  dynamic  action  invocation  mechanism  method  execute  defined  class  action  mapping  point  otherwise  method  null  action  mapping,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2190,update  classfinder  packagebasedactionconfigbuilder  avoid  loading  unnecessary  class  package  scan  avoid  spurious  warning  benefit  default  packagebasedactionconfigbuilder  used  convention  plugin  us  classfinder  utility  class  xworks  look  potential  action  class  classpath  behavior  classfinder  scan  every  class  file  classpath  attempt  load  class  loaded  packagebasedactionconfigbuilder  evaluates  loaded  class  see  action  right  package  proper  name  implement  action  work  fine  process  loading  every  class  classpath  produce  ton  error  message  classfinder  attempt  load  class  potentially  unsatisfied  dependency  issue  nonfatal  message  tend  initially  confuse  user  like  see  couple  example  found  googling  httpwwwmailarchivecomuserstrutsapacheorgmsg85317html  httpwwwmailarchivecomgoogleappenginejavagooglegroupscommsg00048html  httparticlegmaneorggmanecompjakartastrutsuser168495  give  justification  annoying  needed  even  better  here  patch  fix  issue  little  tricky  requires  patch  classfinder  xworks  hopefully  guy  deal  packagebasedactionconfigbuilder  patch  classfinder  allows  specifying  optional  class  name  filter  prevent  load  class  patch  packagebasedactionconfigbuilder  construct  appropriate  filter  various  package  hint  specified  class  together  get  exact  class  loading  behavior  without  annoying  error  message  thought,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2191,several  improvement  method  check  http  method  allowed  using  option  default  implementation  post  put  client  sends  request  header  expect  100continue  verification  action  return  allow  string  httpheaders  result  null  default  method  index  restactionsupport  return  object  instead  string  order  allow  httpheaders  result  returned  result  processing  delayed  interceptor  finished  new  configuration  parameter  show  processing  time  via  log4j  show  action  processing  time  plus  interceptor  result  processing  time  jsp  xml  new  flow  result  processing  content  selected  model  exception  error  list  use  httpheaders  apply  header  etc  result  code  304  result  processed  result  httpheaderresult  executed  regardless  representation  result  always  returned  according  requested  representation  error  look  result  named  defaulterror  able  configure  error  page  could  configured  webxml  request  representation  would  respected,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2192,enable  customization  struts2  core  attached  patch  dispatcher  configurationmanager  allows  customization  various  object  created  system  perhaps  cleaner  way  eg  factory  anyway  reason  request  extending  strut  2  dtd  requires  enhancement  xml  parser  etc  etc  cant  cleanly  unless  way  use  derived  class  strutsxmlconfigurationprovider  etc  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2193,correct  support  includeexclude  parameter  jsonresultsetincludeproperties  got  algorithm  right  using  regular  expression  match  ognl  expression  painful  attached  patch  add  support  wildcard  pattern  jsonresult  jsoninterceptor  update  jsoninterceptorsetincludeproperties  use  correct  algorithm  patch  also  add  includeexclude  support  jsoncleaner  support  filtering  input  data  configuration  jsoninterceptor  jsonresult  handle  output  filtering  also  couple  code  cleanup  change  eliminate  code  duplication,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2194,remove  code  duplication  defaultactioninvocation  restactioninvocation  defaultactioninvocationinvokeaction  refactored  methodresult  processed  separate  function  way  done  restactioninvocation  restactioninvocation  would  duplicate  code  invokeaction,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2195,bring  portlet  20  jsr286  plugin  sandbox  trunk  portlet  20  plugin  sandbox  besides  portlet  event  handling  feature  complete  usable  production  environment  event  feature  isolated  may  delivered  later  step  needed  1  sync  change  trunk  plugin  2  call  vote  3  move  plugin  full  replacement  existing  portlet  plugin  since  downward  compatible,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
2196,placeholder  attribute  stextfieldspassword  dynamic  placeholder  field  fot  stextfield  spassword  evaluate  ognl  expression  namely  resource  key  replacement  eg  stextfield  themesimple  placeholdergettextplaceholderusername  idjusername  namejusername  cssstylewidth180px  issue  html5  think  lukasz  lenart  suggested  making  attribute  dynamic  abstractuitag  line  294  public  void  setdynamicattributestring  uri  string  localname  object  value  throw  jspexception  dynamicattributesputlocalname  value  replace  public  void  setdynamicattributestring  uri  string  localname  object  value  throw  jspexception  dynamicattributesputlocalname  findstringvalue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2197,two  testaction  class  confuse  eclipse  sometimes  two  class  name  orgapachestruts2testaction  lead  problem  sometimes  attached  patch  renames  testaction  junitplugin  junittestaction  safe  use,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2198,contextpath  show  included  log  could  find  action  result  invalid  action  requested  namespace  action  name  value  given  warning  log  suggest  contextpath  show  also  included  114036570  warn  orgapachestruts2dispatcherdispatcher60  could  find  action  result  114036572  action  mapped  namespace  action  name  xxxx  unknown  location  114036573  comopensymphonyxwork2defaultactionproxypreparedefaultactionproxyjava189  114036574  orgapachestruts2implstrutsactionproxypreparestrutsactionproxyjava61  114036576  orgapachestruts2implstrutsactionproxyfactorycreateactionproxystrutsactionproxyfactoryjava39  114036576  comopensymphonyxwork2defaultactionproxyfactorycreateactionproxydefaultactionproxyfactoryjava58  114036579  orgapachestruts2dispatcherdispatcherserviceactiondispatcherjava500  114036579  orgapachestruts2dispatcherfilterdispatcherdofilterfilterdispatcherjava434  114036582  orgapachecatalinacoreapplicationfilterchaininternaldofilterapplicationfilterchainjava280  114036582  orgapachecatalinacoreapplicationfilterchaindofilterapplicationfilterchainjava248  114036584  orgapachecatalinacorestandardwrappervalveinvokestandardwrappervalvejava275  114036585  orgapachecatalinacorestandardcontextvalveinvokestandardcontextvalvejava161  114036588  orgjbossaswebsecuritysecuritycontextassociationvalveinvokesecuritycontextassociationvalvejava139  114036588  orgjbossaswebnamingvalveinvokenamingvalvejava57  114036590  orgapachecatalinacorestandardhostvalveinvokestandardhostvalvejava154  114036591  orgapachecatalinavalveserrorreportvalveinvokeerrorreportvalvejava102  114036594  orgapachecatalinacorestandardenginevalveinvokestandardenginevalvejava109  114036595  orgapachecatalinaconnectorcoyoteadapterservicecoyoteadapterjava362  114036597  orgapachecoyotehttp11http11processorprocesshttp11processorjava877  114036598  orgapachecoyotehttp11http11protocolhttp11connectionhandlerprocesshttp11protocoljava667  114036600  orgapachetomcatutilnetjioendpointworkerrunjioendpointjava952  114036600  javalangthreadrunthreadjava662,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2199,allow  result  post  restore  compatibility  strutsrestplugin  version  221  time  ago  posted  message  mailing  list  got  reply  see  httpstruts1045723n5nabblecomstrutsrestplugin223resultfromposttd4469274html  really  would  like  update  newer  version  strut  benefit  security  fix  absolutely  care  backwardcompatibility  aware  valid  rest  practice  return  result  post  operation  wish  done  first  place  unfortunately  remain  backward  compatible  choice  see  way  restore  221  behavior  allow  u  remain  backwardcompatible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2200,convert  urlhelper  real  bean  converted  bean  dependency  inject  instead  using  actioncontextgetcontextgetcontainer,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,1,0
2201,update  description  missing  extension  point  beanselectionprovider  two  alias  1  arent  documented  aliasunknownhandlermanagerclass  strutsconstantsstrutsunknownhandlermanager  builder  prop  aliasurlhelperclass  strutsconstantsstrutsurlhelper  builder  prop  review  strutsdefaultxml  arent  missing  well,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2202,make  json  plugin  extendable  currently  difficult  modifyextend  current  behaviour  json  plugin  following  problem  use  jodatime  much  better  standard  date  json  plugin  cannot  handle  class  like  localdate  problem  need  lot  boilerplate  code  output  bean  containing  localdate  field  using  json  currently  create  duplicate  service  layer  dtos  annotate  field  ui  copy  jsonfieldbridge  copy  one  dto  using  dozer  something  creates  lot  useless  code  manual  work  would  much  easier  could  extend  jsonwriter  add  support  jodatime  class  duplication  dtos  need  manually  annotate  field  would  require  modify  visibility  private  method  protected  packageprotected  class  public  way  could  create  struts2  result  type  extends  jsonresult  use  writer  extends  jsonwriter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2203,error  setting  character  encoding  parameter  already  read  application  access  log  filter  log  incoming  request  parameter  request  struts2  filter  call  requestsetcharacterencodingencoding  result  error  request  encoding  cannot  set  parameter  read  pollutes  log  error  every  request  cannot  put  access  log  filter  struts2  filter  invoke  chaindofilter  action  custom  filter  access  log  filter  set  request  encoding  advance  struts2  try  set  encoding  later  late  case  proposed  patch  simple  straightforward  would  solve  problem  polluted  log  encoding  already  set  value  try  set  useless  cause  error  case  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2204,convert  filemanager  bean  right  filemanager  mostly  utility  class  static  method  static  state  converted  bean  allow  change  implementation  meet  specific  application  server  need  like  jboss  weblogic,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,1,0
2205,decouple  token  name  respective  session  attribute  name  currently  token  name  used  store  session  attribute  later  token  check  namespacing  session  attribute  security  improved,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2206,allow  package  inheritance  plugins  allow  package  plugins  package  defined  different  plugin  parent  currently  supported  httpstrutsapacheorg2341docspluginshtml  team  creating  plugin  base  feature  organization  would  nice  able  use  result  type  configuration  defined  plugins,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2207,merge  annotationtools  annotationutils  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2208,extract  static  util  method  component  class  componentutils  class  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2209,refactor  problem  report  generation  dispatcher  much  code  public  void  senderrorhttpservletrequest  httpservletresponse  servletcontext  int  exception  must  simplified,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2210,performance  lock  class  loader  jsonwriter  causing  lock  class  loader  always  invokes  introspectorgetbeaninfo  turn  try  load  class  beaninfo  suffix  introspectorfindexplicitbeaninfo  class  exists  try  load  every  json  result  class  loading  involves  lock  application  server  cause  performance  issue  heavily  multithreaded  application  could  solved  caching  beaninfo  class  created  patch  issue  also  mentioned  httpstackoverflowcomquestions12728860javaperformanceissuetomcatwebappclassloaderlocked,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2211,use  latest  jetty  maven  plugin  example  apps  archetype  would  nice  use  latest  jetty  plugin  codexml  plugin  groupidorgmortbayjettygroupid  artifactidjettymavenpluginartifactid  version817v20120910version  configuration  stopkeyctrlcstopkey  stopport8999stopport  scanintervalseconds10scanintervalseconds  scantargets  scantargetsrcmainwebappwebinfwebxmlscantarget  scantargets  configuration  plugin  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2212,struts2  osgi  plugin  work  glassfish  osgi  plugin  work  glassfish  felix  already  included  including  strut  web  application  bundle  containing  activator  class  following  exception  occurs  javalangclasscastexception  myosgiactivator  cannot  cast  orgosgiframeworkbundleactivator  including  bundle  class  implement  bundlecontextaware  following  exception  occurs  exception  starting  filter  struts2  javalanglinkageerror  loader  constraint  violation  loader  instance  orgapachefelixframeworksearchpolicycontentclassloader  previously  initiated  loading  different  type  name  orgosgiframeworkbundlecontext  also  seems  plugin  us  old  version  felix  could  least  partly  responsible  error  since  glassfish  us  newer  one  detail  error  also  available  stackoverflow  posthttpstackoverflowcomquestions14200300usingstruts2osgipluginwithglassfish,1,0,1,0,1,0,0,1,0,1,1,0,0,1,1,0,0
2213,allow  use  custom  jsonwriter  throw  accessing  private  inner  class  method  private  void  mapmap  map  method  method  throw  jsonexception  may  pas  trying  access  private  class  example  source  code  codejava  private  void  mapmap  map  method  method  throw  jsonexception  thisadd  ithasnext  mapentry  entry  mapentry  itnext  object  key  entrygetkey  string  expr  null  thisbuildexpr  try  key  null  logerrorcannot  build  expression  null  key  thisexprstack  continue  else  expr  thisexpandexprkeytostring  thisshouldexcludepropertyexpr  continue  expr  thissetexprstackexpr  catch  exception  ex  logerrorerror  exgetlocalizedmessage  continue  hasdata  thisadd  thisadd  code,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,1,0
2214,refactor  parametersinterceptor  easier  extend  follow  ww3973  please  find  attached  patch  allow  developer  easily  extend  interceptor  return  old  behaviour,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2215,validationaware  add  callable  method  called  defaultworkflowinterceptor  form  error  occurs  action  unaware  event  situation  whereby  one  know  form  error  occurred  example  one  may  wish  populate  actionstack  special  handling  variable  set  flag  denoting  special  logic  jsp  handle  short  isnt  unreasonable  one  want  know  form  error  occurred  able  respond  single  jsp  result  attached  input  suggestion  would  within  validationaware  add  method  void  actionerror  within  defaultworkflowinterceptordointercept  already  condition  validationawareactionhaserrors  end  processing  block  return  resultname  call  validationawareactionactionerror  way  line  logdebugerrors  action  validationawareaction  returning  result  name  input  logdebugerrors  action  validationawareaction  returning  result  name  inputresultname,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2216,move  validationaware  interface  package  comopensymphonyxwork2interceptor  potentially  impact  user  import  directive  change,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2217,support  saving  locale  cookie  extend  xwork  i18n  interceptor  support  saving  locale  cookie  new  interceptor  need  live  struts2  package  xwork  part  web  agnostic,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2218,objectfactory  buildresult  obey  parameternameaware  restriction  result  comopensymphonyxwork2objectfactorybuildresultresultconfig  map  injects  resultconfig  parameter  result  built  however  id  like  able  result  implement  parameternameaware  buildresult  obey  acceptableparametername  result  filter  parameter  injected  im  sorry  dont  proper  patch  small  change  call  setproperty  result  parameternameaware  parameter  name  acceptable  codejava  result  instanceof  parameternameaware  parameternameaware  resultacceptableparameternameparamentrygetkey  reflectionprovidersetpropertyparamentrygetkey  paramentrygetvalue  result  extracontext  true  code  running  strut  2  app  6  year  change  place  getting  around  suggesting  patch  also  look  like  documentation  parameternameaware  would  need  updated  reflect  also  used  result  action,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2219,define  factory  type  supported  objectfactory  0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0,0,1
2220,dont  check  disallowed  ognl  expression  getting  expression  cache  ognl  expression  cache  enabled  cache  hit  dont  need  overhead  traversing  tree  see  disallowed  expression  ive  attached  simple  patch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2221,allow  class  attribute  strut  tag  building  jsp  working  web  related  thing  outside  java  environment  lot  tag  receive  class  attribute  strut  developer  must  remember  call  attribute  cssclass  instead  typing  muscle  memory  drive  half  time  typing  class  instead  lead  html  read  classclass  javautilhashmap  allow  class  like  rest  html  world  need  different  billion  thing  remember  web  developing  shouldnt  one  dont  even  deprecate  obsolete  cssclass  also  allow  class  please,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
2222,typeconversion  converter  attribut  class  please  change  converter  property  type  string  class  type  code  conversionconversions  typeconversiontype  conversiontypeclass  rule  conversionruleproperty  converter  comxxxmyconverter  key  mykey  code  code  conversionconversions  typeconversiontype  conversiontypeclass  rule  conversionruleproperty  converter  myconverterclass  key  mykey  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2223,duplicated  code  extract  uri  many  reference  exactly  code  extract  uri  request  defaultactionmapper  prepareoperations  method  moved  requestutils  used  place,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2224,componenttagsupport  use  tagutils  gain  access  container  instead  directly  calling  dispatchergetinstance  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2225,strut  fileupload  function  get  file  upload  process  data  use  orgapachestruts2dispatchermultipartjakartamultipartrequest  upload  file  struts2  add  orgapachecommonsfileuploadprogresslistener  monitor  file  upload  process,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2226,support  jdk  8  lambda  strut  stumble  encountering  lambda  expression  jdk  8  look  like  orgobjwectwebasm  dependency  need  updated  code  20140518  102141111  error  comopensymphonyxwork2utilfinderclassfinder38  unable  read  class  jdk8testactionslambda  javalangarrayindexoutofboundsexception  52264  orgobjectwebasmclassreaderreadclassunknown  source  orgobjectwebasmclassreaderacceptunknown  source  orgobjectwebasmclassreaderacceptunknown  source  comopensymphonyxwork2utilfinderclassfinderreadclassdefclassfinderjava717  comopensymphonyxwork2utilfinderclassfinderinitclassfinderjava112  orgapachestruts2conventionpackagebasedactionconfigbuilderfindactionspackagebasedactionconfigbuilderjava390  orgapachestruts2conventionpackagebasedactionconfigbuilderbuildactionconfigspackagebasedactionconfigbuilderjava347  orgapachestruts2conventionclasspathpackageproviderloadpackagesclasspathpackageproviderjava53  comopensymphonyxwork2configimpldefaultconfigurationreloadcontainerdefaultconfigurationjava268  comopensymphonyxwork2configconfigurationmanagergetconfigurationconfigurationmanagerjava67  orgapachestruts2dispatcherdispatcherinitpreloadconfigurationdispatcherjava445  orgapachestruts2dispatcherdispatcherinitdispatcherjava489  orgapachestruts2dispatchernginitoperationsinitdispatcherinitoperationsjava74  orgapachestruts2dispatcherngfilterstrutsprepareandexecutefilterinitstrutsprepareandexecutefilterjava57  orgapachecatalinacoreapplicationfilterconfiginitfilterapplicationfilterconfigjava281  orgapachecatalinacoreapplicationfilterconfiggetfilterapplicationfilterconfigjava262  orgapachecatalinacoreapplicationfilterconfiginitapplicationfilterconfigjava107  orgapachecatalinacorestandardcontextfilterstartstandardcontextjava4775  orgapachecatalinacorestandardcontextstartinternalstandardcontextjava5452  orgapachecatalinautillifecyclebasestartlifecyclebasejava150  orgapachecatalinacorecontainerbasestartchildcallcontainerbasejava1559  orgapachecatalinacorecontainerbasestartchildcallcontainerbasejava1549  javautilconcurrentfuturetaskrunfuturetaskjava266  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1142  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava617  javalangthreadrunthreadjava744  code  simple  test  case  attached  tar  xvf  jdk8testtar  cd  jdk8test  mvn  tomcat7run  httplocalhost8080jdk8test,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
2227,drop  deprecated  api  0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2228,support  latest  stable  angularjs  version  maven  angularjs  archetype  upgrade  maven  archetype  latest  stable  version  142  improve  example  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2229,add  dedicated  class  represent  http  parameter  right  parameter  represented  map  lot  logic  duplicated  way  check  given  parameter  already  evaluated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2230,conversionerrorinterceptor  extend  methodfilterinterceptor  would  possible  modify  conversionerrorinterceptor  extend  methodfilterinterceptor  exclude  validation  certain  method  ie  codexml  interceptorref  nameconversionerror  param  nameexcludemethodsexecutecancelparam  interceptorref  code  seems  always  called  need  like  validatorworkflow  noticed  conversion  error  screen  return  redirectaction  action  store  destination  action  retrieve  conversion  error  show  destination  action  screen  although  still  get  dev  mode  noformat  error  setting  expression  beanweight  value  gggg  noformat  come  params  interceptor  want  exclude  cancel  guess  live,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2231,merge  two  existing  i18ninterceptors  one  existing  i18ninterceptor  merged  one,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
2232,disallow  access  httpparameterstomap  httpparameterstomap  potentially  danger  allow  access  raw  parameter  value,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2233,stext  tag  evaluate  defaultmessage  valuestack  default  right  stext  tag  perform  evaluation  defaultmessage  valuestack  default  case  defaultmessage  set  value  name  attribute  easily  used  wrong  developer  evaluation  must  performed  purpose  change  affect  also  slabel  tag  label  attribute  uibeans,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2234,move  defaultclassfinder  convnention  plugin  java8  plugin  dropped  doesnt  make  sense  include  class  asm  jar  core  ww4570,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2235,httpparameters  behave  like  map  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2236,annotationworkflowinterceptor  support  nonpublic  annotated  method  codejava  protected  string  prepare  todo  return  null  code  httpsgithubcomapachestrutsblobmastercoresrcmainjavacomopensymphonyxwork2interceptorannotationsannotationworkflowinterceptorjaval115  codejava  listmethod  method  new  arraylistannotationutilsgetannotatedmethodsactiongetclass  beforeclass  code  httpsgithubcomapachestrutsblobmastercoresrcmainjavacomopensymphonyxwork2utilannotationutilsjaval123  codejava  method  clazzgetmethods  code  clazzgetmethods  return  public  method  method  prepare  excluded  protected  modifier  good  practice  intercept  methodwe  improve  annotationutilsgetannotatedmethods  return  method  perhaps  use  concurrenthashmap  cache  much  better,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2237,bufferflush  behaviour  freemarkerresult  scenario  application  use  freemarker  templateexceptionhandlerrethrowhandler  policy  occasionally  need  produce  large  xml  20200mb  go  memory  freemarkerresulthttpgrepcodecomfilerepo1mavenorgmaven2orgapachestrutsstruts2core25beta1orgapachestruts2viewsfreemarkerfreemarkerresultjava191  two  possible  behaviour  line  191  bufferbehaviour  whole  template  processed  everything  ok  flushed  output  otherwise  exception  thrown  handled  higher  level  output  sent  intended  used  templateexceptionhandlerrethrowhandler  active  flushbehaviour  template  processed  flushed  according  freemarker  library  policy  used  templateexceptionhandler  since  templateexceptionhandler  cannot  switched  given  request  global  configuration  embedded  freemarkermanager  way  force  flushbehaviour  force  bufferbehaviour  using  iswriteifcompleted  implemented  flexible  solution  let  force  behaviour  way  codetitlefreemarkerresultjavaborderstylesolid  final  boolean  willusebufferedwriter  usebufferedwriter  null  willusebufferedwriter  usebufferedwriter  else  willusebufferedwriter  configurationgettemplateexceptionhandler  templateexceptionhandlerrethrowhandler  willusebufferedwriter  else  code  usebufferedwriter  parameter  modified  per  request  code  result  typefreemarker  param  namelocationbigfeedftlparam  param  namecontenttypetextxmlparam  param  nameusebufferedwriterfalseparam  result  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2238,defaultlocalizedtextprovider  refactoring  defaultlocalizedtextprovider  bean  would  possible  refactor  code  allow  override  change  default  behavior  package  searching  resourceproperties  file  currently  extensive  search  class  interface  first  busy  screen  slows  thing  unnecessary  overhead  ie  migrated  struts1  main  ui  resource  default  applicationresourcesproperties  file  shared  across  strut  ui  class  various  package  would  want  duplicate  property  entry  maintenance  etc  would  want  search  default  applicationresourcesproperties  first  package  class  validation  message  possibly  interface  would  make  sense  use  logic  discussion  related  httpmarkmailorgmessagev2oc6c35swfwzwid,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2239,make  multipart  parser  extensible  0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
2240,add  proper  validation  request  multipart  request  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2241,stop  using  defaultlocalizedtextproviderlocalefromstring  static  util  method  method  replaced  localeutilstolocalestring  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2242,expose  freemarker  incompatibleimprovements  freemarkermanager  strutsbeanswrapper  latest  version  freemarker  236  support  use  default  method  interface  communicating  bean  freemarker  template  enable  required  allow  init  parameter  passed  servlet  configuration  freemarkermanager  beanswrapper  sitemesh  plugin  prevents  setting  parameter  doesnt  appear  pas  parameter  release  note  236  httpfreemarkerorgdocsversions2326html  documentation  incompatibleimprovements  httpfreemarkerorgdocspguiconfigincompatibleimprovementshtmlpguiconfigincompatibleimprovementshowtoset  documentation  defaultobejctwrapper  configuration  httpfreemarkerorgdocspguidatamodelobjectwrapperhtmltopicdefaultobjectwrapperici  constructor  defaultobjectwrapper  httpfreemarkerorgdocsapifreemarkertemplatedefaultobjectwrapperhtmldefaultobjectwrapperfreemarkertemplateversion  beanswrapper  httpfreemarkerorgdocsapifreemarkerextbeansbeanswrapperhtml  note  im  arguing  change  parameter  itd  nice  able  pas  initparam  configuration  freemarker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2243,fallback  actioncontext  container  null  actionsupport  right  action  extending  actionsupport  cannot  created  manually  requires  container  injected,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2244,asynchronous  action  method  user  able  return  javautilconcurrentcallablestring  action  strut  see  result  run  resultcode  resultcall  managed  thread  pool  exit  servlets  main  thread  null  result  ie  give  back  main  thread  container  leaf  response  open  concurrent  processing  resultcode  resultcall  returned  strut  call  javaxservletasynccontextdispatch  resume  request  processing  within  container  thread  servlet  generate  appropriate  result  user  according  resultcode  add  better  support  sl  short  request  processing  long  action  execution  short  response  processing  via  servlet  3  async  api  support  case  like  ssl  eg  download  server  llleg  video  converter  server  still  open,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
2245,review  available  interceptor  document  missing  one  eg  annotationparameterfilterinterceptor  annotation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2246,debug  tag  display  anything  dev  mode  noticed  debug  tag  display  content  value  stack  independently  value  devmode  wonder  would  secure  display  anything  devmodefalse  imagine  developer  forgetting  remove  kind  debug  tag  app  go  production  making  silent  production  mode  would  reduce  risk  display  sensitive  data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2247,refactor  configuration  class  configuration  class  see  comopensymphonywebworkconfigjava  poorly  designed  refactored  suggestion  1  xwork  class  use  seems  like  xwork  configs  flexible  enough  say  something  like  config  file  use  2  move  webworkconfigxmlactionconfiguration  comopensymphonywebworkconfigxmlactionconfiguration  use  xwork  xml  config  stuff  seems  like  taken  care  dont  know  class  webworkconfig  old  package  pretty  integral  everything  3  make  configuration  abstract  fold  defaultconfiguration  reason  impl  method  class  abstract  anyway  code  used  defaultconfiguration  easily  moved  configuration  4  remove  getstring  method  return  object  even  really  used  stipulate  property  string,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
2248,implement  new  aware  interface  using  withxxxx  pattern  instead  setter  matter  security  wonder  stop  using  setter  internal  api  like  sessionaware  interface  use  setsession  action  must  implement  method  logic  avoid  mapping  incoming  value  setsession  permit  injecting  value  session  instead  setsession  use  withsession  applysession  applied  aware  interface,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2249,enable  clientside  validation  visitor  validation  clientside  javascript  doesnt  work  advertised  httpwikiopensymphonycomdisplaywwclientsidevalidation  following  form  wwform  actionsaveuser  validatetrue  cssclassdetail  methodpost  generates  following  onsubmit  handler  onsubmitreturnparametersnamevalidate  following  javascript  form  script  typetextjavascript  function  parametersnamevalidate  var  form  documentformsparametersname  var  focus  parametersnamevalidateactual  focus  null  formelementsfocusfocus  formelementsfocustype  text  formelementsfocustype  textarea  formelementsfocusselect  return  false  else  return  true  function  parametersnamevalidateactual  var  form  documentformsparametersname  cannot  find  applicable  validators  return  null  script  add  nameuser  wwform  javascript  look  right  get  function  uservalidateactual  var  form  documentformsuser  cannot  find  applicable  validators  return  null  following  validatorsxml  validator  namerequiredstring  classcomopensymphonywebworkvalidatorsjavascriptrequiredstringvalidator  oddly  enough  xmlbuddy  eclipse  say  name  must  declared,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2250,add  hlog  number  metric  regionserver  add  hlog  number  metric  regionserver  use  metric  alert  memstore  flush  many  hlogs,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2251,stronger  validation  key  unwrapping  encryptionutilunwrapkey  use  crc32  validate  successful  unwrapping  data  key  chose  crc32  limit  overhead  1  232  chance  random  collision  low  enough  extremely  unlikely  however  talking  colleague  jerry  chen  today  cryptographic  hash  would  lower  probability  essentially  zero  wrapping  data  key  per  hcolumndescriptor  per  hfile  saving  byte  really  might  well  use  sha  data  key  addition  consider  running  aes  gcm  mode  cover  hash  additional  authenticated  data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2252,instead  putting  expired  store  file  thru  compaction  archive  hbase9648,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2253,improve  verifyreplication  compute  badrows  accurately  verifyreplicaiton  could  compare  source  table  peer  table  compute  badrows  however  current  badrows  computing  method  might  accurate  enough  example  source  table  contains  row  r1  r2  r3  r4  peer  table  contains  row  r1  r3  r4  badrows  3  r2  source  table  make  later  row  comparison  fail  better  badrows  computed  1  situation  maybe  compute  badrows  accurately  merge  comparison,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2254,region  balancing  bring  newly  added  node  within  acceptable  range  10  node  cluster  9  online  node  215  total  region  9  around  24  region  average  load  24  slop  10  22  26  acceptable  range  starting  10th  node  master  log  showed  code  20081121  155751521  info  orgapachehadoophbasemasterservermanager  received  start  message  723424921060020  20081121  155753351  debug  orgapachehadoophbasemasterregionmanager  server  723424921960020  overloaded  server  load  25  avg  220  slop  01  20081121  155753351  debug  orgapachehadoophbasemasterregionmanager  choosing  reassign  3  region  mostloadedregions  10  region  20081121  155753351  debug  orgapachehadoophbasemasterregionmanager  going  close  region  streamitemsahï¿½1225411051632  20081121  155753351  debug  orgapachehadoophbasemasterregionmanager  going  close  region  streamitemsï¿½ý1225411056686  20081121  155753351  debug  orgapachehadoophbasemasterregionmanager  going  close  region  groups1222913580957  20081121  155753975  debug  orgapachehadoophbasemasterregionmanager  server  723424921360020  overloaded  server  load  25  avg  220  slop  01  20081121  155753975  debug  orgapachehadoophbasemasterregionmanager  choosing  reassign  3  region  mostloadedregions  10  region  20081121  155753976  debug  orgapachehadoophbasemasterregionmanager  going  close  region  upgrade1226892014784  20081121  155753976  debug  orgapachehadoophbasemasterregionmanager  going  close  region  streamitems3zï¿½1225411056701  20081121  155753976  debug  orgapachehadoophbasemasterregionmanager  going  close  region  streamitems  l1225411049042  code  new  regionserver  received  6  region  happened  10th  came  average  load  dropped  22  caused  two  server  25  region  acceptable  avg  24  reassign  3  region  bring  back  average  unfortunately  region  remained  within  10  slop  20  24  overloaded  thus  reassign  region  chance  made  even  6  region  get  reassigned  could  exactly  24  server  case  none  would  assigned  new  node  behave  worse  larger  cluster  adding  new  node  little  impact  avg  loadserver,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2255,regionservers  report  detailed  health  master  master  flag  troubled  regionservers  ui  regionservers  report  detailed  health  master  master  flag  troubled  regionservers  ui  concern  moment  primarily  heap  regionservers  report  used  committed  max  heap  metric  periodic  report  master  flag  regionserver  list  masterjsp  regionservers  available  heap  configurable  threshold,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2256,regionserver  oome  handler  dump  vital  stats  oome  regionserver  dump  log  vital  stats  number  region  number  store  file  estimated  item  count  size  memcaches  estimated  item  count  size  store  file  index  assumes  reserve  released  upon  oome  allow  additional  action,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2257,port  make  flush  decision  per  column  family  trunk  currently  flush  decision  made  using  aggregate  size  column  family  large  small  column  family  coexist  cause  many  small  flush  smaller  cf  need  make  percf  flush  decision,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2258,add  read  log  size  per  second  metric  replication  source  current  metric  replication  source  contain  logeditsreadrate  shippedbatchesrate  etc  could  indicate  fast  data  replicated  peer  cluster  extent  however  clear  enough  know  many  byte  replicating  peer  cluster  metric  production  environment  may  important  know  size  replicating  data  per  second  service  may  affected  network  become  busy,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2259,improve  determinism  debugability  testaccesscontroller  separate  grant  revoke  api  invocation  static  helper  method  securetestutils  wait  permission  cache  update  using  predicate  log  api  call  state  check  wait,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0
2260,refactor  asyncprocess  asyncprocess  currently  two  pattern  usage  one  htable  flush  wo  callback  reuse  one  hcmhtable  batch  call  callback  wo  reuse  former  case  latter  also  throttling  action  initial  submit  call  limiting  number  outstanding  action  per  server  latter  case  relatively  straightforward  former  appears  error  prone  due  reuse  javadoc  claim  safe  multiple  submit  call  performed  without  waiting  async  part  previous  call  finish  field  like  haserror  become  ambiguous  used  wrong  call  callback  successfailure  called  based  original  index  action  submitted  list  one  callback  supplied  ap  ctor  clear  submit  call  index  belongs  several  outstanding  going  add  support  hbase10070  ap  found  might  difficult  cleanly  would  nice  normalize  ap  usage  pattern  particular  separate  global  part  load  tracking  persubmitcall  part  persubmit  part  conveniently  track  stuff  like  initialactions  mapping  index  retry  information  currently  passed  around  method  call  sure  yet  maybe  sending  original  index  server  clientprotosmultiaction  also  avoided  cannot  avoided  api  server  doesnt  onetoone  correspondence  request  response  individual  call  multi  retriesrearrangement  nothing,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,1
2261,auto  detect  data  block  encoding  hfileoutputformat  currently  one  specify  data  block  encoding  table  explicitly  using  config  parameter  hbasemapreducehfileoutputformatdatablockencoding  bulkload  load  option  easily  missed  documented  also  work  differently  compression  block  size  bloom  filter  type  auto  detected  solution  would  add  support  auto  detect  datablock  encoding  similar  parameter  current  patch  following  1  automatically  detects  datablock  encoding  hfileoutputformat  2  keep  legacy  option  manually  specifying  datablock  encoding  around  method  override  auto  detection  3  move  string  conf  parsing  start  program  fails  fast  starting  instead  failing  record  writes  also  make  internals  program  type  safe  4  add  missing  doc  string  unit  test  code  serializing  deserializing  config  paramerters  bloom  filer  type  block  size  datablock  encoding,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2262,refactor  deferredlogflushdurability  related  interfacecodenaming  align  changed  semantic  new  write  thread  model  new  write  thread  model  introduced  hbase8755httpsissuesapacheorgjirabrowsehbase8755  deferredlogflushdurability  apicodenames  change  accordingly  1  timertriggered  deferredlogflush  since  flush  always  done  async  thread  configuration  hbaseregionserveroptionallogflushinterval  longer  needed  2  async  writersyncernotifier  thread  always  triggered  implicitly  semantic  always  hold  hbaseregionserveroptionallogflushinterval  0  deferredlogsyncdisabled  hregionjava  affect  durability  behavior  always  false  3  htabledescriptorisdeferredlogflush  really  mean  write  return  without  waiting  sync  done  interface  name  changed  isasynclogflushsetasynclogflush  reflect  real  meaning,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2263,regionserver  graceful  stop  decommissioning  right  weird  way  node  decommissioning  graceful  stop  gracefulstopsh  bash  script  regionmover  ruby  script  draining  server  support  manually  write  znode  really  also  draining  server  partially  supported  lb  operation  lb  take  account  roundrobin  assignment  normal  balance  see  httphbaseapacheorgbooknodemanagementhtml  hbase3071  think  support  graceful  stop  first  class  citizen  thinking  seems  difference  regionserver  stop  graceful  stop  regionserver  stop  close  region  master  assign  znode  deleted  new  master  design  even  allow  r  able  close  region  without  master  initiating  graceful  stop  becomes  regular  stop  r  already  close  region  cleanly  reject  new  region  assignment  dont  need  much  balancer  draining  server  trickery  tie  new  masteram  redesign  hbase5487  still  deserves  jira  let  use  brainstorm  design,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2264,improvement  import  flow  following  improvement  made  import  logic  make  import  extensible  ie  remove  filter  static  member  import  make  instance  variable  mapper  make  mapper  variable  interest  protected  b  make  sure  import  call  filterrowkey  method  filter  useful  want  filter  data  organization  based  row  key  using  filter  like  prefixfilter  filter  data  filterrowkey  method  rather  filterkeyvalue  method  existing  test  case  testimportexporttestwithfilter  work  assumption  far  successful  one  row  inserted  table  c  provide  option  specify  durability  import  specifying  durability  skipwal  would  improve  performance  restore  considerably  lhofhansl  suggested  parameter  import  minor  refactoring  avoid  building  comma  separated  string  filter  args,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2265,clean  hregionlocationservername  usage  noticed  asyncprocess  update  cache  location  failure  using  single  hrl  object  key  map  intended  server  contains  request  multiple  region  ie  multiaction  contains  request  region  b  c  sits  map  hrl  hrl  server  key  case  failure  eg  request  b  entire  multiaction  location  map  key  passed  updatecache  method  even  though  correct  region  may  cause  subtle  mistake  cache  update  think  itd  good  clean  hrl  usage  around  ap  class  intend  server  name  use  servername  hrl,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2266,hconnection  interface  public  used  internally  contains  bunch  method  hconnection  many  method  public  interface  public  used  extensively  internal  purpose  keep  adding  method  may  make  sense  public  interface  idea  create  separate  internal  interface  inheriting  hconnection  copy  method  deprecate  hconnection  new  method  internal  use  would  added  new  interface  deprecated  method  would  eventually  removed  public  interface,1,1,1,1,1,0,0,0,1,1,1,0,0,0,0,0,0
2267,per  cell  ttls  cell  tag  optionally  store  ttls  per  cell,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2268,refactor  performanceevaluation  tool  perfeval  kind  mess  painful  add  new  feature  test  option  itemized  passed  parameter  internal  method  serialization  handrolled  tedious  ensuring  support  mapreduce  mode  chore  patch  refactors  tool  option  passed  around  method  pojo  instead  onebyone  get  rid  accessors  dont  help  anyone  mapreduce  side  serialization  handled  using  json  jackson  dependency  anyway  instead  handrolled  regex  used  also  away  custom  inputsplit  fileformat  instead  using  text  nlineinputformat  local  mode  side  combine  1  client  n  client  implementation  implementation  us  executorservice  later  decouple  number  client  worker  number  client  task  finally  drop  bunch  confusing  local  state  instead  use  new  testoptions  pojo  parameter  static  method,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1
2269,hbase  rest  xmljson  improvement  ive  begun  work  creating  rest  based  interface  hbase  use  json  xml  would  extensible  enough  add  new  format  road  im  point  would  like  submit  review  get  feedback  continue  work  towards  new  feature  attached  issue  find  patch  change  point  along  necessary  jar  file  json  serialization  also  find  note  use  finished  interface  point  patch  based  jira  issue  hbase814  hbase815  interested  gaining  feedback  guy  think  work  doesnt  work  project  anything  may  need  added  code  style  anything  else  finished  component  framework  around  parsing  jsonxml  input  framework  around  serialzing  xmljson  output  change  exception  handing  change  response  object  better  handle  serializing  output  data  table  crud  call  full  table  fetching  creatingfetching  scanner  todo  fix  filtering  scanner  row  insertdelete  operation  individual  row  fetching  cell  fetching  interface  scanner  use  interface  wikiish  note  done  point  rest  service  hbase  note  get  retrieves  list  table  meta  data  hbase  curl  v  h  accept  textxml  x  get  httplocalhost60050  curl  v  h  accept  applicationjson  x  get  httplocalhost60050  post  create  table  curl  h  contenttype  textxml  h  accept  textxml  v  x  post  httplocalhost60050newtable  table  nametest14name  columnfamilies  columnfamily  namesubscriptionname  maxversions2maxversions  compressionnonecompression  inmemoryfalseinmemory  blockcachetrueblockcache  columnfamily  columnfamilies  table  response  statuscode200codemessagesuccessmessagestatus  json  curl  h  contenttype  applicationjson  h  accept  applicationjson  v  x  post  httplocalhost60050newtable  nametest5  columnfamilies  namecolumnfam1  bloomfiltertrue  timetolive10  inmemoryfalse  maxversions2  compression  maxvaluelength50  blockcacheenabledtrue  note  enum  defined  class  hcolumndescriptorcompressiontype  get  tablename  return  record  table  curl  v  h  accept  textxml  x  get  httplocalhost60050tablename  curl  v  h  accept  applicationjson  x  get  httplocalhost60050tablename  get  tablename  parameter  action  metadata  return  metadata  table  region  return  region  table  curl  v  h  accept  textxml  x  get  httplocalhost60050pricing1actionmetadata  update  table  put  tablename  update  table  curl  v  h  contenttype  textxml  h  accept  textxml  x  put  httplocalhost60050pricing1  columnfamilies  columnfamily  namesubscriptionname  maxversions3maxversions  compressionnonecompression  inmemoryfalseinmemory  blockcachetrueblockcache  columnfamily  columnfamily  namesubscription1name  maxversions3maxversions  compressionnonecompression  inmemoryfalseinmemory  blockcachetrueblockcache  columnfamily  columnfamilies  curl  v  h  contenttype  applicationjson  h  accept  applicationjson  x  put  httplocalhost60050pricing1  columnfamilies  namecolumnfam1  bloomfiltertrue  timetolive10  inmemoryfalse  maxversions2  compression  maxvaluelength50  blockcacheenabledtrue  namecolumnfam2  bloomfiltertrue  timetolive10  inmemoryfalse  maxversions2  compression  maxvaluelength50  blockcacheenabledtrue  delete  table  curl  v  h  contenttype  textxml  h  accept  textxml  x  delete  httplocalhost60050test16  creating  scanner  curl  v  h  contenttype  applicationjson  h  accept  applicationjson  x  post  httplocalhost60050test16actionnewscanner  todo  fix  scanner  filter  response  xml  scanner  id  2  id  scanner  json  id1  using  scanner  curl  v  h  contenttype  applicationjson  h  accept  applicationjson  x  post  httplocalhost60050test16actionscanscanneridscanneridnumrowsnum  row  return  would  first  submission  open  source  project  size  please  give  rough  thanks,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,0
2270,master  support  closeopenreassignmentenabledisable  operation  individual  region  master  support  closeopenreassignmentenabledisable  operation  individual  region  way  client  api  corresponding  shell  command  maybe  also  control  master  ui  one  region  1000  closed  offline  example  due  transient  dfs  problem  currently  whole  table  must  disabled  reenabled  trigger  reassignment  hopefully  successful  reopen  offline  region  flurry  compaction  cause  exacerbate  underlying  problem  actually  make  cluster  state  worse  dfs  error  accumulate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2271,administrative  function  tableregion  maintenance  would  useful  administrative  function  available  htable  hbaseadmin  two  function  im  thinking  right  force  memcache  flush  region  individually  specified  run  major  compaction  region  individually  specified  one  reason  currently  major  compaction  run  day  default  time  run  related  brought  cluster  created  table  case  peak  load  rather  offpeak  time  time  run  administrative  task  like  backup  cleanup  etc  time  would  good  time  also  trigger  major  compaction  memcache  flush  memcache  force  flushing  also  useful  case  cluster  start  issue  might  isolated  single  region  regionserver  lot  edits  sitting  memcache  potentially  unappended  hlogs  want  flush  thing  remove  possibility  losing  anything,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2272,dbe  encode  path  improvement  1st  write  kv  cell  buffer  passed  dbe  encoder  encoder  read  kv  one  one  buffer  encodes  creates  new  buffer  need  model  previously  option  encode  disk  encode  cache  time  read  buffer  hfile  block  passed  encodes  encode  cell  cell  done  making  change  need  u  noop  dbe  impl  write  cell  encoding,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2273,extend  byterange  create  mutable  immutable  byterange  would  need  apis  would  setlimitint  limit  getlimt  asreadonly  apis  would  help  implementation  buffer  offheap  br  backed  dbb  anything  needed  could  added  needed,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0
2274,control  number  region  assigned  backup  master  default  backup  master  treated  like  another  regionserver  host  many  region  regionserver  backup  master  becomes  active  one  region  balancer  need  move  user  region  master  region  server  minimize  impact  better  assign  many  region  backup  master  may  good  leave  backup  master  idle  host  region  either  make  adjustable  user  control  many  region  assign  backup  master,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
2275,support  visibility  expression  deletes  accumulo  specify  visibility  expression  delete  marker  compaction  cell  covered  tombstone  determined  part  matching  visibility  expression  useful  use  case  data  set  coalescing  entry  multiple  data  set  carrying  different  label  combined  one  common  large  table  later  subset  entry  conveniently  removed  using  visibility  expression  currently  hbase  would  possible  custom  coprocessor  otherwise  delete  affect  cell  covered  tombstone  regardless  visibility  expression  scoping  correct  behavior  data  spill  possible  certainly  could  surprising  meant  transitional  decided  support  visibility  expression  deletes  control  complexity  initial  implementation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2276,use  global  procedure  flush  table  memstore  cache  currently  user  trigger  table  flush  hbase  shell  hbaseadmin  api  flush  table  cache  region  server  hosting  region  contacted  flushed  sequentially  le  efficient  hbase  snapshot  global  procedure  used  coordinate  flush  region  distributed  way  let  provide  distributed  table  flush  general  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2277,provide  admin  interface  abstract  hbaseadmin  hbaseadmin  essentially  administrative  api  would  seem  follow  java  best  practice  provide  interface  access  instead  requiring  application  use  raw  object  proposing  would  happy  develop  new  interface  hbaseadmininterface  capture  signature  api  hbaseadmin  implement  interface  new  method  hconnectiongethbaseadmin  return  instance  interface,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
2278,rest  let  user  turn  block  caching  desired  hbase10884  rest  gateway  use  scanner  default  respect  block  caching  add  support  query  parameter  hinting  block  query  cached  enable  block  caching  default,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
2279,extend  trace  fshlogsync  change  introduced  hbase8755  decouple  wal  append  wal  sync  gap  left  tracing  request  believe  mean  span  decoupled  work  happening  hdfs5274  ticket  close  airgap  thread,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
2280,clone  snapshot  secure  cluster  provide  option  apply  retained  user  permission  currently  code  sudo  su  testuser  create  t1  f1  sudo  su  hbase  snapshot  t1  snapone  clonesnapshot  snapone  t2  code  scenario  user  testuser  would  permission  clone  table  t2  need  add  improvement  feature  permission  original  table  recorded  snapshot  metadata  option  provided  applying  new  table  part  clone  process,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2281,remove  timeoutmontior  hbase8002  timeoutmonitor  disabled  default  lately  havent  see  much  problem  region  assignment  integration  testing  cm  thinking  may  time  remove  timeout  monitor,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2282,support  setting  custom  priority  per  client  rpc  server  ability  handle  custom  rpc  priority  level  currently  using  differentiate  metaroot  update  replication  priority  update  specified  annotation  tag  per  r  method  however  client  need  ability  create  custom  handler  eg  phoenix938  really  cleanly  tied  together  request  request  priority  disconnect  way  client  overwrite  priority  per  table  payloadcarryingrpccontroller  always  set  priority  per  rootmeta  otherwise  use  generic  priority,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2283,remove  duplicated  code  hcm  add  javadoc  regionstate  etc  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2284,add  regionobserver  pre  hook  operate  row  lock  coprocessor  hook  placed  outside  row  lock  meant  sidestep  performance  issue  arising  significant  work  done  within  hook  invocation  however  security  code  increase  sophistication  running  concurrency  issue  trying  use  result  early  decision  since  initial  introduction  coprocessor  upcalls  significant  refactoring  done  around  concurrency  control  core  become  complex  potentially  issue  many  coprocessor  user  either  move  existing  regionobserver  pre  hook  execute  row  lock  introduce  new  set  regionobserver  pre  hook  execute  row  lock  named  indicate  second  option  le  likely  lead  surprise  regionobserver  hook  javadoc  updated  advice  coprocessor  implementor  take  row  lock  hook  current  thread  happens  already  row  lock  try  take  lock  another  row  deadlock  risk  always  drawback  adding  hook  potential  performance  impact  benchmark  impact  decide  second  option  viable  choice  first  option  required  finally  introduce  higher  level  interface  managing  registration  user  code  execution  low  level  hook  filed  hbase11125  discus,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2285,add  mapredtablesnapshotinputformat  feature  parity  mapreduce  mapred  implementation  important  hive,1,1,1,0,1,1,0,0,1,0,1,0,0,0,0,0,0
2286,potentially  improve  block  locality  major  compaction  old  region  might  specific  use  case  region  longer  written  due  key  region  1  store  file  old  havent  written  still  use  region  read  locality  would  nice  propose  putting  configuration  option  something  like  hbasehstoreminlocalitytoskipmajorcompact  0  1  decide  whether  skip  major  compaction  old  region  single  store  file  ill  attach  patch  let  know  guy  think,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2287,enable  hbaseadminexecprocedure  return  data  procedure  execution  hbase11201  enables  global  procedure  member  return  data  procedure  master  hbase9426  let  user  invoke  procedure  client  via  hbaseadminexecprocedure  jira  fill  gap  enable  client  get  return  data  master  procedure  execution,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2288,blockcache  lazy  block  decompression  maintaining  data  compressed  form  block  cache  greatly  increase  effective  blockcache  size  show  meaning  improvement  cache  hit  rate  well  designed  application  idea  lazily  decompressdecrypt  block  theyre  consumed  rather  soon  theyre  pulled  disk  related  le  invasive  hbase8894,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2289,thrift  support  authenticationimpersonation  thrift  server  access  hbase  fixed  authenticated  user  however  dont  authenticate  thrift  client  great  thrift  server  authenticate  client  support  impersonation,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,0
2290,pe  allow  random  value  size  allow  pe  write  random  value  size  helpful  mimicing  real  sizing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2291,couple  callqueue  related  improvement  one  inmemory  read  testing100  get  request  one  top  scalibility  bottleneck  came  single  callqueue  tentative  sharing  callqueue  according  rpc  handler  number  showed  big  throughput  improvementthe  original  get  qps  around  60k  one  hotspot  tunning  got  220k  get  qps  single  region  server  ycsb  read  scenario  another  stuff  seperating  queue  read  call  queue  write  call  queue  done  internal  branch  would  helpful  outage  avoid  read  write  request  ran  handler  thread  one  stuff  changing  current  blocking  behevior  callqueue  full  considering  full  callqueue  almost  mean  backend  processing  slow  somehow  failfast  reasonable  using  hbase  low  latency  processing  system  see  callqueueputcall,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2292,reduce  frequency  rng  call  securewalcellcodecencryptedkvencoder  reducing  frequency  rng  call  securewalcellcodecencryptedkvencoder  save  37  cpu  time  method  3  total  cpu  time  ingest  test  wal  processing  critical  latency  sensitive  area,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2293,improve  file  size  info  snapshotinfo  tool  add  sizeinbytes  flag  print  file  size  byte  instead  human  readable  format  add  check  file  length  manifest  hfile  marking  corrupted  file  length  dont  match  noformat  snapshot  file  4839b  testtba81219be11ade1d0d2913267caeeb3fecfbec5567b2cb04cd1a76c2f4106991de7  testtbf2622221b913c44a61a03550cb74e3a1cf8b02813a4f564957bd820c88fccf376a  found  4967b  testtb0cab854a3877697e726a73187fe21643cf7afb8fe1e2f141eb9b8e17d1f68cd576  archive  12b  testtb35074c28fd4dc304930f261fa8e0ce9ccffedd9b9044b74768a6631003695c2f32  corrupted  4839b  testtbbb2ac9c8efc5ac9077084268c60dd8dacf50a3144088b049d98007af331821abd7  4839b  testtbcda2a3ea0f5630d19018916cbe73264ecfda0a1008656c403cb17f37a061d04120  4905b  testtb5b6e6b804e075778185e2fb1a27bae90cf1177a58d798a46ec952a0bc19f902711  archive  bad  snapshot  1  hfiles  0  log  missing  1  hfiles  corrupted  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2294,metatableaccessor  shouldnt  use  zookeeeper  committing  patch  hbase4495  there  improvement  made  discussed  originally  review  board  jira  metatableaccessor  metatablelocator  class  first  one  used  access  information  stored  hbasemeta  table  second  one  used  deal  zookeeper  state  find  region  server  hosting  hbasemeta  wait  become  available  metatableaccessor  turn  operate  meta  table  content  shouldnt  need  zk  reason  metatableaccessor  using  zk  caller  request  assignment  information  request  location  meta  table  cant  read  meta  case  metatableaccessor  relay  call  metatablelocator  may  solution  declare  client  metatableaccessor  shall  use  work  meta  table  content,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2295,combine  singlemultiple  queue  rpcexecutor  single  class  little  odd  use  multiple  class  leading  mutliple  ifelse  condition  rpc  execution  could  combine  one  make  logic  also  put  code  one  place,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2296,pe  add  cycling  test  n  time  unit  test  sizezipfvaluesize  calculation  small  pe  diff  add  cycle  argument  small  test  run  long  time  keyset,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2297,abstract  visibility  label  related  service  interface  storage  retrieval  label  dictionary  authentication  set  marshalling  unmarshalling  visibility  expression  representation  operation  attribute  cell  tag  management  assignment  authorization  principal  allow  u  introduce  additional  serde  implementation  visibility  expression  example  storing  string  place  compressedtokenized  representation  others  order  support  additional  use  case,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,1,1
2298,refactoring  configuration  change  enabling  visibilitylabels  unit  test  unit  test  contain  code  enabling  visibility  change  incorporating  future  configuration  change  visibility  label  configuration  made  easier  refactoring  single  place,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2299,clean  zkbased  region  assignment  clean  zkbased  region  assignment  code  use  zkless  one  master  branch  make  code  easier  understand  maintain,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2300,put  htable  region  method  interface  htable  method  abstracted  htableinterface  notable  exception  following  method  pertain  region  metadata  code  hregionlocation  getregionlocationfinal  string  row  hregionlocation  getregionlocationfinal  byte  row  hregionlocation  getregionlocationfinal  byte  row  boolean  reload  byte  getstartkeys  byte  getendkeys  pairbytebyte  getstartendkeys  void  clearregioncache  code  default  scope  method  maybe  bundled  others  code  listregionlocations  listregionlocations  code  since  consensus  seems  would  muddy  htableinterface  noncore  functionality  go  mapreduce  look  region  boundary  need  exposed  somewhere  let  throw  straw  man  start  conversation  propose  code  orgapachehadoophbaseclienthregioninterface  code  htable  implement  interface  also  add  method  hconnection  code  hregioninterface  gettableregiontablename  tablename  hregioninterface  gettableregiontablename  tablename  executorservice  pool  code  stack  ndimiduk  enis  thought,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
2301,add  rwqueuerpcexecutor  ability  split  get  scan  handler  rwqueuerpcexecutor  devision  read  writes  request  split  also  smallreads  longreads  useful  force  deprioritization  scan  r,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2302,provide  common  base  abstract  class  regionobserver  masterobserver  security  coprocessors  extend  regionobserver  masterobserver  unfortunately  one  two  use  available  base  abstract  class  implementation  provide  common  base  abstract  class  regionobserver  masterobserver  interface  update  current  coprocessors  extend  interface  use  new  common  base  abstract  class,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
2303,tighten  region  state  transition  regionserver  report  master  region  transition  check  current  region  state  exactly  expect,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2304,find  way  set  sequenceid  cell  server  hbase11591  need  set  sequenceid  hfile  bulk  loaded  kv  since  trying  use  concept  cell  read  path  need  use  setsequenceid  cell  converted  kv  keyvalue  impl  accessor  setsequenceid  anoophbase  suggested  use  server  side  impl  cell  accessors  jira  aim  solve  see  related  code  change  need  carried,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,1
2305,keyvalue  cell  convert  waledit  apis  almost  main  interface  classapis  changed  keyvalue  cell  missing  waledit  public  marked  replication  well  cp  also  2  apis  deal  kv  addkeyvalue  kv  arraylistkeyvalue  getkeyvalues  suggest  deprecate  add  098  addcell  kv  listcell  getcells  replace  10,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2306,importtsv  abstract  label  tag  creation  pluggable  interface  hbase11553  abstracted  visibilitylabelservice  using  one  go  string  based  label  tag  instead  default  ordinal  based  mapreduce  side  importtsv  also  support  abstraction  layer  applicable  hfileoutputformat  mapper  create  cell  written  hfiles  also  every  mapper  custom  written  also  dealing  low  level  hbase  thing  creation  tag  cell  good  idea  issue  plan  provide  public  audience  facade  class  facilitate  cell  creation  mapper  make  use,1,1,1,1,1,0,0,0,1,0,1,0,0,0,0,0,1
2307,create  connection  connectionmanager  cleanup  hbase  interface  10  implementing  new  table  admin  interface  following  eniss  guideline  hbase10602  jira  generate  new  connectionmanager  replace  hcm  connection  replace  hconnection  detail  jira  intends  implement  portion  code  interface  connection  extends  closeable  table  gettable  rest  hconnection  method  getadmin  deprecated  method  cache  related  etc  deprecated  interface  hconnection  extends  connection  deprecated  htableinterface  gettable  user  encouraged  use  connection  class  connectionmanager  createconnectionconfiguration  sure  whether  want  static  factory  method  create  connection  ctor  deprecated  class  hcm  extends  connectionmanager  user  encouraged  use  connectionmanager  code,1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0
2308,split  tableorregionname  admin  method  two  targetted  method  purpose  two  implement  eniss  suggestion  strongly  type  method  take  tableorregionname  argument  instance  code  void  compactfinal  string  tablenameorregionname  void  compactfinal  byte  tablenameorregionname  code  becomes  code  deprecated  void  compactfinal  string  tablenameorregionname  deprecated  void  compactfinal  byte  tablenameorregionname  void  compacttablename  table  void  compactregionfinal  byte  regionname  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2309,hfile  tool  implement  tool  disable  blockcache  default  tried  using  binhbase  hfile  memoryconstrained  environment  crashed  trying  instantiate  blockcache  went  override  configuration  found  couldnt  refactor  hfile  remove  main  put  implementation  entirely  hfileprettyprinter  said  class  extends  configured  implement  tool  configs  overridden  cli  also  disabled  blockcache  default,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2310,get  rid  writables  htabledescriptor  hcolumndescriptor  currently  protobuf  encoding  structure  existence  writable  misleading  need  removed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2311,changing  map  type  used  internally  hbasemapwritable  cellcache  need  hbasemapwritable  different  kind  map  used  internally  showed  problem  instantiation  map  done  static  control  extending  hmw  get  memory  usage  parent  well  child  trying  different  idea  solve  seems  like  easiest  way  would  setmaptype  method  set  null  code  old  code  would  kept  would  need  instantiate  2  different  map  problem  setting  null  old  code  need  changed  fit  new  model  also  used  future,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
2312,add  append  remove  peer  tablecfs  cmds  replication  hbase8751  introduces  tablestablecolumn  family  config  replication  peer  flexible  practical  replication  hbase  cluster  easy  make  mistake  add  remove  tabletablecolumn  family  existing  peer  especially  tablecfs  long  need  copy  current  tablecfs  peer  first  add  remove  tabletablecolumn  family  tofrom  tablecfs  last  set  back  tablecfs  using  cmd  setpeertablecfs  implement  two  new  cmds  appendpeertablecfs  removepeertablecfs  operation  adding  removing  tabletablecolumn  family  useful  operation  tool,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2313,hbase  directory  exists  version  file  inexistent  still  proceed  bootstrapping  dev  list  suggested  change  way  manage  empty  hbase  directory  case  stack  answered  quote  yes  fact  probably  safetodo  weve  left  far  behind  prehistory  version  hbase  hbaseversion  file  hbaserootdir  absent  let  proceed  write  rather  treat  nonmigrated  instance  quote,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2314,make  setting  start  stop  row  specific  prefix  easier  want  set  scan  application  scan  specific  row  prefix  actually  quite  hard  described  several  place  set  startrow  prefix  yet  stoprow  set  prefix  1  prefix  ascii  put  byte  easy  simply  increment  last  byte  array  application  us  real  binary  rowids  may  run  scenario  prefix  something  like  code  0x12  0x23  0xff  0xff  code  increment  code  0x12  0x24  code  prepared  proposed  patch  make  setting  value  correctly  lot  easier,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0
2315,keep  table  state  meta  hbase7767  moved  table  enableddisabled  state  kept  hdfs  instead  zookeeper  istabledisabled  used  hconnectionimplementationrelocateregion  became  master  rpc  call  rather  zookeeper  client  call  since  relocateregion  call  everytime  want  relocate  region  region  moved  r  etc  implies  master  client  uncached  region  affected  see  hbase7767  hbase11974  background,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2316,regionservers  find  new  master  new  master  come  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2317,byte  unsafe  faster  additional  optimization  orgapachehadoophbaseutilbytes  new  version  compareto  method  new  version  primitive  converter  putxxxtoxxx,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2318,move  core  connection  creation  functionality  connectionfactory  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2319,change  hbase  storekey  format  hbase859  cleaned  key  removing  need  hregioninfo  context  comparing  key  issue  changing  format  work  done  hbase859  mean  change  localized  hstorekey  particular  comparators  parse  routine  since  0200  require  rewriting  data  thing  consider  row  columnfamily  columnqualifier  timestamp  keytype  leave  columnfamily  altogether  write  hfile  metadata  key  compare  done  store  context  columnfamily  safely  left  equation  key  rise  store  columnfamily  need  appending  keytype  probably  byte  type  delete  cell  delete  row  delete  family  delete  column  else  put  end  type  sort  part  sort  order  encounter  key  going  support  key  go  chronological  order,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
2320,provide  command  list  visibility  label  command  list  visibility  label  place  would  handy  also  line  many  hbase  list  command,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2321,wal  accounting  store  hbase10201  made  flush  decision  per  store  done  enough  work  hlog  two  problem  1  record  minseqid  hregion  fshlog  duplication  2  maybe  hole  wal  accounting  example  assume  family  sequence  id  1  3  family  b  seqid  2  flush  family  record  wal  sequence  id  1  removed  safely  replay  point  sequence  id  3  also  replayed  unnecessary,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0,0
2322,zookeeperwrapper  constant  cleanup  lot  zookeeper  constant  hconstants  used  one  place  remove  directly  put,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2323,use  threadlocalrandom  randomqueuebalancer  look  like  random  randomqueuebalancer  main  cause  contention  rpc  queue  insertion  replace  random  threadlocalrandom,1,0,0,0,0,0,0,0,1,1,0,1,1,0,0,0,0
2324,add  rpcclient  interface  enable  changing  rpcclient  implementation  currently  hconnectionimplementation  work  included  rpcclient  direct  implementation  defined  interface  would  great  able  swap  default  rpcclient  another  implementation  also  controlled  default  hconnectionimplementation  suggested  change  create  rpcclient  interface  defines  way  hconnectionimplementation  interacts  rpc  client  like  getting  blocking  protobuf  service  interface  closing  client  define  rpcclient  implementation  construct  setting  configuration  variable  default  current  rpcclient  possibly  create  abstract  rpcclient  class  load  basic  rpc  layer  configuration  used  implementation  enables  experimentation  rpcclients  could  enable  new  feature  could  performant  included  client  created  new  rpcclient  implementation  based  netty  also  called  asynchronously  would  great  also  able  use  rpcclient  default  way  test  see  issue  httpsgithubcomjurmousasynchbaseclient  httpsgithubcomjurmousasynchbaseclientblobmastersrcmainjavaorgapachehadoophbaseipcasyncrpcclientjava,0,0,0,0,0,0,0,0,1,1,1,0,0,1,1,0,0
2325,adapt  payloadcarryingrpccontroller  also  used  async  way  change  hbase12597  possible  create  new  rpc  client  place  blockingrpcchannel  called  payloadcarryingrpccontroller  controller  usable  async  context  method  supported  moment  see  timelimitedrpccontroller  method  throw  unsupportedoperationexception  issue  implementing  method  payloadcarryingrpccontroller  also  used  async  context  work  sync  context,1,0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0
2326,refactor  base  clustermanager  hbase  notion  sending  signal  situation  need  run  integration  test  system  using  ssh  command  move  sshsignal  related  part  clustermanager  make  part  implementation  detail  hbaseclustermanager,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
2327,add  new  asyncrpcclient  change  hbase12597  possible  add  new  rpcclients  issue  adding  new  async  rpcclient  would  enable  hbase  non  blocking  protobuf  service  communication  besides  delivering  new  asyncrpcclient  would  also  like  ask  question  would  take  replace  current  rpcclient  would  enable  simplify  async  code  next  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2328,support  multiple  port  number  zk  quorum  string  hbase  allow  zk  quorum  string  contain  port  number  format  noformat  hostname1port1hostname2port2hostname3port3  noformat  instead  expects  string  format  noformat  hostname1hostname2hostname3port3  noformat  port  3  used  client  port  flex  parsing  form  accepted  sample  exception  code  javaioioexception  cluster  key  passed  host12181host22181host32181host42181host521812181hbase  invalid  format  behbasezookeeperquorumhbasezookeeperclientportzookeeperznodeparent  orgapachehadoophbasezookeeperzkutiltransformclusterkeyzkutiljava403  orgapachehadoophbasezookeeperzkutilapplyclusterkeytoconfzkutiljava386  orgapachehadoophbasereplicationreplicationpeerszkimplgetpeerconfreplicationpeerszkimpljava304  orgapachehadoophbasereplicationreplicationpeerszkimplcreatepeerreplicationpeerszkimpljava435  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2329,heap  occupancy  based  client  pushback  heap  occupancy  regionserver  beyond  configurable  high  water  mark  suggestion  95  98  reject  user  rpcs  allow  administrative  rpcs  occupancy  dropped  configurable  low  water  mark  suggestion  92  implement  building  hbase5162  change  might  expensive  check  heap  occupancy  case  sample  periodically  chore  use  last  known  value  pushback  calculation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2330,let  metascanner  recycle  given  connection  heavy  create  connection  meta  scan  connection  create  rpcclients  rpcclients  create  rpc  connection  cannot  recycled  test  lot  metascans  heavy  async  client  issue  make  anything  us  metascans  reuse  connection,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2331,visibility  label  support  visibility  label  user  group  thinking  support  visibility  label  associated  user  group  able  grant  visibility  label  group  addition  individual  user  provides  convenience  usability  use  group  denote  group  name  similarly  done  acccesscontroller  example  code  setauths  group1  secretprivate  code  code  getauth  group1  code  user  belonging  group1  visibility  label  granted  group1  well  also  support  super  user  group  specified  hbasesitexml  code  update  mainly  server  side  visibilitylabelservice  implementation,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
2332,replication  fails  delete  corresponding  zk  node  peer  removed  removing  peer  client  side  delete  peerid  peersznode  node  alive  region  server  notified  delete  corresponding  hlog  queue  rsznode  replication  however  failed  server  whose  hlog  queue  transferred  alive  serversthis  likely  happens  setting  big  value  replicationsleepbeforefailover  lot  region  server  restarted  hlog  queue  wont  deleted  peer  removed  think  removepeer  guarantee  corresponding  zk  node  removed  completes  otherwise  create  new  peer  peerid  removed  one  might  unexpected  data  replicated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2333,dont  transfer  queued  hlogs  dead  server  alive  server  region  server  downor  cluster  restart  hlog  queue  transferred  alive  region  server  shared  cluster  might  create  several  peer  replicating  data  different  peer  cluster  might  lot  hlogs  queued  peer  caused  several  reason  peer  might  disabled  error  peer  cluster  might  prevent  replication  replication  source  may  fail  read  hlog  hdfs  problem  server  restarted  another  alive  server  take  replication  job  dead  server  might  bring  big  pressure  resourcesnetworkdisk  read  alive  server  also  fast  enough  replicate  queued  hlogs  alive  server  replication  job  including  take  dead  server  totally  transferred  another  alive  server  might  cause  server  large  number  queued  hlogsin  shared  cluster  find  one  server  might  thousand  queued  hlogs  replication  optional  way  reasonable  alive  server  transfer  one  peer  hlogs  dead  server  one  time  alive  region  server  might  opportunity  transfer  hlogs  rest  peer  may  also  help  queued  hlogs  processed  fast  discussion  welcome,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2334,thrift  support  nextnbrow  like  functionality  currently  java  hbase  api  support  calling  nextnumberofrows  thrift  interface  doesnt  patch  get  working  internally,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2335,parallel  execution  hbck  checkregionconsistency  lot  region  cluster  500k  noticed  hbck  took  quite  time  checkandfixconsistency  davelatham  patched  cluster  check  parallel  speed  thing  ill  attach  patch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2336,upgrade  jetty  926  jetty  component  used  hbase  stargate  rest  endpoint  version  6126  fairly  outdated  recently  customer  inquire  enabling  crossorigin  resource  sharing  cors  rest  endpoint  found  older  version  include  necessary  filter  configuration  option  highlighted  httpwikieclipseorgjettyfeaturecrossoriginfilter  jetty  project  significant  update  version  7  8  9  including  transition  eclipse  subproject  updating  latest  version  may  nontrivial  last  update  jetty  component  httpsissuesapacheorgjirabrowsehbase3377  minor  version  update  require  significant  work  update  include  package  namespace  update  likely  larger  number  required  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2337,clientside  metric  there  little  visibility  hbase  client  folk  care  add  kind  metric  collection  end  wrapping  table  method  invocation  systemcurrenttimemillis  crude  example  look  performanceevaluation  exposing  request  latency  integrationtestregionreplicaperf  client  quite  complex  there  lot  going  hood  impossible  see  right  without  profiler  crucial  part  performance  distributed  system  deeper  visibility  client  function  im  sure  wiring  hadoop  metric  system  right  choice  client  often  embedded  library  user  application  integration  metric  tool  ie  client  embedded  coprocessor  report  metric  usual  r  channel  client  used  mr  job  would  propose  interfacebased  system  pluggable  implementation  box  wed  include  hadoopmetrics  implementation  one  possibly  dropwizardmetricshttpsgithubcomdropwizardmetrics  thought,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
2338,region  supportable  publicevolving  subset  hregion  hbase12566  lhofhansl  proposed  quote  maybe  region  interface  hregion  store  hstore  store  marked  interfaceaudienceprivate  used  coprocessor  hook  quote  example  coprocessors  reach  hregion  order  participate  row  region  locking  protocol  one  area  functionality  legitimate  coprocessors  user  inbetween  interface  make  sense  addition  promote  store  interface  audience  limitedprivatecoproc,1,1,1,1,1,0,1,0,0,1,0,0,0,0,0,1,1
2339,supportable  splittransaction  regionmergetransaction  interface  making  splittransaction  regionmergetransaction  limited  private  required  support  local  indexing  feature  phoenix  ensure  region  colocation  ensure  region  split  region  merge  coprocessors  method  call  without  touching  internals  like  creating  zks  file  layout  change  assignment  1  stepsbeforeponr  stepsafterponr  ensure  split  2  meta  entry  pas  coprocessors  atomically  update  normal  splitmerge  3  rollback  failure,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,1,0
2340,hbck  print  status  scanning  many  region  running  simple  command  like  hbck  summary  large  table  take  time  print  information  let  known  thing  progressing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2341,metascanner  replaced  metatableaccessor  metascanner  metatableaccessor  similar  thing  seems  tend  diverge  let  one  thing  enquiry  meta,1,0,1,0,1,0,1,1,0,0,1,0,0,0,0,0,1
2342,new  master  come  regionservers  continue  region  assignment  last  master  hbase1205  handle  master  going  coming  somewhere  else  happens  new  master  scan  everything  reassign  region  ideal  instead  keep  region  assignment  last  master,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2343,allow  turn  memstore  replication  region  replica  hbase11568  allows  use  replication  send  wal  edits  primary  replica  sometimes  memstore  replication  required  nice  flag  disable  result  le  phase1  rowlevel  consistency  provided  flush  edit  transfered  via  replication  refresh  hfiles  create  t1  f  regionreplication  2  regionmemstorereplication  false,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
2344,hbase  streaming  scan  feature  scan  operation  iterates  row  table  subrange  table  synchronous  nature  data  served  client  side  hinders  speed  application  traverse  data  increase  overall  processing  time  may  cause  great  variance  time  application  wait  next  piece  data  scanner  next  method  client  side  invokes  rpc  regionserver  store  result  cache  application  specify  many  row  transmitted  per  rpc  default  set  100  row  cache  considered  producerconsumer  queue  hbase  client  push  data  queue  application  consumes  currently  queue  synchronous  ie  blocking  specifically  application  consumed  data  cache  cache  empty  hbase  client  retrieves  additional  data  server  refill  cache  new  data  time  application  blocked  assumption  application  processing  time  balanced  time  take  retrieve  data  asynchronous  approach  reduce  time  application  waiting  data  attach  design  document  also  patch  based  private  branch  evaluation  result  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2345,progress  heartbeat  long  running  scanner  necessary  set  long  timeouts  client  issue  scan  large  region  data  region  might  filtered  depending  scan  criterion  usability  concern  hard  identify  worst  case  timeout  use  scan  occasionallyintermittently  failing  production  depending  variable  scan  criterion  would  better  clientserver  scan  protocol  send  back  periodic  progress  heartbeat  client  long  server  scanner  alive  making  progress  related  orthogonal  streaming  scan  hbase13071,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2346,pe  add  able  write  many  column  jonathanlawlor  need  able  test  wide  row  scanning  want  make  sure  nothing  broke  chunking  patch  come  want  get  coarse  perf  number,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2347,perf  reuse  ipcutilbuildcellblock  buffer  running  scan  profiling  flight  recorder  mildly  fingering  resize  buffer  allocated  ipcutilbuildcellblock  point  contention  halfhearted  blaming  hundred  m  five  minute  sampling  ten  instance  showing  tried  w  flamegraphlightweight  profiler  reported  buffer  allocation  taking  22  total  cpu  see  attachment  tracesvg  enabled  tracelevel  logging  orgapachehadoophbaseipcipcutil  indeed  every  allocation  resize  initial  allocation  16k  default  220k  test  return  ten  randomly  sized  row  zipfian  sized  0  8k  upping  allocation  220k  meant  avoided  resize  initial  allocation  blamed  10  allocation  see  trace2svg  attached  let  buffer  reuse  save  bunch  allocation  cpu,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2348,bulk  loaded  hfile  replication  currently  plan  use  hbase  replication  feature  deal  disaster  tolerance  scenariobut  encounter  issue  use  bulkload  frequentlybecause  bulkload  bypass  write  path  generate  wal  data  replicated  backup  cluster  inappropriate  bukload  twice  active  cluster  backup  cluster  advise  modification  bulkload  feature  enable  bukload  active  cluster  backup  cluster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2349,allow  block  cache  external  allow  external  service  provide  block  cache  nice  property  allowing  failoverupgrades  happen  without  causing  fully  cold  cache  additionally  allows  read  replica  share  memory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2350,revisit  security  auditing  semantics  specifically  following  thing  need  closer  look  include  based  feedback  andor  suggestion  table  name  say  test  instead  fully  qualified  table  namedefaulttest  used  right  using  scope  similar  argument  operation  would  better  decouple  argument  operation  scope  involved  checking  eg  say  createtable  following  audit  log  code  access  denied  user  esteban  reason  insufficient  permission  remote  address  1020301  request  createtable  context  usersrikanthxxx  scopedefault  actioncreate  code  scope  rightly  used  default  namespace  missing  information  like  operation  params  create  used  log  prior  hbase12511  would  love  hear  input,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2351,replace  explicit  hbaseadmin  creation  connectiongetadmin  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2352,add  debugwarn  fail  htd  check  even  tablesanitychecks  false  hbase10591  introduced  sanity  check  table  configuration  createtable  hmastersanitychecktabledescriptor  skip  check  hbasetablesanitychecks  true  debuggability  log  warn  tablesanitychecks  false  nice  check  like  family  maxfilesize  limit  flush  size  limit  compressionencryption  codec  available  ttl  block  size  help  debug  going,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2353,hbase  provide  inputformat  supporting  multiple  scan  mapreduce  job  snapshot  currently  hbase  support  pushing  multiple  scan  mapreduce  job  live  table  via  multitableinputformat  support  single  scan  mapreduce  job  table  snapshot  would  handy  support  multiple  scan  snapshot  well  probably  another  input  format  multitablesnapshotinputformat  mimic  functionality  present  multitableinputformat  new  input  format  would  likely  take  name  snapshot  used  addition  scan,1,1,1,0,1,1,0,0,1,1,1,0,0,0,0,0,0
2354,improvement  stochastic  load  balancer  two  thing  jira  try  address  1  locality  picker  stochastic  balancer  pick  region  least  locality  candidate  swapmove  user  configures  locality  cost  configs  balancer  always  seems  move  region  bad  locality  2  cluster  equal  number  loaded  region  always  pick  first  one  pick  random  region  one  equally  loaded  server  improves  chance  finding  good  candidate  load  picker  invoked  several  time,1,0,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0
2355,expand  testsizefailures  include  small  scan  jonathan  hbase13335  quote  may  also  good  idea  extend  testsizefailures  also  test  ensure  data  seen  scan  small  eg  perform  scan  near  end  configure  scansetsmalltrue  even  though  wouldnt  small  scan  would  test  make  sure  fix  behaves  expected  quote,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2356,remove  distributed  mode  minizookeeper  minizookeeper  currently  standalone  distributed  mode  hbase  testing  need  use  standalone  mode  remove  distributed  logic,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
2357,new  method  htablejava  return  start  end  key  region  table  writing  custom  tableinputformat  generate  split  within  region  need  start  end  key  region,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2358,move  thrift  020  move  hbase  thrift  bit  thrift  020  released,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2359,synctable  rsync  hbase  table  given  hbase  table  remote  cluster  similar  identical  data  efficiently  update  target  table  data  question  identical  source  table  efficiency  context  mean  using  far  le  network  traffic  would  required  ship  data  one  cluster  take  inspiration  rsync  design  doc  httpsdocsgooglecomdocumentd12c9kjewnrxf5v4qwbcoixfdchn7pxvxv1io6pw0u,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2360,performance  distributed  splitting  regionserver  commit  log  hbase1008  improvement  log  splitting  regionserver  crash  need  run  even  faster  hbase1008  bigtable  paper  split  distributed  going  1000  log  need  distribute  least  multithread  splitting  1  region  starting  expect  find  one  reconstruction  log  need  make  pick  bunch  edit  log  fine  log  elsewhere  hdfs  output  directory  written  split  participant  whether  multithreaded  mapreducelike  distributed  process  let  write  distributed  sort  first  mr  learn  whats  involved  distributed  sort  much  possible  use  mr  framework  piece  startup  region  go  directory  pick  file  written  split  participant  deleting  clearing  dir  read  making  take  multiple  log  input  also  make  split  process  robust  rather  current  tenuous  process  loses  edits  doesnt  make  end  without  error  2  column  family  rereads  reconstruction  log  find  edits  need  fix  split  sort  edits  column  family  store  read  edits,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2361,rename  column  method  masterobserver  columnfamily  interface  make  bit  harder  implementors  itd  easier  java8  default  implementation  could  either  add  new  columnfamily  method  deprecate  old  one  rename  existing  one  without  deprecation  first  implementors  would  need  change  code  case  basemasterobserver  basemasterandregionobserver  itd  make  thing  easier  people  using  class  go  option  1  thats  preference  plan  would  add  method  200  remove  old  one  300,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2362,add  regionlocator  method  thrift2  proxy  thrift2  doesnt  provide  functionality  java  client  getting  region  location  change,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2363,importtsv  add  dryrun  functionality  log  bad  row  importtsv  job  skip  bad  record  default  keep  count  though  dimporttsvskipbadlinesfalse  used  fail  bad  row  encountered  easily  able  determine  row  corrupted  input  rather  failing  one  row  time  seems  like  good  feature  moreover  dryrun  functionality  kind  tool  essentially  quick  run  tool  without  making  change  reporting  errorswarnings  successfailure  identify  corrupted  row  simply  logging  enough  worst  case  row  logged  size  log  input  size  seems  fine  however  user  might  work  figuring  log  link  show  user  tool  start  help  dry  run  simply  use  ifelse  skip  writing  kv  mutation  present,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2364,update  thrift  use  compactframed  protocol  tcompactprotocoltframedtransport  nonblocking  server  option  promise  better  efficiency  performance  improvement  consider  moving  hbase  thrift  bit  full  platform  support  ready  tcompactprotocol,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2365,provide  single  super  user  check  implementation  followup  hbase13375,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
2366,optimize  fuzzyrowfilter  fuzzyrowfilter  room  improvement  lot  bytebybyte  arithmetic  nonefficient  algorithm  selecting  next  candidate  row  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2367,move  static  helper  method  keyvalue  cellutils  add  keyvalueparsecolumn  cellutils  also  public  static  helper,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2368,run  minicluster  top  minidfscluster  similar  dont  start  minizk  cluster  already  one  specified  skip  starting  minidfs  cluster  user  specifies  different  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2369,use  zookeeper  multi  clear  znodes  zkprocedureutil  address  todo  zkprocedureutil  clearchildznodes  clearznodes  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2370,move  unsafe  based  operation  unsafeaccess  new  class  added  bytesjava  unsafe  based  read  hbase13916  add  similar  unsafe  based  read  bb  bytebufferutils  move  unsafe  based  operation  unsafeaccess  otehr  place  refer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2371,stochastic  load  balancer  jmx  metric  today’s  default  hbase  load  balancer  stochastic  load  balancer  cost  function  based  cost  function  weight  tunable  visibility  cost  function  result  directly  provided  driving  example  cluster  tuning  skewed  rack  size  one  rack  half  node  rack  tuning  cluster  uniform  response  time  region  server  ability  tolerate  rack  failure  balancing  localitycost  regionreplicarack  cost  regioncountskew  cost  difficult  without  way  attribute  cost  function’s  contribution  overall  cost  jira  proposes  provide  visibility  via  jmx  cost  function  stochastic  load  balancer  well  overall  cost  balancing  plan,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2372,add  configuration  skip  validating  hfile  format  bulk  loading  bulk  loading  million  hfile  one  htable  checking  hfile  format  timeconsuming  phase  maybe  could  use  parallel  mechanism  increase  speed  come  million  hfiles  may  still  cost  dozen  minute  think  necessary  add  option  advanced  user  bulkload  without  checking  hfile  format  course  default  value  option  true,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2373,add  write  sniffing  canary  currently  canary  tool  sniff  read  operation  hard  finding  problem  write  path  support  write  sniffing  create  system  table  named  canary  canary  tool  tool  make  sure  region  number  large  number  regionserver  region  distributed  onto  regionservers  periodically  tool  put  data  region  calculate  write  availability  hbase  send  alert  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2374,allow  setting  richer  state  value  tostring  pv2  debugging  procedure  crash  loaded  store  state  running  would  help  knew  state  statemachineprocedure  going  start  running  chatting  w  matteo  suggested  allowing  procedure  customize  string  patch  make  statemachineprocedure  print  base  state  running  finished  followed  statemachineprocedure  state  eg  simplestatemachineprocedure  staterunnableservercrashassign,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2375,cleanup  deprecated  apis  cell  class  cleanup  deprecated  apis  cell  class,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2376,changing  internal  structure  immutablebyteswritable  contructor  constructor  immutablebyteswritable  take  byte  newdata  int  offset  int  length  copying  byte  soon  get  change  point  byte  passed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2377,storefilepasseskeyrangefilter  need  create  cell  scan  start  stop  row  profiling  saw  code  passeskeyrangefilter  storefile  code  keyvalue  smallestscankeyvalue  scanisreversed  keyvalueutil  createfirstonrowscangetstoprow  keyvalueutilcreatefirstonrowscan  getstartrow  keyvalue  largestscankeyvalue  scanisreversed  keyvalueutil  createlastonrowscangetstartrow  keyvalueutilcreatelastonrowscan  getstoprow  code  row  need  copied  considering  cellcomparatorcomparerowscell  byte  already  refactored  firstkeykv  lastkeykv  part  jiras,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2378,remove  hlogedit  httpsissuesapacheorgjirabrowsehbase1403focusedcommentid12708553pagecomatlassianjirapluginsystemissuetabpanels3acommenttabpanelaction12708553  stack  im  thinking  hlog  hcd  hlog  value  hlogedit  new  keyvalue  class  thbase  flag  interest  performance  id  like  create  hlogedit  shove  keyvalue,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2379,client  api  determining  server  side  support  cell  level  security  add  client  api  determining  server  side  support  cell  level  security  ask  master  assuming  many  instance  master  regionservers  consistent  view  site  configuration  return  true  feature  required  cell  level  security  present  false  otherwise  throw  unsupportedoperationexception  master  support  rpc  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2380,hbase  backuprestore  phase  3  merge  backup  image  user  merge  incremental  backup  image  single  incremental  backup  image  merge  support  incremental  image  merge  support  image  backup  destination  command  code  hbase  backup  merge  image1image2imagek  code  example  code  hbase  backup  merge  backup143126764557backup143126764456  code  operation  complete  recent  backup  image  kept  example  backup143126764557  merged  backup  image  image  deleted  file  system  backup  system  table  corresponding  backup  manifest  merged  backup  image  updated  remove  dependency  deleted  image  merged  backup  image  contains  data  original  image  deleted  image,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
2381,hbase  backuprestore  phase  3  filter  wals  backup  include  edits  backed  table  h2  high  level  design  overview  incremental  backup  request  come  table  select  table  already  registered  backup  system  union  result  new  table  set  ut  every  table  k  utt  perform  following  convert  new  wal  file  hfile  applying  table  filter  k  edits  table  pas  filter  move  hfiles  backup  destination  restore  incremental  run  full  restore  first  collect  hfiles  intermediate  incremental  image  run  hfilesplitterjob  split  file  current  table  region  boundary  load  file  using  loadincrementalhfiles  tool,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2382,remove  duplicate  code  gettabledescriptor  htable  todo  comment  said  htablegettabledescriptor  hadmingettabledescriptor  remove  duplicate  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2383,enhance  chaos  monkey  framework  adding  zookeeper  datanode  fault  injection  one  shortcoming  existing  chaosmonkey  framework  lack  fault  injection  hbase  dependency  like  zookeeper  hdfs  etc  patch  attempt  solve  problem  partially  adding  datanode  zk  node  fault  injection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2384,refine  regiongroupingprovider  fix  issue  make  scalable  therere  multiple  issue  regiongroupingprovider  including  provider  cache  using  byte  array  key  concurrenthashmap  right  reason  herehttpstackoverflowcomquestions1058149usingabytearrayashashmapkeyjava  using  identitygroupingstrategy  get  group  use  key  cache  mean  cache  include  entry  region  especially  unnecessary  using  boundedregiongroupingprovider  besides  fixing  issue  suggest  change  boundedregiongroupingprovider  provider  pluggable  strategy  make  whole  picture  much  clear  detail  please  refer  patch,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0
2385,allow  load  balancer  operate  region  transition  adding  force  flag  issue  add  boolean  parameter  force  balancer  command  admin  force  region  balancing  even  region  transition  assuming  rit  transient  enhancement  requested  customer  assumption  change  operator  run  hbck  reasonable  idea  region  stuck  transition  using  force  flag  recent  event  customer  cluster  ended  small  number  regionservers  hosting  region  cluster  one  regionserver  50  roughly  20000  region  balancer  couldnt  run  due  small  number  region  stuck  transition  admin  ended  killing  regionservers  reassignment  would  yield  equitable  distribution  region  different  cluster  single  store  file  corrupt  hdfs  block  ssds  cluster  known  lose  data  however  since  single  region  10  1000  region  cluster  stuck  transition  balancer  couldnt  run  state  keeping  hbase  isnt  good  yet  admin  kick  balancer  automatically  scenario  knowing  safe  option  available  operator  use  see  fit  seems  prudent,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2386,metric  block  cache  take  region  replica  account  currently  metric  block  cache  aggregate  sense  dont  distinguish  primary  secondary  tertiary  replica  jira  separate  block  cache  metric  primary  region  replica  aggregate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2387,consolidate  printusage  integrationtestloadandverify  investigating  use  itlav  little  screwy  subclass  overriding  printusage  method  correctly  pas  help  get  info  argument  get  rest  noformat  hbasendimiduk112rc27  hbase  orgapachehadoophbasetestintegrationtestloadandverify  help  usage  binhbase  orgapachehadoophbasetestintegrationtestloadandverify  option  option  hhelp  show  usage  mmonkey  arg  chaos  monkey  run  monkeyprops  arg  property  file  specifying  chaos  monkey  property  nccnoclustercleanup  dont  clean  cluster  end  hbasendimiduk112rc27  hbase  orgapachehadoophbasetestintegrationtestloadandverify  integrationtestloadandverify  doptions  loadverifyloadandverify  load  table  row  dependency  verifies  dependency  chain  option  dloadmappertablename  table  writeverify  default  autogen  dloadmapperbackrefsn  number  backreferences  per  row  default  50  dloadmappernumtowriten  number  row  per  mapper  default  100000  per  mapper  dloadmapperdeleteafterbool  delete  successful  verify  default  true  dloadmappernumpresplitsn  number  presplit  region  start  default  40  dloadmappermaptasksn  number  map  task  load  default  200  dverifyreducetasksn  number  reduce  task  verify  default  35  dverifyscannercachingn  number  hbase  scanner  caching  row  read  default  50  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2388,scan  different  timerange  column  family  present  scan  api  support  table  level  time  range  specific  use  case  benefit  per  column  family  time  range  see  background  discussion  httpsmailarchivesapacheorgmodmboxhbaseuser201508mbox3ccaa4mzom00ef5eoxstk0hetxeby8mqss61gbvgttgpaspmhqhawmailgmailcom3e  couple  choice  would  good  validate  first  update  scan  api  support  family  table  level  update  one  proposal  would  add  scansettimerangebyte  family  long  mintime  long  maxtime  store  mapbyte  timerange  executing  scan  family  specified  timerange  use  otherwise  fall  back  using  table  level  timerange  client  using  new  api  old  region  server  would  get  family  correctly  filterd  old  client  sending  scan  new  region  server  would  work  correctly  question  get  storefilescannershouldusescanner  match  proper  family  time  range  scan  available  doesnt  currently  available  family  part  one  option  would  try  pas  column  family  constructor  path  another  would  instead  alter  shouldusescanner  pas  specific  timerange  use  similar  currently  pass  column  use  also  appears  workaround  family  available,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2389,incremental  backup  bulk  loading  currently  incremental  backup  based  wal  file  bulk  data  loading  bypass  wals  obvious  reason  breaking  incremental  backup  way  continue  backup  bulk  loading  create  new  full  backup  table  may  feasible  customer  bulk  loading  regularly  say  every  day  review  board  date  httpsreviewsapacheorgr54258  order  miss  hfiles  loaded  region  directory  situation  postbulkloadhfile  hook  called  bulk  load  interrupted  record  hfile  name  thru  precommitstorefile  hook  time  incremental  backup  check  presence  hfiles  present  become  part  incremental  backup  image  review  board  httpsreviewsapacheorgr57790  google  doc  design  httpsdocsgooglecomdocumentd1acclsechdvzvsasorgqqrnrlogx4mnyibvau7lq5lje,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2390,refine  regiongroupingprovider  phase2  remove  provider  nesting  formalize  wal  group  name  nesting  defaultwalprovider  inside  regiongroupingprovider  make  logic  ambiguous  since  provider  provide  log  suggest  directly  instantiate  fshlog  regiongroupingprovider  wrt  wal  group  name  regiongroupingprovider  using  sth  like  factoryidnullrandomuuid  quite  long  unnecessary  suggest  directly  use  provideridgroupname  detail  please  refer  initial  patch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2391,show  regionservers  version  master  status  page  production  env  regionservers  may  removed  cluster  hardware  problem  rejoined  cluster  repair  potential  risk  version  rejoined  regionserver  may  diff  others  cluster  upgraded  many  version  solve  show  regionservers  version  server  list  master  status  page  highlight  regionserver  version  different  master  version  similar  hdfs3245  suggestion  welcome,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
2392,concurrent  lru  block  cache  lrubased  block  cache  committed  hbase1192  threadsafe  contains  big  lock  hash  map  high  load  block  cache  hit  heavily  number  thread  need  built  handle  massive  concurrency  issue  aim  implement  new  block  cache  lru  eviction  backed  concurrenthashmap  separate  eviction  thread  influence  drawn  solrs  concurrentlrucache  however  major  difference  solr  treat  cached  element  equal  size  whereas  dependent  heapsize  interface  realistic  though  approximate  heap  usage,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
2393,remove  deprecated  hbasetestingutilitydeletetable  method  hbase  tablename  apis  since  096  test  code  doesnt  privacystability  marker  able  remove  deprecated  method  200  deletetable  separate  unit  test  related  cleanup,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2394,remove  deprecated  hbasetestcase  dependency  testhfile  remove  dependency  long  deprecated  hbasetestcase  090  modified  reference  tfiles  havent  part  modern  hbase,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2395,exorcise  deprecated  putadd  replace  putaddcolumn  put  api  changed  add  addcolumn  update  instance  remove  put  added  hbase  100,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2396,batching  buffered  mutator  awful  adding  list  mutation  adding  list  mutation  buffer  limit  checked  every  mutation  added  lead  lot  try  flush,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2397,support  permissive  mode  secure  cluster  allow  simple  auth  client  implementing  hbase  security  existing  cluster  useful  support  mixed  secure  insecure  client  client  configuration  migrated  secure  authentication  currently  option  allow  secure  client  fallback  simple  auth  insecure  cluster  providing  analogous  setting  server  would  allow  phased  rollout  security  first  security  enabled  cluster  server  permissive  mode  enabled  client  converting  using  secure  authentication  incrementally  server  audit  log  allow  identification  client  still  using  simple  auth  connect  finally  sufficient  client  converted  secure  operation  serverside  permissive  mode  removed  allowing  completely  secure  operation  obviously  enabled  effective  access  control  would  still  useful  tool  enable  smooth  operational  rollout  security  permissive  mode  would  course  disabled  default  enabling  provide  big  scary  warning  log  startup  possibly  flagged  relevant  uis,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2398,htablemutaterow  collect  stats  trying  fix  stats  implementation  moving  result  object  rpc  payload  cell  payload  part  value  returned  request  change  also  u  use  easily  switch  asyncprocess  executor  support  stats  nearly  rpc  call  however  mean  upgrade  client  server  lose  stats  visibility  side  upgraded  could  keep  around  result  based  stats  storage  accommodate  old  api  send  stats  back  server  result  rpc  payload  note  still  wire  compatible  protobufs  mean  ride  lack  information  tricky  part  result  noninterfaceaudienceprivate  getstatistics  method  along  two  interfaceaudienceprivate  addresults  setstatistics  method  might  need  release  deprecate  getstats  method  throwing,1,1,1,1,1,0,0,0,0,0,1,0,1,0,0,0,1
2399,cleanup  snapshot  code  move  common  code  use  helper,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2400,expose  checkandmutate  via  thrift2  user  ask  checkandmutate  wasnt  exposed  via  thrift2  see  good  reason  since  checkandput  checkanddelete  already  let  add,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2401,support  passing  multiple  qops  saslclientserver  via  hbaserpcprotection  currently  set  value  hbaserpcprotection  one  authenticationintegrityprivacy  used  set  javaxsecuritysaslqop  saslutiljava  problem  cluster  want  switch  one  qop  another  itll  take  downtime  rolling  upgrade  create  situation  node  old  value  new  whichll  prevent  communication  similar  issue  client  try  connect  javaxsecuritysaslqop  take  list  qop  preference  order  transition  qop1  qop2  easily  done  like  qop1  qop2qop1  rolling  restart  qop2  rolling  restart  need  change  hbaserpcprotection  accept  list,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0
2402,verifyreplication  use  peer  configuration  peer  connection  verifyreplication  us  replication  peer  configuration  construct  zookeeper  quorum  address  peer  connection  however  configuration  property  peer  configuration  dropped  merge  configuration  property  replicationpeerconfig  creating  peer  connection  obtaining  credential  peer  cluster,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
2403,dont  allow  multis  run  max  result  size  user  put  list  ton  different  get  table  send  along  multi  server  unwraps  get  multi  single  get  may  size  limit  total  might  protect  server  batch  server  side  rpc  smaller,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2404,add  throughput  controller  flush  hbase8329  added  throughput  controller  compaction  avoid  spike  caused  huge  io  pressure  like  networkdisk  overflow  however  even  control  still  observing  disk  utils  near  100  analysis  think  caused  flush  especially  increase  setting  hbasehstoreflushercount  jira  propose  add  throughput  control  feature  flush  supplement  hbase8329  better  control  io  pressure,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
2405,dont  allow  multi  retain  many  block  scan  multis  limit  total  size  cell  returned  however  request  pointing  block  keyvalues  keep  alive  lot  data  size  take  following  example  multi  list  10000  get  fat  row  column  returned  different  block  column  small  32  byte  total  cell  size  32  10000  320kb  however  block  128k  total  retained  heap  size  almost  2gigs,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2406,region  normalization  allowed  underlying  namespace  quota  currently  namespace  quota  hmasternormalizeregions  skip  table  namespace  however  performing  region  merges  wouldnt  violate  quota  constraint  region  split  namespaceauditorcheckquotatosplitregion  called  check  whether  quota  exceeded  region  split  plan  still  executed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2407,cull  testhfilewriterv2  hfilewriterfactory  2x  remove  hfile  v2  patch  clean  remnant  unit  test  associated,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2408,implement  inexpensive  seek  operation  hfile  earlyout  row  column  version  filter  etc  seek  end  row  one  key  time  seek  hfile  level  case  would  end  skipping  block  process  common  case  relatively  large  row  regex  row  filter  call  end  nothing  constant  time  could  also  call  seek  next  column  even  specific  column  explicittracker  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2409,simple  implementation  date  based  tiered  compaction  simple  implementation  datebased  tiered  compaction  similar  cassandra  following  benefit  1  improve  daterangebased  scan  structuring  store  file  datebased  tiered  layout  2  reduce  compaction  overhead  3  improve  ttl  efficiency  perfect  fit  use  case  1  mostly  datebased  date  write  scan  focus  recent  data  2  never  rarely  deletes  data  outoforder  writes  handled  gracefully  time  range  overlapping  among  store  file  tolerated  performance  impact  minimized  configuration  set  hbasesitexml  overriden  pertable  percolumnfamly  level  hbase  shell  design  spec  httpsdocsgooglecomdocumentd1amlnb2n8us1xicstegdlkiql6tohorlz323mguy8edituspsharing  result  production  httpsdocsgooglecomdocumentd1gqrtqzmmktewoijzc8uctqhacnmdxbsjtaqsyiwsmguedit,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2410,use  le  contended  class  metric  running  benchmark  look  like  result  pretty  extreme  locking  histogram  pretty  extreme,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2411,break  writer  reader  storefile  storefilejava  trending  become  monolithic  class  1800  line  would  make  sense  break  reader  writer  500  line  separate  file  many  different  thing  single  class  comparators  reader  writer  stuff  hurt  readability  lot  point  reading  piece  code  require  scrolling  see  level  readerwriterbase  class  level  belongs  smallsmall  thing  really  dont  help  trying  understanding  code  good  reason  dont  often  affect  existing  patch  need  done  branch  etc  class  really  use  single  iteration  refactoring  make  thing  lot  better,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
2412,intrarow  scanning  continue  scaling  number  column  version  single  row  need  mechanism  scan  within  row  return  column  time  currently  entire  row  must  come  back  one  piece,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2413,cleanup  htable  putting  javadocs  trunk  noticed  missing  deprecation  also  exists  never  deprecated  though  new  serverside  implementation  exists  issue  ensure  everything  deprecated  add  880  compatible  exists  deprecating  old  one  also  im  going  best  keep  updated  javadoc  release  httpjgraylahbasejavadoc0200trunk,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2414,provide  option  skip  calculating  block  location  snapshotinputformat  mr  job  reading  snapshotinputformat  need  calculate  split  based  block  location  order  get  best  locality  however  process  may  take  long  time  large  snapshot  setup  computing  layer  spark  hive  presto  could  run  side  hbase  cluster  scenario  block  locality  doesnt  matter  therefore  great  option  skip  calculating  block  location  every  job  super  useful  hiveprestospark  connector,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2415,hbase  manage  multiple  node  zookeeper  quorum  thought  already  jira  cannot  seem  find  need  manage  multiple  node  zookeeper  quorum  required  fully  distributed  option  hbase  make  thing  easier  user  here  relevant  irc  conversation  ryan  andrew  code  jun  17  181439  djryan  right  include  client  deps  hbaselib  jun  17  181447  djryan  removing  zookeeper  would  problematic  jun  17  181456  djryan  hbase  put  private  zk  quorum  jun  17  181502  djryan  doesnt  bother  q1  jun  17  181505  apurtell  djryan  nitay  agreed  thats  wonder  private  zk  quorum  managed  hbase  jun  17  181512  apurtell  q  5  jun  17  181522  djryan  maybe  ship  tool  manage  jun  17  181523  apurtell  possible  jun  17  181529  djryan  agree  jun  17  181539  nitay  apurtell  ok  id  happy  bump  priority  hbase  managing  full  cluster  work  jun  17  181547  iand  niand20515858226ptrusxonet  joined  hbase  jun  17  181548  apurtell  nitay  would  awesome  jun  17  181557  apurtell  skip  discussion  cloudera  including  zk  also  jun  17  181612  apurtell  use  private  port  wont  conflict  typical  zk  install  jun  17  181615  nitay  also  think  user  able  point  existing  cluster  long  rpm  compatible  fine  jun  17  181623  nitay  apurtell  isnt  hadoop  going  start  using  zk  jun  17  181631  apurtell  nitay  agree  clouderaautoconfigrpm  deb  case  jun  17  181634  nitay  cloudera  dude  working  using  namenode  whatnot  like  master  jun  17  181635  djryan  2  thing  jun  17  181638  djryan  set  myids  jun  17  181638  nitay  jun  17  181640  djryan  start  zk  jun  17  181642  djryan  stop  zk  jun  17  181650  djryan  dont  want  startstop  zk  cluster  bounce  jun  17  181651  nitay  ye  stupid  myids  jun  17  181652  djryan  start  jun  17  181654  djryan  done  ti  jun  17  181658  iand  niand20515858226ptrusxonet  left  hbase  leaving  jun  17  181713  apurtell  djryan  yes  start  thats  work  fine  many  hbase  restarts  jun  17  181728  nitay  need  separate  shell  cmd  something  stop  zk  jun  17  181735  nitay  start  starthbase  already  running  type  thing  jun  17  181743  djryan  yes  jun  17  181758  nitay  ok  jun  17  181819  apurtell  quorum  peer  started  node  confregionservers  5  possible  jun  17  181837  apurtell  zoocfg  jun  17  181851  nitay  oh  thinking  separate  confzookeepers  jun  17  181858  apurtell  nitay  even  better  jun  17  181859  nitay  use  first  five  r  jun  17  181926  nitay  apurtell  yeah  really  wouldnt  confzookeepers  would  rip  hostnames  zoocfg  jun  17  181938  nitay  go  way  generate  zoocfg  confzookeepers  jun  17  181942  nitay  gotta  one  jun  17  181949  nitay  dont  want  edit  jun  17  181954  apurtell  nitay  right  jun  17  182021  apurtell  well  jun  17  182029  nitay  zoocfg  right  info  right  cause  u  need  thing  hostnames  ie  client  quorum  port  jun  17  182031  apurtell  leave  server  default  zoocfg  jun  17  182039  apurtell  consider  confzookeepers  jun  17  182047  djryan  call  confzoos  jun  17  182054  djryan  zookeeper  config  jun  17  182054  djryan  dir  jun  17  182057  nitay  parsing  zoocfg  insert  jun  17  182108  nitay  cause  right  java  property  anyways  jun  17  182112  apurtell  let  zk  wrapper  parse  file  exist  otherwise  build  list  quorum  peer  like  already  jun  17  182134  apurtell  someone  could  edit  either  would  dtrt  jun  17  182148  nitay  apurtell  yeah  make  sense  jun  17  182158  nitay  discus  getting  rid  zoocfg  completely  jun  17  182212  nitay  put  xml  create  property  zk  right  prop  jun  17  182214  apurtell  purpose  need  file  available  post  install  script  lay  static  hbase  cluster  config  based  discovers  hadoop  installation  jun  17  182356  apurtell  need  hook  sysvinit  use  chkconfig  enabledisable  service  cluster  node  according  role  defined  hadoopconfmasters  hadoopconfregionservers  jun  17  182413  apurtell  put  hmaster  namenode  jun  17  182417  apurtell  region  server  datanodes  jun  17  182435  apurtell  hadoopconfslaves  mean  jun  17  182444  apurtell  pick  n  host  slave  host  zk  quorum  jun  17  182450  apurtell  make  sense  jun  17  182533  nitay  yes  think  ull  auto  generating  hbase  configs  server  run  jun  17  182550  apurtell  nitay  yes  jun  17  182551  nitay  simple  line  line  confzookeepers  type  file  clean  easy  jun  17  182557  apurtell  nitay  agree  jun  17  182559  apurtell  think  initial  question  answered  hbase  manage  private  zk  ensemble  jun  17  182607  apurtell  somehow  jun  17  182610  nitay  right  jun  17  182615  apurtell  ok  thanks  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2416,clusterstatus  able  return  response  scope  current  clusterstatus  response  return  much  information  load  per  region  replication  cluster  wide  sometimes  response  quite  large  10  100  mb  method  like  getserversize  getregionscount  dont  really  need  full  response  one  possibility  provide  scope  filter  clusterstatus  request  limit  response  back  client,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2417,make  snapshotmanager  accessible  masterservices  see  comment  background  httpsissuesapacheorgjirabrowsehbase15411focusedcommentid15209640pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment15209640  procedure  executes  master  performs  snapshot  procedure  need  access  snapshotmanager  jira  add  accessor  masterservices,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2418,print  procedure  wal  content  let  printer  print  content  procedure  wal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2419,time  limit  scanning  offered  client  rsrpcservicesscan  set  time  limit  equaling  mathminscannerleasetimeoutperiod  rpctimeout  2  response  heartbeat  message  reach  limit  however  two  timeout  setting  hbaseclientscannertimeoutperiod  hbaserpctimeout  read  r  configure  may  different  client  client  setting  much  le  server  may  still  timeout  client  side,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2420,add  provision  adding  mutation  memstore  able  write  region  batchmutate  coprocessor  hook  part  phoenix1734  need  write  index  update  region  coprocessors  writing  batchmutate  api  allowed  mvcc  raised  phoenix2742  discus  alternative  way  write  region  directly  proper  solution  currently  provision  write  wal  edits  coprocessors  set  wal  edits  minibatchoperationinprogress  noformat  set  waledit  operationmutation  specified  position  param  index  param  waledit  public  void  setwaleditint  index  waledit  waledit  thiswaleditsfromcoprocessorsgetabsoluteindexindex  waledit  noformat  similarly  allow  write  mutation  coprocessors  memstore  well  else  provide  batch  mutation  api  allow  write  batch  mutate  coprocessors,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2421,remove  pb  reference  admin  20  subtask  hbase15174,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
2422,remove  pb  reference  result  doublecolumninterpreter  public  facing  class  20  subtask  hbase15174,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2423,remove  deprecated  hconnection  20  thus  removing  pb  reference  20  subtask  hbase15174,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0
2424,report  metric  jvmpausemonitor  jvmpausemonitor  detecting  jvm  pause  pause  logged  warn  would  also  good  expose  information  dashboard  via  metric  system  make  easier  get  info  host  central  location  operator,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2425,add  override  mechanism  exempt  class  dynamically  loading  table  coprocessor  part  hadoops  timeline  service  v2  yarn2928  adding  table  coprocessor  yarn4062  however  finding  coprocessor  cannot  loaded  dynamically  relevant  snippet  exception  noformat  javaioioexception  class  orgapachehadoopyarnservertimelineservicestorageflowflowruncoprocessor  cannot  loaded  orgapachehadoophbasemasterhmastersanitychecktabledescriptorhmasterjava1329  orgapachehadoophbasemasterhmastercreatetablehmasterjava1269  orgapachehadoophbasemastermasterrpcservicescreatetablemasterrpcservicesjava398  orgapachehadoophbaseprotobufgeneratedmasterprotosmasterservice2callblockingmethodmasterprotosjava42436  orgapachehadoophbaseipcrpcservercallrpcserverjava2031  orgapachehadoophbaseipccallrunnerruncallrunnerjava107  orgapachehadoophbaseipcrpcexecutorconsumerlooprpcexecutorjava130  orgapachehadoophbaseipcrpcexecutor1runrpcexecutorjava107  javalangthreadrunthreadjava745  caused  javaioioexception  class  orgapachehadoopyarnservertimelineservicestorageflowflowruncoprocessor  cannot  loaded  orgapachehadoophbaseregionserverregioncoprocessorhosttesttablecoprocessorattrsregioncoprocessorhostjava324  orgapachehadoophbasemasterhmastercheckclassloadinghmasterjava1483  orgapachehadoophbasemasterhmastersanitychecktabledescriptorhmasterjava1327  8  caused  javalangclassnotfoundexception  orgapachehadoopyarnservertimelineservicestorageflowflowruncoprocessor  javaneturlclassloader1runurlclassloaderjava366  javaneturlclassloader1runurlclassloaderjava355  javasecurityaccesscontrollerdoprivilegednative  method  javaneturlclassloaderfindclassurlclassloaderjava354  javalangclassloaderloadclassclassloaderjava425  sunmisclauncherappclassloaderloadclasslauncherjava308  javalangclassloaderloadclassclassloaderjava358  orgapachehadoophbaseutilcoprocessorclassloaderloadclasscoprocessorclassloaderjava275  orgapachehadoophbaseregionserverregioncoprocessorhosttesttablecoprocessorattrsregioncoprocessorhostjava322  10  noformat  tracked  fact  coprocessorclassloader  regarding  hadoop  class  exempt  loading  coprocessor  jar  since  coprocessor  sits  coprocessor  jar  yet  loading  class  delegated  parent  jar  classloading  fails  would  nice  ability  exclude  certain  class  exempt  class  loaded  via  table  coprocessor  classloader  see  hadoops  applicationclassloader  similar  feature  way  load  coprocessor  table  scope,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2426,use  masterservices  directly  instead  casting  hmaster  possible  bunch  hmaster  cast  masterprocedureenv  servermanager  get  rid  use  directly  masterservices  also  id  like  masterservices  noop  implementation  testing,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
2427,refactor  rpc  class  better  accept  async  change  class  layout  need  changed  better  accept  async  version  class  partly  commit  patch  hbase13784  class  turned  interface  asyncrpcchannel  asyncrpcchannelimpl  implementation  coprocessorrpcchannel  synccoprocessorrpcchannel  implementation  new  lowerlevel  abstraction  protoretryingcallable  retryingcallable  abstractregionservercallable  regionservercallable,1,1,0,1,0,1,0,0,1,0,1,0,0,1,1,0,0
2428,move  memcache  concurrentskiplistmap  concurrentskiplistset  cslm  replace  old  entry  new  put  csls  replace  existent  key  making  test  present  remove  semantic  safe  need  synchronizing  replacement  ryan  rawson  suggestion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2429,cellcounter  improvement  looking  cellcounter  map  reduce  seems  like  improved  area  currently  support  setting  scan  batching  important  fetching  version  column  actually  would  nice  support  scan  configuration  currently  provided  tableinputformat  generating  job  counter  containing  row  key  column  qualifier  guaranteed  blow  anything  smallest  table  usable  doesnt  make  sense  count  job  output  row  qualifier  specific  counter  dropped,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2430,change  name  inmemory  update  memcache  memtable  map  sorted  edits  kept  per  store  currently  called  memcache  memcache  name  wellknown  app  something  else  also  memcache  cache  bt  called  memtable  let  rename  itll  make  easier  explaining  hbase  whatll  call  update  inmemorystoreedits,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1
2431,add  async  rpcchannels  rpcclients  rpcclients  need  expose  async  protobuf  rpcchannel  custom  asyncrpcchannel  without  protobuf  overhead  async  table  implementation  made,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1
2432,endpointbased  export  tool  time  exporting  table  reduced  use  endpoint  technique  export  hdfs  file  region  server  rather  hbase  client  experiment  elapsed  time  endpointbased  export  le  half  current  export  tool  enable  hdfs  compression  shortcoming  need  alter  table  deploying  endpoint  comment  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2433,translate  columnvaluefilter  rowfilterset  new  filter  interface  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2434,verifyreplication  prefix  filtering  verifyreplication  currently  let  user  verify  data  within  time  range  replicated  particular  peer  useful  verify  data  start  particular  prefix  example  would  unsalted  multitenant  phoenix  table  wish  verify  data  particular  tenant  add  new  option  verifyreplication  job  allow  list  prefix  given,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2435,cleanup  testregionservermetrics  go  testregionservermetrics  looking  hbase15929  patch  use  setupteardown  table  using  rule  set  table  name  based  testname  refactor  copypasted  code  fragment  single  function,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2436,new  behavior  version  considering  mvcc  t  rather  t  hbase  book  section  version  called  current  limitation  see  httphbaseapacheorgbookhtmlcurrentlimitations  quote  283  current  limitation  2831  deletes  mask  put  deletes  mask  put  even  put  happened  delete  entered  see  hbase2256  remember  delete  writes  tombstone  disappears  next  major  compaction  run  suppose  delete  everything  ⇐  new  put  timestamp  ⇐  put  even  happened  delete  masked  delete  tombstone  performing  put  fail  get  notice  put  effect  start  working  major  compaction  run  issue  problem  use  alwaysincreasing  version  new  put  row  occur  even  care  time  delete  put  immediately  chance  happen  within  millisecond  2832  major  compaction  change  query  result  …\u200bcreate  three  cell  version  t1  t2  t3  maximumversions  setting  2  getting  version  value  t2  t3  returned  delete  version  t2  t3  one  t1  appear  obviously  major  compaction  run  behavior  case  anymore…\u200b  see  garbage  collection  bending  time  hbase  quote  limitation  result  current  implementation  multiversions  consider  timestamp  matter  come  remove  old  version  immediately  enough  number  new  version  get  stronger  semantics  version  two  guarantee  1  delete  mask  put  come  2  version  masked  enough  number  higher  version  version  cf  conf  never  seen  example  understanding  delete  t3  mean  use  deleteaddcolumns  delete  version  whose  t  greater  3  delete  t3  mean  use  deleteaddcolumn  delete  version  whose  ts3  case  1  put  t2  put  t3  delete  t3  put  t1  get  t1  put  delete  case  2  maxversion2  put  t1  put  t2  put  t3  delete  t3  always  get  t2  matter  major  compaction  t1  masked  put  t3  t1  never  seen  case  3  maxversion2  put  t1  put  t2  put  t3  delete  t2  delete  t3  get  nothing  case  4  maxversion3  put  t1  put  t2  put  t3  delete  t2  delete  t3  get  t1  masked  case  5  maxversion2  put  t1  put  t2  put  t3  delete  t3  put  t1  get  t3t1  put  t1  second  time  2nd  latest  version  read  case  6maxversion2  put  t3put  t2put  t1  get  t3t2  like  get  t  still  key  version  different  version  may  result  different  result  even  size  result  smaller  versionssee  case  3  4  getscansetmaxversions  handled  end  read  correct  data  according  cf  version  setting  semantics  different  current  hbase  may  need  logic  support  new  semantic  configurable  default  disabled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2437,robust  way  deal  early  termination  hbck  hbck  running  want  disable  catalog  janitor  balancer  splitmerge  today  implementation  robust  hbck  terminated  earlier  controlc  changed  state  would  reset  original  hbase15406  trying  solve  problem  splitmerge  switch  implementation  complicated  solve  cj  balancer  proposal  solve  problem  use  znode  indicate  hbck  running  cj  balancer  splitmerge  switch  look  znode  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2438,better  documentation  replicationpeers  replicationpeers  interface  method  documented  tied  zookeeper  implementation  replicationpeers  also  method  name  little  confusing  review  board  httpsreviewsapacheorgr48696,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2439,improve  hbasefsck  scalability  problem  hbasefsck  make  unnecessarily  slow  especially  large  table  cluster  many  region  patch  try  fix  biggest  bottleneck  also  include  couple  bug  fix  race  condition  caused  gathering  holding  state  live  cluster  longer  true  time  use  state  fsck  processing  race  condition  cause  fsck  crash  become  unusable  large  cluster  lot  region  splitsmerges  scalabilityperformance  problem  hbasefsck  change  patch  make  unnecessary  io  rpcs  caused  fetching  array  filestatuses  discarding  everything  path  passing  path  pathfilter  filter  look  previously  discarded  filestatuses  path  actually  worse  double  io  first  lookup  obtains  batch  filestatuses  lookup  individual  rpcs  performed  sequentially  avoid  adding  filestatusfilter  filtering  happen  directly  filestatuses  performance  bug  affect  fsck  also  extent  thing  like  snapshot  hfile  archival  etc  didnt  time  look  deep  thing  affected  didnt  want  increase  scope  ticket  focus  mostly  fsck  make  improvement  codepaths  change  patch  though  make  fairly  easy  fix  code  path  later  jiras  feel  feature  strongly  impacted  problem  offlinereferencefilerepair  expensive  part  fsck  often  50  fsck  runtime  running  time  scale  number  store  file  yet  function  completely  serial  make  offlinereferencefilerepair  multithreaded  loadhdfsregiondirs  us  tablelevel  concurrency  big  bottleneck  1  large  cluster  1  large  table  nearly  region  change  loadhdfsregiondirs  regionlevel  parallelism  instead  tablelevel  parallelism  operation  change  benefit  cluster  especially  noticeable  large  cluster  large  table  version  098  original  patch  moderately  sized  production  cluster  2  user  table  160k  region  hbasefsck  went  taking  18  min  5  minute,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2440,tablecfwalentryfilter  scopewalentryfilter  redundantly  iterate  cell  tablecfwalentryfilter  scopewalentryfilter  filter  iterating  cell  since  filter  chained  work  twice  instead  iterate  cell  apply  cell  filtering  logic  cell,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
2441,add  fastpath  codel  awesome  codel,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2442,rowcounter  support  multiple  key  range  currently  rowcounter  allows  single  key  range  used  filter  would  useful  case  able  specify  multiple  key  range  prefix  job  example  counting  set  phoenix  tenant  id  unsalted  table  could  done  enhancing  existing  key  range  parameter  take  multiple  startstop  row  pair  alternately  new  rowprefixes  option  could  added  similar  hbase15847  verifyreplication,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2443,add  comment  procedurestoretracker  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2444,reduce  number  rpcs  large  put  patch  proposed  reduce  number  rpc  large  put  number  data  size  write  threadsingleserverrequestrunnable  result  three  main  factors：  1  flush  size  taken  bufferedmutatorimplbackgroundflushcommits  2  limit  task  number  3  clientbackoffpolicy  lot  request  created  le  mutation  result  two  reason  1  many  region  target  table  different  server  2  flush  size  step  one  summed  “all”  server  rather  “individual”  server  patch  remove  limit  flush  size  step  one  add  maximum  size  submit  server  asyncprocess,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2445,improve  performance  rpc  encryption  apache  common  crypto  hbase  rpc  encryption  enabled  setting  “hbaserpcprotection”  privacy  token  authentication  utilized  digestmd5  mechanism  secure  authentication  data  protection  digestmd5  us  de  3des  rc4  encryption  slow  especially  scan  become  bottleneck  rpc  throughput  apache  common  crypto  cryptographic  library  optimized  aesni  provides  java  api  cipher  level  java  stream  level  developer  use  implement  high  performance  aes  encryptiondecryption  minimum  code  effort  compare  current  implementation  orgapachehadoophbaseiocryptoaesaes  crypto  support  jce  cipher  openssl  cipher  better  performance  jce  cipher  user  configure  cipher  type  default  jce  cipher,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2446,check  replicationscopes  value  stringently  create  table  modify  table  master  check  value  replicationscope  le  0  however  value  replicationscope  must  0  1  otherwise  lead  regionserver  shutdown  think  check  value  replicationscope  stringent  beginning  dont  fully  understand  usage  replicationscope  set  replicationscope  2  mistakewhen  insert  data  tablethe  regionservers  abort  one  onefinanly  cluster  abort，the  exception  follow  quote  20160816  123445245  warn  regionserverhost60023appendpool1t1  walfshlog  append  sequenceid94  requesting  roll  wal  javalangnullpointerexception  orgapachehadoophbaseprotobufgeneratedwalprotosfamilyscopebuildersetscopetypewalprotosjava3939  orgapachehadoophbasewalwalkeygetbuilderwalkeyjava618  orgapachehadoophbaseregionserverwalprotobuflogwriterappendprotobuflogwriterjava118  orgapachehadoophbaseregionserverwalfshlogringbuffereventhandlerappendfshlogjava1886  orgapachehadoophbaseregionserverwalfshlogringbuffereventhandleroneventfshlogjava1750  orgapachehadoophbaseregionserverwalfshlogringbuffereventhandleroneventfshlogjava1672  comlmaxdisruptorbatcheventprocessorrunbatcheventprocessorjava128  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1145  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava615  javalangthreadrunthreadjava744  20160816  123445293  info  memstoreflusher0  regionserverhstore  added  hdfshbasetest27hbase122datadefaultusertable2aa98c17845c9c6d5c8760b87b3ba09ai35825c94e72945c0bf7df3f0adefa1b6  entries1161600  sequenceid59  filesize1676  20160816  123445296  fatal  memstoreflusher0  regionserverhregionserver  aborting  region  server  hbase1016614199600231471262434177  replay  wal  required  forcing  server  shutdown  orgapachehadoophbasedroppedsnapshotexception  region  usertable14712625600092aa98c17845c9c6d5c8760b87b3ba09a  orgapachehadoophbaseregionserverhregioninternalflushcacheandcommithregionjava2427  orgapachehadoophbaseregionserverhregioninternalflushcachehregionjava2105  orgapachehadoophbaseregionserverhregioninternalflushcachehregionjava2067  orgapachehadoophbaseregionserverhregionflushcachehregionjava1958  orgapachehadoophbaseregionserverhregionflushhregionjava1884  orgapachehadoophbaseregionservermemstoreflusherflushregionmemstoreflusherjava510  orgapachehadoophbaseregionservermemstoreflusherflushregionmemstoreflusherjava471  orgapachehadoophbaseregionservermemstoreflusheraccess900memstoreflusherjava75  orgapachehadoophbaseregionservermemstoreflusherflushhandlerrunmemstoreflusherjava259  javalangthreadrunthreadjava744  caused  orgapachehadoophbaseregionserverwaldamagedwalexception  append  sequenceid94  requesting  roll  wal  orgapachehadoophbaseregionserverwalfshlogringbuffereventhandlerappendfshlogjava1898  orgapachehadoophbaseregionserverwalfshlogringbuffereventhandleroneventfshlogjava1750  orgapachehadoophbaseregionserverwalfshlogringbuffereventhandleroneventfshlogjava1672  comlmaxdisruptorbatcheventprocessorrunbatcheventprocessorjava128  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1145  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava615  1  caused  javalangnullpointerexception  orgapachehadoophbaseprotobufgeneratedwalprotosfamilyscopebuildersetscopetypewalprotosjava3939  orgapachehadoophbasewalwalkeygetbuilderwalkeyjava618  orgapachehadoophbaseregionserverwalprotobuflogwriterappendprotobuflogwriterjava118  orgapachehadoophbaseregionserverwalfshlogringbuffereventhandlerappendfshlogjava1886  6  quote,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2447,replication  namespaces  config  peer  config  table  cf  peer  production  cluster  dozen  namespace  every  namespace  dozen  table  complicated  config  table  cf  peer  namespace  need  replication  table  slave  cluster  easy  config  support  replication  namespace  suggestion  discussion  welcomed  review  board  httpsreviewsapacheorgr51521,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
2448,improve  transparent  tablecf  encryption  common  crypto  apache  common  crypto  httpscommonsapacheorgpropercommonscryptoindexhtml  cryptographic  library  optimized  aesni  hbase7544  introduces  framework  transparent  encryption  feature  protecting  hfile  wal  data  rest  currently  jce  cipher  used  bu  default  improvement  use  common  crypto  accelerate  transparent  encryption  hbase  new  crypto  provider  common  crypto  provided  transparent  encryption,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
2449,move  unexpectedstateexception  common  unexpectedstateexception  seems  useful  enough  least  want  use  moved  common  moment  used  memstore  class  life  regionserver  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2450,add  option  loadincrementalhfiles  allows  skipping  unmatched  column  family  work  hbase15449  came  need  loadincrementalhfiles  bail  unmatched  column  family  use  case  like  table  two  column  family  b  full  backup  taken  table  column  family  b  dropped  data  written  table  incremental  backup  performed  table  user  performs  incremental  restore  using  latest  backup  since  column  family  b  gone  loadincrementalhfiles  would  fail  ioexception  family  mismatch  issue  add  option  loadincrementalhfiles  bulk  load  load  hfiles  existing  column  family,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2451,rewrite  delegation  token  test  parameterized  pattern  testdelegationtokenwithencryption  testgeneratedelegationtoken,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2452,enhance  loadincrementalhfiles  api  accept  store  file  path  input  currently  loadincrementalhfiles  take  directory  output  path  input  parameter  scenario  incremental  restore  bulk  loaded  hfiles  list  path  hfiles  known  loadincrementalhfiles  take  list  input  parameter  proceed  loading,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2453,expose  load  information  client  side  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2454,add  option  bulk  load  always  copy  hfiles  instead  renaming  related  hbase14417  support  incrementally  restoring  multiple  destination  issue  add  option  would  always  copy  hfiles  bulk  load,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2455,move  znode  path  configs  separated  class  make  easier  use  curator  client  future  also  try  fix  bad  practise  declares  mastermaintznode  static  update  nonstatic  method,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0
2456,make  bytebufferutilsequals  safer  correct  bytebufferutilsequalshconstantsemptybytebuffer  0  0  hconstantsemptybytearray  0  0  throw  javalangarrayindexoutofboundsexception  1  think  return  true,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2457,procedure  v2  use  base  class  remove  duplicate  set  test  code  table  ddl  procedure  table  ddl  procedure  test  set  avoid  duplicate  code  help  maintain  existing  test  move  set  base  class,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
2458,define  behavior  default  empty  filterlist  current  empty  filterlist  filter  data  filterlistisfamilyessential  always  return  false  cause  null  cell  retrieved  regionscannerimplstoreheap  seems  empty  filterlist  nothing  following  code  common  noformat  private  static  filter  makefilter  filterlist  filterlist  new  filterlist  condition  add  filter  nothing  add  return  filterlist  noformat  keep  current  logic  filter  data  add  enough  comment  explain  add  filterlistsize  filterlistempty  preventing  filtering  data  comment  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2459,refactor  orgapachehadoophbaseclientaction  according  previous  comment  action  doesn’t  apply  generic  b  action  implement  comparabler  actioncompareto  cast  object  action  reason  outlined  refactor  action,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2460,add  replicateall  flag  avoid  misuse  namespaces  tablecfs  config  replication  peer  first  add  new  peer  shell  cmd  code  addpeer  1  clusterkey  server1ciecom2181hbase  code  dont  set  namespaces  table  cf  peer  config  mean  replicate  table  peer  cluster  append  table  peer  config  code  appendpeertablecfs  1  table1  code  peer  replicate  table1  peer  cluster  change  replicate  one  table  replicate  table  cluster  easy  misuse  production  cluster  avoid  appending  table  peer  replicates  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
2461,create  1  split  per  region  generalize  hbase12590  common  request  user  able  better  control  many  map  task  created  per  region  right  always  1  region  1  input  split  1  map  task  go  spark  since  us  tif  region  size  large  50  gb  desirable  able  create  1  split  per  region  hbase12590  add  config  property  mr  job  able  handle  skew  region  size  algorithm  roughly  code  region  size  average  sizeratio  cut  region  two  mr  input  split  average  size  region  size  average  sizeratio  one  region  one  mr  input  split  sum  several  continuous  region  size  average  size  ratio  combine  region  one  mr  input  split  code  although  set  data  skew  ratio  05  something  abuse  hbase12590  creating  1  split  task  per  region  ideal  way  create  patch  example  cannot  create  2  task  per  region  want  fix  properly  extend  approach  hbase12590  make  client  specify  desired  num  mapper  desired  split  size  tif  generates  split  based  current  region  size  similar  algorithm  hbase12590  generic  way  also  would  eliminate  hand  tuning  data  skew  ratio  also  think  guidepost  approach  phoenix  stats  table  used  exactly  purpose  right  region  split  power  two  assuming  uniform  distribution  within  region,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2462,expand  mob  compaction  partition  policy  daily  weekly  monthly  today  mob  region  hold  mob  file  region  daily  partition  mob  compaction  policy  major  mob  compaction  still  one  file  per  region  daily  given  365  day  one  year  least  365  file  per  region  since  hdfs  limitation  number  file  one  folder  going  scale  lot  region  reduce  mob  file  number  want  introduce  partition  policy  weekly  monthly  compact  mob  file  within  one  week  month  one  file  jira  create  track  effort,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2463,add  taskmonitorgettasks  variant  accepts  type  selection  taskmonitortmpljamon  code  list  extends  monitoredtask  task  taskmonitorgettasks  iterator  extends  monitoredtask  iter  tasksiterator  apply  requested  filter  iterhasnext  monitoredtask  iternext  filterequalsgeneral  instanceof  monitoredrpchandler  iterremove  code  mean  user  refreshes  rsstatus  page  regardless  type  filter  always  traverse  clone  monitoredtasks  gettasks  synchronized  code  public  synchronized  listmonitoredtask  gettasks  code  variant  gettasks  added  take  type  filter  unnecessary  cloning  avoided,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2464,refactor  rwqueuerpcexecutorbalancedqueuerpcexecutorrpcexecutor  1  rwqueuerpcexecutor  eight  constructor  method  longest  one  ten  parameter  used  simplerpcscheduler  easy  confused  read  code  2  duplicate  method  implement  rwqueuerpcexecutor  balancedqueuerpcexecutor  implemented  parent  class  rpcexecutor  3  simplerpcscheduler  read  many  configs  new  rpcexecutor  callqueuescanshareconfkey  needed  rwqueuerpcexecutor  callqueuecodeltargetdelay  callqueuecodelinterval  callqueuecodellifothreshold  needed  adaptivelifocodelcallqueue  thought  refactor  suggestion  welcome  review  board  httpsreviewsapacheorgr53726,1,0,1,0,1,0,0,0,1,1,1,0,1,0,0,0,0
2465,improve  simpleloadbalancer  always  take  serverlevel  balance  account  currently  bytable  strategy  might  still  serverlevel  imbalance  improve  jira  background  operating  large  scale  clustersour  case  company  still  prefer  use  simpleloadbalancer  due  simplicity  quick  balance  plan  generation  etc  current  simpleloadbalancer  two  mode  1  bytable  guarantee  region  one  table  could  uniformly  distributed  2  bycluster  ignores  distribution  within  table  balance  region  together  pressure  different  table  different  first  bytable  option  preferable  one  case  yet  choice  sacrifice  cluster  level  balance  would  cause  server  significantly  higher  load  eg  242  region  server  417  region  server  breal  world  stats  consider  case  cluster  3  table  4  server  noformat  server  3  region  table11  table21  table31  server  b  3  region  table12  table22  table32  server  c  3  region  table13  table23  table33  server  0  region  noformat  bytable  strategy  perspective  cluster  already  perfectly  balanced  table  level  perfect  status  like  noformat  server  2  region  table21  table31  server  b  2  region  table12  table32  server  c  3  region  table13  table23  table33  server  2  region  table11  table22  noformat  see  server  load  change  3330  2232  table1  table2  table3  still  keep  balanced  goal  jira  try  achieve  two  ut  added  well  last  one  demonstrating  advantage  new  strategy  also  onconfigurationchange  method  implemented  hot  control  slop  variable  using  strategy  largest  cluster  several  month  effect  could  assured  extent,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2466,expose  keyvaluecheckparameters  checkfortagslength  used  cell  implementation  keyvalue  2  useful  private  function  check  input  parameter  checkparameters  checkfortagslength  would  great  access  could  private  used  cell  extendedcell  implementation,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2467,mob  make  ref  cell  creation  efficient  flush  mob  data  ref  cell  created  per  actual  mob  cell  creates  lot  garbage  refer  mobutilscreatemobrefcell  need  add  2  tag  ref  cell  arraylist  created  default  size  creating  ref  array  call  cellutilgettags  create  new  arraylist  even  original  cell  tag  new  kv  created  create  new  backing  byte  copy  also  along  flushcompaction  op  fresh  tag  object  created  tablename  tag  fix  include  1  table  name  tag  going  change  per  hstore  even  new  tag  added  keep  byte  2  tag  mobhstore  level  flush  compaction  store  use  2  create  new  mobrefcell  like  tagrewritecell  value  tag  part  diff  original  cell,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2468,add  retry  loadincrementalhfiles  tool  using  loadincrementalhfiles  tool  s3  filesystem  prone  failing  due  filenotfoundexceptions  due  inconsistency  simple  configurable  retry  logic  added,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2469,optimize  mob  compaction  del  file  today  del  file  mobdir  major  mob  compaction  every  mob  file  recompacted  cause  lot  io  slow  major  mob  compaction  may  take  month  finish  need  improved  idea  1  compact  del  file  one  instead  compact  based  group  startkey  key  use  firstkeystartkey  make  mob  file  see  del  file  need  included  partition  2  based  timerange  del  file  compaction  file  timerange  need  include  del  file  newer  file,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2470,refactor  asyncprocess  bufferedmutatorimpl  htable  following  reason  refactoring  updateheavy  application  example  loader  creates  many  bufferedmutator  batch  update  bufferedmutators  can’t  share  large  threadpool  shutdown  method  called  closing  bufferedmutator  patch  add  flag  bufferedmutatorparams  preventing  calling  shutdown  method  bufferedmutatorimplclose  asyncprocess  powerful  traffic  control  control  single  table  currently  allow  alternate  traffic  control  implementation  advanced  user  want  control  suggestion  welcome,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2471,hold  reference  hregion  store  instead  hregioninfo  generally  useful  low  impact  modification  enabled  fixup  patch  hbase1715  let  one  potentially  take  action  region  store  already  associating  hri  seems  like  binding  region  store  without  benefit  reference  region  object  result  pass  local  test,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2472,separate  smalllarge  file  delete  thread  hfilecleaner  accelerate  archived  hfile  cleanup  speed  using  pciessd  flush  speed  really  quick  although  per  cf  flush  still  hbaseregionserveroptionalcacheflushinterval  setting  mechanism  avoid  data  kept  memory  long  flush  small  hfiles  online  environment  found  single  thread  cleaner  kept  cleaning  earlier  flushed  small  file  large  file  got  chance  caused  disk  full  many  problem  deleting  hfiles  parallel  many  thread  also  increase  workload  namenode  propose  separate  largesmall  hfile  cleaner  thread  like  compaction  turned  work  well  cluster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2473,abstract  interface  rpcservercall  rpcservercall  concrete  class  marked  noformat  interfaceaudiencelimitedprivatehbaseinterfaceaudiencecoproc  hbaseinterfaceaudiencephoenix  noformat  let  abstract  interface  potential  consumer  want  pas  around,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2474,avoid  compacting  already  compacted  mob  file  del  file  today  one  file  partition  del  file  file  skipped  del  file  current  logic  compact  alreadycompacted  file  del  file  let  say  one  mob  file  regiona20161101  compacted  1212016  del  file  regionb20161201del  mob  compaction  kick  regiona20161101  le  threshold  picked  compaction  since  del  file  regiona20161101  regionb20161201del  compacted  regiona201611011  regionb20161201del  cannot  deleted  since  allfile  compaction  next  mob  compaction  regiona201611011  regionb20161201del  picked  compacted  regiona201611012  case  cause  unnecessary  io,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2475,add  mechanism  control  hbase  cleaner  behavior  cleaner  used  get  rid  archived  hfiles  old  wals  hbase  case  heavy  workload  cleaner  affect  query  performance  creating  lot  connection  perform  costly  read  writes  underlying  filesystem  patch  allows  user  control  hbase  cleaner  behavior  providing  shell  command  enable  disable  manually  run  main  intention  patch  avoid  running  expensive  cleaner  chore  peak  time  experimentation  saw  lot  hfiles  wal  log  related  file  getting  created  inside  archive  dir  didnt  see  zklock  related  file  since  replacing  hdfs  s3  delete  call  take  forever  complete,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2476,remove  immutablesegmentgetkeyvaluescanner  based  discussion  anastass  patch  memstoresnapshot  us  keyvaluescanner  actually  seems  redundant  considering  already  segmentscanner  idea  snapshot  scanner  simple  iterator  type  scanner  lack  capability  reference  counting  segment  used  snapshot  snapshot  mulitple  segment  latest  impl  better  hold  segment  ref  counting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2477,add  observer  notification  bulk  loaded  hfile  moved  region  directory  currently  postbulkloadhfile  hook  notifies  location  bulk  loaded  hfiles  however  bulk  load  fails  hfile  moved  region  directory  postbulkloadhfile  hook  called  way  pluggable  component  replication  see  hbase17290  backup  restore  know  hfiles  moved  region  directory  even  postbulkloadhfile  called  finally  block  write  backup  table  zookeeper  issued  postbulkloadhfile  may  fail  ending  situation  issue  add  precommitstorefile  hook  notifies  path  committed  hfile  bulk  loaded  hfile  moved  region  directory  precommitstorefile  hook  write  backup  table  zookeeper  issued  movement  hfile  write  fails  ioexception  would  make  bulk  load  fail  leaving  hfile  region  directory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2478,nearinstantaneous  online  schema  table  state  update  need  take  table  offline  update  hcd  htd  one  option  putting  htds  hcds  zk  mirror  disk  catalog  table  used  cold  init  scenario  discussed  irc  scheme  regionservers  hosting  region  table  would  watch  permanent  node  zk  associated  table  schema  update  take  appropriate  action  watcher  effect  schema  update  become  another  item  todo  list  hbasetablestablenameschema  must  associated  write  locking  scheme  also  handled  zk  primitive  avoid  situation  one  concurrent  update  clobber  another,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2479,avoid  busy  waiting  throttledinputstream  codetitlethrottledinputstreamjavaborderstylesolid  calculate  precise  sleep  time  instead  busy  waiting  private  void  throttle  throw  ioexception  getbytespersec  maxbytespersec  try  threadsleepsleepdurationms  totalsleeptime  sleepdurationms  catch  interruptedexception  e  throw  new  ioexceptionthread  aborted  e  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2480,introduce  per  request  limit  number  mutation  hbase16224  introduced  hbaseclientmaxperrequestheapsize  limit  amount  data  sent  client  consider  adding  per  request  limit  number  mutation  batch  recent  troubleshooting  session  customer  application  code  avoid  oome  server  side,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
2481,support  specifying  wal  directory  outside  root  directory  currently  wal  storefiles  need  filesystem  filesystems  amazon  s3  don’t  support  append  consistent  writes  two  property  imperative  wal  order  avoid  loss  writes  however  storefiles  don’t  necessarily  need  consistency  guarantee  since  writes  cached  locally  writes  fail  always  replayed  wal  jira  aim  allow  user  configure  log  directory  wals  outside  root  directory  even  different  filesystem  default  value  still  put  log  directory  root  directory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2482,correct  semantic  permission  grant  currently  hbase  grant  operation  following  semantic  code  hbasemain0190  grant  hbasetst  rw  ycsb  0  row  00960  second  hbasemain0200  userpermission  ycsb  user  namespacetablefamilyqualifierpermission  hbasetst  defaultycsb  permissionactionsreadwrite  1  row  00550  second  hbasemain0210  grant  hbasetst  ca  ycsb  0  row  00820  second  hbasemain0220  userpermission  ycsb  user  namespacetablefamilyqualifierpermission  hbasetst  defaultycsb  permission  actionscreateadmin  1  row  00490  second  code  later  permission  replace  previous  granted  permission  confused  hbase  administrator  seems  reasonable  hbase  merge  multiple  granted  permission,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2483,refactor  hlog  hlog  1215  line  going  add  lot  functionality  file  refactored,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2484,refactor  procedure  framework  code  change  moved  lock  masterprocedureschedulerqueue  one  queue  object  used  namespacetable  arent  100  dont  need  complexity  arising  functionality  one  place  schemalocking  owns  lock  locking  implementaion  moved  procedure2  package  removed  namespacequeue  wasnt  used  queue  addpeekpolletc  function  threw  unsupportedoperationexception  used  lock  namespaces  lock  moved  queue  class  needed  anymore  remoed  regionevent  locking  region  tablesnamespaces  used  locking  queue  class  region  couldnt  separate  proc  queue  region  level  hence  redundance  locking  separate  use  region  removed  queueinterface  class  declaration  except  one  implementaion  make  point  interface  moot  removed  queueimpl  concrete  implementation  abstract  queue  class  moved  function  queue  class  avoid  unnecessary  level  inheritance  hierarchy  removed  procedureeventqueue  class  wrapper  around  arraydeque  class  procedurewaitqueue  type  class  encapsulated  table  priority  related  stuff  single  class  removed  unused  function  perf  using  masterprocedureschedulerperformanceevaluation  10  thread  10m  ops  5  table  without  patch  10  regionstable  yield  584980  addback  time  41s  poll  time  10  1m  regionstable  yield  16  addback  time  59s  poll  time  129s  patch  10  regionstable  yield  86413  addback  time  41s  poll  time  82s  1m  regionstable  yield  9  addback  time  6  poll  time  13  memory  footprint  cpu  dont  compare  gc  depends  life  object  much  longer  realworld  scenario  without  patch  withoutpatchpngwidth800  patch  withpatchpngwidth800,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,0,0
2485,avoid  copy  family  initializing  fswalentry  compare  family  cloning  noformat  setbyte  familyset  setsnewtreesetbytesbytescomparator  cell  cell  cell  cellutilmatchingfamilycell  waleditmetafamily  todo  avoid  clone  familysetaddcellutilclonefamilycell  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2486,reuse  byte  array  building  hfile  block  two  improvement  ondiskblockbyteswithheader  maintain  byte  array  reused  building  hfile  ondiskblockbyteswithheader  copied  new  byte  array  need  cache  block  block  need  cached  uncompressedblockbyteswithheader  never  created  codetitlehfileblockjavaborderstylesolid  private  void  finishblock  throw  ioexception  blocktype  blocktypedata  thisdatablockencoderendblockencodingdatablockencodingctx  userdatastream  baosinmemorygetbuffer  blocktype  blocktype  datablockencodingctxgetblocktype  userdatastreamflush  array  copy  safe  cache  byte  array  cacheonwrite  header  still  empty  dummy  header  yet  filled  uncompressedblockbyteswithheader  baosinmemorytobytearray  prevoffset  prevoffsetbytypeblocktypegetid  need  set  state  package  block  cacheonwrite  way  block  ready  yet  encoded  compressed  state  stateblockready  blocktype  blocktypedata  blocktype  blocktypeencodeddata  ondiskblockbyteswithheader  datablockencodingctx  compressandencryptuncompressedblockbyteswithheader  else  ondiskblockbyteswithheader  defaultblockencodingctx  compressandencryptuncompressedblockbyteswithheader  calculate  many  byte  need  checksum  tail  block  int  numbytes  int  checksumutilnumbytes  ondiskblockbyteswithheaderlength  filecontextgetbytesperchecksum  put  header  disk  byte  header  currently  unfilledout  putheaderondiskblockbyteswithheader  0  ondiskblockbyteswithheaderlength  numbytes  uncompressedblockbyteswithheaderlength  ondiskblockbyteswithheaderlength  set  header  uncompressed  byte  cacheonwrite  iff  different  ondiskblockbyteswithheader  array  ondiskblockbyteswithheader  uncompressedblockbyteswithheader  putheaderuncompressedblockbyteswithheader  0  ondiskblockbyteswithheaderlength  numbytes  uncompressedblockbyteswithheaderlength  ondiskblockbyteswithheaderlength  ondiskchecksumlength  numbytes  ondiskchecksum  new  bytenumbytes  checksumutilgeneratechecksums  ondiskblockbyteswithheader  0  ondiskblockbyteswithheaderlength  ondiskchecksum  0  filecontextgetchecksumtype  filecontextgetbytesperchecksum  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2487,put  writetowal  method  proper  gettersetter  name  putwritetowal  getter  putwritetowalboolean  setter  putgetwritetowal  returning  boolean  putsetwritetowalboolean,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2488,rsgroup  code  refactoring  making  rsgroupinfomanager  nonstatic  rsgroupadminendpoint  encapsulate  rsgroupadminservice  internal  class  rsgroupadminendpoint  need  inheritence  make  rsgroupadminendpoint  extend  basemasterobserver  got  rid  unwanted  empty  implementation  change  two  internal  class  rsgroupadminserver  nonstatic  outer  class  variable  shared  rename  rsgroupserde  rsgroupprotobufutilprotobufutil  use  place  moved  2  function  rsgroupmanagerimpl  used  javadoc  comment  improving  variable  name  maybe  misc  refactoring,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
2489,removing  memstorescanner  snapshotscanner  compactingmemstore  becoming  new  default  store  comprises  multiple  memory  segment  12  memstorescanner  encapsulates  scanning  segment  memory  part  store  snapshotscanner  used  scan  snapshot  segment  upon  flush  disk  logic  scanner  scattered  multiple  class  storescanner  segmentscanner  memstorescanner  snapshotscanner  make  maintainance  debugging  challenging  task  always  good  reason  example  memstorescanner  keyvalueheap  kvh  creating  store  scanner  also  kvh  make  kvh  inside  kvh  reasoning  correctness  method  supported  scanner  seek  next  hasnext  peek  etc  hard  debugging  cumbersome  addition  removing  memstorescanner  layer  allow  store  scanner  filter  one  memory  scanner  instead  either  taking  case  discarding  rarely  snapshotscanner  simplified  version  segmentscanner  used  specific  context  however  additional  implementation  logic  real  advantage  improved  performance  therefore  suggest  removing  memstorescanner  snapshotscanner  code  adjusted  handle  list  segment  scanner  encapsulate  fit  well  current  code  since  case  point  list  scanner  expected  passing  actual  list  segment  scanner  natural  wrapping  single  high  level  scanner  collectionssingeltonlist,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2490,coprocessor  design  improvement  two  main  change  adding  template  coprocessor  type  coprocessorenvironment  ie  interface  coprocessorenvironmentc  extends  coprocessor  enables  u  load  relevant  coprocessors  host  right  type  host  load  type  coprocs  execoperation  check  coproc  correct  type  ie  xcoprocessorhost  load  xobserver  yobserver  others  check  execoperation  coproc  instanceof  xobserver  ignore  rest  allow  sharing  bunch  functionsclasses  currently  duplicated  host  eg  coprocessoroperations  coprocessoroperationwithresult  execoperations  introduce  4  coprocessor  class  use  composition  new  class  old  observer  real  gold  moving  forward  well  able  break  giant  everythinginone  observer  masterobserver  100  function  smaller  focused  observer  smaller  observer  different  compat  guarantee  here  detailed  design  doc  httpsdocsgooglecomdocumentd1mpkm1crrvbmzl4dbqzrus8obyvnnhhr5it2yyhifxtgedituspsharing,1,0,1,0,1,0,0,1,1,0,1,0,1,0,0,1,1
2491,support  weak  soft  object  pool  ycsb  testing  embedded  mode  hbase17744  found  high  read  load  gc  quite  severe  even  offheap  l2  cache  investigation  found  caused  using  weak  reference  idreadwritelock  embedded  mode  read  quick  lock  might  already  get  promoted  old  generation  weak  reference  cleared  cause  dirty  card  table  old  reference  get  removed  new  lock  object  set  referencecache  see  weakobjectpoolget  thus  slowing  ygc  distributed  mode  therell  also  lock  object  created  weak  reference  soft  reference  slowing  processing  proposed  use  soft  reference  idreadwritelock  used  cache  wont  get  cleared  jvm  memory  enough  could  resolve  issue  mentioned  whats  propose  extend  weakobjectpool  generate  support  weak  soft  reference  note  gc  issue  emerges  embedded  mode  directoperator  case  cost  wire  removed  thus  produce  extremely  high  concurrency,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0
2492,remove  testing  code  asyncrequestfutureimpl  hbase16224  left  testing  code  asyncrequestfutureimpl  iterates  mutation  order  get  data  size  cost  directly  proportional  size  batch  remove,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0
2493,improve  performanceevaluation  current  performanceevaluation  class  two  problem  updated  hadoop0200  approach  split  map  strict  need  provide  correct  inputsplit  inputformat  class  current  code  us  textinputformat  filesplit  reasonable  fix  problem,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2494,backup  optimization  phase  backup  restore  optimized  walplayer  support  multiple  table  run  distcp  per  table  backuprestore  eventual  goal  2  mr  job  per  backuprestore,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2495,pe  tool  random  read  totally  random  recently  using  pe  tool  bucket  cache  related  performance  test  one  thing  noted  way  random  read  work  totally  random  suppose  load  200g  data  using  size  param  use  rows500000  randomread  assumption  among  200g  data  could  generate  randomly  500000  row  key  read  happens  pe  tool  generates  random  row  set  row  key  fall  first  500000  row  quite  evident  tried  use  hbase15314  testing  suppose  split  bucket  cache  size  200g  2  file  100g  randomreads  rows500000  always  land  first  file  2nd  file  better  make  pe  purely  random,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2496,add  generic  method  updating  metric  start  end  procedure  execution  procedure  procv2  framework  procedure  class  generic  method  update  metric  start  end  procedure  execution  specific  procedure  override  implement  update  respective  metric  default  implementation  need  provided  override  implementation  optional,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2497,many  zk  connection  currently  open  ton  new  connection  zookeeper  like  every  time  instantiate  new  htable  maximum  number  client  connection  described  code  property  namehbasezookeeperpropertymaxclientcnxnsname  value30value  descriptionproperty  zookeepers  config  zoocfg  limit  number  concurrent  connection  socket  level  single  client  identified  ip  address  may  make  single  member  zookeeper  ensemble  set  high  avoid  zk  connection  issue  running  standalone  pseudodistributed  description  property  code  hit  max  number  zk  refuse  connection  suppose  4  map  running  server  hosting  r  may  actually  lose  connection  r  eventually  hit  session  timeout  maybe  singleton  zkw,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2498,make  largesmall  file  clean  thread  number  configurable  hfilecleaner  currently  one  thread  large  small  file  cleaning  write  pressure  huge  might  need  cleaner  thread  need  make  thread  number  configurable  observed  18pb  data  archive  directory  online  due  business  access  rate  change  proposal  one  necessary  change  required  default  value  configuration  would  still  left  1  keep  low  pressure  nn  normal  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2499,refactor  replicationsource  one  basic  idea  move  code  recovered  queue  new  subclass  recoveredreplicationsource  replicationsource  dont  need  call  isqueuerecovered  many  time  make  code  clearly,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
2500,lowlatency  space  quota  size  report  presently  space  quota  enforcement  relies  regionservers  sending  report  master  region  host  done  periodically  reading  cached  size  hfile  region  ultimately  computed  hdfs  mean  master  unaware  region  size  growth  next  time  chore  regionserver  fire  fair  amount  latency  minute  default  operation  like  flush  compaction  bulkloads  delayed  even  though  regionserver  running  operation  locally  instead  create  api  operation  could  invoke  would  automatically  update  size  region  operated  example  successful  flush  report  size  region  increased  size  flush  compaction  subtract  size  input  file  compaction  add  size  resulting  file  decouples  computation  region  size  sending  region  size  master  allowing  u  send  report  frequently  increasing  responsiveness  cluster  size  change,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
2501,track  file  archival  low  latency  space  quota  snapshot  related  work  proposed  hbase17748  building  idea  hbase18133  make  space  quota  tracking  hbase  snapshot  faster  respond  snapshot  play  location  file  whether  data  archive  directory  play  factor  realized  size  table  like  flush  compaction  etc  moving  file  data  directory  archive  directory  done  regionserver  hook  call  send  necessary  information  master  quickly  update  size  table  snapshot  play  require  regionserver  report  full  coordinate  file  moved  tableregionfamilyfile  snapshotquotaobserverchore  running  master  avoid  hdfs  lookup  partial  total  compute  location  region  hfiles  may  also  require  refactoring  snapshotquotaobserverchore  decouple  receipt  file  archival  report  regionservers  eg  hregionfilesystemremovestorefiles  master  processing  size  snapshot,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,1
2502,incremental  load  support  multipletable  hfileoutputformat  h2  introduction  mapreduce  currently  support  ability  write  hbase  record  bulk  hfiles  single  table  file  uploaded  relevant  regionservers  information  reasonable  latency  feature  useful  make  large  set  data  available  query  time  well  provides  way  efficiently  process  large  input  hbase  without  affecting  query  latency  however  support  write  variation  record  key  hfiles  belonging  multiple  hbase  table  within  mapreduce  job  h2  goal  goal  jira  extend  hfileoutputformat2  support  writing  hfiles  different  table  within  mapreduce  job  singletable  hfile  feature  backwardscompatible  use  case  needed  write  record  key  smaller  hbase  table  quicker  access  record  key  date  appended  larger  table  longer  term  storage  chronological  access  table  would  different  ttl  setting  support  respective  access  pattern  also  needed  able  bulk  write  record  multiple  table  different  subset  large  input  efficiently  possible  rather  run  mapreduce  job  multiple  time  one  table  record  structure  would  useful  able  parse  input  single  time  write  multiple  table  simultaneously  additionally  wed  like  maintain  backwards  compatibility  existing  heavilyused  hfileoutputformat2  interface  allow  benefit  locality  sensitivity  introduced  long  implemented  support  multiple  table  support  single  table  multi  table  hfile  writes  h2  proposal  backwards  compatibility  existing  single  table  support  hfileoutputformat2  maintained  case  mapper  need  emit  table  rowkey  however  new  class  multihfileoutputformat  provide  helper  function  generate  rowkey  mapper  prefix  desired  tablename  existing  rowkey  well  provides  configureincrementalload  support  multiple  table  hfileoutputformat2  updated  following  way  configureincrementalload  accept  multiple  table  descriptor  region  locator  pair  analogous  single  pair  currently  accepted  hfileoutputformat2  compression  block  size  bloom  type  datablock  setting  per  column  family  set  configuration  object  indexed  retrieved  tablename  column  family  getregionstartkeys  support  multiple  regionlocators  calculate  split  point  therefore  partition  collectively  table  similarly  eventual  number  reducer  equal  total  number  partition  across  table  recordwriter  class  able  process  rowkeys  either  without  tablename  prepended  depending  configureincrementalload  configured  multihfileoutputformat  hfileoutputformat2  use  multihfileoutputformat  write  output  hfiles  match  output  format  hfileoutputformat2  however  default  use  case  keep  existing  directory  structure  column  family  name  directory  hfiles  within  directory  case  multihfileoutputformat  output  hfiles  output  directory  following  relative  path  noformat  table1  family1  hfiles  table2  family1  family2  hfiles  noformat  aim  comprehensive  solution  original  ticket  hbase3727  hbase16261  thanks  clayb  support  contribution  bloomberg  developer  patch  attached  shortly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2503,much  faster  locality  cost  function  candidate  generator  noticed  stochastic  load  balancer  scaling  well  cluster  size  say  smaller  cluster  17  table  12  region  server  5k  region  balancer  considers  100000  cluster  configuration  60  per  balancer  run  5000  per  60  bigger  cluster  82  table  160  region  server  13k  region  bigger  cluster  able  converge  balance  quickly  thing  like  table  skew  region  load  etc  balancer  enough  time  think  rewritten  locality  cost  function  incremental  meaning  recomputes  cost  based  recent  region  move  proposed  balancer  rather  recomputing  cost  across  regionsservers  every  iteration  also  cache  locality  every  region  every  server  beginning  balancer  execution  localitybasedcostfunction  localitycandidategenerator  reference  way  need  collect  hdfs  block  every  region  iteration  balancer  change  running  6  production  cluster  4  qa  cluster  without  issue  speed  improvement  noticed  massive  big  cluster  consider  20x  cluster  configuration  one  design  decision  made  consider  locality  cost  difference  best  locality  possible  given  current  cluster  state  currently  measured  locality  old  locality  computation  would  measure  locality  cost  difference  current  locality  100  locality  new  computation  instead  take  difference  current  locality  given  region  best  locality  region  cluster,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2504,refactor  replicationsourcewalreaderthread  hbase18130  add  get  method  replicationsource  replicationsourcewalreaderthread  doesnt  need  many  parameter  initialize  walentryfilter  used  replicationsourcewalreaderthread  dont  need  new  every  replicationsourcewalreaderthread  meanwhile  separate  new  recoveredreplicationsourcewalreaderthread  recovered  replication  source  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
2505,remove  deprecated  apis  remove  deprecated  stuff  client  mapred,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2506,amv2  create  new  recovermetaprocedure  use  servercrashprocedure  hmasterfinishactivemasterinitialization  unit  test  hbasemasterproceduretestservercrashproceduretestrecoveryanddoubleexecutiononrswithmeta  enabled  run  several  time  fails  intermittently  cause  meta  recovery  done  two  different  place  servercrashprocedureprocessmeta  hmasterfinishactivemasterinitialization  coordinated  hmasterfinishactivemasterinitialization  get  submit  splitmetalog  first  running  call  servercrashprocedureprocessmeta  fails  causing  step  retried  loop  servercrashprocedureprocessmeta  submits  splitmetalog  splitmetalog  hmasterfinishactivemasterinitialization  finished  success  returned  without  work  servercrashprocedureprocessmeta  submits  splitmetalog  request  going  hmasterfinishactivemasterinitialization  submits  test  fails  exception  stack  discussed  possible  solution  create  recovermetaprocedure  call  required  procedure  framework  provides  mutual  exclusion  requires  idempotence  fix  problem,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
2507,reduce  global  heap  pressure  flush  based  heap  occupancy  region  flushed  memory  component  exceed  threshold  default  size  128mb  flush  policy  decides  whether  flush  store  comparing  size  store  another  threshold  configured  hbasehregionpercolumnfamilyflushsizelowerbound  currently  implementation  case  compare  data  size  keyvalue  threshold  compare  heap  size  includes  index  size  metadata,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2508,clean  parameterized  test  declaration  debugging  something  unrelated  noticed  use  constructor  form  junit  parameterized  test  instead  annotated  member  form  personally  find  using  parameter  annotation  clear  also  move  parameter  generator  hbasecommon  accessible  module,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
2509,share  eventloopgroup  nettyrpcserver  nettyrpcclient  asyncfswalprovider  r  side  need  find  proper  way  pas  eventloopgroup  instance  configuration  object,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2510,remove  byte  formal  parameter  sizeof  classsize  classsizememorylayout  classsizeunsafelayout  classsize  class  internal  static  class  sizeof  function  2  formal  parameter  byte  b  int  len  function  internal  logic  use  refer  byte  b  could  removed  codetitlehbasecommonsrcmainjavaorgapachehadoophbaseutilclasssizejavaborderstylesolid  class  classsize  public  static  long  sizeofbyte  b  int  len  return  memorylayoutsizeofb  len  class  classsizememorylayout  long  sizeofbyte  b  int  len  return  alignarrayheadersize  len  class  classsizeunsafelayout  long  sizeofbyte  b  int  len  return  alignarrayheadersize  len  unsafeaccesstheunsafearraybyteindexscale  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2511,multiget  multidelete  multiput  batched  appropriate  region  server  ive  started  create  general  interface  batchmulti  call  would  like  get  input  thought  handle  protocol  look  like  first  naive  patch  coming  soon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2512,performance  issue  clientasyncprefetchscanner  slower  clientsimplescanner  copied  test  result  hbase17994  code  binhbase  orgapachehadoophbaseperformanceevaluation  rows100000  nomapred  scan  1  binhbase  orgapachehadoophbaseperformanceevaluation  rows100000  nomapred  asyncprefetchtrue  scan  1  code  mean  latency  test1  test2  test3  test4  test5  scan  1221  1432  1325  1307  1183  scan  prefetchtrue  3736  3788  3756  3766  3828,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2513,add  rowmutations  support  batch  rowmutations  multiple  put  andor  deletes  atomically  single  row  current  batch  call  support  rowmutations  part  batch  add  missing  part  able  batch  rowmutations,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2514,expose  bucketcache  value  configured  bucketcache  always  us  default  value  cache  configuration  however  doesnt  work  use  case  particular  user  want  able  configure  percentage  cache  single  access  multi  access  inmemory  access,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2515,always  overwrite  t  appendincrement  unless  existing  cell  found  dont  pas  custom  timestamp  increment  increment  timestamp  always  rewrite  hence  user  cant  increment  cell  custom  timestamp  codetitleprotobufutiljava  value  null  valuessize  0  cell  cell  value  valuebuilderclear  valuebuildersetqualifierunsafebyteoperationsunsafewrap  cellgetqualifierarray  cellgetqualifieroffset  cellgetqualifierlength  valuebuildersetvalueunsafebyteoperationsunsafewrap  cellgetvaluearray  cellgetvalueoffset  cellgetvaluelength  cellgettagslength  0  valuebuildersettagsunsafebyteoperationsunsafewrapcellgettagsarray  cellgettagsoffset  cellgettagslength  columnbuilderaddqualifiervaluevaluebuilderbuild  code  contrast  increment  user  append  cell  custom  timestamp  would  better  make  behavior  consistent,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2516,update  htrace  42  htrace  perfectly  integrated  hbase  version  320  buggy  upgrade  4x  trivial  would  take  time  might  worth  keep  state  would  better  remove  course  doesnt  mean  tracing  would  useless  form  use  htrace  32  might  add  value  project  fixing  would  far  much  effort  based  decision  community  keep  htrace  update  version,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2517,refactor  clusteroptions  applying  code  base  far  clusterstatusoptions  clean  applied  code  base  refactoring  next  move,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2518,deprecate  kv  usage  mr  move  cell  30  0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0
2519,copy  loadincrementalhfiles  another  package  mark  old  one  deprecated  loadincrementalhfiles  depend  map  reduce,1,1,1,0,1,1,0,0,0,1,0,0,0,0,0,0,0
2520,use  filesystem  requires  hflush  hsync  append  etc  query  outputstream  capability  place  rely  underlying  filesystem  holding  promise  hflushhsync  importantly  wal  use  new  interface  provided  hdfs11644  fail  loudly  present  eg  s3  ec  mount  etc,1,1,0,0,0,1,0,0,1,0,1,0,0,0,0,0,0
2521,verifyrep  snapshot  need  restore  snapshot  mapper  following  method  stack  seems  like  mapper  task  restore  snapshot  verify  replication  snapshot  many  hfiles  take  long  time  restore  snapshot  cluster  took  30min  snapshot  restoring  verify  big  table  code  verifiermap  replicatedscanner  new  tablesnapshotscanner  tablesnapshotscannerinit  restoresnapshothelpercopysnapshotforscanner  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2522,coprocessor  design  improvement  follow  hbase17732  creating  new  jira  track  suggestion  came  review  httpsreviewsapacheorgr62141  blocker  done  separately  suggestion  apurtell  change  service  coprocessorgetservice  listservice  coprocessorgetservices  think  overstepped  offering  table  resource  management  via  interfacehttpsgithubcomapachehbaseblobmasterhbaseclientsrcmainjavaorgapachehadoophbasecoprocessorenvironmentjaval57  lot  internal  resource  type  couldshould  managed  way  left  implementor  perhaps  remove  table  ref  management  leave  well  checkin  finalized  design  doc  repo  httpsdocsgooglecomdocumentd1mpkm1crrvbmzl4dbqzrus8obyvnnhhr5it2yyhifxtgedit  fyi  stack  added  example  javadoc  coprocessor  base  interface  implement  one  new  design,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2523,add  new  split  algorithm  num  string  use  reversed  sequential  number  phone  number  first  part  rowkey  split  algorithm  create  presplit  table  specify  split  point  code  create  t1f  split  123456789  code,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
2524,bulk  incremental  load  existing  table  hbase48  bulk  load  new  tablemaybe  practicable  bulk  load  aganist  existing  table,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2525,move  transform  logic  filterlist  transformcell  method  avoid  extra  ref  question  cell  anoophbase  discussed  implement  filterkeyvalue  transformcell  method  following  avoid  saving  transformedcell  referencecell  state  filterlist  avoid  costly  cell  clone  code  returncode  filterkeyvaluecell  c  returncode  rc  null  forfilter  filter  subfilters  rc  mergereturncoderc  filterfilterkeyvaluec  return  rc  cell  transformcellcell  c  throw  ioexception  cell  transformed  c  forfilter  filter  subfilters  iffilterfilterkeyvaluec  include  line1  transformed  filtertransformcelltransformed  return  transformed  code  line  1  need  remember  return  code  subfilter  filterkeyvalue  include  returncode  need  transformcell  subfilter  new  boolean  array  introduced  filterlist  cost  maintaining  boolean  array  le  cost  maintaining  two  ref  question  cell,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2526,reduce  zk  request  split  log  observe  cluster  1000  node  hundred  node  abort  split  log  split  slow  find  regionserver  master  wait  zookeeper  response  need  reduce  zookeeper  request  pressure  big  cluster  1  reduce  request  rsznode  every  time  calculateavailablesplitters  get  rsznodes  child  zookeeper  cluster  huge  heavy  patch  reduce  request  2  regionserver  max  split  task  running  may  still  trying  grab  task  issue  zookeeper  request  sleep  wait  grab  task,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2527,promote  testacidguarantees  largetests  start  mini  cluster  make  faster  0,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,0,1
2528,improve  stability  splitting  log  fail  way  splitting  log  like  following  figure  httpsissuesapacheorgjirasecureattachment12905027splitlogicoldjpg  problem  outputsink  write  recovered  edits  splitting  log  mean  create  one  writerandpath  region  retain  end  cluster  small  number  region  per  r  large  create  many  hdfs  stream  time  prone  failure  since  datanode  need  handle  many  stream  thus  come  new  way  split  log  httpsissuesapacheorgjirasecureattachment12905028splitlogicnewjpg  try  cache  recovered  edits  exceeds  maxheapusage  pick  largest  entrybuffer  write  file  close  writer  finish  read  entry  memory  start  writeandclosethreadpool  start  certain  number  thread  write  buffer  file  thus  create  hdfs  stream  hbaseregionserverhlogsplitlogwriterthreads  set  biggest  benefit  control  number  stream  create  splitting  log  exceeds  hbaseregionserverwalmaxsplitters  hbaseregionserverhlogsplitlogwriterthreads  hbaseregionserverwalmaxsplitters  number  region  hlog  contains,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2529,classloader  load  hdfs  useful  adding  filter  classpath  without  restart  service  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2530,refactoring  regionstates  rsproceduredispatcher  working  bug  fix  part  first  time  understand  new  trying  make  sense  thing  improvement  way  adding  javadoc  comment  bug  serverstatenoderegions  hashset  there  synchronization  prevent  concurrent  addregionremoveregion  let  use  concurrent  set  instead  use  getregionsintransitioncount  directly  avoid  instead  getregionsintransitionsize  latter  copy  everything  new  array  waste  size  there  mixed  use  getregionnode  getregionstatenode  return  type  regionstatenode  changing  everything  getregionstatenode  similarly  rename  regionnode  fns  regionstatenode  regionstatenodetransitionstate  return  value  useless  since  always  return  first  param  minor  improvement,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
2531,remove  span  object  syncfuture  useless  0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2532,add  deferred  log  flush  attribute  htd  su  case  wed  like  able  default  sync  every  appended  edit  table  control  disable  sync  could  rely  table  like  meta  syncs  optional  log  syncer  timer  logsyncer  user  table  always  synced  example  set  10ms  timer  log  syncer  worse  case  lose  10ms  noncatalog  edits,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2533,make  cpenvgetconnection  return  facade  throw  unsupported  cp  call  close  follows  hbase19301  suggestion  zghaobac  prevent  cp  accidentally  closing  connection  returned  cpenvgetconnection  return  hosting  server  connection  throw  unsupportedexception  cp  call  close,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2534,add  proper  privilege  check  rsgroup  command  currently  listrsgroups  command  executed  user  inconsistent  list  command  listpeers  listpeerconfigs  add  proper  privilege  check  listrsgroups  command  privilege  check  added  gettablersgroup  getserverrsgroup  getrsgroup  command,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
2535,move  using  apache  common  collectionutils  bunch  unused  code  collectionutils  code  found  apache  common  library,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2536,add  excludenamespace  excludetablecfs  support  replication  peer  config  followup  issue  hbase16868  copied  comment  hbase16868  replicateall  flag  useful  avoid  misuse  replication  peer  config  cluster  config  excludenamespace  excludetablecfs  replication  peer  let  tell  use  case  two  online  serve  cluster  one  offline  cluster  mrspark  job  online  cluster  table  replicate  table  replicate  offline  cluster  table  need  olap  job  hundred  table  one  table  dont  need  replicate  offline  cluster  config  lot  table  replication  peer  config  add  new  config  option  excludetablecfs  need  config  one  table  dont  need  replicate  excludetablecfs  replicateall  flag  false  config  namespace  tablecfs  mean  namespacetables  need  replicate  peer  cluster  replicateall  flag  true  config  excludenamespace  excludetablecfs  mean  namespacetables  cant  replicate  peer  cluster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2537,add  timerange  support  checkandmutate  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2538,major  compaction  tool  basic  overview  tool  work  parameter  table  store  clusterconcurrency  timestamp  input  table  desired  concurrency  list  store  wish  major  compact  tool  first  check  filesystem  see  store  need  compaction  based  timestamp  provide  default  current  time  take  list  store  require  compaction  executes  request  concurrently  n  distinct  regionservers  compacting  given  time  thread  wait  compaction  complete  moving  next  queue  region  split  merge  move  happens  tool  ensures  region  get  major  compacted  well  help  u  two  way  limit  much  io  bandwidth  using  major  compaction  cluster  wide  guaranteed  tool  completes  requested  compaction  complete  regardless  move  merges  split,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2539,introduce  builder  replicationpeerconfig  make  immutable  introduce  new  replicationpeerconfigbuilder  deprecated  old  set  method  replicationpeerconfig  make  replicationpeerconfig  give  immutable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2540,revisit  method  replicationpeerconfigbuilder  add  4  method  replicationpeerconfigbuilder  putconfiguration  putallconfiguration  putpeerdata  putallpeerdata  meanwhile  remove  setconfiuration  serpeerdata  replicationpeerconfigbuilder  previous  replicationpeerconfig  didnt  support  setconfiuration  serpeerdata  previous  code  used  getconfigurationput  putall  add  configuration  add  method  keep  consistent  old  usage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2541,bufferedmutatorimplmutate  wait  result  ap  order  throw  failed  mutation  currently  bmimutate  doesnt  wait  result  ap  error  stored  ap  way  return  error  user  calling  flush  catch  exception  nonintuitive  feel  bmimutate  wait  result  say  user  parse  exception  thrown  bmmutate  get  failed  mutation  also  remove  global  error  ap,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2542,unit  test  full  wal  replay  cycle  currently  test  log  splitting  master  current  role  never  try  storerunreconstructionlog  good  time  unit  test  whole  cycle,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1
2543,remove  baselogcleanerdelegate  deprecated  islogdeletablefilestatus  use  isfiledeletablefilestatus  instead  mark  islogdeletablefilestatus  deprecated  update  serverside  code  use  isfiledeletablefilestatus,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
2544,use  regioninfo  directly  instead  identifier  namespace  getting  wal  needed  synchronous  replication  need  determine  whether  region  use  special  wal  writes  two  filesystems  think  general  simplification  apply  master  branch2  first,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2545,split  testhcm  several  smaller  test  take  much  time  finish  especially  timeout  related  test  move  test,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
2546,put  object  simple  read  method  checking  already  added  data  added  put  object  simple  method  equivalent  add  tell  keyvalue  object  already  added  familymap  would  make  sense  add  getter  boolean  method  2  ease  use  readsearch  familymap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2547,rowmutations  follow  fluent  pattern  row  ops  including  put  delete  get  scan  fluent  interface  also  changing  return  type  void  rowmutations  wont  break  api  bc  unless  someone  interest  void  object,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2548,break  dependency  wal  constructor  replication  implementing  synchronous  replication  found  need  depend  replication  wal  even  pain,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,1
2549,revisit  timestamp  usage  metatableaccessor  totally  mess  make  confusing  reimplementing  serial  replication  feature  let  clean  first,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2550,redesign  single  instance  pool  cleanerchore  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2551,starting  hquorumpeer  try  match  1  address  many  new  user  hit  issue  default  hostname  returned  dnsgetdefaulthost  one  configured  hbasezookeeperquorum  get  confusing  debug  instead  try  match  nonlocal  address  find,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2552,accesscontrolclient  api  enhancement  background  currently  hbase  acls  retrieved  based  namespace  table  name  direct  api  available  retrieve  permission  based  namespace  table  name  column  family  column  qualifier  specific  user  client  write  application  logic  multiple  step  retrieve  acls  based  table  name  column  name  column  qualifier  specific  user  hbase  enhance  accesscontrolclient  apis  simplyfy  accesscontrolclient  api  extended  following  apis  retrieve  permission  based  namespace  table  name  column  family  column  qualifier  specific  user  permission  retrieved  based  following  input  namespacetable  already  available  namespacetable  username  table  cf  table  cf  username  table  cf  cq  table  cf  cq  username  scope  retrieving  permission  follows  existing  2  validate  whether  user  allowed  perform  specified  operation  particular  table  useful  check  user  privilege  instead  getting  acd  client  operation  user  validation  performed  based  following  input  table  cf  cq  username  action  scope  validating  user  privilege  user  perform  self  check  without  special  privilege  admin  privilege  required  perform  check  user  example  suppose  two  user  usera  userb  scenario  usera  want  check  whether  usera  privilege  perform  mentioned  action  usera  dont  need  admin  privilege  self  query  usera  want  check  whether  userb  privilege  perform  mentioned  action  usera  must  admin  superuser  privilege  trying  query  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2553,use  configuration  instead  hbaseconfiguration  hbaseconfiguration  extends  configuration  add  functionality  function  hashcode  really  refactored  hadoop  configuration  think  placesespecially  client  side  hbase  method  class  accept  configuration  rather  hbaseconfiguration  creation  configuration  right  file  hbasesite  hbasedefault  encapsulated  private  method  public  static  one  issue  arisen  nutchhbase  patch  include  nutch  configuration  hbase  configuration  moreover  people  may  want  include  separate  projectspecific  configuration  file  configuration  without  need  dependent  hbaseconfiguration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2554,alternate  indexed  hbase  implementation  speed  scan  adding  index  region  rather  secondary  table  purpose  goal  indexed  hbase  contrib  speed  scan  indexing  hbase  column  indexed  hbase  ihbase  different  indexed  table  transactional  hbase  ithbase  index  ithbase  fact  hbase  table  using  indexed  column  value  row  key  ihbase  creates  index  region  level  difference  summarized  global  ordering  ithbase  yes  ihbase  comment  ihbase  index  region  flip  side  global  ordering  compatibility  good  old  hregion  result  coming  back  row  order  value  order  thbase  full  table  scan  ithbase  ihbase  comment  ithbase  partial  scan  index  table  ihbase  support  specifying  startend  row  limit  number  scanned  region  multiple  index  usage  ithbase  ihbase  yes  comment  ihbase  take  advantage  multiple  index  scan  ihbase  idxscan  object  accepts  expression  allows  intersection  unison  several  indexed  column  criterion  extra  disk  storage  ithbase  yes  ihbase  comment  ihbase  index  created  region  startsflushes  require  extra  storage  extra  ram  ithbase  yes  ihbase  yes  comment  ihbase  index  memory  hence  increase  memory  overhead  thbase  index  increase  number  region  region  server  support  thus  costing  memory  parallel  scanning  support  ithbase  ihbase  yes  ithbase  index  table  need  consulted  get  issued  matching  row  behavior  ihbase  perceived  client  different  regular  scan  hence  support  parallel  scanning  seamlessly  parallel  get  implemented  speedup  ithbase  scan  ihbase  outperform  ithbase  1  flexible  support  range  query  multiindex  query  b  support  different  type  byte  array  2  le  overhead  ithbase  pay  least  two  table  roundtrips  one  index  table  main  table  3  quicker  index  expression  evaluation  ihbase  using  dedicated  index  data  structure  ithbase  using  regular  hregion  scan  facility  implementation  note  •  index  storefilesevery  index  scan  performs  full  memstore  scan  indexing  memstore  implemented  scanning  memstore  prove  performance  bottleneck  •  index  expression  evaluation  performed  using  bit  setsthere  two  type  bitsets  compressed  expanded  index  typically  store  compressed  bitset  expression  evaluator  probably  use  expanded  bitset  todo  patch  change  hbase  core  instantiate  default  hregion  fix  bug  filter  would  like  add  contrib  package  020  branch  time  0203  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2555,improve  snapshot  manifest  copy  exportsnapshot  exportsnapshot  need  copy  snapshot  manifest  destination  cluster  first  setowner  setpermission  path  done  one  thread  lead  long  time  submit  job  snapshot  big  tried  make  processing  parallel  reduce  total  time  submitting  dramatically,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2556,break  wal  reader  writer  impl  hlog  use  configuration  reflection  bind  hlog  reader  writer  runtime  allow  user  chose  different  hlog  readerwriter  implementation  pair,1,0,1,0,1,0,0,0,1,1,0,0,0,0,0,1,0
2557,br  delete  command  enhancement  make  command  useable  currently  user  need  provide  list  backup  id  delete  would  nice  convenient  option  deleting  backup  older  xxx  day  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2558,validate  pre20  coprocessors  hbase  20  coprocessors  api  changed  recently  give  tooling  user  determine  use  previous  coprocessors  safely  tool  try  load  coprocessors  current  classpath  ensuring  class  reference  classpath  check  previously  removed  coprocessor  method  version  check  method  signature  code  reference  checked  version,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2559,colocate  recovered  edits  directory  hbasewaldir  investigation  hbase20723  realized  wouldnt  get  best  performance  hbasewaldir  configured  different  fast  medium  hbase  rootdir  wrt  recovered  edits  since  recovered  edits  directory  currently  rootdir  setup  may  result  fast  recovery  region  server  failover  issue  find  proper  hopefully  backward  compatible  way  colocating  recovered  edits  directory  hbasewaldir,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2560,modify  preupgrade  coprocessor  validator  support  table  level  coprocessors  0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2561,auth  support  keytab  login  hbase  client  therere  lot  question  connect  kerberized  hbase  cluster  hbaseclient  api  usermail  slack  channel  hbaseclientkeytabfile  hbaseclientkeytabprincipal  already  existed  code  base  used  canary  issue  make  use  two  configs  support  clientside  keytab  based  login  issue  resolved  hbaseclient  directly  connect  kerberized  cluster  without  changing  code  long  hbaseclientkeytabfile  hbaseclientkeytabprincipal  specified,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2562,separate  region  server  report  request  new  handler  master  rpc  scheduler  rpc  request  executed  thread  pool  task  separate  r  report  request  new  handler,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2563,separate  config  block  size  log  splitting  write  hlog  since  block  size  recovered  edits  hlog  right  set  large  value  block  size  name  node  may  able  assign  enough  space  log  splitting  set  large  value  hlog  block  size  help  reduce  number  region  server  asking  new  block  thus  think  separate  config  block  size  necessary,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2564,hbasetestingutilitystartminicluster  use  builder  pattern  currently  13  startminicluster  method  set  mini  cluster  im  surprised  future  good  support  different  combination  optional  parameter  pick  one  carefully  still  wondering  default  value  parameter  add  new  option  may  bring  new  method  one  solution  use  builder  pattern  create  class  miniclusteroptions  along  static  class  miniclusteroptionsbuilder  create  new  method  startminiclusterminiclusteroptions  master  delete  old  13  method  branch2  deprecate  old  13  method  thought,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2565,improve  snapshot  performance  temporary  snapshot  directory  rootdir  s3  using  apache  hbase  snapshot  feature  used  make  point  time  recovery  hbase  creates  manifest  file  region  file  referenced  user  restores  snapshot  hbases  s3  storage  mode  developer  store  data  offcluster  amazon  s3  however  utilizing  s3  file  system  inefficient  operation  namely  renames  hadoop  ecosystem  application  use  atomic  rename  method  committing  data  however  s3  rename  separate  copy  delete  every  file  longer  atomic  fact  quite  costly  addition  put  deletes  s3  latency  issue  traditional  filesystems  encounter  manipulating  region  snapshot  consolidate  single  manifest  hbase  s3  user  significant  amount  region  put  deletes  renames  final  commit  stage  snapshot  become  bottleneck  causing  snapshot  take  many  minute  even  hour  complete  purpose  patch  increase  overall  performance  snapshot  utilizing  hbase  s3  use  temporary  directory  snapshot  exists  traditional  filesystem  like  hdfs  circumvent  bottleneck,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2566,add  ability  hbase  canary  ignore  configurable  number  zookeeper  node  running  orgapachehadoophbasetoolcanary  args  zookeeper  treatfailureaserror  canary  try  get  znode  zookeeper  server  ensemble  server  unavailable  unresponsive  canary  exit  failure  code  use  canary  gauge  server  health  alert  accordingly  strict  example  5node  zookeeper  cluster  one  node  safe  expected  rolling  upgradespatches  request  allow  canary  take  another  parameter  codejava  permittedzookeeperfailures  ncode  n1  5node  zookeeper  ensemble  example  canary  still  pas  4  zookeeper  node  reachable  fail  3  fewer  reachable  first  jira  posting  sorry  messed  anything,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2567,save  log  string  churn  wal  splitter  skipping  early  log  dir  trivial  change  splitlogmanager  save  u  log  line  least  per  wal  dir  go  split  also  save  notneeded  churn  slm,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2568,split  tableinputformatscan  individual  test  done  split  hbase8326  split  test  two  part  still  bit  slow  split  several  test  increase  parallelism  make  mvn  test  run  faster,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
2569,refactor  regionmover  1  move  connection  admin  regionmovers  member  variable  need  create  connection  many  time  2  use  trywithresource  reduce  code  3  use  servername  instead  string  4  dont  use  deprecated  method  5  remove  duplicate  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2570,make  refreshhfilesclient  runnable  user  enables  hbasecoprocessorregionclasses  refreshhfilesendpoint  user  also  run  client  tool  runner  classcli  call  refresh  hfiles  directly,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
2571,hook  replication  issue  getting  hook  mdc  replication  core  hbase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2572,add  html  version  default  hbasesitexml  hadoop  getting  started  page  html  version  default  configuration  coresitexml  hdfssitexml  mapredsitexml  would  useful  page  hbasedefaultxml  easy  reference  without  flipping  editor  patch  creates  html  file  default  hbasedefaultxml  usign  xslt  new  target  confgenhtml  added  sample  run  ant  confgenhtml  buildfile  buildxml  init  confgenhtml  xslt  processing  optworkspaceremotewshbaseconfhbasedefaultxml  optworkspaceremotewshbasebuildhbasesitehtml  xslt  loading  stylesheet  optworkspaceremotewshbasedocsconf2htmlxsl  echo  html  format  default  hbase  configuration  available  optworkspaceremotewshbasebuildhbasesitehtml  build  successful,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2573,hr  report  master  hmsg  available  still  take  lot  time  client  see  split  region  move  around  default  pe  take  around  4  second  creating  table  take  bit  2  second  remember  discussion  stack  hrsrun  suppose  sleep  message  send  turn  sleep,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2574,mr  copy  table  discussed  hbase2197  need  way  copy  table  one  cluster  another  requires  creating  job  modifying  tof,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2575,compaction  event  written  hlog  sequence  compaction  look  like  compact  region  new  file  write  compacted  region  entry  hlog  delete  old  file  deal  case  r  paused  step  1  2  region  since  reassigned,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
2576,support  hadoop  020  021  022  since  hadoop  021  isnt  going  well  supported  lot  user  may  wish  stick  020  next  hbase  major  release  support  020  021  hdfs265  support  swapped  hdfs200  running  hdfs  020  cluster  without  patchset  shouldnt  supported,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2577,stargate  multiuser  mode  support  optional  operating  mode  simple  user  isolation,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
2578,hfile  memstore  maintain  minimum  maximum  timestamps  order  fix  hbase1485  hbase29  would  helpful  hfile  memstore  track  maximum  minimum  timestamps  following  nice  property  straight  get  entry  already  found  timestamp  x  x  hfilemaxtimestamp  hfile  doesnt  need  checked  thus  current  fast  behavior  get  maintained  use  strictly  increasing  timestamps  correct  behavior  sometimes  write  outoforder  scan  latest  timestamp  storage  used  decide  cell  win  even  timestamp  cell  equal  essence  rather  comparing  timestamps  instead  able  compare  tuples  row  timestamp  storagemaxtimestamp  general  mintimestampstorage  maxtimestampstorage  b  storage  flushed  storage  b,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2579,transactional  contrib  correctly  handle  avoid  case  writes  occur  millisecond  patch  fix  issue  putsdeletes  occur  timestamp  indexing  layer  avoid  delete  followed  put  row  index  update  row  put  transactional  layer  correctly  handled  put  put  scan  way  scan  see  last  put  even  timestamp  remove  sleep  fix  putputscan  transactional  test  run  many  time  sure  hit  case  millisecond  also  small  cleanup  null  handling  failfast  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2580,refactoring  tablerecordreader  mapred  mapreduce  reuse  outside  scope  inputsplit  recordreader  storing  tfidf  hbase  lucenehbase  project  need  scan  key  across  table  retrieve  columnar  value  quite  amount  logic  reused  tablerecordreader  purpose  refactored  tablerecordreader  protected  inner  class  public  class  outside  created  impl  class  actual  work  without  dependency  hadopmapreduce  package  recordreader  retaining  implementation  reused  across  library  thing  mapred  mapreduce  package  let  know  thought,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0
2581,stargate  performanceevaluation  version  pe  work  stargate  patch  includes  number  fix  multiuser  mode  client  library  also,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2582,stargate  review  jersey  json  dependency  thomas  koch  hbase2383  quote  stargate  lib  folder  contains  asm31jar  jacksonasl094jar  jerseycore110eajar  jerseyserver110eajar  persistenceapi10jar  commonscodec13jar  jaxbimpl2110jar  jerseyjson110eajar  jsr311api11jar  protobufjava210jar  seems  following  jar  either  used  used  test  asm31jar  jacksonasl094jar  jaxbimpl2110jar  following  already  debian  commonscodec13jar  persistenceapi10jar  libgeronimojpa30specjava  1111  protobufjava210jar  libprotobufjava  2301  leaf  following  packaged  jerseycore110eajar  jerseyserver110eajar  jerseyjson110eajar  httpsjerseydevjavanet  jsr311api11jar  httpsjsr311devjavanet  upstream  version  jersey  1151  would  stargate  work  version  javanet  doesnt  seem  release  tarballs  could  obtain  source  jar  httpdownloadjavanetmaven2comsunjerseyjerseybundle1151jerseybundle1151sourcesjar  httpdownloadjavanetmaven2javaxwsrsjsr311api111jsr311api111sourcesjar  quote  jar  stargate  lib  directory  added  per  getting  started  recipe  jersey  wiki  task  update  jersey  1151  remove  jsonorg  json  dependency  substitute  required  prune  unnecessary  jar,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
2583,improving  filter  api  allow  modification  keyvalue  list  filter  stand  filter  interface  allows  filtering  filterfilterallremaining  true  indicates  scan  false  keep  going  filterfilterrowkeybyteintint  true  drop  row  false  also  call  filterfilterkeyvaluekeyvalue  true  drop  keyvalue  filterfilterrow  last  chance  drop  entire  row  based  sequence  filtervalue  call  eg  filter  row  doesnt  contain  specified  column  would  useful  allow  additional  api  form  step  prune  list  keyvalues  sent  implementing  additional  filterfilterrowlistkeyvalue  would  allow  user  write  custom  filter  api  drop  unnecessary  keyvalues  according  userdefined  rule,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
2584,concurrent  flushers  hlog  sync  using  hdfs895  hdfs895  change  hflush  able  run  concurrently  multiple  thread  flush  concurrent  writes  file  need  rip  outamend  group  commit  code  bit  take  advantage,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2585,improvement  prewarm  meta  cache  client  couple  different  use  case  cause  storm  read  meta  startup  example  large  mr  job  cause  map  task  hit  meta  since  start  empty  cache  couple  possible  improvement  proposed  mr  job  could  ship  copy  meta  table  distributedcache  client  could  prewarm  cache  large  scan  meta  table  instead  random  read  miss  miss  could  fetch  ahead  number  row  meta,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2586,add  admin  create  table  start  end  key  params  desired  number  region  would  adornment  create  table  precreates  n  region  new  table  came  yesterday  hbase  hackathon3,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2587,allow  record  filtering  selected  row  key  value  hbase  export  desirable  add  record  filtering  capability  hbase  export  following  code  example  scan  byte  prefix  bytestobytesargs5  args5startswith  ssetfilternew  rowfiltercompareopequal  new  regexstringcomparatorargs5  else  ssetfilternew  prefixfilterprefix,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2588,refactor  storefile  code  currently  storefile  code  thin  wrapper  around  hfilereader  addition  bloomfilters  feature  operate  hfile  layer  need  clarify  difference  storefile  hfile  end  need  refactor  storefilereader  code  code  interoperates,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
2589,read  passed  specified  time  range  seek  next  column  processing  stream  keyvalues  scanquerymatcher  check  timestamp  current  kv  specific  timerange  currently  check  range  returning  skip  outside  range  continuing  check  within  range  check  actually  return  skip  stamp  greater  timerange  nextcol  stamp  le  timerange  know  wont  take  anymore  column  current  column  timerange,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2590,cleanup  array  v  list  scanner  array  list  used  inconsistently  working  set  scanner  throughout  keyvalueheap  memstore  storescanner  etc  pick  one  use  consistently,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2591,add  ability  easily  extend  hlog  action  id  like  add  ability  extend  hlog  action  like  log  rolling  log  archiving  using  listener  one  could  specified  hlog  creation  others  could  added  later,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2592,rest  module  test  use  deprecated  foundation  rest  module  unit  test  based  hbaseclustertestcase  deprecated  update  use  junit4  hbasetestingutility,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
2593,add  atomic  checkanddelete  support  currently  hbase  support  atomic  checkandput  operation  individual  row  would  useful  also  support  atomic  checkanddelete  added  support  atomic  checkanddelete  trunk  provide  corresponding  patch  tonight  merge  upstream  change  last  day,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2594,make  hlog  file  name  unique  currently  hlog  archiving  thread  add  another  timestamp  ensure  file  name  unique  ugly  make  harder  track  hlogs  movement  outside  like  replication  instead  could  use  uuid  file  name  discussing  stack  need  keeping  timestamp  file  name  think  cant  get  rid  since  need  read  hlogs  sequence  splitting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2595,harmonize  get  delete  operation  work  hbase2400  implementing  deletes  avro  server  felt  quite  awkward  rather  clean  api  get  object  allows  restriction  result  set  row  expressed  addcolumn  addfamily  settimestamp  settimerange  setmaxversions  setfilters  delete  object  hide  semantics  behind  various  constructor  deletecolumns  deletefamily  naive  vantage  point  see  reason  would  bad  idea  mimic  get  api  exactly  though  could  quite  possibly  missing  something  thought,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2596,speed  rest  test  meantime  hbase2564  rest  test  could  lot  faster  currently,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2597,refactor  hlog  splitlog  hbase2437  continued  break  split  code  new  class  suggestion  made  review  hbase2437  untangle  hlog  split  code  moving  split  code  support  hlog  distinct  class  see  early  todd  lipcon  comment  httpreviewhbaseorgr74,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0
2598,compaction  request  prioritized  prevent  blocking  testing  write  capacity  4  machine  hbase  cluster  getting  long  frequent  client  pause  attempted  load  data  looking  problem  wed  get  relatively  large  compaction  queue  region  hit  hbasehstoreblockingstorefiles  limit  would  get  block  client  compaction  request  would  get  put  back  queue  waiting  many  le  important  compaction  client  basically  stuck  point  compaction  done  prioritizing  compaction  request  allowing  request  blocking  action  go  first  would  help  solve  problem  see  problem  looking  log  file  youll  first  see  event  many  hlog  put  lot  request  compaction  queue  noformat  20100525  105326570  info  orgapachehadoophbaseregionserverhlog  many  hlogs  logs33  maxlogs32  forcing  flush  22  region  responsecountsrs6ezzltdwhgitwhy1274232223324  responsesrs0qhkl5rumpcbx3k12742130572421274513189592  responsesrs1anyntegjzvishw12742177419  211274511001873  responsesrs1hq4ug5bdolayue12742167574251274726323747  responsesrs1y7sbqstszrye7a12743286978381274478031930  responsesrs1zh5tb5odw4bvlm12742162398941274538267659  responsesrs3bhc4kyom3q72yc12742905469871274502062319  responsesrs3ra9babmaxfavbk127421457  99581274381552543  responsesrs6sdrgnuyyld3or612742199411551274385453586  responsesrs8agcemwbi6mzuoq12743068574291274319602718  responsesrs8c8t9dn47uwtg1s12742153817651274289112817  responsesrs8j5wmdmkmjxzk6g12742995938611274494738952  responsesrs8e5sz0hefpadb6c1274288  6414591274495868557  responsesrs8rjcnmbxpkzi89612743069816841274403047940  responsesrs9fs3vedcyrf0kx212742459713311274754745013  responsesrs9ozgptxo31npv3c12742140277691274396489756  responsesrsa3fdo2jhqwuy37c12742092286601274399508186  responsesrsa3ljvxwtj29mhva12742  noformat  see  many  log  file  noformat  20100525  105331364  debug  orgapachehadoophbaseregionservercompactsplitthread  compaction  requested  region  responsesindex1274799047787rcbkrgxx0fdwjpso1274804575862783020138  regionserver19216808160020cacheflusher  20100525  105332364  warn  orgapachehadoophbaseregionservermemstoreflusher  region  responsesindex1274799047787rcbkrgxx0fdwjpso1274804575862  many  store  file  putting  back  end  flush  queue  noformat  lead  noformat  20100525  105327061  info  orgapachehadoophbaseregionserverhregion  blocking  update  ipc  server  handler  60  60020  region  responsesindex1274799047787rcbkrgxx0fdwjpso1274804575862  memstore  size  1280m  blocking  1280m  size  20100525  105327061  info  orgapachehadoophbaseregionserverhregion  blocking  update  ipc  server  handler  84  60020  region  responsesindex1274799047787rcbkrgxx0fdwjpso1274804575862  memstore  size  1280m  blocking  1280m  size  20100525  105327065  info  orgapachehadoophbaseregionserverhregion  blocking  update  ipc  server  handler  1  60020  region  responsesindex1274799047787rcbkrgxx0fdwjpso1274804575862  memstore  size  1280m  blocking  1280m  size  noformat  compaction  split  done  flush  able  happen  unblocks  ipc  allowing  writes  continue  unfortunately  process  take  upwards  15  minute  specific  case  shown  log  took  4  minute,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2599,master  rewrite  cleanup  090  parent  issue  master  change  targeted  090  release  change  done  part  issue  grew  work  done  hbase2485  move  region  transition  zk  addition  work  issue  include  general  hmaster  zookeeper  refactorings  cleanup,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,1,1
2600,make  hbase2694  replicationfriendly  hbase2694  good  bit  reworking  around  zk  removedchanged  piece  needed  replication  work  correctly  mainly  2  thing  listznodes  need  offer  version  take  watcher  else  registering  listener  much  pain  since  filter  lot  stuff  based  path  event  lot  important  new  multiton  implemented  zkw  prevents  starting  multiple  cluster  inside  jvm  since  master  would  use  name  provide  patch  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2601,provide  strong  authentication  secure  rpc  engine  hbase  rpc  code  orgapachehadoophbaseipc  originally  forked  hadoop  rpc  class  performance  tweak  added  optimization  come  cost  keeping  hadoop  rpc  change  however  bug  fix  improvementsnew  feature  particular  impact  implement  security  feature  hbase  see  hbase1697  hbase2016  secure  hadoop  implementation  hadoop4487  relies  heavily  rpc  change  support  client  authentication  via  kerberos  securing  mutual  authentication  clientserver  connection  via  sasl  making  use  builtin  hadoop  rpc  class  gain  u  piece  free  secure  hbase  im  proposing  drop  hbase  forked  version  rpc  convert  direct  use  hadoop  rpc  working  contribute  important  fix  back  upstream  hadoop  core  based  review  hbase  rpc  change  key  divergence  seem  hbaseclient  added  use  tcp  keepalive  hbase1754  made  connection  retries  sleep  configurable  hbase1815  prevent  npe  socket  null  due  creation  failure  hbase2443  hbaserpc  mapping  method  name  code  removed  hbase2219  hbaseserver  use  tcp  keep  alives  hbase1754  oome  server  trigger  abort  hbase1198  hbaseobjectwritable  allows  list  serialization  includes  class  code  mapping  hbase328  proposed  process  1  open  issue  patch  hadoop  core  important  fixesadjustments  hbase  rpc  hbase1198  hbase1815  hbase1754  hbase2443  plus  pluggable  objectwritable  implementation  rpcinvocation  allow  use  hbaseobjectwritable  2  ship  hadoop  version  rpc  patch  applied  ideally  avoid  another  copynpaste  code  fork  subject  ability  isolate  change  impacting  hadoop  internal  rpc  wire  format  3  hadoop  core  patch  applied  drop  back  plain  vanilla  hadoop  version  realize  many  different  opinion  proceed  hbase  rpc  im  hoping  issue  kick  discussion  best  approach  might  motivation  maximizing  reuse  authentication  connection  security  work  thats  already  gone  hadoop  core  ill  put  together  set  patch  around  1  2  obviously  need  consensus  around  move  forward  im  missing  difference  hbase  hadoop  rpc  please  list  well  discus,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2602,create  better  way  chain  log  cleaner  stack  review  hbase2223  quote  implementation  know  implementation  cant  chain  decision  class  class  say  soon  decision  class  say  exit  chain  case  first  chain  would  ttl  decision  would  one  third  would  snapshotting  decision  dont  chain  part  patch  please  open  issue  implement  quote,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
2603,utilize  rowcol  bloom  filter  multiple  column  within  family  requested  get  noticed  following  snippet  storefilejavascannershouldseek  code  switchbloomfiltertype  case  row  key  row  break  case  rowcol  columnssize  1  byte  col  columnsfirst  key  bytesaddrow  col  break  fallthrough  default  return  true  code  columnssize  1  currently  dont  take  advantage  bloom  filter  optimize  check  bloom  column  none  column  present  bloom  avoid  opening  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2604,hbck  ability  repair  basic  problem  right  hbck  utility  detect  issue  region  deployment  cant  fix  able  handle  basic  thing  like  closing  one  side  double  assignment  readding  something  meta  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2605,small  cleanup  orgapachehadoophbaseregionserverwal  since  touching  area  probably  better  leave  cleaner  state  non  deprecated  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2606,retain  assignment  information  cluster  shutdownstartup  hbase57  want  consider  block  location  region  assignment  important  cluster  startup  currently  lose  locality  region  assignment  randomly  jira  shotterm  solution  cluster  startup  problem  retaining  assignment  information  cluster  shutdown  using  next  cluster  startup,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2607,hlog  preparation  cleanup  done  updatelock  major  slowdown  something  ive  seen  quite  often  production  environment  quote  20100816  161727104  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000385321  whose  highest  sequenceedit  id  64837079950  20100816  161727286  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000392770  whose  highest  sequenceedit  id  64837088260  20100816  161727452  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000399300  whose  highest  sequenceedit  id  64837096566  20100816  161727635  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000406997  whose  highest  sequenceedit  id  64837104865  20100816  161727827  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000413803  whose  highest  sequenceedit  id  64837113153  20100816  161727993  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000421709  whose  highest  sequenceedit  id  64837121467  20100816  161728160  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000427333  whose  highest  sequenceedit  id  64837129775  20100816  161728432  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000434365  whose  highest  sequenceedit  id  64837138074  20100816  161728518  info  orgapachehadoophbaseregionserverhlog  removing  old  hlog  file  hbaselogsrs22600201280909840873hlogdat1282000440347  whose  highest  sequenceedit  id  64837146376  20100816  161728612  warn  orgapachehadoophbaseregionserverhlog  ipc  server  handler  39  60020  took  1801ms  appending  edit  hlog  editcount0  20100816  161728615  warn  orgapachehadoophbaseregionserverhlog  ipc  server  handler  37  60020  took  1804ms  appending  edit  hlog  editcount1  20100816  161728615  warn  orgapachehadoophbaseregionserverhlog  ipc  server  handler  25  60020  took  1805ms  appending  edit  hlog  editcount2  20100816  161728619  warn  orgapachehadoophbaseregionserverhlog  ipc  server  handler  41  60020  took  1875ms  appending  edit  hlog  editcount50  20100816  161728619  warn  orgapachehadoophbaseregionserverhlog  ipc  server  handler  24  60020  took  1876ms  appending  edit  hlog  editcount51  20100816  161728619  warn  orgapachehadoophbaseregionserverhlog  ipc  server  handler  48  60020  took  1881ms  appending  edit  hlog  editcount54  quote  looking  hlogrollwriter  roll  cleanup  unused  hlog  file  updatelock  block  appenders  shown  first  part  lock,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2608,add  threadlocal  behavior  htable  pool  welldocumented  fact  hbase  table  client  viz  htable  threadsafe  hence  recommendation  use  htablepool  threadlocal  manage  access  table  downside  latter  requires  user  reinvent  wheel  term  mapping  table  name  table  b  force  user  maintain  threadlocal  object  ideally  would  nice  could  make  htablepool  handle  threadlocal  object  well  way  becomes  one  stop  shop  clientside  table  also  insulates  user  threadlocal  object  propose  way  generalize  htablepool  underlying  pool  type  either  reusable  threadlocal  make  possible  introdudce  concept  sharedmap  essentially  map  key  collection  value  element  managed  pool  effect  collection  act  shared  pool  resource  access  closely  controlled  dictated  particular  semantics  pool  furthermore  simplify  construction  htablepools  added  couple  parameter  viz  hbaseclienthtablepooltype  hbaseclienthbasepoolsize  control  default  behavior  htablepool  case  size  pool  set  nonzero  positive  number  used  cap  number  resource  pool  may  contain  given  key  size  integermaxvalue  interpreted  mean  unbounded  pool  currently  sharedmap  support  following  type  pool  threadlocalpool  represents  pool  build  threadlocal  class  essentially  bind  resource  thread  accessed  reusablepool  represents  pool  build  linkedlist  class  essentially  allows  resource  checked  point  temporarily  removed  pool  resource  longer  required  returned  pool  order  reused  roundrobinpool  represents  pool  store  resource  arraylist  loadbalances  access  resource  returning  different  resource  every  time  given  key  looked,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2609,increment  multiple  column  row  currently  way  multiple  increment  single  row  one  rpc  jira  adding  htable  hregioninterface  method  increment  multiple  column  within  single  row,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2610,refactor  zk  logging  trunk  le  identifier  log  message  help  debugging  currently  logging  done  zookeeperwatcher  add  zkw  identifier  front  log  message  happens  logging  done  class  zkutil  zkconfig  make  cant  turn  logging  using  log4j  config  nothing  also  zk  give  connection  sessionid  tie  zk  log  hbase  log  include  sessionid  zkw  identifier  help  debugging  especially  using  minihbasecluster  client  master  r  zk  server  logging  file,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2611,make  bulk  assignment  cluster  startup  run  faster  currently  hbase3018  come  bulk  assignment  plan  sorted  server  spawn  thread  assign  region  per  server  assigning  parallel  work  still  slow  enough  look  slower  old  assignment  wed  lump  n  region  time  able  pas  regionserver  region  open  one  rpc  need  figure  keep  zk  state  regionserver  processing  big  lot  region  look  little  awkward  since  currently  open  handler  open  region  notion  ping  waiting  run  able  start  cluster  fast  important  time  take  major  upgrade  longer  take  spin  longer  downtime,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2612,unify  code  majorminor  compaction  today  minor  compaction  process  deletes  purge  old  version  etc  major  compaction  rationale  probably  save  cpu  evaluate  major  compaction  logic  indeed  run  significantly  slower  unifying  minor  compaction  thing  major  compaction  advantage  key  deletedupdated  repeatedly  fact  deletesoverwrites  processed  minor  compaction  make  subsequent  minor  compaction  expensive  total  amount  data  keep  growing  well  fewer  bug  logic  symmetric  possible  bug  ttl  enforcement  version  enforcement  etc  could  cause  behavior  different  major  compaction  keeping  logic  mean  bug  get  caught  earlier  note  still  need  one  difference  two  scheme  delete  marker  compaction  doesnt  compact  file  still  need  leave  delete  marker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2613,add  ability  multiple  zk  server  quorum  minizookeepercluster  test  writing  interesting  thing  happen  zk  quorum  multiple  server  one  dy  testing  cluster  turned  bug  hbase  interaction  zk  would  good  add  ability  multiple  zk  server  unit  test  able  kill  individually,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2614,add  ability  multiple  master  localhbasecluster  test  writing  really  able  unit  test  new  master  properly  need  able  multiple  master  running  within  single  logical  cluster  expose  method  like  getactivemaster  isactivemaster  well  simple  way  kill  individual  master  kill  active  master,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2615,allow  disable  automatic  shipping  dependency  jar  mapreduce  job  since  hbase3001  tablemapreduceutilinittablemapreducejob  automatically  upload  hbase  jar  needed  execute  map  reduce  job  case  building  job  jar  using  maven  assembly  plugin  way  necessary  dependency  job  jar  case  default  behavior  hbase  cause  needle  upload  work  also  uploads  hadoopcore  necessary  therefore  propose  add  variant  inittablemapreducejob  method  extra  boolean  argument  disable  automatic  adding  dependency  jar  attach  patch  proposed  change  note  everything  work  optimization,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2616,rest  content  transcoding  reasonable  user  request  support  decoding  base64  encoded  value  rawbinary  servicing  get  request  accept  header  applicationoctetstream  introduce  table  schema  attribute  column  family  instructs  rest  gateway  perform  input  andor  output  transcoding  base64binary  get  vice  versa  put  post  first  supported  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2617,replication  add  ability  enabledisable  stream  jira  initially  scope  hbase2201  pushed  since  low  value  compared  required  effort  want  ship  0900  rather  soonish  need  design  way  enabledisable  replication  stream  determinate  fashion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2618,sanity  date  time  check  region  server  join  cluster  introduce  sanity  check  r  join  cluster  make  sure  clock  isnt  far  skew  rest  cluster  r  time  far  skew  master  would  prevent  joining  r  would  die  log  error  r  even  small  difference  time  cause  huge  problem  due  bhase  store  value  timestamps  according  jd  servermanager  already  code  hserverinfo  info  new  hserverinfoserverinfo  checkisdeadinfogetservername  startup  checkalreadysamehostportinfo  recordnewserverinfo  false  null  code  new  check  would  fit  nicely  jg  suggests  add  clockoutofsynclike  exception,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
2619,drop  root  instead  store  meta  location  directly  zookeeper  rather  storing  root  region  location  zookeeper  going  root  reading  meta  location  store  meta  location  directly  zookeeper  purpose  root  region  bigtable  paper  support  multiple  meta  region  currently  explicitly  support  single  meta  region  translation  current  code  single  root  location  single  meta  location  simple  longterm  seems  reasonable  could  store  several  meta  region  location  zk  there  discussion  hbase1755  actually  moving  meta  zk  think  jira  good  step  towards  taking  complexity  deal  catalog  table  everywhere  asis  new  client  already  requires  zk  get  root  location  would  change  requirement  way  primary  motivation  simplify  thing  like  catalogtracker  way  handle  root  class  really  simple  tracking  meta  difficulty  bit  hacky  hack  tracking  meta  location  caused  one  bug  hbase3159,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1
2620,review  document  fix  regionsintransition  timeout  logic  testing  stack  weve  uncovered  issue  concurrent  r  failure  master  heavy  load  led  situation  handle  zk  event  far  actually  occur  uncovered  issue  timeout  logic  jira  reviewing  timeout  semantics  especially  around  zk  usage  ensuring  handle  thing  appropriately,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2621,hbase1921  new  master  hbase1921  lost  writing  new  master  code  guess  going  much  harder  implement  think  critical  feature  considering  reason  brought  old  master  there  already  test  testzookeeper  disabled  ago,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2622,move  hbasefsck  client  util  seems  weird  hbasefsck  put  client  instead  util  expect  ill  move,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2623,rest  filter  gzipdeflate  content  encoding  wrap  input  output  side  hbase3275  rest  gateway  return  gzip  deflate  encoded  content  client  client  requested  using  appropriate  acceptencoding  header  however  jetty  gzipfilter  wrap  output  side  processing  client  submit  gzip  deflate  encoded  request  ie  contentencoding  gzip  contenttype  data  decoded  simply  passed  implement  filter  also  wrap  input  side  processing  client  submit  compressed  put  post  body,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2624,max  compaction  size  add  ability  specify  maximum  storefile  size  compaction  limit  include  file  compaction  useful  large  object  store  cluster  presplit  region,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2625,allow  roundrobin  distribution  table  created  multiple  region  distribute  initial  region  created  new  table  roundrobin  fashion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2626,admin  api  explicit  split  point  add  ability  explicitly  split  existing  region  userspecified  point  currently  disable  automated  splitting  presplit  newlycreated  table  explicit  boundary  cannot  explicitly  bound  split  existing  region,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2627,allow  hbaserpcmetrics  register  custom  interface  method  opened  comment  hbase2997  james  kennedy  note  quote  hbaserpcmetrics  logging  warn  message  every  time  encounter  unregistered  rpc  method  case  get  huge  log  file  filled  warning  hbasetrx  transactional  extension  hbase  us  subclass  hregionserver  add  new  interface  method  easy  enough  tell  log4j  ignore  hbaserpcmetrics  output  however  would  nice  serverhregionserver  hbaserpcmetrics  mechanism  extensible  could  pas  new  interface  grab  hbaserpcmetrics  object  add  interface  top  quote  hbaserpcmetrics  already  public  method  createmetricsclass  register  method  counter  need  way  expose  metric  class  allow  region  server  subclass  call  add  getmetrics  method  rpcserver  hbaseserver,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2628,hbck  pause  fixing  rechecking  state  right  run  fix  option  hbck  try  fix  issue  immediately  rerun  see  fix  worked  however  fix  require  node  cluster  take  action  take  couple  second  eg  notice  change  zk  pick  fixed  region  hbck  pause  amount  time  fixing  rerunning,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2629,remove  kv  copy  every  kv  scan  introduced  hbase3232  offending  code  inside  storescannernext  code  kv  longer  immutable  due  keyonlyfilter  use  copy  safety  keyvalue  copykv  new  keyvaluekvgetbuffer  kvgetoffset  kvgetlength  code  look  wrong  given  philosophy  avoidance  garbagemaking  copy  maybe  looked  thing  done  keyonlyfilter  making  copy  rather  mutating  original  making  critical  092,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2630,hfileoutputformat  use  column  family  compression  algorithm  hfileoutputformat  currently  creates  hfile  writer  using  compression  algorithm  set  configuration  hbasehregionmaxfilesize  default  compression  code  take  account  compression  algorithm  configured  table  column  family  result  bulk  uploaded  table  compressed  major  compaction  run  could  fixed  using  column  family  descriptor  creating  hfile  writer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2631,hfile  cli  improvement  add  miscellaneous  improvement  hfile  cli  improved  debugging  hfiles  1  option  show  key  hfile  2  option  display  block  index  3  support  inspecting  hfiles  remote  hdfs  cluster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2632,hbase  make  batchupdate  public  api  today  want  interact  row  hbase  start  update  make  change  commit  lock  fine  simple  application  however  try  thing  like  support  table  operation  part  mapreduce  job  becomes  difficult  support  propose  create  new  class  rowmutation  la  bigtable  paper  encapsulates  group  action  row  make  available  api  consumer  might  look  something  like  code  rowmutation  r  tablegetmutationrowkey  rsettimestamp1111  rputnew  textcolfam1name  value  rdeletenew  textcolfam2deleted  tablecommitr  code  syntax  would  supercede  existing  startupdatecommit  format  could  deprecated  mapped  rowmutation  behind  scene,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2633,speedup  hfilewriter  append  remove  double  writes  block  cache  specified  using  bytearraydatastream  baos  flushed  compress  stream  finishblock  machine  hfileperformanceevaluation  sequentialwritebenchmark  pass  4000ms  2500ms  running  sequentialwritebenchmark  1000000  row  took  4247ms  running  sequentialwritebenchmark  1000000  row  took  4512ms  running  sequentialwritebenchmark  1000000  row  took  4498ms  running  sequentialwritebenchmark  1000000  row  took  2697ms  running  sequentialwritebenchmark  1000000  row  took  2770ms  running  sequentialwritebenchmark  1000000  row  took  2721ms,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2634,allow  atomic  putdelete  one  call  right  following  call  putput  deletedelete  incrementincrements  cannot  combine  single  call  complete  single  row  lock  would  nice  would  also  allow  u  ca  could  putincrement  check  succeeded  amendment  since  increment  currently  support  mvcc  cannot  included  atomic  operation  put  delete,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2635,improve  selection  region  balance  currently  loadbalancer  go  list  region  per  r  grab  first  one  balance  bad  list  often  sorted  naturally  since  r  boot  open  region  sequential  sorted  order  since  come  meta  mean  balancing  region  starting  almost  sorted  fashion  discovered  one  internal  user  created  new  table  starting  letter  p  grown  100  region  last  hour  served  1  region  server  looking  master  log  balancer  moved  many  region  region  server  table  start  letter  region  moved  come  one  part  code  modified  code  hregioninfo  hri  region  dont  rebalance  meta  region  hriismetaregion  continue  regionstomoveaddnew  regionplanhri  serverinfo  null  numtaken  numtaken  numtooffload  break  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2636,improve  regionsplitter  performance  running  regionsplitter  100node  cluster  900  region  plenty  data  utility  took  around  72  hour  run  analysis  revealed  two  major  bottleneck  1  serialized  logical  split  ie  waiting  split  request  registered  parallelizing  step  align  configured  actual  outstanding  split  2  outstanding  split  modeled  like  queue  changing  list  scanner  allow  handling  split  finish  order,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2637,expose  perregion  request  rate  metric  currently  export  metric  request  rate  region  server  help  identifying  uneven  load  high  level  see  given  server  high  load  youre  forced  extrapolate  based  application  pattern  data  serving  likely  culprit  much  easier  exported  request  rate  metric  perregion  server  dynamically  updating  metric  key  based  assigned  region  may  pose  minor  challenge  seems  valuable  diagnostic  tool  available,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2638,distinguish  read  write  request  count  region  distinguishing  read  write  request  count  top  hbase3507  would  benefit  load  balancer  action  balancing  read  v  write  load  different  read  load  region  movement  low  keep  scanner  happy  write  load  region  movement  allowed  cheaper  counter  burdensome  keeping  extra  count,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2639,nmapinputformat  use  different  config  param  number  map  annoyingly  mr  local  runner  drop  mapredmaptasks  parameter  running  job  use  different  config  parameter  specify,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2640,improvement  hbck  test  entire  region  chain  meta  provide  better  error  reporting  current  hbck  tool  miss  inconsistency  meta  case  detect  issue  provide  much  way  useful  feedback  incorporate  full  region  chain  test  similar  checkmetarb  ie  look  overlap  hole  cycle  believe  checkmetarb  redundant  change  unit  test  better  test  test  actual  error  discovered  instead  error  truefalse  case  overlap  hole  output  end  broken  chain  previous  implementation  run  check  twice  inefficient  importantly  report  redundant  error  could  confusing  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2641,speedup  loadincrementalhfiles  adam  phelps  log  look  like  1  hfiles  loading  split  looking  code  loadincrementhfiles  hbase  v0901  im  actually  thinking  problem  code  load  hfiles  sequentially  largest  table  2500  region  data  loaded  fairly  well  distributed  across  end  around  2500  hfiles  load  period  12  second  per  hfile  mean  loading  process  time  consuming  currently  serverbulkloadhfile  blocking  call  utilize  executorservice  achieve  better  parallelism  multicore  computer  new  configuration  parameter  hbaseloadincrementalthreadsmax  introduced  set  maximum  number  thread  parallel  bulk  load,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2642,clean  compressiontest  directly  reference  distributedfilesystem  right  compressiontest  number  issue  always  writes  home  directory  user  regardless  path  provided  requires  actually  writing  hdfs  local  file  probably  sufficient,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2643,eliminate  use  threadlocals  coprocessorenvironment  bypass  complete  current  coprocessor  framework  threadlocal  object  used  bypass  complete  booleans  coprocessorenvironment  allows  coprocessorhost  implementation  identify  shortcircuit  processing  prexxx  postxxx  hook  method  profiling  region  server  however  show  threadlocals  become  contention  point  hot  code  path  preput  refactor  coprocessorhost  prepost  implementation  remove  usage  threadlocal  variable  replace  locally  scoped  variable  eliminate  contention  handler  thread,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2644,redefine  identity  hbase  configuration  judging  javadoc  hconnectionmanager  sharing  connection  across  multiple  client  going  cluster  supposedly  good  thing  however  fact  onetoone  mapping  configuration  connection  instance  kind  work  goal  specifically  create  htable  instance  using  given  configuration  instance  copy  thereof  end  two  distinct  hconnection  instance  cover  really  expected  behavior  especially  given  configuration  instance  get  cloned  lot  id  like  play  devil  advocate  propose  deepcompare  hbaseconfiguration  instance  multiple  hbaseconfiguration  instance  property  map  hconnection  instance  case  one  concerned  single  hconnection  insufficient  sharing  amongst  client  quote  javadoc  one  able  mark  given  hbaseconfiguration  instance  uniquely  identifiable  note  sharing  connection  make  clean  hconnection  instance  little  awkward  unless  course  apply  change  described  hbase3766,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2645,cleanup  locking  contention  master  new  master  us  lot  synchronized  block  safe  take  jstacks  see  there  multiple  layer  lock  contention  bunch  region  moving  like  balancer  run  main  culprit  regionintransition  assignmentmanager  zkassign  us  zkwgetznnodes  basically  another  set  region  transition  locking  regionstate  level  understanding  even  tho  multiple  thread  handle  region  transition  everything  actually  serialized  time  lock  holder  talking  zk  region  server  take  millisecond  simple  example  assignmentmanager  want  update  timer  region  r  usually  waiting  another  thread  thats  holding  lock  talking  zk,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2646,storefile  level  compaction  locking  multithreaded  compaction  hbase1476  solve  problem  major  compaction  clogging  highpriority  minor  compaction  however  still  problem  since  compaction  storelevel  store  undergoing  major  compaction  storefile  count  increase  major  really  need  way  allow  multiple  outstanding  compaction  per  store  compactselection  lockreserve  file  used  compaction  also  allow  u  know  going  compact  inserting  compactsplitthread  make  informed  priority  queueing  decision,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2647,tidy  naming  consistency  documentation  coprocessor  framework  naming  inconsistency  coprocessor  api  stale  javadocs  spotted  lars  george  dig  clean  official  release  forced  go  round  deprecation  make  change  current  item  list  rename  baseregionobservercoprocessor  baseregionobserver  basemasterobserver  rename  observercontext  parameter  variable  env  c  ctx  unnecessary  public  modifier  method  regionobserver  interface  part  take  pas  javadocs  verify  date  currently  implemented  please  tack  cosmetic  change  inconsistency  find,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
2648,minor  compaction  need  check  still  compactionthreshold  compacting  busy  region  43  storefiles  compactionthreshold8  region  stopped  client  stopped  putting  new  data  expect  storefiles  compacted  later  almost  one  day  later  43  storefiles  still  note  hbase  instance  disabled  major  compaction  seems  minor  compaction  started  continuiously  compact  remaining  storefiles  checked  code  true  test  obvious  issueproblem  complete  minor  compaction  check  current  storefiles  need  minor  compaction  think  may  bug  leak  try  test  1  put  many  data  region  30  storefiles  accumulated  backend  compaction  cannot  catch  fast  put  hbasehstorecompactionthreshold8  basehstorecompactionmax12  2  stop  put  3  30  storefiles  still  long  time  automatic  minor  compaction  4  submit  compaction  region  12  file  compaction  19  storefiles  minor  compaction  stopped  think  minor  compaction  complete  check  number  storefiles  still  many  another  minor  compaction  start  continuiously,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2649,add  facility  track  currently  progressing  actionsworkflows  lot  troubleshooting  involves  answering  question  well  server  right  today  involves  combination  interpreting  jstack  output  andor  trudging  log  problem  method  user  may  direct  ssh  access  regionserver  machine  production  environment  b  log  verbose  hard  separate  whats  still  going  v  stuff  might  completed  c  interpreting  jstack  requires  pretty  good  knowledge  codebase  plus  diving  source  code  id  like  add  singleton  take  care  tracking  major  action  going  region  server  master,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2650,refactor  coprocessor  compaction  api  hbase3797  compaction  logic  flow  significantly  altered  current  compaction  coprocessor  api  insufficient  gaining  full  insight  compaction  requestsresults  refactor  coprocessor  api  hbase3797  committed  extensible  increase  visibility,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2651,change  hfile  format  order  support  hbase3763  hbase3856  need  change  format  hfile  new  format  proposal  attached  thanks  mikhail  bautin  documentation,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1
2652,make  mapper  function  importtsv  plugable  would  really  useful  allow  ability  specify  different  mapper  importtsv  class  use  current  tsvimporter  would  allow  transformation  made  input  data  added  hbase  one  suggestion  add  new  command  line  option  specify  user  defined  mapper  udm  maybe  instead  refactor  extended  subclass  specify  new  mapper  mapper  statically  defined  bound  job  though  im  sure  best  way  make  dynamically  plugable  suggestion  welcome,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0
2653,enhance  hbase  rpc  support  freeing  server  handler  thread  even  response  ready  current  implementation  server  handler  thread  pick  item  incoming  callqueue  process  wrap  response  writable  sends  back  ipc  server  module  waste  threadresources  thread  blocked  disk  io  transaction  logging  read  block  cache  etc  would  nice  make  rpc  server  handler  thread  pick  call  ipc  queue  hand  application  eg  hregion  application  queue  processed  asynchronously  send  response  back  ipc  server  module  saying  response  ready  rpc  server  handler  thread  ready  pick  another  request  incoming  callqueue  queued  call  processed  application  indicates  ipc  module  response  ready  sent  back  client  rpc  client  continues  experience  behaviour  rpc  client  synchronous  block  till  response  arrives  rpc  enhancement  allows  u  powerful  thing  regionserver  future  make  enhance  regionservers  threading  model  messagepassing  model  better  performance  limited  number  thread  regionserver,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
2654,hbase  version  command  line  print  version  info  hadoop  handy  feature  dump  version  info  eg  code  hadoop  version  hadoop  0202cdh3u1snapshot  subversion  r  d94813ecd0d4b3f63f4d30baa8a22a59dc76d5a8  compiled  root  wed  may  25  031504  edt  2011  source  checksum  72d8d076770d2afa1f16f06d31d2b58a  code  hbase,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
2655,schedule  logspliiting  startup  distributed  log  splitting  enabled  better  call  splitlog  region  server  simultaneously  large  number  splitlog  task  get  scheduled  one  log  file  splitlogworker  region  server  executes  one  task  time  shouldnt  danger  dfs  overload  scheduling  task  ensures  maximum  parallelism,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2656,hlog  pretty  printer  currently  rudimentary  way  print  hlog  data  limited  currently  print  keyonly  information  need  extend  functionality  similar  developed  hfiles  pretty  printer  idea  functionality  filter  sequenceid  filter  row  region  option  print  value  addition  key  info  option  print  output  json  format  script  easily  parse  analysis,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2657,hbase  add  method  getting  multiple  cell  row  ability  return  cell  row  likely  number  situation  getfull  return  much  data  needed  using  individual  get  call  would  likely  small  method  support  returning  specific  list  column  code  maptext  byte  result  tablegetmultinew  textcella  cellb  cellc  timestamp  code,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2658,hmastercreatetable  could  heavily  optimized  looking  createtable  method  hmaster  one  thats  private  seem  inefficient  set  enabled  flag  table  every  region  done  every  time  create  new  region  create  new  hlog  close  reuse  one  instead  see  really  necessary  one  rpc  meta  per  region  batch  put  provide  drastic  speedup  even  creating  table  50  region,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2659,enable  direct  byte  buffer  lrublockcache  java  offer  creation  direct  byte  buffer  allocated  outside  heap  need  manually  freed  accomplished  using  documented  clean  method  feature  optional  implementing  benchmark  difference  speed  garbage  collection  observance,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2660,user  able  choose  custom  tableinputformats  without  modifying  tablemapreduceutilinittablemapperjob  currently  orgapachehadoophbasemapreducetablemapreduceutilinittablemapperjob  force  hbase  job  use  default  tableinputformatclass  job  input  format  class  jobsetinputformatclasstableinputformatclass  line  included  inittablemapperjob  restriction  cause  user  modify  inittablemapperjob  addition  implementing  tableinputformat  would  nicer  user  use  custom  tableinputformats  without  additionally  tampering  hbase  source  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2661,coprocessors  support  configuration  coprocessor  load  time  user  able  pas  configuration  option  coprocessors  option  applied  load  time  system  coprocessors  use  configuration  container  extend  table  coprocessor  load  specification  allow  arbitrary  keyvalue  pair  end  keyvalue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2662,update  hbase  metric  framework  metrics2  framework  metric  framework  marked  deprecated  hadoop  020203  022  might  get  removed  future  hadoop  release  hence  hbase  need  revise  dependency  metricscontext  use  metrics2  framework,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1,0
2663,usability  improvement  htablepool  improve  usability  htablepool  implementation  rely  user  returning  connection  pool  rather  transparently  user  close  htableimplementation  got  htableimplementation  proxy  implementation  returned  wrap  htable  object  hold  reference  pool  client  close  proxy  actually  automatically  return  wrapped  htable  back  pool  reused  case  method  htablepoolputtable  dont  need  public,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2664,implement  hbase  version  show  processlist  one  feature  dba  use  mysql  analysis  show  processlist  give  applicationlevel  stats  rpc  thread  right  use  jstack  coredevelopercentric  need  create  similar  tool  dbaopsappdevs  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2665,data  gc  remove  version  ttl  except  last  written  version  chatting  today  backup  cluster  want  able  restore  dataset  point  time  within  limited  timeframe  say  one  week  thereafter  version  older  one  week  rather  ttl  let  go  version  older  ttl  instead  let  go  version  except  last  one  written  like  versions1  ttl  one  week  want  allow  error  caught  within  week  happening  user  mistakenly  remove  critical  table  well  able  restore  moment  catastrophe  hit  otherwise  keep  one  version,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2666,blockcache  content  report  summarized  blockcache  report  regionserver  would  helpful  example  table1  cf1  100  block  totalbytesyyyyy  averagetimeincachexxxx  hour  cf2  200  block  totalbyteszzzzz  averagetimeincachexxxx  hour  table2  cf1  75  block  totalbytesyyyyy  averagetimeincachexxxx  hour  cf2  150  block  totalbyteszzzzz  averagetimeincachexxxx  hour  etc  current  metric  list  blockcachesize  blockcachefree  way  know  whats  single  block  isnt  really  important  pattern  cftable  came  big  long  average  theyve  cache  important  interface  exists  hregioninterface  think  would  helpful  operational  perspective  updated  729  removing  suggestion  ui  would  happy  get  report  configured  interval  dumped  log  file,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,1
2667,atomicappend  put  appends  latest  version  cell  ie  read  current  value  add  byte  offered  client  tail  writes  new  entry  come  time  client  want  add  existing  cell  rather  make  new  cell  time  place  frontend  keep  list  url  user  visited  md5s  update  user  progress  rather  read  modify  clientside  write  new  value  back  hbase  would  sweet  could  one  operation  hbase  server  tsdb  aim  space  efficient  rather  pay  cost  kv  wrapper  per  metric  would  rather  kv  interval  kv  value  metric  period  could  done  coprocessor  feel  like  fundamental  feature  benoît  suggests  atomicappend  take  flag  indicate  whether  client  want  see  resulting  cell  often  client  wont  want  see  result  case  pay  price  formulating  delivering  response  client  drop,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0
2668,metric  hfile  hdfs  block  locality  normally  put  hbase  hdfs  cluster  eg  region  server  run  datenode  reasonably  good  data  locality  explained  lars  also  work  done  jonathan  address  startup  situation  scenario  region  different  machine  machine  hold  underlying  hfile  block  least  period  time  performance  impact  whole  table  scan  operation  map  reduce  job  time  1  load  balancer  move  region  compaction  thus  generate  hfile  new  region  server  region  hdfs  block  remote  2  new  machine  added  removed  hbases  region  assignment  policy  different  hdfss  block  reassignment  policy  3  even  much  hbase  activity  hdfs  load  balance  hfile  block  nonhbase  application  push  data  hdfs  lot  done  load  balancer  summarized  ted  curious  hfile  hdfs  block  locality  used  another  factor  done  experiment  hdfs  block  locality  impact  map  reduce  latency  first  need  define  metric  measure  hfile  data  locality  metric  defintion  given  table  region  server  region  define  following  higher  value  local  hfile  region  server  point  view  hfile  locality  index  total  number  hdfs  block  retrieved  locally  region  server  total  number  hdfs  block  hfiles  test  result  show  hfile  locality  impact  latency  based  table  1m  row  36kb  per  row  region  distributed  balance  map  job  rowcounter  hfile  locality  index  map  job  latency  sec  28  157  36  150  47  142  61  133  73  122  89  103  99  95  first  suggestion  expose  hfile  locality  index  new  region  server  metric  ideal  somehow  measure  hfile  locality  index  per  map  job  level  regarding  ifwhen  include  another  factor  load  balancer  different  work  item  unclear  load  balancer  take  various  factor  account  come  best  load  balancer  strategy,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0
2669,slow  query  log  produce  log  message  slow  query  rpc  server  decide  slow  based  configurable  warn  response  time  parameter  query  designated  slow  output  response  slow  message  followed  fingerprint  query  summary  limited  size  another  configurable  parameter  limit  log  spamming,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
2670,make  replication  service  pluggable  via  standard  interface  definition  current  hbase  code  support  replication  service  used  sync  data  one  hbase  cluster  another  would  nice  make  pluggable  interface  crossdatacenter  replication  service  used  conjuction  hbase,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
2671,extend  walactionslistener  api  accomodate  log  archival  walobserver  interface  expose  log  roll  event  would  nice  extend  accomodate  log  archival  event  well,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2672,exposing  hbase  filter  thrift  api  currently  use  filter  one  explicitly  add  scanner  filter  thrift  api  making  messy  long  patch  trying  add  support  filter  clean  way  user  specifies  filter  via  string  string  parsed  server  construct  filter  information  found  attached  document  named  filter  language  patch  trying  extend  progress  made  patch  hbase1744  jira  httpsissuesapacheorgjirabrowsehbase1744,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2673,coprocessors  pull  cp  constant  cp  package  oahhhconstants  hbase3810  stack  gave  comment  patch  committed  bit  odd  class  parent  package  reference  sub  package  class  least  constant  pulled  level  htabled  create  new  jira  constant  pulled  oahhregionserverregioncoprocessorhost  oahhhconstants,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2674,support  fault  tolerant  instant  schema  update  master  intervention  ie  enabledisable  bulk  assignunassign  zk  jira  slight  variation  approach  done  part  httpsissuesapacheorgjirabrowsehbase1730  support  instant  schema  update  modify  table  add  column  modify  column  operation  1  enabledisabling  table  2  bulk  unassignassign  region,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
2675,data  block  encoding  keyvalues  aka  delta  encoding  prefix  compression  compression  key  key  sorted  hfile  usually  similar  possible  design  better  compression  general  purpose  algorithm  additional  step  designed  used  memory  aim  save  memory  cache  well  speeding  seek  within  hfileblocks  improve  performance  lot  key  length  larger  value  length  example  make  lot  sense  use  value  counter  initial  test  real  data  key  length  90  byte  value  length  8  byte  show  could  achieve  decent  level  compression  key  compression  ratio  92  total  compression  ratio  85  lzo  data  85  lzo  delta  encoding  91  much  better  performance  2080  faster  decompression  ratio  lzo  moreover  allow  far  efficient  seeking  improve  performance  bit  seems  simple  compression  algorithm  good  enough  saving  due  prefix  compression  int128  encoding  timestamp  diffs  bitfields  avoid  duplication  way  comparison  compressed  data  much  faster  byte  comparator  thanks  prefix  compression  bitfields  order  implement  hbase  two  important  change  design  needed  solidify  interface  hfileblock  hfilereader  scanner  provide  seeking  iterating  access  uncompressed  buffer  hfileblock  bad  performance  extend  comparators  support  comparison  assuming  n  first  byte  equal  field  equal  link  discussion  something  similar  httpsearchhadoopcomm5aqgxjenad1hbasewindowssubjreprefixcompression,0,0,0,0,0,0,1,0,1,0,1,0,0,0,1,0,1
2676,add  percolumn  family  metric  right  region  server  level  statistic  however  readwrite  flow  varies  lot  based  column  family  involved  add  dynamic  per  column  family  metric  jmx  track  column  family  individually,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2677,change  necessary  build  run  hadoop  023  modification  necessary  run  today  trunk  copypaste  versionedprotocol  hbase  ipc  package  upgrade  protobufs  240a  fix  one  test  testhfileoutputformat  new  taskattemptcontext  api  remove  illegal  access  private  member  fsnamesystem  test  use  reflection,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
2678,make  hlog  resilient  write  pipeline  failure  current  implementation  hlog  rolling  recover  transient  error  write  pipeline  seems  two  problem  hloglogsyncer  trigger  ioexception  timebased  sync  operation  trigger  log  rolling  request  corresponding  catch  block  escaping  internal  loop  result  logsyncer  thread  exit  never  restarted  tell  even  log  rolling  successful  log  rolling  request  triggered  ioexception  sync  append  never  happen  entry  yet  written  log  mean  write  error  immediately  recovered  extends  exposure  error  occurring  pipeline  addition  seems  like  able  better  handle  transient  problem  like  rolling  restart  datanodes  hbase  regionservers  running  currently  reliably  cause  regionserver  abort  log  rolling  either  append  timebased  sync  trigger  initial  ioexception  initiating  log  rolling  request  however  log  rolling  fails  closing  current  writer  datanodes  bad  causing  regionserver  abort  case  seems  like  least  allow  option  continue  new  writer  abort  subsequent  error,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2679,need  flush  regionserver  rather  table  option  evening  needed  clean  log  cluster  log  regionserver  let  go  log  need  edits  emptied  memory  flush  table  region  need  able  flush  regionserver  need  add,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2680,update  protobuf  dependency  240a  hadoop  trunk  using  version  protobufs  incompatibility  make  impossible  hbase  coexist  need  regenerate  code  240a  update  pom,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0
2681,allow  loadbalancer  pluggable  everyone  seems  want  something  different  load  balancer  people  want  low  latency  simplicity  total  control  seems  like  point  load  balancer  cant  thing  people  something  akin  hadoop  jts  pluggable  scheduler  seems  like  enable  solution  without  making  code  much  complex,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,1,0
2682,optimize  flushing  store  cache  max  version  new  min  version  discussed  jon  room  improvement  memstore  flushed  disk  currently  expired  kv  pruned  flushing  also  prune  version  find  least  maxversions  version  memstore  hold  new  minversion  feature  find  least  minversion  version  store  remove  version  expired  generally  use  mechanism  used  compaction  ie  storescanner  need  add  scanner  memstore  scan  along  current  snapshot,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
2683,assignmentmanager  debug  log  info  level  metaroot  region  master  debug  log  quite  verbose  people  dont  usually  trying  debug  cluster  bad  state  due  meta  root  issue  really  helpful  info  transition  info  important  region  always  log  detail  info  level,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2684,add  debugging  dump  servlet  master  regionserver  debugging  cluster  would  nice  single  textonly  page  curled  used  debugging  servlet  include  following  info  build  version  monitored  task  status  server  list  recently  aborted  region  server  see  hbase4275  region  transition  executor  pool  status  see  hbase4281  stack  trace  thread  configuration  last  n  kb  server  log,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2685,performance  scanner  getrow  return  map  duplicate  data  right  whenever  get  back  multiple  cell  worth  data  time  map  hstorekeybyte  mean  duplicated  text  row  long  timestamp  least  every  cell  quite  bit  wasted  also  mean  lot  translation  every  time  could  create  new  writable  contains  one  row  one  timestamp  map  textbyte,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2686,update  thrift  070  new  version  thrift  070  feature  bug  fix  could  useful  include  next  release  hbase,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2687,remove  duplicated  code  put  delete  get  scan  multiput  came  discussion  stack  wrt  hbase2195  currently  lot  duplicated  code  especially  put  delete  also  operation  example  putdeletegetscan  attribute  exactly  code  class  put  delete  also  familymap  row  rowlock  timestamp  etc  one  way  introduce  operationwithattributes  extends  operation  putdeletegetscan  extend  rather  operation  addition  put  delete  could  extends  mutation  would  extend  operationwithattributes  static  inheritance  hierarchy  desired  use  delegation,1,1,1,0,1,1,0,0,0,0,0,1,1,0,0,0,0
2688,add  decent  heuristic  region  size  u  brainstorming  morning  default  region  size  general  point  made  way  better  toolarge  toosmall  since  always  split  table  cant  merge  region  currently  hfile  v2  multithreaded  compaction  fewer  reason  avoid  verylarge  region  10gb  small  table  may  want  small  region  size  distribute  load  better  across  cluster  big  table  multigb  probably  best,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2689,hbaseadminassign  use  force  flag  hbaseadminassign  code  public  void  assignfinal  byte  regionname  final  boolean  force  throw  masternotrunningexception  zookeeperconnectionexception  ioexception  getmasterassignregionname  force  code  hmaster  call  code  pairhregioninfo  servername  pair  metareadergetregionthiscatalogtracker  regionname  pair  null  throw  new  unknownregionexceptionbytestostringregionname  cphost  null  cphostpreassignpairgetfirst  force  return  assignregionpairgetfirst  cphost  null  cphostpostassignpairgetfirst  force  code  force  flag  getting  used  may  need  update  javadoc  provide  force  flag  parameter  going  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2690,move  block  cache  parameter  reference  single  cacheconf  class  storefile  hfile  currently  use  boolean  argument  various  block  cache  configuration  parameter  exist  number  parameter  going  continue  increase  look  compressed  cache  delta  encoding  specific  l1l2  configuration  every  new  config  currently  requires  changing  many  constructor  introduces  new  boolean  move  everything  single  class  modification  much  le  disruptive,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2691,provide  access  rpcserver  instance  regionserverservices  case  regionobserver  coprocessors  may  want  directly  access  running  rpcserver  instance  region  server  token  based  authentication  example  needed  coprocessor  interact  secretmanager  validates  authentication  token  secure  rpc  engine  addition  async  call  handling  serverside  becomes  additionally  important  coprocessors  want  send  back  delayed  response  client  case  coprocessor  would  need  able  call  rpcservergetcurrentcall  send  back  response  propose  add  access  rpcserver  regionserverservices  code  return  reference  region  server  rpc  server  public  rpcserver  getrpcserver  code  simultaneously  drop  existing  regionserverservicesgetrpcmetrics  method  since  could  accessed  via  rpcservergetrpcmetrics,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2692,move  clientscanner  htable  see  hbase1935  motivation  clientscanner  able  exist  outside  htable  also  add  abstract  client  scanner  easy  development  new  client  side  scanner  parallel  scanner  per  region  scanner,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2693,run  aggressive  compaction  peak  hour  number  iop  disk  top  rack  bandwidth  utilization  peak  hour  much  lower  peak  hour  depending  application  usage  pattern  utilize  knowledge  improve  performance  hbase  cluster  increasing  compact  selection  ratio  much  larger  value  offpeak  hour  otherwise  increasing  hbasehstorecompactionratio  12  default  hbasehstorecompactionratiooffpeak  5  default  help  reduce  average  number  file  per  store,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
2694,lazyseek  optimization  storefile  scanner  previously  several  storefiles  column  family  region  would  seek  merge  result  even  though  rowcolumn  looking  might  recent  smallest  file  prioritize  read  file  check  recent  file  first  done  lazy  seek  pretend  next  value  storefile  seekrow  seekcolumn  lasttimestampinstorefile  earlier  kv  order  anything  might  actually  occur  file  dont  find  result  earlier  file  fake  kv  bubble  top  kv  heap  real  seek  done  expected  significantly  reduce  amount  disk  io  09222011  dark  launch  testing  measurement  joint  work  liyin  tang  huge  thanks  many  helpful  discussion  idea  putting  fake  kv  highest  timestamp  storefile  scanner  priority  queue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2695,ability  application  store  metadata  transaction  log  mysql  allows  application  store  arbitrary  blob  along  transaction  transaction  log  jira  similar  feature  request  hbase  use  case  follows  application  one  data  center  store  blob  data  along  transaction  replication  software  pick  blob  transaction  log  hand  another  instance  application  running  remote  data  center  b  application  b  responsible  applying  remote  hbase  cluster  also  handle  conflict  resolution,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2696,increment  operation  release  rowlock  syncing  hlog  allows  better  throughput  hot  rowsi  seen  change  make  single  row  update  improve  400  incrementssecserver  4000  incrementssecserver,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2697,better  key  splitting  regionsplitter  regionsplitter  utility  allows  user  create  presplit  table  command  line  rolling  split  existing  table  support  pluggable  split  algorithm  implement  splitalgorithm  interface  onlydefault  splitalgorithm  one  assumes  key  fall  range  ascii  string  00000000  ascii  string  7fffffff  sane  default  seems  useless  user  user  likely  surprised  fact  region  split  occur  byte  range  ascii  character  better  default  split  algorithm  would  one  evenly  divide  space  byte  patch  making  table  five  region  would  split  x33x33  x66x66  x99x99  xccxcc  xffxff,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
2698,catalogtracker  identity  crisis  need  cutback  scope  ct  need  good  reworking  id  suggest  scope  cut  way  deal  zk  transaction  rather  zk  reading  meta  location  hbase  hconnection  purveyor  hregioninterfaces  meta  root  server  abortable  verifier  catalog  location  done  would  suggest  better  belongs  zk  package  meta  class  move  client  package  here  messy  note  added  head  ct  class  hbase3446  spent  time  trying  make  ct  code  todo  class  need  rethink  original  intent  would  onestopshop  root  meta  location  would  get  info  reading  watching  zk  state  class  used  server  needed  know  root  meta  movement  also  clientside  inside  htable  rather  figure  root  meta  location  fault  client  would  instead  get  notification  zk  original  intent  frustrated  fact  class  read  hbase  table  root  table  figure  meta  region  location  mean  depend  hconnection  hconnection  retrying  also  mechanism  finding  root  meta  location  verifying  try  location  fails  new  lookup  etc  least  hconnection  htable  cant  ct  since  ct  need  hconnection  even  want  ht  ct  ht  keep  session  zk  rather  shouldnt  like  asynchbase  wed  open  connection  zk  read  need  let  connection  go  fix  make  root  meta  address  wholey  zk  zk  root  hbase  table  meta  even  class  verification  location  making  call  hconnection  root  meta  lookup  isnt  verification  useless  since  return  whatever  dependent  result  call  need  use  hconnection  verified  may  change  meantime  hconnection  us  ct  primitive  root  meta  tracker  finding  root  location  meta  moved  zk  class  may  make  sense  meantime  cohere  watch  meta  root  verification  let  hconnection  since  going  done  ultimately  anyways  class  spread  throughout  codebase  need  reigned  class  used  serverside  even  move  meta  location  zk  currently  used  client  package  used  metareader  metaeditor  class  usually  get  configuration  using  indirectly  asking  hconnection  configuration  even  used  get  hconnection  end  stack  10232011  code,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
2699,hbck  improve  region  map  output  hbase4375  added  region  coverage  visualization  hbck  detail  mode  user  binary  row  key  output  difficult  parse  awksed  pull  program  numeric  excel  capable  handling  tsv  formatted  data  patch  improves  output  using  bytestostringbinary  escape  binary  instead  bytestostring  printing  key  suggests  repair  action  collect  problem  group  group  region  overlapping,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2700,remove  htabledescriptor  hregioninfo  hregioninfo  every  region  hbase  currently  hregioninfo  also  contains  htabledescriptor  schema  mean  store  schema  n  time  n  number  region  table  additionally  every  region  table  region  server  open  copy  schema  thus  stored  memory  open  region  hregioninfo  merely  contained  table  name  htabledescriptor  could  stored  separate  file  easily  found,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
2701,put  operation  release  rowlock  syncing  hlog  allows  better  throughput  hot  row  single  row  update  improves  100  putssecserver  5000  putssecserver,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2702,avoid  top  row  seek  dedicated  bloom  filter  delete  family  bloom  filter  previous  jira  hbase4469  avoid  top  row  seek  operation  rowcol  bloom  filter  enabled  jira  try  avoid  top  row  seek  case  creating  dedicated  bloom  filter  delete  family  subtle  use  case  interested  top  row  empty  column  example  interested  row1cf11put  seek  top  row  row1cf1maxtsmaximum  delete  family  bloom  filter  say  delete  family  avoid  top  row  seek  return  fake  kv  last  kv  row  createlastonrowcol  way  already  missed  real  kv  interested  solution  problem  disable  optimization  trying  getscan  row  empty  column  evaluation  testseekoptimization  previously  bloomnone  comprnone  total  seek  without  optimization  2506  optimization  1714  6840  saving  3160  bloomrow  comprnone  total  seek  without  optimization  2506  optimization  1714  6840  saving  3160  bloomrowcol  comprnone  total  seek  without  optimization  2506  optimization  1458  5818  saving  4182  bloomnone  comprgz  total  seek  without  optimization  2506  optimization  1714  6840  saving  3160  bloomrow  comprgz  total  seek  without  optimization  2506  optimization  1714  6840  saving  3160  bloomrowcol  comprgz  total  seek  without  optimization  2506  optimization  1458  5818  saving  4182  get  10  seek  saving  rowcol  bloom  filter  enabledhbase4469  change  bloomnone  comprnone  total  seek  without  optimization  2506  optimization  1458  5818  saving  4182  bloomrow  comprnone  total  seek  without  optimization  2506  optimization  1458  5818  saving  4182  bloomrowcol  comprnone  total  seek  without  optimization  2506  optimization  1458  5818  saving  4182  bloomnone  comprgz  total  seek  without  optimization  2506  optimization  1458  5818  saving  4182  bloomrow  comprgz  total  seek  without  optimization  2506  optimization  1458  5818  saving  4182  bloomrowcol  comprgz  total  seek  without  optimization  2506  optimization  1458  5818  saving  4182  get  10  seek  saving  kind  bloom  filter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2703,allow  cf  retain  deleted  row  parent  allows  cluster  retain  row  ttl  keep  minimum  number  version  however  client  deletes  row  version  older  delete  tomb  stone  remove  next  major  compaction  even  memstore  flush  see  hbase4241  way  retain  version  guard  software  error  see  two  option  1  add  new  flag  hcolumndescriptor  something  like  retaindeleted  2  fold  parent  change  ie  keep  minimumnumberofversions  version  even  past  delete  marker  1  would  allow  flexibility  2  come  somewhat  naturally  parent  user  viewpoint  comment  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2704,refactor  testopenedregionhandler  testopenregionhandler  improvement  task  taken  refactor  testopenedregionandler  testopenregionhandler  mockserver  mockregionserverservices  accessed  common  utility  package  one  testcases  testopenedregionhandler  need  start  cluster  also  moving  common  package  help  mocking  server  future  testcases,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2705,ability  specify  custom  startend  regionsplitter  hbase4489  changed  default  endkey  hexstringsplit  7fff  ffff  correct  existing  user  090  regionsplitter  7fff  end  key  schema  last  region  split  properly  new  code  need  let  user  specify  custom  startend  key  range  situation  like  arise  optimally  also  write  startend  key  meta  could  figure  implicitly  instead  requiring  user  explicitly  specify,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2706,prefix  compression  trie  data  block  encoding  hbase  data  block  format  room  2  significant  improvement  application  high  block  cache  hit  ratio  first  prefix  compression  current  keyvalue  format  somewhat  metadata  heavy  tremendous  memory  bloat  many  common  data  layout  specifically  long  key  short  value  second  random  access  keyvalues  inside  data  block  mean  every  time  double  datablock  size  average  seek  time  average  cpu  consumption  go  factor  2  standard  64kb  block  size  10x  slower  random  seek  4kb  block  size  block  size  small  4kb  cause  problem  elsewhere  using  block  size  256kb  1mb  may  efficient  disk  access  blockcache  perspective  many  bigdata  application  infeasible  random  seek  perspective  prefixtrie  block  encoding  format  attempt  solve  problem  feature  trie  format  row  key  encoding  completely  eliminates  duplicate  row  key  encodes  similar  row  key  standard  trie  structure  also  save  lot  space  column  family  currently  stored  beginning  block  could  easily  modified  allow  multiple  family  name  per  block  qualifier  block  stored  trie  format  caters  nicely  wide  row  duplicate  qualifers  row  eliminated  size  trie  determines  width  block  qualifier  fixedwidthint  minimum  timestamp  stored  beginning  block  delta  calculated  maximum  delta  determines  width  block  timestamp  fixedwidthint  block  structured  metadata  beginning  section  row  trie  column  trie  timestamp  delta  value  work  done  row  trie  every  leaf  node  corresponding  row  contains  list  offsetsreferences  corresponding  cell  row  cell  fixedwidth  enable  binary  searching  represented  1  byte  operationtype  x  byte  qualifier  offset  x  byte  timestamp  delta  offset  operation  type  block  zero  percell  overhead  timestamps  qualifier  get  chance  compression  aspect  strong  make  small  sacrifice  varint  size  enable  faster  binary  search  trie  fanout  node  compressed  slower  version  might  build  also  applying  suffix  etc  compression  trie  node  cost  slower  write  speed  even  compression  could  obtained  using  vints  instead  fints  sacrifice  random  seek  speed  though  huge  one  current  drawback  current  write  speed  programmed  good  construct  like  treemaps  bytebuffers  binary  search  etc  programmed  level  optimization  read  path  work  need  done  optimize  data  structure  used  encoding  could  probably  show  10x  increase  still  slower  delta  encoding  much  higher  decode  speed  yet  created  thorough  benchmark  write  speed  sequential  read  speed  though  trie  reaching  point  internally  efficient  probably  within  half  quarter  max  read  speed  way  hbase  currently  us  far  optimal  keyvaluescanner  related  class  iterate  trie  eventually  need  smarter  method  thing  like  skipping  next  row  result  without  scanning  every  cell  accomplished  also  allow  much  faster  compaction  full  row  key  compared  often  current  code  github  trie  code  separate  project  slightly  modified  hbase  hbase  project  well  deltaencoding  patch  applied  build  top  httpsgithubcomhotpadshbasetreeprefixtrie1  httpsgithubcomhotpadshbaseprefixtrietreehcellscanners  ill  follow  later  implementation  idea,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2707,always  cache  index  bloom  block  would  add  new  boolean  config  option  hfileblockcachedatablocks  default  would  true  setting  false  allows  hbase  mode  index  block  cached  useful  analytical  scenario  useful  working  set  data  cannot  expected  fit  aggregate  cache  equivalent  setting  cacheblocks  false  scan  including  scan  behalf  get  would  like  get  general  feeling  folk  think  change  would  simple  update  mikhail  probably  dont  need  new  conf  option  instead  make  index  block  cached  default,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2708,streamline  hstore  startup  compaction  several  useful  patch  streamline  hstore  startup  compaction  part  abandoned  change  hbase69  incorporated,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
2709,improvement  test  global  possible  make  test  using  default  cluster  configuration  number  region  1  instead  2  3  allows  faster  stopstart  step  toward  shared  cluster  configuration  sleep  lower  remove  sleep  based  synchronisation  test  hbasetestingutility  testglobalmemstoresize  testadmin  testcoprocessorendpoint  testhfileoutputformat  testlrublockcache  testservercustomprotocol  testreplicationsink  optimize  put  setting  setwritetowal  false  put  big  loop  done  test  rely  wal  local  issue  testtableinputformatscan  fully  deletes  hadooptmpdir  directory  teardown  make  impossible  use  another  test  using  directory  testidlock  log  much  9000  line  per  second  test  time  lowered  15  second  make  part  small  subset  testmemoryboundedlogmessagebuffer  useless  systemoutprintln  iohfiletestreseekto  useless  systemoutprintln  testtableinputformat  shutdown  cluster  testglobalmemstore  shutdown  cluster  restclienttestremoteadmin  simplified  use  local  admin  single  test  instead  two  hbasetestingutilityensuresomeregionserversavailable  start  one  server  start  number  missing  server  instead  testmergetool  startsstops  dfs  cluster  hbasetestingutility,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2710,use  random  zk  client  port  unit  test  run  parallel  hardcoded  zk  client  port  long  problem  running  hbase  test  suite  parallel  mini  zk  cluster  run  random  free  port  port  passed  part  unit  test  need  talk  mini  cluster  fact  randomizing  port  expose  lot  place  code  new  configuration  instantiated  result  client  try  talk  default  zk  client  port  time  initial  fix  089fb  already  allows  run  unit  test  parallel  10  minute  fix  trunk  follow,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2711,dont  create  unnecessary  linkedlist  evicting  blockcache  evicting  blockcache  code  creates  linkedlist  containing  every  single  block  sorted  access  time  list  created  priorityqueue  dont  believe  necessary  priorityqueue  used  directly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2712,naming  error  testhlogutils  softvaluesortedmaptest  softvaluesortedmaptest  test  junit  one  tend  think  called  dont  know  used  testhlogutils  wrong  name  test  helper  confuses  script  looking  test  would  seems  better  thing  rename  anything  special  keep  history  attached  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2713,pertable  columnfamily  metric  configurable  table  name  inclusion  kept  adding  granular  block  read  block  cache  usage  statistic  combinatorial  explosion  various  case  monitor  started  happen  especially  wanted  pertablecolumn  familyblock  type  statistic  aggregate  statistic  various  subset  dimension  unclutters  hfile  reader  lrublockcache  storefile  etc  creating  centralized  class  know  update  kind  pertablecfblock  type  counter  table  name  column  family  configuration  pushed  base  class  schemaconfigured  convenient  many  existing  class  property  hfile  readerswriters  hfile  block  etc  base  class  whether  collect  pertable  columnfamily  percolumnfamily  metric  configured  hbasemetricsshowtablename  configuration  key  dont  expect  configuration  change  runtime  cache  setting  statically  log  warning  attempt  made  flip  already  set  way  dont  pas  configuration  lot  place  eg  everywhere  hfile  reader  instantiated  thanks  liyin  initial  version  pertable  metric  patch  lot  valuable  feedback,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2714,improve  rowcounter  count  row  specific  key  range  currently  rowcounter  mr  package  simple  map  job  full  scan  table  enhance  utility  let  user  specify  key  range  count  number  row  range,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2715,sleep  synchronisation  improvement  test  multiple  small  change  commiters  removing  sleep  made  visible  bug  jvmclusterutilhmasterwaitforserveronline  add  synchro  point  may  want  review  jvmclusterutilhmasterwaitforserveronline  removed  condition  never  met  test  c  c  added  new  synchronization  point  assignementmanagerwaitforassignment  add  timeout  wait  stuck  notification  received  wait  hmasterloop  use  notification  instead  1  sleep  hregionserverwaitforserveronline  new  method  used  jvmclusterutilwaitforserveronline  replace  1  sleep  notification  hregionservergetmaster  1  sleep  replaced  one  01s  sleep  one  02s  sleep  hregionserverstop  use  notification  sleeper  lower  shutdown  05s  zookeepernodetrackerstart  replace  recursive  call  loop  zookeepernodetrackerblockuntilavailable  add  timeout  wait  stuck  notification  received  wait  hbasetestingutilityexpiresession  use  timeout  1  instead  5  testzookeepertestclientsessionexpired  use  timeout  1  instead  5  change  hbasetestingutility  60  faster  testregionrebalancingwaitforallregionsassigned  use  sleep  02s  instead  1  testrestartclustertestclusterrestart  send  table  creation  together  check  creation  faster  testhlog  shutdown  whole  cluster  instead  dfs  standard  jvmclusterutilstartup  lower  sleep  1  01s  hconnectionmanagerclose  zookeeper  name  debug  message  hconnectionmanager  connection  close  always  null  set  null  delete,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2716,percf  set  rpc  metric  porting  percf  set  metric  rpc  time  response  size  089fb  trunk  mutation  signature  set  column  family  involved  rpc  request  increment  several  metric  allowing  monitor  access  pattern  deal  guarding  explosion  number  metric  hbase4638  might  even  implemented  part  jira,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2717,support  reverse  scan  reversed  scan  mean  scan  row  backward  startrow  bigger  stoprow  reversed  scan  example  following  row  aaac1q1value1  aaac1q2value2  bbbc1q1value1  bbbc1q2value2  cccc1q1value1  cccc1q2value2  dddc1q1value1  dddc1q2value2  eeec1q1value1  eeec1q2value2  could  reversed  scan  ddd  bbbexclude  like  scan  scan  new  scan  scansetstartrowddd  scansetstoprowbbb  scansetreversedtrue  forresult  resulthtablegetscannerscan  systemoutprintlnresult  aslo  could  reversed  scan  shell  like  hbase  scan  tablereversed  truestartrowddd  stoprowbbb  output  dddc1q1value1  dddc1q2value2  cccc1q1value1  cccc1q2value2  documentation  find  hbase  say  want  forward  reverse  scan  build  2  table  one  ascending  one  descending  fundamental  reason  hbase  support  forward  scan  seems  like  lot  extra  space  overhead  coding  overhead  keep  sync  support  2  table  assuming  discussed  cant  find  discussion  anywhere  would  infeasible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2718,distributed  log  splitting  coding  enhancement  make  easier  understand  semantics  change  reviewing  distributed  log  splitting  feature  found  cosmetic  issue  make  code  hard  understand  great  fix  issue  semantic  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2719,make  thrift  server  thread  pool  bounded  add  commandline  ui  test  started  internal  hotfix  found  thrift  server  spawned  15000  thread  bound  thread  pool  size  added  custom  thread  pool  server  implementation  called  hbasethreadpoolserver  hbase  codebase  made  following  parameter  configurable  command  line  config  setting  minworkerthreads  maxworkerthreads  maxqueuedrequests  increasing  load  server  creates  new  thread  every  connection  pool  size  reach  minworkerthreads  server  put  new  connection  queue  creates  new  thread  queue  full  attempt  create  new  thread  fails  server  drop  connection  default  tthreadpoolserver  would  crash  case  never  happened  thread  pool  unbounded  server  would  hang  indefinitely  consume  lot  memory  cause  huge  latency  spike  client  side  another  part  fix  refactoring  unit  testing  commandline  part  thrift  server  logic  sufficiently  complicated  existing  thriftserver  class  test  part  new  testthriftservercmdline  test  start  thrift  server  random  port  various  combination  option  talk  client  api  another  thread,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2720,replace  hql  w  hbasefriendly  jirb  jython  shell  hbase  shell  useful  admin  debugging  tool  couple  downside  extend  fragile  parser  definition  need  tinkeringwith  new  java  class  must  added  current  test  suite  hql  lacking  coverage  current  code  could  rewrite  evolved  piecemeal  another  downside  presence  hql  interpreter  give  misimpression  hbase  like  sql  database  wish  issue  suggests  jettison  hql  instead  offer  user  jirb  jython  command  line  wed  ship  script  jrubyjython  class  wed  source  startup  thing  like  import  base  client  class  folk  wouldnt  remember  package  stuff  sat  added  prettyprint  scanner  getters  outputting  text  xhtml  binary  would  also  make  easy  hqlthings  jrubypython  script  advantage  alreadywritten  parser  need  extension  probing  deeper  hbase  ie  better  debugging  hql  could  ever  easy  extension  adding  scriptsmodules  rather  java  code  le  likely  hbase  could  confused  sql  db  downside  probably  verbose  requires  ruby  python  knowledge  everyone  know  sql  big  jruby  lib  24m  going  write  security  downside  hql  suffers  moment  though  possible  sort  update  selects  ui  prevent  modification  db  ui  something  would  hard  jrubyjython  parser  others  think,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2721,cellvalue  class  transporting  cell  timestamp  cell  value  simultaneously  get  method  take  timestamp  parameter  mean  least  old  x  handy  getting  data  fit  expectation  exist  however  result  get  back  doesnt  actually  contain  real  timestamp  cell  stored  example  let  say  write  stock  price  favorite  company  row  yhoo  cell  stockprice  take  default  timestamp  right  day  pass  want  get  recent  stock  price  yhoo  also  price  gathered  current  system  couldnt  without  also  scan  time  added  new  class  called  cellvalue  contained  byte  cell  value  well  long  timestamp  stored  could  return  instance  class  wherever  used  return  byte  could  used  get  method  getrow  getclosestatorbefore  etc  advantage  making  timestamp  firstclass  citizen  hbase  hasnt  far  thought,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2722,clean  log  message  code  recoverablezookeeper  recoverablezookeeper  number  log  message  comment  dont  really  read  correctly  piece  code  cleaned  simple  cleanup  shouldnt  actual  behavioral  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2723,improve  performance  block  cache  key  pure  random  read  test  data  thats  100  block  cache  see  spending  quite  time  getblockcachekey  quote  ipc  server  handler  19  62023  daemon  prio10  tid0x00007fe0501ff800  nid0x6c87  runnable  0x00007fe0577f6000  javalangthreadstate  runnable  javautilarrayscopyofarraysjava2882  javalangabstractstringbuilderexpandcapacityabstractstringbuilderjava100  javalangabstractstringbuilderappendabstractstringbuilderjava390  javalangstringbuilderappendstringbuilderjava119  orgapachehadoophbaseiohfilehfilegetblockcachekeyhfilejava457  orgapachehadoophbaseiohfilehfilereaderv2readblockhfilereaderv2java249  orgapachehadoophbaseiohfilehfileblockindexblockindexreaderseektodatablockhfileblockindexjava209  orgapachehadoophbaseiohfilehfilereaderv2scannerv2seektohfilereaderv2java521  orgapachehadoophbaseiohfilehfilereaderv2scannerv2seektohfilereaderv2java536  orgapachehadoophbaseregionserverstorefilescannerseekatorafterstorefilescannerjava178  orgapachehadoophbaseregionserverstorefilescannerseekstorefilescannerjava111  orgapachehadoophbaseregionserverstorefilescannerseekexactlystorefilescannerjava219  orgapachehadoophbaseregionserverstorescannerinitstorescannerjava80  orgapachehadoophbaseregionserverstoregetscannerstorejava1689  orgapachehadoophbaseregionserverhregionregionscannerimplinithregionjava2857  quote  since  hfile  name  size  known  offset  long  possible  allocate  exactly  need  maybe  use  byte  key  drop  separator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2724,bump  default  hfileblockcachesize  hfilev2  here  email  sent  mailing  list  describing  problem  quote  thought  stuck  writing  detailed  block  caching  documentation  hfilev2  index  live  block  cache  mean  upgrade  may  sudden  get  terrible  cache  hit  ratio  memory  taken  index  somewhat  mitigated  fact  people  dont  usually  need  keep  index  block  memory  end  efficient  brings  question  set  hfileblockcachesize  higher  since  index  kept  block  cache  currently  set  20  looking  production  machine  see  storefileindexsize  around  600700mb  thats  potentially  much  data  id  block  cache  likely  half  thats  really  used  actively  would  good  new  default  25  30  handle  pushed  bcmemstore  size  limit  change  quote  ill  bump  25  put  release  note  fact  people  verify  setting  upgrading  make  sure  memstoreblock  cache  isnt  80  meaning  theyd  havent  change  block  cache  size  would  bumped  memstores  40  60,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
2725,allow  hmsgs  carry  payload  eg  exception  happened  remote  side  make  look  master  log  get  general  sense  failure  type  etc  across  cluster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2726,support  checksum  hbase  block  cache  current  implementation  hdfs  store  data  one  block  file  metadatachecksum  another  block  file  mean  every  read  hbase  block  cache  actually  consumes  two  disk  iop  one  datafile  one  checksum  file  major  problem  scaling  hbase  hbase  usually  bottlenecked  number  random  disk  iop  storagehardware  offer,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
2727,uber  hbck  online  automated  repair  table  integrity  region  consistency  problem  current  0905  0920rc2  version  hbck  detects  region  consistency  table  integrity  invariant  violation  however  fix  automatically  repair  region  consistency  case  deployment  problem  updated  version  able  handle  case  including  new  orphan  regiondir  case  complete  likely  deprecate  offlinemetarepair  tool  subsume  several  open  metahole  related  issue  here  approach  comment  top  new  version  file  code  hbasefsck  hbck  tool  checking  repairing  region  consistency  table  integrity  region  consistency  check  verify  meta  region  deployment  region  server  state  data  hdfs  regioninfo  file  accordance  table  integrity  check  verify  possible  row  key  resolve  exactly  one  region  table  mean  individual  degenerate  backwards  region  hole  region  overlapping  region  general  repair  strategy  work  step  1  repair  table  integrity  hdfs  merge  fabricate  region  2  repair  region  consistency  meta  assignment  table  integrity  repair  table  region  directory  scanned  regioninfo  file  table  integrity  verified  orphan  region  region  regioninfo  file  hole  new  region  fabricated  backwards  region  sidelined  well  empty  degenerate  endkeystartkey  region  overlapping  region  new  region  created  data  merged  new  region  table  integrity  repair  deal  solely  hdfs  done  offline  hbase  region  server  master  need  running  phase  use  completely  reconstruct  meta  table  offline  fashion  region  consistency  requires  three  condition  1  valid  regioninfo  file  present  hdfs  region  dir  2  valid  row  regioninfo  data  meta  3  region  deployed  regionserver  assigned  region  consistency  requires  hbck  contact  hbase  master  region  server  connect  must  first  called  successfully  much  region  consistency  information  transient  le  risky  repair  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
2728,remove  getregionserverwithoutretries  getregionserverwithretries  hconnection  interface  broke  meta  method  hconnection  take  servercallables  hconnections  inevitably  make  tangle  model  frustrates  able  mocked  implemenations  hconnection  method  better  belong  something  like  hconnectionmanager  elsewhere  altogether,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2729,basic  client  pushback  mechanism  current  blocking  close  limit  memstores  multiplier  factor  many  store  file  global  memstore  memory  bad  coarse  confusing  hitting  hbase5161  really  becomes  obvious  need  something  better  little  brainstorm  stack  came  quickly  two  solution  send  exception  client  like  overloadedexception  thats  thrown  situation  happens  like  getting  past  low  memory  barrier  would  thrown  client  get  handler  check  putting  deleting  client  would  treat  retryable  exception  ideally  wouldnt  check  meta  new  location  could  fancy  multiple  level  pushback  like  send  exception  25  client  go  situation  persists  easy  implement  well  using  lot  io  send  payload  least  wouldnt  sit  r  memory  send  message  alongside  successful  put  delete  tell  client  slow  little  way  dont  back  forth  payload  client  server  cleaner  think  involved  solution  every  case  r  obvious  thing  notify  operator  situation  log  web  ui  metric  etc  idea,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2730,delete  ttl  store  file  compaction  selection  currently  hbase  deletes  ttl  store  file  compaction  change  sequence  delete  ttl  store  file  selecting  store  file  compaction  way  hbase  keep  deleting  old  invalid  store  file  without  compaction  also  prevent  unnecessary  compaction  since  ttl  store  file  deleted  compaction  selection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2731,utilize  tthreadedselectorserver  remove  redundant  code  thriftserver  hregionthriftserver  tthreadedselectorserver  good  rpcheavy  situation  io  limited  one  cpu  see  httpsissuesapacheorgjirabrowsethrift1167  porting  related  class  form  thrift  trunk  thrift070  lot  repeat  code  thriftserver  hregionthriftserver  code  moved  runnable  called  thriftserverrunner,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2732,improve  client  scanner  interface  current  client  scanner  interface  pretty  ugly  need  instantiate  hstorekey  sortedmaptext  byte  externally  pas  next  pretty  bad  starter  client  choose  implementation  map  create  extra  brain  cycle  figure  hstorekey  doesnt  show  anywhere  else  entire  client  side  api  bubble  next  way  get  row  presumably  timestamp  column  propose  supplant  hscannerinterface  scanner  easiertouse  version  client  next  method  would  look  something  like  code  public  rowresult  next  throw  ioexception  code  pack  data  much  cleanly  including  using  cell  value  instead  raw  byte  meaning  much  granular  timestamp  information  also  dont  need  hstorekey  anymore  breaking  scanner  away  hscannerinterface  leave  internal  scanning  code  completely  alone  keep  using  hstorekeys  make  client  cleaner,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1
2733,provide  basic  building  block  multirow  local  transaction  final  iteration  issue  provides  generalized  public  mutaterowswithlocks  method  hregion  used  coprocessors  implement  atomic  operation  efficiently  coprocessors  already  region  aware  make  good  pairing  apis  feature  design  available  client  via  htable  api  took  long  time  arrive  apologize  public  exposure  erratic  retrospect  thought  process  hbase  provide  basic  building  block  multirow  local  transaction  local  mean  colocating  data  global  cross  region  transaction  discussed  bit  discussion  two  solution  emerged  1  keep  rowkey  determining  grouping  location  allow  efficient  intrarow  scanning  client  application  would  model  table  hbaserows  2  define  prefixlength  htabledescriptor  defines  grouping  row  region  never  split  inside  grouping  prefix  1  true  current  storage  paradigm  hbase  2  true  current  client  side  api  explore  two  sample  patch  discussed  length  dev  mailing  list  hbase3584  hbase5203  committed  supporting  atomic  cross  row  transaction  within  region  becomes  simple  aware  hesitation  usefulness  feature  start  somewhere  let  use  jira  discussion  ill  attach  patch  test  momentarily  make  concrete,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2734,ensure  compaction  cacheonwrite  data  block  create  unit  test  hbase3976  making  sure  dont  cache  data  block  write  compaction  even  cacheonwrite  enabled  generally  enabled  different  implementation  hbase3976  without  hbase4422  cacheconfig  top  89fb  created  liyin  cacheconfig  presumably  sure  even  work  since  patch  hbase3976  may  committed  need  create  unit  test  verify  dont  cache  data  block  write  compaction  resolve  hbase3976  new  unit  test  fail,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2735,filter  expired  store  file  scanner  compaction  compaction  time  hbase  generate  store  scanner  scan  list  store  file  would  efficient  filer  expired  store  file  since  need  read  key  value  store  file  optimization  already  implemented  89fb  building  block  hbase5199  well  supposed  noops  compact  expired  store  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2736,region  historian  whenever  try  debug  region  splitting  assignment  compaction  etc  issue  always  end  look  120  different  log  file  cryptic  name  region  try  piece  together  chain  event  challenging  best  effort  time  would  useful  would  new  utility  ive  nicknamed  region  historian  give  text  name  region  track  log  message  relevant  master  regionserver  log  interleave  message  way  timestamps  correctly  list  order  event  result  log  summary  accurately  describes  happened  region  lifetime  making  much  easier  try  figure  something  went  wrong  thing  could  would  replace  cryptic  log  message  simple  event  like  region  split  b  region  assigned  server  x  trace  lineage  region  backwards  parent  came  existence  im  sure  thing  would  think  would  useful  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2737,dynamic  schema  configuration  currently  ability  core  developer  add  pertable  percf  configuration  setting  heavyweight  need  add  reserved  keyword  way  stack  support  variable  longterm  youre  going  expose  explicitly  user  ended  using  configurationget  lot  lightweight  tweak  setting  youre  trying  understand  system  behavior  since  many  config  params  may  never  need  tuned  need  add  ability  put  read  arbitrary  kv  setting  hbase  schema  combined  online  schema  change  allow  u  safely  iterate  configuration  setting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2738,automagically  tweak  global  memstore  block  cache  size  based  workload  hypertable  neat  thing  change  size  given  cellcache  memstores  block  cache  based  workload  need  image  scroll  bottom  link  httpwwwhypertablecomdocumentationarchitecture  thatd  one  le  thing  configure,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0
2739,hbaseobjectwritable  able  serializedeserialize  generic  array  hbaseobjectwritable  encode  writables  cannot  encode  extends  writable  becomes  issue  example  adding  coprocessor  method  take  see  hbase5352,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2740,remove  minidfs  startup  minihbasecluster  change  minihbasecluster  always  require  minidfs  started  elsewhere  decide  read  write  based  config  passed  constructor  hbaseclustertestcase  updated  minidfs  spinup  shutdown  part  normal  process  completing  issue  prime  u  solving  truly  external  dfs  issue  making  test  suite  faster,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
2741,uberhbck  add  option  handle  offline  split  parent  recent  case  attempted  repair  cluster  suffered  hbase4238  67  generation  leftover  split  data  hbck  repair  option  development  version  hbase5128  treat  hdfs  ground  truth  didnt  check  split  offline  flag  found  meta  net  effect  essentially  attempted  merge  many  region  back  eldest  genenerations  parent  range  safe  guard  prevent  megamerges  added  hbase5128  issue  would  automate  handling  megamerge  avoiding  case  lingering  grandparent  strategy  would  add  check  meta  perform  part  catalog  janitor  responsibility  lingering  grandparent  would  potentially  include  option  sideline  region  deleting  grandparent  region  min  size  sidelining  mechanism  cleaning  meta  note  already  exists  mechanism  reload  region  bulk  loaded  mechanism  loadincrementalhfiles  used  readd  grandparent  automatically  splitting  necessary  hbase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2742,improve  exception  come  clientside  clientside  exception  contain  regionserver  region  client  going  looking  unknownscannerexception  came  client  look  like  something  happened  regionserver  cluster  20plus  machine  dont  know  looking,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2743,cut  link  client  zookeeper  ensemble  link  often  considered  issue  various  reason  one  limit  number  connection  zk  manage  stack  suggesting  well  remove  link  master  hconnection  choice  made  considering  existing  api  dont  want  break  first  patch  submit  hadoopqa  committed  show  progress  direction  taken  zookeeper  used  public  getter  let  client  whatever  want  close  zookeeper  closing  connection  deprecate  keep  read  get  master  address  create  master  done  temporary  zookeeper  connection  read  root  location  done  temporary  zookeeper  connection  questionable  used  public  function  locateregion  reworked  read  cluster  id  done  temporary  zookeeper  connection  check  base  done  available  done  zookeeper  connection  given  parameter  istabledisabledistableavailable  public  function  done  temporary  zookeeper  connection  called  internally  hbaseadmin  htable  getcurrentnrhrs  public  function  get  number  region  server  create  pool  thread  done  temporary  zookeeper  connection  master  used  getmaster  public  getter  zookeeper  deprecate  keep  ismasterrunning  public  function  used  internally  hmerge  hbaseadmin  gethtabledescriptor  public  function  offering  access  master  could  make  using  temporary  master  connection  well  main  point  hbase  class  zookeeper  zookeeperwatcher  really  designed  strongly  coupled  architecture  changed  requires  lot  modification  class  likely  adding  class  middle  hierarchy  something  like  anyway  non  connected  client  always  really  slower  tcp  connection  establishing  tcp  connection  slow  link  zk  client  seems  make  sense  use  case  however  wont  scale  tcp  connection  required  every  client  move  table  descriptor  part  away  client  need  find  new  place  issue  hbaseadmin  zk  master  may  put  timeout  connection  would  make  whole  system  le  deterministic  however,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2744,filter  one  cf  match  load  return  full  row  improve  performance  scan  kind  filter  scan  performed  whole  row  loaded  result  list  filter  exists  applied  detect  row  needed  scan  performed  several  cf  filter  check  data  subset  cf  data  cf  checked  filter  needed  filter  stage  decided  include  current  row  case  significantly  reduce  amount  io  performed  scan  loading  value  actually  checked  filter  example  two  cf  flag  snap  flag  quite  small  bunch  megabyte  used  filter  large  entry  snap  snap  large  10  gb  quite  costly  scan  needed  row  flag  specified  use  singlecolumnvaluefilter  limit  result  small  subset  region  current  implementation  loading  cf  perform  scan  small  subset  needed  attached  patch  add  one  routine  filter  interface  allow  filter  specify  cf  needed  operation  hregion  separate  scanner  two  group  needed  filter  rest  joined  new  row  considered  needed  data  loaded  filter  applied  filter  accepts  row  rest  data  loaded  data  speed  kind  scan  3050  time  also  give  u  way  better  normalize  data  separate  column  optimizing  scan  performed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2745,purge  startupdate  usage  internal  code  test  case  batch  update  nothing  internal  using  deprecated  startupdate  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2746,allow  import  optionally  use  hfileoutputformat  importtsv  support  importing  life  table  generate  hfiles  bulk  load  import  allow  could  even  consider  merging  tool  one  principle  difference  parsing  part  although  maybe  different  jira,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2747,add  baseline  compression  efficiency  datablockencodingtool  datablockencodingtool  currently  provide  baseline  compression  efficiency  eg  hadoop  compression  codec  applied  unencoded  data  eg  using  lzo  compress  block  would  like  following  column  report  possibly  percentage  raw  data  size  baseline  kv  blockcache  baseline  k  v  disk  lzo  compressed  k  v  datablockencoded  block  cache  k  v  datablockencoded  lzocompressed  disk  background  never  store  compressed  block  cache  always  store  encoded  data  block  cache  data  block  encoding  enabled  column  family,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2748,secure  bulk  load  design  doc  httpscwikiapacheorgconfluencedisplayhcataloghbasesecurebulkload  short  summary  security  stand  cover  bulkloadhfiles  feature  user  calling  method  bypass  acls  also  loading  made  cumbersome  secure  setting  hdfs  privilege  bulkloadhfiles  move  data  user  directory  hbase  directory  would  require  certain  write  access  privilege  set  solution  create  coprocessor  make  use  authmanager  verify  user  write  access  table  launch  mr  job  hbase  user  importing  ie  rewrite  text  hfiles  one  tricky  part  job  impersonate  calling  user  reading  input  file  expecting  user  pas  hdfs  delegation  token  part  securebulkload  coprocessor  call  extend  inputformat  make  use  token  output  written  temporary  directory  accessible  hbase  bulkloadhfiles  called,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2749,move  compressiondecompression  encoder  specific  encoding  context  part  working  hbase5313  want  add  new  columnar  encoderdecoder  make  sense  move  compression  part  encoderdecoder  1  scanner  columnar  encoded  block  lazy  decompression  specific  part  key  value  object  2  avoid  extra  byte  copy  encoder  hblockwriter  encoder  specified  writer  hblockwriter  use  default  compressioncontext  something  similar  today  code,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
2750,configurable  file  directory  based  umask  currently  many  file  created  hbase  user  written  using  default  file  permission  granted  hdfs  however  ensure  correct  usergroup  view  file  directory  need  able  apply  configurable  umask  either  directory  file  ticket  cover  setting  permission  file  written  dfs  opposed  thing  like  pid  log  file  impetus  allow  webuser  view  directory  structure  hbase  actually  see  actual  data  hbase  storing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2751,add  metric  hbase  debugmonitor  production  cluster  metric  wish  available  particular  although  average  f  latency  useful  histogram  recent  latency  90  read  completed  100ms  99  200ms  etc  would  useful  similar  histogram  latency  common  operation  get  put  delete  would  useful  counting  number  access  region  detect  hotspotting  exposing  current  number  hlog  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2752,unify  hregionmutaterowswithlocks  hregionprocessrow  mutaterowswithlocks  atomic  mutation  multiple  row  processrow  atomic  readmodifywrites  single  row  useful  generalize  processrowswithlocks  atomic  readmodifywrites  multiple  row  also  help  reduce  redundancy  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2753,dont  delete  hfiles  backup  mode  came  discussion  stack  would  nice  hbase  could  notified  backup  progress  via  znode  example  case  either  1  rename  hfiles  delete  filebck  2  rename  hfiles  special  directory  3  rename  general  trash  directory  would  need  tied  backup  mode  way  able  get  consistent  backup  based  hfiles  hdfs  snapshot  hard  link  would  better  option  1  make  cleanup  bit  harder,1,1,1,0,1,1,0,0,1,1,1,0,0,0,0,0,0
2754,add  ability  get  table  shell  currently  command  operate  table  shell  first  take  table  name  input  two  main  consideration  annoying  write  table  name  every  time  able  get  reference  table  current  implementation  wasteful  creates  new  htable  call  reuses  connection  since  us  configuration  able  get  handle  single  htable  operate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2755,replace  client  zookeeper  watcher  simple  zookeeper  read  code  package  need  read  data  zk  could  done  simple  read  actually  implemented  watcher  hold  zk  resource  fixing  could  also  opportunity  remove  need  client  provide  master  address  port,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2756,make  compaction  code  standalone  part  hbase2462  make  compaction  code  standalone  run  independent  hbase  make  easier  profile  try  stuff,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2757,move  exception  subpackages  exception  masterside  regionserverside  clientside  move  subpackages,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2758,avoid  byte  buffer  allocation  reading  value  result  object  calling  resultgetvalue  extra  dummy  keyvalue  associated  underlying  byte  array  allocated  well  persistent  buffer  contain  returned  value  avoided  reusing  static  array  dummy  object  passing  bytebuffer  object  value  destination  buffer  read  method  current  functionality  maintained  added  separate  method  call  stack  employ  described  change  provide  detail  patch  running  test  profiler  reduction  read  time  seems  40,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2759,hbck  disable  balancer  using  synchronousbalanceswitch  hbck  disable  balancer  using  adminbalanceswithbool  would  preferable  use  newer  synchronusbalanceswitch  method  found  094  trunk  branch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2760,hbck  handle  case  tableinfo  file  missing  092  branch  tableinfo  file  could  missing  hdfs  hbck  able  detect  repair  properly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2761,make  processbasedlocalhbasecluster  run  hdfs  make  robust  currently  processbasedlocalhbasecluster  run  top  raw  local  filesystem  need  start  processbased  hdfs  cluster  well  also  need  make  whole  thing  stable  use  unit  test,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2762,creating  region  master  initializes  creates  memstore  within  master  server  didnt  complete  analysis  attached  patch  save  025s  region  creation  locally  unit  test  work,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2763,parallelize  load  regioninfo  file  diagnosticrepair  portion  hbck  heavily  loaded  hdfss  dfs  node  may  respond  quickly  back  60  attempting  read  data  another  datanode  portion  information  gathered  hdfs  regioninfo  file  loaded  serially  hbase  cluster  100  1000  10000  region  encountering  60  delay  block  progress  painful  already  parallelization  portion  hdfs  information  load  operation  goal  move  reading  regioninfos  parallelized  section,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2764,enhance  hbck  sideline  overlapped  mega  region  many  region  one  overlapped  group  default  10  hbck  currently  doesnt  merge  since  take  time  case  sideline  region  group  break  overlapping  fix  inconsistency  later  sidelined  region  bulk  loaded  manually,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2765,investigate  ipc  performance  turning  file  io  running  performanceevaluation  test  1048576  sequential  writes  hbase  managed  achieve  7285  ipcs  per  second  running  performanceevaluation  sequential  write  test  modified  abort  instead  commit  possible  68337  operation  per  second  obviously  spending  lot  time  ipcs  need  investigate  find  bottleneck  marshalling  unmarshalling  socket  setup  teardown,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2766,fix  hlog  compression  incompatibility  ran  test  verify  wal  compression  turned  default  use  case  useful  value  two  order  magnitude  bigger  key  insert  time  wasnt  different  cpu  usage  15  higher  150  cpu  usage  v  130  compressing  wal  value  smaller  key  saw  38  improvement  insert  run  time  cpu  usage  33  higher  600  cpu  usage  v  450  im  sure  wal  compression  account  additional  cpu  usage  might  able  insert  faster  spend  time  memstore  per  second  memstores  bad  contain  ten  thousand  value  two  extreme  show  price  cpu  save  lot  machine  2  quad  ht  still  lot  idle  cpu,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2767,move  dynamic  metric  storage  hregion  hregion  right  responsibility  storing  static  count  latency  number  use  metric  package  since  map  incremented  set  lot  place  make  adding  functionality  hard  move  metric  functionality  schemametrics  making  class  naming  next  step  simplify  api  exposed  using  easier,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2768,add  verification  step  hlogperformanceevaluation  verify  wal  expected  count  edits,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2769,allow  adding  filter  tableinputformat  time  ensure  tif  subclassable  0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0
2770,name  filter  interface  confusing  dont  like  name  filter  method  rowfilterinterface  dont  really  tell  method  used  implementation  scanner  id  like  change  filtertext  filterrow  filtertext  text  byte  filtercolumn  worst  one  filternotnullsortedmaptext  byte  filterrowtext  sortedmaptext  byte  add  row  key  may  nice  timestamps  method  well  also  java  doc  could  cleaned  improved  tell  filtering  implemented  check  row  key  first  check  individual  column  finally  check  assembled  row  upon  positive  feedback  ill  create  patch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2771,query  fails  region  moved  let  regionserver  return  new  address  client  mainly  useful  rolling  restart  decrease  load  master  network  load  note  region  immediately  opened  close  seems  preferable  wait  retrying  server  optimisation  would  heuristic  depending  region  closed  rolling  restart  server  move  region  stop  may  failure  server  stopped  patch  wont  help  implementation  first  patch  region  move  added  parameter  regionserverclose  say  sending  region  regionserver  keep  list  moved  entry  kept  100  second  regionserver  sends  specific  exception  receives  query  moved  region  exception  contains  new  address  client  analysis  exeptions  update  cache  accordingly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2772,make  testacidguarantees  usable  system  testing  currently  testacidguarantees  run  via  main  always  abort  npe  dig  nonexistant  hbasetestingutility  flusher  thread  tool  work  properly  command  line  would  useful  long  running  test  used  conjunction  fault  injection  verify  row  acid  property,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2773,remove  hregioninterface  step  move  internals  pb  avoid  conversion  performance  reason  remove  hregioninterface  therefore  region  server  support  clientprotocol  adminprotocol  later  hregion  work  pb  message  directly,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,1
2774,hbck  refactor  parallel  workitem  future  would  convert  workitem  logic  low  level  notifies  rough  exception  handling  canonical  future  pattern  currently  two  instance  pattern  loading  hdfs  dirs  contacting  regionservers  assignment  soon  loading  hdfs  regioninfo  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2775,client  code  dont  wait  request  executed  resubmitting  request  error  client  function  hconnectionmanagerprocessbatchcallback  work  two  step  make  request  collect  failure  success  prepare  retry  mean  immediate  error  region  moved  split  dead  server  still  wait  initial  request  executed  submitting  failed  request  scenario  request  taking  5  second  final  execution  time  5  initial  request  1  wait  time  5  final  request  11  could  improve  analyzing  immediately  result  would  lead  u  scenario  mentioned  6  second  could  performance  improvement  nearly  50  many  case  much  50  request  execution  time  different,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2776,limit  amount  time  edit  live  memstore  colleague  mine  ran  interesting  issue  inserted  data  wal  disabled  happened  fit  aggregate  memstores  memory  two  week  later  problem  hdfs  cluster  caused  region  server  abort  found  data  lost  looking  log  found  memstores  flushed  two  week  option  flush  memstores  periodically  obvious  downside  like  many  small  storefiles  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2777,add  load  balancer  balancer  pluggable  give  option,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
2778,scanner  response  r  include  metric  rowskvs  filtered  currently  difficult  know  issuing  filter  percentage  row  skipped  filter  expose  basic  counter  back  client  scanner  object  example  number  row  filtered  row  key  alone  filterrowkey  number  time  filter  response  returned  filterkeyvalue  corresponding  filterreturncode  would  slickest  could  actually  return  tree  counter  case  filterlist  combining  filter  used  toplevel  good  start,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2779,adding  fuction  check  tableregion  compaction  feature  helpful  find  major  compaction  going  show  minor  compaction,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2780,offline  snapshot  hbase  096  continuation  hbase50  current  trunk  since  implementation  drastically  changed  opening  new  ticket,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2781,hbase  create  hbasespecific  mapfile  implementation  today  hbase  us  hadoop  mapfile  class  store  data  persistently  disk  convenient  already  done  maintained  people  however  beginning  look  like  might  possible  performance  benefit  hbasespecific  implementation  mapfile  incorporated  precise  feature  issue  serve  place  track  discussion  feature  might  included  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2782,improve  rit  performance  assignment  large  cluster  main  point  patch  lowering  number  copy  rit  list  lowering  number  synchronization  synchronizing  region  rather  everything  also  contains  fix  around  rit  notification  list  sometimes  modified  without  corresponding  notify  test  flakiness  correction  actually  unrelated  patch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2783,improvement  splitworker  speed  distributed  log  splitting  first，we  test  localmastersplitting  distributedlogsplitting  environment：34  hlog  file  5  regionserversafter  kill  one  4  r  th  splitting  work  400  region  one  hlog  file  localmastersplit60s  distributedlogsplitting165s  fact  production  environment  distributedlogsplitting  also  took  60  30  regionservers  34  hlog  file  regionserver  may  high  load  found  splitworker  split  one  log  file  took  20  30ms50ms  per  writerclose  10ms  per  create  writer  think  could  improvement  parallelizing  create  close  writer  thread  patch  change  logic  distributedlogsplitting  localmastersplitting  parallelizing  close  thread,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2784,retiring  region  used  exploit  remove  little  dance  around  region  close  region  first  get  moved  retiring  queue  idea  iirc  region  retiring  could  serve  read  close  going  business  meant  region  online  bit  longer  feature  used  region  added  retiring  get  bother  look  retiring  either  remove  retiring  cocept  altogether  else  make  use,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2785,move  keyvalue  hbasecommon  module  pull  keyvalue  hbasecommon  module  part  modularization  strategy  hbase5977  specifically  necessary  modularize  hbase4676  also  brings  class  hbasecommon  classsize  heapsize  htestconst  testkeyvalue  keyvaluetestutil  loadtestkvgenerator  testloadtestkvgenerator  md5hash  move  trivial  constant  hregioninfodelimiter  hregioninfo  hconstants,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
2786,timeouts  row  lock  scan  separate  apparently  timeout  used  row  locking  scanning  global  would  better  two  separate  timeouts  opening  issue  make  lars  george  happy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2787,hbck  check  specified  table  currently  hbck  fix  specified  table  fix  one  table  time  however  doesnt  check  health  specified  table  still  check  health  whole  system  table  specified  check  health  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2788,move  datablockencoding  related  class  hbasecommon  module  order  isolate  implementation  detail  hbase4676  prefixtrie  encoding  datablockencoders  putting  module  pull  datablockencoding  related  interface  hbasecommon  test  moved  patch  notable  change  trimming  dependency  hfileblock  add  dependency  much  regionserver  test  suite  pass  locally  tried  keep  simple  possible  let  know  concern,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2789,move  simple  keyvalue  test  hbasecommon  module  testkeyvalue  loadtestkvgenerator  testloadtestkvgenerator  move  hbasecommon  brings  md5hash  dependency  well  play  well  maven  discussed  hbase6162  moved  loadtestkvgenerator  srctest  folder  srcmain  folder  test  module  see  couple  file  import  statement  affected,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
2790,use  visitor  pattern  metaregion  reduce  code  clone  htable  hconnectionmanager  htable  hconnectionmanagertableservers  scan  meta  region  way  later  also  retry  one  time  fails  visitor  pattern  used  new  scanning  method  metaregion  accept  visitor  gather  information  region  name  table  list  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2791,possible  performance  improvement  client  batch  operation  presplit  send  background  today  batch  algo  noformat  operation  listop  add  todolist  todolist  maxsize  last  list  split  todolist  per  location  send  split  list  region  server  clear  todolist  wait  noformat  could  create  immediately  final  object  instead  intermediate  array  split  per  location  immediately  instead  sending  list  whole  full  send  enough  data  single  location  would  noformat  operation  listop  get  location  add  todo  locationtodolist  locationtodolist  maxlocationsize  send  locationtodolist  region  server  clear  locationtodolist  dont  wait  continue  loop  send  remaining  wait  noformat  trivial  write  add  error  management  retried  list  must  shared  operation  added  todolist  doable  interesting  mainly  big  writes,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
2792,hbck  group  together  sidelined  region  need  bulk  loaded  later  currently  hbck  sideline  region  break  big  overlap  group  avoid  possible  compaction  region  split  sidelined  region  bulk  loaded  back  later  information  region  output  much  easier  group  together  sideline  rootdir  example  hbasehbcktobeloaded  even  lose  output  file  still  know  region  load  back,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2793,audit  log  message  include  column  family  qualifier  information  consistently  code  related  issue  accesscontrollerjavapermissiongranted  creating  audit  log  method  one  following  grant  access  create  audit  log  table  name  deny  access  table  permission  create  audit  log  table  name  deny  access  column  family  qualifier  permission  create  audit  log  specific  family  qualifier  case  one  column  family  andor  qualifier  request  loss  information  even  case  one  column  family  andor  qualifier  involved  information  may  lost  would  better  behavior  consistently  included  information  request  regardless  access  granted  denied  regardless  permission  caused  denial  column  family  qualifier  info  part  audit  log  message,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2794,reading  wal  file  recovery  lead  time  lost  hdfs  timeouts  using  dead  datanodes  hbase  writes  writeaheadlog  revover  hardware  failure  log  written  hdfs  zookeeper  hbase  get  informed  usually  30  start  recovery  process  mean  reading  writeaheadlog  replay  edits  server  standard  deployment  hbase  process  regionserver  deployed  box  datanodes  mean  box  stop  weve  actually  lost  one  edits  lost  regionserver  datanode  hdfs  mark  node  dead  10  minute  appears  available  try  read  block  recover  delaying  recovery  process  60  second  read  usually  fail  socket  timeout  file  still  opened  writing  add  extra  20  risk  losing  edits  connect  ipc  dead  dn  possible  solution  shorter  dead  datanodes  detection  nn  requires  nn  code  change  better  dead  datanodes  management  dfsclient  requires  dfs  code  change  nn  customisation  write  wal  file  another  dn  instead  local  one  reordering  block  returned  nn  client  side  put  block  dn  dead  r  end  priority  queue  requires  dfs  code  change  kind  workaround  solution  retained  last  one  compared  discussed  mailing  list  proposed  patch  modify  hdfs  source  code  add  proxy  two  reason  hdfs  function  managing  block  order  static  md5md5crc32filechecksum  implementing  hook  dfsclient  would  require  implement  partially  fix  change  dfs  interface  make  function  non  static  put  hook  static  none  solution  clean  adding  proxy  allows  put  code  hbase  simplifying  dependency  management  nevertheless  would  better  hdfs  solution  allows  target  last  version  could  allow  minimal  interface  change  non  static  method  moreover  writing  block  non  local  dn  would  even  better  solution  long  term,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2795,enable  multithread  memstore  flush  kv  large  hlog  closed  highpressure  putting  found  memstore  often  high  water  mark  block  putting  enable  multithread  memstore  flush  performance  test  data  reference  1test  environment  ：  random  writting；upper  memstore  limit  56gblower  memstore  limit  48gb400  region  per  regionserver；row  len50  byte  value  len1024  bytes5  regionserver  300  ipc  handler  per  regionserver5  client  50  thread  handler  per  client  writing  2test  result  one  cacheflush  handler  tps  78ks  per  regionserver  flush101mbs  per  regionserver  appears  many  aboveglobalmemstorelimit  blocking  two  cacheflush  handler  tps  107ks  per  regionserver  flush1246mbs  per  regionserver  200  thread  handler  per  client  two  cacheflush  handler  tps161ks  per  regionserver  flush186mbs  per  regionserver,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
2796,mapfile  index  empty  run  repair  cluster  lost  data  made  interesting  scenario  hbase  one  empty  index  file  would  get  eofexception  tried  scan  open  region  hbase646  added  checking  data  info  index  file  tried  run  repair  index  wrong  place  wasnt  first  removing  broken  index  itd  fail,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2797,deprecate  htablepool  favor  hconnectiongettable  update  propose  deprecating  htablepool  instead  introduce  gettable  method  hconnection  allow  hconnection  manage  threadpool  initial  proposal  propose  simple  tablepool  could  called  lighthtablepool  something  better  name  internally  would  maintain  hconnection  executor  service  invocation  gettable  would  create  new  htable  close  would  close  testing  find  light  weight  htablepool  easier  monitor  term  resource  used  would  hardly  dozen  line  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2798,quarantine  corrupted  hfiles  hbck  weve  encountered  upgrade  090  hbases  2021x  hdfs  092  hbases  hdfs  2x  get  stuck  havent  able  duplicate  problem  dev  environment  suspect  may  related  hdfs3731  hbase  side  seems  reasonable  quarantine  likely  truncated  hfiles  could  later  recovered  here  example  exception  weve  encountered  code  20120718  055501152  error  handleropenregionhandler  openregionhandlerjavaopenregion346  failed  open  regionusermappings080112102aa76ef98197605d341b9e6c5824d2bc10011317824890618eaed0e7abc6d27d28ff0e5a9b49c4c  0d  javaioioexception  javalangillegalargumentexception  invalid  hfile  version  842220600  expected  1  2  orgapachehadoophbaseiohfilefixedfiletrailerreadfromstreamfixedfiletrailerjava306  orgapachehadoophbaseiohfilehfilepickreaderversionhfilejava371  orgapachehadoophbaseiohfilehfilecreatereaderhfilejava387  orgapachehadoophbaseregionserverstorefilereaderinitstorefilejava1026  orgapachehadoophbaseregionserverstorefileopenstorefilejava485  orgapachehadoophbaseregionserverstorefilecreatereaderstorefilejava566  orgapachehadoophbaseregionserverstoreloadstorefilesstorejava286  orgapachehadoophbaseregionserverstoreinitstorejava223  orgapachehadoophbaseregionserverhregioninstantiatehstorehregionjava2534  orgapachehadoophbaseregionserverhregioninitializehregionjava454  orgapachehadoophbaseregionserverhregionopenhregionhregionjava3282  orgapachehadoophbaseregionserverhregionopenhregionhregionjava3230  orgapachehadoophbaseregionserverhandleropenregionhandleropenregionopenregionhandlerjava331  orgapachehadoophbaseregionserverhandleropenregionhandlerprocessopenregionhandlerjava107  orgapachehadoophbaseexecutoreventhandlerruneventhandlerjava169  javautilconcurrentthreadpoolexecutorworkerruntaskthreadpoolexecutorjava886  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava908  javalangthreadrunthreadjava619  caused  javalangillegalargumentexception  invalid  hfile  version  842220600  expected  1  2  orgapachehadoophbaseiohfilehfilecheckformatversionhfilejava515  orgapachehadoophbaseiohfilefixedfiletrailerreadfromstreamfixedfiletrailerjava303  17  code  specifically  fixedfiletrailer  incorrect  seemingly  missing,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
2799,migration  addcolumndeletecolumn  functionality  metautils  needed  hbase533,1,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,1
2800,replicationsourcemanager  able  track  multiple  wal  path  currently  replicationsourcemanager  us  logrolled  receive  notification  new  hlog  remembers  latestpath  region  server  multiple  wal  support  need  keep  track  multiple  path  replicationsourcemanager,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
2801,multiregion  transaction  optimistic  concurrency  control  need  acid  transaction  across  table  issue  adding  transaction  span  multiple  region  envision  many  competing  writes  readdominated  general  make  optimistic  concurrency  control  occ  seem  like  way  go,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2802,resourcechecker  refinement  based  discussion  hbase6234  resourcechecker  added  n  keywal  help  resolve  hadoop  qa  issue  since  widely  utilized  modularization  drop  resourcechecker  test  moved  hbasecommon  module  bringing  resourcechecker  hbasecommon  would  involved  bringing  dependency  quite  far  reaching  question  get  rid  refactor  resuse,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2803,make  htable  hregion  hregionserver  hstore  hcolumndescriptor  subclassable  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2804,htablecoprocessorexec  always  scan  whole  table  current  logic  htablecoprocessorexec  always  scan  entire  meta  table  loading  memory  filter  key  return  fall  specified  range  version  patch  scan  portion  meta  specified  key  range  return  put  simply  loadallthenfilter  afterwards  onlyscanwhatisneeded  former  low  efficiency  greatly  impact  regionserver  carrying  meta  many  coprocessorexec  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2805,remove  unnecessary  throw  ioexception  bytesreadvlong  remove  throw  ioexception  caller  doesnt  catch  ignore  code  public  static  long  readvlongfinal  byte  buffer  final  int  offset  throw  ioexception  code  also  add  code  public  static  int  readvintfinal  byte  buffer  final  int  offset  throw  ioexception  return  intreadvlongbufferoffset  code  useful  code  put  long  variable  length  encoded  number  offset  result  byte  array  param  vint  integer  make  vint  param  result  buffer  put  vint  return  vint  length  byte  vint  public  static  int  vinttobytesbyte  result  int  offset  final  long  vint  long  vint  112  127  resultoffset  byte  return  1  int  len  112  0  1l  take  one  complement  len  120  long  tmp  tmp  0  tmp  tmp  8  len  resultoffset  byte  len  len  len  120  len  120  len  112  int  idx  len  idx  0  idx  int  shiftbits  idx  1  8  long  mask  0xffl  shiftbits  resultoffset  bytei  mask  shiftbits  return  len  1  decode  vint  buffer  pointed  ptr  increment  offset  ptr  length  vint  param  ptr  pointer  byte  array  buffer  return  decoded  vint  value  int  public  static  int  vintfrombytesimmutablebyteswritable  ptr  return  int  vlongfrombytesptr  decode  vint  buffer  pointed  ptr  increment  offset  ptr  length  vint  param  ptr  pointer  byte  array  buffer  return  decoded  vint  value  long  public  static  long  vlongfrombytesimmutablebyteswritable  ptr  final  byte  buffer  ptrget  final  int  offset  ptrgetoffset  byte  firstbyte  bufferoffset  int  len  writableutilsdecodevintsizefirstbyte  len  1  ptrsetbuffer  offset1  ptrgetlength  return  firstbyte  long  0  int  idx  0  idx  len1  idx  byte  b  bufferoffset  1  idx  8  b  0xff  ptrsetbuffer  offsetlen  ptrgetlength  return  writableutilsisnegativevintfirstbyte  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2806,allow  master  info  server  started  read  mode  case  user  could  want  web  ui  accessible  might  want  split  compact  functionality  usable  allowing  web  ui  start  readonly  mode  would  good,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2807,make  bloomfilter  truefalse  selfsizing  remove  bloomfilter  option  one  bloomfilter  type  make  sense  hbase  context  also  make  bloomfilter  selfsizing  know  size  flushing  putting  02  api  change  simpler  punt  later,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
2808,mttr  improve  region  server  recovery  time  distributed  log  replay  saw  interesting  issue  cluster  went  hard  30  node  1700  wals  replay  replay  took  almost  hour  look  like  could  run  faster  much  time  spent  zking  nning  putting  096  get  look  least  always  punt,1,1,1,0,1,1,0,0,0,0,1,0,0,0,1,0,1
2809,hbase  master  rebalance  region  assignment  periodically  master  currently  region  assignment  startup  split  dead  regionservers  mean  join  new  regionserver  cluster  startup  get  assigned  fair  share  alreadyserved  region  would  expect  get  share  new  region  served  master  periodically  check  balance  region  based  whatever  assignment  function  instead  reaction  listed  event,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2810,refactor  compaction  selection  config  code  similarly  089fb  change  separate  jira  refactoring  change  hbase7055  one  code  review,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
2811,improve  byte  accept  byte  buffer  dont  allow  u  directly  access  backing  array  inside  hbase  seems  implicit  assumption  byte  buffer  backed  array  readonly  freely  call  bytebufferarray  arrayoffset  without  runtime  exception  class  including  byte  supposed  used  user  outside  hbase  think  possibility  method  receive  byte  buffer  dont  hold  assumption,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2812,add  data  block  encoding  opts  performance  evaluation  add  ability  specify  data  block  encoding  configuration  option  blockencodingtype  propertyvalue  example  hbase  orgapachehadoophbaseperformanceevaluation  mapreducetasktimeout60000  blockencodingdiff  sequentialwrite  1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2813,prefix  compression  trie  data  block  encoding  hbasecommon  hbaseserver  change  hbasecommon  hbaseserver  change  hbase4676  prefix  compression  trie  data  block  encoding,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
2814,compression  test  add  couple  test  verify  storecreatewriterintmp  respect  compression  data  block  encoding  hbase5690  lz4  compression  support  hbase5838,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2815,add  multi  get  remotehtable  rest  server  support  multiget  remotehtable  class  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2816,hlog  file  meta  root  edits  hbase6774  discussion  separating  edits  meta  region  region  edits  wrt  edits  written  jira  track  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0
2817,create  integration  test  balancing  region  killing  region  server  2  original  test  general  need  another  one  would  targeted  would  test  master  logic  particular  eg  kill  master  rediscovered  hbase6060  using  first  run,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2818,compaction  tool  hbase5616  part  compaction  code  refactor  compactiontool  added  issue  tool  test  mockito  required  test  scope  removed  pomxml  otherwise  tool  doesnt  start  mock  used  tool  mocking  hregiongetregioninfo  code  store  us  hregionregioninfo  directly  hstorejaval2021  hstorejaval1389  hstorejaval1402  end  npe  tool  mocked  store  us  dummy  family  compacted  file  doesnt  get  family  property  specified  compression  encoding  end  compaction  compactiontooljaval155  default  compaction  file  removed  note  compacted  one  already  removed  inside  storecompact  end  empty  dir  compact  everything  ive  fixed  stuff  added  support  run  compaction  mr  job  specify  table  compact  regionfamily  specify  region  compact  family  specify  family,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
2819,supporting  hlog  appends  thank  open  ticket  track  need  changed  support  appends  coding  done  hadoop1700,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2820,rename  rest  server  main  restserver  jps  rest  server  shown  main  class  main  special  reason  called  main  suggest  change  restserver  instead,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2821,add  verbose  logging  option  hconnectionmanager  course  hbase7250  found  clientside  error  well  serverside  error  thats  another  question  hard  debug  local  commits  useful  notthathacky  hconnectionmanager  logging  added  need  productionize  default  easytoenable  debugging,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2822,remove  flushrelated  record  wal  make  locking  granular  comment  many  people  hbase6466  hbase6980  indicate  flush  record  wal  useful  removed,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
2823,expose  master  table  operation  coprocessors  way  masterservices  something  im  working  coprocessor  initializes  would  like  add  column  table  column  missing  exposing  master  table  operation  coprocessors  way  masterservices  solved  problem  generally  useful  master  coprocessors,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2824,online  merge  support  executing  region  merge  transaction  regionserver  similar  split  transaction  process  merging  two  region  aclient  sends  rpc  dispatch  merging  region  master  bmaster  move  region  together  regionserver  heavily  loaded  region  resided  cmaster  sends  rpc  merge  region  regionserver  dregionserver  executes  region  merge  transaction  thread  pool  ethe  bcd  run  asynchronously  process  region  merge  transaction  aconstruct  new  region  merge  transaction  bprepare  merge  transaction  transaction  canceled  unavailable  eg  two  region  dont  belong  table  two  region  adjacent  noncompulsory  merge  region  closed  reference  cexecute  transaction  following  set  region  transition  set  merging  state  setmerginginzk  created  temporary  merge  data  directory  createdmergedir  closed  merging  region  closedregiona  merging  region  taken  server  online  region  list  offlinedregiona  closed  merging  region  b  closedregionb  merging  region  b  taken  server  online  region  list  offlinedregionb  started  creation  merged  region  startedmergedregioncreation  point  return  got  transaction  recoverable  crashing  regionserver  ponr  droll  back  step  c  throw  exception  usage  hbaseadminmergeregions  see  detail  patch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2825,cleanup  client  connection  layer  issue  originated  discussion  hbase7442  currently  broken  abstraction  hbaseclient  bound  single  configuration  instance  time  construction  reused  connection  cluster  combined  multiple  overlapping  layer  connection  caching  going  code  seems  like  lot  mismatch  higher  layer  lower  layer  much  abstraction  lower  layer  clientcache  stuff  seems  completely  unused  currently  effectively  hbaseclient  singleton  secureclient  well  092094  client  code  dont  see  anything  call  constructor  rpcenginegetproxy  version  nondefault  socket  factory  lot  code  around  seems  like  built  waste  fact  single  configuration  fixed  hbaseclient  seems  like  broken  abstraction  currently  stand  addition  cluster  id  configuration  parameter  max  retries  retry  sleep  fixed  time  construction  look  code  look  like  clientcache  sharing  hbaseclient  instance  unnecessary  complication  cache  hbaseclient  instance  hconnectionmanager  already  mapping  configuration  hconnection  seems  like  hconnectionimplementation  instance  hbaseclient  instance  away  clientcache  mapping  would  keep  hbaseclient  associated  single  clusterconfiguration  fix  current  breakage  reusing  hbaseclient  different  cluster  need  refactoring  interaction  hconnectionimplementation  hbaserpcrpcengine  hbaseclient  hand  might  want  expose  separate  rpcenginegetclient  method  return  new  rpcclient  interface  implemented  hbaseclient  move  rpcenginegetproxystopproxy  implementation  client  proxy  invocation  go  client  without  requiring  static  client  cache  havent  fully  thought  could  missing  important  aspect  approach  least  seems  like  step  right  direction  fixing  client  abstraction,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
2826,add  efficient  way  batch  update  many  row  hbase747  introduced  simple  way  batch  update  many  row  goal  issue  enhanced  version  send  many  row  single  rpc  region  server  client  code  figure  row  go  server  group  accordingly  send,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2827,canary  monitoring  program  specifically  regionserver  motivation  ticket  provide  canary  monitoring  tool  specifically  hregionserver  detail  follows  1  tool  required  operation  team  due  thought  canary  region  hbase  many  implemented  coarsegranular  one  based  original  oahhtoolcanary  2  tool  implemented  multithreading  mean  get  request  sent  thread  reason  use  way  due  suffered  region  server  hung  issue  root  cause  still  clear  tool  help  operation  team  detect  hung  region  server  example  1  tool  doc  binhbase  orgapachehadoophbasetoolregionservercanary  help  usage  opts  regionservername  1  regionservrname  2  regionservername  fqdn  servername  use  linux  commandhostname  f  check  servername  opts  help  show  help  exit  e  use  regionservername  regular  expression  mean  regionservername  regular  expression  pattern  f  b  stop  whole  program  first  error  occurs  default  true  n  timeout  check  default  600000  milisecs  daemon  continuous  check  defined  interval  interval  n  interval  check  sec  2  send  request  regionserver  hbase  cluster  binhbase  orgapachehadoophbasetoolregionservercanary  3  send  request  regionserver  given  name  binhbase  orgapachehadoophbasetoolregionservercanary  rs1domainname  4  send  request  regionservers  given  regularexpression  opttrendcircusopstoolbinhbasecanarymonitoreachregionserversh  e  rs1domainnamepattern  another  example  binhbase  orgapachehadoophbasetoolregionservercanary  e  twpoctmpuppethdn0912clienttwtrendnetorg  5  send  request  regionserver  also  set  timeout  limit  test  query  regionserverrs1domainname  timeout  limit  10sec  f  false  mean  exit  program  even  test  failed  binhbase  orgapachehadoophbasetoolregionservercanary  f  false  10000  rs1domainname  echo  1  timeout  echo  6  run  daemon  mode  mean  send  request  regionserver  periodically  binhbase  orgapachehadoophbasetoolregionservercanary  daemon,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2828,convert  test  use  hbasetestingutilitycreatemultiregions  hbacreatetable  like  discussed  hbase7534  hbasetestingutilitycreatemultiregions  disappear  come  back  there  25  different  place  code  rely  need  changed  way  changed  testreplication  perfect  someone  want  get  started  hbase  dev,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2829,transparent  tablecf  encryption  introduce  transparent  encryption  hbase  disk  data  depends  separate  contribution  encryption  codec  framework  hadoop  core  aesni  native  code  codec  work  done  context  mapreduce4491  id  gather  additional  jiras  common  hdfs  part  requirement  transparent  encryption  cf  table  level  protect  data  leakage  file  rest  twotier  key  architecture  consistency  best  practice  feature  rdbms  world  builtin  key  management  flexible  nonintrusive  key  rotation  mechanism  exposed  modifiable  user  hardware  security  module  integration  via  java  keystore  hbck  support  transparently  encrypted  file  plugin  architecture  hbck  additional  goal  shell  support  administrative  function  avoid  performance  impact  null  crypto  codec  case  play  nicely  change  underway  hfile  block  coding  etc  aiming  rough  parity  oracle  transparent  tablespace  encryption  feature  described  httpwwworaclecomtechnetworkdatabaseowpsecurityadvancedsecurity11gr133411pdf  quote  “transparent  data  encryption  us  2tier  key  architecture  flexible  nonintrusive  key  rotation  least  operational  performance  impact  application  table  least  one  encrypted  column  table  key  applied  encrypted  column  table  equally  encrypted  tablespace  tablespace  key  table  key  stored  data  dictionary  database  tablespace  key  stored  header  tablespace  additionally  header  underlying  o  file  make  tablespace  key  encrypted  tde  master  encryption  key  stored  outside  database  external  security  module  either  oracle  wallet  pkcs12  formatted  file  encrypted  using  passphrase  supplied  either  designated  security  administrator  dba  setup  hardware  security  module  hsm  device  higher  assurance  …”  quote  design  detail  forthcoming  design  document  patch  soon  clearance  place,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2830,replication  create  interface  replication  peer  0,1,0,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0
2831,replication  create  interface  replication  queue  0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
2832,add  costless  notification  mechanism  master  regionservers  client  would  useful  add  mechanism  distribute  information  client  regionservers  especially  would  useful  know  globally  regionservers  client  apps  regionservers  dead  would  allow  lower  load  system  without  client  using  staled  information  going  dead  machine  make  recovery  faster  client  point  view  common  use  large  timeouts  client  side  client  may  need  lot  time  declaring  region  server  dead  trying  another  one  client  receives  information  separatly  region  server  state  take  right  decision  continuestop  wait  accordingly  also  send  information  example  instruction  like  slow  instruct  client  increase  retries  delay  technically  master  could  send  information  lower  load  system  multicast  communication  ie  master  connect  server  tcp  packet  every  10  second  receiver  depend  information  available  great  break  anything  optional  end  would  thread  master  sending  protobuf  message  dead  server  multicast  socket  socket  configured  anything  client  side  receive  information  node  dead  refresh  cache,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2833,client  retry  timeout  doesnt  need  x2  fallback  going  different  server  see  hbase7520  go  server  get  bunch  failure  finally  learn  region  b  doesnt  make  sense  wait  30  second  going  b,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2834,remove  hfilev1  code  hfilev1  removed  regionserver  somewhat  drag  development  working  lower  level  read  path  impediment  cleaning  store  code  v1  hfiles  ceased  written  092  v1  reader  left  place  user  could  upgrade  090  092  hfiles  compacted  092  v1  code  longer  needed  decided  leave  v1  code  place  094  user  could  upgrade  directly  090  094  code  still  trunk  probably  shown  door  see  option  1  delete  code  tell  people  make  sure  compact  everything  using  092  094  2  create  standalone  script  people  run  092  094  cluster  iterates  filesystem  print  v1  file  message  user  run  major  compaction  3  add  functionality  0960  first  release  maybe  hbck  proactively  kill  v1  file  sure  none  upgrading  096  098  4  punt  098  probably  one  option  year  would  vote  1  2  allow  u  v1free  0960  hfilev1  already  survived  2  major  release  upgrade  think  many  would  agree  enough  pre10  free  product  remove  0960  way  introduce  nice  performance  improvement  subsequent  096x  release,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
2835,dont  use  bulk  assigner  assigning  several  region  assign  one  region  bulk  assigner  may  slower,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2836,rename  storeconfiguration  remove  unnecessary  method  storeconfiguration  interface  name  confusing  one  method  unnecessary,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2837,hbasetestingutilitytruncatetable  acting  like  cli  would  like  discus  behavior  truncatetable  method  hbasetestingutility  currently  removing  data  scandelete  pattern  however  truncate  command  cli  additional  thing  disables  table  drop  creates  similar  column  descriptor  enables  table  think  truncatetable  method  misleading  example  used  force  coprocessor  reloaded  course  disable  enable  table  within  unit  test  perhaps  deserves  discussed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2838,refactor  openregionhandler  cleanup  happens  one  place  finally  block  based  discussion  hbase7698  jimmy  suggested  improvment  look  httpsissuesapacheorgjirabrowsehbase7698focusedcommentid13572736pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment13572736,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2839,use  store  interface  instead  hstore  coprocessor  compaction  store  interface  almost  never  used  coprocessors  compaction  using  hstore  replace  hstore  store  ability  create  custom  store  testing  instead  injecting  stuff  hstore,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
2840,clean  compactionrequest  compactselection  part  1  certain  part  compactionrequest  unnecessary  offpeak  hour  management  part  way  selection  part  way  store  part  way  policy  need  cleaned  preparation  compactionpolicy  return  compactionrequest,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
2841,improve  hbase  thrift  v1  return  result  sorted  order  hbase  natively  store  column  sorted  based  column  qualifier  scan  guaranteed  return  sorted  column  java  api  work  fine  thrift  api  broken  hbase  us  treemap  ensures  sort  order  maintained  however  hbase  thrift  specification  us  simple  map  store  data  map  since  unordered  doesnt  result  column  returned  sort  order  consistent  storage  hbase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2842,add  compaction  policy  explores  storefile  group  workload  stable  compaction  large  small  using  current  storefile  selection  algorithm  currently  find  first  file  sizefi  sum0  i1  filesizefx  ensure  min  number  file  arent  bail  many  file  keep  larger  one  would  propose  something  like  find  set  storefiles  every  file  satisfies  filesizefi  sum0  i1  filesizefx  num  file  set  max  num  file  set  min  pick  set  file  maximizes  storefiles  set  sumfilesizefx  thinking  algorithm  pretty  easy  reason  file  satisfy  ratio  rewrite  least  amount  data  get  biggest  impact  seek,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2843,enable  encapsulating  compaction  policycompactorstore  file  manager  interaction  shennanigans  avoid  massive  casting  andor  deciphering  structure  traveling  sfm  compaction  policy  compactor  nontrivial  compaction  scheme  like  stripe  level  need  make  interaction  hidden  elsewhere  change  made  coprocessor  compaction  make  compactionrequest  limitedvisibility  class  user  coprocessors  able  subclass  return  seems  like  viable  solution  problem  hand  policy  optionally  subclass  compaction  request  return  instead  calling  somethingcompactreq  reqcompact  called  something  already  stored  inside  req  magic  happen  merging  code  actually  see  subclassing  compactionrequest  break  policy  require  bunch  ugly  code  coprocessors  subclass  every  policy  telling  apart,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
2844,htuwaittableavailable  default  value  30  often  used  5  delay  enough  env  parallelize  heavily  test  30  default  seems  make,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2845,use  servername  connectiongetclient  connectiongetadmin  code  subpart  hbase7590  patch  already  hbase7590  contains  bad  fix  confusion  seq  number  jira  try  fix  correctly  client  code  mostly  us  hostnameport  get  connection  region  server  side  effect  server  dy  comeback  client  wont  notice  theory  region  looking  likely  somewhere  else  case  add  dead  server  management  client  hbase7590  need  manage  distinction  server  sure  declaring  dead  server  restarted,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2846,make  policy  compactor  default  store  engine  separately  pluggable  thing  like  tierbased  default  policy  experiment  permutation  technically  storeengine  used  achieve  permutation  thing  make  convenient  replace  compaction  policycompator  standard  scheme  like  tierbased  add  separate  hook  defaultstoreengine  long  custom  one  conform  default  expectation  eg  flat  list  sorted  file  etc,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2847,table  operation  tablehandler  rest  interface  current  implementation  metadata  query  table  allowed  convinent  use  rest  interface  write  thirdparty  client  library  think  functionality  rest  interface  similar  hbase  shell  user  createshowupdatedelateenabledisable  table,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2848,remove  update  improve  explicitcolumntracker  performance  columntrackerjava  update  method  used  anyone  one  call  checkcolumn  different  hfiles  update  file  rewalk  target  column  column  feed  checkcolumn  order  within  explicitcolumntracker  target  column  optimized  dynamic  maintain  changing  list  column  yet  match  instead  move  index  enough  optimization  save  time  avoid  reconstruct  column  array  upon  row  checkcolumn  method  performance  could  improved  1020,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2849,provide  client  api  explicitly  lock  unlock  row  need  able  perform  series  read  writes  single  row  without  potential  interference  client  unfortunately  bit  involved  normal  read  currently  acquire  row  lock  requires  adding  additional  getgetrow  call  obtain  release  row  lock  addition  two  additional  client  call  lockrowunlockrow  actually  acquire  release  lock  though  lock  associated  hregion  tracked  within  hregionserver  lock  acquired  client  handled  much  like  scanner  obtain  row  lock  hregion  store  region  name  lock  identifier  synchronized  map  also  obtain  lease  ensure  lock  eventually  released  even  client  dy  also  required  adding  rowlocklistener  implement  leaselistener  private  class  hr  handle  row  lock  lease  expiration  hrslockrow  return  long  lockid  openscanner  used  subsequent  client  call  reuse  existing  row  lock  call  check  lock  valid  perform  operation  without  locking  wrapper  around  get  new  version  batchupdate  openscanner  etc  going  really  add  noise  list  available  htableclient  method  im  sure  something  people  would  want  commit  normal  release  regardless  provide  convenient  functionality  may  useful  others  also  looking  clint  morgan  hbase669  one  major  downside  significant  amount  overhead  involved  row  locking  already  built  extend  api  allow  client  work  directly  little  overhead  obvious  performance  consideration  used  necessary  row  locked  unlocked  quickly  roundtrip  client  call  design  specific  note  schema  table  even  family  column  must  accessed  row  lock  time  first  attempt  adding  additional  functionality  comment  criticism  code  review  encouraged  patch  tomorrow,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2850,snapshot  manifest  file  instead  multiple  empty  file  currently  taking  snapshot  mean  creating  one  empty  file  file  source  table  directory  plus  copying  regioninfo  file  region  table  descriptor  file  snapshotinfo  file  restore  snapshot  verification  traverse  filesystem  fsliststatus  find  snapshot  file  open  regioninfo  file  get  information  avoid  hammering  namenode  lot  empty  file  use  manifest  file  contains  list  file  information  need  keep  r  parallelism  r  write  manifest  code  message  snapshotdescriptor  required  string  name  optional  string  table  optional  int64  creationtime  optional  type  type  optional  int32  version  message  snapshotregionmanifest  optional  int32  version  required  regioninfo  regioninfo  repeated  familyfiles  familyfiles  message  storefile  required  string  name  optional  reference  reference  message  familyfiles  required  byte  familyname  repeated  storefile  storefiles  code  code  hbasesnapshotsnapshotname  hbasesnapshotsnapshotnamesnapshotinfo  hbasesnapshotsnapshotnametablename  hbasesnapshotsnapshotnametablenametableinfo  hbasesnapshotsnapshotnametablenameregionmanifestn  code,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
2851,refactor  default  compactor  make  part  easier  reuse  refactor  default  compactor  make  part  easier  reuse  make  eventual  hbase7967  patch  smaller,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0
2852,tablemap  survive  use  work  tablemap  task  exceeds  client  lease  time  task  fail  unknownscannerexception  tableinputformatbase  handle  restarting  new  scanner  last  key  seen,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2853,eliminate  exception  exportsnapshot  null  table  snapshot  data  test  environment  snapshoting  null  table  data  snapshot  artifact  generated  successfully  snapshot  meta  data  cf  data  region  dir  exporting  null  snapshot  via  exportsnapshot  javaioioexception  input  path  specified  job  occurred  affect  normal  application  flow  seems  snapshot  null  table  also  make  sense  meta  information  snapshot  although  archive  show  later  snapshot  restore  seems  work  dummy  snapshot  artifact  cf  data  eliminate  exception  exportsnapshot  null  table  snapshot  make  application  work,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2854,row  key  array  byte  heard  several  people  row  key  hbase  le  restricted  hadoopiotext  think  least  row  key  writablecomparable  would  lead  general  case  either  hadoopiobyteswritable  hbaseioimmutablebyteswritable  primary  difference  two  class  hadoopiobyteswritable  default  allocates  100  byte  pay  attention  length  byteswritablegetsize  converting  string  byteswritable  vice  versa  become  problematic  hbaseioimmutablebyteswritable  contrast  allocates  many  byte  pas  allow  size  changed  change  text  nontext  key  preference  would  immutablebyteswritable  fixed  size  set  operation  like  get  etc  something  like  systemarraycopy  specify  number  byte  copy  comment  question  welcome  issue  receive  enough  feedback  text  restrictive  willing  change  need  hear  would  useful  thing  change  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2855,hbck  support  table  lock  table  lock  introduced  hbase7305  hbase7546  others  see  design  doc  hbase7305  issue  add  support  hbck  report  fix  possible  condition  table  lock  namely  due  bug  table  lock  remains  notreleased  hbck  able  report  remove  lock  normal  table  operation  continue  also  see  comment  hbase7977,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
2856,improve  loadtest  extensibility  patch  roll  related  change  allow  class  extending  testminiclusterloadsequential  override  reader  writer  thread  set  including  extending  reader  writer  make  class  extending  multithreadedwriter  cleanly  override  put  constructed  provide  option  passing  custom  table  descriptor  hbasetestingutilitycreatepresplitloadtesttable  hbasetestingutilitywaituntilallregionsassigned  check  region  counting  belongs  table  created  test  return  accidentally  count  many  region  example  region  acl  table  security  enabled  class  based  testminiclusterloadsequential  may  want  enable  security,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2857,add  truncate  hmaster  method  currently  truncate  truncatepreserve  shell  function  implemented  deletetable  createtable  using  acls  user  running  truncate  must  right  create  table  global  granted  user  create  table  add  truncate  truncatepreserve  hbaseadminhmaster  acl  check  httpsreviewsapacheorgr15835,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2858,mapreduce  snapshot  file  idea  add  inputformat  run  mapreduce  job  snapshot  file  directly  bypassing  hbase  server  layer  similar  usage  tableinputformat  taking  scan  object  user  instead  running  online  table  run  table  snapshot  one  split  per  region  snapshot  open  hregion  inside  recordreader  regionscanner  used  internally  scan  without  hregionserver  bit  user  asking  searching  way  run  mr  job  reading  directly  hfiles  allows  new  use  case  reading  stale  data  ok  take  snapshot  periodically  run  mr  job  snapshot  export  snapshot  remote  hdfs  cluster  run  mr  job  cluster  without  hbase  cluster  future  use  case  combine  snapshot  data  online  hbase  data  scan  yesterday  snapshot  read  today  data  online  hbase  cluster,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
2859,provide  mutability  compoundconfiguration  discussion  hbase8347  proposed  compoundconfiguration  support  mutability  done  consolidating  immutableconfigmaps  first  modification  compoundconfiguration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2860,support  libjar  inside  coprocessor  jar  currently  jar  file  inside  coprocessor  jar  folder  lib  would  great  support  jar  file  lib  ie  front,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2861,deprecate  tablemapreduceadddependencyjarsconfiguration  class  expose  two  public  static  method  name  adddependencyjars  one  void  adddependencyjarsjob  helpful  go  way  detect  job  dependency  well  shipping  necessary  hbase  dependency  shfty  nefarious  void  adddependencyjarsconfiguration  class  add  exactly  user  request  forcing  resolve  dependency  giving  false  sense  security  deprecate  latter  throw  big  giant  warning  people  use  one  handy  functionality  providing  help  heuristic  fail  added  via  new  method  signature  something  like  void  adddependencyjarsjob  class  method  would  everything  void  adddependencyjarsjob  plus  let  user  specify  arbitrary  additional  class  way  hbase  still  help  user  also  give  superpower  compensate  heuristic  fail  reference  appears  reason  hbase  pig  doesnt  really  work  box  see  hbasestoragejavahttpsgithubcomapachepigblobtrunksrcorgapachepigbackendhadoophbasehbasestoragejaval730,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2862,option  row  query  rest  interface  prior  implementation  support  exact  column  namecolfamilylabel  need  get  col  family  query  version,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2863,consolidate  multiple  overloaded  method  hregioninterface  hregionserver  many  overloaded  method  hregionserverinterface  consequently  hregionserver  consolidated  one  method  per  operation  client  pas  appropriate  parameter  server  server  side  single  method  able  handle  parameter  supplied  eg  long  value  supplied  1  boolean  value  supplied  appropriately  object  supplied  passed  null  overloaded  method  eventually  call  method  server  side  eventually  removing  overload  would  make  following  control  flow  easier,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2864,port  hbase6874  implement  prefetching  scanner  089fb  help  scanner  performance  trunk,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
2865,replication  remove  replicationzookeeper  class  logic  replicationzookeeper  refactored  three  interface  status  queue  peer  almost  logic  replicationzookeeper  removed  class  call  refactored  call  state  interface  directly,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0
2866,allow  parallel  snapshot  different  table  currently  one  snapshot  time  allowed  like  restore  allow  taking  snapshot  different  table  parallel,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2867,hcmistableenabled  doesnt  really  tell  current  trunk  load  table  8m  row  try  delete  disable  return  saying  table  successfully  deleted  try  drop  table  say  table  disabled  run  disabledrop  cycle  time  still  fails  eventually  wait  long  enough  succeeds  maybe  table  drop  block  table  seen  disabled  region  little  disorientating  way  work  could  lead  admins  distrust  status  message  emitted,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2868,autodrop  rollback  snapshot  snapshot  restore  excerpt  snapshot  restore  javadoc  code  restore  specified  snapshot  original  table  table  must  disabled  restoring  table  new  snapshot  current  table  state  created  case  failure  table  rolled  back  original  state  code  improve  handling  rollbacksnapshot  two  way  1  give  better  name  rollbacksnapshot  adding  codeforrollbackcode  currently  name  form  string  rollbacksnapshot  snapshotname  environmentedgemanagercurrenttimemillis  2  drop  rollbacksnapshot  end  restoresnapshot  restore  successful  introduce  new  config  param  named  hbasesnapshotrestoredroprollback  keep  compatibility  current  behavior,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2869,serverside  remove  convertion  pb  type  client  type  call  method  regionserver  rpc  receives  call  call  described  using  protobufs  make  serverside  invocation  transform  pb  param  object  make  native  pojo  eg  pb  put  hbase  oahhclientput  make  call  server  way  similar  putting  result  wire  convertion  oahhclientresult  pb  result  issue  first  investigating  possible  away  w  marshallingunmarshalling  serverside  especially  given  pb  object  rich  accessor  getters  etc  possible  w  pb  alone  serverside  go  ahead  rip  serverside  convertions,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2870,implement  tag  internals  tag  look  like  intent  jira  come  hbase7897  would  help  u  decide  structure  format  tag  look  like,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
2871,htablegetregionsinrange  provide  noncached  api  getregionsinrange  call  getregionlocation  without  reloading  return  wrong  result  cache  outdated  due  region  split  cost  always  reloading  isnt  significant  consider  default  otherwise  let  api  getregionsinrange  force  reload,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2872,get  rid  hbasehstorecompactioncomplete  setting  hbasehstorecompactioncomplete  strange  setting  cause  finished  compaction  complete  file  left  tmp  hstore  used  one  test  setting  name  also  used  compactiontool  usage  semiunrelated  could  probably  removed  easily,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2873,clean  code  around  compaction  completion  hstore  method  completecompaction  caller  long  something  changed  something  else  putting  separate  easytoreview  jira  make  future  change  smaller,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2874,enhance  deletesnapshotrb  call  snapshot  deletion  api  regex  hbase8461  added  api  hbaseadmin  allows  user  specify  regular  expression  deleting  snapshot  jira  would  allow  deletesnapshotrb  utilize  functionality,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2875,store  last  flushed  sequence  id  store  region  distributed  log  replay  hbase7006  store  last  flushed  sequence  id  region  zookeeper  prevent  deleted  data  appearing  store  last  flushed  sequence  id  store  region  zookeeper  see  discussion  httpsissuesapacheorgjirabrowsehbase7006focusedcommentid13660428pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment13660428,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
2876,hlogs  zk  cleaned  replication  lag  minimal  cluster  low  replication  lag  measured  ageoflastshippedop  source  found  hlogs  accumulating  cleaned  new  wals  rolled  time  call  logpositionandcleanoldlogs  clean  older  log  whenever  current  wal  written  suggested  currentwalbeingwrittento  false  however  lag  small  may  hit  following  block  first  continue  onto  next  wal  without  clearing  old  wals  replicationsourcerun  readallentriestoreplicateornextfilecurrentwalisbeingwrittento  false  advance  next  wal  without  cleaning  close  existing  wal  continue  ship  edits  call  logpositionandcleanoldlogs  hit  readallentriestoreplicateornextfilefalse  older  log  cleaned  persist  zookeeper  node  since  simply  call  continue  skip  subsequent  logpositionandcleanoldlogs  call  called  end  clearing  old  log,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2877,change  exploring  compaction  policy  prefer  smaller  compaction  blocked  store  sidenote  hbase8665  discussion  compact  blocked  store  might  want  use  different  heuristic  choose  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2878,accesscontroller  restrict  htabledescriptor  enumeration  user  concerned  table  schema  exposed  every  user  would  like  protected  similar  rest  admin  operation  schema  used  hopeless  meta  would  leak  htabledescriptors  hregioninfo  longer  case  094  consider  adding  cp  hook  master  intercepting  hmasterinterfacegethtabledescriptors  hmasterinterfacegethtabledescriptorsliststring  add  support  accesscontroller  allowing  global  admin  first  method  add  support  accesscontroller  allowing  access  descriptor  table  name  list  second  method  user  table  admin  privilege  listed  table  name  fix  code  hbaseadmin  elsewhere  expects  able  enumerate  table  descriptor  eg  deletetable  table  admin  delete  table  won’t  global  admin  privilege  enumerate  total  list  minor  fixup  needed  place  like  make  assumption,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2879,replication  change  replication  rpc  use  cell  block  currently  replication  rpc  ship  edits  simply  dump  byte  value  wal  edit  keyvalue  pair  protobuf  message  modify  replication  rpc  mechanism  use  cell  block  leverage  encoding  compression,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2880,enable  peer  cluster  choosechange  columnfamiliestables  really  want  replicate  source  cluster  consider  scenario  cf  replicationscope1  1  cluster  3  table  table  cfacfb  table  b  cfxcfy  table  c  cf1cf2  2  cluster  x  want  replicate  table  cfa  table  b  cfx  table  c  cluster  3  cluster  want  replicate  table  b  cfy  table  c  cf2  cluster  current  replication  implementation  cant  achieve  since  itll  push  data  replicatable  columnfamilies  cluster  peer  xy  scenario  improvement  provides  finegrained  replication  theme  enable  peer  cluster  choose  columnfamiliestables  really  want  source  cluster  set  tablecflist  peer  addpeer  hbaseshell  addpeer  3  zk1100hbase  table1  table2cf1cf2  table3cf2  b  view  tablecflist  config  peer  using  showpeertablecfs  hbaseshell  showpeertablecfs  1  c  changeset  tablecflist  peer  using  setpeertablecfs  hbaseshell  setpeertablecfs  2  table1cfx  table2cf1  table3cf1cf2  theme  replicationscope1  mean  columnfamily  replicated  cluster  tablecflist  list  determines  cftable  actually  replicated  specific  peer  provide  backcompatibility  empty  tablecflist  list  replicate  replicatable  cftable  mean  dont  allow  peer  replicates  nothing  source  cluster  think  reasonable  replicating  nothing  bother  adding  peer  improvement  address  exact  problem  raised  first  faq  httphbaseapacheorgreplicationhtml  global  mean  replicate  provision  replicate  cluster  x  cluster  later  yes  much  later  also  noticed  somebody  mentioned  replicationscope  integer  rather  boolean  finegrained  replication  purpose  think  extending  replicationscope  cant  achieve  replication  granularity  flexibility  providing  perpeer  replication  configuration  improvement  running  smoothly  production  cluster  xiaomi  several  month,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2881,new  write  thread  model  hlog  improve  overall  hbase  write  throughput  current  write  model  write  handler  thread  executing  put  individually  go  full  append  hlog  local  buffer  hlog  writer  append  write  hdfs  hlog  writer  sync  sync  hdfs  cycle  write  incurs  heavy  race  condition  updatelock  flushlock  optimization  checking  current  synctillhere  txid  expectation  thread  help  writesync  txid  hdfs  omitting  writesync  actually  help  much  le  expectation  three  colleaguesye  hangjun  wu  zesheng  zhang  peng  xiaomi  proposed  new  write  thread  model  writing  hdfs  sequence  file  prototype  implementation  show  4x  improvement  throughput  17000  70000  apply  new  write  thread  model  hlog  performance  test  test  cluster  show  3x  throughput  improvement  12150  31520  1  r  22000  70000  5  r  1  r  write  throughput  1k  rowsize  even  beat  one  bigtable  precolator  published  2011  say  bigtables  write  throughput  31002  provide  detailed  performance  test  result  anyone  interested  change  new  write  thread  model  1  put  handler  thread  append  edits  hlogs  local  pending  buffer  notifies  asyncwriter  thread  new  edits  local  buffer  2  put  handler  thread  wait  hlogsyncer  function  underlying  thread  finish  sync  contains  txid  3  single  asyncwriter  thread  responsible  retrieve  buffered  edits  hlogs  local  pending  buffer  write  hdfs  hlogwriterappend  notifies  asyncflusher  thread  new  writes  hdfs  need  sync  4  single  asyncflusher  thread  responsible  issuing  sync  hdfs  persist  writes  asyncwriter  notifies  asyncnotifier  thread  sync  watermark  increase  5  single  asyncnotifier  thread  responsible  notifying  pending  put  handler  thread  waiting  hlogsyncer  function  6  logsyncer  thread  since  always  asyncwriterasyncflusher  thread  job,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2882,region  assigments  scan  table  directory  making  slow  huge  table  table  130k  region  take  3  second  region  server  open  region  assigned  watching  thread  region  server  running  0945  opening  many  region  show  thread  opening  reigon  code  like  noformat  pri  ipc  server  handler  4  60020  daemon  prio10  tid0x00002aaac07e9000  nid0x6566  runnable  0x000000004c46d000  javalangthreadstate  runnable  javalangstringindexofstringjava1521  javaneturiparserscanurijava2912  javaneturiparserparseurijava3004  javaneturiiniturijava736  orgapachehadoopfspathinitializepathjava145  orgapachehadoopfspathinitpathjava126  orgapachehadoopfspathinitpathjava50  orgapachehadoophdfsprotocolhdfsfilestatusgetfullpathhdfsfilestatusjava215  orgapachehadoophdfsdistributedfilesystemmakequalifieddistributedfilesystemjava252  orgapachehadoophdfsdistributedfilesystemliststatusdistributedfilesystemjava311  orgapachehadoopfsfilterfilesystemliststatusfilterfilesystemjava159  orgapachehadoopfsfilesystemliststatusfilesystemjava842  orgapachehadoopfsfilesystemliststatusfilesystemjava867  orgapachehadoophbaseutilfsutilsliststatusfsutilsjava1168  orgapachehadoophbaseutilfstabledescriptorsgettableinfopathfstabledescriptorsjava269  orgapachehadoophbaseutilfstabledescriptorsgettableinfopathfstabledescriptorsjava255  orgapachehadoophbaseutilfstabledescriptorsgettableinfomodtimefstabledescriptorsjava368  orgapachehadoophbaseutilfstabledescriptorsgetfstabledescriptorsjava155  orgapachehadoophbaseutilfstabledescriptorsgetfstabledescriptorsjava126  orgapachehadoophbaseregionserverhregionserveropenregionhregionserverjava2834  orgapachehadoophbaseregionserverhregionserveropenregionhregionserverjava2807  sunreflectgeneratedmethodaccessor64invokeunknown  source  sunreflectdelegatingmethodaccessorimplinvokedelegatingmethodaccessorimpljava25  javalangreflectmethodinvokemethodjava597  orgapachehadoophbaseipcwritablerpcengineservercallwritablerpcenginejava320  orgapachehadoophbaseipchbaseserverhandlerrunhbaseserverjava1426  noformat  open  region  region  server  first  load  latest  htabledescriptor  since  hbase4553  htabledescriptors  stored  file  system  hbasetabledirtableinfosequencenum  file  largest  sequencenum  current  descriptor  done  current  descirptor  updated  atomically  however  since  filename  known  advance  fstabledescriptors  filesystemliststatus  operation  list  file  directory  find  directory  also  contains  region  directory  case  load  130k  filestatus  object  even  using  globstatus  matching  function  still  transfer  object  client  performing  pattern  matching  furthermore  hdfs  us  default  transferring  1000  directory  entry  rpc  call  requires  130  roundtrips  namenode  fetch  directory  entry  consequently  reassign  region  table  constant  fraction  thereof  requires  time  proportional  square  number  region  case  region  server  fails  200  region  take  10  minute  reassigned  zk  expiration  log  splitting,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1
2883,fix  hotspot  scanner  scanning  lot  rpcs  huge  performance  hit  propose  add  way  fetch  row  next  put  cache  configurable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2884,pluggable  rpcscheduler  today  rpc  scheduling  mechanism  pretty  simple  execute  request  isolated  threadpools  based  priority  current  implementation  normal  getput  request  using  pool  wed  like  add  peruser  perregion  level  isolation  misbehaved  userregion  saturate  threadpool  cause  do  others  easily  idea  similar  fairscheduler  mr  current  scheduling  code  standalone  mixed  others  connectionprocessrequest  issue  first  step  extract  interface  people  free  write  test  implementation  patch  doesnt  make  completely  pluggable  yet  parameter  pas  constructor  hmaster  hregionserver  use  rpcserver  different  threadpool  size  config  let  know  solution,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
2885,alter  table  operation  also  related  change  rest  interface  made  change  alter  operation  hbase  shell  add  update  delete  column  family  also  make  change  tablehandler  rest  interface  change  hbase  shell  alter  table  name  cf  version  3  command  try  find  column  family  named  cf  first  modifycolumn  add  column  alter  table  name  cf  method  delete  command  delete  column  family  named  cf  achieve  goal  also  add  method  hbaseadminjava  public  tabledescriptor  gettabledescriptorbyte  tablename  change  tablehandler  rest  interface  curl  x  put  httplocalhost60050apitablename  xml  version10  encodingutf8  table  nametablesname  columnfamilies  columnfamily  namecf1name  maxversions2maxversions  compressionnonecompression  inmemoryfalseinmemory  blockcachetrueblockcache  columnfamily  columnfamilies  table  check  column  family  cf1  exists  modifycolumn  addcolumn  curl  x  delete  httplocalhost60050apitablenamecolumncf1  deletecolumn  cf1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2886,protobuf  message  style  google  protobuf  style  guide  httpsdevelopersgooglecomprotocolbuffersdocsstyle  lay  convention  message  field  name  underscoreseparated  service  mixedcase  protos  trunk  follow  style  instead  follow  java  naming  convention  protobuf  compiler  automatically  change  style  name  match  language  compiling  unable  protobuf  style  used  result  using  hbase  proto  file  language  different  naming  convention  java  little  bit  painful  since  core  feature  moving  protobufs  opening  door  wire  compatible  implementation  language  think  may  want  addressed  patch  change  naming  convention  protos  resulting  java  file  protobuf  compiler  put  functionally  correct  java  naming  style,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2887,add  limit  key  length  check  key  value  length  client  side  currently  limit  key  length  parameter  htabledescriptor  since  row  key  length  need  considered  addition  column  key  trivial  add  since  htd  upgraded  without  requiring  migration  checking  key  length  value  length  done  client  side  fail  early  rather  request  sent  server  mean  batchupdate  need  reference  either  htable  htd  transient  reference  htable  htd  need  serializeddeserialized,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2888,addendum  pluggable  rpcscheduler  patch  fix  review  comment  stack  small  fix  make  rpcscheduler  fully  pluggable  one  write  hisher  implementation  add  classpath  specify  config  hbaseregionserverrpcschedulerfactoryclass  add  unit  test  fix  rpcschedulerstop  called  discovered  test,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
2889,add  viewedit  tool  favored  node  mapping  region  add  tool  one  run  offline  view  favored  node  mapping  region  also  fix  mapping  needed  tool  exists  089fb  branch  port  trunk095,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2890,replicationlogcleaner  slow  large  scale  large  scale  replicationlogcleaner  fails  clean  oldlogs  fast  cluster  producing  old  hlog  file  replicated  deleted  replicationlogcleaner  check  every  replication  queue  zookeeper  removing  mean  cluster  scale  number  file  delete  scale  well  time  delete  file  cleanup  chore  scale  quadratically  case  reached  point  oldlogs  growing  faster  cleaned  running  patch  allows  replicationlogcleaner  refresh  list  file  replication  queue  zookeeper  batch  file  cleanerchore  want  evaluate  id  propose  updating  filecleanerdelegate  take  listfilestatus  rather  single  one  time  would  allow  file  cleaner  check  external  resource  reference  zookeeper  replicationlogcleaner  hdfs  snapshotlogcleaner  look  like  may  also  similar  trouble  scale  load  reference  per  batch  rather  every  log,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2891,provide  interface  getting  user  client  sometimes  user  want  provide  user  class  depending  type  security  support  local  environment  instance  running  hadoop1  v  hadoop2  v  cdh  mean  potentially  different  way  getting  usergroupinformation  issue  abstract  mechanism  obtain  oahhbasesecurityuser  userprovider  userprovider  extented  hadoop  12  shim  well  supporting  custom  authentication  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2892,thrift  getrow  support  specifying  column  thrift  interface  getrow  function  support  asking  specific  column,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2893,add  convenience  method  rowfilterset  patch  add  getoperator  addfilter  rowfilterset  found  useful  constructing  filter  higherlevel  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2894,make  custom  distributed  barrier  procedure  pluggable  currently  one  want  implement  custom  distributed  barrier  procedure  eg  distributed  log  roll  distributed  table  flush  hbase  core  code  need  modified  order  procedure  work  looking  snapshot  code  especially  region  server  side  code  enable  procedure  generic  lifecycle  management  ie  init  start  stop  make  part  pluggable  proposal  following  coprocessor  example  define  two  property  code  hbaseprocedureregionserverclasses  hbaseproceduremasterclasses  code  value  comma  delimited  list  class  region  server  side  class  implement  following  interface  code  public  interface  regionserverproceduremanager  public  void  initializeregionserverservices  r  throw  keeperexception  public  void  start  public  void  stopboolean  force  throw  ioexception  public  string  getprocedurename  code  master  side  class  implement  interface  code  public  interface  masterproceduremanager  public  void  initializemasterservices  master  throw  keeperexception  ioexception  unsupportedoperationexception  public  void  stopstring  public  string  getprocedurename  public  void  execprocedureproceduredescription  desc  throw  ioexception  ioexception  code  proceduredescription  defined  code  message  proceduredescription  required  string  name  1  required  string  instance  2  optional  int64  creationtime  3  default  0  message  property  required  string  tag  1  optional  string  value  2  repeated  property  prop  4  code  generic  api  defined  hmaster  trigger  procedure  code  public  boolean  execprocedureproceduredescription  desc  throw  ioexception  code  snapshotmanager  regionserversnapshotmanager  special  example  masterproceduremanager  regionserverproceduremanager  automatically  included  user  dont  need  specify  conf  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2895,optimization  major  compaction  remove  deletes  well  deleted  cell  currently  major  compaction  retains  deletes  deleted  cell  remove,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2896,improve  performance  small  scan  review  board  httpsreviewsapacheorgr14059  performance  improvement  test  show  153x  improvement  small  scan  limit50  cache  hit  ratio100  see  performance  test  result  picture  attachment  usage  scan  scan  new  scanstartrowstoprow  scansetsmalltrue  resultscanner  scanner  tablegetscannerscan  set  new  small  attribute  true  scan  object  others  one  scan  operation  would  call  3  rpc  least  openscanner  next  closescanner  think  could  reduce  rpc  call  one  small  scan  get  better  performance  also  using  pread  better  seekread  small  scan  point  see  hbase7266  implement  small  scan  patch  take  performance  test  following  aenvironment：  patched  094  version  one  regionserver  one  client  50  concurrent  thread  kv  size50100  100  lru  cache  hit  ratio  random  start  row  scan  bresults  see  picture  attachment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2897,cleanup  inconsistency  protobuf  message  rpc  name  minor  cleanup  inconsistency  name  protobuf  message  rpcs  ran  dynamically  working  hbaseprotocol  nice  message  rpc  name  consistent  possible  specifically  change  rpc  name  match  message  name  plus  request  response  change  message  renames  accesscontrolprotosuserpermissionsrequest  response  getuserpermissionsrequest  response  aggregateprotosaggregateargument  aggregaterequest  authenticationprotostokenrequest  response  getauthenticationtokenrequest  response  authenticationprotostokenrequest  response  getauthenticationtokenrequest  response  multirowmutationmultimutaterequest  response  mutaterowsrequest  response  rowprocessorprotosrowprocessorrequest  response  processrowrequestrequest  response  securebulkloadprotosdelegationtokenproto  delegationtoken  rpc  renames  masteradminprotosruncatalogscan  catalogscan  masteradminprotossnapshot  takesnapshot  masteradminprotosgetcompletedsnapshots  listcompletedsnapshots  rowprocessorprotosprocess  rowprocessorprotosprocessrow  outer  classname  change  multirowmutation  multirowmutationprotos  tracing  tracingprotos  file  renames  hbaseproto  hbaseproto,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,1,1
2898,multi  row  get  return  result  even  one  row  specified  query  missing  improve  exception  handling  client  try  retrieve  multiple  row  using  rest  api  even  one  specified  row  exist  404  returned  correct  way  return  result  found  row  ignore  nonexistent  one  also  current  code  base  exception  handled  exception  like  access  denied  column  found  exception  throw  apis  500  server  found  returned  user  leaf  end  user  wondering  caused  rest  command  fail,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,1,1
2899,rest  interface  generic  column  family  configure  also  get  row  using  offset  limit  update  column  family  operation  rest  interface  overwrite  default  metadata  using  default  value  unexpected  use  column  family  get  old  value  update  requested  user  also  nondefault  metadata  value  hbasehregionmajorcompaction  still  enable  createupdate  using  rest  interface  rowhandler  user  request  offset  limit  get  row,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2900,nulloutputstream  removed  guava  15  comgooglecommonionulloutputstream  dropped  guava  150  favor  comgooglecommoniobytestreamsnulloutputstream  prevents  project  artifact  upgrading  guava  14  guava  15  noformat  error  20130926  174612229  hbasemastermasterfilesystem  bootstrap  orgapachehadoophbasedroppedsnapshotexception  region  root0  orgapachehadoophbaseregionserverhregioninternalflushcachehregionjava1608  orgapachehadoophbaseregionserverhregioninternalflushcachehregionjava1482  orgapachehadoophbaseregionserverhregiondoclosehregionjava1011  orgapachehadoophbaseregionserverhregionclosehregionjava959  orgapachehadoophbaseregionserverhregionclosehregionjava930  orgapachehadoophbasemastermasterfilesystembootstrapmasterfilesystemjava447  orgapachehadoophbasemastermasterfilesystemcheckrootdirmasterfilesystemjava387  orgapachehadoophbasemastermasterfilesystemcreateinitialfilesystemlayoutmasterfilesystemjava134  orgapachehadoophbasemastermasterfilesysteminitmasterfilesystemjava119  orgapachehadoophbasemasterhmasterfinishinitializationhmasterjava536  orgapachehadoophbasemasterhmasterrunhmasterjava395  javalangthreadrunthreadjava680  caused  javalangnoclassdeffounderror  comgooglecommonionulloutputstream  orgapachehadoophbaseiohfilehfilewriterv2closehfilewriterv2java374  orgapachehadoophbaseregionserverstorefilewriterclosestorefilejava1283  orgapachehadoophbaseregionserverstoreinternalflushcachestorejava836  orgapachehadoophbaseregionserverstoreflushcachestorejava747  orgapachehadoophbaseregionserverstorestoreflusherimplflushcachestorejava2229  orgapachehadoophbaseregionserverhregioninternalflushcachehregionjava1583  11  caused  javalangclassnotfoundexception  comgooglecommonionulloutputstream  javaneturlclassloader1runurlclassloaderjava202  javasecurityaccesscontrollerdoprivilegednative  method  javaneturlclassloaderfindclassurlclassloaderjava190  javalangclassloaderloadclassclassloaderjava306  sunmisclauncherappclassloaderloadclasslauncherjava301  javalangclassloaderloadclassclassloaderjava247  17  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2901,temporary  test  file  left  tmphbaseuser  currently  160mb  stuff  left  behind  unit  test  run  jenkins  setup  table  name  left  behind  indicate  due  class  testcompaction  either  testforcecacheimporatntblocks  testscannerselectionuingttl  testscannerselectionusingkeyrange  testhregion,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2902,distributedhbasecluster  throw  exception  best  effort  restore  end  integration  test  calling  distributedclusterrestorecluster  case  cm  killed  node  leave  cluster  state  taken  however  cm  used  test  example  itloadandverify  region  server  die  external  daemon  kill  server  still  try  restore  end  test  may  may  succeed  depending  configuration  region  server  going  unaccessible  etc  two  thing  either  best  effort  restore  cluster  fail  test  error  skip  running  restore  disruptive  action  taken  place  leaning  towards  former  one  since  r  go  wo  cm  due  bad  disk  etc  cannot  restore  cluster  fail  test  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2903,alow  one  log  splitter  per  r  iirc  idea  came  lad  xiaomi  small  cluster  6  r  one  went  wals  see  log  20131009  054727890  debug  orgapachehadoophbasemastersplitlogmanager  total  task  25  unassigned  21  wal  splitting  held  want  slot  cluster  split  wals  need  careful  dont  overwhelm  foreground  regionservers  splitter  help  get  back  online  faster,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2904,custom  threadpool  coprocessor  obtained  htables  coprocessors  currently  use  default  htable  constructor  take  single  threadpoolthis  overly  constrictive  coprocessors  desire  tighter  control  resource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2905,hbase  native  metric  metric  collection  coprocessors  would  help  provide  better  visibility  coprocessors  provided  way  coprocessors  export  metric  general  idea  extend  access  hbase  metric  bus  coprocessor  environment  coprocessors  register  increment  custom  metric  coprocessor  metric  reported  along  others  normal  mechanism,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
2906,make  compaction  logging  le  confusing  1  one  popular  question  hbase  user  got  scheduled  major  compaction  run  per  week  many  need  somehow  tell  user  wherever  log  major  compaction  whether  major  compaction  thats  request  regular  major  compaction  user  request  promoted  took  file  esp  latter  clear  2  small  v  large  compaction  thread  minor  v  major  compaction  confusing  maybe  thread  named  short  long  compaction,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
2907,hbasefscknumthreads  property  isnt  passed  hbck  via  cmdline  option  use  generic  option  way  pas  hbasefscknumthreads  property  hbase  hbck  accept  new  setting  value  code  hbase  hbck  hbasefscknumthreads5  code  still  find  thread  5  already  set  via  generic  opttion  code  20131024  092502561pool2thread6debugorgapachehadoopsecurityusergroupinformation  privilegedaction  ashbasespndhdn1sjdcispntrendmicrocom  authkerberos  fromsunreflectnativemethodaccessorimplinvoke0native  method  usergroupinformationjava1430  20131024  092502562pool2thread10debugorgapachehadoopsecurityusergroupinformation  privilegedaction  ashbasespndhdn1sjdcispntrendmicrocom  authkerberos  fromsunreflectnativemethodaccessorimplinvoke0native  method  usergroupinformationjava1430  20131024  092502565pool2thread13debugorgapachehadoopsecurityusergroupinformation  privilegedaction  ashbasespndhdn1sjdcispntrendmicrocom  authkerberos  fromsunreflectnativemethodaccessorimplinvoke0native  method  usergroupinformationjava1430  20131024  092502566pool2thread11debugorgapachehadoopsecurityusergroupinformation  privilegedaction  ashbasespndhdn1sjdcispntrendmicrocom  authkerberos  fromsunreflectnativemethodaccessorimplinvoke0native  method  usergroupinformationjava1430  20131024  092502567pool2thread9debugorgapachehadoopsecurityusergroupinformation  privilegedaction  ashbasespndhdn1sjdcispntrendmicrocom  authkerberos  fromsunreflectnativemethodaccessorimplinvoke0native  method  usergroupinformationjava1430  20131024  092502568pool2thread12debugorgapachehadoopsecurityusergroupinformation  privilegedaction  ashbasespndhdn1sjdcispntrendmicrocom  authkerberos  fromsunreflectnativemethodaccessorimplinvoke0native  method  usergroupinformationjava1430  20131024  092502570pool2thread7debugorgapachehadoopsecurityusergroupinformation  privilegedaction  ashbasespndhdn1sjdcispntrendmicrocom  authkerberos  fromsunreflectnativemethodaccessorimplinvoke0native  method  usergroupinformationjava1430  20131024  092502571pool2thread14debugorgapachehadoopsecurityusergroupinformation  privilegedaction  ashbasespndhdn1sjdcispntrendmicrocom  authkerberos  fromsunreflectnativemethodaccessorimplinvoke0native  method  usergroupinformationjava1430  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2908,need  hbase  partitioner  tablemapreduceutilinittablereducejob  mr  job  run  say  20  reducer  get  120th  data  output  table  problem  u  large  import  job  data  get  sorted  key  reducer  pound  one  region  time  need  add  onto  tablemapreduceutilinittablereducejob  method  set  partitioner  set  number  reducer  number  region  table  map  map  partitioner  send  batchupdates  one  region  one  reducer  get  even  spread  writer  region  would  assure  one  reducer  send  update  one  region  keeping  one  region  getting  overloaded  others,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2909,idempotent  operation  dups  return  result  instead  throwing  conflict  exception  hbase3787  could  store  mvcc  operation  context  use  convert  modification  request  read  dups  instead  throwing  operationconflictexception  mvcc  tracking  aware  mvcc  number  present  given  scanner  usually  relatively  shortlived  would  prevent  low  watermark  advancing  quite  bit  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2910,narrow  getclosestrowbefore  passing  column  family  currently  getclosestrowbefore  usually  interested  catalog  table  edits  info  family  written  well  also  go  trawl  region  historian  column  family  though  irrelevant  worse  got  row  corresponding  info  entry  wed  hosed  add  able  narrow  scope  getclosestrowbefore  passing  column  family  dive,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2911,start  jsr88  console  deployer  hook  jsr88  ddbeans  dconfigbeans  start  consolebased  deployer  right  start  navigating  ejb  dd  printing  info  screen  enough  show  working  includes  fix  ddbeans  dconfigbeans  make  work  well  together  new  tool  implementation  deployableobject  ejb  jar  subclass  new  cli  console  package  right  consists  solely  commandline  deployer  assume  expanded  future,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
2912,webservice  deployment  ew  patch  code  deploy  webservice  geronimo  1  webservicedeployergbean  calling  deploy  gbean  method  one  deploy  webservice  right  axis  service  keep  seperate  configstore  changed  decide  final  thing  2the  deployer  accept  webservice  jar  file  generate  required  code  using  ew  deploy  time  axis  gbean  need  restart  get  new  deploymnet  3the  complete  senario  shown  webservicetestjava  test  run  code  need  javahomelibtoolsjar  classpth  since  still  get  classpath  maven  exclude  test  somebody  using  ide  add  toolsjar  classpath  work  fine  4  let  add  doc  wiki  work,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2913,add  support  ejbref  resolution  matching  ejb  interface  application  assume  ejbrefs  resolved  matching  interface  type,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2914,transactioncontext  usage  confused  confusing  currently  transactioncontext  static  accessors  current  thread  transactioncontext  transactioncontextmanager  objectgbean  nonstatic  accessors  helper  method  create  various  type  tc  associate  current  thread  component  use  transactioncontext  static  method  use  gbean  method  problem  new  thread  dont  automatically  get  tc  thread  create  add  code  create  tc  thread  created  eg  servlet  direct  access  tc  cannot  safely  shared  thread  therefore  dont  think  using  inheritablethreadlocal  tc  good  solution  proposal  implement  absence  suggestion  eliminate  static  method  tc  use  gbean  accessors  gettransactioncontext  method  never  return  null  tc  current  thread  create  new  unspecifiedtransactioncontext  associate  thread  returning  may  create  additional  method  getnonnulltransactioncontext  existing  method  used  would  error  transactioncontext  associated  current  thread  advantage  see  using  gbean  rather  static  method  simplify  plugging  different  set  transactioncontext  implementation  wish,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
2915,jsr88  deployer  work  remotely  currently  deployer  sends  file  server  tool  server  must  machine  file  network  drive  would  useful  file  inputstream  could  sent  server  allowing  deployment  remote  machine  however  rmi  may  best  transport,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2916,improved  structure  xxxrefs  geronimo  plan  geronimo  jndi  component  environment  reference  resolved  turning  information  supplied  ejblink  geronimo  plan  element  complete  object  name  resolving  reference  usually  consists  calling  method  named  gbean  currently  easy  way  ejblink  spec  dd  targetname  resourceref  connection  factory  nonlink  ejbrefs  require  supply  complete  object  name  difficult  error  prone  target  object  name  jsr77  compliant  name  proposal  tag  geronimo  plan  ref  element  component  jsr77  name  supplied  filled  context  element  domain  server  application  module  type  name  im  entirely  clear  whether  server  attribute  allow  specify  server  different  vm  something  along  line  needed  well  im  proposing  keep  current  targetname  element  case  want  specify  entire  name  among  thing  provide  geronimo  plan  ejblink  like  functionality  simplify  access  javamail  nonconnectionfactory  resource,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
2917,socketprotocolstresstest  fails  socketprotocolstresstest  testconcurrentrequests  constantly  fails  maven  build  cf  timeout  problem  geronimo160  succeeds  run  junit  test  within  eclipse  v  301  id  like  excluded  unittest  file  modulesnetworkprojectxml  like  datagramprotocoltest  patch  follows  btw  could  someone  admin  right  jira  add  network  module  component  list  thanks  ralf,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2918,runtime  control  connection  pool  needed  connection  pool  visible  configurable  runtime  deployment  time  readonly  current  size  current  idle  connection  partition  count  readwrite  maxsize  minsize  need  initial  implementation  blockingtimeoutmilliseconds  idletimeoutminutes  need  initial  implementation,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1
2919,configurationentry  support  multiple  loginmodules  abstract  class  configurationentry  support  returning  multiple  loginmodules  accurately  array  appconfigurationentrys  however  none  concrete  implementation  allow  required  feature  order  calleridentityuserpasswordrealmbridge  work  need  password  put  private  credential  set  currently  one  set  login  module  actually  authenticate  different  loginmodule  populates  private  credential  set  order  behavior  need  load  loginmodules  currently  available  configurationentries  cant  configured  problem  configurationentry  get  data  securityrealm  securityrealm  return  single  appconfigurationentry  loginmodule  doesnt  make  sense  make  new  multiple  configuration  entry  take  multiple  security  realm  input  concept  want  one  security  realm  two  login  module  think  change  start  allowing  securityrealm  return  multiple  appconfgurationentry  value  need  configuration  syntax  standard  security  realm  gbeans  change  take  multiple  login  module  including  option  control  flag  like  might  want  use  vanilla  sqlsecurityrealm  add  geroinmopasswordcredentialloginmodule  hypothetical  audittrailloginmodule  addition  standard  loginmodule,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2920,connection  factory  extracted  conceptually  wrong  gbean  currently  connection  factoriesdatasources  proxy  obtained  jcamanagedconnectionfactory  gbean  since  connectionfactorydatasource  gbean  jsr77  requirement  would  make  sense  obtain  connection  factorydatasource  would  additional  feature  allowing  one  set  several  connection  factory  different  name  use  connectionmanager  managedconnectionfactory  would  instance  let  set  separately  named  queueconnectionfactory  topicconnectionfactory  share  connection  named  appropriately  let  leave  resourcerefs  plan  apps  call  factory  different  name,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2921,gbeans  use  jsr77  naming  convention  name  mostly  default  component  currently  usage  object  name  nonj2eewrapping  gbeans  le  random  confusing  adopt  much  jsr77  naming  possible  gbeans  furthermore  little  possible  name  specified  gbean  xml  descriptor  here  proposal  1  service  module  parent  must  specify  domain  server  name  domain  server  name  inherited  child  recursively  2  gbeans  deployed  service  dd  j2eeapplicationnull  geronimomoduleconfigid  3  gbeans  deployed  j2ee  module  application  j2eeapplication  set  application  geronimomoduleconfigid  4  gbean  xml  descriptor  attribute  j2eetype  name  invent  j2eetype  name  needed  prefix  ger  geronimo  im  inclined  remove  possibility  directly  specifying  entire  object  name  really  needed  id  suggest  attribute  called  targetname  analogy  usage  ref,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0
2922,connector  deployment  convert  10  dd  15  dd  processing  module  builder  connector  module  builder  convert  10  spec  dd  15  spec  dd  processing,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
2923,removed  tomcatsecurewebappcontext  placed  code  tomcatwebappcontext  removed  tomcatsecurewebappcontext  instead  placed  security  code  tomcatwebappcontext  similarly  jetty  updated  unit  test  reflect  change  also  changed  tomcatmodulebuilder  use  gbeandata  instead  deprecated  gbeanmbean  diff  included  index  srctestorgapachegeronimotomcatabstractwebmoduletestjava  srctestorgapachegeronimotomcatabstractwebmoduletestjava  revision  123364  srctestorgapachegeronimotomcatabstractwebmoduletestjava  working  copy  1327  1327  securityroles  map  legacysecurityconstraintmap  throw  exception  protected  objectname  setupsecureappcontextsecurityconstraint  securityconstraints  string  securityroles  throw  exception  gbeandata  app  new  gbeandatawebmodulename  tomcatsecurewebappcontextgbeaninfo  gbeandata  app  new  gbeandatawebmodulename  tomcatwebappcontextgbeaninfo  appsetattributewebapproot  new  filetargetvarcatalinawebappswar3touri  appsetattributewebclasspath  new  uri  appsetattributeconfigurationbaseurl  new  filetargetvarcatalinawebappswar3webinfwebxmltourl  index  srcjavaorgapachegeronimotomcatdeploymenttomcatmodulebuilderjava  srcjavaorgapachegeronimotomcatdeploymenttomcatmodulebuilderjava  revision  123364  srcjavaorgapachegeronimotomcatdeploymenttomcatmodulebuilderjava  working  copy  387  387  import  orgapachegeronimodeploymentutildeploymentutil  import  orgapachegeronimogbeangbeaninfo  import  orgapachegeronimogbeangbeaninfobuilder  import  orgapachegeronimogbeanjmxgbeanmbean  import  orgapachegeronimogbeangbeandata  import  orgapachegeronimoj2eedeploymentearcontext  import  orgapachegeronimoj2eedeploymentmodule  import  orgapachegeronimoj2eedeploymentmodulebuilder  979  979  throw  new  deploymentexceptioncould  construct  module  name  e  gbeanmbean  gbean  gbeandata  gbean  try  gbean  new  gbeanmbeantomcatwebappcontextgbeaninfo  gbean  new  gbeandatawebmodulename  tomcatwebappcontextgbeaninfo  gbeansetattributewebapproot  baseuri  gbeansetattributewebclasspath  webclasspath  1107  1107  catch  exception  e  throw  new  deploymentexceptionunable  initialize  webapp  gbean  e  earcontextaddgbeanwebmodulename  gbean  earcontextaddgbeangbean  return  null  index  srcjavaorgapachegeronimotomcattomcatsecurewebappcontextjava  srcjavaorgapachegeronimotomcattomcatsecurewebappcontextjava  revision  123364  srcjavaorgapachegeronimotomcattomcatsecurewebappcontextjava  working  copy  1142  00  copyright  20032004  apache  software  foundation  licensed  apache  license  version  20  license  may  use  file  except  compliance  license  may  obtain  copy  license  httpwwwapacheorglicenseslicense20  unless  required  applicable  law  agreed  writing  software  distributed  license  distributed  basis  without  warranty  condition  kind  either  express  implied  see  license  specific  language  governing  permission  limitation  license  package  orgapachegeronimotomcat  import  javaneturi  import  javaneturl  import  orgapachecatalinarealm  import  orgapachecatalinadeployloginconfig  import  orgapachecatalinadeploysecurityconstraint  import  orgapachecommonslogginglog  import  orgapachecommonslogginglogfactory  import  orgapachegeronimogbeangbeaninfo  import  orgapachegeronimogbeangbeaninfobuilder  import  orgapachegeronimogbeangbeanlifecycle  import  orgapachegeronimogbeanwaitingexception  wrapper  webapplicationcontext  set  j2ee  environment  version  rev  56022  date  20041030  071618  0200  sat  30  oct  2004  public  class  tomcatsecurewebappcontext  extends  tomcatwebappcontext  implement  gbeanlifecycle  private  final  static  log  log  logfactorygetlogorgapachegeronimotomcattomcatsecurewebappcontextclass  private  final  loginconfig  loginconfig  private  final  realm  tomcatrealm  private  final  securityconstraint  securityconstraints  private  final  string  securityroles  public  tomcatsecurewebappcontexturi  webapproot  uri  webclasspath  url  configurationbaseurl  string  authmethod  string  realmname  string  loginpage  string  errorpage  realm  tomcatrealm  securityconstraint  securityconstraints  string  securityroles  tomcatcontainer  container  superwebapproot  webclasspath  configurationbaseurl  container  assert  authmethod  null  assert  realmname  null  assert  loginpage  null  assert  errorpage  null  assert  tomcatrealm  null  assert  securityconstraints  null  assert  securityroles  null  thistomcatrealm  tomcatrealm  thissecurityconstraints  securityconstraints  thissecurityroles  securityroles  loginconfig  new  loginconfig  loginconfigsetauthmethodauthmethod  loginconfigsetrealmnamerealmname  loginconfigsetloginpageloginpage  loginconfigseterrorpageerrorpage  public  void  setcontextproperties  supersetcontextproperties  contextsetrealmtomcatrealm  contextsetloginconfigloginconfig  add  security  constraint  int  0  securityconstraintslength  securityconstraint  sc  securityconstraintsi  contextaddconstraintsc  add  security  role  int  0  securityroleslength  contextaddsecurityrolesecurityrolesi  public  void  dostart  throw  waitingexception  exception  superdostart  loginfotomcatsecurewebappcontext  started  public  void  dostop  throw  exception  superdostop  loginfotomcatsecurewebappcontext  stopped  public  void  dofail  superdofail  loginfotomcatsecurewebappcontext  failed  public  static  final  gbeaninfo  gbeaninfo  static  gbeaninfobuilder  infofactory  new  gbeaninfobuildertomcat  secure  webapplication  context  tomcatsecurewebappcontextclass  infofactoryaddattributewebapproot  uriclass  true  infofactoryaddattributewebclasspath  uriclass  true  infofactoryaddattributeconfigurationbaseurl  urlclass  true  infofactoryaddattributepath  stringclass  true  infofactoryaddattributeauthmethod  stringclass  true  infofactoryaddattributerealmname  stringclass  true  infofactoryaddattributeloginpage  stringclass  true  infofactoryaddattributeerrorpage  stringclass  true  infofactoryaddattributetomcatrealm  realmclass  true  infofactoryaddattributesecurityconstraints  securityconstraintclass  true  infofactoryaddattributesecurityroles  stringclass  true  infofactoryaddreferencecontainer  tomcatcontainerclass  infofactorysetconstructornew  stringwebapproot  webclasspath  configurationbaseurl  authmethod  realmname  loginpage  errorpage  tomcatrealm  securityconstraints  securityroles  container  gbeaninfo  infofactorygetbeaninfo  public  static  gbeaninfo  getgbeaninfo  return  gbeaninfo  index  srcjavaorgapachegeronimotomcattomcatwebappcontextjava  srcjavaorgapachegeronimotomcattomcatwebappcontextjava  revision  123364  srcjavaorgapachegeronimotomcattomcatwebappcontextjava  working  copy  216  219  import  javaneturl  import  orgapachecatalinacontext  import  orgapachecatalinarealm  import  orgapachecatalinadeploysecurityconstraint  import  orgapachecatalinadeployloginconfig  import  orgapachecommonslogginglog  import  orgapachecommonslogginglogfactory  498  5219  private  string  docbase  null  public  tomcatwebappcontexturi  webapproot  uri  webclasspath  url  configurationbaseurl  tomcatcontainer  container  private  final  loginconfig  loginconfig  private  final  realm  tomcatrealm  private  final  securityconstraint  securityconstraints  private  final  string  securityroles  public  tomcatwebappcontexturi  webapproot  uri  webclasspath  url  configurationbaseurl  string  authmethod  string  realmname  string  loginpage  string  errorpage  realm  tomcatrealm  securityconstraint  securityconstraints  string  securityroles  tomcatcontainer  container  assert  webapproot  null  assert  webclasspath  null  assert  configurationbaseurl  null  606  7419  thiscontainer  container  thissetdocbasethiswebapprootgetpath  thistomcatrealm  tomcatrealm  thissecurityconstraints  securityconstraints  thissecurityroles  securityroles  authmethod  null  loginconfig  new  loginconfig  loginconfigsetauthmethodauthmethod  loginconfigsetrealmnamerealmname  loginconfigsetloginpageloginpage  loginconfigseterrorpageerrorpage  else  loginconfig  null  public  string  getdocbase  736  10028  public  void  setcontextproperties  contextsetdocbasewebapprootgetpath  contextsetpathpath  security  tomcatrealm  null  contextsetrealmtomcatrealm  loginconfig  null  contextsetloginconfigloginconfig  add  security  constraint  securityconstraints  null  int  0  securityconstraintslength  securityconstraint  sc  securityconstraintsi  contextaddconstraintsc  add  security  role  securityroles  null  int  0  securityroleslength  contextaddsecurityrolesecurityrolesi  public  context  getcontext  1097  1587  public  void  dofail  containerremovecontextthis  loginfotomcatwebappcontext  failed  1249  17320  infofactoryaddattributepath  stringclass  true  infofactoryaddattributeauthmethod  stringclass  true  infofactoryaddattributerealmname  stringclass  true  infofactoryaddattributeloginpage  stringclass  true  infofactoryaddattributeerrorpage  stringclass  true  infofactoryaddattributetomcatrealm  realmclass  true  infofactoryaddattributesecurityconstraints  securityconstraintclass  true  infofactoryaddattributesecurityroles  stringclass  true  infofactoryaddreferencecontainer  tomcatcontainerclass  infofactorysetconstructornew  stringwebapproot  webclasspath  configurationbaseurl  container  infofactorysetconstructornew  stringwebapproot  webclasspath  configurationbaseurl  authmethod  realmname  loginpage  errorpage  tomcatrealm  securityconstraints  securityroles  container  gbeaninfo  infofactorygetbeaninfo,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
2924,put  gbeandatas  deployment  context  queriable  container  use  query  resolve  link  gbeans  deploymentcontext  kept  queriable  registry  like  basicgbeanregistry  gbeandata  rather  thand  gbeaninstance  ejblinks  resourcelinks  gbeanlinks  etc  resolved  querying  registry  rather  special  purpose  tracking  simplify  refcontext  considerably  feature  needed  mail  gbean  deployed  j2ee  module  app  client  used  module,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
2925,numerous  enhancement  fix  interop  numerious  change  made  code  make  geronimo  code  friendly  cleaned  stub  skel  generator  add  java  method  overloading  removed  unnecessary  file  iiop  name  stub  repository  standalone  server  startup  fixeda  bunch  iiop  marshalling  error  showed  running  rmiiiop  code  j2ee  c  13  test  harness  rmiiiop  variable  name  code  style  changed  wasnt  done  make  previous  point  easier  made  number  gbeans  support  various  element  server  started  use  existing  networkservices  idea  ejbcontainer  webservicecontainer  thing  remember  still  todo  add  interceptor  support  plug  security  transaction  add  code  inserting  custom  data  object  ref  store  reference  statefull  object  server  side,1,1,1,0,1,1,1,0,0,0,1,0,1,0,0,0,1
2926,csiv2  csstss  gbean  reference  shorter  reference  cs  bean  ejbrefs  using  corba  require  entire  gbean  name  shortened  allow  supplying  part  gbean  name  inferrable  context  normally  name  component  line  j2eerelated  gbean  reference  similarly  tss  reference  appear,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2927,remaining  ejb  jar  javabeans  initial  checkin  javabeans  xml  dd  earlier  today  included  partial  implementation  ejbjar  pretty  rough  hadnt  combined  j2ee  object  yet  ejb  jar  javabeans  complete  also  added  minimal  javadoc  javabeans  there  loader  ejb  jar  based  dom  thats  12  complete  handle  everything  enterprisebeans  nothing  relationship  assemblydescriptor  nevertheless  enough  begin  work  involved  couple  minor  enhancement  loader  utility  class  jeremy  put  together  also  includes  validator  us  new  bean  process  metainfejbjarxml  actual  test  far  minimal  pretty  easy  extend  parallel,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2928,directory  based  hot  deployment  support  initial  start  directorybased  hot  deployment  geronimo  chance  update  thing  would  like  see  im  going  ahead  submitting  commiter  tweak  get  build  basically  gbean  service  monitor  specified  directory  filesystem  addition  modification  deletion  based  event  particual  module  filesystem  either  deployed  redeployed  undeployed  service  take  assumtion  deployment  plan  packaged  within  module  also  specified  directory  currently  hardcoded  attribute  deployment  plan  would  nice  configuration  started  webapp  welland  gbean  linked  webapp  directory  could  changed  fly  multiple  directory  well  option  could  specified  perhaps  could  something  configurable  console  also  currently  calling  orgapachegeronimodeploymentdeployer  deploy  initially  wanted  reference  deployer  gbean  invoke  deploy  issue  used  workaround  class  monitor  file  sytem  found  internet  however  able  detected  generic  change  made  modification  file  change  filesystem  catagorized  either  addition  modifiecations  deletion  see  license  file  unsure  weather  used  wether  need  rewritten  scratch  case  trivial  please  let  know  good  start  suggestion  think  something  pushed  10  glad  spend  additional  time  get  learning  exercise  pretty  scrappy  right  think  alot  could  done  thanks  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2929,workmanager  implementation  patch  contains  implementation  workmanager  spi  implementation  delegate  submitted  work  three  distinct  executor  one  synchronization  policy  executor  thread  pool  based  doug  lea  pooledexecutor  workmanager  workexecutors  mbeans  deployed  via  workmanagementservicexml  file  execution  work  worklistener  provided  work  submission  duly  notified  test  case  yielding  three  distinct  synchronization  policy  also  provided  test  case  us  worklistener  notification  order  introspect  status  submitted  work  gianny,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2930,provide  option  setting  controlling  hash  table  size  provide  session  system  option  setting  control  minimum  maximum  hash  table  size  operator  hashjoin  hashaggregate,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
2931,optimize  logical  boolean  operator  evaluation  using  fastsuccessfastfail  approach  short  circuit  evaluation  supported  boolean  andor  operator  drill937  could  optimize  boolean  andor  operator  reordering  evaluation  sequence  choose  evaluate  cheapest  test  first  instance  consider  following  expression  reallyslowtest  slowertest  fasttest  choose  evaluate  reallyslowtest  first  test  every  input  contrast  choose  fasttest  first  could  skip  evaluation  slowertest  reallyslowtest  input  fails  fasttest  performance  would  better  transform  expression  fasttest  slowertest  reallyslowtest  add  support  need  1  change  boolean  andor  take  arbitrary  number  operand  previously  andor  processed  taking  two  operand  way  could  compare  sort  operand  one  single  andor  operator  2  assign  cost  category  different  functionsoperators  reflect  rough  estimation  individual  functionoperator  3  reorder  operand  based  cumulative  cost  evaluation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2932,provide  reset  command  reset  option  default  value  within  session  currently  set  configuration  option  would  useful  reset  command  reset  value  option  default  system  value  alter  session  reset  option  name  dont  want  add  new  keyword  reset  could  potentially  overload  set  command  allow  user  set  default  value,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2933,multiplex  bitdata  adding  applicationlayer  back  pressure  0,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,0
2934,enhance  memory  profiling  reduce  memory  consumption  key  relational  operator  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2935,rename  randomreceiver  unorderedreceiver  decrease  confusion  0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1
2936,sender  report  misleadingincomplete  metric  screen  broadcastsender  singlesender  populating  metric  queryprofile  0  waittime  reported  byte  sent  reported  nsenders  named  nreceivers,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0
2937,add  configuration  drillclient  encode  complexrepeated  type  json  string  0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1
2938,memory  estimation  planning  optionally  allow  limiting  query  memory  compute  memory  usage  query  replan  without  hash  operation  usage  exceeds  limit,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1
2939,add  support  union  distinct  type  query  selects  compatible  column  json  file  either  side  union  operator  fails  query  work  union  used  example  failure  0  jdbcdrillzklocal  select  id  dfsusersbrumsbydrilldonutsjson  union  select  id  dfsusersbrumsbydrilldonutsjson  query  failed  orgapachedrillexecrpcrpcexception  remote  failure  running  queryerrorid  dfe76b6b7eb049ee80841e29ea995be0  endpoint  address  10250028  userport  31010  controlport  31011  dataport  31012  errortype  0  message  failure  parsing  sql  cannotplanexception  node  rel880subset6physicalsingleton  could  implemented  planner  state  query  union  work  0  jdbcdrillzklocal  select  id  dfsusersbrumsbydrilldonutsjson  union  select  id  dfsusersbrumsbydrilldonutsjson  id  0001  0001  2  row  selected  0111  second,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
2940,hive  scalar  udfs  add  data  type  support  date  timestamp  decimal  currently  passing  data  type  date  timestamp  decimal  hive  udfs  supported  task  add  support  type,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
2941,json  projection  pushdown  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2942,implement  support  fixed  binary  type  parquet  reader  currently  red  fixed  binary  column  parquet  one  decimal  converted  type  subset  use  case  fixed  binary  table  used  store  arbitrary  binary  data  byte  aligned  length  value  unfortunately  fixed  binary  vector  implemented  drill  currently  data  read  varbinary  vector  cam  optimized  later,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2943,create  new  text  mode  json  currently  drill  fails  schema  change  json  due  fundamental  limitation  drill  record  representation  others  due  drill  lack  full  support  mutating  schema  solved  temporarily  reading  data  string  allowing  user  use  combination  case  statement  udfs  appropriately  handle  schema  mutation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2944,add  support  local  exchange  node  exchange  node  currently  assume  remote  communication  certain  situation  useful  consolidate  separate  minor  fragment  together  pushing  remote  node  reduce  communication  overhead  depending  size  nature  data,1,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,0
2945,fast  schema  return  right  first  schema  query  set  returned  blocking  operator  complete  many  case  would  useful  empty  record  set  returned  prior  completing  blocking  operator  tool  understand  schema  sooner,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
2946,support  scalar  replacement  valueholder  expression  improve  performance  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
2947,enable  partition  pruning  filesystem  query  file  files2012janlogcsv  files2013janlogcsv  write  query  select  file  dir0  2012  dir1jan  drill  read  file  filter  second  file  drill  recognize  dir02012  dir1jan  pushed  storage  layer  prune  file  read  part  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2948,offload  fragment  profile  data  dfs  rather  storing  zookeeper  pstores  really  built  trivial  configuration  data  large  query  profile  move  using  dfs  storage  query  profile  distributed  mode  release  note  default  blob  data  hence  fragment  profile  stored  local  file  system  drilllogdir  folder  however  moved  dfs  specifying  target  folder  url  using  drillexecsysstoreproviderzkblobroot  setting  drill  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2949,create  unit  test  framework  ease  creating  unit  test  full  result  verification  0,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
2950,avro  record  reader  record  reader  implementation  avro  data  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2951,update  hiverecordreader  read  hive  decimal  field  scale  precision  currently  hiverecordreader  read  decimal  data  hive  convert  varchar  reason  hive012  doesnt  enforce  precision  scale  record  drill  may  get  record  different  precision  scale  within  column  drill  cant  handle  currently  hive013  scale  precision  enforced  record  column  drill1347  upgrade  hive  storage  plugin  work  hive013  jira  created  track  change  hiverecordreader  read  hive  decimal  data  decimal  varchar,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2952,generalize  codegenerator  functionholder  support  type  function  codegenerator  much  embedded  business  logic  abstracted  dont  copy  past  code  multiple  time,1,0,1,0,1,0,0,0,0,0,1,0,0,0,1,0,0
2953,enable  full  engine  jdbc  layer  get  full  exec  engine  many  thing  implicitly  defined  instead  need  add  explicit  option  proposal  define  set  jdbc  connection  string  property  engineref  mean  reference  interpreter  capability  schema  available  enginefull  default  mean  full  execution  engine  tool  available  engineboth  mean  type  available  enginefull  additional  property  zkconnection  string  also  requires  implementation  smarter  schema  type  provides  automatic  schema  type  recognized  execution  engine,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2954,prudent  use  zkstore  using  zk  need  prudent  much  data  store  update  thing  zkstore  cachewatcher  based  profile  stored  rather  local  dfs,1,0,1,0,1,0,1,0,0,0,0,1,1,0,0,1,1
2955,drillclient  becomes  invalid  drillbit  restart  drillclient  connects  drillbit  drillbit  restarts  drillclient  cannot  send  query  drillbit  havent  looked  drillclient  rpcbus  capable  handling  reconnect  retry  automatically  user  code  handle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2956,merge  join  operator  implement  merge  join  physical  operator  support  left  right  inner  join,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2957,implement  filter  pushdown  parquet  parquet  reader  currently  support  project  pushdown  limiting  number  column  read  however  use  filter  pushdown  read  subset  requested  column  particularly  useful  parquet  file  contain  statistic  importantly  min  max  value  page  evaluating  predicate  value  could  save  major  reading  decoding  time  largest  barrier  implementing  current  design  reader  firstly  currently  two  separate  parquet  reader  one  reading  flat  file  quickly  another  reading  complex  data  enhancement  make  flat  reader  make  support  nested  data  much  efficient  manner  however  speed  flat  file  reader  currently  come  able  make  vectorized  copy  parquet  file  design  somewhat  odds  filter  pushdown  make  useful  vectorized  copy  filter  match  large  run  value  within  file  might  rare  case  assuming  file  often  somewhat  sorted  primary  field  like  date  numeric  key  often  field  used  limit  query  subset  data  however  case  filter  record  make  individual  copy  need  design  work  best  way  balance  performance  use  case  mind,1,1,1,0,1,1,0,0,0,0,1,0,1,0,0,0,0
2958,add  peak  memory  allocation  operator  operatorstats  currently  localmemoryallocated  always  set  zero  try  fill  stats  end  fragment  execution  calling  allocatorgetallocatedmemory  point  already  released  allocated  memory  instead  stat  peak  memory  allocator  seen  lifetime  operator  execution  useful  operator  allocator  example  query  query  profile  find  aggregate  peak  memory  operator  across  minor  fragment  major  fragment  list  descending  order  peak  memory  usage  codesql  select  majorfragmentid  opprofileoperatortype  optype  sumopprofilepeaklocalmemoryallocated  aggpeakmemoryacrossallminorfragments  select  majorfragmentid  flattenminorfragprofileoperatorprofile  opprofile  select  majorfragmentmajorfragmentid  majorfragmentid  flattenmajorfragmentminorfragmentprofile  minorfragprofile  select  flattenfragmentprofile  majorfragment  dfstmpajson  opprofileoperatortype  6  want  filter  particular  operator  group  majorfragmentid  opprofileoperatortype  order  aggpeakmemoryacrossallminorfragments  desc  code  code  majorfragmentid  optype  aggpeakmemoryacrossallminorfragments  1  4  115065856  1  3  10027008  0  3  1671168  3  6  1536000  2  6  901120  1  6  606208  3  28  393216  2  28  229376  3  10  122880  2  10  81920  0  11  0  0  10  0  0  13  0  1  10  0  1  11  0  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2959,support  basic  parallelization  insertion  sql  aggregate  plan  add  additional  hash  function  xor  support  hash  combination  update  basicoptimizer  support  parallel  sql  aggregation  plan  upstream  user  requested  sort,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
2960,add  io  wait  time  stats  parquet  json  input  file  currently  time  spent  io  read  time  included  part  total  processing  time  jira  measure  io  read  time  separately  add  operatorstats  implementation  detail  add  filesystem  implementation  called  drillfilesystem  take  existing  filesystem  instance  operatorstats  whenever  file  opened  using  drillfilesystem  return  instance  drillfsdatainputstream  facade  actual  fsdatainputstream  drillfsdatainputstream  add  io  read  time  stats  whenever  read  request  issued  io  stats  work  drillfilesystem  used  patch  modified  json  parquet  reader  use  drillfilesystem  text  reader  included,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
2961,split  jdbc  implementation  orgapachedrilljdbc  pkg  place  doc  jdbc  implementation  class  interface  part  drill  published  jdbc  interface  moved  package  orgapachedrilljdbc  support  using  javadoc  produce  enduser  documentation  drillspecific  jdbc  api  behavior  eg  whats  implemented  plus  extension  keep  clear  part  drill  published  jdbc  interface  v  ie  item  technically  accessible  public  protected  meant  used  drill  user  part  1  move  class  package  orgapachedrilljdbc  eg  drillhandler  drillconnectionimpl  implementation  package  eg  orgapachedrilljdbcimpl  2  split  current  orgapachedrilljdbcdriver  publishedinterface  portion  still  orgapachedrilljdbcdriver  plus  implementation  portion  orgapachedrilljdbcimpldriverimpl  orgapachedrilljdbcdriver  would  expose  published  interface  eg  constructor  method  javasqldriver  orgapachedrilljdbcimpldriverimpl  would  contain  method  part  drill  published  jdbc  interface  including  method  need  public  protected  using  avatica  shouldnt  used  drill  user  3  needed  drill  extension  documentation  create  drillspecific  interface  extending  standard  jdbc  interface  example  create  place  documenting  drillspecific  behavior  method  defined  javasqlconnection  create  interface  eg  orgapachedrilljdbcdrillconnection  extends  interface  javasqlconnection  adjust  internal  implementation  class  orgapachedrilljdbcimpl  implement  drillspecified  interface  rather  directly  implementing  javasqlconnection  add  method  declaration  drillspecific  documentation  drillspecific  subinterface  4  drillspecific  interface  created  per  part  3  consider  using  covariant  return  type  narrow  return  type  drillspecific  interface  example  javasqlconnections  createstatement  method  return  type  javasqlstatement  drill  implementation  method  always  return  drillspecific  implementation  javasqlstatement  also  implementation  drillspecific  interface  extends  javasqlstatement  therefore  drillspecific  connection  interface  redeclare  createstatement  returning  drillspecific  statement  interface  type  drillspecific  statement  type  subtype  javasqlstatement  would  likely  make  easier  client  code  access  drill  extension  method  although  client  might  cast  something  else  special  get  first  drillspecific  interface  class  could  traverse  object  eg  connection  statement  statement  result  set  etc  still  using  drillspecific  type  needing  cast  whatever  step  note  step  1  2  already  prototyped,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,1
2962,improve  profile  page  web  ui  show  additional  memory  stats  fragment  status  0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
2963,make  jdbc  connection  honor  configuration  option  disabling  embedded  web  server  current  implementation  drill  jdbc  connection  honor  handle  parameter  passed  jdbc  connection  stringexcept  local  mode  flag  proposal  make  implementation  recognize  bag  configuration  option  passed  userspecifically  one  disabling  embedded  web  server  typical  use  case  feature  would  unit  test  jdbc  unit  test  instantiates  individual  drillbit  per  test  case  local  mode  turn  start  embedded  web  server  prevents  u  parallelizing  test  due  fact  port  assigned  web  server  currently  use  former  bit  also  impairs  test  runtime  starting  web  server  take  12  secondstest  case,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2964,enable  querying  partition  information  without  reading  data  reading  series  file  nested  directory  drill  currently  add  column  representing  directory  structure  traversed  reach  file  currently  read  column  stored  varchar  tha  name  dir0  dir1  regular  column  drill  allows  arbitrary  query  data  term  aggregate  filter  sort  etc  allow  optimizing  read  basic  partition  pruning  already  added  prune  case  expression  like  dir0  2015  simple  list  converted  planning  series  or  equal  expression  user  want  query  directory  information  dynamically  include  specific  directory  name  query  prompt  full  table  scan  filter  operation  dir  column  enhancement  allow  complex  query  run  directory  metadata  scanning  matching  directory,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2965,allow  multithreaded  copy  andor  flush  partitionsender  related  drill133  localexchange  merge  data  multiple  receiver  localexchange  fan  later  multiple  sender  amount  data  need  sent  increase  add  ability  copyflush  data  multiple  thread,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2966,build  sampling  range  partitioner  create  new  operator  cache  number  record  batch  coordinate  across  cluster  distribution  partitioning  key  try  determine  reasonable  set  range  partition  outgoing  stream  include  partition  key  equal  width  receiving  fragment  histogram  similar  held  distributed  cache  need  figure  logic  long  wait  partitioning  estimate  good  enough  need  update  partitioning  sender  drop  partitioning  column  rather  sending  onward,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
2967,clone  parquet  record  reader  log  file  record  caused  error  reader  believe  title  self  exploratory  parquet  reader  fails  reason  due  offending  record  drill  log  file  multiple  file  linerecord  error  occurs  improve  debugging  dealing  large  file  large  number  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2968,add  exception  pause  injection  testing  drillbit  stability  use  exception  injection  mechanism  add  exception  injection  test  variety  distributed  failure  scenario  scenario  weve  worked  1  cancellation  tc1  cancel  result  set  returned  tc2  cancel  middle  fetching  result  set  tc3  cancel  result  set  produced  fetched  tc4  cancel  everything  completed  fetched  test  setup  need  query  dataset  large  enough  sent  different  drillbits  eg  tpch  100  query  force  multiple  drillbits  work  eg  count  group  2  completed  case  check  drillbits  still  running  tc1  success  tc2  failed  query  query  executed  sql  parsing  tc3  failed  query  query  executed  sending  fragment  drillbits  execution  tc4  failed  query  query  execution  currently  possible  create  scenario  query  may  hang  check  drillbits  running  clean  state  run  select  count  sysdrillbits  code  select  count  sysmemory  code,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
2969,current  method  combining  hash  value  produce  skew  current  method  combining  hash  value  multiple  column  produce  skew  case  even  though  individual  hash  function  produce  skew  combining  function  xor  code  hasha  b  xor  hasha  hashb  code  result  0  row  b  hasha  hashb  clearly  create  severe  skew  affect  performance  query  hashaggregate  based  groupby  b  hashjoin  column,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2970,fix  expression  interpreter  allow  executing  expression  planning  time  expression  interpreter  currently  available  drill  cannot  used  planning  time  mean  connect  direct  memory  allocator  stored  drillbitcontext  level  implement  new  rule  based  evaluating  expression  constant  small  datasets  partition  information  limitation  must  addressed,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
2971,separate  queryresult  two  message  queryresult  querydata  currently  foreman  screenroot  use  queryresult  part  querywritablebatch  send  data  andor  query  status  split  two  separate  message  one  data  sent  screenroot  another  querystatus  sent  foreman,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
2972,implement  diagnostic  operator  support  inserting  diagnostic  physical  operator  physical  plan  record  record  batch  output  preceding  operator  additionally  provide  tool  view  data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2973,proposal  cast  mechanism  proposal  implementing  cast  mechanism  drill  casting  mechanism  would  two  type  implicit  type  casting  explicit  type  casting  detail  implicit  type  cast  would  take  care  casting  lower  datatype  holder  higher  datatype  holder  automatically  bq  eg  intholder  would  casted  float4holderfloat8holder  directly  explicit  type  casting  would  enable  user  use  cast  function  cast  value  another  datatype  specifying  type  cast  function  would  function  exposed  syntax  similar  standard  sql  format  bq  eg  select  cast  somevalue  int  sometable  type  conversion  rule  conversion  rule  similar  sql  standard  implicit  type  conversion  arithmetic  comparison  operator  etc  operand  type  different  string  would  converted  double  operand  would  converted  type  choosing  type  higher  precision  value  passed  functionudf  value  would  converted  parameter  accepted  function  case  multiple  overloaded  function  present  function  least  number  conversion  would  selected  case  multiple  function  least  number  conversion  would  error  returned  user  ambiguous  function  explicit  type  conversion  user  would  use  cast  function  converting  type  another  specified  type  nonconvertible  type  user  get  error  back,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2974,support  large  list  0,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,1,1
2975,pause  injection  pause  indefinitely  signalled  currently  injected  pause  make  thread  sleep  specified  time  enhanced  stop  thread  indefinitely  using  countdownlatch  quite  similar  cancellation  work  task  add  another  message  rpc  layer  signal  paused  remote  thread  resume  controlhandler  counting  complication  thread  reached  pause  site  yet  b  add  resume  signal  like  ctrlc  sqlline  enhancement  another  signal  trigger  pause  sqlline,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
2976,handle  counting  status  sent  batch  fragmentcontext  tracking  sent  batch  currently  done  sender  much  code  duplicated  unnecessary  want  move  tracking  sent  batch  handling  status  fragmentcontext,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
2977,make  dfstesttmp  schema  location  local  f  exclusive  test  jvm  fork  currently  dfstesttmp  workspace  location  local  filesystem  hardcoded  tmpdrilltest  test  creates  view  new  table  created  location  problem  two  test  fork  running  parallel  sharing  dfstesttmp  workspace  location  cause  synchronization  issue  example  testviewsupportview1  creates  view  testview1  workspace  dfstesttmp  cause  new  view  file  tmpdrilltest  directory  point  parallel  running  test  testinfoschemashowtables  make  call  list  table  dfstesttmp  workspace  show  table  return  testview1  one  table  dfstesttmp  workspace  expecting  causing  testinfoschemashowtables  fail  proposed  solution  setting  drill  test  cluster  basetestquery  root  class  test  modify  workspace  dfstesttmp  location  point  temp  directory  created  using  filescreatetempdir  two  process  call  filescreatetempdir  time  one  guarateed  get  exclusive  directory  long  1000  call  per  millisecond  jdbc  rely  property  drilljdbcunittests  connection  property  setup  exclusive  directory  dfstesttmp  workspace,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2978,filter  pushed  subquery  group  im  sure  one  theoretically  filter  could  pushed  subquery  code  0  jdbcdrillschemadfs  explain  plan  select  x  z  select  a1  b1  avga1  t1  group  a1  b1  sqx  z  x  10  text  json  0000  screen  0001  projectx0  y1  z2  0002  projectx0  y1  zcastcasthighcase3  0  null  2  3any  null  0003  selectionvectorremover  0004  filtercondition0  10  0005  hashagggroup0  1  agg0sum00  agg1count0  0006  projecta11  b10  0007  scangroupscanparquetgroupscan  entriesreadentrywithpath  pathmaprfsdrilltestdatapredicatest1  selectionrootdrilltestdatapredicatest1  numfiles1  columnsa1  b1  code  distinct  subquery  code  0  jdbcdrillschemadfs  explain  plan  select  x  z  select  distinct  a1  b1  c1  t1  sqx  z  x  10  text  json  0000  screen  0001  projectx0  y1  z2  0002  projectx0  y1  z2  0003  selectionvectorremover  0004  filtercondition0  10  0005  hashagggroup0  1  2  0006  projecta12  b11  c10  0007  scangroupscanparquetgroupscan  entriesreadentrywithpath  pathmaprfsdrilltestdatapredicatest1  selectionrootdrilltestdatapredicatest1  numfiles1  columnsa1  b1  c1  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
2979,use  pojorecordreader  system  table  current  implementation  us  systemrecordreader  populate  systemrecords  required  pojorecordreader  used  accomplish  task,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2980,move  drill  alternative  costbased  planner  join  planning  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2981,add  simplified  activity  log  create  simple  log  track  time  submitted  time  completed  user  query  queryid  outcome,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2982,add  convenience  method  test  builder  creating  nested  baseline  value  building  test  case  often  need  create  list  instance  set  baseline  value  java  spaceas  opposed  using  baseline  query  issue  proposes  adding  static  utility  method  testbuilderlistofvalues  expedite  process  creating  list  applies  map  like  testbuildermapofkeyvaluesequence,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2983,hive  partition  pruning  happening  tested  100  commit  id  hive  013  code  select  sysversion  commitid  commitmessage  committime  buildemail  buildtime  d8b19759657698581cc0d01d7038797952888123  drill3100  testimpersonationdisabledwithminidfs  fails  window  15052015  011803  edt  unknown  15052015  030710  edt  1  row  selected  0083  second  code  reproduce  1  use  hive  create  partition  table  code  create  table  partitiontableid  int  username  string  partitioned  byyear  string  month  string  row  format  delimited  field  terminated  insert  table  partitiontable  partitionyear2014month11  select  1u  password  limit  1  insert  table  partitiontable  partitionyear2014month12  select  2  password  limit  1  insert  table  partitiontable  partitionyear2015month01  select  3e  password  limit  1  insert  table  partitiontable  partitionyear2015month02  select  4r  password  limit  1  insert  table  partitiontable  partitionyear2015month03  select  5n  password  limit  1  code  2  hive  query  partition  pruning  2  query  code  hive  explain  extended  select  partitiontable  year2015  month  0203  partition  value  month  02  year  2015  partition  value  month  03  year  2015  explain  extended  select  partitiontable  year2015  month  02  month  03  partition  value  month  02  year  2015  partition  value  month  03  year  2015  code  hive  scan  2  partition  201502  201503  3  drill  partition  pruning  2  query  code  explain  plan  select  hivepartitiontable  year2015  month  0203  text  json  0000  screen  0001  projectid0  username1  year2  month3  0002  selectionvectorremover  0003  filterconditionand2  2015  or3  02  3  03  0004  scangroupscanhivescan  tabletabledbnamedefault  tablenamepartitiontable  inputsplitsmaprfsuserhivewarehousepartitiontableyear2015month01000000004  maprfsuserhivewarehousepartitiontableyear2015month02000000004  maprfsuserhivewarehousepartitiontableyear2015month03000000004  column  partition  partitionvalues2015  01  partitionvalues2015  02  partitionvalues2015  03  explain  plan  select  hivepartitiontable  year2015  month  02  month  03  text  json  0000  screen  0001  projectid0  username1  year2  month3  0002  selectionvectorremover  0003  filterconditionand2  2015  3  02  3  03  0004  scangroupscanhivescan  tabletabledbnamedefault  tablenamepartitiontable  inputsplitsmaprfsuserhivewarehousepartitiontableyear2015month01000000004  maprfsuserhivewarehousepartitiontableyear2015month02000000004  maprfsuserhivewarehousepartitiontableyear2015month03000000004  column  partition  partitionvalues2015  01  partitionvalues2015  02  partitionvalues2015  03  code  drill  scan  3  partition  201501  201502  201503  note  inlist  1  value  drill  partition  pruning  well  code  explain  plan  select  hivepartitiontable  year2015  month  02  text  json  0000  screen  0001  projectid0  username1  year2  month3  0002  scangroupscanhivescan  tabletabledbnamedefault  tablenamepartitiontable  inputsplitsmaprfsuserhivewarehousepartitiontableyear2015month02000000004  column  partition  partitionvalues2015  02  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
2984,textreader  support  multibyte  line  delimiters  linedelimiter  textformatconfig  doesnt  support  rn  record  delimiters,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2985,reading  select  column  parquet  file  0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0
2986,csv  reader  allow  newlines  inside  quote  reading  csv  file  contains  newlines  within  quoted  string  eg  via  select  dfstmpqcsv  drill  10  say  error  system  error  comunivocityparserscommontextparsingexception  error  processing  input  cannot  use  newline  character  within  quoted  string  many  tool  produce  csv  file  newlines  quoted  string  drill  able  handle  workaround  csvquote  program  httpsgithubcomdbrocsvquote  encode  embedded  comma  newlines  even  decode  later  desired,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2987,apache  drill  jdbc  storage  plugin  query  rdbms  system  mysql  netezza  apache  drill  developed  base  code  jdbc  storageplugin  apache  drill  code  primitive  consitutes  good  starting  point  coding  today  provides  primitive  support  select  rdbms  jdbc  goal  provide  complete  select  support  rdbms  push  capability  currently  code  using  standard  jdbc  class,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2988,add  window  function  rownumber  rank  percentrank  denserank  cumedist  add  support  following  window  function  rownumber  rank  denserank  percentrank  cumedist,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
2989,umbrella  plan  read  hive  table  native  drill  read  native  reader  underlying  table  format  exists  read  hive  currently  done  hive  serde  interface  provides  flexibility  api  optimized  maximum  performance  reading  data  drill  native  data  structure  parquet  text  file  backed  table  plan  read  drill  native  read  currently  read  file  type  provide  untyped  data  parquet  metadata  file  currently  make  use  type  information  planning  text  file  read  file  list  varchars  case  cast  need  injected  provide  datatypes  provided  read  serde  interface,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2990,enhance  rpc  layer  offload  request  work  onto  separate  thread  right  app  responsible  ensuring  small  amount  work  done  rpc  thread  case  app  doesnt  correctly  additionally  high  load  situation  small  amount  work  become  trivial  need  make  rpc  layer  protect  slow  requestsresponses,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2991,query  planning  support  partition  clause  drill  ctas  statement  going  add  partition  clause  drill  ctas  statement  partition  clause  specify  list  column  result  table  column  list  used  partition  data  create  table  tablename  colname  partition  colname  selectstatement  semantics  restriction  partition  clause  column  partition  clause  table  column  list  selectstatement  column  base  table  selectstatement  schemaless  otherwise  query  validation  error  would  raised  partition  column  resolved  column  schemaless  query  column  could  result  join  operation  restriction  added  since  join  operation  query  planner  would  know  table  might  produce  partition  column  example  code  create  table  mytable1  partition  rregionkey  select  rregionkey  rname  cptpchregionparquet  code  code  create  table  mytable2  partition  rregionkey  select  cptpchregionparquet  code  code  create  table  mytable3  partition  rregionkey  select  rrregionkey  rrname  nnnationkey  nnname  cptpchnationparquet  n  cptpchregionparquet  r  nnregionkey  rrregionkey  code  invalid  case  1  partition  column  table  column  list  code  create  table  mytable4  partition  rregionkey2  select  rregionkey  rname  cptpchregionparquet  code  invalid  case  2  partition  column  resolved  join  operator  code  create  table  mytable5  partition  rregionkey  select  cptpchnationparquet  n  cptpchregionparquet  r  nnregionkey  rrregionkey  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2992,userexceptions  logged  right  class  currently  system  error  logged  using  userexceptionlogger  class  throw  userexception  delegate  logging  userexceptionbuild  method,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
2993,add  named  metric  named  operator  operatorprofile  useful  reading  json  query  profile  rename  fragmentstatsgetoperatorstats  fragmentstatsnewoperatorstats,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
2994,move  operatorwrapper  list  fragmentwrapper  list  creation  profilewrapper  ctor  avoid  recomputation  case  consistent  comparator  name,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
2995,extend  heap  memory  manager  support  growing  vector  add  following  interface  bufferl  memory  manager  ptr  allocsize  min  max  allocate  block  given  size  total  capacity  minmax  trimptr  free  extra  capacity  current  size  capacity  rationale  isnt  always  possible  anticipate  size  vector  creating  new  vector  one  strategy  overallocate  vector  trim  size  vector  complete  routine  allow  u  implement  strategy,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
2996,add  new  httpd  format  plugin  add  httpd  logparser  based  format  plugin  author  kind  enough  move  logparser  project  released  apache  license  find  dependency  groupidnlbasjesparsehttpdloggroupid  artifactidhttpdlogparserartifactid  version20version  dependency,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
2997,rename  nonrootstatusreporter  fragmentstatusreporter  drill3072  need  statusreporter  interface  abstractstatusreporter  one  implementation  nonrootstatusreporter  renamed  fragmentstatusreporter  root  nonroot  fragment  use  report  status  foreman,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1,1
2998,add  implicit  file  column  support  could  find  another  ticket  talk  file  name  column  selected  filtered  querying  directory  like  dir0  dir1  available,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
2999,bson  record  reader  mongo  storage  plugin  improve  mongo  query  performance  considering  suggestion  provided  dragoncurve  hgunes  drill  mailing  chain,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
3000,add  support  encoding  drill  data  type  byte  ordered  format  following  jira  added  functionality  hbase  httpsissuesapacheorgjirabrowsehbase8201  need  port  functionality  drill  allow  filtering  pruning  row  scan,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3001,add  ansiquotes  option  drill  sql  parser  recognize  ansisql  identifier  added  possibility  changing  character  quoting  identifier  setting  quotingidentifiers  systemsession  option  codeplannerparserquotingidentifierscode  three  mode  quoting  identifier  1  back  tick  default  quoting  mode  unicode  u0060  grave  accent  codecode  character  used  setting  systemsession  option  quoting  identifier  2  double  quote  unicode  u0022  quotation  mark  codecode  character  used  setting  systemsession  option  quoting  identifier  3  bracket  unicode  u005b  left  square  bracket  codecode  character  used  setting  systemsession  option  quoting  identifier  left  quote  character  right  quote  character  quoting  identifier  mode  unicode  u005d  right  square  bracket  codecode  example  using  quotingidentifiers  option  code  0  jdbcdrillzklocal  select  sysoptions  name  plannerparserquotingidentifiers  name  kind  type  status  numval  stringval  boolval  floatval  plannerparserquotingidentifiers  string  system  default  null  null  null  1  row  selected  0189  second  0  jdbcdrillzklocal  select  employeeid  fullname  cpemployeejson  limit  1  employeeid  fullname  1  sheri  nowmer  1  row  selected  0148  second  0  jdbcdrillzklocal  alter  session  set  plannerparserquotingidentifiers  ok  summary  true  plannerparserquotingidentifiers  updated  1  row  selected  0107  second  0  jdbcdrillzklocal  select  employeeid  fullname  cpemployeejson  limit  1  employeeid  fullname  1  sheri  nowmer  1  row  selected  0129  second  0  jdbcdrillzklocal  alter  session  set  plannerparserquotingidentifiers  ok  summary  true  plannerparserquotingidentifiers  updated  1  row  selected  0102  second  0  jdbcdrillzklocal  select  employeeid  fullname  cpemployeejson  limit  1  employeeid  fullname  1  sheri  nowmer  1  row  selected  014  second  0  jdbcdrillzklocal  alter  session  set  plannerparserquotingidentifiers  ok  summary  true  plannerparserquotingidentifiers  updated  1  row  selected  01  second  0  jdbcdrillzklocal  select  employeeid  fullname  cpemployeejson  limit  1  employeeid  fullname  1  sheri  nowmer  1  row  selected  0139  second  code  quoting  character  acceptable  particular  one  chosen  code  0  jdbcdrillzklocal  alter  session  set  plannerparserquotingidentifiers  ok  summary  true  plannerparserquotingidentifiers  updated  1  row  selected  0561  second  0  jdbcdrillzklocal  select  employeeid  fullname  cpemployeejson  limit  1  error  parse  error  lexical  error  line  1  column  8  encountered  96  sql  query  select  employeeid  fullname  cpemployeejson  limit  1  error  id  9bfcb6b77d9d46d78ea078d1d88b5c3b  vitaliipc31010  statecode0  code  possibility  setting  quotingidentifiers  using  quotingidentifiers  property  jdbc  connection  url  string  example  code  jdbcdrillzklocalquotingidentifiers  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3002,add  support  inner  class  code  generator  situation  would  helpful  support  code  generation  inner  class  expand  codegenerator  surrounding  class  support  case,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
3003,drop  table  support  umbrella  jira  track  support  drop  table  feature,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3004,add  support  lead  lag  ntile  firstvalue  lastvalue  window  function  jira  track  progress  following  window  function  particular  order  lead  lag  ntile  firstvalue  lastvalue,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3005,use  factory  create  root  allocator  use  factory  instead  constructor  toplevel  direct  memory  allocator  replace  allocator  get  instantiated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3006,add  http  support  drill  web  interface  currently  web  ui  rest  api  call  dont  support  transport  layer  security  tl  jira  add  support  tl  need  feature  adding  user  authentication  drill  web  interface  proposal  always  default  http  cluster  admin  set  following  ssl  configuration  specify  keystore  andor  truststore  javanetsslkeystore  javanetsslkeystorepassword  javanetssltruststore  javanetssltruststorepassword  cluster  admin  didnt  specified  ssl  config  generate  self  signed  certificate  programmatically  use  using  library  bouncy  castlehttpwwwbouncycastleorg  make  use  jetty  apis  add  http  connection  example  herehttpgiteclipseorgcjettyorgeclipsejettyprojectgittreeexamplesembeddedsrcmainjavaorgeclipsejettyembeddedlikejettyxmljava  let  know  comment,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3007,improve  classpath  scanning  reduce  time  take  classpath  scanning  function  registry  take  long  time  second  every  time  wed  want  avoid  loading  class  use  bytecode  inspection  instead  build  time  cache  avoid  scanning  startup,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
3008,rewrite  mergejoinbatch  using  record  batch  iterator  current  implementation  merge  join  operator  convoluted  handle  duplicate  record  batch  mergejoin  rewrite  use  record  batch  iterator  hide  complexity  managing  multiple  record  batch  iterating,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3009,implement  external  sort  operator  operator  allow  sorting  data  larger  size  memory  spilling  disk  necessary  also  part  jira  implement  new  merge  sort  algorithm  hopefully  better  utilize  cluster  resource  current  sort  based  quicksort  problem  quicksort  cant  sorting  batch  arrived  often  result  low  cpu  utilization  data  read  disk  followed  period  high  cpu  usage  external  sort  include  sorting  batch  individually  arrives  case  spill  occur  make  sense  take  advantage  fact  batch  already  sorted  nway  merge  done  spill  effective  way  according  test  done  done  case  rather  nway  merge  using  heap  variation  natural  merge  sort  amount  essentially  staged  2way  merge  incoming  sorted  batch,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
3010,hive  udfs  drill  plan  support  scalar  hive  function  udf  genericudf  aggregate  table  function  come  later  design  document  httpsdocsgooglecomdocumentd19hd4fcqho8gktyeixhykkdg1kowlhb1811hl1c4u8eedituspsharing  review  httpsreviewsapacheorgr18372diffpage1,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
3011,read  raw  key  value  byte  sequence  file  sequence  file  store  list  keyvalue  pair  keysvalues  type  hadoop  writable  provide  format  plugin  read  raw  byte  sequence  file  deserialized  udffrom  hadoop  writable  drill  type,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
3012,select  option  add  mechanism  pas  parameter  storageplugin  writing  select  statement  discussion  httpmailarchivesapacheorgmodmboxdrilldev201510mbox3ccao2bvc4acgk32b3qyvqv1xppdpg3tc2bfg3d0xdgeuprhd6kthv5q40mailgmailcom3e  httpmailarchivesapacheorgmodmboxdrilldev201511mbox3ccaovc4clzylvjevisfjqtcyxbzsmfy4bqrmjhbidwzgqfvjgmailgmailcom3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3013,reduce  metadata  cache  file  size  parquet  metadata  cache  file  fair  amount  redundant  metadata  cause  size  cache  file  bloat  two  thing  reduce  1  schema  repeated  every  row  group  keep  merged  schema  similar  discussed  insert  functionality  2  max  min  value  stats  used  partition  pruning  value  keep  maxvalue  minvalue,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,1
3014,handle  schema  change  externalsort  improvement  make  use  union  vector  handle  schema  change  new  schema  appears  schema  merged  previous  schema  result  new  schema  us  union  type  store  column  type  conflict  batch  including  batch  already  arrived  coerced  new  schema  new  comparison  function  included  handle  comparison  union  type  comparison  union  type  work  follows  1  numeric  type  mutually  compared  compared  using  drill  implicit  cast  rule  2  type  compared  type  among  value  type  3  overall  precedence  type  regard  ordering  precedence  yet  defined  part  work  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3015,make  us  autocloseables  use  addsuppressed  exception  avoid  noise  log  0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3016,ability  submit  simple  type  physical  plan  directly  endpoint  drillbit  execution  today  drill  query  execution  optimistic  stateful  least  due  data  exchange  stage  query  execution  fails  whole  query  fails  query  simple  scan  filter  push  project  data  exchange  happens  drillbits  need  fail  whole  query  one  drillbit  fails  minor  fragment  running  drillbit  rerun  drillbit  probably  multiple  way  achieve  jira  open  discussion  1  agreement  need  support  use  case  2  mean  achieving,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3017,union  involving  empty  directory  side  union  result  failed  query  union  query  involves  empty  directory  either  side  union  operator  result  failed  query  return  result  nonempty  side  input  union  note  emptydir  empty  directory  directory  exists  file  drill  14  gitcommitidb9068117  4  node  cluster  centos  codejava  0  jdbcdrillschemadfstmp  select  columns0  emptydir  union  select  castcolumns0  int  c1  testwindowcsv  error  validation  error  line  1  column  24  line  1  column  32  table  emptydir  found  error  id  5c024786670341078a4a16c96097be08  centos01qalab31010  statecode0  0  jdbcdrillschemadfstmp  select  castcolumns0  int  c1  testwindowcsv  union  select  columns0  emptydir  error  validation  error  line  1  column  90  line  1  column  98  table  emptydir  found  error  id  58c98bc499df425caa07c8c5faec4748  centos01qalab31010  statecode0  code  solution  overview  resolving  current  issue  drill  query  empty  directory  schemaless  drill  table  user  query  empty  directory  use  query  join  union  union  operator  empty  directory  parquet  metadata  cache  file  schemaless  drill  table  well  work  similar  empty  file  query  star  return  empty  result  field  indicated  select  statement  field  returned  intoptional  type  empty  directory  query  union  operator  change  result  statement  union  absent  query  query  join  return  empty  result  except  case  using  outer  join  clause  outer  table  right  join  derived  table  left  join  data  case  data  nonempty  table  returned  empty  directory  table  used  complex  query  code  change  internally  empty  directory  interprets  dynamicdrilltable  null  selection  schemalessscan  schemalessbatchcreator  schemalessbatch  introduced  used  execution  state  interaction  operator  batch  empty  directory  contain  parquet  metadata  cache  file  parquetgroupscan  table  valid  schemalessscan  used  instead,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
3018,enhance  storageplugin  interface  expose  logical  space  rule  planning  purpose  currently  storageplugins  expose  rule  executed  physical  space  add  interface  method  storageplugin  expose  logical  space  rule  planner,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3019,add  support  hbase  1x  road  map  upgrade  hbase  version  1x  series  currently  drill  support  hbase  098  version,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3020,add  experimental  kudu  plugin  merge  work  done  drill  master  others  utilize  plugin  httpsgithubcomdremiodrillstoragekudu,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3021,adding  support  custom  window  frame  current  implementation  window  function  16  support  default  frame  want  add  support  frame  clause  umbrella  task  track  progress  adding  remaining  frame,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3022,allow  field  name  include  dot  json  data  like  codejavascript  001  version001  datecreated20140315  012  version012  datecreated20140521  code  way  select  row  since  identifier  contain  dot  trying  select  drill  throw  following  error  error  system  error  unsupportedoperationexception  unhandled  field  reference  001  field  reference  identifier  must  form  qualified  name  must  fixed  since  many  json  data  file  containing  dot  key  eg  specifying  version  number  etc,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
3023,kerberos  authentication  drill  support  kerberos  based  authentication  client  mean  odbc  jdbc  driver  well  webrest  interface  support  inbound  kerberos  web  would  likely  spnego  odbc  jdbc  generic  kerberos  since  hive  much  hadoop  support  kerberos  potential  lot  reuse  idea  implementation  note  related  httpsissuesapacheorgjirabrowsedrill3584,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3024,drill  support  inbound  impersonation  today  drill  support  impersonation  external  source  example  authenticate  drill  drill  access  hdfs  using  impersonation  many  scenario  also  need  impersonation  drill  example  might  use  front  end  tool  tableau  authenticate  tool  server  version  need  access  drill  perform  query  want  query  run  tableau  user  theory  intermediate  tool  could  store  userid  password  every  user  drill  isnt  scalable  secure  solution  note  hs2  today  support  inbound  impersonation  described  httpsissuesapacheorgjirabrowsehive5155  best  approach  tied  connection  object  coarse  grained  potentially  expensive  would  better  call  odbcjdbc  driver  switch  identity  existing  connection  modern  sql  database  oracle  db2  support  function,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3025,apache  drill  support  network  encryption  sasl  encryption  drill  client  drillbit  clearly  related  drill291  wanted  make  explicit  need  include  network  level  encryption  authentication  particularly  important  client  connection  drill  often  sending  password  clear  encryption,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
3026,allow  filesystemplugin  subclass  override  formatcreator  filesystemplugin  subclass  able  customize  plugins  formatcreator  created  filesystemplugin  constructor  immediately  used  create  schemafactory  instance  formatcreator  instantiation  moved  protected  method  subclass  choose  implement  differently,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3027,drill  hive  incompatible  timestamp  representation  parquet  gitcommitidabbrev83d460c  created  parquet  file  timestamp  type  using  drill  define  hive  table  top  parquet  file  use  timestamp  column  type  drill  fails  read  hive  table  hive  storage  plugin  implementation  added  int96  timestamp  converter  parquet  reader  controling  system  session  option  storeparquetint96astimestamp  value  option  false  default  proper  work  old  query  script  convertfrom  timestampimpala  function  option  true  using  function  unnesessary  lead  query  fail,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3028,add  support  view  create  drop  select  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3029,implement  text  format  plugin  implement  format  plugin  read  text  file  eg  csv  tsv  able  read  compressed  uncompressed  data  record  reader  return  single  column  type  repeatedvarchar  compression  delimiter  type  determined  file  extension,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3030,improve  current  fragment  parallelization  module  current  fragment  parallelizer  simpleparallelizerjava  can’t  handle  correctly  case  operator  mandatory  scheduling  requirement  set  drillbitendpoints  affinity  drillbitendpoint  ie  much  portion  total  task  scheduled  drillbitendpoint  assumes  scheduling  requirement  soft  except  one  case  mux  demux  case  mandatory  parallelization  requirement  1  unit  example  cluster  3  node  running  drillbits  storage  service  data  table  present  storage  service  two  node  groupscan  need  scheduled  two  node  order  read  data  storage  service  doesnt  support  costly  reading  data  remote  node  inserting  mandatory  scheduling  requirement  within  existing  simpleparallelizer  sufficient  may  end  plan  fragment  two  groupscans  hard  parallelization  requirement  proposal  add  property  operator  tell  parallelization  implementation  use  operator  dont  particular  strategy  project  filter  depend  incoming  operator  current  existing  operator  requirement  existing  groupscans  default  current  parallelizer  simpleparallelizer  screen  default  new  mandatory  assignment  parallelizer  possible  physicalplan  generated  fragment  operator  different  parallelization  strategy  case  exchange  inserted  operator  change  parallelization  strategy  required  send  detailed  design  doc,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3031,specification  ordering  asc  desc  sort  plan  node  us  string  construction  also  allow  use  corresponding  calcite  enums  small  change  provide  cleaner  interface  constructing  sort  configuration  test  current  class  mix  together  two  task  converting  string  chose  put  plan  asc  desc  calcite  enums  well  validating  allowed  value  calcite  several  value  currently  use  like  strictlyascendingdescending  clustered  break  two  task  apart  allow  construction  directly  enum  still  provide  validation  drill  allowed  value,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3032,create  logical  plan  builder  programmatic  creation  logical  plan  useful  user  generating  logical  plan  within  java  first  consumer  would  likely  sql  parser,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3033,improve  metadata  cache  performance  query  single  partition  consider  two  type  query  run  parquet  metadata  caching  noformat  query  1  select  col  abc  query  2  select  col  dir0  b  dir1  c  noformat  certain  dataset  query1  elapsed  time  1  sec  whereas  query2  elapsed  time  9  sec  even  though  accessing  amount  data  user  expectation  perform  roughly  main  difference  come  reading  bigger  metadata  cache  file  root  level  query2  applying  partitioning  filter  query1  read  much  smaller  metadata  cache  file  subdirectory  level,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3034,add  support  truncation  unit  datetrunc  function  currently  support  year  month  day  hour  minute  second  truncate  unit  type  time  timestamp  date  extend  function  support  year  month  day  hour  minute  second  week  quarter  decade  century  millennium  truncate  unit  type  time  timestamp  date  interval  day  interval  year  also  get  rid  ifandelse  truncation  unit  implementation  instead  resolve  direct  function  based  truncation  unit  calcite  drill  drilloptiq  expression  conversion,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3035,improve  performance  query  informationschema  hive  plugged  query  code  select  informationschematables  code  converted  call  fetch  table  storage  plugins  user  hive  call  hive  metadata  storage  would  1  gettable  2  getpartitions  however  information  regarding  partition  used  type  query  beside  efficient  way  fetch  table  use  getmultitable  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3036,generate  warning  web  ui  drillbits  version  mismatch  detected  display  drillbit  version  web  ui  drillbits  version  doesnt  match  current  drillbit  generate  warning  screenshots  newmatchingdrillbitsjpg  newmismatchingdrillbitsjpg,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3037,expose  new  system  metric  add  metric  drillmetrics  registry  exposed  web  ui  jconsole  jmx  pending  query  running  query  completed  query  current  memory  usage  root  allocator  clean  document  metric  registration  api  deprecate  getmetrics  method  contextual  object  use  drillmetricsgetregistry  directly  make  jmx  reporting  log  reporting  configurable  system  property  since  config  file  meant  used  common  module,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3038,allow  casting  boolean  literal  postgre  drill  return  result  try  cast  0  1  boolean  inside  value  constructor  drill  version  170snapshot  commit  id  09b26277  noformat  0  jdbcdrillschemadfstmp  valuescast1  boolean  error  system  error  illegalargumentexception  invalid  value  boolean  1  fragment  00  error  id  35dcc4bb0c5d466f8fb5cf7f0a892155  centos02qalab31010  statecode0  0  jdbcdrillschemadfstmp  valuescast0  boolean  error  system  error  illegalargumentexception  invalid  value  boolean  0  fragment  00  error  id  2dbcafe292c7475ea2aa9745ef72c1cc  centos02qalab31010  statecode0  noformat  get  result  postgres  query  noformat  postgres  valuescast1  boolean  column1  1  row  postgres  valuescast0  boolean  column1  f  1  row  noformat  stack  trace  drillbitlog  noformat  20160513  071616578  28ca80bf0af9bc05258b6b5744739ed8frag00  error  oadewfragmentfragmentexecutor  system  error  illegalargumentexception  invalid  value  boolean  0  fragment  00  error  id  2dbcafe292c7475ea2aa9745ef72c1cc  centos02qalab31010  orgapachedrillcommonexceptionsuserexception  system  error  illegalargumentexception  invalid  value  boolean  0  fragment  00  error  id  2dbcafe292c7475ea2aa9745ef72c1cc  centos02qalab31010  orgapachedrillcommonexceptionsuserexceptionbuilderbuilduserexceptionjava543  drillcommon170snapshotjar170snapshot  orgapachedrillexecworkfragmentfragmentexecutorsendfinalstatefragmentexecutorjava318  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecworkfragmentfragmentexecutorcleanupfragmentexecutorjava185  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecworkfragmentfragmentexecutorrunfragmentexecutorjava287  drilljavaexec170snapshotjar170snapshot  orgapachedrillcommonselfcleaningrunnablerunselfcleaningrunnablejava38  drillcommon170snapshotjar170snapshot  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1145  na17045  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava615  na17045  javalangthreadrunthreadjava744  na17045  caused  javalangillegalargumentexception  invalid  value  boolean  0  orgapachedrillexectestgeneratedprojectorgen9dosetupprojectortemplatejava95  nana  orgapachedrillexectestgeneratedprojectorgen9setupprojectortemplatejava93  nana  orgapachedrillexecphysicalimplprojectprojectrecordbatchsetupnewschemaprojectrecordbatchjava444  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecrecordabstractsinglerecordbatchinnernextabstractsinglerecordbatchjava78  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecphysicalimplprojectprojectrecordbatchinnernextprojectrecordbatchjava129  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecrecordabstractrecordbatchnextabstractrecordbatchjava162  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecphysicalimplbaserootexecnextbaserootexecjava104  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecphysicalimplscreencreatorscreenrootinnernextscreencreatorjava81  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecphysicalimplbaserootexecnextbaserootexecjava94  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecworkfragmentfragmentexecutor1runfragmentexecutorjava257  drilljavaexec170snapshotjar170snapshot  orgapachedrillexecworkfragmentfragmentexecutor1runfragmentexecutorjava251  drilljavaexec170snapshotjar170snapshot  javasecurityaccesscontrollerdoprivilegednative  method  na17045  javaxsecurityauthsubjectdoassubjectjava415  na17045  orgapachehadoopsecurityusergroupinformationdoasusergroupinformationjava1595  hadoopcommon270mapr1602jarna  orgapachedrillexecworkfragmentfragmentexecutorrunfragmentexecutorjava251  drilljavaexec170snapshotjar170snapshot  4  common  frame  omitted  noformat  implementation  added  support  allow  casting  list  string  postgres  httpswwwpostgresqlorgdocs96staticdatatypebooleanhtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3039,dynamic  udfs  support  allow  register  udfs  without  restart  drillbits  design  described  document  httpsdocsgooglecomdocumentd1ffyjtwae5tluyhehcfldyupcdeiezr2rlnsrotyyab4edituspsharing  gist  httpsgistgithubcomarinaielchiievaa1c4cfa3890145c5ecb1b70a39cbff55filedynamicudfssupportmd,1,0,1,0,1,0,0,1,0,0,0,0,1,0,0,0,0
3040,fragmentexecutor  use  eventprocessor  avoid  blocking  rpc  thread  currently  rpc  thread  block  trying  deliver  cancel  early  termination  message  blocked  fragment  executor  foreman  already  us  eventprocessor  avoid  scenario  fragmentexecutor  could  improved  avoid  blocking  rpc  thread  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3041,improve  metadata  cache  performance  query  multiple  partition  consider  query  following  type  run  parquet  data  metadata  caching  noformat  select  col  dir0  b  dir1  1  2  3  noformat  query  drill  read  metadata  cache  file  top  level  directory  efficient  since  interested  file  subdirectory  b  drill4530  improves  performance  query  leaf  level  directory  single  partition  3  subpartitions  due  list  build  upon  drill4530  enhancement  least  reading  cache  file  immediate  parent  level  ab  instead  top  level  goal  jira  improve  performance  type  query,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3042,improve  parquet  reader  performance  reported  user  field  generally  getting  read  speed  100150  mbsnode  parquet  scan  operator  seems  little  low  given  number  drive  node  24  looking  option  improve  performance  operator  query  io  bound,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3043,add  support  null  equality  join  join  equality  condition  allows  nullnull  fails  example  use  query  codesql  select  t1  t2  t1c1  t2c2  t1c1  null  t2c2  null  select  t1  inner  join  t2  t1c1  t2c2  t1c1  null  t2c2  null  code  got  unsupportedoperation  error  add  support  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3044,allow  drillbits  advertise  configurable  host  address  zookeeper  certain  situation  running  drill  distributed  docker  container  desirable  advertise  different  hostname  zookeeper  would  output  inetaddressgetlocalhost  propose  adding  configuration  variable  drillexecrpcbitadvertisedhost  passing  address  zookeeper  configuration  variable  populated  otherwise  falling  back  present  behavior,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3045,support  storage  plugin  optimizer  rule  example  hbase  storage  plugin  could  add  rule  would  transform  hbase  scan  followed  qualified  filter  operation  hbase  scan  hbase  filter  pushed  directly  scan  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3046,temporary  table  support  link  design  doc  httpsdocsgooglecomdocumentd1gsrow6q2wr5fpx7ssq5iavmjxj6xcojfygyqpvocgedit  gist  httpsgistgithubcomarinaielchiieva50158175867a18eee964b5ba36455fbffiletemporarytablessupportmd,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3047,function  return  unique  id  per  sessionconnection  similar  mysqls  connectionid  design  implement  function  return  unique  id  per  sessionconnection  similar  mysqls  connectionid  implementation  detail  function  sessionid  added  function  return  current  session  unique  id  represented  string  parameter  codejava  boolean  isniladiccode  added  udf  functiontemplate  indicate  function  niladic  function  called  without  parameter  parenthesis  please  note  function  override  column  name  table  alias  used  retrieve  column  value  table  example  codesqlselect  sessionid  table  return  value  niladic  function  sessionid  code  codesqlselect  t1sessionid  table  t1  return  sessionid  column  value  table  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
3048,option  debug  generated  java  code  using  ide  drill  make  extensive  use  java  code  generation  implement  operator  drill  us  sophisticated  technique  blend  generated  code  precompiled  template  code  unfortunate  sideeffect  behavior  difficult  visualize  debug  generated  code  turn  drill  codemerge  facility  essence  doityourself  version  subclassing  drill  template  parent  class  generated  code  subclass  rather  using  plainold  subclassing  drill  combine  code  two  class  single  artificial  packet  byte  code  source  exists  modify  code  generation  path  optionally  allow  plainold  java  compilation  generated  code  subclass  template  compile  generated  code  plainold  java  class  bytecode  fixup  write  code  known  location  ide  search  looking  source  file  change  developer  turn  feature  set  breakpoint  template  step  directly  generated  java  code  called  template  feature  option  enabled  developer  needed  existing  bytecode  technique  used  production  code  generation,1,0,1,0,1,0,0,0,1,1,0,0,0,0,0,0,1
3049,skip  initializing  enabled  storage  plugins  every  query  query  lifecycle  attempt  made  initialize  enabled  storage  plugin  building  schema  tree  done  regardless  actual  plugins  involved  within  query  sometimes  one  enabled  storage  plugins  issue  either  due  misconfiguration  underlying  datasource  slow  overall  query  time  taken  increase  drastically  likely  due  attempt  made  register  schema  faulty  plugin  example  jdbc  plugin  configured  sql  server  one  point  underlying  sql  server  db  go  drill  query  starting  execute  point  beyond  begin  slow  drastically  must  skip  registering  unrelated  schema  workspace  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3050,enable  generated  code  debugging  drill  operator  drill5052  add  ability  debug  generated  code  code  generated  drill  operator  minor  problem  compiled  directly  using  new  technique  issue  ignore  bytecodemerge  technique  us  production  ticket  asks  try  drill5052  feature  operator  clean  minor  problem  ensure  operator  generates  code  suitable  debugging  use  new  codegeneratorplainoldjavacapable  method  mark  generated  class  ready  plainold  java  code  gen  advantage  feature  two  1  ability  step  generated  code  increase  understanding  existing  operator  ease  development  improvement  existing  operator  new  operator  choose  create  2  open  door  experimenting  improve  performance  generated  code,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
3051,provide  simplified  unified  cluster  fixture  test  drill  provides  robust  selection  test  framework  evolved  satisfy  need  variety  test  case  newbie  however  result  bewildering  array  way  basically  thing  set  embedded  drill  cluster  run  query  check  result  key  test  setting  distributed  pomxml  file  config  file  stored  resource  hardcoded  setting  base  test  class  also  test  base  class  helpfully  set  test  cluster  individual  test  need  different  config  immediately  tear  default  cluster  create  new  one  ticket  proposes  new  test  framework  available  new  test  combine  best  existing  test  framework  single  easytouse  package  builder  cluster  accept  configtime  option  accept  runtime  session  system  option  specify  number  drillbits  simplified  api  common  option  autocloseable  use  trywithresources  statement  integration  existing  test  builder  class,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
3052,enhance  mock  data  source  better  data  sql  access  drill  provides  mock  data  storage  engine  generates  random  data  mock  engine  used  older  unit  test  need  volume  data  particular  detail  data  mock  data  source  continues  use  even  modern  test  example  work  external  storage  batch  requires  test  varying  amount  data  exact  form  data  important  quantity  example  want  ensure  spilling  happens  various  trigger  point  need  read  right  amount  data  trigger  existing  mock  data  source  two  limitation  1  generates  blackwhite  alternating  value  awkward  use  sorting  2  mock  generator  accessible  physical  plan  sql  query  enhancement  proposes  fix  limitation  1  generate  uniform  randomly  distributed  set  value  2  provide  encoding  let  sql  query  specify  data  generated  example  sql  query  code  select  idi  names50  mockemployee10k  code  say  generate  two  field  integer  suffix  varchar50  s50  suffix  generate  10000  row  10k  suffix  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3053,publish  operator  majorfragment  stats  profile  page  currently  show  runtimes  major  fragment  minmaxavg  time  setup  processing  waiting  various  operator  would  worthwhile  additional  stats  following  majorfragment  busy  active  time  minor  fragment  within  major  fragment  busy  operator  profile  busy  active  time  fragment  within  operator  busy  record  total  number  record  propagated  operator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3054,unit  test  fail  due  cttas  temporary  name  space  check  drill  operate  embedded  mode  mode  storage  plugin  definition  default  may  present  particular  using  drill  test  framework  storage  plugins  defined  drill  code  available  yet  drill  check  existence  dfstmp  plugin  definition  named  drillexecdefaulttemporaryworkspace  parameter  plugin  defined  exception  occurs  code  orgapachedrillcommonexceptionsuserexception  parse  error  unable  create  drop  tablesviews  schema  dfstmp  immutable  error  id  792d4e5d3f314f388bb4d108f1a808f6  orgapachedrillcommonexceptionsuserexceptionbuilderbuilduserexceptionjava544  orgapachedrillexecplannersqlschemautilitesresolvetomutabledrillschemaschemautilitesjava184  orgapachedrillexecplannersqlschemautilitesgettemporaryworkspaceschemautilitesjava201  orgapachedrillexecserverdrillbitvalidatetemporaryworkspacedrillbitjava264  orgapachedrillexecserverdrillbitrundrillbitjava135  orgapachedrilltestclusterfixturestartdrillbitsclusterfixturejava207  code  expected  either  configuration  would  exist  would  use  default  tmpdrill  location  check  drilltmp  would  deferred  actually  required  executing  cttas  statement  seemed  test  framework  must  altered  work  around  problem  defining  necessary  workspace  unfortunately  drillbit  must  start  define  workspace  needed  drillbit  start  workaround  possible  user  embedded  drillbit  may  know  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3055,allow  extended  mock  table  access  sql  query  drill5152  provided  simple  way  generate  sample  data  sql  using  new  simplified  version  mock  data  generator  approach  convenient  inherently  limited  example  limited  syntax  available  sql  encoding  much  information  column  repeat  count  data  generator  simple  sql  approach  allow  generating  multiple  group  data  however  feature  present  original  mock  data  source  via  special  json  configuration  file  previously  physical  plan  could  access  extended  syntax  ticket  request  sql  interface  extended  mock  data  source  code  select  mockexamplemockoptionsjson  code  mock  data  source  option  always  stored  json  file  since  existing  mock  data  generator  sql  never  us  json  file  simple  rule  table  name  end  json  specification  else  information  encoded  table  column  name  format  data  generation  syntax  documented  mock  data  source  class,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0
3056,refinement  new  cluster  fixture  test  framework  rollup  number  enhancement  cluster  fixture  framework  config  option  suppress  printing  csv  output  allows  printing  single  test  printing  running  maven  parsing  query  profile  extract  plan  run  time  information  fix  bug  log  fixture  enabling  logging  package  improved  zk  support  set  new  cttas  default  temporary  workspace  test  revise  testdrillbitresiliance  use  new  framework  revise  testwindowframe  use  new  framework  revise  testmergejoinwithschemachanges  use  new  framework,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
3057,add  server  metadata  api  jdbc  odbc  client  expose  lot  metadata  regarding  server  version  support  various  part  sql  standard  currently  returned  information  hardcoded  clientsdrivers  mean  infomation  returned  support  client  version  server  version  instead  new  method  provided  client  query  actual  server  support  support  client  server  optional  example  client  use  api  server  doesnt  support  fallback  default  value,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
3058,create  suboperator  test  framework  drill  provides  two  unit  test  framework  wholeserver  sqlbased  testing  original  basetestquery  newer  clusterfixture  use  testbuilder  mechanism  build  systemlevel  functional  test  run  query  check  result  jason  provided  operatorlevel  test  framework  based  part  mock  drill  operator  become  complex  cry  need  true  unitlevel  test  level  whole  system  operator  need  test  individual  piece  together  form  operator  umbrella  ticket  includes  number  task  needed  create  suboperator  framework  intention  time  find  need  revisit  existing  operator  create  new  one  employ  suboperator  test  framework  exercise  code  finer  granularity  possible  prior  framework,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,0
3059,implement  suboperator  unit  test  managed  external  sort  validate  proposed  suboperator  test  framework  creating  lowlevel  unit  test  managed  version  external  sort  external  sort  small  number  existing  test  test  quite  superficial  managed  sort  project  found  many  bug  managed  sort  tested  adhoc  systemlevel  test  created  using  new  cluster  fixture  framework  test  could  reach  deep  inside  sort  code  exercise  specific  condition  result  spent  far  much  time  using  qa  functional  test  identify  specific  code  issue  using  subopeator  unit  test  framework  instead  test  bit  functionality  unit  test  level  work  practical  serve  model  operator  testing  project,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
3060,extend  test  framework  profile  parser  printer  multifragment  query  recently  added  test  framework  tool  called  profileparser  started  tool  analyzing  run  time  singlefragment  query  time  evolved  compare  planned  actual  cost  multifragment  query  ticket  request  multifagment  support  added  printing  run  time  query  singlethread  print  query  prior  version  code  op  0  screen  setup  0  0  0  process  35  0  0  wait  16  memory  10  op  1  project  setup  22  1  0  process  41  0  0  memory  5  code  query  multifragment  form  tree  use  format  used  display  planning  v  actual  info  code  0309  project  setup  0  m  0  0  process  0  m  0  0  0310  hashjoin  hash  join  setup  0  m  0  0  process  5097619  m  326770  73  0312  project  setup  36  m  2  0  process  180  m  11  0  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
3061,refactor  parquet  record  reader  parquet  record  reader  class  key  part  drill  evolved  time  become  somewhat  hard  follow  number  u  working  parquetrelated  task  find  spend  uncomfortable  amount  time  trying  understand  code  particular  writer  need  figure  convince  reader  provide  higherdensity  record  batch  rather  continue  decypher  complex  code  multiple  time  ticket  request  refactor  code  make  functionally  identical  structurally  cleaner  result  faster  time  value  working  code  lowerpriority  change  coordinated  others  working  code  base  ticket  record  reader  class  include  various  reader  writer  parquet  us  since  another  project  actively  modifying  class,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
3062,refactor  scanbatch  allow  unit  testing  record  reader  recent  set  pr  refactored  context  code  allow  easier  unit  testing  operator  internals  recent  attempt  help  community  user  revealed  would  helpful  refactor  part  scanbatch  operatorcontext  allow  unit  testing  reader  code  particular  make  scanbatchmutator  static  class  created  unit  test  separate  scanbatch  rest  drill  split  operatorcontext  executiononly  operatorexeccontext  interface  used  testing  leave  operatorcontext  method  require  drill  present  requires  bit  implementation  work  change  operatorcontext  abstract  class  interface  extend  operatorexcecontext  operatorcontext  appears  class  hold  static  method  java  8  allows  static  method  interface  drill  us  java  7  support  move  method  new  operatorutilities  class  fix  reference  split  operatorcontextimpl  class  two  part  move  new  abstractoperatorcontext  class  code  implement  lowlevel  runtime  method  leave  original  class  functionality  depends  rest  drill  reference  drillbitcontext  add  method  new  operatorfixture  class  create  testtime  version  operatorexeccontext  interface,1,0,1,0,1,0,0,0,1,0,1,1,1,0,0,0,0
3063,support  http  kerberos  auth  using  spnego  drill4280  support  kerberos  jdbc  odbc  api  ticket  request  add  kerberos  using  spengohttpsenwikipediaorgwikispnego  http  connection  requires  creating  direct  web  session  currently  web  session  session  java  client  session,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
3064,support  spill  disk  hash  aggregate  operator  support  gradual  spilling  memory  disk  available  memory  get  small  allow  memory  work  hash  aggregate  operator,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
3065,extend  physical  operator  test  framework  test  mini  plan  consisting  multiple  operator  drill4437  introduced  unit  test  framework  test  nonscan  physical  operator  json  reader  implicitly  used  specify  input  physical  operator  test  need  extend  unit  test  framework  two  scenario  1  need  way  test  scan  operator  different  record  reader  drill  support  variety  data  source  important  make  sure  every  record  reader  work  properly  according  protocol  defined  2  need  way  test  socalled  miniplan  aka  plan  fragment  consisting  multiple  nonscan  operator  2nd  need  alternative  leverage  sql  statement  query  planner  however  approach  direct  dependency  query  planner  1  planner  change  may  impact  testcase  lead  different  plan  2  always  easy  job  force  planner  get  desired  plan  fragment  testing  particular  would  good  relatively  easy  way  specify  miniplan  couple  targeted  physical  operator  jira  created  track  work  extend  unit  test  framework  drill4437  related  work  drill5318  introduced  suboperator  test  fixture  mainly  targeted  test  suboperator  level  framework  drill4437  extension  would  focus  operator  level  multiple  operator  level  execution  would  go  recordbatchs  api  call  drill4437  going  use  mockit  mock  required  object  fragment  context  operator  context  etc,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3066,remove  webserver  dependency  drillclient  encryption  support  using  sasl  client  wont  able  authenticate  using  plain  mechanism  encryption  enabled  cluster  today  webserver  embedded  inside  drillbit  creates  drillclient  instance  webclient  session  webuser  authenticated  part  authentication  drillclient  instance  drillbit  using  plain  mechanism  encryption  enabled  fail  since  encryption  doesnt  support  authentication  using  plan  mechanism  hence  webclient  connect  drillbit  issue  well  approach  1  since  drillclient  used  per  webuser  session  expensive  heavyweight  rpc  layer  drillclient  dependency  2  foreman  webuser  also  selected  different  node  extra  hop  transferring  data  back  webclient  resolve  issue  would  better  authenticate  webuser  locally  using  drillbit  webserver  running  without  creating  drillclient  instance  use  local  pamauthenticator  authenticate  user  authentication  successful  local  drillbit  also  serve  foreman  query  submitted  webuser  achieved  submitting  query  local  drillbit  foreman  work  queue  also  remove  requirement  encrypt  channel  opened  webserver  drillclient  selected  drillbit  since  approach  wont  physical  channel  opened,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0
3067,implement  function  date  interval  data  type  list  function  supported  part  task  date  interval  arithmetic  function  date  integer  date  interval  time  interval  timestamp  interval  timestamptz  interval  date  intervalday  time  intervalday  timestamp  intervalday  timestamptz  intervalday  date  intervalyear  time  intervalyear  timestamp  intervalyear  timestamptz  intervalyear  date  time  date  date  time  time  timestamp  timestamp  timestamptz  timestamptz  interval  interval  intervalday  intervalday  intervalyear  intervalyear  interval  div  integer  float  double  intervalday  div  integer  float  double  intervalyear  div  integer  float  double  interval  intervalday  intervalyear  date  utility  function  currentdate  currenttime  currenttimestamp  localtime  localtimestamp  timeofday  clocktimestamp  function  text  parameter  one  following  year  month  day  hour  minute  second  dateparttext  date  dateparttext  time  dateparttext  timestamp  dateparttext  timestamptz  dateparttext  interval  dateparttext  intervalday  dateparttext  intervalyear  extract  function  similar  datepart  extractfield  date  extractfield  time  extractfield  timestamp  extractfield  timestamptz  extractfield  interval  extractfield  intervalday  extractfield  intervalyear  date  formatting  function  text  parameter  represents  desired  output  format  tochardate  text  tochartime  text  tochartimestamp  text  tochartimestamptz  text  function  first  text  param  represents  string  converted  date  type  second  text  param  represents  format  todatetext  text  totimetext  text  totimestamptext  text  totimestamptztext  text  input  long  millisecond  epoch  todatelong  totimelong  totimestamplong  totimestamptzlong,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
3068,limit  memory  usage  hbase  reader  early  limit  0  optimization  set  true  alter  session  set  plannerenablelimit0optimization  true  executing  limit  0  query  drill  return  data  type  available  metadata  possible  drill  determine  data  type  metadata  early  limit  0  optimization  set  false  drill  read  first  batch  data  determine  schema  hbase  reader  determines  max  batch  size  using  magic  number  4000  lead  oom  row  size  large  overall  vectorbatch  size  issue  reconsidered  future  releasesthis  temporary  fix  avoid  oom  limit  memory  usage  hbase  reader  adding  max  allowed  allocated  memory  contant  default  64  mb  thus  batch  size  limited  4000  memory  limit  exceed  number  record  within  max  allowed  memory  limit  first  row  batch  larger  allowed  default  written  batch  batch  contain  row,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3069,rollup  number  test  framework  enhancement  recent  development  work  identified  number  minor  enhancement  suboperator  unit  test  create  suboperatortest  base  class  routine  setup  shutdown  additional  method  simplify  creating  complex  schema  field  width  define  test  workspace  pluginspecific  option  csv  storage  plugin  verifying  row  set  add  method  verify  release  actual  batch  addition  existing  method  verify  free  actual  expected  batch,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1
3070,improve  performance  filter  operator  pattern  matching  query  using  filter  sql  like  operator  use  java  regex  library  pattern  matching  however  case  like  abc  end  abc  abc  start  abc  abc  contains  abc  observed  implementing  case  simple  code  instead  using  regex  library  provides  good  performance  boost  46x  idea  use  special  case  code  simple  common  case  fall  back  java  regex  library  complicated  one  provide  good  performance  benefit  common  case,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3071,predicate  push  hbase  scan  drill494  hbase  storage  plugin  could  transform  hbase  scan  followed  qualified  filter  example  rowkey  equality  single  hbase  scan  operation  hbase  rowkeyfilter  filter,1,1,1,1,1,0,0,0,1,0,1,0,0,0,0,0,0
3072,queuebased  memory  assignment  buffering  operator  apache  drill  already  queueing  feature  based  zk  semaphore  bit  testing  show  feature  fact  work  propose  enhance  feature  light  revision  make  work  managed  external  sort  newlyadded  spilling  feature  hash  agg  operator  key  requirement  build  may  want  tackle  larger  project  create  complete  solution  later  existing  functionality  two  zkbased  queue  called  “small”  “large”  query  queue  threshold  call  given  query  cost  determine  queue  query  go  admit  level  two  queue  call  q  ql  basically  query  come  plan  query  usual  obtain  final  query  cost  planner  call  c  ct  query  go  small  queue  else  go  large  queue  suppose  small  queue  ask  zk  query  run  zk  check  q  query  already  running  query  wait  else  query  run  proposed  change  include  refactor  code  provide  queueing  api  support  variety  queuing  mechanism  provide  three  null  queue  default  inprocess  queue  testing  zk  queue  modify  query  profile  web  ui  show  two  new  bit  information  queue  queue  query  sent  total  planning  cost  modify  query  profile  web  ui  show  two  memory  assignment  number  total  memory  allocated  query  memory  per  sort  hashadd  operator  add  queue  mechanism  ability  memory  assignment  provide  weight  w  every  small  query  get  1  unit  every  large  query  get  w  unit  use  queue  admit  level  determine  total  unit  u  q  w  ql  obtain  total  direct  memory  system  subtract  reserve  percent  r  overhead  math  get  memory  per  query  query  small  queue  r  u  large  queue  r  u  w  use  memory  amount  “memory  per  query”  number  existing  sorthashagg  memory  assignment  instead  fixed  2  gb  result  nice  incremental  addition  already  make  bit  easier  people  actually  use  feature  see  planning  number  see  queue  used  allowing  effectively  tune  system  api  used  feature  also  allow  third  party  add  robust  admission  control  feature  needed  perhaps  tying  existing  queueing  mechanism  choice,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3073,support  systemsession  internal  option  additional  option  system  fix  feature  proposed  benzvi  currently  option  accessible  user  sysoptions  would  like  add  internal  option  altered  visible  sysoptions  table  internal  option  could  seen  another  alias  select  internaloptions  intention  would  put  new  option  werent  comfortable  exposing  end  user  table  option  corresponding  feature  considered  stable  could  changed  appear  sysoption  table  bunch  fix  option  system  clubbed  optionvalidators  longer  hold  default  value  default  value  contained  systemoptionmanager  option  optiondefinition  option  definition  includes  validator  metadata  option  visibility  required  permission  scope  set  option  manager  interface  cleaned  type  required  passed  order  set  delete  option,1,0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,1
3074,support  impersonation  without  authentication  rest  api  today  user  authenticated  via  rest  api  way  provide  user  name  executing  query  default  executed  anonymous  user  doesnt  work  impersonation  without  authentication  enabled  drill  server  side  since  anonymous  user  doesnt  exist  query  fail  need  way  provide  user  name  impersonation  enabled  drill  side  query  executed  rest  api  two  approach  achieve  1  use  formbased  authentication  web  ui  user  prompted  enter  login  session  user  created  user  treated  admin  formbased  authentication  cache  user  information  user  wont  need  set  user  name  time  want  execute  query  log  option  also  available  example  screenshot  login  page  attached  loginpagejpg  programmatic  perspective  user  would  need  first  authenticate  use  cookie  get  query  result  2  use  username  header  request  web  ui  query  page  additional  input  field  appear  user  would  need  enter  user  name  issuing  query  example  screenshot  query  page  attached  querypagewithusernamejpg  hood  user  name  would  added  client  request  request  header  server  side  header  would  used  create  user  session  principal  programmatic  perspective  user  would  need  add  header  issuing  request  two  option  second  chosen  would  ease  rest  api  usage  programmatic  perspective  plus  using  formbased  authentication  may  lead  false  assumption  user  authenticated  reality  true  implementation  detail  second  approach  note  implementation  take  affect  authentication  disabled  impersonation  enabled  mean  freemarker  page  wont  include  j  lib  script  condition  met  client  side  additional  input  field  added  query  page  client  submitting  query  request  would  changed  using  ajax  add  username  header  would  taken  new  input  field  server  side  header  would  used  create  session  principal  provided  user  name  admin  right  user  name  header  provided  null  empty  default  anonymous  principal  used  case  post  request  query  queryjson  post  request  query  queryjson  username  header  required  error  thrown  also  adding  user  name  input  parameter  required  web  ui  user  wont  able  send  request  field  filled  adding  user  name  header  approach  web  ui  enter  user  name  user  name  input  field  query  page  submiiting  query  querypagewithusernamejpg  step  required  sqlline  codedrilllocalhost  n  user1code  curl  code  curl  v  h  contenttype  applicationjson  h  username  user1  querytypesql  query  select  sysversion  httplocalhost8047queryjson  code  java  way  code  string  url  httplocalhost8047queryjson  urlconnection  connection  new  urlurlopenconnection  connectionsetdooutputtrue  trigger  post  connectionaddrequestpropertyusername  user1  connectionsetrequestpropertycontenttype  applicationjson  string  data  querytypesql  query  select  sysversion  try  outputstream  output  connectiongetoutputstream  outputwritedatagetbytesstandardcharsetsutf8name  try  inputstream  response  connectiongetinputstream  string  result  ioutilstostringresponse  systemoutprintlnresult  code  note  apache  httpclient  used  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3075,speed  unit  test  test  split  category  highlevel  category  fast  slow  lowlevel  category  vector  webui  planner  operator  storage  hive  jdbc  kudu  mongo  hbase  test  categorized  travis  build  run  fast  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3076,make  code  generation  topn  operator  modular  test  work  pr  several  pr  batched  together  full  description  work  following  drill5783  unit  test  created  priority  queue  topn  operator  code  generation  class  passed  around  completely  unused  function  registry  reference  place  removed  priority  queue  unused  parameter  method  removed  drill5841  many  many  way  temporary  folder  created  unit  test  unified  way  folder  created  dirtestwatcher  subdirtestwatcher  basedirtestwatcher  unit  test  updated  use  test  watcher  create  temp  directory  target  file  generated  used  context  test  easily  found  consistent  location  change  fix  sporadic  hashagg  test  failure  well  failure  caused  stray  file  tmp  drill5894  dfstest  used  storage  plugin  throughout  unit  test  highly  confusing  use  dfs  instead  misc  general  code  cleanup  many  place  stringformat  used  unnecessarily  test  builder  method  already  use  stringformat  pas  args  cleaned,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,1,1
3077,filter  pushdown  parquet  handle  multi  rowgroup  file  drill1950  implemented  filter  pushdown  parquet  file  case  one  rowgroup  per  parquet  file  case  multiple  rowgroups  per  file  detects  rowgroup  pruned  tell  drillbit  read  whole  file  lead  performance  issue  multiple  rowgroup  per  file  help  handle  partitioned  dataset  still  read  relevant  subset  data  without  ending  file  really  needed  let  say  instance  parquet  file  composed  rg1  rg2  one  column  minmax  rg1  12  minmax  rg2  23  select  file  a3  today  read  whole  file  patch  read  rg2  documentation  support  section  httpsdrillapacheorgdocsparquetfilterpushdown  updated  fix  file  multiple  row  group  supported,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3078,use  often  new  parquet  reader  choice  using  regular  parquet  reader  optimized  one  based  type  column  file  column  read  query  doesnt  matter  increase  little  bit  case  optimized  reader  used  checking  projected  column  simple  optimization  waiting  fast  parquet  reader  handle  complex  structure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3079,provide  option  set  query  memory  percent  total  drill  provides  parameter  set  memory  per  query  static  number  default  2  gb  number  wonderful  setting  default  drillbit  configuration  8  gb  heap  allows  23  concurrent  query  drillbit  memory  increase  default  becomes  bit  constraining  user  change  setting  seldom  addition  provide  option  set  memory  percent  total  memory  allocation  10  say  total  memory  128  gb  query  get  13gb  big  improvement  existing  option  act  floor  query  must  receive  least  much  memory  documentation  new  option  documented  plannermemorypercentperquery  default  005  equivalent  5  disable  feature  set  0  information  found  pull  request  description,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3080,migrate  operatorfixture  use  systemoptionmanager  rather  mock  operatorfixture  provides  structure  testing  individual  operator  suboperator  bit  code  framework  provides  mock  networkfree  serverfree  version  fragment  context  operator  context  part  mock  operatorfixture  provides  mock  version  system  option  manager  provides  simple  testonly  implementation  option  set  recent  major  change  system  option  manager  mock  implementation  drifted  sync  system  option  manager  rather  upgrading  mock  implementation  ticket  asks  use  system  option  manager  directly  configured  zk  file  persistence  option  key  reason  change  system  option  manager  implemented  sophisticated  way  handle  option  default  better  leverage  provide  mock  implementation,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
3081,refactor  simplify  fragment  operator  context  testing  drill  execution  engine  fragment  context  provides  state  fragment  whole  operator  context  provides  state  single  operator  historically  concrete  class  make  generous  reference  drillbit  context  hence  need  full  drill  server  order  operate  drill  historically  made  extensive  use  systemlevel  testing  build  entire  server  fire  query  test  component  time  augmenting  approach  unit  test  ability  test  operator  part  operator  isolation  since  operator  requires  access  operator  fragment  context  fact  context  depend  overall  server  creates  large  barrier  unit  testing  earlier  checkin  started  path  defining  context  interface  different  runtime  testtime  implementation  enable  testing  ticket  asks  refactor  interface  simplifying  operator  context  introducing  interface  fragment  context  new  code  use  new  interface  older  code  continues  use  concrete  implementation  time  operator  enhanced  modified  allow  unitlevel  testing,1,0,0,0,0,0,0,0,1,0,1,1,1,0,0,1,1
3082,improve  parquet  reader  performance  flat  data  type  parquet  reader  key  usecase  drill  jira  attempt  improve  parquet  reader  performance  several  user  reported  parquet  parsing  represents  lion  share  overall  query  execution  track  flat  data  type  nested  dts  might  involve  functional  processing  enhancement  eg  nested  column  seen  document  user  might  want  perform  operation  scoped  document  level  need  span  row  another  jira  created  handle  nested  column  usecase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3083,simple  pattern  matcher  work  drillbuf  directly  4  simple  pattern  ie  startswith  endswith  contains  constant  need  overhead  charsequencewrapper  work  drillbuf  directly  save  u  isascii  check  utf8  decoding  row  utf8  encoding  ensures  utf8  character  prefix  valid  character  instead  decoding  varchar  row  processing  encode  patternstring  setup  raw  byte  comparison  instead  bound  checking  reading  one  byte  time  get  whole  buffer  one  shot  use  comparison  improved  overall  performance  filter  operator  around  20,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
3084,avoid  strong  check  introduced  drill5582  plain  mechanism  plain  mechanism  weaken  strong  check  introduced  drill5582  keep  forward  compatibility  drill  112  client  drill  19  server  fine  since  without  strong  check  plain  mechanism  still  vulnerable  mitm  handshake  unlike  mutual  authentication  protocol  like  kerberos  also  keeping  forward  compatibility  respect  sasl  treat  unknownsaslsupport  valid  value  handshake  message  received  client  running  later  version  let  say  113  drillbit  112  new  value  saslsupport  field  unknown  server  field  decoded  unknownsaslsupport  scenario  client  treated  one  aware  sasl  protocol  server  doesnt  know  exact  capability  client  hence  sasl  handshake  still  required  server  side,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3085,implement  create  table  exists  currently  tableview  name  exists  create  table  fails  validation  error  exists  support  create  table  ensure  query  succeeds  also  functionality  added  view,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3086,predicate  pushdown  support  kafkamsgoffset  part  kafka  storage  plugin  review  suggestion  paul  noformat  make  sense  provide  way  select  range  message  starting  point  count  perhaps  want  run  query  every  five  minute  scanning  message  since  previous  scan  want  limit  take  say  next  1000  message  could  use  pseudocolumn  kafkamsgoffset  purpose  maybe  select  topic  kafkamsgoffset  12345  noformat,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3087,updating  apache  mapr  hive  library  232  211mapr1710  version  respectively  currently  drill  us  hive  version  121  librarieshttpsgithubcomapachedrillblobmasterpomxmll53  perform  query  hive  version  library  used  hive1x  version  hive2x  version  feature  hive2x  broken  example  using  orc  transactional  table  fix  good  update  drillhive  library  version  21  newer  task  done  resolving  dependency  conflict  investigating  backward  compatibility  newer  drillhive  library  older  hive  version  1x  updating  drillhive  version  maprhttpsgithubcomapachedrillblobmasterpomxmll1777  profile  starting  commit  drill  hive  client  updated  232  211mapr1710  version  default  mapr  profile  respectively  drill  support  querying  hive  transactional  orc  bucketed  table  httpscwikiapacheorgconfluencedisplayhivehivetransactions  note  updated  drill  hive  client  preserve  backward  compatibility  older  121  hive  servermetastore  version,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3088,improve  performance  copier  used  sv  remover  top  n  etc  currently  copier  copy  record  incoming  batch  beginning  outgoing  batch  need  able  copy  record  append  end  outgoing  batch  also  paul  generic  copier  performant  simpler  added,1,0,1,0,1,0,0,0,0,0,1,1,0,0,0,0,1
3089,avoid  memory  copy  direct  buffer  heap  spilling  local  disk  spilling  local  disk  file  system  support  writablebytechannel  preferable  avoid  copy  offheap  java  heap  writablebytechannel  work  directly  offheap  memory,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3090,direct  buffer  bound  checking  disabled  default  direct  buffer  bound  checking  enabled  either  assertion  enabled  see  drill6001  drillenableunsafememoryaccess  property  set  true  enabled  production  default  drillenableunsafememoryaccess  set,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3091,implement  spill  disk  hash  join  implement  spill  memory  disk  needed  feature  hash  join  operator  similar  prior  work  hash  aggregate  design  draft  document  published  httpsdocsgooglecomdocumentd1cogqy4e5d58qjyvzc7ka834hsab3wdqwqkcmosaiedituspsharing  functional  spec  available  httpsdocsgooglecomdocumentd1bpaddvcrxkhxi2rjquvisiwxnqldbrzzt9cwmanh4h0edit,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,1,1
3092,allow  splitting  generated  code  chainedhashtable  block  avoid  code  large  error  allow  splitting  generated  code  chainedhashtable  block  avoid  code  large  error  reproduce  file  1200columnscsv  noformat  01231200  01231200  noformat  query  noformat  select  columns0  column1columns1200  dfs1200columnscsv  union  select  columns0  column1columns1200  dfs1200columnscsv  noformat  error  noformat  error  system  error  compileexception  file  orgapachedrillexeccompiledrilljavafileobjecthashtablegen10java  line  7886  column  24  hashtablegen10java57650  error  code  large  public  boolean  iskeymatchinternalbuildint  incomingrowidx  int  htrowidx  compilererrlimitcode  noformat  root  cause  drill4715  added  ability  ensure  method  size  wont  go  beyond  64k  limit  imposed  jvm  blkcreatemodetrueifbound  added  create  new  block  expression  added  hit  upperbound  defined  execjavacompilerexpinmethodsize  number  expression  method  hit  upper  bound  create  call  inner  method  example  noformat  public  void  dosetuprecordbatch  incomingbuild  recordbatch  incomingprobe  throw  schemachangeexception  logic  return  dosetup0incomingbuild  incomingprobe  noformat  code  generation  chainedhashtable  added  code  method  one  block  using  blkcreatemodefalse  since  gethashbuild  gethashprobe  method  contained  state  thus  could  split  method  hash  generated  key  expression  first  key  seed  0  subsequent  key  hash  generated  based  seed  previous  key  allow  splitting  method  following  done  1  method  signature  changed  added  new  parameter  seedvalue  initially  starting  seed  value  hardcoded  code  generation  set  0  passed  method  parameter  2  initially  hash  function  call  key  transformed  one  logical  expression  allow  splitting  create  logical  expression  key  thus  splitting  possible  new  seedvalue  parameter  used  seed  holder  pas  seed  value  next  key  3  parameterexpression  added  generate  reference  method  parameter  code  generation  code  example  noformat  public  int  gethashbuildint  incomingrowidx  int  seedvalue  throw  schemachangeexception  nullablevarcharholder  out3  new  nullablevarcharholder  out3  isset  vv0  getaccessorissetincomingrowidx  out3  isset  1  out3  buffer  vv0  getbuffer  long  startend  vv0  getaccessorgetstartendincomingrowidx  out3  start  int  startend  out3  end  intstartend  32  intholder  seedvalue4  new  intholder  seedvalue4  value  seedvalue  start  eval  portion  hash32  function  intholder  out5  new  intholder  final  intholder  new  intholder  nullablevarcharholder  out3  intholder  seed  seedvalue4  hash32functionswithseednullablevarcharhasheval  inisset  0  outvalue  seedvalue  else  outvalue  orgapachedrillexecexprfnimplhashhelperhash32instart  inend  inbuffer  seedvalue  out5  end  eval  portion  hash32  function  seedvalue  out5  value  return  gethashbuild0incomingrowidx  seedvalue  noformat  example  code  generation  hashtablegen5for40columnsbeforejava  code  compiles  hashtablegen5for40columnsafterjava  code  compiles  hashtablegen5for1200columnsbeforejava  error  compilation  method  large  hashtablegen5for1200columnsafterjava  code  compiles  since  method  split,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3093,avoid  excessive  locking  localpersistentstore  query  profile  written  localpersistentstore  write  unnecessary  serialized  due  readwrite  lock  introduced  versioned  persistentstore  versioned  access  need  protected  readwrite  lock,1,1,1,1,1,0,1,0,1,0,1,0,0,0,0,0,0
3094,validate  planner  assume  hashjoin  preserve  ordering  f  maprdb  hive  explanation  provided  boaz  explained  design  document  new  automatic  spill  feature  hashjoin  operator  may  cause  spilling  occurs  row  leftprobe  side  returned  different  order  incoming  order  due  splitting  row  partition  currently  drill  planner  assumes  leftorder  preserved  hashjoin  operator  therefore  change  query  relying  order  may  return  wrong  result  hashjoin  spill  fix  needed  option  ordered  simpler  complex  change  order  rule  planner  thus  whenever  order  needed  downstream  hashjoin  planner  would  add  sort  operator  would  big  execution  time  waste  planner  need  leftorder  hashjoin  may  ass  size  rightbuild  side  need  statistic  right  side  small  enough  planner  would  set  option  runtime  avoid  spilling  hence  preserving  leftside  order  case  spilling  becomes  necessary  code  would  return  error  possibly  message  suggesting  setting  special  option  retrying  special  option  would  add  sort  operator  allow  hashjoin  spill  generating  code  fragment  hashjoin  leftorder  maintained  codegen  time  check  hashjoin  spilled  add  sort  operator  nothing  like  exists  drill  may  complicated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3095,complete  internal  metadata  layer  improved  batch  handling  slice  batch  handling  projecthttpsgithubcompaulrogersdrillwikibatchhandlingupgrades  includes  enhancement  internal  metadata  system,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
3096,singlemergeexchange  scaling  many  minor  fragment  allocated  query  singlemergeexchange  created  global  order  required  output  following  query  produce  singlemergeexchange  codejava  0  jdbcdrillzklocal  explain  plan  select  llinenumber  dfsdrilltableslineitem  order  llinenumber  text  json  0000  screen  0001  projectllinenumber0  0002  singlemergeexchangesort00  0101  selectionvectorremover  0102  sortsort00  dir0asc  0103  hashtorandomexchangedist00  0201  scantabledfs  drilltableslineitem  groupscanjsontablegroupscan  scanspecjsonscanspec  tablenamemaprfsdrilltableslineitem  conditionnull  columnsllinenumber  maxwidth15  code  10  node  cluster  table  huge  drill  spawn  many  minor  fragment  merged  single  node  one  merge  receiver  create  lot  memory  pressure  receiver  node  also  execution  bottleneck  address  issue  merge  receiver  multiphase  merge  receiver  ideally  large  cluster  one  introduce  tree  merges  merging  done  parallel  first  step  think  better  use  existing  infrastructure  multiplexing  operator  generate  orderedmux  minor  fragment  pertaining  one  drillbit  merged  merged  data  sent  across  receiver  operator  10  node  cluster  node  process  14  minor  fragment  current  version  code  merges  140  minor  fragment  proposed  version  two  level  merges  1  14  merge  drillbit  parallel  10  minorfragments  merged  receiver  node,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
3097,handle  item  star  column  project  filter  push  directory  pruning  project  push  filter  push  partition  pruning  work  dynamically  expanded  column  represented  star  item  operator  item0  columnname  0  star  often  occurs  view  subselect  cte  star  issued  solve  issue  create  drillfilteritemstarrewriterrule  rewrite  item  operator  filter  push  directory  pruning  project  scan  push  logic  handled  separately  already  existing  rule  drillpushprojectintoscanrule  basically  consider  following  query  select  col1  select  col1  select  use  case  since  item  star  column  considered  project  filter  push  directory  pruning  push  pruning  happen  causing  drill  read  column  file  several  needed  ready  file  instead  view  star  query  common  example  behavior  significantly  degrades  performance  item  star  query  comparing  query  without  item  star  example  data  set  create  table  three  file  dedicated  subfolder  noformat  use  dfstmp  create  table  orderctast1  select  castoorderdate  date  oorderdate  cptpchordersparquet  oorderdate  date  19920101  date  19920103  create  table  orderctast2  select  castoorderdate  date  oorderdate  cptpchordersparquet  oorderdate  date  19920104  date  19920106  create  table  orderctast3  select  castoorderdate  date  oorderdate  cptpchordersparquet  oorderdate  date  19920107  date  19920109  noformat  filter  push  select  orderctas  oorderdate  date  19920101  read  one  file  noformat  0000  screen  0001  project0  0002  projectt1¦¦0  0003  selectionvectorremover  0004  filtercondition1  19920101  0005  projectt1¦¦0  oorderdate1  0006  scangroupscanparquetgroupscan  entriesreadentrywithpath  pathtmporderctast1000parquet  selectionroottmporderctas  numfiles1  numrowgroups1  usedmetadatafilefalse  column  noformat  select  select  orderctas  oorderdate  date  19920101  ready  three  file  noformat  0000  screen  0001  project0  0002  selectionvectorremover  0003  filterconditionitem0  oorderdate  19920101  0004  scangroupscanparquetgroupscan  entriesreadentrywithpath  pathtmporderctast1000parquet  readentrywithpath  pathtmporderctast2000parquet  readentrywithpath  pathtmporderctast3000parquet  selectionroottmporderctas  numfiles3  numrowgroups3  usedmetadatafilefalse  column  noformat  directory  pruning  select  orderctas  dir0  t1  read  data  one  folder  noformat  0000  screen  0001  project0  0002  project0  0003  scangroupscanparquetgroupscan  entriesreadentrywithpath  pathtmporderctast1000parquet  selectionroottmporderctas  numfiles1  numrowgroups1  usedmetadatafilefalse  column  noformat  select  select  orderctas  dir0  t1  read  content  three  folder  noformat  0000  screen  0001  project0  0002  selectionvectorremover  0003  filterconditionitem0  dir0  t1  0004  scangroupscanparquetgroupscan  entriesreadentrywithpath  pathtmporderctast1000parquet  readentrywithpath  pathtmporderctast2000parquet  readentrywithpath  pathtmporderctast3000parquet  selectionroottmporderctas  numfiles3  numrowgroups3  usedmetadatafilefalse  column  noformat  project  scan  push  select  oorderdate  count1  orderctas  group  oorderdate  ready  one  column  file  noformat  0000  screen  0001  projectoorderdate0  expr11  0002  hashagggroup0  expr1count  0003  scangroupscanparquetgroupscan  entriesreadentrywithpath  pathtmporderctast1000parquet  readentrywithpath  pathtmporderctast2000parquet  readentrywithpath  pathtmporderctast3000parquet  selectionroottmporderctas  numfiles3  numrowgroups3  usedmetadatafilefalse  columnsoorderdate  noformat  select  oorderdate  count1  select  orderctas  group  oorderdate  ready  column  file  noformat  0000  screen  0001  projectcolvrchr0  expr11  0002  streamagggroup0  expr1count  0003  sortsort00  dir0asc  0004  projectcolvrchritem0  oorderdate  0005  scangroupscanparquetgroupscan  entriesreadentrywithpath  pathtmporderctast1000parquet  readentrywithpath  pathtmporderctast2000parquet  readentrywithpath  pathtmporderctast3000parquet  selectionroottmporderctas  numfiles3  numrowgroups3  usedmetadatafilefalse  column  noformat  jira  aim  fix  three  described  case  order  improve  performance  query  item  star  column,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1
3098,limit  batch  size  merge  join  based  memory  merge  join  limit  output  batch  size  32k  row  irrespective  row  size  create  large  small  batch  term  memory  depending  upon  average  row  width  change  figure  output  row  count  based  memory  specified  new  outputbatchsize  option  average  row  width  incoming  left  right  batch  output  row  count  minimum  1  max  64k,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1
3099,enhance  record  batch  sizer  retain  nesting  information  map  column  enhance  record  batch  sizer  maintain  columnsizes  nested  fashion  map  given  column  get  sizing  information  child  underneath,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
3100,parquet  pushdown  planning  improvement  currently  parquet  pushdown  planning  certain  limitation  httpsdrillapacheorgdocsparquetfilterpushdown  jira  aim  fix  list  improvement  find  1  null  true  false  2  timestamp  date  time  implicit  explicit  cast  noformat  timestamp  date  timestamp  varchar  date  timestamp  date  varchar  time  timestamp  time  date  time  varchar  noformat,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0
3101,memory  consumption  fix  jira  cover  work  done  improve  drill  handling  memory  specifically  includes  allow  trimming  buffer  data  written  unused  memory  returned  pool  handle  case  attempt  write  beyond  buffer  capacity  handle  case  buffer  allocator  unable  allocate  new  buffer  due  memory  constraint  dynamically  adjust  allocation  size  based  trend,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0
3102,enhance  test  schema  builder  remaining  type  result  set  loader  project  enhanced  schema  builder  used  test  handle  drill  complex  type  map  union  list  repeated  list  schema  builder  previously  handled  map  ticket  describes  addition  one  part  result  set  loader  also  add  runtime  schema  improvement  function  create  array  testing  rather  writing  new  string  foo  bar  syntax,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
3103,batch  sizing  hash  join  limit  output  batch  size  hash  join  based  memory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3104,support  pushdown  system  table  querying  profile  store  fetch  record  applying  limit  codesql  select  sysprofiles  limit  1  code  test  scenario  120k  profile  store  codesql  select  count  sysprofiles  code  took  90  minute,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3105,support  parquet  filter  push  complex  type  currently  parquet  filter  push  working  complex  type  including  array  jira  aim  implement  filter  push  complex  type  underneath  type  among  supported  simple  type  filter  push  instance  currently  drill  support  filter  push  varchars  decimal  etc  though  drill  start  support  support  applied  complex  type  automatically  complex  field  pushed  way  regular  field  except  one  case  array  query  predicate  usershobbiesids2  null  wont  able  push  able  determine  exact  number  null  array  field  consider  1  2  3  v  1  2  array  different  file  statistic  second  case  wont  show  null  querying  two  file  term  data  third  value  array  null,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1
3106,project  push  hbase  scan  query  hbase  table  requires  subset  column  qualify  hbase  scan  column  example  noformat  select  rowkey  fc1  fc2  g  hbasemytable  noformat  qualify  hbase  scan  family  gall  fc1  c2,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,0,1
3107,web  ui  indicate  operator  spilled  inmemory  data  disk  currently  indication  operator  spilling  disk  would  help  explain  slow  running  query  suggestion  welcome  current  proposal  simply  update  operator  overview  section  show  average  max  spill  cycle  preferrably  color  code  formatting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3108,cluster  view  show  relevant  information  fixing  drill6224  noticed  information  useful  cluster  view  shown  drillbits  homepage  proposal  show  following  heap  memory  use  direct  memory  actively  use  since  able  get  total  memory  held  netty  moment  currently  allocated  running  query  process  cpu  average  system  load  factor  information  port  number  dont  help  much  general  cluster  health  might  worth  removing  information  realestate  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3109,add  operator  metric  batch  sizing  merge  join  add  operator  metric  batch  sizing  stats  merge  join,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3110,limit  batch  size  hash  aggregate  limit  batch  size  hash  aggregate  based  memory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3111,fix  tostring  drillfuncholder  type  0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
3112,inconsistent  method  name  field  following  method  name  field  method  mainly  appending  rename  method  append  better  codejava  private  void  fieldstring  label  string  value  indent  outappendlabel  append  appendvalue  appendn  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3113,unordered  receiver  report  memory  usage  drill  profile  functionality  doesnt  show  memory  usage  unordered  receiver  operator  problematic  analyzing  oom  condition  since  cannot  account  query  memory  usage  jira  fix  memory  reporting  unordered  receiver  operator,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3114,batch  sizing  union  batch  sizing  change  union  operator,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3115,provide  sqltypeof  modeof  function  drill  provides  typeof  function  return  type  column  returned  string  however  base  data  type  drill  data  type  major  type  also  includes  cardinality  mode  example  optional  int  required  varchar  type  information  useful  handling  data  conversion  example  could  tell  column  value  nullable  int  could  guess  one  drill  invented  could  merge  hand  type  another  file  actual  value  two  option  equivalent  either  provide  modeof  return  cardinality  datatypeof  return  maybe  modeof  might  useful  h4  documentation  documentation  information  extracted  pr  h5  sqltypeof  sqltypeof  return  data  type  using  sql  name  whether  column  null  sql  name  one  used  cast  statement  thus  sqltypeof  castx  type  return  type  type  name  type  decimal  type  also  includes  precision  scale  example  decimal6  3  h5  modeof  modeof  return  cardinality  mode  column  null  nullable  array  h5  drilltypeof  drilltypeof  function  work  like  typeof  return  internal  drill  name  even  value  null  h5  example  example  usage  highlight  old  friend  nullable  int  missing  column  noformat  select  sqltypeofa  atype  modeofa  amode  jsonallnulljson  atype  amode  integer  nullable  noformat  array  repeated  type  noformat  select  sqltypeofcolumns  coltype  modeofcolumns  colmode  csvcustcsv  coltype  colmode  character  varying  array  noformat  nonnull  type  noformat  select  sqltypeofname  nametype  modeofname  namemode  csvhcustcsvh  nametype  namemode  character  varying  null  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3116,support  jppd  join  predicate  push  feature  support  jppd  join  predicate  push  benefit  hashjoin  broadcast  hashjoin  performance  reducing  number  row  send  across  network  memory  consumed  feature  already  supported  impala  call  runtimefilter  httpswwwclouderacomdocumentationenterprise59xtopicsimpalaruntimefilteringhtml  first  pr  try  push  bloom  filter  hashjoin  node  parquet’s  scan  node  propose  basic  procedure  described  follow  hashjoin  build  side  accumulate  equal  join  condition  row  construct  bloom  filter  sends  bloom  filter  foreman  node  foreman  node  accept  bloom  filter  passively  fragment  hashjoin  operator  aggregate  bloom  filter  form  global  bloom  filter  foreman  node  broadcast  global  bloom  filter  probe  side  scan  node  maybe  already  send  partial  data  hash  join  nodescurrently  hash  join  node  prefetch  one  batch  side  4  scan  node  accepts  global  bloom  filter  foreman  node  filter  rest  row  satisfying  bloom  filter  implement  execution  flow  main  new  notion  described  1  runtimefilter  it’s  filter  container  may  contain  bloomfilter  minmaxfilter  2  runtimefilterreporter  wrap  logic  send  hash  join’s  bloom  filter  foremanthe  serialized  bloom  filter  sent  data  tunnelthis  object  instanced  fragmentexecutor  passed  fragmentcontextso  hashjoin  operator  obtain  fragmentcontext  3  runtimefilterrequesthandler  responsible  accept  sendruntimefilterrequest  rpc  strip  actual  bloomfilter  network  translates  filter  workerbee’s  new  interface  registerruntimefilter  another  rpc  type  broadcastruntimefilterrequest  register  accepted  global  bloom  filter  workerbee  registerruntimefilter  method  propagate  fragmentcontext  probe  side  scan  node  fetch  aggregated  bloom  filter  4runtimefiltermanager  foreman  instance  runtimefiltermanager  indirectly  get  every  runtimefilter  workerbee  bloomfilters  accepted  aggregated  broadcast  aggregated  bloom  filter  probe  side  scan  node  data  tunnel  broadcastruntimefilterrequest  rpc  5  runtimefilterenableoption  global  option  added  decide  whether  enable  new  feature  welcome  suggestion  advice  youthe  related  pr  presented  soon  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3117,store  context  name  abstractstorageplugin  instead  replicating  field  storageplugin  0,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
3118,native  mapr  db  plugin  support  hive  maprdb  json  table  hive  create  query  maprdb  table  via  maprdbjsonhandler  httpsmaprdocsmaprcomhomehiveconnectingtomaprdbhtml  aim  jira  implement  drill  native  reader  hive  maprdb  table  similar  parquet  design  proposal  use  jsontablegroupscan  instead  hivescan  add  storage  planning  rule  convert  hivescan  maprdbgroupscan  add  systemsession  option  enable  using  native  reader  native  reader  used  drill  build  mapr  profile  reason  leverage  default  profile  documentation  two  new  option  added  storehiveparquetoptimizescanwithnativereader  false  storehivemaprdbjsonoptimizescanwithnativereader  false  storehiveparquetoptimizescanwithnativereader  new  option  used  instead  storehiveoptimizescanwithnativereaders  latter  deprecated  removed  115  httpsissuesapacheorgjirabrowsedrill6527,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3119,make  storage  plugins  name  case  insensitive  storage  plugin  name  case  insensitive  dfs  v  dfs  informationschema  v  informationschema  workspace  schema  name  case  insensitive  root  v  root  tmp  v  tmp  even  user  two  directory  tmp  tmp  create  two  workspace  tmp  name  example  tmp  v  tmpu  table  name  case  sensitivity  treated  per  plugin  example  system  plugins  informationschema  sys  table  name  view  table  case  insensitive  actually  currently  sys  plugin  table  name  case  insensitive  informationschema  table  name  case  sensitive  need  synchronized  file  system  plugins  table  name  must  case  sensitive  since  table  name  imply  directory  file  name  case  sensitivity  depends  file  system  documentation  httpsdrillapacheorgdocslexicalstructure  updated  relevant  information,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
3120,drill  plugins  handler  storage  plugins  handler  service  used  drill  startup  stage  update  storage  plugins  configs  storagepluginsoverrideconf  file  plugins  configs  present  persistence  store  updated  otherwise  bootstrap  plugins  updated  result  configs  loaded  persistence  store  enabled  status  absent  storagepluginsoverrideconf  file  last  plugin  config  enabled  status  persists  drillexecstorageactiononpluginsoverridefile  boot  option  added  action  performed  storagepluginsoverrideconf  file  successful  updating  storage  plugins  configs  possible  value  none  default  rename  remove  null  issue  updating  hive  plugin  config  rest  solved  client  still  instantiated  disabled  plugins  drill6412  orghontonchashoconjacksondataformathocon  library  added  proper  deserializing  hocon  conf  file  additional  refactoring  comtypesafeconfig  orgapachecommonscommonslang3  placed  dependencymanagement  block  proper  version  correct  property  metric  drilloverrideexampleconf  specified  please  find  detail  design  overview  document  httpsdocsgooglecomdocumentd14jkb2ta8dgnoie5yt2rimkj7r0iaysgjjg8xitl5ymiedituspsharing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3121,rename  correlateprel  lateraljoinprel  currently  drill  correlateprel  physical  relation  operator  lateraljoin  implementation  explain  plan  show  correlateprel  confusing  hence  good  rename  operator  lateraljoinprel,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3122,support  emit  outcome  streaming  agg  update  streaming  aggregator  recognize  emit  outcome,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3123,lateral  excluding  column  output  container  provided  projection  push  rule  drill6545  lateralpop  information  list  column  excluded  lateral  output  container  mostly  used  avoid  producing  origin  repeated  column  lateral  output  required  projection  list  needed  absence  lateral  copy  repeated  column  n  number  time  n  number  row  right  incoming  batch  left  incoming  batch  row  copy  costly  memory  latency  perspective  hence  avoiding  must  lateralunnest  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3124,add  storehiveconfproperties  option  allow  set  hive  property  session  level  use  case  hive  external  table  ddl  noformat  create  external  table  mykey  int  val  string  row  format  delimited  field  terminated  stored  textfile  location  datamytbl  noformat  path  datamytb  contains  sub  directory  file  datamytblsubdirdatatxt  following  data  noformat  1  value1  2  value2  noformat  querying  table  hive  user  get  following  exception  noformat  failed  exception  javaioioexceptionjavaioioexception  file  filedatamytblsubdir  noformat  able  query  table  user  need  set  two  property  true  hivemapredsupportssubdirectories  mapredinputdirrecursive  set  system  level  hivesitexml  session  hive  console  noformat  set  hivemapredsupportssubdirectoriestrue  set  mapredinputdirrecursivetrue  noformat  currently  able  query  table  drill  user  specify  property  hive  plugin  noformat  type  hive  configprops  hivemetastoreuris  thriftlocalhost9083  hivemetastoresaslenabled  false  hbasezookeeperquorum  localhost  hbasezookeeperpropertyclientport  5181  hivemapredsupportssubdirectories  true  mapredinputdirrecursive  true  enabled  true  noformat  jira  scope  jira  aim  add  new  session  option  drill  storehiveconfproperties  allow  user  specify  hive  property  session  level  user  write  property  string  delimited  new  line  symbol  property  value  set  doublequotes  quote  otherwise  would  parsed  incorrectly  property  name  value  separated  alter  session  set  override  previously  set  property  session  level  query  drill  couldnt  unparse  property  string  warning  logged  property  parsed  loading  javautilproperties  default  value  empty  string  example  noformat  alter  session  set  storehiveconfproperties  hivemapredsupportssubdirectoriestruenmapredinputdirrecursivetrue  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3125,case  hashjoin  memory  calculator  reserve  memory  probe  side  build  phase  two  case  hashjoin  memory  calculator  reserve  memory  1  reserve  maximum  incoming  probe  batch  size  build  phase  really  necessary  fetch  probe  data  probe  phase  account  data  received  oknewschema  2  httpsissuesapacheorgjirabrowsedrill6646,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3126,improve  removingrecordbatch  transfer  record  need  copied  selectionvector2  contains  list  index  row  removingrecordbatch  copy  underlying  recordbatch  sv2  created  operator  like  filter  limit  etc  provide  selected  row  underlying  buffer  later  removingrecordbatch  copy  row  based  index  selectionvector2  output  container  type  none  case  row  need  copied  removingrecordbatch  incoming  batch  improved  full  transfer  valuevectors  input  output  container  instead  row  row  copy  example  incoming  batch  row  selected  filter  condition  filterrecordbatch  prepare  sv2  record  rowindex  later  removingrecordbatch  downstream  filter  potentially  transfer  instead  row  row  copy,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
3127,operatingsystemmxbean  class  cast  exception  loaded  ibm  jvm  related  httpsissuesapacheorgjirabrowsedrill6289  httpsgithubcomapachedrillblob1140commonsrcmainjavaorgapachedrillexecmetricscpugaugesetjaval28httpsurldefenseproofpointcomv2urluhttps3agithubcomapachedrillblob1140commonsrcmainjavaorgapachedrillexecmetricscpugaugesetjava23l28ddwmfagccskdksmqhcnjzxdqvpwtxgrct6otg6lptxkmyy7yg3amf8a5myr857ns3kmymu7pi8sk6qw8vra9hjia0npnasmpztptwrtznkglcuorzdl5lq6gyp5iaf3umfzgdomeie  exception  thread  main  javalangexceptionininitializererror  javalangj9vminternalsensureerrorj9vminternalsjava141  javalangj9vminternalsrecordinitializationfailurej9vminternalsjava130  orgapachedrillexecmetricsdrillmetricsgetregistrydrillmetricsjava111  orgapachedrillexecmemoryallocationmanagerclinitallocationmanagerjava64  orgapachedrillexecmemorybaseallocatorclinitbaseallocatorjava48  orgapachedrillexecmemoryrootallocatorfactorynewrootrootallocatorfactoryjava45  orgapachedrillexecmemoryrootallocatorfactorynewrootrootallocatorfactoryjava40  caused  javalangclasscastexception  comibmlangmanagementextendedoperatingsystem  incompatible  comsunmanagementoperatingsystemmxbean  orgapachedrillexecmetricscpugaugesetinitcpugaugesetjava40  orgapachedrillexecmetricsdrillmetricsregistryholderregistersystemmetricsdrillmetricsjava63  orgapachedrillexecmetricsdrillmetricsregistryholderclinitdrillmetricsjava53,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3128,jppdmove  aggregating  bf  foreman  runtimefilter  pr  move  bloomfilter  aggregating  work  foreman  runtimefilter  though  change  runtimefilter  apply  incoming  bf  soon  possible,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3129,hashjoin  build  hash  table  probe  side  empty  currently  inner  right  join  still  build  hashtables  probe  side  empty  performance  optimization  would  build,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3130,push  column  value  predicate  hbase  scan  continuation  drill571  convert  qualified  clause  column  hbase  scan,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3131,implement  window  functioning  want  support  window  functioning  drill,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
3132,add  jsonrecordreader  repeated  field  late  bind  schema  support  yet,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
3133,support  2  phase  count  aggregate  drill  currently  support  2  phase  aggregation  sum  min  max  enhancement  support  2  phase  count  aggregate  phase  1  partial  count  phase  2  need  sum  partial  count  produce  final  count,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
3134,drill  need  return  complex  type  eg  map  array  json  string  drill  need  help  user  understand  available  column  given  hbase  table  columnfamily  one  way  implement  describe  command  columnfamily  purpose  let  drill  column  sampling  mandatory  limit  clause  specifies  sample  size  throttle  number  column  returned  instead  narrow  proposal  general  mechanism  return  complex  type  json  string  allow  client  tool  odbc  driver  operate  complex  type  returning  map  json  would  provide  transparency  hbase  columnfamilies  allow  odbc  driver  help  surface  name  column  within  columnfamily  returning  array  json  would  provide  transparency  csv  file  since  conveys  number  column  odbc  driver,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
3135,aggregate  function  correlation  coefficient  calculation  adding  new  aggregate  function  correlation  calculation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3136,runtime  code  generation  support  function  parameter  complex  nested  type  jira  enhance  runtime  code  generation  component  following  way  1  allow  generate  runtime  code  function  whose  parameter  fieldreader  parameter  fieldreader  could  match  argument  repeated  list  repeated  map  element  repeated  listmap  nested  complex  type  2  addition  fieldreader  also  match  singular  value  int  float4  varchar  support  enabled  one  could  implement  function  parameter  fieldreader  match  simple  complex  nested  type  example  leverage  new  code  generation  logic  add  new  function  converttojson  convert  simple  complex  type  string  json  format  param  fieldreader  input  output  varbinaryholder,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3137,add  google  compute  preemptible  support  google  compute  provider  support  preemptible  instance  adding  fairly  straightforward,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3138,backblaze  b2  cloud  storage  backblaze  announced  b2  object  storage  api  httpswwwbackblazecomb2docs,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3139,add  security  groupfirewall  support  base  computeservice  right  dont  abstraction  dealing  security  groupsfirewalls  across  various  compute  apis  result  code  need  deal  said  security  groupsfirewalls  implementation  cloud  support  isa  pain  say  least  cloud  support  security  group  similar  concept  many  least  ec2  nova  cloudstack  cloudstack  fact  two  different  implementation  depending  network  type  seems  standard  enough  merit  generic  interface  base  computeservice,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3140,make  proxy  configuration  logic  setting  clearer  line  java  convention  description  httpsgithubcomjcloudsjcloudspull914  absence  special  jcloudsproxy  setting  jclouds  respect  normal  jvm  convention  proxy  detection  javanethttpproxyhost  property  default  proxy  unlike  everything  else  java  surprising  previously  jclouds  looked  jvm  proxy  jcloudsusesystemproxies  set  cumbersome  way  jcloudsusesystemproxies  tried  set  javanetusesystemproxy  read  startup  subsequently  ignored  jvm  little  effect  effect  jcloudsusesystemproxies  effectively  tell  jclouds  use  default  proxy  chosen  jvm  looking  javanet  property  necessarily  o  proxy  referred  javanetusesystemproxy  default  value  jcloudsusesystemproxies  taken  javanetusesystemproxy  succeeds  causing  javanetusesystemproxy  take  effect  succeeding  strange  accidental  way  way  normal  javanethttpproxyhost  others  take  effect  set  jcloudsusesystemproxiestrue  make  sure  javanetusesystemproxyfalse  add  explicit  control  whether  jvm  default  proxy  usable  true  default  switch  precedence  user  specifies  jcloudsproxyhost  used  irrespective  whether  system  proxy  jvm  proxy  specified  think  user  would  expect  need  set  special  proxy  setting  jclouds  use  importantly  case  set  jvm  proxy  setting  right  thing  happen,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3141,add  support  subnetwork  definition  google  compute  google  compute  added  subnetwork  definition  feb  2016  support  added  jclouds  httpscloudgooglecomcomputedocssubnetworkssubnetworksfeatures,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3142,managing  header  name  tempauth  identity  protocol  v1  state  jclouds  openstack  swift  official  client  python  manage  v1  protocol  httpdocsopenstackorgdeveloperpythonswiftclientswiftclienthtml  even  dont  specification  use  code  official  client  implementation  jclouds  currently  sortof  v1  identity  protocol  openstackswift  module  apisopenstackswiftsrcmainjavaorgjcloudsopenstackswiftv1configswiftauthenticationmodulejava  tempauthcredentials  almost  identity  v1  protocol  except  name  header  xstorageuser  v  xauthuser  xstoragepath  v  xauthkey  proposal  keep  current  behaviour  default  add  2  parameter  change  header  name  variable  property  put  builder  like  property  override  new  property  overridessetpropertyjcloudskeystonecredentialtype  tempauthcredentials  overridessetpropertyjcloudsswifttempauthheaderuser  xauthuser  overridessetpropertyjcloudsswifttempauthheaderpass  xauthpass  swiftapi  contextbuildernewbuilderprovider  endpointargs1  credentialsidentity  credential  modulesmodules  overridesoverrides  buildapiswiftapiclass,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
3143,portable  objectlevel  storage  class  presently  jclouds  support  objectlevel  storage  class  s3  adding  support  azure  gc  could  add  option  portable  abstraction,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
3144,add  temporary  signed  url  support  s3  s3blobrequestsigner  throw  unsupportedoperationexception  3arg  variant  signgetblob  signputblob  take  expiration  timeout  input,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3145,add  support  full  gce  v1beta15  api  jclouds192  weve  got  16x  line  gce  support  working  fully  implementing  v1beta15  api  im  working  getting  done  added  170  going  leave  16x  line  supporting  apis  existing  v1beta13  running  v1beta15  adding  new  api  call  needed  thing  like  zone  v  global  operation  ill  get  working,1,1,1,0,1,1,0,0,1,0,1,0,0,0,0,1,1
3146,swift  delete  chunk  deleting  multipart  blob  jclouds  automatically  creates  blob  chunk  multipart  upload  multipart  blob  deleted  blobstoreremoveblob  chunk  left  behind  would  nice  jclouds  automatically  deleted  test  case  httpsgithubcombrightinteractivejcloudsprototypeblob1cfa515b15658b3b7f74b2714dbf5b47fb4e14f2srctestjavacombrightinteractivejcloudsputgetdeletemultiparttestjava  fails  last  assert  assertequals0  blobstorecountblobscontainer  imho  automatic  deletion  doesnt  need  optional  mean  api  change  needed  jclouds  automatically  creates  chunk  shouldnt  always  automatically  delete  jclouds250  probably  need  addressed  issue  otherwise  jclouds  might  automatically  delete  blob  whose  name  start  multipart  blob  name,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3147,atmos  awss3  azure  blob  signer  doesnt  support  query  parameter  authentication  blob  store  provider  allow  using  signed  request  two  form  either  authorization  header  query  parameter  using  query  parameter  form  signed  request  necessary  client  dont  support  adding  header  returning  redirect  authorization  header  would  removed  jclouds  atmos  awss3  azure  implementation  generate  signed  request  authorization  header  cloudfilesus  hpcloudobjectstorage  use  query  parameter  ideally  blobrequestsigner  interface  would  allow  user  decide  form  signed  request  create,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3148,support  multipart  upload  generic  s3  generic  s3  provider  like  cloudian  support  multipart  upload  httpwwwcloudiancomcloudstorageproductscloudiancloudstorageplatformhtml  jclouds  move  awsspecific  provider  support  generic  s3  api,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0
3149,support  2gb  payload  single  request  running  default  http  driver  java  7  default  http  driver  us  java  httpurlconnection  us  integer  determine  fixed  length  content  mean  cannot  used  send  2gb  content  current  workaround  use  http  driver  support  2gb  payload  single  request  issue  conditionally  allow  default  driver  support  2gb  payload  single  request  via  conditionally  using  setfixedlengthstreamingmodelong  java  7  setfixedlengthstreamingmodeint  java  6  httpsgistgithubcomandrewgaul6439757,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3150,add  securitygroupextension  support  nova  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3151,migrate  unit  test  chefapitest  chefapiexpecttest  unit  test  chefapitestjava  using  old  way  good  migrate  new  way  done  chefapiexpecttest,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3152,use  omnibus  installer  install  chef  client  currently  running  chef  solo  chef  bootstrap  node  chef  client  manually  installed  installation  process  installs  ruby  rubygems  chef  gem  since  gem  ruby  automatically  updated  latest  version  downloaded  default  procedure  may  get  broken  backwards  incompatible  version  chefclient  gem  published  workarouned  specifying  version  ruby  chef  gem  install  creating  chefcontext  building  chefsolo  script  still  isnt  strong  enough  opscode  released  omnibus  easily  install  chefclient  dependency  omnibus  installer  detect  operating  system  node  install  appropriate  ruby  rubygems  distribution  compatible  desired  chefclient  version  transparent  isolated  way  preferred  way  install  chef  simplify  lot  chef  bootstrap  script  reduce  considerably  point  failure  happen  chef  installation  using  gem  still  supported  user  already  installed  ruby  want  control  installed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3153,jcloud  support  custom  chef  environment  jcloud  support  custom  chef  environment  trying  bootstrap  node  different  environment  default  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3154,disable  s3  virtual  host  bucket  generic  s3  s3compatible  provider  support  virtual  host  bucket  thus  disable  feature  default  continue  enable  virtual  host  bucket  awss3  support  although  feature  suffers  dns  settling  issue,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3155,add  securitygroupextension  support  gce  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3156,allow  image  preference  logic  supplied  templatebuilder  id  like  tie  jcloudss  templatebuilder  use  filteringmatching  capability  use  custom  logic  determine  matching  image  best  custom  value  best  ie  preferred  driving  use  case  want  portable  way  say  recent  ubuntu  centos  normally  default  course  doesnt  always  right  thing  option  specified  broken  ubuntu  alpha  image  aws  worst  offender  asking  16gb  ram  uswest1  give  back  awful  ubuntu  804  alpha  instance  would  also  handle  use  case  someone  want  say  ubuntu  11  12  centos  6x  best  failing  ubuntu  10  centos  5x  never  alpha  image  im  thinking  allowing  set  imagesorterordering  fit  templatebuilderimpl  currently  work  already  us  ordering  cant  change  stay  line  naming  convention  sorter  ordering  hardwaresorter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3157,move  gce  v1beta16  api  gces  got  new  api  version  v1beta16  httpsdevelopersgooglecomcomputedocstransitionv1beta16  there  huge  difference  real  change  load  balancer  implementing  yet  moving  around  quota  zone  region  didnt  actually  quota  zone  first  place  nonetheless  itd  good  bump  api  version  since  tend  vanish  old  one  163  thisll  mean  sv1beta15v1beta16g  170  im  also  adding  regionlevel  quota,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3158,allow  creating  node  computeservice  explicitly  specified  name  currently  instance  naming  node  created  computeservicecreatenodesingroup  etc  us  combination  specified  group  name  groupnamingconventions  unique  suffix  generally  thats  three  character  random  string  ec2  id  string  instance  fine  many  case  instance  name  doesnt  need  referenced  directly  actual  human  say  pain  case  currently  work  around  creating  instance  perapiprovider  clientsapis  hack  single  instance  creation  computeservice  utilizing  providerspecific  templateoptions  class  there  generalized  way  get  real  control  name  given  instance  computeservice  possible,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3159,remove  async  interface  apis  provider  jclouds  160  deprecated  async  interface  let  use  issue  subtasks  track  removing  supporting  code  17x  current  master,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3160,avoid  inputsupplierinputstream  support  bytesource  bytesource  convenience  method  avoids  generic  notational  overhead  guava  moving  towards  httpsgroupsgooglecomforummsgguavadiscussbchfnnxb9qaxlmy2uzsmpsj  note  bytesource  implement  inputsupplierinputstream  retain  source  compatibility,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3161,support  java  8  ensure  compatibility  java  8  advance  ga  release  march  presently  several  jclouds  test  core  fail  due  new  collection  method  hashmap  ordering  difference  yet  tested  backport  fix  17x,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3162,openstack  keypairapi  missing  get  orgjcloudsopenstacknovav20extensionskeypairapi  missing  get  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3163,google  cloud  storage  support  presently  user  access  google  cloud  storage  via  s3compatible  api  although  native  support  would  give  access  durable  reduced  availability  better  region  support  resumable  uploads,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3164,refactor  softlayer  support  current  softlayer  design  bit  complicated  maintained  looking  softlayer  python  client  think  get  inspiration  modernize  simplify  softlayer  cci  support,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
3165,support  aws  signature  version  4  mar  15  2012  amazon  announced  secure  way  sign  api  request  httpsforumsawsamazoncomannjspaannid1398  new  aws  region  frankfurt  support  version  2  jclouds  presently  us  httpdocsawsamazoncomamazons3latestapisigv4authenticatingrequestshtml  eventhough  aws  clone  like  openstack  support  version  jclouds  support  version  important  address  s3  ec2,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0
3166,add  support  arbitrary  cpu  ram  computeservice  provider  abiquo  cloudsigma  concept  hardware  profile  allow  user  specify  arbitrary  cpu  ram  value  current  computeservice  abstraction  assumes  provider  hardware  profile  force  implementation  provider  provide  fixed  hardcoded  list  conform  interface  would  great  modernize  compute  workflow  hardware  profile  mandatory  user  manually  set  value  needed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3167,headofline  blocking  problem  deleteallkeysinlist  current  implementation  deleteallkeysinlist  suffers  headofline  blocking  problem  get  pageset  blob  container  creates  future  deleting  wait  future  complete  getting  next  pageset  issue  originally  reported  andrew  gaul  gaul  1  shri  1  httpsgithubcomjcloudslegacyjcloudsissues1087,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3168,support  sshagent  authentication  access  created  node  see  httpsgithubcomjcloudsjcloudspull312,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3169,enhancement  availability  zone  api  availability  zone  api  openstack  extension  misused  several  place  including  test  linking  pr  make  extension  optional  make  live  test  work  matter  provider  support  extension,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
3170,add  support  iop  encrypted  volumetype  field  ec2  blockdevicemapping  dont  currently  support  iop  encrypted  volumetype  field  ec2  eb  blockdevicemapping  theyre  described  httpdocsawsamazoncomawsec2latestapireferenceapireferencequeryruninstanceshtml  add  especially  since  volumetype  needed  use  new  general  purpose  eb  ssd  volume,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3171,replace  handwritten  domain  class  autovalue  one  maintenance  port  ive  noticed  drift  related  using  guava  implement  hashcodeequals  domain  class  opportunity  guava  incompatibility  something  like  high  value  opinion  moreover  lot  inconsistency  value  class  caused  bug  extra  review  time  pull  request  autovalue  generates  concrete  implementation  take  possibility  inconsistency  field  name  nullability  etc  handled  compile  time  doesnt  introduce  dependency  note  chance  guava  version  conflict  user  httpsgithubcomgoogleautotreemastervalue  may  case  need  custom  gson  adapter  ex  opposed  constructorannotation  approach  revision  approach  believe  work  worthwhile  case  builder  wont  generated  still  think  valuable  example  many  case  shouldnt  making  builder  anyway  ex  readonly  object  never  instantiated  list  even  choose  still  write  builder  problem  isolated,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3172,add  support  tag  cloudstack  also  add  182  exists  currently  dont  support  tag  creating  deleting  listing  seeing  use  list  method  resource  type  using  filtering  list  method  resource  type  cloudstack  add,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3173,s3  retry  500  internalerror  jclouds  retries  several  error  500  internalerror  s3  description  suggests  retry  encountered  internal  error  please  try,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3174,support  multidelete  generic  s3  generic  s3  provider  like  dreamobjects  support  multidelete  object  jclouds  move  awsspecific  provider  support  generic  s3  api,1,0,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0
3175,expose  component  operation  multipart  upload  presently  jclouds  expose  multipart  upload  via  simple  interface  codejava  blobstoreputblobcontainername  blob  new  putoptionsmultiparttrue  code  allow  complicated  interaction  parallel  uploads  uploads  unknown  contentlengths  interface  like  writing  outputstream  current  multipartuploadstrategy  implementation  duplicate  code  across  azureblob  gc  s3  provider  propose  expose  mpu  component  operation  eg  initiate  complete  abort  upload  part  via  blobstore  abstraction  allow  u  address  feature,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3176,support  delimiter  option  blob  store  interface  s3  openstack  swift  gc  azure  support  delimiter  option  listing  container  specifically  api  allows  passing  character  list  request  would  used  delimiter  entry  currently  jclouds  default  using  another  character  certainly  possible  jclouds  support  api  option,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3177,move  listenerlist  implementation  interface  interface  universal  paradigm  pivot  listener  interface  class  data  structure  used  notify  listener  change  classdata  adapter  static  class  interface  file  implement  interface  default  implementation  separate  enclosed  static  class  implement  listenerlist  interface  listener  interface  usually  always  listener  list  class  definedused  class  need  notify  listener  however  class  must  parallel  interface  also  adapter  class  yet  different  place  seems  somewhat  reasonable  move  listener  list  class  interface  three  related  thing  located  file  preliminary  poc  concept  done  queryjava  querylistenerjava  look  good  doesnt  seem  require  change  client  code  accessor  method  refer  listenerlist  listener  list  class  order  general  course  help  u  hide  implementing  class  away  inside  interface  attach  diff  poc  hopefully  make  clear  may  seem  somewhat  nebulous  concept  idea  keep  like  thing  together  clarity,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3178,many  place  throw  illegalargumentexception  parameter  validation  inconsistent  primarily  code  look  like  currently  codejava  param  null  throw  new  illegalargumentexceptionparam  null  code  place  message  exception  place  check  parameter  place  message  regularize  checking  everywhere  making  common  core  method  null  check  check  0  etc  checking  messaging  common  also  simplifies  code  jit  compiling  shouldnt  affect  runtime  speed  either  common  method  get  compiled  andor  inlined  appropriate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3179,move  tutorial  ruler  class  mainline  code  use  others  ruler  class  associated  skin  listener  class  already  exists  two  place  tutorial  branch  go  main  wtk  code  used  others  might  find  useful,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0
3180,add  numberruler  heading  component  use  scrolling  textarea  textpane  similiar  ruler  component  pivot1017  would  size  display  line  number  column  count  used  row  column  heading  object  scrollpane  around  textarea  textpane  used  pure  text,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3181,introduce  style  enum  compiletime  checking  style  name  many  place  use  hardcoded  string  component  style  name  number  fairly  common  font  color  horizontalalignment  would  reduce  possibility  misspelling  style  name  enum  java  compiler  would  check  spelling  instead  finding  runtime  style  name  misspelled  would  involve  adding  method  componentstyledictionary  deal  enum  key,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3182,optimize  labelskinpaintgraphics2d  paint  method  called  order  magnitude  actually  already  pretty  fast  there  one  method  optimize  hell  one,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3183,create  new  gauge  object  display  single  value  circular  speedometer  fashion  instance  monitoring  application  thing  like  cpu  disk  usage  nicely  displayed  circular  gauge  showing  single  current  value  paradigm  currently  used  product  apache  ambari  called  gauge  widget,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3184,dont  set  selected  index  rollup  expander  expand  transition  complete  expand  transition  doesnt  start  selection  change  event  already  fired  outside  listener  way  knowing  transition  end  prevents  listener  calling  scrollareatovisible  container  fully  expanded  example,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
3185,change  locale  validators  unable  change  locale  used  validators  example  textinputvalidatortest  textinputfloatrange  ive  seen  giving  input  current  locale  work  good  havent  find  way  change  locale  set  different  format  validators  maybe  simplest  thing  could  set  different  locale  let  validators  using  case  application  would  use  locale  think  common  case  time  manage  locale  application  showing  time  user  best  could  new  setting  alive  without  restart  application  run  application  multilocale  environment  user  default  chosen  locale  thanks  sample  portion  code  us  could  go  example  textinputvalidatortest  hint  implementation  1  make  decimalvalidator  abstract  reason  currently  abstract  historical  holdover  2  make  decimalvalidator  constructor  public  3  modify  various  validator  class  extra  constructor  take  locale  parameter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1
3186,complete  textarea  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1
3187,context  menu  handler  create  frameworklevel  support  context  menu  creating  componentcontextmenuhandler  interface  display  host  detects  right  click  1  get  reference  lowestlevel  component  mouse  thats  nonnull  2  construct  path  display  component  instantiate  menupopup  3  walk  path  passing  menu  popups  menu  contextmenuhandler  found  along  path  4  open  menu  popup  menu  nonempty  path  walked,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3188,replace  disabled  item  indexespaths  listview  tableview  treeview  disabled  item  filter  add  disabled  item  filter  listbutton  using  filter  specify  disabled  item  flexible  also  allow  u  preserve  disabled  item  across  model  sort,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3189,clean  multiple  selection  implementation  convert  span  struct  replace  spansequence  listselection  listselectionsequence  return  instance  listselectionsequence  listviewgetselectedranges  tableviewgetselectedranges  avoid  need  copy  selection  content  fire  selected  range  add  remove  event  range  actually  added  removed  dont  refire  existing  selection,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
3190,add  collapsible  flag  expander  set  false  skin  would  present  user  way  collapse  expander  component  would  throw  caller  tried  set  invalid  state  collapsible  expanded,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
3191,add  disabled  date  filter  calendar  calendarbutton  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3192,change  selected  highlighted  tablepane  row  column  selected  wrong  term  also  cause  selectionbackgroundcolor  property  change  highlightbackgroundcolor,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3193,tablepane  row  column  collapse  vacant  tablepanes  row  column  either  empty  contains  invisible  component  collapse  spacing  allocated  note  spanned  content  bleeds  cell  cell  considered  empty  row  column  spanning  content  inhabits  considered  occupied  assuming  spanning  content  visible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3194,eliminate  component  displayable  property  use  visible  purpose  currently  skin  treat  displayable  flag  preferred  visibility  may  correct  interpretation  arguably  nondisplayable  component  simply  taken  flow  made  invisible  also  skin  currently  respect  displayable  flag  may  need  eg  windowskin  eliminate  property  use  component  visibility  instead  approach  taken  awt  also  review  container  currently  trying  respect  displayable  remove  code  doesnt  make  sense,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3195,allow  container  obtain  keyboard  focus  allow  u  resolve  issue  pivot213  well  address  potential  use  case  cant  currently  handle  example  making  textarea  container  allow  textarea  act  highly  customizable  form  similar  form  supported  html  additionally  focusable  container  supported  windowing  toolkits  including  awt  also  eliminate  negative  comparison  point,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3196,add  orientation  meter  component  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3197,create  new  buttongroup  class  implement  orgapachepivotcollectionsgroup  iterablebutton  move  buttongroup  toplevel  class  implement  orgapachepivotcollectionsgroup  currently  way  enumerate  group  content  seems  like  swing  buttongroup  class  support  wed  end  something  along  line  buttongroup  group  iterablebutton  addbuttonvoid  removebuttonboolean  getselectionbutton  setselectionbuttonvoid  buttongrouplistener  selectionchangedpreviousselectionbuttonvoid  button  getgroupbuttongroup  setgroupbuttongroupvoid  buttongroupadd  remove  would  call  buttonsetgroup  vice  versa  similarly  buttongroupsetselection  would  call  buttonsetselected  vice  versa  wed  also  move  named  group  dictionary  buttongroup,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
3198,add  hit  detection  drawing  primitive  add  new  api  allow  caller  programmatically  determine  shape  drawing  user  click,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3199,make  component  editor  fire  event  several  use  case  call  event  notification  editor  tableviewroweditor  treeviewnodeeditor  listviewitemeditor  include  preview  event  well  here  associated  api  change  public  interface  editor  public  boolean  isediting  public  void  save  public  void  savechanges  public  void  cancel  public  void  canceledit  tableview  public  interface  roweditor  extends  editor  public  void  edittableview  tableview  int  rowindex  int  columnindex  public  void  editrowtableview  tableview  int  rowindex  int  columnindex  public  listenerlistroweditorlistener  getroweditorlisteners  public  interface  roweditorlistener  public  vote  previeweditrowroweditor  roweditor  tableview  tableview  int  rowindex  int  columnindex  public  void  editrowvetoedroweditor  roweditor  vote  reason  public  void  roweditingroweditor  roweditor  tableview  tableview  int  rowindex  int  columnindex  public  vote  previewsavechangesroweditor  roweditor  tableview  tableview  int  rowindex  int  columnindex  dictionarystring  object  change  public  void  savechangesvetoedroweditor  roweditor  vote  reason  public  void  changessavedroweditor  roweditor  tableview  tableview  int  rowindex  int  columnindex  public  void  editcancelledroweditor  roweditor  tableview  tableview  int  rowindex  int  columnindex  treeview  public  interface  nodeeditor  extends  editor  public  void  edittreeview  treeview  path  path  public  void  editnodetreeview  treeview  path  path  public  listenerlistnodeeditorlistener  getnodeeditorlisteners  public  interface  nodeeditorlistener  public  vote  previeweditnodenodeeditor  nodeeditor  treeview  treeview  path  path  public  void  editnodevetoednodeeditor  nodeeditor  vote  reason  public  void  nodeeditingnodeeditor  nodeeditor  treeview  treeview  path  path  public  vote  previewsavechangesnodeeditor  nodeeditor  treeview  treeview  path  path  object  change  public  void  savechangesvetoednodeeditor  nodeeditor  vote  reason  public  void  changessavednodeeditor  nodeeditor  treeview  treeview  path  path  public  void  editcancellednodeeditor  nodeeditor  treeview  treeview  path  path  listview  public  interface  itemeditor  extends  editor  public  void  editlistview  listview  int  index  public  void  edititemlistview  listview  int  index  public  listenerlistitemeditorlistener  getitemeditorlisteners  public  interface  itemeditorlistener  public  vote  previewedititemitemeditor  itemeditor  listview  listview  int  index  public  void  edititemvetoeditemeditor  itemeditor  vote  reason  public  void  itemeditingitemeditor  itemeditor  listview  listview  int  index  public  vote  previewsavechangesitemeditor  itemeditor  listview  listview  int  index  object  change  public  void  savechangesvetoeditemeditor  itemeditor  vote  reason  public  void  changessaveditemeditor  itemeditor  listview  listview  int  index  public  void  editcancelleditemeditor  itemeditor  listview  listview  int  index,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3200,add  variableitemheight  style  terralistviewskin  setting  value  true  would  ease  restriction  item  list  view  height  true  height  item  would  determined  asking  renderer  preferred  height,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3201,add  disabledcheckmarkfilter  treeview  listview  allow  targetted  checkboxes  enableddisabled  return  disabled  checkmark  filter  return  disabled  checkmark  filter  ttnulltt  disabled  checkmark  filter  set  public  filter  getdisabledcheckmarkfilter  set  disabled  checkmark  filter  param  disableditemfilter  disabled  checkmark  filter  ttnulltt  disabled  checkmark  filter  public  void  setdisabledcheckmarkfilterfilter  disabledcheckmarkfilter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3202,renderers  passed  indexpath  listview  tableview  renderers  would  passed  itemrow  index  treeviews  renderer  would  passed  row  index  well  node  path,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3203,add  automationid  property  component  id  facilitate  automated  testing  tool  providing  key  tool  obtain  reference  component  instance,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3204,make  calendardate  structlike  class  using  mutator  method  calendardate  might  well  make  structlike  class  like  bound  point  dimension  etc,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
3205,add  variablerowheight  style  terratableviewskin  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3206,add  hidedisabledfilesboolean  style  terrafilebrowserskin  terrafilebrowsersheetskin  style  would  determine  file  covered  disabled  file  filter  would  shown  file  list  default  style  would  false  current  behavior  making  true  would  cause  disabled  file  removed  file  table  view,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3207,add  orgapachepivotutiltime  class  class  would  time  equivalent  calendardate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3208,provide  mean  programmatically  detecting  current  application  context  example  define  static  isactive  method  desktopapplicationcontext  browserapplicationcontext,1,0,1,0,1,0,1,0,1,0,1,0,0,1,0,0,0
3209,unable  easily  drag  multiple  selected  item  listview  step  reproduce  1  create  list  view  selectmodemulti  attach  drag  source  2  select  multiple  item  click  drag  selection  list  view  expected  behavior  expect  multiple  item  dragged  actual  result  upon  mouse  selection  reset  single  item  causing  drag  one  item  workaround  hold  ctrl  shift  begin  drag  kind  work  around  issue  obviously  lessthanideal  user  experience  note  could  affect  tableview  treeview  well  though  werent  tested  part  ticket,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3210,make  alert  prompt  property  mutable  specifically  type  message  option  body  make  easier  work  class  wtkx,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3211,make  data  binding  robust  data  binding  robust  support  configurable  twoway  mapping  using  bind  type  load  store  support  binding  model  data  well  selection  state  datadriven  component  following  component  updated  button  calendar  calendarbutton  colorchooser  colorchooserbutton  label  listbutton  listview  spinner  tableview  textarea  textinput  treeview  additionally  data  binding  event  moved  interface  addition  new  bound  property  create  number  new  databinding  related  event,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3212,rename  direction  enum  focustraversaldirection  somewhat  arbitrary  define  direction  forward  backward  enum  used  almost  exclusively  focus  traversal  place  used  delete  method  textarea  textinput  us  directionbackward  represent  backspace  make  sense  directionforward  doesnt  really  correspond  delete  method  instead  take  boolean  backspace  argument  would  used  distinguish  backspace  delete  use  direction  enum  would  truly  focus  traversal  name  focustraversaldirection  appropriate,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3213,remove  tablepanerowsetvisible  method  tablepanerowsetvisible  little  misleading  convenience  method  setting  visiblility  component  row  row  doesnt  maintain  independent  visibility  property  also  row  remain  visible  visible  component  exists  another  row  span  row  thus  remove,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3214,rename  textinput  textarea  inserttext  insert  also  remove  index  argument  consistent  delete  help  clarify  intent  method  replace  current  selection  inserted  text,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3215,add  repeatable  property  listbutton  found  requirement  application  user  click  label  part  linkbutton  button  fire  immediately  without  showing  popup  thus  invoking  action  currently  selected  entry  user  click  triangle  part  popup  shown  patched  linkbutton  add  new  boolean  property  called  showpopupontriggerclickonly  terralistbuttonskin  couldnt  think  better  name  sorry  set  true  listbutton  popup  show  user  click  triangle  user  click  rest  button  however  buttonpresslisteners  fire  usual  user  click  part  button  property  false  behavior  default  value  property  false  tested  patch  application  componentexplorer  work  good  would  nice  integrate  patch  otherwise  id  still  option  write  custom  skin  think  patch  could  interesting  developer  well,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0
3216,rename  alternaterowcolor  style  alternaterowbackgroundcolor  also  add  new  alternaterowcolor  style  define  foreground  color  alternate  row  apply  change  terrratableviewskin  terralistviewskin,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3217,move  terralistviewskin  listsize  style  intrinsic  listbutton  property  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3218,window  desktopapplicationcontext  support  javaawtwindowseticonimages  display  multiresolution  icon  desktopapplicationcontext  currently  set  window  icon  host  frame  using  javaawtwindowseticonimageimage  however  since  java6  there  new  method  called  seticonimageslistimage  icon  set  multiresolution  icon  eg  set  16x16  icon  window  title  bar  48x48  icon  shown  microsoft  window  task  switcher  64x64  icon  shown  window  vista7  aero  task  list  runtime  implementation  choose  appropriate  icon  list  provided  seticonimages  without  possibility  set  multiresolution  icon  o  scale  image  either  fit  current  environment  might  lead  poor  result  suggestion  add  new  method  seticonimageslistimage  method  pivotwtkwindow  set  use  desktopapplicationcontext  maybe  add  seticonpictureslistpicture  get  around  issue  downcasting  picture  updateframetitlebar  thanks  dirk,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3219,eliminate  threadutilities  class  created  primarily  icedtea  compatibility  still  requirement,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3220,add  color  name  javaawtcolor  style  attribute  like  border  stylescolorblue  content  textarea  wtkxidtextarea  stylesbackgroundcolorred  content  border,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3221,move  xml  path  accessor  method  xml  class  parity  jsonjsonserializer,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3222,allow  instance  creation  customization  reading  wtkx  file  creating  instance  creation  factory  method  inside  serializer  class  order  allow  instance  creation  customization  change  serialization  class  creating  protected  instance  creation  method  wtkxserializer  class  b  change  private  constructor  protected  c  allow  creation  custom  serialization  instance  recursing  tree  creating  protected  serialization  creation  method  client  visible  apis  changed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3223,add  getcontextpath  getlocation  queryservlet  without  getcontextpath  method  query  servlet  unable  determine  location  wont  able  return  correct  value  dopost  getlocation  convenience  method  return  location  servlet  protocol  host  port  context  path  servlet  path,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3224,rename  alertprompt  getselectedoption  getselectedoptionindex  current  method  name  implies  option  value  returned  rather  option  index  renaming  method  eliminate  ambiguity  new  getselectedoption  method  added  return  actual  option  value,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3225,allow  dictionary  value  specified  using  element  wtkx  currently  possible  populate  dictionary  type  via  attribute  element  example  supported  hashmap  abc123  mybeanclass  abc  myotherbeanclass  abc  mybeanclass  hashmap  abc  myotherbeanclass  abc  hashmap  prevents  caller  populating  dictionary  anything  primitive  value  wtkxserializer  also  allow  caller  populate  dictionary  complex  type  shown,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3226,move  message  processing  functionality  pivotcore  move  subscribe  unsubscribe  sendmessage  method  applicationcontext  new  orgapachepivotutilmessagebus  class  rename  applicationcontextmessagelistener  orgapachepivotutilmessagebuslistener,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,1,0
3227,bindable  improvement  add  argument  bindableinitialize  provide  caller  access  serializers  namespace  resource  location  allow  untrusted  application  take  advantage  bindable  without  needing  use  bxml  annotation  among  thing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3228,fire  selection  change  event  selection  change  indirectly  currently  selection  change  event  fired  explicit  call  made  affect  selection  example  listview  calling  either  setselectedranges  clearselection  fire  event  however  operation  indirectly  change  selection  state  adding  removing  item  listviews  model  data  trigger  event  originally  done  design  selectedrangeschanged  includes  previous  selection  argument  didnt  want  manually  reconstruct  every  time  selection  changed  side  effect  model  change  public  void  selectedrangeschangedlistview  listview  sequencespan  previousselectedranges  however  practice  working  within  model  challenging  registered  selection  change  listener  expecting  receive  notification  selection  change  forgetting  designed  way  im  guessing  developer  may  confused  well  proposing  component  maintain  selection  state  also  fire  selection  change  event  selection  change  indirectly  case  null  value  would  passed  previous  selection  save  effort  reconstructing  previous  selection  info  give  listener  additional  information  nature  change  ie  null  indirect  state  change  change  also  propagated  textinput  similar  issue  character  change  event  currently  textinput  fire  character  change  event  via  textinputcharacterlistener  text  change  event  via  textinputtextlistener  textchanged  event  pas  previous  text  value  inconsistent  change  event  textchanged  incorporated  textinputcharacterlistener  pas  previous  text  value  changed  via  explicit  call  settext  otherwise  pas  null  updated  version  textarea  probably  follow  approach,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3229,allow  bxmlinclude  tag  include  arbitrary  content  support  number  additional  use  case  including  externalizing  style,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,0
3230,make  listview  selecteditem  etc  notifying  property  property  dont  currently  fire  event  change  possible  dynamically  bind  using  namespace  binding  note  fire  selectmode  single,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3231,make  tab  pane  button  accordion  header  content  renderer  configurable  currently  tabpane  button  content  specified  via  tabpanelabel  tabpaneicon  attached  property  accordion  header  content  set  via  accordionlabel  accordionicon  limit  content  button  icon  andor  text  string  might  better  allow  caller  specify  data  button  directly  attached  label  icon  property  could  replaced  tabbuttondata  panelheaderdata  simply  buttondata  headerdata  container  could  allow  caller  specify  renderer  via  getsetbuttondatarenderer  getsetheaderdatarenderer  respectively,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3232,update  bxmlserializer  extensibility  reintroduce  bxmlserializer  extensibility  api  protected  method  hook  subclass  way  make  sense  new  bxmlserializer  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3233,allow  caller  specific  table  view  header  renderer  percolumn  basis  0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
3234,allow  serializers  fire  event  data  read  allow  caller  hook  serialization  process  update  ui  incrementally  rather  waiting  readobject  return,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,1
3235,bindmapping  imageview  possible  bindmapping  imageview  exemple  load  panel  bean  content  boolean  would  like  display  cross  image  valid  image  dependant  boolean  best  regard  duto,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3236,rollup  differentiate  useradded  skinadded  component  rollup  differentiate  useradded  skinadded  component  like  tabpane  etc  ideally  might  accomplished  defining  heading  content  component  similar  scrollpane  defines  view  rowheader  columnheader  strictly  speaking  dont  need  support  arbitrary  number  child  component  rollup  since  could  handled  setting  content  component  container,1,1,1,1,1,0,0,0,0,0,1,0,0,0,0,1,1
3237,provide  automated  support  setting  enum  value  adding  support  converting  string  enum  value  beanadaptercoerce  potentially  eliminate  conversion  overload  currently  using,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
3238,componentuserdata  allow  multiple  client  coexist  handy  able  stash  extra  info  component  multiple  library  want  quickly  get  hand  multiple  library  want  conflict  eg  add  librarya  libraryb  pivot  application  library  want  enhance  standard  pivot  behaviour  stashing  stuff  component  overwrite  others  userdata  better  solution  would  use  map  value  method  like  void  putuserdataclass  key  object  userdata  object  getuserdataclass  key,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3239,pimping  alert  following  patch  add  title  parameter  alertalert  method  show  better  default  title  depending  messagetype  also  add  translation  german,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3240,finishing  touch  skin  color  finishing  touch  skin  color  info  later  jira  httpsissuesapacheorgjirabrowsepivot579  see  even  final  part  implemented  could  useful  httpsissuesapacheorgjirabrowsepivot245  another  discussion  find  nabble  change  color  index  usage  better  visual  appearance  course  retrofitting  existing  behavior  whenif  possible  note  probably  little  change  custom  color  json  file  little  updated  little  thing  tooltips  doesnt  use  palette  color  use  hardcoded  color  think  make  use  yellowish  color  palette  index  19  one  variant  18  20  use  similar  yellowish  different  color  index  possible  color  warning  could  adapt  little  color  pivot  palette  look  similar  tell  example  someone  remember  background  color  swing  tooltips  ok  best  graphic  design  color  little  change  could  also  little  feature  palette  yellowish  needed  could  different  added  documentation  terra  package  javadoc  file  color  palette  usage  terra  skin  help  anyone  want  write  custom  color  removed  probably  best  place  tutorial  last  colorschemebuilder  maybe  even  kitchen  sink  add  tooltips  see  happen  see  make  sense  maybe  colorschemebuilder  move  element  tab2  tab3  grouping  similar  component  componets  added,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3241,splashscreen  control  ive  tried  get  hold  splashscreen  ive  defined  manifestmf  file  manifestversion  10  xcomment  mainclass  added  automatically  build  splashscreenimage  commacadenbalresourceswelcomejpg  desktopapplicationcontext  take  impossible  get  splashscreen  null  pointer  exception  thrown  could  extend  api  show  splashscreen  close  init  action  finished  open  application  window  nameless  gray  pivot  window  displayed  quite  long  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3242,add  closeable  property  tabpane  true  user  would  able  close  tab  clicking  close  icon  tab  button,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3243,pivot  blocking  edt  greg  hello  thread  httpmailarchivesapacheorgmodmboxpivotuser201001mbox3c4b5e581d2080604hmsharvardedu3e  final  word  sorry  possible  know  know  possible  reason  need  martin  httpnetbeansorgbugzillashowbugcgiid90590  namely  cleanup  shutdown  requested  confirmed  orgapachepivotwtkapplication  public  boolean  shutdownboolean  optional  throw  exception  since  call  shutdownboolean  optional  edt  need  block  using  approach  httpbugssuncomviewbugdobugid6424157  wich  almost  work  except  check  everywhere  containerasserteventdispatchthread  fails  described  httpbugssuncomviewbugdobugid6424157  due  eventqueueisdispatchthread  failing  t1  v  t1  distinction  request  think  could  make  containerasserteventdispatchthread  le  pedantic  allow  current  pastnext  edt  thread  pas  created  eventqueue  push  pop  thanks  andrei,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3244,implement  color  chooser  widget  would  nice  color  chooser  probably  easiest  copy  jcolorchooser  apache  harmony  convert  swing  pivot,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3245,allow  task  executed  using  executorservice  supplied  execution  time  orgapachepivotutilconcurrenttask  passed  executorservice  construction  used  task  executed  asynchronously  httppivotapacheorg20docsapiorgapachepivotutilconcurrenttaskhtmltaskjavautilconcurrentexecutorservice  would  useful  able  override  default  executorservice  noarg  constructor  used  executing  task  asynchronously  especially  task  might  run  multiple  time  executorservice  use  known  task  constructed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3246,extending  pivot  collection  monad  functional  method  add  usuful  method  pivot  collection  like  needed  process  element  going  function  style  like  addall  contains  etc  simplify  usage  people  coming  language  try  align  language  namesconventions  possible  like  scala  c  verify  even  add  interface  defining  single  method  could  passed  method  contain  logic  processing  element  like  apply  scala  chose  right  name  maybe  function  similar  info  httpapachepivotdevelopers417237n3nabblecomsomeideaonextendingpivotcollectionstd3321472html  change  collection  still  discussed  wait  30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3247,display  host  scaling  add  ability  scale  display  host  accessibility  could  hook  builtin  gesture  like  ctrlshiftmousewheel  allow  user  dynamically  scale  display  running  pivot  app,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3248,improve  performance  graphic  improve  performance  using  double  buffering  component  info  httpapachepivotdevelopers417237n3nabblecomredoublebufferingofcomponentstd3675333html  httpapachepivotusers399431n3nabblecomdoublebufferingofcomponentstd3674898html  note  httpapachepivotusers399431n3nabblecomperformanceandframeresizingpatchestd3623149html  proposed  patch  piotr  opinion  applied  maybe  changing  something  noel  others  think  something  already  committed  trunk  without  specifying  issue  thanks  piotr  initial  patch  discussiontests  committed  work,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3249,compilation  error  java  7  jdk  17  seen  continuous  build  environment  jenkins  apache  setup  use  java  7  httpsbuildsapacheorgjobpivottrunk20on20java207  build  pivot  source  trunk  raise  compilation  error  probably  change  even  buildproperties  buildxml  let  ci  build  force  17  java  version  source  target  idea  could  keep  release  specified  buildproperties  otherwise  use  current  java  version  discussion  httpapachepivotdevelopers417237n3nabblecomcompilationerrorsofpivottrunkwithjava7inapachejenkinstd3973664html  extract  generated  output  environmentinfo  echo  echo  compile  environment  pivotbuildbyjenkins202  echo  show  deprecation  true  echo  debug  true  echo  source  16  target  16  echo  encoding  utf8  echo  indexjars  true  echo  arg  xlint  echo  echo  java  environment  home  x1jenkinstoolsjavajdk17032jre  version  170  echo  core  mkdir  created  dir  x1jenkinsjenkinsslaveworkspacepivottrunk  java  7pivottrunkcoreantbin  javac  compiling  133  source  file  x1jenkinsjenkinsslaveworkspacepivottrunk  java  7pivottrunkcoreantbin  javac  warning  option  bootstrap  class  path  set  conjunction  source  16  javac  x1jenkinsjenkinsslaveworkspacepivottrunk  java  7pivottrunkcoresrcorgapachepivotxmlelementjava641  error  name  clash  removenode  element  override  method  whose  erasure  another  method  yet  neither  override  javac  public  int  removenode  node  javac  javac  first  method  removek  dictionary  javac  second  method  removet  sequence  javac  kvt  typevariables  javac  k  extends  object  declared  interface  dictionary  javac  v  extends  object  declared  interface  dictionary  javac  extends  object  declared  interface  sequence  javac  x1jenkinsjenkinsslaveworkspacepivottrunk  java  7pivottrunkcoresrcorgapachepivotxmlelementjava802  error  name  clash  removestring  element  override  method  whose  erasure  another  method  yet  neither  override  javac  public  string  removestring  attributename  javac  javac  first  method  removet  sequence  javac  second  method  removek  dictionary  javac  tkv  typevariables  javac  extends  object  declared  interface  sequence  javac  k  extends  object  declared  interface  dictionary  javac  v  extends  object  declared  interface  dictionary  javac  2  error  javac  1  warning  build  failed  x1jenkinsjenkinsslaveworkspacepivottrunk  java  7pivottrunkbuildxml474  following  error  occurred  executing  line  x1jenkinsjenkinsslaveworkspacepivottrunk  java  7pivottrunkbuildxml145  compile  failed  see  compiler  error  output  detail  total  time  3  second  build  step  invoke  ant  marked  build  failure  finished  failure,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3250,add  activity  indicator  file  browser  loading  directory  file  browser  loading  content  directory  take  time  depending  environment  whether  network  drive  indication  anything  happening  perhaps  activityindicator  could  overlaid  file  list  display  area  indicate  something  happening  background  work  since  loading  file  happening  second  thread,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3251,replace  desktopapplicationcontextdisplayexception  call  applicationcontexthandleuncaughtexception  consistent  way  handle  uncaught  exception  pivot  application  however  uncaught  exception  thrown  desktopapplicationcontext  class  example  applicationstartup  handled  using  private  static  method  displayexception  display  dialog  logic  cannot  overriden  may  applicationcontexthandleuncaughtexception  could  made  protected  call  desktopapplicationcontextdisplayexception  could  replaced  applicationcontexthandleuncaughtexception  possibly  applicationadapter  could  implement  uncaughtexceptionhandler  current  desktopapplicationcontextdisplayexception  logic  could  moved  new  applicationadapteruncaughtexceptionthrown  method  enable  override  uncaught  exception  handling  globally  pivot  application  motivation  deploy  pivot  app  using  java  web  start  user  default  disabled  java  console  familiar  want  display  custom  dialog  handle  uncaught  exception  displaying  full  stack  trace  possiblity  report  exception  help  desk  think  current  implementation  possible  override  handling  uncaught  exception  thrown  application  init  specific  situation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3252,standard  handling  exception  bxmlserializer  require  handling  uncaught  exception  using  standard  mechanism  implementing  uncaughtexceptionhandler  interface  pivotapplication  class  similar  recently  resolved  httpsissuesapacheorgjirabrowsepivot916  currently  possible  also  bxmlserializer  class  resolve  would  propose  1  handle  exception  reporting  bxmlserializer  single  protected  method  enable  overriding  method  bxmlserializer  descendant  upload  patch  2  change  scope  static  applicationcontexthandleuncaughtexception  method  public  enable  delegation  exception  handling  bxmlserializer  descendant  applicationcontext  hack  like  httpsvncodespotcomaapacheextrasorgpivotcontribtrunkpivotcontributilsrcpivotcontributilserializerinjectingserializerjava  wont  required  anymore  please  let  know  someone  see  elegant  solution,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3253,hide  tabpage  folder  application  need  control  tabbutton  visibility  tabpane  know  could  remove  component  tab  list  patching  pivot  adding  settabvisible  method  tabpane  easier  better  solution  u,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
3254,java2d  performance  optimization  following  performance  number  sample  run  local  machine  theyre  meaningful  compared  one  another  shouldnt  ever  compared  someone  el  number  future  performance  run  show  relative  run  time  paintgraphics2d  call  skin  class  sorted  avg  run  time  pre  skin  call  avg  m  total  m  pivotwtkskinterraterramenupopupskin  73  0000000  0  pivotwtkskinterraterrapanoramaskin  430  0000000  0  pivotwtkskinterraterrarollupskin  2562  0000000  0  pivotwtkskinterraterrasplitpaneskin  471  0000000  0  pivotwtkskinterraterraflowpaneskin  34167  0000088  3  pivotwtkskinterraterraformskin  565  0001770  1  pivotwtkskinterraterrasliderskin  559  0001789  1  pivotwtkskinterraterramenubarskin  176  0011364  2  pivotwtkskinterraterrasplitpaneskinsplitterskin  433  0011547  5  pivotwtkskinterraterraseparatorskin  165  0012121  2  pivotwtkskinterraterracalendarskin  156  0019231  3  pivotwtkskinterraterrascrollpanecornerskin  291  0020619  6  pivotwtkskinterraterratabpaneskin  368  0021739  8  pivotwtkskinterraterratablepaneskin  863  0040556  35  pivotwtkskinterraterraaccordionskin  92  0043478  4  pivotwtkskinterraterraspinnerskinspinbuttonskin  1476  0052168  77  pivotwtkskinterraterrascrollbarskinhandleskin  678  0058997  40  pivotwtkskinterraterraspinnerskin  744  0060484  45  pivotwtkskinterraterracalendarskindatebuttonskin  5818  0061705  359  pivotwtkskinterraterralabelskin  36104  0066696  2408  pivotwtkskinterraterratextinputskin  222  0072072  16  pivotwtkskinimageviewskin  6488  0074445  483  pivotwtkskinterraterrameterskin  804  0085821  69  pivotwtkskinterraterraalertskin  124  0088710  11  pivotwtkskinterraterrasliderskinthumbskin  555  0095495  53  pivotwtkskinterraterraexpanderskinshadebuttonskin  256  0097656  25  pivotwtkskinterraterrarollupskinrollupbuttonskin  1818  0097910  178  pivotwtkskinterraterrascrollbarskin  834  0100719  84  pivotwtkskinterraterrascrollbarskinscrollbuttonskin  1415  0108127  153  pivotwtkskinterraterraaccordionskinpanelheaderskin  263  0133080  35  pivotwtkskinterraterraexpanderskin  266  0146617  39  pivotwtkskinterraterracheckboxskin  3210  0151713  487  pivotwtkskinterraterramenubuttonskin  591  0155668  92  pivotwtkskinterraterrapromptskin  19  0157895  3  pivotwtkskinterraterraspinnerskinspinnercontentskin  735  0161905  119  pivotwtkskinterraterralistbuttonskin  134  0164179  22  pivotwtkskinterraterramenubaritemskin  664  0183735  122  pivotwtkskinterraterramenuskin  69  0202899  14  pivotwtkskinterraterramenuitemskin  238  0210084  50  pivotwtkskinterraterratabpaneskintabbuttonskin  1041  0282421  294  pivotwtkskinterraterracalendarbuttonskin  340  0285294  97  pivotwtkskintextareaskin  71  0323944  23  pivotwtkskinterraterraframeskinframebuttonskin  122  0336066  41  pivotwtkskinterraterratableviewheaderskin  413  0341404  141  pivotwtkskinterraterraborderskin  6200  0358226  2221  pivotwtkskinterraterrapushbuttonskin  1300  0363846  473  pivotwtkskinterraterralinkbuttonskin  399  0385965  154  pivotwtkskinterraterrascrollpaneskin  1968  0462398  910  pivotwtkskinterraterraradiobuttonskin  565  0467257  264  pivotwtkskinterraterratreeviewskin  427  1060890  453  pivotwtkskinwindowskin  802  1168329  937  pivotwtkskindisplayskin  797  1193225  951  pivotwtkskinterraterralistviewskin  194  1324742  257  pivotwtkskinterraterratableviewskin  465  1408602  655  pre  thing  jump  page  1  labelskin  called  paint  ton  used  virtually  every  renderer  average  run  time  comparatively  fast  foundational  one  paint  method  optimized  tilt  2  borderskins  paint  way  costlier  youd  think  itd  relative  skin  80th  percentile  also  called  awful  lot  find  whats  taking  long  speed  3  displayskin  windowskin  fill  background  color  yet  often  entire  clip  rect  display  always  window  always  maximized  surprisingly  expensive  scrollpaneskin  issue  lesser  extent  known  trick  speeding  primitive  graphic  operation  doubt  worth  asking,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3255,implement  simple  macro  system  jsonserializer  occurred  since  using  json  style  sheet  style  application  getting  quite  big  macro  system  maybe  similar  cc  define  something  similar  would  useful  especially  repeated  color  constant  like  padding  value  font  etc  would  enable  using  custom  value  consistently  avoiding  inconsistency  due  typo  change  introduced  one  place  others  thinking  simple  define  name  value  cc  using  name  substitution  token  easily  implemented  jsonserializer  im  open  suggestion  syntax  believe  feature  useful  especially  json  stylesheet,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3256,ability  file  manager  ingest  file  place  case  product  directory  want  ingest  catalog  without  actually  moving  new  location  call  kind  ingestion  place  ingestion  useful  file  manager  able  ingest  place,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3257,rewrite  file  manager  browser  webapp  using  apache  wicket  existing  file  manager  webapp  life  webappfilemgr  written  plainol  jsp  actually  fine  felt  hoopla  webapps  lately  would  take  crack  rewriting  jsp  webapp  using  apache  wicket  also  make  easier  file  upcoming  issue  porting  pc  opsui  webapp  able  lift  straight  away,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3258,rewrite  workflow  monitor  webapp  using  apache  wicket  similar  oodt155  except  workflow  monitor  web  application,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3259,update  ca  curator  tutorial  ive  picked  issue  curator  war  deployment  ca  curator  tutorial  httpoodtapacheorgcomponentsmavencuratoruserbasichtmlsection2  seems  web  app  deployed  name  xml  file  context  path  attribute  ive  tried  mac  snow  leopard  ubuntu  linux  using  flavour  tomcat6  paul  ramirez  path  attribute  ignored  unless  context  defined  statically  serverxml  file  otherwise  context  path  determined  tomcat  name  context  file  fooxml  hosted  foo  since  tomcat  specific  configuration  dont  way  change  update  tutorial,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3260,make  resource  manager  failure  success  aware  instead  complete  aware  patch  add  failure  success  status  resource  manager  alerting  user  job  arrived  either  state  currently  resource  manager  understands  whether  job  complete,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3261,xmlps  able  stream  large  result  currently  xmlps  store  row  resultset  cderesult  object  addition  cderesult  converted  string  httpresponse  nearly  doubling  memory  usage  large  result  heap  space  easily  run  despite  increasing  max  heap  space  servlet  container  eg  xmx1024m  xmlps  able  streamchunk  result  taking  consideration  following  resultsets  represent  iterable  collection  row  without  actually  storing  row  memory  httpresponsegetoutputstream  offer  streaming  response  chunked  transferencoding  contentlength  header  managed  automatically  servlet  container  tomcat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3262,extension  opendapps  module  extract  variable  dd  stream  second  patch  targeted  extending  opendapps  functionality  use  cmds  jpl  project  patch  contains  functional  modification  four  file  opendapprofilehandler  harvesting  metadata  multiple  thredds  catalog  avoid  stopping  process  catalog  result  error  rather  keep  harvesting  datasets  datasetextractor  parse  datasets  thredds  catalog  even  dont  explicit  direct  access  subelement  rather  urlpath  attribute  datasecrawler  select  metadata  extraction  thredds  datasets  opendap  access  url  disregard  others  thredds  catalog  authority  attribute  datasetgetuniqueid  return  string  null  case  use  datasetgetid  method  return  dataset  id  authority  prepended  profileutils  create  oodt  profelement  opendap  variable  found  dd  stream  wether  explicitly  configured  minimize  manual  handling  configuration  file  variable  configured  use  configuration  spec  possibly  rename  cast  rangedelementtype  enumelementtype  variable  configured  assume  rangedelementtype  finally  class  additional  log  statement  debugging  purpose,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3263,integrate  ca  protocol  pushpull  brians  got  ca  protocol  done  let  integrate  pushpull,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
3264,refactoring  metadata  extraction  functionality  opendapps  module  main  purpose  patch  refactor  metadata  parsing  functionality  extensible  framework  metadataextractors  metadataextractor  interface  defines  general  capability  parsing  metadata  source  adding  namevalue  pair  ca  metadata  container  existing  code  parsing  thredds  metadata  catalog  moved  datasetcrawler  class  threddsmetadataextractor  implement  aforementioned  interface  additionally  another  implementation  dasmetadataextractor  added  parse  opendap  da  stream  capture  netcdf  global  attribute  finally  ncmlmetadataextractor  added  stub  implementation  future  parsing  ncml  document  patch  also  contains  following  change  addition  oodt  profile  assigned  uuid  identifier  since  thredds  dataset  id  used  resource  identifier  thredds  catalog  parsed  extract  cf  standard  name  variable  long  name  found,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3265,improve  richness  consistency  metadata  extracted  thredds  catalog  main  purpose  patch  improve  richness  consistency  metadata  extracted  thredds  catalog  opendap  stream  check  required  information  indeed  present  resulting  oodt  metadata  profile  detail  class  affected  follow  profiler  invokes  profilechecking  utility  print  summary  important  metadata  field  quick  review  publisher  dasmetadataextractor  extract  variable  name  long  name  cf  standard  name  opendap  da  stream  threddsmetadataextractor  store  additional  metadata  hostname  par  type  documentation  tag  including  xlinks  us  type  attribute  create  different  metadata  element  add  additional  geospatial  temporal  coverage  element  store  multiple  thredds  access  url  oodt  reslocation  attribute  opendap  url  thredds  catalog  url  tds  html  landing  page  reslocations  ecoded  tuple  store  multiple  field  parse  variable  information  thredds  catalog  since  metadata  reliably  consistently  extracted  opendap  stream  profilechecker  new  utility  class  check  oodt  profile  versus  list  requiredoptional  element  profileutils  fix  bug  caused  metadata  value  containing  split  across  multiple  xml  element  check  string  null  adding  value  metadata  allow  multiple  value  profile  element  provided  configuration  file  includes  resulting  oodt  profile  opendapconfigxml  updated  example  configuration  new  metadata  field  general  change  changed  level  log  output  several  class  relevant  information  stand,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3266,change  curator  web  app  better  support  high  frequency  update  httpsreviewsapacheorgr8684  patch  contain  two  change  curator  update  metadata  method  new  method  used  vfastr  converted  use  xmlrpc  client  instead  embedded  catalog  one  ca  catalog  access  backend  store  time  old  method  used  existing  system  converted  use  shared  catalog  instance  opposed  create  new  catalog  instance  request  necessary  minimize  use  resource  database  connection  note  second  update  method  also  converted  use  xmlrpc  interface  proper  testing  platform  available,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3267,make  resource  manager  work  without  ganglion  disabling  resource  monitor  assignment  monitor  feature  required,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
3268,replace  print  stack  log  output  0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3269,add  support  local  session  improvement  bucket  making  zookeeper  work  large  scale  planning  1  million  client  connect  zookeeper  ensemble  set  50100  observer  majority  client  read  ie  update  create  ephemeral  node  zookeeper  today  client  creates  session  session  creation  handled  like  update  use  case  session  createdrop  workload  easily  overwhelm  ensemble  following  proposal  local  session  support  larger  number  connection  1  idea  introduce  new  type  session  local  session  local  session  doesnt  full  functionality  normal  session  2  local  session  cannot  create  ephemeral  node  3  local  session  lost  cannot  reestablish  using  sessionidpassword  session  watch  gone  good  4  local  session  connects  session  info  maintained  zookeeper  server  case  observer  connected  leader  aware  creation  session  state  written  disk  5  ping  expiration  handled  server  session  connected  change  make  zookeeper  scale  much  larger  number  client  without  making  core  ensemble  bottleneck  term  api  two  option  considered  1  let  client  specify  connect  time  kind  session  want  2  session  connect  local  session  automatically  get  promoted  global  session  operation  requires  global  session  eg  creating  ephemeral  node  chubby  took  approach  lazily  promoting  session  global  dont  think  would  work  case  want  keep  session  never  create  ephemeral  node  always  local  option  2  would  make  broadly  usable  option  1  would  easier  implement  thinking  implementing  option  1  first  cut  would  client  flag  islocalsession  much  like  current  readonly  flag  would  used  determine  whether  create  local  session  global  session,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3270,enabling  large  number  watch  large  number  client  zookeeper  see  watch  manager  consuming  several  gb  memory  dug  bit  deeper  scenario  testing  10k  client  connected  observer  20k  znodes  zookeeper  1k  20m  data  total  client  fetch  put  watch  znodes  200  million  watch  seems  single  watch  take  100  byte  currently  14528037  watch  according  yourkit  profiler  watchmanager  12  g  already  going  work  might  end  needing  20g  ram  watch  need  compact  way  storing  watch  possible  solution  1  use  bitmap  instead  current  hashmap  approach  znode  would  get  unique  id  get  created  every  session  keep  track  bitmap  indicates  set  znodes  session  watching  bitmap  assuming  100k  znodes  would  12k  10k  session  keep  track  watch  using  120m  instead  20g  2  second  idea  based  observation  client  watch  znodes  set  example  znodes  folder  multiple  client  watch  set  total  number  set  couple  order  magnitude  smaller  total  number  znodes  scenario  100  set  instead  keeping  track  watch  znode  level  keep  track  set  level  may  mean  get  may  also  need  implemented  set  level  save  watch  100m  suggestion  solution  thanks,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
3271,remove  duplicate  newleader  packet  leader  follower  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3272,add  zkupdateserverlistnewserverlist  set  server  change  would  like  update  server  list  stored  client  without  restarting  client  moreover  assuming  number  client  per  server  expectation  old  configuration  guaranteed  current  list  shuffling  example  would  like  rebalance  client  connection  across  new  set  server  way  number  client  per  server  server  expectation  b  excessiveunnecessary  client  migration  simple  achieve  without  b  reshuffle  new  list  server  every  client  would  create  unnecessary  migration  wed  like  avoid  propose  simple  probabilistic  migration  scheme  achieves  b  client  locally  decides  whether  migrate  list  server  change  attached  document  describes  scheme  show  evaluation  zookeeper  also  implemented  rebalancing  consistenthashing  scheme  show  comparison  derived  probabilistic  migration  rule  simple  formula  also  provide  someone  interested  proof,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3273,improve  zxidrollovertest  test  seems  flakey  jenkins  job  run  zookeeper  unit  test  orgapachezookeeperserverzxidrollovertest  sometimes  fails  eg  noformat  orgapachezookeeperkeeperexceptionconnectionlossexception  keepererrorcode  connectionloss  foo0  orgapachezookeeperkeeperexceptioncreatekeeperexceptionjava90  orgapachezookeeperkeeperexceptioncreatekeeperexceptionjava42  orgapachezookeeperzookeeperexistszookeeperjava815  orgapachezookeeperzookeeperexistszookeeperjava843  orgapachezookeeperserverzxidrollovertestchecknodeszxidrollovertestjava154  orgapachezookeeperserverzxidrollovertesttestrolloverthenrestartzxidrollovertestjava211  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3274,allow  serverside  sasl  login  jaas  configuration  programmatically  set  rather  reading  jaas  configuration  file  currently  cnxnfactory  check  javasecurityauthloginconfig  decide  whether  enable  sasl  zookeeperservernioservercnxnfactoryjava  zookeeperservernettyservercnxnfactoryjava  configure  check  javasecurityauthloginconfig  present  start  new  loginserver  saslservercallbackhandlerconf  since  saslservercallbackhandler  right  thing  checking  getappconfigurationentry  empty  allow  sasl  jaas  configuration  programmatically  checking  weather  configuration  entry  present  instead  javasecurityauthloginconfig  something  quite  similar  done  saslclient  zookeeper1373,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3275,multithread  commitprocessor  commitprocessor  single  thread  pull  request  queue  run  downstream  processor  noticeably  inefficient  readintensive  workload  could  run  concurrently  trick  handling  write  transaction  propose  multithreading  code  according  following  two  constraint  session  must  see  request  responded  order  committed  transaction  must  handled  zxid  order  across  session  believe  cover  constraint  need  honor  particular  believe  relax  following  matter  read  request  one  session  happens  write  request  another  session  constraint  propose  following  thread  1  primary  queue  servicingwork  dispatching  thread  0n  assignable  worker  thread  given  session  always  assigned  worker  thread  assigning  session  always  worker  thread  using  simple  sessionid  mod  number  worker  thread  guarantee  first  constraint  request  push  onto  thread  queue  processed  order  way  guarantee  second  constraint  allow  single  commit  transaction  flight  timethe  queue  servicing  thread  block  commit  transaction  flight  transaction  completes  clear  flag  32  core  machine  running  linux  2638  achieved  best  performance  32  worker  thread  56  5  improvement  throughput  improvement  measured  top  zookeeper1504  isolation  new  class  introduced  patch  workerservice  also  zookeeper1504  executorservice  wrapper  make  worker  thread  daemon  thread  name  easily  debuggable  manner  support  assignable  thread  used  nonassignable  thread  used  nioservercnxnfactory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3276,plumb  zookeeperserver  object  auth  plugins  want  plumb  zookeeperserver  object  auth  plugins  store  authentication  data  zookeeper  access  zookeeperserver  object  also  access  zkdatabase  look  entry  local  copy  zookeeper  data  order  implement  make  sure  zookeeperserver  instance  passed  providerregistryinitialize  method  initialize  try  find  constructor  authenticationprovider  take  zookeeperserver  instance  constructor  found  used  otherwise  initialize  look  constructor  take  argument  use  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3277,add  async  interface  multi  request  currently  async  interface  multi  request  zookeeper  java  client,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3278,upgrade  netty  version  upgrade  netty  version,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3279,add  cli  command  recursively  list  znode  child  troubleshooting  application  znodes  multiple  level  deep  eg  hbase  replication  handy  see  child  znodes  recursively  rather  run  l  node  manually  propose  adding  option  l  command  r  list  child  node  given  znode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3280,refactor  touchaddsession  sessiontrackerimpljava  jira  extends  idea  zookeeper1978  besides  refactoring  getput  operation  concurrentmap  addsession  method  addsession  also  call  touchsession  repeatedly  check  session  existed  would  nice  refactor  refactoring  second  issue  relevant  zookeeper1978  create  jira  fix,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3281,backup  config  file  create  backup  file  static  dynamic  configuration  file  changing  file  since  static  file  changed  twice  removing  ensemble  definition  point  dynamic  file  doesnt  exist  yet  removing  clientport  information  probably  fine  back  static  file  independently  dynamic  file  track  backup  history  option  1  could  bakxx  extention  backup  xx  sequence  number  option  2  configuration  version  part  file  name  dynamic  configuration  file  instead  file  like  zooreplicated1cfgdynamic1000000  reconfiguration  simply  create  new  dynamic  file  new  version  update  link  static  file  point  new  dynamic  one  review  place  httpsreviewsapacheorgr24208,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3282,ux  improvement  zooinspector  simple  change  would  simplify  using  zooinspector  lot  alphabetical  order  node  tree  view  short  term  caching  zookeeper  node  faster  rendering  node  tree  adddelete  node  context  menu  node  keyboard  shortcut  adddeleting  node  logging  information  zooinspector  failed  load  nodeviewers,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3283,support  multiple  zookeeper  client  different  configuration  single  jvm  two  zk  client  one  jvm  one  secure  client  second  normal  client  non  secure  cluster  zookeepersaslclient  system  property  true  default  second  client  connection  failing  pas  client  configuration  client  constructor  like  hdfs  client  example  code  public  zookeeperstring  connectstring  int  sessiontimeout  watcher  watcher  configuration  conf  throw  ioexception  code,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3284,enable  creation  node  ttls  user  would  like  able  create  node  tied  session  expire  automatically  action  taken  client  within  time  window  propose  enable  client  interacting  zk  via  http  thin  client  create  ephemerallike  node  idea  design  discussion  node  support  normal  zk  node  operation  including  acls  sequential  key  generation  etc  however  support  ephemeral  flag  node  created  ttl  updated  via  refresh  operation  zk  quorum  watch  node  similarly  way  watch  session  liveness  node  refreshed  within  ttl  expire  question  1  let  refresh  operation  set  ttl  different  base  value  2  setting  ttl  new  base  value  cause  watch  fire  3  want  allow  node  child  prevent  similar  ephemeral  node,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3285,improvement  fle  im  attach  patch  implement  following  modification  currently  server  leader  election  doesnt  receive  notification  amount  time  sends  new  set  notification  least  one  server  delivered  message  previous  set  patch  amount  time  server  wait  notification  sending  new  set  increase  exponentially  separated  connecting  server  queuing  new  notification  message  message  advantage  tell  instance  quorumcnxmanager  try  connect  server  without  generating  new  notification  message  changed  logging  level  several  message  quorumcnxmanager  warn  really  either  info  debug  ive  changed  info,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3286,remove  file  delete  duplicate  code  test  code  code  delete  folder  recursive  written  multiple  test  file  following  file  containing  piece  code  code  srcjavasystestorgapachezookeepertestsystemquorumpeerinstancejava  srcjavatestorgapachezookeepertestclientbasejava  srcjavatestorgapachezookeeperserverquorumlearnertestjava  srcjavatestorgapachezookeeperserverquorumzab10testjava  code  remove  duplicate  code  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3287,eliminate  using  static  initialize  sever  allow  server  embeddable  osgi  enviorments  patrick  request  open  issue  email  threadhttpn2nabblecomactivemqisnowusingzookeepertd1573272html  main  culprit  ive  noticed  code  serverstatsregisterasconcrete  code  may  others,0,1,0,1,0,0,0,0,1,1,1,0,0,0,0,0,0
3288,add  chroot  request  would  nice  able  root  zookeeper  handle  specific  point  namespace  application  use  zookeeper  work  rooted  subtree  example  ops  decides  application  x  use  subtree  appsx  application  use  subtree  appsy  x  chroot  appsx  path  reference  rooted  appsx  thus  x  creates  path  myid  actually  creating  path  appsxmyid  two  way  expose  mechanism  1  simply  add  chrootstring  path  api  2  integrate  service  identifier  scheme  example  zkserver12181server22181myroot  like  second  form  personally,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3289,cleanup  logging  level  used  use  correct  level  message  generated  cleanup  logging  make  sure  logging  us  correct  level  esp  error  warn  make  sure  message  meaningful  esp  fix  fixmsg  log,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3290,better  command  line  parsing  zookeepermain  command  line  parsing  zookeepermain  basicwe  use  kind  cli  parsing  commonscli  something  else  standard  improve  command  line  parsing  remove  scattered  code  zookeepermain  much  better  command  line  parsing,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3291,cleanup  fix  bookkeeper  observed  one  race  condition  multiple  thread  try  write  concurrently  patch  fix  also  remove  commented  code,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
3292,add  check  validate  datadir  datalogdir  parameter  startup  according  zookeeper2960  startup  check  validate  datadir  datalogdir  parameter  set  correctly  perhaps  introduce  check  kind  datalogdir  different  datadir  snapshot  exist  datalogdir  throw  exception  quit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3293,add  additional  server  metric  patch  add  several  new  serverside  metric  well  make  easier  add  new  metric  future  patch  also  includes  handful  minor  metricsrelated  change  here  highlevel  summary  change  patch  extends  request  latency  tracked  serverstats  track  read  update  latency  separately  update  request  must  voted  change  data  read  request  handled  locally  dont  change  data  patch  add  servermetrics  logic  related  avgminmaxcounter  simplecounter  class  code  designed  make  incredibly  easy  add  new  metric  add  new  metric  add  one  line  servermetrics  directly  reference  new  metric  anywhere  code  base  servermetrics  logic  handle  creating  metric  properly  adding  metric  json  output  monitor  admin  command  properly  resetting  metric  necessary  motivation  behind  servermetrics  make  thing  easy  enough  encourages  new  metric  added  liberally  lack  indepth  metricsvisibility  longstanding  zookeeper  weakness  facebook  internal  change  build  servermetrics  nearly  100  internal  metric  time  –  well  upstreaming  coming  month  publish  internal  patch  patch  add  20  new  metric  14  handled  servermetrics  patch  replaces  us  synchronized  serverstats  atomic  operation  here  list  new  metric  added  patch  uptime  time  peer  stable  leadingfollowingobserving  state  leaderuptime  uptime  peer  leading  state  globalsessions  count  global  session  localsessions  count  local  session  quorumsize  configured  ensemble  size  syncedobservers  similar  existing  syncedfollowers  observer  fsynctime  time  fsync  transaction  log  avgminmax  snapshottime  time  write  snapshot  avgminmax  dbinittime  time  reload  database  –  read  snapshot  apply  transaction  avgminmax  readlatency  read  request  latency  avgminmax  updatelatency  update  request  latency  avgminmax  propagationlatency  endtoend  latency  update  proposal  leader  committedtodatatree  given  host  avgminmax  followersynctime  time  follower  sync  leader  avgminmax  electiontime  time  entering  leaving  election  avgminmax  lookingcount  number  transition  looking  state  diffcount  number  diff  syncs  performed  snapcount  number  snap  syncs  performed  commitcount  number  commits  performed  leader  connectionrequestcount  number  incoming  client  connection  request  bytesreceivedcount  similar  existing  packetsreceived  track  byte,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3294,zookeeper  client  support  ipv6  address  document  ipv6  feature  issue  followup  work  zookeeper3057httpsissuesapacheorgjirabrowsezookeeper3057  1zk  server  side  support  ipv6  style  like  server12001db81242ac11228883888but  zk  client  side  support  ipv6  like  this2001db81242ac1122181we  need  unify  look  kafka  example  kafka1123httpsissuesapacheorgjirabrowsekafka1123  producer  client  also  support  ipv6  like  2001db81242ac112  2document  ipv6  feature  let  user  know,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3295,refactor  quorumpeermaintestjava  move  commonly  used  function  base  class  move  following  method  quorumpeertestbasejava  teardown  launchservers  waitforone  waitforall  logstates,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0
3296,use  session  map  improve  performance  closing  session  netty  previously  need  go  cnxns  find  session  close  n  total  connection  affect  performance  close  session  renew  session  lot  connection  server  jira  going  reuse  session  map  code  nio  implementation  improve  performance,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0
3297,masking  bookie  failure  writes  ledger  idea  jira  work  change  necessary  make  client  mask  failure  bookie  writing  ledger  im  submitting  preliminary  patch  submit  final  one  need  288  committed,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
3298,header  version  logsnap  file  moved  sourceforge  apache  httpsourceforgenettrackerindexphpfuncdetailaid1961767groupid209147atid1008547,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
3299,bookkeeper  streaming  api  easier  store  checpointssnapshots  bookkeeper  currently  bookkeeper  api  allows  byte  interface  ldwritebytes  interface  like  stream  ledgercreatestream  sure  interface  right  post  concrete  one  giving  little  thought  stream  used  wirte  checkpoint  swritebytes  closed  sclose  close  snapshot  api  could  use  current  api  implement  snapshot  chunk  byte  buffered  stream  written  via  ldwritebytes,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0
3300,asynchronous  version  createledger  async  version  read  write  async  version  creating  ledger  cause  application  change  whole  thread  design  easier  consistent  add  async  version  createledger,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3301,java  shell  indicate  connection  status  command  prompt  would  useful  java  shell  showed  current  connection  status  part  command  prompt  show  particular  following  use  case  attempted  connect  java  shell  remote  cluster  unavailable  run  first  command  l  cluster  shell  hang  would  nice  shell  indicated  connection  status  prompt  make  clear  shell  currently  connected  hard  see  attempting  connect  console  message  lost  messaes,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3302,refactor  follower  related  class  peerfollower  hierarchy  preparation  observer  observer  patch  zookeeper368  lot  functionality  shared  follower  observer  avoid  copying  code  make  sense  push  common  code  parent  peer  class  specialise  follower  observer  time  lengthier  method  follower  broken  make  code  readable,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,1,1
3303,startup  message  account  common  error  missing  leading  slash  config  file  would  nice  startup  noticed  directory  without  leading  slash  config  file  worth  warning  moreover  directory  exists  looking  root  looking  current  directory  serious  warning  order,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3304,server  support  listening  specified  network  address  issue  maililist  located  httpmailarchivesapacheorgmodmboxhadoopzookeeperuser200912mbox3c4ac0d28c0912210242g58230a9ds1c55361561c70d61mailgmailcom3e  checked  server  size  code  seems  option  provided  feature  useful  two  network  interface  one  internet  others  intranet  want  run  zookeeper  intranet  exposed  outside  world,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3305,add  monitoring  fourletter  word  filing  feature  request  based  zookeeperuser  discussion  zookeeper  new  fourletter  word  return  keyvalue  pair  appropriate  importing  monitoring  system  ganglion  large  installed  base  command  initially  export  following  count  instance  ensemble  b  count  uptodate  instance  ensemble  designed  future  additional  data  added  example  output  could  define  statistic  comment  print  key  space  character  value  line  total  number  instance  ensemble  zkensembleinstancestotal  5  number  instance  currently  participating  quorum  zkensembleinstancesactive  4  mailing  list  date  mon  19  apr  2010  121044  0700  patrick  hunt  phuntapacheorg  zookeeperuserhadoopapacheorg  subject  recovery  issue  debug  04192010  1155  travis  crawford  wrote  would  lot  easier  operation  perspective  leader  explicitly  published  health  stats  count  instance  ensemble  b  count  uptodate  instance  ensemble  would  greatly  simplify  monitoring  alerting  instance  fall  behind  one  could  configure  monitoring  system  let  someone  know  take  look  log  thats  great  idea  please  enter  jira  new  4  letter  word  jmx  support  would  also  great  starter  project  someone  interested  becoming  familiar  server  code  patrick,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3306,make  zookeeperserver  di  friendly  proposed  change  discussed  mailing  list  threadhttpmailarchivesapacheorgmodmboxhadoopzookeeperdev200807mbox3caf2843cd0807180907v44b310bg232be99ac0b47a27mailgmailcom3e  basic  goal  decouple  current  configuration  system  public  api  see  stuff  like  zookeeperserver  coupled  serverconfig  bit  allow  use  setter  injection  addition  constructor  injection  important  thing  needed  let  spring  easily  configure  object  move  main  method  zookeeperserver  class,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
3307,need  multiupdate  command  allow  multiple  znodes  updated  safely  basic  idea  single  method  called  multi  accept  list  create  delete  update  check  object  desired  version  file  state  case  create  version  existence  constraint  satisfied  update  done  atomically  two  api  style  suggested  one  list  style  transaction  allows  builderlike  method  build  set  update  commit  method  finalize  transaction  trivially  reduced  first  kind  api  list  based  api  style  considered  primitive  builder  style  implemented  syntactic  sugar  total  size  data  update  creates  single  transaction  limited  1mb  implementationwise  capability  done  using  standard  zk  internals  change  include  update  zk  client  new  call  additional  wire  level  request  server  code  convert  transaction  idempotent  form  code  slightly  extended  convert  list  operation  idempotent  form  client  downrev  server  reject  multiupdate  detected  gracefully  informative  exception  thrown  facilitate  shared  development  established  github  repository  httpsgithubcomtdunningzookeeper  happy  extend  committer  status  anyone  agrees  donate  code  back  apache  final  patch  attached  bug  normal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3308,extract  ipagemap  interface  pagemap  extract  ipagemap  interface  pagemap  make  easier  client  provide  wrapped  proxied  implementions  give  option  implementing  custom  isessionstores,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
3309,remove  onattach  onattach  doesnt  work  reliably  really  needed  functionality  moved  onbeforerender  also  give  much  flexibility  possible  method  thus  onattach  method  removed  made  final  actually  dont  fail  silently,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3310,wicketguice  support  provider  injection  typeliteral  injection  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3311,optimize  memory  usage  look  way  component  keep  state  optimize  memory  usage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3312,make  portlet  support  configurable  default  disabled  currently  new  portlet  support  enabled  automatically  runtime  wicketfilter  detects  javaxportletportletcontext  class  find  class  wicket  setting  adjustedoverridden  specifically  portlet  support  like  setting  renderstrategy  redirecttorender  always  portlet  support  used  needed  even  deployed  portlet  supporting  web  container  automatic  setting  change  result  unexpectedinvalid  behavior  fix  default  behavior  portlet  support  reverted  back  disabled  need  specifically  enabled  support  transparent  configuration  portlet  support  eg  needed  even  without  change  application  webxml  flexible  layer  configuration  setting  provided  wicket  filter  parameter  detectportletcontext  specified  detect  portletcontext  parameter  value  true  else  webxml  context  parameter  orgapachewicketdetectportletcontext  specified  detect  portletcontext  parameter  value  true  else  orgapachewicketprotocolhttpportletwicketportletproperties  resource  found  classpath  detect  portletcontext  specifies  propertyvalue  orgapachewicketdetectportletcontexttrue  note  wicketportletproperties  resource  already  used  wicketportlet  determine  servletcontextprovider  andor  portletresourceurlfactory  class  specified  otherwise  provides  100  save  solution  still  allowing  transparent  enabling  portlet  support  portal  like  jetspeed2  provide  wicketportletproperties  appropriate  value  outofthebox  using  solution  wicket  example  still  run  without  needed  change  jetspeed2  default  behavior  reverted  back  automatically  look  portletcontext  thus  default  provide  portlet  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3313,backport  wicketfilter  20  13  wicket  20  us  filter  serving  wicket  page  resource  backported  1x  stream,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3314,allow  24  hour  time  field  datetimefield  european  country  standard  date  format  24hours  12hours  ampm  itd  nice  time  format  configurable  component,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3315,open  modal  window  without  ajaxrequesttarget  wicket  122  included  new  modal  window  component  however  component  used  valid  ajaxrequesttarget  would  useful  modal  window  could  opened  programmatically  time  without  ajaxrequesttarget,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3316,enable  subclassing  ajaxrequesttarget  wicket  programming  experience  far  always  didnt  feel  quite  comfortable  ajax  part  issue  particular  example  always  include  common  feedback  panel  template  page  add  targetaddcomponentfeedbackpanel  everywhere  cumbersome  elegant  add  listener  using  ajaxrequesttargetaddlistener  possible  without  subclassing  request  cycle  yuk  ask  catch  short  moment  ajaxrequesttarget  instantiated  ajaxrequesttargetonrespond  called  automatically  set  focus  first  form  component  error  add  bulky  code  onsubmit  onerror  check  errrors  call  ajaxrequesttargetsetfocus  add  common  function  like  ajaxrequesttargetyellowfadeformcomponent  utility  method  call  like  ajaxutilyellowfadetarget  nice  functionality  like  really  belong  request  target  found  issue  solved  elegantly  could  catch  moment  ajaxrequesttarget  instantiated  attached  little  patch  solves  issue  make  ajax  lot  powerful  inside  wicket  imho  also  break  current  code  enhancement  notice  unless  need,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3317,move  iresponsefilter  implementation  new  subfolder  package  move  iresponsefilter  implementation  new  subfolder  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3318,better  clustering  support  diskpagestore  session  nodea  get  replicated  nodeb  store  page  replicated  nodeb  diskpagestore  immediately  rather  keeping  nodeb  session  two  benefit  back  button  support  nodea  get  session  originating  nodea  served  nodeb  much  lower  memory  consumption  page  nodea  dont  need  session  nodeb  stored  disk,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3319,allow  query  component  markup  id  without  creating  one  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3320,improve  selectoptions  allow  customization  created  selectoption  object  ive  created  patch  make  selectoptions  flexible  allows  customization  created  selectoption  object  eg  adding  ajaxeventbehavior  patch  also  extends  javadoc  select  ive  added  example  use  select  selectoptions  selectoption,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3321,generic  intercomponent  event  mechanism  attached  patch  provides  generic  mechanism  transmitting  intercomponent  event  within  page  grown  primarily  need  repaint  relevant  ajax  component  event  used  also  nonajax  environment  normal  form  submits  basic  idea  fire  ivisitor  page  component  sending  event  giving  argument  eventspecific  listener  interface  must  implemented  component  willing  receive  event  whatever  need  add  ajaxrequesttarget  supplied  event  sometimes  basic  wicket  mechanism  sharing  model  enough  particularly  repainting  relevant  component  ajax  event  get  tedious  component  far  away  complex  dom  tree  benefit  approach  loose  coupling  sending  receiving  end  however  strong  static  typing  easy  enough  find  ide  event  broadcasted  received  good  testability  eventbroadcaster  mocked  sending  end  event  handler  tested  directly  receiving  end  possibly  mock  event  need  keep  reference  component  instance  path  could  problematic  repeater  real  observer  listener  pattern  implementation  component  cannot  register  unregister  dynamically  registering  handled  statically  class  basis  implementing  relevant  event  receiver  interface,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
3322,make  application  class  beanish  application  class  getters  property  like  applicationsettings  securitysettings  couldnt  make  property  writable  also  realize  internal  implementation  might  change  bit  currently  setting  class  implement  interface  us  single  instance  setting  default  reason  want  set  application  object  spring  access  via  wicketspring  current  implementation  application  doesnt  facilitate  set  part  well,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1
3323,image  could  made  ajax  aware  could  cool  image  could  made  ajax  awareso  would  add  random  noise  added  ajax  context  currently  add  new  image  via  ajax  updatedbecause  browser  doesnt  know  reload  normal  procedure  use  noncaching  image  instead  confusing  lot  people  pasted  mailinglist  people  want  stable  url  image  would  imagine  cached  browser  case  ajax  doesnt  work  url  change  browser  need  know  refresh  maybe  image  know  requested  within  ajax  request  automatically  add  random  noise  urlthere  maybe  room  improvement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3324,set  session  locale  constructing  session  object  currently  create  session  object  like  webapplicationgetsession  session  null  create  session  using  session  factory  session  getsessionfactorynewsessionrequest  set  client  locale  session  sessionsetlocalerequestgetlocale  propose  change  constructor  session  websession  take  locale  parameter  well  would  make  possible  custom  session  class  fix  locale  setting  constructor  possible  overriding  sessiongetlocale,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3325,wicketajaxindicatorappender  rename  ajaxindicatorappender  tiny  niggle  really  ajax  component  start  ajax  always  forget  one  perhaps  rename  keep  deprecated  subclass  old  name,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
3326,make  autocompletebehaviors  configuration  flexible  add  autocompletesettings  encapsulates  needed  configuration  option  dont  need  hundred  constructor  every  combination  configuration  option  available,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3327,expose  iitemfactory  refreshingview  modified  refreshingview  expose  iitemfactory  facilitate  dynamic  row  addition  using  iitemfactory  impl  used  create  original  row  onpopulate  allows  code  use  protected  method  refreshingview  newchildid  newitem  populateitem  would  normally  access  well  promote  code  resue  activity,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3328,datepicker  javascript  optimized  currently  datepicker  generates  3000  byte  javascript  date  field  currently  datepicker  generates  3000  byte  javascript  per  date  field  specifically  per  date  field  datepicker  table  2  date  column  10  row  mean  60000  byte  excess  http  traffic  show  slows  page  rendering  significantly  datepicker  javascript  optimized  javascript  wizard  know  hook  could  serve  change  know  problem  datepicker  component  given  initializer  method  instead  using  parametrized  method  call  block  1  initprojectemployeestartdate123  function  wicketdatetimeinit  widgetid  projectemployeestartdate123  suitably  parametrized  componentid  projectemployeestartdate123  suitably  parametrized  block  2  wicketcalendarinitfinished  initprojectemployeestartdate123  suitably  parametrized  else  wicketcalendarinitspushinitprojectemployeestartdate123  suitably  parametrized,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3329,stringrequesttarget  bloated  need  care  looking  stringrequesttarget  found  following  thing  unnecessary  1  create  charset  object  string  sufficient  encoding  2  write  stream  first  read  back  write  response  stream  using  internal  buffer  3  flush  output  stream  4  specify  charset  contenttype  charset  parameter  made  version  stringrequesttarget  attached  patch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3330,ajaxlazyloadpanel  shouldnt  call  getloadingcomponentstring  constructor  use  case  class  mypanel  extends  ajaxlazyloadpanel  private  boolean  bool  public  mypanelstring  id  boolean  bool  superid  bool  used  call  thisbool  bool  assigned  call  public  getloadingcomponentstring  id  bool  return  componenta  else  return  componentb  since  getloadingcomponentstring  called  part  super  constructor  actual  value  bool  never  used  furthur  bool  object  instead  primitive  could  potentially  cause  npe  instead  loading  component  created  onbeforerender  protected  void  onbeforerender  renderedonce  loadingcomponent  getloadingcomponentcontent  addloadingcomponentsetrenderbodyonlytrue  renderedonce  true  superonbeforerender  also  requires  change  ajax  behavior  public  boolean  isenabledcomponent  component  return  getcontent  loadingcomponent  loadingcomponent  null,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3331,make  wicket  configuration  type  enum  would  suggest  starting  wicket  15x  wicket  configuration  type  converted  enum  current  string  orgapachewicketapplicationgetconfigurationtype  future  configurationtype  orgapachewicketapplicationgetconfigurationtype  package  orgapachewicket  public  enum  configurationtype  development  deployment  enum  lot  benefit  eg  cover  case  case  block  upper  lowercase  inconsistency,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3332,please  make  requestloggerlogrequestdata  sessiondata  protected  could  please  make  method  protected  rather  private  make  simple  something  like  override  protected  irequestlogger  newrequestlogger  return  new  requestlogger  override  protected  void  logrequestdata  rd  sessiondata  sd  custom  logging  also  would  real  nice  time  extract  creation  appendingstringbuffer  method  log  method  look  like  protected  void  logrequestdata  rd  sessiondata  sd  logisinfoenabled  loginfocreatestringbufferrd  sd  true  protected  final  void  createstringbufferrequestdata  rd  sessiondata  sd  boolean  includeruntimeinfo  stuff  taken  log  creates  asb  includeruntimeinfo  runtime  runtime  runtimegetruntime  long  max  runtimemaxmemory  1000000  long  total  runtimetotalmemory  1000000  long  used  total  runtimefreememory  1000000  asbappendmaxmem  asbappendmax  asbappendmtotal  asbappendtotal  asbappendmused  asbappendused  asbappendm  return  asb,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3333,radiogroupcheckgroup  support  embedded  radiogroupscheckgroups  possible  markup  like  span  wicketidcheckgroup1  span  wicketidcheckgroup2  table  tr  wicketidrepeater  tdinput  wicketidcheckforgroup1td  tdinput  wicketidcheckforgroup2td  tr  table  constructor  check  take  additional  reference  check  group  belongs,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
3334,need  way  programmaticaly  configure  location  temp  directory  file  uploads  size  chunk  buffer  using  fileuploadfield  way  configure  temporary  file  created  way  pas  lower  level  use  systemproperty  also  way  configure  size  memory  buffer  used  receive  data  currently  hardcoded  4k  small  application  slow  file  writes  id  like  able  bump  128k,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3335,application  add  componentinstantiationlistener  dont  want  cant  remove  writing  unit  test  requires  instantiate  component  instantiated  component  discovered  requires  application  attached  current  thread  problem  instantiated  application  set  thread  using  applicationset  however  point  saw  following  error  javalangillegalstateexception  locate  create  session  context  request  cycle  problem  application  constructor  add  component  instantiation  listener  delegate  discovery  authorization  strategy  session  session  isnt  present  want  create  one  tried  setting  session  requires  request  cycle  requires  request  response  etc  see  two  issue  1  application  creates  component  instantiation  listener  cannot  removed  way  remove  reference  listener  pas  removecomponentinstantiationlistener  listener  created  anonymously  inside  application  constructor  could  solved  creating  method  called  something  like  initializedefaultcomponentinstantiationlisteners  subclass  could  override  noop  2  listener  application  creates  always  creates  session  even  though  session  default  implementation  method  application  call  delegate  back  application  issue  could  resolved  solution  1  since  application  know  theyre  going  override  authorization  strategy  persession  basis  could  add  authorization  listener  didnt  create  session,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3336,back  port  resource  caching  component  provided  resource  cache  key  20  resource  caching  overridable  component  level  including  providing  resource  cache  key  resource  stream  providing  null  resource  cache  key  achieve  resource  stream  never  cached  something  need  want  use  dynamic  resource  stream  change  request  session  request  back  port  functionality  truly  dynamic  template  used  wicket  13  well,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3337,wickettester  version  depend  junit  wickettester  dependency  junit  mostly  assert  method  would  nice  wickettester  generic  would  possible  use  unit  test  tool  assert  method  could  instance  method  return  result  object  result  contains  message  boolean  evaluation  example  class  result  private  boolean  evaluation  private  string  message  void  assertrenderedpageclass  expectedreneredpageclass  result  wasrenderedpageclass  expectedreneredpageclass  junit  specific  junitwickettester  could  extend  generic  base  class  provide  junit  style  assertion  implemented  wickettester  using  base  class  method  void  assertrenderedpageclass  expectedreneredpageclass  result  result  wasrenderedpageexpectedreneredpageclass  asserttrueresultevaluation  resultmessage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3338,remove  icomponentborder  favor  ibehavior  yeah  think  depricate  icomponentborder  14  point  ibehavior  beforeafter  remove  15  maybe  remote  also  public  final  component  setcomponentborderfinal  icomponentborder  border  component  make  public  final  component  setcomponentborderfinal  ibehavior  border  make  clear  people  border  set  using  behavior  else  know  hide  quoted  text  sat  may  16  2009  1221  juergen  donnerstag  juergendonnerstaggmailcom  wrote  hi  question  looking  code  call  implementation  render  component  final  icomponentborder  border  getcomponentborder  border  null  borderrenderbeforethis  notifybehaviorscomponentbeforerender  onrendermarkupstream  notifybehaviorscomponentrendered  border  null  borderrenderafterthis  icomponentborder  could  implemented  via  behavior  well  reason  icomponentborder  need  special  treatment  implemented  behavior  juergen  yeah  think  depricate  icomponentborder  14  point  ibehavior  beforeafter  like  componentborder  stuff  set  without  influencing  beahavior  component  stuff  render  content  component  use  debugging  environment  mm  wait  give  everybody  chance  comment,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3339,text  browserinfopage  customizable  text  browserinfopage  customizable  currently  user  get  flash  text  page  id  rather  saw  blank  page  least  something  say  loading  realise  duplicate  closed  issue  wicket1591  say  think  made  wrong  call  order  change  text  browserinfopage  override  webrequestcyclenewclientinfo  method  problem  isnt  tricky  implementing  requires  copying  large  chunk  code  webrequestcycle  method  could  potentially  change  future  version  code  making  implementation  prone  bug  think  changing  text  browserinfopage  probably  relatively  common  requirement  since  look  pretty  unprofessional  flash  text  first  application  page  displayed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3340,patch  adding  listener  ajaxrequesttarget  add  listener  hook  step  ajaxrequesttarget  response,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3341,make  modificationwatcher  replacable  google  app  engine  allow  application  spawn  thread  wicket  modificationwatcher  deploying  wicket  application  gae  work  debug  mode  even  deploying  local  app  engine  development  environment  would  nice  would  possible  use  different  modificationwatcher  spawn  thread  problem  modificationwatcher  interface  concrete  class  b  modificationwatcher  final  bonus  would  nice  optional  modificationwatcher  implementation  wicket  core  rely  thread  instead  check  resource  every  request  example,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
3342,defaultcssautocompletetextfield  renamed  defaultcssautocompletetextfield  renamed  defaultcssautocompletetextfield  match  naming  superclass  autocompletetextfield,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3343,tabbedpanel  extract  factory  method  tabscontainer  please  consider  adding  factory  method  tab  container  see  attached  diff,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3344,ichainingmodel  implementation  direct  implementation  ichainingmodel  largely  taken  abstractpropertymodel  need  generic  typing  14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3345,ajaxlazyloadpanel  callback  script  rendering  usecase  ajaxlazyloadpanel  need  loaded  later  document  onready  j  event  triggered  later  clientside  event  like  click  button  way  implemented  right  way  override  ajaxlazyloadpanel  change  callback  handling  script  would  useful  instead  addnew  abstractdefaultajaxbehavior  override  public  void  renderheadiheaderresponse  response  superrenderheadresponse  responserenderondomreadyjavascriptgetcallbackscripttostring  would  protected  method  would  thing  addnew  abstractdefaultajaxbehavior  override  public  void  renderheadfinal  iheaderresponse  response  superrenderheadresponse  handlecallbackscriptresponse  getcallbackscripttostring  protected  void  handlecallbackscriptfinal  iheaderresponse  response  final  string  callbackscript  responserenderondomreadyjavascriptcallbackscript,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3346,make  datepicker  datetimefield  overrideable  id  like  use  datetimefield  component  api  see  override  datepicker  get  added  component  id  like  subclass  datepicker  customize  icon  positioning  etc  dealing  datetextfield  add  datepicker  behavior  cant  using  datetimefield  way  could  enhanced  simple  protected  newdatepicker  method  datetimefield  would  accomplish  submit  patch  see  httpoldnabblecomdatetimefieldenhancementtd26835114html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3347,improve  diagnostics  serialization  exception  jdks  default  serialization  exception  doesnt  give  whole  lot  information  object  didnt  implement  serializable  try  improve  giving  info  object  tree  serialized,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3348,palette  allow  tracking  abstractchoices  component  via  ajax  default  two  selects  used  palette  excluded  ajax  serialisation  thus  way  tracking  mouse  click  via  ajax  thus  javascript  code  causing  moved  protected  function  derived  class  implement  different  behaviour  see  attached  patch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3349,improve  cssjs  contribution  currently  order  cs  contribution  page  1stcontainer2ndcomponent3rd  inverse  order  allow  deepest  nested  component  contribute  first  way  outer  container  contribution  appear  allowing  container  override  cssjavascript,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3350,locate  property  file  using  convention  markup  file  original  inquiry  mailing  list  httpwwwmailarchivecomuserswicketapacheorgmsg47803html  curious  property  file  located  way  html  ive  overridden  resourcestreamlocator  public  iresourcestream  locate  class  clazz  string  apath  string  astyle  locale  alocale  string  anextension  notice  property  file  locating  doesnt  invoke  method  invokes  lesser  arg  version  stylevariationlocale  already  embedded  path  inconvenience  im  trying  inspect  style  location  perhaps  shouldnt  im  trying  reading  doc  expected  locating  work  way  html  property  threw,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3351,reduce  number  springbeanlocatorgetbeannameofclass  call  application  use  springbean  without  name  given  extensively  cause  performance  problem  due  fact  time  springbeanlocator  us  getbeannameofclass  method  look  bean  name  within  aplicationcontext  inhouse  improvement  cache  bean  name  localized  bean  annotproxyfieldvaluefactory  instance  springbeanlocator  gest  always  beanname  constructor  attached  source  code  speeded  app  40  attached  file  provides  improvement  143  version,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3352,injectorholdergetinjectorinjectthis  doesnt  work  wicketguice  using  wicketguice  integration  dependency  injection  provide  helper  mechanism  injectorholdergetinjectorinjectthis  class  extend  oawcomponent,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
3353,multiple  fileuploads  one  httpsession  possible  upload  file  one  httpsession  time  several  tab  uploadinfoobject  saved  session  set  null  first  succesful  upload  therefore  could  probably  save  map  uploadinfoobjects  instead  wouldnt  useful  besides  reason  dont  want  use  possibility  multiple  uploads  one  form,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3354,make  visitor  api  cleaner  clean  visitor  api  returning  magic  object  like  ivisitorcontinue  ivisitorcontinuebutdonotgodeeper  also  possible  return  null  visitor  currently  reserved  ivisitorcontinue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
3355,patch  allow  access  html  resource  associated  java  class  html  file  used  static  resource  wicket1x  accessible  packageresourceguard  block  html  extension  file  understand  application  html  file  associated  java  class  ohers  attachement  allow  nonapplication  html  file  used  resource  also  saw  trunk  html  file  used  static  resource  html  file  trunk,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3356,refactor  rework  pageability  need  add  navigatorlabel  gridview  navigatorlabel  constructor  accepting  datatable  dataview  pageablelistview  gridview  instead  creating  new  constructor  accepting  gridview  think  would  far  better  merge  ipageable  private  navigatorlabelpageablecomponent  single  public  interface  making  pageable  component  implement  interface  understand  approach  break  apis  need  one  major  version  maybe  two  allowing  deprecation  le  breaking  alternative  good  opinion  change  constructor  accepting  dataview  make  accept  abstractpageableview  common  ancestor  dataview  gridview  defines  method  needed  satisfy  navigatorlabelpageablecomponent,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3357,tag  attribute  value  escaped  properly  writeoutput  wicket741  double  quote  character  escaped  character  single  quote  ampersand  escaped  escaped  included  attribute  value  result  xml  compliant  xhtml  validation  mark  error  escaped  single  quote  used  instead  double  quote  tag  attributevalue  result  broken  double  quote  wicket741  im  sure  character  also  escaped  validatorsparsers  allow  mark  error  would  also  replace  suggest  adding  line  marked  componenttagwriteoutput  attribute  without  value  possible  eg  disabled  value  null  responsewrite  value  stringsreplaceallvalue  amp  added  value  stringsreplaceallvalue  34  value  stringsreplaceallvalue  39  added  value  stringsreplaceallvalue  lt  added  value  stringsreplaceallvalue  gt  added  responsewritevalue  responsewrite,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3358,backport  iheadercontributorrenderonloadjavascript  etc  backport  matejs  nice  little  onload  stuff  httpsvnapacheorgviewvcviewrevrevision505792,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3359,refactor  damage  control  irequestcycleprocessor  see  discussion  httpwwwnabblecomrefactordamagecontrolirequestcycleprocessortf3178965htmla8821208,1,0,0,0,0,0,0,1,0,0,1,1,1,0,1,1,0
3360,copy  attribute  wicketpanel  source  tag  page  like  code  div  wicketidcontent  code  two  type  panel  could  go  different  styling  im  currently  stuck  using  pointless  extra  div  code  wicketpanel  div  classstyle1  content  1  div  wicketpanel  code  wicket  allows  copying  attribute  wicketpanel  tag  source  tag  panel  would  become  lot  cleaner  neater  code  wicketpanel  classstyle1  content  1  wicketpanel  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3361,ability  pas  locale  getstring  function  localepublic  string  getstringfinal  string  key  final  component  component  final  imodel  model  final  locale  locale  final  string  style  final  string  defaultvalue  deprecated  functionality  readded  see  mailinglist  httpapachewicket1842946n4nabblecomgetresourcetranslationwithspecificlocaletp2247162p2247162html  thanks  marieke  vandamme,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3362,remove  irequesttargetgetlock  synchronize  block  using  synchronization  done  sessiongetpage  better  place  make  irequesttargetgetlock  redundant  remove  method  code  depends,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3363,abstractpropertymodel  getobjectclass  dont  consider  nested  iobjectclassawaremodel  target  currently  abstractpropertymodel  target  implement  iobjectclassawaremodel  interface  known  class  target  used  infer  modeled  property  type  requested  improvement  use  target  typeproperty  expression  return  property  type  abstractpropertymodel,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3364,implement  page  versioning  wicket  15  wicket  15  missing  page  versioning  functionality  currently  page  version  incremented  page  initial  load  init  version  0  component  addition  component  change  component  model  change  component  state  change  component  removal  point  component  involved  applicable  noauto  component  contrast  wicket  14  page  version  created  even  ajax  request  allow  support  browser  back  button  ajax  application,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3365,throw  illegalstateexception  already  implemented  oninitialize  method  discussed  devs  mail  list  oninitialize  method  may  already  implemented  user  component  next  release  throw  illegalstateexception  situation  imo  better  method  called  twice  im  sending  patch  implementation  test  related  note  oninitialize  javadoc  say  override  must  call  superlink  oninitialize  usually  first  thing  override  much  like  constructor  put  super  call  oninitialize  overriding  method  componentinitializationtest,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3366,refactor  authenticatedwebsession  class  introduce  defaultauthenticatedwebsession  class  experience  apache  wicket  spring  security  integration  came  conclusion  current  wicketauthroles  implementation  isnt  flexible  enough  usage  spring  security  form  login  http  basic  authentication  mechanism  definite  point  call  authenticatedwebsessionsignin  authenticatedwebsessionsignout  method  cause  login  logout  procedure  completely  managed  spring  security  think  authenticatedwebsession  refactored  following  public  abstract  class  authenticatedwebsession  extends  websession  public  abstract  role  getroles  public  abstract  object  getuser  public  abstract  boolean  issignedin  current  version  authenticatedwebsession  class  become  defaultauthenticatedwebsession  class  extends  authenticatedwebsession  point  opportunity  delegate  user  role  sign  state  management  framework  eg  spring  security  possible  use  custom  implementation  ie  subclass  defaultauthenticatedwebsession  moment  issignedin  method  declared  final  workaround  issignedinboolean  method  doesnt  look  pretty,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
3367,remove  headercontributor  friend  favor  iheadercontributor  0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3368,feedback  message  serializable  string  componenterror  currently  accepts  serializable  message  parameter  inconsistent  info  fatal  warn  whats  serializable  really  bad  idea  message  always  string  random  object  tostringed  tostring  really  bad  practice  generating  message  user  consumption  1  generally  bleeds  implementation  detail  2  generally  isnt  localized  often  impossible  localize  also  mean  feedbackmessagemessage  string  serializable  exact  reason,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3369,abstractresource  give  access  error  message  http  error  abstractresource  let  set  errorcode  something  go  wrong  custom  error  message  really  annoying  userdeveloper  get  hint  something  go  wrong  current  responsesenderrordatageterrorcode  null  always  null  custom  error  message  attached  simple  patch  fix,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3370,nice  practical  url  scheme  id  like  url  redesigned  currently  lot  issue  preserving  bookmarkable  url  action  page  preserving  page  state  using  ajax  page  bookmarkable  url  introducte  hybrid  url  url  would  contains  page  class  page  instance  id  example  url  mounted  page  hybrid  url  mypageparam1value125  url  entered  wicket  would  first  try  retrieve  page  id  25  page  found  would  check  whether  class  match  given  mount  point  would  show  page  otherwise  new  page  instance  would  created  url  would  redirected  eg  mypageparam1value131  31  would  new  page  instance  also  would  configurable  per  page  class  entering  bookmarkable  url  browser  would  automatically  redirected  hybrid  url  instance  user  enters  mypage  get  immediately  rendered  mypage4  4  new  page  instance  benefit  would  ajax  change  page  would  persisted  refreshing  page  case  current  bookmarkable  url,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3371,add  even  support  frontend  proxy  schema  client  ip  would  nice  something  like  httpcodegooglecompxebiafrancewikixforwardedfilter  core  people  life  would  lot  easier  really  quite  easy  add  actually  parsing  header  wrapping  original  request,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3372,add  timestamp  part  resource  filename  better  caching  even  though  getresourcesettingssetaddlastmodifiedtimetoresourcereferenceurl  still  far  perfect  add  query  parameter  resource  filename  cache  invalidate  parameter  change  however  caching  aggressive  altering  query  param  might  enough  stale  resource  left  cache  browser  intermediate  proxy  user  complain  tell  press  f5  clear  cache  whatever  decided  implement  support  adding  timestamp  resource  part  filename  resource  link  like  link  relstylesheet  typetextcss  hrefwicketresourcemygreatapphomepagecssstylecss  timestamp  last  modified  timestamp  file  injected  base  name  file  link  relstylesheet  typetextcss  hrefwicketresourcemygreatapphomepagecssstylets1282376261000css  format  pathcomponent  basefilename  t  timestampinmilliseconds  extension  prefix  t  t  timestamp  avoid  naming  conflict  filename  already  got  numeric  part  extension  locale  style  variation  taken  consideration  eg  stylecss  styledecss  styleencss  running  test  case  mockapplication  wickettester  provides  default  case  timestamps  disabled  check  rendered  markup  predictable  url  control  check  timestamp  behavior  getresourcesettingssetusetimestamponresources  getresourcesettingsgetusetimestamponresources  default  behavior  enabled  able  configure  resource  caching  large  lifetime  say  infinite  get  best  possible  network  performance  utilization  proxy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3373,pageparameters  api  verbose  need  optimized  method  name  long  chain,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3374,support  starting  formcomponentpanel  wickettester  normally  use  validator  error  feeback  behavior  component  like  textfields  ddc  simple  component  placed  panel  simply  tested  wickettester  use  formcomponentpanel  provide  way  adding  validator  error  feedback  behavior  container  cant  tested  simply  wickettester  cant  started  could  create  helper  panel  test  would  great  wicket  could  support  testing  component  easy  panel  page,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3375,add  irequestlistener  interface  allow  easier  framework  extension  point  see  httpapachewicket1842946n4nabblecomsessionattachtp3004389p3004681html  basically  add  interface  onbeginrequest  onendrequest  plugged  webrequestcycle  allows  framework  extension  plugin  listener  rather  extending  wrc  requiring  extend,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
3376,improve  homepagemapper  keep  url  redirect  currently  request  handled  homepagemapper  request  come  bookmarkablemapper  url  created  eg  link  form  redirects  etc  requesting  end  url  browser  address  bar  like  wicketbookmarkablecomexamplemypage  generated  bookmarkablemapper  final  url  bit  confusing  user  suggestion  improvement  drop  homepagemapper  use  mountedmapper  appgethomepage  instead  mapper  registered  systemmapper  asked  preconfigured  mapper  user  application  still  want  map  something  else  applicationgethomepage  addnew  mountedmapper  custompageclass,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3377,use  standard  exception  handling  ajaxrequesttarget  respond  method  ajaxrequesttarget  catching  runtimeexceptions  throwed  would  prefer  handle  exception  requesttarget  wrapper  wicket  ajaxrequesttarget  could  made  something  case  error  respond  method  ajaxrequesttarget  im  using  ajaxrequesttarget  replace  wizard  panel  case  error  would  display  error  panel  instance  original  panel,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3378,extra  clientside  scripting  closing  modalwindow  would  like  add  extra  clientside  scripting  executed  modalwindow  closed  already  add  serverside  overriding  onclosebuttonclicked  window  already  closing  need  want  show  confirmbox  user  confirm  want  close  window  thanks  marieke  vandamme,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3379,servlet  3  annotation  webfilter  supported  trying  run  application  way  webfiltervalue  urlpatterns  initparams  webinitparam  nameapplicationclassname  valuedelogviewerhomeapp  public  class  homefilter  extends  wicketfilter  result  follwing  exception  servletservice  servlet  default  threw  exception  javalangillegalargumentexception  error  initializing  wicketfilter  filtermapping  element  urlpattern  us  filter  delogviewerhomefilter  orgapachewicketprotocolhttpwicketfiltergetfilterpathwicketfilterjava930  orgapachewicketprotocolhttpwicketfilterinitwicketfilterjava677  orgapachecatalinacoreapplicationfilterconfiggetfilterapplicationfilterconfigjava259  orgapachecatalinacoreapplicationfilterchaininternaldofilterapplicationfilterchainjava237  orgapachecatalinacoreapplicationfilterchaindofilterapplicationfilterchainjava215  orgapachecatalinacorestandardwrappervalveinvokestandardwrappervalvejava277  orgapachecatalinacorestandardcontextvalveinvokestandardcontextvalvejava188  orgapachecatalinacorestandardpipelineinvokestandardpipelinejava641  comsunenterprisewebwebpipelineinvokewebpipelinejava97  comsunenterprisewebpesessionlockingstandardpipelineinvokepesessionlockingstandardpipelinejava85  orgapachecatalinacorestandardhostvalveinvokestandardhostvalvejava185  orgapachecatalinaconnectorcoyoteadapterdoservicecoyoteadapterjava325  orgapachecatalinaconnectorcoyoteadapterservicecoyoteadapterjava226  comsunenterprisev3servicesimplcontainermapperservicecontainermapperjava165  comsungrizzlyhttpprocessortaskinvokeadapterprocessortaskjava791  comsungrizzlyhttpprocessortaskdoprocessprocessortaskjava693  comsungrizzlyhttpprocessortaskprocessprocessortaskjava954  comsungrizzlyhttpdefaultprotocolfilterexecutedefaultprotocolfilterjava170  comsungrizzlydefaultprotocolchainexecuteprotocolfilterdefaultprotocolchainjava135  comsungrizzlydefaultprotocolchainexecutedefaultprotocolchainjava102  comsungrizzlydefaultprotocolchainexecutedefaultprotocolchainjava88  comsungrizzlyhttphttpprotocolchainexecutehttpprotocolchainjava76  comsungrizzlyprotocolchaincontexttaskdocallprotocolchaincontexttaskjava53  comsungrizzlyselectionkeycontexttaskcallselectionkeycontexttaskjava57  comsungrizzlycontexttaskruncontexttaskjava69  comsungrizzlyutilabstractthreadpoolworkerdoworkabstractthreadpooljava330  comsungrizzlyutilabstractthreadpoolworkerrunabstractthreadpooljava309  javalangthreadrunthreadjava662,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3380,strange  iresourcestream  type  hierarchy  current  type  hierarchy  look  like  iresourcestream  istringresourcestream  abstractresourcestream  abstractstringresourcestream  propobly  rather  iresourcestream  abstractresourcestream  istringresourcestream  abstractstringresourcestream,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,0
3381,urlresourcestream  load  target  content  twice  pageaclass  include  component  try  load  httplocalhost8080pageb  pagebclass  mounted  pageb  print  dummy  letter  class  initialized  web  server  requested  load  pagea  server  console  print  dummy  letter  twice  one  request  print  2  line  dummy  letter  traced  includeclass  us  urlresourcestreamclass  load  url  reading  source  found  urlresourcestreamclass  requested  url  twice  1st  constructor  2nd  getinputstream  amended  request  save  bandwithserver  time,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1
3382,new  feature  wickettester  new  method  executebehaviorfinal  abstractajaxbehavior  behavior  execute  ajax  behavior  executelistenercomponent  component  invoking  listener  assertresultpagefinal  class  pageclass  final  string  filename  assert  last  rendered  page  expected  html  document  file  assertresultpagefinal  string  expecteddocument  assert  last  rendered  page  expected  html  document  string,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3383,refactor  ibehavior  interface  concrete  class  discussion  vote  httpmarkmailorgthread4sqwjdvribsqdy3e,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3384,dont  use  see  upperclass  javadoc  inheritance  sufficient  see  time  see  orgapachewicketapplicationgetapplicationkey  override  public  final  string  getapplicationkey  return  getname  javadoc  link  parent  javadoc  using  see  required  since  javadoc  inheritance  enabled  default  unless  want  modify  javadoc  parent  class  sufficient  dont  declare  javadoc  le  work  better  result  override  public  final  string  getapplicationkey  return  getname  automatically  inherit  javadoc  method  override  quite  often  see  link  broken  refactoring  see  generates  lot  unnessecary  work  fix  link  refactors  make  javadoc  le  usable  shouldnt  abandon  style  documentation  parent  javadoc  fine  child,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3385,add  restartresponseatsigninpage  method  authenticatedwebapplication  situation  need  able  get  sign  page  class  outside  context  authenticatedwebapplication  class  subclass  basically  ive  got  spring  security  framework  thats  going  register  custom  exception  mapper  wrap  default  one  see  authenticationcredentialsnotfoundexception  need  throw  restartresponseatinterceptpagegetsigninpage  add  method  patch  coming,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3386,download  link  set  contenttype  contentlength  header  using  wicket  download  link  response  header  contenttype  contentlength  header  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3387,log  warn  throw  exception  ajaxformcomponentupdatingbehavior  added  choice  component  thinking  warn  console  stringformatajaxformcomponentupdatingbehavior  suposed  add  form  component  ajaxformchoicecomponentupdatingbehavior  meant  choicesgroups  one  component  html  many  getcomponentgetpagerelativepath  ajaxformcomponentupdatingbehaviorbind  detect  component  instance  radiochoice  checkboxmultiplechoice  radiogroup  checkgroup  dont  know  better  throw  exception  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3388,propose  removing  final  modifier  abstractsingleselectchoiceconvertvalue  creating  subclass  dropdownchoice  wanted  write  specialized  reverse  mapping  function  would  allow  option  value  used  primary  key  direct  lookup  object  unfortunately  abstractsingleselectchoiceconvertvalue  final  modifier  im  guessing  inside  joke  linear  search  chance  removing  final  modifier,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3389,springbean  support  nonsingleton  bean  two  fix  wicketspring  springbeanlocator  got  new  property  called  singletonbean  true  bean  singleton  property  set  constructor  wicketspringannot  annotproxyfieldvaluefactory  modified  bean  nonsingleton  bypass  cache,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3390,set  tabpanelstitel  escapemodelfalse  let  tabpanels  title  label  display  whatever  want  eg  setescapemodelstringfalse  need  callback  method  like  one  linke  one  protected  webmarkupcontainer  newlinkmarkupcontainer  parent  string  linkid  final  int  index  return  new  linkparent  linkid  private  static  final  long  serialversionuid  1l  override  public  void  onclick  setselectedtabindex  overwrite  eg  newlinklabel  method  annonymous  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3391,backport  link  hierarchy  trunk  link  hierarchy  trunk  cleaner  allows  disabled  ajax  link,1,1,1,0,1,1,0,0,0,0,0,1,1,0,0,0,0
3392,fix  documentation  error  review  model  review  newly  backported  model  bug  documentation  also  consider  remark  httpwwwnabblecommodelquirkstf3489227html  email  propertymodelpropertytypecomponent  never  called  see  non  existent  method  abstractpropertymodelpropertytypecomponent  boundcompoundpropertymodelpropertytypecomponent  ditto  make  boundcompoundpropertymodelbindingtype  worthless  compoundpropertymodel  since  dont  icompoundmodel  longer  shouldnt  class  better  named  inheritablepropertymodel  attachedcompoundpropertymodel  inner  class  implement  iinheritablemodel  superfluous  componentinitmodel  tested  iwrapmodel  ever  able  used  iinheritablemodel  iwrapmodel  iwrapmodelgetnestedmodel  name  class  method  misguiding  wrapping  model  inside  model  quite  common  wicket  see  propertymodel  javadoc  interface  mainly  used  marker  case  model  inherited  component  higher  hierarchy  see  componentinitmodel  markupcontainersetmodel  call  iinheritedmodel  getinheritablemodel  know  interface  used  iassingmentawaremodelwraponassignmentcomponent  method  could  equally  well  return  imodel  setcomponentcomponent,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3393,allow  iresourcestreamlength  return  1  iresourcestreamlength  return  1  wicket  resourcestreamrequesttargetresponse  send  contentlength  header  iresourcestream  doesnt  know  advance  number  byte  allows  send  response  without  buffering  whole  resouse,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3394,iheaderresponserenderonunloadjavascriptstring  javascript  renderonloadjavascript  ought  renderonunloadjavascript  copy  past  little  smelly  beyond  wouldnt  mind  able  specify  element  event  added  index  wicketsrcmainjavaorgapachewicketmarkuphtmlinternalheaderresponsejava  wicketsrcmainjavaorgapachewicketmarkuphtmlinternalheaderresponsejava  revision  529942  wicketsrcmainjavaorgapachewicketmarkuphtmlinternalheaderresponsejava  arbeitskopie  1974  19719  see  orgapachewicketmarkuphtmliheaderresponserenderonunloadjavascriptjavalangstring  public  void  renderonunloadjavascriptstring  javascript  list  token  arraysaslistnew  object  javascriptevent  unload  javascript  wasrenderedtoken  false  renderjavascriptreferencewicketeventreferenceinstance  javascriptutilswritejavascriptgetresponse  wicketeventaddwindow  unload  function  javascript  markrenderedtoken  index  wicketsrcmainjavaorgapachewicketmarkuphtmliheaderresponsejava  wicketsrcmainjavaorgapachewicketmarkuphtmliheaderresponsejava  revision  529942  wicketsrcmainjavaorgapachewicketmarkuphtmliheaderresponsejava  arbeitskopie  1744  17411  param  javascript  public  void  renderonloadjavascriptstring  javascript  render  javascript  executed  page  unloaded  param  javascript  public  void  renderonunloadjavascriptstring  javascript,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3395,investigate  whether  use  component  meta  data  storage  feedback  message  investigate  see  also  httpwwwnabblecomre3asvncommit3ar530991inincubatorwickettrunkjdk14wicketsrcmainjavaorgapachewicket3asessionjavafeedbackfeedbackmessagesjavap10119808html  advantage  oneone  mapping  concept  set  message  component  youll  never  worry  cleanup  clean  rendered  message  leave  unrendered  whenever  request  component  garbage  collected  disadvantage  central  storage  place  making  harder  track  probably  le  efficient  storage  processing,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3396,change  name  iformprocessinglistener  see  httpwwwnabblecomwhatistheusecaseforiformprocessinglistenertf3635720htmla10152501,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3397,formcomponentlabel  radio  since  radio  extends  webmarkupcontainer  instead  formcomponent  possible  set  formcomponentlabels  radiobuttons  since  desireable  able  click  label  select  radiobutton  would  nice  change  reflect  radio  really  formcomponent,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
3398,prevent  settimeout  ajaxselfupdatingtimerbehavior  firing  contributing  component  replaced  currently  settimeout  ajaxtimerbehavior  fire  contributing  component  replaced  removed  ajax  request  result  exception  server  side  full  page  refresh  client  side  one  possible  solution  override  getcallbackscript  enclose  ajax  callback  another  function  execute  ajax  request  markup  contributing  component  still  dom  tree  protected  charsequence  getcallbackscriptboolean  recordpageversion  string  mid  getcomponentgetmarkupid  stringbuilder  sb  new  stringbuilderexecfuncfunction  sbappendvar  el  wicketget  mid  sbappendifnull  el  sbappendsupergetcallbackscriptrecordpageversion  sbappend  sbappend  return  sbtostring  option  request  cycle  swallow  component  found  exception  timer  behavior  since  fire  1  extra  time  complicated  scheme  would  involve  wicket  actively  managing  javascript  timer  token  client  side  removed  cleartimeout  contributing  component  removed  ajax  request  javascript  would  trivial  simple  container  object  mapping  dom  id  timer  token  wicket  lifecycle  would  need  support  onremove  callback  component  perform  cleanup,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3399,textfield  determine  object  type  model  model  support  currently  mandatory  specify  type  model  object  textfields  constructor  convesion  work  properly  certain  model  propertymodel  compoundpropertymodel  wicket  determine  target  property  type  automatically,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3400,variation  javascriptheadercontributor  externaljavascriptheadercontributor  javascriptheadercontributor  contributes  reference  javascript  file  relative  context  externaljavascriptheadercontributor  allows  reference  javascript  file  long  reference  recognized  src  attribute  script  element  really  extension  rather  downtesnsion  since  externaljavascriptheadercontributor  equal  javascriptheadercontributor  line  code  prepend  getcontextpath  given  reference  mf,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3401,configuration  app  mode  isnt  customisable  everything  else  wicket  programatically  configurable  apart  deployment  development  app  mode  cant  set  system  property  due  security  constraint  dont  want  set  thing  webxml  tedious  already  deployment  id  im  using  configured  somewhere  else  using  spring  talked  ivaynberg  wicket  reckon  application  abstract  getconfigurationmodestring  function  overridden  webapplication  portletapplication  appropriately  replicate  current  functionality  default  implementation  final  override  pull  config  wherever  like  anyone  objection  changing  thing  work  like  please  shout  otherwise  supply  patch  1x  trunk  shortly,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3402,model  able  provide  information  fieldgettersetter  usable  eg  automatically  creating  validators  annotation,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
3403,tree  component  cleanup  remove  old  tree  wicketextensions  move  tree  treetable  core  extension  commit  new  tree  component  core,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3404,throw  error  image  found  testing  testing  came  across  following  error  junitframeworkassertionfailederror  expectedwebtestpage  wasdummyhomepage  real  error  gfxofflinegif  exist  change  file  exists  everything  go  fine  test  tomcat  get  proper  404  unable  find  package  resource  path  defaultgfxofflinegif  style  null  locale  en  see  also  httpwwwnabblecomjunittestingandnotexistingimagestf3907536html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3405,enhance  ichoicerenderer  idchoice  object  lookup  add  object  idtochoicestring  id  ichoicerenderer  add  class  choicerenderer  implement  ichoicerenderer  encapsulate  default  linear  search  remove  method  added  wicket348  support  custom  lookup,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
3406,bring  back  inspector  copy  inspector  completely  broken  shame  useful  tool  really  supported  anymore  give  people  sense  confidence  navigate  wicket  session  see  component  inspector  bring  inspector  back  could  following  thing  1  fix  inspector  need  factor  stack  trace  metadata  size  thing  accurate  inspector  cause  every  page  viewed  using  fail  page  expired  exception  2  add  security  setting  setinspectorenabled  default  false  disabled  unless  inspector  explicitly  enabled  constructor  every  publicly  accessible  bookmarkable  page  inspector  package  throw  illegalstateexception  explanation  must  safely  use  inspector  application  add  security  page  via  wicketauthroles  mean  call  setinspectorenabledtrue  enjoy  return  inspector,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3407,make  getconvertedinput  final  remove  final  convert  renamed  convertinput  see  httpwwwnabblecomre3ausegetconverterinputratherthanupdatemodelinformcomponentpanelp11399356html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3408,improve  pagestore  create  abstractfilestore  contains  deserialization  logic  create  simplesynchronousfilepagestore  demonstrate  developing  custom  pagestores  create  diskpagestore  us  one  file  per  pagemap  improve  performance  hight  load  move  page  version  infromation  sessionstore  pagestore  used  getting  page  1  specified  ajax  version  number  make  possible  certain  pagestores  reuse  serialized  page  data  serializing  pagemap  improve  clustering  efficiency,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3409,date  converter  try  use  component  coupled  get  locale  date  converter  try  use  component  coupled  get  locale  without  date  example  doesnt  use  appropriate  date  pattern,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3410,wrap  guiceinjector  proxying  object  since  guicecomponentinjector  already  proxying  support  build  id  like  use  inject  object  besides  component  function  like  guicecomponentinjectorinject  object  xy  would  great,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3411,backport  header  contribution  filtering  1x  attached  patch  backports  branch  1x  modification  made  rev461786  wicket  trunk  iheaderresponse  related  class  hope  help,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3412,update  imagebutton  handle  resourcereferenc  consistent  image  support  resourcereferences  imagebutton  modified  exhibit  behavior  new  constructor  method  added  existing  method  modified  behave  similiar  image  maintaining  button  construct,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3413,merge  portlet  support  branch  trunk  provide  easy  review  patch  core  wicket  change  required  merging  wicket130beta3portletsupport  branch  back  trunk  note  efficiency  reason  ill  provide  patch  beta3  release  merge  plan  accepted  ill  synchronize  latest  trunk  change  since  beta3  release  course  already  review  patch  going  delay  think  needed  right  also  indicated  martijn  dashorst  target  merge  beta4  cutoff  hope  go  rc  mode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3414,improve  multiple  distinct  aggregation  currently  tajo  provides  three  stage  optimizing  distinct  query  aggregation  support  one  column  distinct  aggregation  follows  codetitlequery1borderstylesolid  select  aflag  countdistinct  aid  cnt  sumdistinct  aid  total  table1  group  aflag  code  write  two  column  distinct  aggregation  cant  apply  optimized  distinct  aggregation  follows  codetitlequery2borderstylesolid  select  aflag  countdistinct  aid  cnt  sumdistinct  aid  total  countdistinct  aname  cnt2  countdistinct  acode  cnt3  table1  group  aflag  code  case  may  see  low  performance  query  thus  need  improve  multiple  distinct  aggregation  correctly  support  three  stage  multiple  distinct  aggregation,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3415,remove  hadoop  native  dependency  pullserver  currently  tajo  support  multiple  hadoop  version  binary  therefore  many  user  need  build  binary  remove  code  dependency  nativeio,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3416,improve  function  system  allow  function  implementation  type  current  function  system  function  implementation  single  java  class  subclassed  orgapachetajocatalogfunctionfunction  approach  many  room  improvement  approach  always  us  datum  input  output  value  function  creating  unnecessary  object  likely  exploit  given  information  included  query  statement  example  parameter  constant  variable  issue  propose  improvement  allow  function  system  support  function  implementation  type  addition  propose  three  function  implementation  type  legacy  java  class  function  provided  current  tajo  static  method  java  class  code  generation  asm  later  could  expand  feature  allow  pig  hive  function  tajo,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
3417,separate  sql  statement  catalog  store  developing  additional  catalog  store  another  database  system  needed  add  additional  sql  statement  trigger  index  sql  statement  could  increase  code  size  catalog  store  database  schema  changed  may  affect  catalog  store  source  code  feel  needed  separate  sql  statement  java  source  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3418,separate  logical  plan  optimizer  maven  module  already  bunch  code  logical  planner  optimizer  expression  expression  optimizer  played  key  role  tajo  project  tajo  evolved  many  part  started  require  planner  optimization  code  trying  make  good  use  planning  information  part  since  planner  optimization  part  included  tajocore  maven  module  depend  tajocore  biggest  maven  module  tajo  propose  separate  logical  planner  logical  optimizer  expression  expression  optimizer  tajocore  separate  maven  module,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
3419,concurrent  execution  independent  execution  block  currently  tajo  execute  executionblocks  one  one  even  though  remain  enough  resource  execute  two  executionblocks  improve  query  processing  performance  executing  two  independent  executionblocks  possible,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3420,improve  comparison  timestamp  date  type  see  discussion  httpsgroupsgooglecomdmsgtajouserkr5u8kmptlday0pntoalwdej  comparison  timestamp  date  may  widely  used  many  application  however  type  conversion  required  need  improve  comparison  two  type,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3421,remove  hadoop  dependency  tajoclient  module  tajoclient  client  module  allow  user  application  access  tajo  cluster  tajoclient  also  used  tajojdbc  since  tajoclient  depends  hadoopclient  module  jdbc  user  application  include  lot  thirdparty  library  hadoop  especially  hard  jdbc  single  jdbc  jar  main  purpose  issue  remove  hadoop  dependency  tajoclient  module  addition  ill  remove  dependency  tajoclient  possible,1,0,1,0,1,0,1,0,0,1,1,0,0,0,0,0,1
3422,implement  queryable  virtual  table  catalog  information  would  like  propose  queryable  interface  catalog  information  information  may  contain  table  column  information  tajo  catalog  currently  tajocli  offer  meta  command  retrieving  table  list  however  queryable  virtual  table  provide  handy  way  tajo  user,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
3423,refactor  improve  datum  datum  constructor  called  many  time  many  overhead  converting  primitive  string  change  lazy  datum  type  improve  memory  efficiency  improve  text  number  processing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3424,pluggable  line  deserializer  delimitedtextfile  delimitedtextfile  directly  par  line  delimited  text  file  par  line  csv  tsv  field  many  limit  deal  custom  textbased  file  format  patch  enables  delimitedtextfile  use  pluggable  line  de  serializer  first  add  abstract  class  userdefined  line  serde  class  follows  codejava  public  abstract  class  textlineserde  protected  schema  schema  protected  tablemeta  meta  protected  int  targetcolumnindexes  public  textlineserdeschema  schema  tablemeta  meta  int  targetcolumnindexes  thisschema  schema  thismeta  meta  thistargetcolumnindexes  targetcolumnindexes  public  abstract  void  init  public  abstract  void  buildtuplefinal  bytebuf  buf  tuple  tuple  throw  ioexception  public  abstract  void  release  code  also  added  table  property  textserdeclass  allows  user  specify  custom  line  serder  table  property  affect  text  file  format  specify  line  serder  follows  codesql  create  xxx  x  int  int  using  text  textserdeclass  orgapachetajostoragetextcsvlineserde  code,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3425,ha  tajoclient  connect  tajomaster  first  problem  tajoclient  opened  tajoclient  initially  try  connect  tajomaster  manner  guarantee  high  availability  known  tajomaster  host  may  work  anymore  manner  still  failure  point  also  manner  prohibits  tajo  cluster  run  dynamic  cluster  environment  like  yarn  solution  tajo  ha  client  get  directly  tajomaster  address  others  ha  component  without  contacting  tajomaster,1,0,1,0,1,0,1,0,0,1,0,0,0,0,0,0,1
3426,clean  logical  plan  json  format  current  implementation  logical  plan  us  ugly  json  document  format  need  cleanup  improve  format,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
3427,change  default  client  table  time  zone  behavior  default  tajoclient  us  gmt  client  time  zone  unless  session  variable  timezone  specified  also  default  table  us  gmt  table  time  zone  unless  table  property  timezone  specified  patch  change  default  behavior  follows  tajoclient  use  timezonegetdefault  default  table  implicitly  us  tajotimezone  default  word  default  time  zone  affect  table  property  catalog  also  added  documentation  time  zone  httppeopleapacheorghyunsiktimezonetimezonehtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3428,separate  query  ddl  execution  code  globalengine  code  cleanup  issue  patch  separate  query  execution  ddl  execution  hook  globalengine,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,0
3429,improve  memory  usage  hashshuffle  currently  hashshuffle  keep  intermediate  file  appender  tuple  list  memory  required  memory  proportion  input  size  input  size  10gb  hashjoin  key  partition  count  78125  10tb  128mb  required  memory  10gb  78125  128kb  improve  hashshuffle  file  writer  following  separate  buffer  file  writer  keep  tuples  offheap  buffer  reuse  buffer  flush  buffer  total  buffer  capacity  required  maxbuffersize  write  partition  file  asynchronously,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3430,cleanup  tajoasyncdispatcher  interrupt  stop  event  see  titile  tajoasyncdispatcher  implementation  copied  yarn  asyncdispatcher  log  message  handling  many  create  thread  interrupted  message  improve  stop  event  noformat  20141217  100835327  warn  orgapachetajomastertajoasyncdispatcher  stop115  interrupted  exception  stopping  20141217  100835328  warn  orgapachetajomastertajoasyncdispatcher  stop115  interrupted  exception  stopping  20141217  100836896  warn  orgapachetajomastertajoasyncdispatcher  stop115  interrupted  exception  stopping  20141217  100836898  warn  orgapachetajomastertajoasyncdispatcher  stop115  interrupted  exception  stopping  20141217  100837745  fatal  orgapachetajomastertajoasyncdispatcher  dispatch143  error  dispatcher  threadqueryjobheartbeat  orgapachehadoopyarnexceptionsyarnruntimeexception  javalanginterruptedexception  orgapachetajomastertajoasyncdispatchergenericeventhandlerhandletajoasyncdispatcherjava204  orgapachetajomasterquerymasterqueryinprogressheartbeatqueryinprogressjava290  orgapachetajomasterquerymasterqueryinprogressaccess000queryinprogressjava53  orgapachetajomasterquerymasterqueryinprogressqueryinprogresseventhandlerhandlequeryinprogressjava196  orgapachetajomasterquerymasterqueryinprogressqueryinprogresseventhandlerhandlequeryinprogressjava192  orgapachetajomastertajoasyncdispatcherdispatchtajoasyncdispatcherjava137  orgapachetajomastertajoasyncdispatcher1runtajoasyncdispatcherjava79  javalangthreadrunthreadjava701  caused  javalanginterruptedexception  javautilconcurrentlocksabstractqueuedsynchronizeracquireinterruptiblyabstractqueuedsynchronizerjava1222  javautilconcurrentlocksreentrantlocklockinterruptiblyreentrantlockjava340  javautilconcurrentlinkedblockingqueueputlinkedblockingqueuejava269  orgapachetajomastertajoasyncdispatchergenericeventhandlerhandletajoasyncdispatcherjava199  7  20141217  100837746  warn  orgapachetajomastertajoasyncdispatcher  stop115  interrupted  exception  stopping  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3431,remove  hadoopcommon  dependency  tajorpc  tajorpc  depends  hadoopcommon  due  one  integer  configurable  parameter  result  naturally  depends  lot  thirdparty  library  main  objective  issue  remove  hadoopcommon  dependency  tajorpc  maker  tajo1160  easier,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3432,cleanup  relationship  queryinprogress  queryjobmanager  queryinprogress  instance  maintains  individual  event  handler  involving  thread  complicates  relationship  queryjobmanager  queryinprogress  main  objective  issue  remove  event  handler  queryinprogress  distinguishes  role  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3433,refactoring  orgapachetajomaster  package  orgapachetajomaster  includes  mixed  class  tajomaster  querymaster  look  somewhat  messy  patch  refactors  located  proper  package  especially  follows  move  class  orgapachetajoquerymaster  move  orgapachetajoscheduler  orgapachetajomasterscheduler  move  class  orgapachetajomaster  tajoapachetajomasterexec  move  class  orgapachetajomaster  orgapachetajoha  remove  fragmentpair  scheduledfetch  querymasterrunner  unused  move  abstractdefault  taskscheduler  taskscheduler  orgapachetajoquerymaster  move  issue  class  nobody  seems  working  package  think  change  refactor,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3434,rename  tajomasterprotocol  querycoordinatorprotocol  tajomaster  mainly  three  role  query  coordination  including  query  scheduler  cluster  resource  management  client  endpoint  tajomasterprotocol  played  role  query  coordinator  name  expressive  term  purpose  patch  proposes  rename  tajomasterprotocol  querycoordinatorprotocol,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,1
3435,haserviceutil  directly  use  hdfs  haserviceutil  tightly  coupled  hdfs  filesystem  plan  implement  multiple  ha  implementation  like  hdfs  zookeeper  need  abstract  support  multiple  implementation  also  force  tajoclient  hadoop  hdfs  dependency  decouple  using  hdfs  haserviceutil  eliminate  hdfs  dependency  tajoclient,1,0,1,0,1,0,1,0,0,1,1,0,0,0,0,1,0
3436,support  compressiondecompression  csvfile  currently  textfile  support  compressiondecompression  utilizing  hadoop  compressioncodecfactory,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
3437,change  default  output  file  format  currently  default  output  file  csv  due  nature  csv  mainly  three  problem  line  field  delimiter  duplicated  character  included  result  data  plan  text  file  likely  larger  file  format  read  write  performance  slow  need  change  default  output  file  format  file  format  also  need  investigate  file  format  best,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3438,improve  memory  usage  physical  executor  introduction  basically  tuple  instance  maintained  singleton  physical  operator  however  memorybased  operator  type  need  keep  multiple  tuples  memory  operator  multiple  instance  must  created  tuple  problem  currently  temporal  routine  avoid  unexpected  problem  due  singleton  instance  tuple  however  methodology  inconsistent  complex  cause  unexpected  bug  solution  consistent  methodology  needed  handle  problem  operator  keep  multiple  tuples  memory  must  maintain  tuples  separate  instance,1,0,1,0,1,0,1,0,1,0,0,0,0,1,0,0,1
3439,python  udf  support  python  abundant  user  thirdparty  library  language  widely  used  data  analytic  area  would  great  tajo  support  python  udf,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3440,bump  hadoop  220  hadoop  220  released  need  bump  hadoop  220  hadoop  version  us  protobuf250  tajo  also  need  bump  protobuf250,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3441,refactor  filterpushdownrulevisitjoin  welldefined  small  method  filterpushdownrulevisitjoin  long  complicated  handle  various  case  single  method  need  refactor  method  several  small  welldefined  method,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3442,improve  join  order  algorithm  consider  missed  case  associative  join  operator  tajo1277  fix  bug  related  associativity  join  operator  still  missed  case  join  operator  associative  work  include  case  described  following  link  httpstackoverflowcomquestions20022196areleftouterjoinsassociative  httpscwikiapacheorgconfluencedisplayhivelanguagemanualjoins,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3443,support  multibytes  delimiter  csv  file  support  multicharacter  nonascii  delimiter  csv  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3444,improve  broadcast  table  cache  currently  broadcast  implementation  keep  tuples  scan  operator  create  duplicated  table  cache  memory  improve,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0
3445,remove  locking  rmcontext  seemed  necessary,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3446,predicate  support  see  title  predicate  basic  part  sql  standard  need  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3447,rpcconnectionpool  check  reference  counter  connection  close  connection  pool  shared  one  closed  referenced  thread  furthermore  current  pool  implementation  lock  whole  connection  connectingclosing  connection  making  bad  interference  operation  sane  connection,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1
3448,support  reconnect  tsql  development  need  restart  tajomaster  frequently  restart  tsql  client  also  little  annoying  new  option  reconnect  tsql  make  life  easier  little  bit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3449,minor  performance  improvement  memsortexec  currently  tajo  us  collectionssort  tuplecompartor  incur  overhead  comparing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3450,make  intermediateentryproto  compact  listpairlong  pairinteger  integer  long,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3451,implement  hash  antijoin  operator  hash  antijoin  operator  used  clause  need,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3452,support  explain  global  get  physical  plan  inconvenient  see  log  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3453,add  bind  method  evalnode  evalnode  eval  method  evaluate  tuples  method  prepare  actual  execution  example  fieldeval  know  actual  field  index  input  tuple  process  also  performed  eval  method  problem  eval  method  involve  two  work  different  behavior  flag  null  check  condition  eval  method  different  behavior  involves  unnecessary  branch  causing  performance  degradation  add  bindschema  method  evalnode  move  preparation  code  eval  bindschame  method  also  refactor  signature  evalschema  tuple  evaltuple,1,1,0,0,0,1,0,0,0,0,0,1,1,0,0,0,1
3454,implement  insert  overwrite  clause  insert  appends  data  existing  table  contrast  insert  overwrite  overwrite  existing  table  data  used  idiom  analytical  field  based  hdfs  need,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3455,improve  hive  compatibility  currently  hive  released  110  also  hive  0140  changed  hcatalog  package  name  tajo  provides  hive  0120  hive  0131  thus  need  improve  hive  compatibility  issue  i’ll  remove  hcatalog  dependency  it’s  problem  hcatalog  used  find  hive  data  type  tajo  find  right  data  type  hive  serdeconstants,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
3456,countdistinct  column  supported  distinct  included  count  function  supported  code  select  countdistinct  col1  table  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3457,comparing  two  date  two  timestamp  need  normalizing  date  timestamp  type  converted  normalized  form  timemeta  comparing  even  datum  type,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3458,apply  tajo1407  externalsortexec  tipped  hyoungjun  kim  seemed  possible  apply  easily,1,1,1,0,1,1,0,0,1,0,1,1,0,0,0,0,0
3459,eliminate  queryconf  file  write  queryconf  subclass  orgapachehadoopconfconfiguration  similar  mechanism  jobconf  mapreduce  overhead  big  distributed  across  number  node  ive  added  querymeta  patch  tajo144  querymeta  contains  set  keyvalue  pair  based  protobuf  since  querymeta  wrapper  class  protobuf  message  contain  specific  information  query  lightweight  easy  disseminated  across  number  node  issue  replace  queryconf  querymeta  eliminate  part  queryconf  written  xml  file  hdfs,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
3460,add  seekablescanner  support  delimitedtextfilescanner  csvfile  deprecated  delimitedtextfilescanner  support  seekablescanner  interface  bstindex,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
3461,clean  catalogstore  currently  catalogstore  designed  read  schema  xml  file  initial  mode  mysqlstore  mariadbstore  read  sql  statement  file  thus  need  clean  file,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3462,use  dedicated  thread  release  resource  allocated  container  currently  us  thread  pool  used  launching  task  make  deadlock  situation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3463,refactoring  hashjoinexecs  condition  make  improvement  offense,1,1,1,0,1,1,0,0,0,0,0,1,1,0,0,0,0
3464,improve  broadcast  join  planning  global  engine  generates  logical  plan  mark  part  plan  broadcast  plan  mean  input  broadcasted  worker  currently  broadcast  part  identified  according  rigid  hardcoded  rule  limit  broadcast  opportunity  many  case  issue  propose  refactoring  broadcast  planner  general  brief  rule  broadcast  join  plan  relation  node  broadcastable  input  size  exceed  predefined  threshold  output  execution  block  eb  broadcastable  every  input  broadcastable  given  eb  containing  join  child  eb  eb  merged  single  eb  least  one  child  eb  output  broadcastable  total  size  broadcast  relation  eb  cannot  exceed  predefined  threshold  merging  eb  according  first  rule  result  eb  may  satisfy  second  rule  case  enforce  repartition  join  large  relation  satisfy  second  rule  outer  join  preservedrow  relation  broadcastable  avoid  input  data  duplication  full  outer  join  cannot  executed  broadcast  join  brief  background  rule  data  preservedrow  relation  appeared  join  result  regardless  join  condition  multiple  task  execute  outer  join  broadcasted  preservedrow  relation  emit  duplicate  result  even  though  single  task  execute  outer  join  every  input  broadcastable  broadcast  join  allowed  one  input  relation  consists  multiple  file,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3465,python  udaf  support  need  support  python  udaf  well  udf  tajo1344,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,1,1
3466,add  test  case  verify  join  plan  lacking  test  case  verify  query  plan  even  though  directly  affect  query  processing  performance  important  especially  join  query  plan  changed  optimizing  join  order  affect  performance  significantly  need  verify  optimal  join  plan  first  approach  test  query  plan  candidate  consider  adding  special  class  verifies  query  plan  traversing  verifying  result  explain  query  think  second  approach  look  good  reason  easy  implement  string  match  easy  verify  logical  plan  global  plan  without  adding  special  class  traverse  query  plan  important  reason  second  approach  guarantee  query  planner  deterministic,1,0,1,0,1,0,0,0,0,1,1,0,0,0,1,0,1
3467,remove  querymaster  client  sharing  tajomaster  tajoworker  querymaster  client  remove  use  possible  connection  refused  large  cluster  many  open  connection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3468,insert  wrong  target  column  cause  npe  h3  reproduce  code  create  table  t1  col1  int  col2  int  insert  t1  col1  col3  select  lorderkey  lpartkey  defaultlineitem  code  target  column  name  wrong  ie  col3  insert  statement  query  cause  npe,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3469,removing  rest  api  create  table  post  databasesdatabasenametables  interface  currently  post  databasesdatabasenametables  interface  hard  use  serialize  tabledesc  class  think  using  query  interface  better  create  table  interface  changed  result  query  interface  removing  location  header  add  response  body  query  resultcode  urlif  query  finished  directlry  uri  isnt,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3470,allow  tajo  use  hive  udf  hive  widely  used  area  many  user  maintained  lot  big  table  hive  metastore  using  hiveql  udfs  currently  tajo  provides  udf  hive  user  implement  udfs  tajo  wrap  hive  udf  tajo  seems  would  able  use  tajo  easily  analysis  infrastructure,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3471,tajo  java  client  version  2  propose  tajo  java  client  version  2  motivation  follows  tajo1625  error  propagation  changed  significantly  java  client  make  use  new  error  propagation  system  java  client  throw  proper  exception  many  java  api  expose  internal  data  structure  protocol  buffer  data  structure  requires  user  understand  internal  behavior  architecture  hide  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3472,precompute  hash  value  various  kind  id  queryid  executionblockid  taskid  taskattemptid  used  key  hashmap  statically  maintaining  hash  value  improve  performance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3473,jdbc  tablespace  support  main  objective  issue  implement  jdbcbased  storage  tablespace  implementation,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
3474,improve  offheap  rowblock  offheaprowblock  added  tajo907  support  memory  pooling  already  use  netty  pooledbytebufallocator  delimitedtextfile  easy  add  implementation  pooledbytebufallocator,1,0,1,0,1,0,0,1,1,1,1,0,1,0,0,0,1
3475,add  example  tajoclient  v2  patch  add  example  code  tajoclient  v2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3476,implement  tajo  jdbc  driver  tajo  required  integrated  legacy  bi  olap  tool  tajo  provide  jdbc  driver,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
3477,improve  performance  cross  join  cross  join  one  heavy  operation  furthermore  operator  performed  single  worker  current  implementation  please  see  implementation  hashpartitioner  partitionkeyids  empty  getpartition  always  return  single  value  one  possible  alternative  executing  cross  join  broadcast  join  outer  table  smaller  one  always  broadcasted  join  performed  machine  store  part  inner  table  new  session  variable  required  set  broadcast  threshold  cross  join,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3478,move  tajo  java  8  discussed  mailing  list  httpsearchhadoopcommzgio9xqitpkrul7java8subjdiscussionmigrationtojava8  patch  move  tajo  java  8  change  language  level  maven  fix  unit  test  failure,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3479,implement  storagemanager  scanning  asynchronously  current  storagemanager  provide  scan  scheduling  function  scan  operation  run  concurrently  cause  random  disk  access  disk  read  performance  good  proposed  storagemanager  based  double  buffering  disk  scheduler  schedule  order  scanned  adjust  scanner  inputstream  tuple  pool  next  operation  scannode  blocked  tuple  pool  filled  assigned  scanner  scheduler  read  dataxmb  fill  tuple  pool  notifies  next  operation  scanning  scanner  reenter  diskscanqueue  way  scanner  pas  column  vector  vectorized  query  engine  see  attached  file,1,1,1,0,1,1,0,0,0,1,0,0,0,0,0,0,0
3480,tajoclustertests  available  used  external  maven  module  tajoclustertests  separated  order  help  maven  module  use  cluster  test  actually  unavailable  test  resource  table  ddl  data  set  accessed  absolute  path  patch  make  test  resource  accessable  maven  module,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3481,remove  querymastertask  cache  immediately  stored  persistent  storage  query  information  stored  asyncronously  persistent  storage  exist  lru  cache  cache  entry  removed  immediately  stored  persistent  storage,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
3482,separate  sql  parser  independent  maven  module  patch  move  sql  parser  part  tajoparsersql  maven  module  required  tajo1817,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3483,creating  many  tablemetaproto  object  might  lead  potential  memory  leak  current  tablemetaimpl  pb  object  created  every  getproto  call  since  tablemetagetproto  called  creating  fragment  current  implementation  shall  cause  memory  exception  many  pb  object  created  large  data,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3484,add  shutdown  hook  manager  order  set  priority  sometimes  eventgroup  thread  netty’s  stopped  jvm  start  shutdownhook  thread  stopped  without  kill  signal  deadlock  state  explicitly  call  shutdown  eventgroup  thread  netty’s  set  shutdownhook  order  example  start  tajomaster  run  tsql  find  deadlock,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
3485,well  support  selfdescribing  data  format  problem  tajo  already  support  selfdescribing  data  format  like  json  parquet  orc  capable  providing  schema  information  user  must  define  schema  query  current  implementation  solve  inconvenience  improve  query  planner  support  selfdescribing  data  format  well  solution  first  need  allow  omitting  schema  definition  create  table  statement  query  submitted  selfdescribing  table  column  dont  exist  table  filled  null,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3486,refactor  globalplanner  global  plan  data  structure  im  sorry  submitting  big  patch  patch  modifies  refactors  broadly  global  planning  logical  planning  physical  planning  part  hard  separate  issue  smaller  issue  especially  patch  primarily  rewrite  globalplanner  masterplan  global  plan  data  structure  follows  removed  globalplanoptimizer  added  directedgraph  interface  simpledirectedgraph  concret  class  visitor  class  visit  graph  postorder  traverse  way  improved  masterplan  using  new  graph  api  query  block  graph  execution  block  graph  represented  simpledirectedgraph  traverse  graph  easily  using  graph  apis  added  datachannel  class  represent  data  flow  execution  block  masterplantostring  print  text  graph  represent  relationship  among  execution  block  distributed  plan  add  sophisticated  explain  feature  distributed  plan  logical  plan  useful  plan  debugging  limit  operator  pushed  child  execution  block  intermediate  data  volume  sort  query  limit  reduced  significantly  tablesubquery  inline  view  supported  follows  sql  standard  query  follows  code  select  select  lorderkey  lpartkey  url  select  lorderkey  lpartkey  case  lpartkey  null  lorderkey  1  1  else  2  end  url  lineitem  res1  join  select  part  res2  lpartkey  ppartkey  result  code  addition  ive  refactored  follows  column  qualifier  name  improved  schema  deal  qualified  column  name  tabledesc  instance  retrieved  forced  qualifier  column  fixed  tajo162  bug  lot  trivial  improvement  refactors,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,1
3487,using  tutilnewhashsetmap  replaced  java  diamond  operator  see  title  introduced  java  7  dont  need  tutilnewhashsetmap  utility  method  anymore  need  eliminate,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3488,refactor  rpc  client  take  connection  parameter  currently  rpc  client  implementation  take  parameter  refactoring  allows  rpc  client  take  flexible  parameter  also  add  connection  timeout  cleaned  routine,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
3489,add  string  pattern  matching  operator  patch  add  pattern  matching  operator  ilike  similar  regex  operator  improves  like  operator  addition  improves  null  handling  string  pattern  matching  operator  also  ive  added  manual  query  language  wiki  page  httpswikiapacheorgtajoquerylanguagepatternmatching,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3490,logicalnode  identifier  distinguish  logical  node  instance  part  logicalplan  instance  object  id  used  key  map  data  identifier  distinguish  logical  node  instance  would  better  current  implementation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3491,implement  hbasetablespacegettablevolume  method  table  volume  important  role  query  planning  tajos  query  optimizer  make  many  decision  based  table  volume  currently  available  statistic  however  hbasetablespace  doesnt  support  gettablevolume  method  plan  good  query  involves  hbase  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3492,query  master  us  much  memory  range  shuffle  ran  simple  sort  query  8tb  table  follows  noformat  tpch10tb  select  lineitem  order  lorderkey  noformat  first  stage  completed  query  master  divide  range  sort  key  lorderkey  multiple  partition  range  shuffle  partitioning  time  took  9  minute  log  noformat  20151026  142310782  info  orgapachetajoengineplannerglobalparallelexecutionqueue  next  executable  block  eb14458354388020004000002  20151026  142310782  info  orgapachetajoquerymasterquery  scheduling  stageeb14458354388020004000002  20151026  142310796  info  orgapachetajoquerymasterstage  orgapachetajoquerymasterdefaulttaskscheduler  chosen  task  scheduling  eb14458354388020004000002  20151026  142310796  info  orgapachetajoquerymasterstage  eb14458354388020004000002  table  volume  approximately  663647  mb  20151026  142310796  info  orgapachetajoquerymasterstage  eb14458354388020004000002  determined  number  nonleaf  task  10370  20151026  142310816  info  orgapachetajoquerymasterrepartitioner  eb14458354388020004000002  try  divide  6000000000  1  10370  sub  range  total  unit  10370  20151026  142458996  info  orgapachetajoutiljvmpausemonitor  detected  pause  jvm  host  machine  eg  gc  pause  approximately  2440ms  gc  pool  p  marksweep  collection  count1  time2214ms  gc  pool  p  scavenge  collection  count1  time622ms  20151026  142724040  warn  orgapachetajoutiljvmpausemonitor  detected  pause  jvm  host  machine  eg  gc  pause  approximately  13237ms  gc  pool  p  marksweep  collection  count1  time12635ms  gc  pool  p  scavenge  collection  count1  time674ms  20151026  142851914  warn  orgapachetajoutiljvmpausemonitor  detected  pause  jvm  host  machine  eg  gc  pause  approximately  20873ms  gc  pool  p  marksweep  collection  count1  time20486ms  gc  pool  p  scavenge  collection  count1  time644ms  20151026  143052392  warn  orgapachetajoutiljvmpausemonitor  detected  pause  jvm  host  machine  eg  gc  pause  approximately  30986ms  gc  pool  p  marksweep  collection  count1  time30546ms  gc  pool  p  scavenge  collection  count1  time696ms  20151026  143207550  warn  orgapachetajoutiljvmpausemonitor  detected  pause  jvm  host  machine  eg  gc  pause  approximately  15449ms  gc  pool  p  marksweep  collection  count1  time14593ms  gc  pool  p  scavenge  collection  count1  time1148ms  20151026  143215807  info  orgapachetajoquerymasterstage  10370  object  scheduled  noformat,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
3493,implement  enforcer  force  physical  planner  choose  specified  algorithm  tajo  worker  generates  physical  plan  logical  plan  received  querymaster  however  plan  need  force  physical  planner  choose  specified  algorithm  traditionally  enforcer  play  role  provide  physical  property  query  plan  enforce  physical  algorithm  also  need  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3494,improve  memory  usage  externalsortexec  externalsortexec  keep  tuple  list  sort  cause  many  gc  change  offheap  tuple  instead  vtuple,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3495,rename  name  option  property  tablemeta  trivial  patch  rename  option  property  tablemeta  necessary  make  naming  consistent,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3496,insert  select  support  insert  select  statement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3497,rcfile  compatible  apache  hive  support  text  binary  serializationdeserialization  dafault  orgapachetajostoragebinaryserializedeserialize  use  sequencefilemetadata  key  rcfileserde  value  orgapachetajostoragebinaryserializedeserialize  orgapachetajostoragetextserializedeserialize  improve  memory  efficiency  support  tajo  pushdown  projection  support  compression,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
3498,add  tablestatupdaterewriter  currently  set  table  volume  tabledesc  logicalplanner  case  cannot  employ  pushdowned  filter  getting  table  volume  postpone  getting  table  volume  late  possible  join  ordering  optimization  patch  move  table  stat  update  code  last  rewrite  rune  pre  rewriter,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
3499,default  optimizer  use  table  volume  tablestat  currently  optimizer  default  get  table  volume  storage  manager  employ  join  optimization  case  cause  performance  degradation  aggregating  file  volume  cheap  large  partitioned  table  s3  hdfs  patch  improves  tablestatupdaterewriter  use  table  volume  tablestat  default  also  add  session  variable  usetablevolume  allow  optimizer  use  table  volume  storage  handler,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3500,add  asynctaskserver  tajomaster  tajomaster  performs  various  task  query  lifetime  task  likely  easily  delayed  sometimes  may  main  cause  unnecessary  blocking  problem  patch  add  asynctaskserver  run  delayed  task  asynchronous  way,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3501,querymaster  tajoworker  support  exception  propagation  error  propagation  system  refactored  tajo1625  worker  query  master  missing  tajo1625  issue  improve  error  propagation  system  tajoworker  querymaster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3502,upgrading  orc  reader  version  currently  tajo  us  prestoorc086  old  version  even  integrated  presto  using  jdk  18  time  tajo  based  jdk  18  upgraded  recent  version  0132  becomes  robust  minor  feature  added  additionally  hive  compatibility  improved  upgrading  necessary  support  hivecatalog,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3503,error  progress  update  use  stderr  instead  stdout  error  progress  update  message  separated  stderr  want  use  tsql  c  command,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3504,implement  adapter  legacy  schema  see  tajo2042  issue  ill  implement  adapter  legacy  new  schema  implementation,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0
3505,apply  new  identifier  system  new  schema  patch  applies  tajo2104  new  schema  system,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3506,refactor  schema  immutable  order  make  schema  simplified  need  refactor  immutable  object,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3507,implement  radix  sort  radix  sort  known  fast  sort  algorithm  length  sort  key  long  benefit  radix  sort  used  faster  tim  sort  issue  implement  radix  sort  tajo  conduct  benchmark  test  compare  performance  tim  sort,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3508,implement  regexpreplace  function  regexpreplace  function  replaces  substring  matched  given  regular  expression  like  function  follow  postgresql  nonstandard  function  following  noformat  regexpreplacestring  text  pattern  text  replacement  text  noformat,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,1,0
3509,improve  disk  load  query  run  simultaneously  currently  tajo  us  tajoworkerresourcedisks  resource  scheduler  effect  read  performance  leaf  task  consider  run  query  simultaneously  disk  load  control  move  worker  node  instead  scheduler,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
3510,simplify  rpc  address  default  configuration  cluster  mode  set  binding  address  following  configuration  tajocatalogclientrpcaddress  tajoresourcetrackerrpcaddress  server  tajomasterumbilicalrpcaddress  configuration  set  use  tajomasterumbilicalrpcaddress  default  connecting  hostname  codexml  property  nametajomasterumbilicalrpcaddressname  valuehostname26001value  property  property  nametajomasterclientrpcaddressname  valuehostname26002value  property  property  nametajoresourcetrackerrpcaddressname  valuehostname26003value  property  property  nametajocatalogclientrpcaddressname  valuehostname26005value  property  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3511,implement  type  cast  expression  need  implement  type  cast  expression  defined  noformat  cast  expression  type  expressiontype  noformat,1,0,1,0,1,0,0,0,0,1,0,0,1,0,0,0,1
3512,pullserver  auxiliary  service  yarn  going  support  yarn  tajos  one  resource  scheduler  pullserver  capable  executing  auxiliary  service,1,1,1,0,1,1,0,1,1,0,1,0,0,0,0,1,1
3513,use  type  instead  datatype  evalnode  see  tajo2042  tajo2043  issue  change  return  type  evalnodegetvaluetype  orgapachetajotypetype  related  code  also  ill  converter  order  keep  existing  apis,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3514,apply  new  type  implementation  schema  catalog  see  tajo2042  main  objective  issue  apply  new  type  schema  column  catalog  test  ive  added  array  map  type  ddl  statement,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1
3515,null  character  meta  csv  table  supported  n  represents  default  null  value  hive  get  default  null  value  empty  string  without  text  column  add  table  option  null  value,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3516,fragment  interface  cleanup  need  improve  fragment  interface  consistent  various  type  fragment,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
3517,implement  example  http  tablespace  see  discussion  httpmailarchivesapacheorgmodmboxtajodev201605mboxbrowser  tikcet  implement  simple  example  http  tablespace,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3518,add  alter  table  unset  property  statement  tajo  ddl  version  011x  set  statement  table  property  user  make  typo  ddl  statement  mistake  cannot  removed  also  need  way  remove  already  set  property,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3519,maximize  disk  read  bandwidth  utilization  storagemanagerv2  moving  tuple  creation  role  next  currently  tuple  creation  mechanism  storagemanagerv2  follows  1  file  scan  scheduled  scanner  read  data  disk  make  tuple  insert  tuple  pool  2  next  scanner  pull  already  created  tuple  tuple  pool  asynchronously  tuple  creation  time  scanner  cannot  fully  use  time  read  disk  result  le  disk  read  bandwidth  utilization  tuple  creation  role  moved  next  scanner  spend  whole  time  read  file  file  scan  fully  utilize  disk  read  bandwidth,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3520,rearrange  datatype  enumeration  refactor  type  system  patch  rebuilds  datatype  enumeration  refactors  type  system  efficiency  extendibility  type  detail  follows  remove  array  return  value  evalnode  function  catalog  operator  function  expression  return  one  data  type  instead  data  type  array  add  typeprotobuf  type  enables  tajo  use  protocol  buffer  class  type  remove  arraydatum  typearray  used  function  requiring  return  two  value  instead  use  generated  protobuf  type  return  type  add  rich  data  type  datatypetype  add  protobufdatum  protobufdatumfactory  help  create  builder  data  type  cleanup  catalog  many  others,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3521,rename  join  operator  add  join  operator  physicalplanner  current  physical  operator  join  different  naming  rule  follows  leftouterhashjoin  fullouterhashjoin  hashsemijoin  hashantijoin  patch  renames  join  operator  consistency  follows  algorithmjoin  type  join  example  outer  join  following  name  hashleftouterjoin  mergerightouterjoin  hashfullouterjoin  patch  add  join  algorithm  left  semianti  hash  join  physical  operator  add  insubquery  clause  exists  predicate  tajo  algebra,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3522,support  postgresql  catalogstore  see  title  postgresql  also  widely  used  open  source  dbms  like  tajo179  need  support  postgresql  catalog  store,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3523,implement  logicalplanverifier  check  logical  plan  valid  current  tajo  verification  system  check  whether  logical  plan  valid  logicalplanverifier  verify  following  logical  plan  operand  type  checking  operator  type  restriction  example  plus  operand  must  numerical  value  table  column  existence  check  example  follows  create  table  statement  must  check  table  already  exists  column  included  select  list  must  exist  corresponding  table,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3524,improving  web  ui  tajo  web  ui  need  improved  convenient  management,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
3525,cleanup  exception  engine  patch  remove  unused  exception  move  exception  proper  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3526,rearrange  default  port  number  config  name  tajo  us  many  port  number  config  property  inconsistent  main  objective  issue  rearrange  default  port  number  config  property  also  make  wiki  page  describe,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3527,protocol  buffer  deserialization  logicalnode  current  implementation  logical  plan  serialized  json  object  sent  worker  however  transmission  json  object  incurs  high  overhead  due  large  size  protocolbuffer  good  alternative  overhead  quite  small  already  used  module  tajo,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
3528,boolean  datum  compatible  apache  hive  current  implementation  boolean  datum  compatible  apache  hive  sample  data  code  1  true  code  hive  cli  code  hive  select  booltest  ok  null  null  true  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3529,maintaining  connectivity  tajo  master  regardless  restart  tajo  master  currently  restart  tajo  master  restart  worker  client  also  client  worker  problem  connection  tajo  master  due  master  restart  need  close  previous  connection  try  reconnect  master,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3530,separating  querymaster  taskrunner  role  worker  c  implementation  tajo  worker  think  better  maintain  java  code  querymaster  implement  taskrunner  c  code  rather  implementing  querymaster  taskrunner  c  code  accordingly  standby  mode  worker  following  3  mode  1  taskrunner  querymaster  current  implementation  2  taskrunner  c  3  querymaster  java  worker  work  c  taskrunner  1  2  worker  work  separate  querymasters  java  process  backward  compatibility  default  mode  mode  1  taskrunner  querymaster  achieve  goal  need  separate  java  taskrunner  java  querymaster  worker  first  implement  c  taskrunner,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
3531,improving  queryexecutor  page  web  ui  current  implementation  following  issue  many  result  result  view  occupies  much  space  current  implementation  furthermore  memory  overflow  might  occurred  browser  maximal  number  result  limited  1000  row,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3532,add  table  partitioning  table  partitioning  give  many  facility  maintain  large  table  first  enables  data  management  system  prune  many  input  data  actually  necessary  addition  give  system  optimization  opportunity  exploit  physical  layout  basically  tajo  follow  rdbmsstyle  partitioning  system  including  range  list  hash  order  keep  hive  compatibility  need  add  hive  partition  type  exists  existing  dbms  system,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
3533,refactor  tabledesc  tablemeta  fragment  current  implementation  tabledesc  tablemeta  implemented  interface  implementation  unnecessary  abstraction  simplicity  patch  remove  interface  merge  concrete  class  addition  tabledesc  tablemetas  role  ambiguous  patch  clarifies  role  follows  tablemeta  contains  usual  physical  information  used  worker  tabledesc  contains  logical  information  table  others  used  worker  result  ive  moved  tablestats  schema  tablemeta  tabledesc  besides  current  implementation  fragment  also  subclassed  tabledesc  relationship  wrong  fragment  independent  one  tabledesc  patch  change  relationship  independent  one,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0
3534,improve  fragment  generic  current  fragment  file  patch  improves  fragment  generic  first  ive  changed  fragment  interface  original  fragment  filefragment  respectively  fragmentproto  changed  contain  table  name  bytestring  contains  storagedependent  content  added  fragmentconvertor  transforms  fragmentproto  specified  fragment  instance  would  useful  represent  various  fragment  type  like  row  range  hbase  database  table,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,1,1
3535,drop  table  command  remove  data  file  default  h3  problem  current  implementation  tajo  remove  data  directory  user  issue  drop  table  command  dangerous  many  case  example  user  may  lost  large  data  set  h3  solution  default  drop  table  remove  data  directory  need  add  config  property  tajocommanddroptabledataremoval  want  change  behavior  drop  table  addition  tajo  provide  drop  table  tablename  purge  removing  data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3536,implement  killquery  feature  current  version  killquery  feature  partially  implemented  need  complete  feature  add  command  tsql,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,1,1
3537,implement  chrint  function  chr  function  return  one  character  ascii  code  argument  code  text  chrint  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3538,make  datalocation  class  separate  class  move  tajocorestorage  package  current  implementation  datalocation  inner  class  queryunit  thus  cannot  used  class  tajocorestorage  package  however  useful  many  class  tajocorestorage  package  filefragment,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3539,make  taskscheduler  pluggable  task  scheduler  changed  according  task  scheduling  algorithm  locality  policy  storage  thus  need  improve  task  scheduler  interface  pluggable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
3540,improve  greedyheuristicjoinorderalgorithm  deal  noncommutative  join  greedyheuristicjoinorderalgorithm  default  costbased  join  order  algorithm  designed  inner  join  cannot  deal  noncommutative  join  leftrightfull  outer  join  semianti  join  main  goal  issue  improve  algorithm  deal,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3541,improve  tajoresourcemanager  support  elaborate  resource  management  h3  status  current  tajo  resource  manager  rm  tajo  rm  manages  cpu  disk  resource  incompletely  provides  resource  management  memory  allocation  addition  tajo  rm  considers  memory  resource  fixed  number  slot  h3  problem  many  case  workload  categorized  io  intensive  job  cpu  memory  consuming  job  example  scan  hash  partition  insert  overwrite  may  belong  io  intensive  job  general  aggregation  belong  cpumemory  consuming  job  current  rm  fit  support  selectively  io  intensive  job  cpumemory  consuming  job  provides  memory  slot  need  elaborate  resource  management  mechanism  addition  resource  management  system  remain  resource  le  required  resource  allocated  response  resource  request  good  fully  utilize  cluster  resource  order  mitigate  problem  need  add  resilience  allocation  mechanism  example  minmax  request  would  useful  h3  proposal  tajo  rm  provides  resource  management  disk  cpumemory  tajo  rm  provide  allocation  request  call  min  max  memory  request  min  max  disk  request  minmax  request  useful  fully  utilize  remain  cluster  resource  resource  request  priority  priority  disk  memory  priority  disk  disk  allocation  limited  depending  remain  disk  resource  memory  allocation  limited  regardless  remain  memory  resource  reduce  remain  memory  resource  priority  memory  memory  allocation  limited  depending  remain  memory  resource  disk  allocation  limited  regardless  remain  disk  resource  reduce  remain  disk  resource  disk  resource  worker  represented  float  value  initial  disk  resource  number  disk  participate  hdfs  data  directory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3542,implement  substr  function  h3  function  definition  code  text  substrstring  text  int4  count  int4  code  h3  description  extract  substring  substringstring  count  string  null  result  also  null  note  one  based  index  negative  integer  count  omitted  string  returned  count  cannot  negative  integer  count  0  result  instead  null  h3  example  sementic  code  hyunsik  select  substrabcdef  3  2  substr  cd  1  row  hyunsik  select  substrabcdef3  substr  cdef  1  row  hyunsik  select  substrabcdef11  substr  1  row  hyunsik  select  substrabcdef01  substr  1  row  hyunsik  select  substrabcdef02  substr  1  row  code,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,1
3543,implement  strposstring  substring  function  h3  function  definition  code  int  strposstring  text  substring  text  code  h3  description  function  find  location  specified  substring  string  substring  null  result  null  substring  result  1  matched  substring  result  0  result  onebased  index  h3  example  code  hyunsik  select  strpostajojo  strpos  3  1  row  code,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
3544,add  database  support  tajo  currently  table  reside  single  namespace  default  tajo  support  multiple  namespaces  ie  database  user  create  table  independent  namespace,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
3545,improve  tajoclient  directly  get  query  result  first  request  currently  tajoclient  cannot  deal  simple  query  eg  select  table  limit  1  select  1  executed  tajomaster  without  distributed  execution  final  result  always  stored  hdfs  tajoclient  get  result  via  scanner  tabledesc  obtained  getqueryresultresponse  simple  query  directly  executed  tajomaster  tajoclient  need  directly  get  binary  serialized  row  result  getquerystatusresponse  getqueryresultresponse  instead  reading  materialized  table  feature  would  also  useful  low  latency  query  explain  clause  expronly  statement  without  clause,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3546,improve  externalsortexec  nmerge  sort  final  pas  omission  background  current  externalsortexec  us  binary  external  merge  sort  algorithm  httpenwikipediaorgwikiexternalsortingexternalmergesort  word  pas  externalsortexec  merges  two  file  one  sorted  file  proposal  goal  proposal  improve  externalsortexec  following  improvement  nmerge  sort  merge  n  file  though  memory  pas  reduce  number  pass  consequently  reduces  considerable  io  overhead  final  pas  omission  physical  operator  pipelined  parent  operator  final  pas  merge  sort  must  also  invoked  parent  physical  operator  omit  final  pas  merge  sort,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3547,implement  quoteident  function  id  like  develop  function,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3548,increase  default  value  worker  memory  since  default  value  worker  memory  memory  required  launch  query  master  worker  launch  query  master  doesnt  free  memory  without  extra  configuration  cluster  consisting  one  machine  cause  available  worker  resource  execution  block  query  cannot  executed  though  error  make  user  confused,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
3549,implement  findinset  function  findinsetstrstrarray  return  first  occurrence  str  strarray  strarray  commadelimited  string  return  null  either  argument  null  return  0  first  argument  comma  example  select  findinsetcrcrtccrcdef  col1  result  3,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3550,refactoring  taskscheduler  assign  multiple  fragment  current  implementation  task  process  one  fragment  however  processing  multiple  fragment  task  increase  query  processing  performance  according  storage  layout  user  query  issue  taskscheduler  refactored  enable  assigning  multiple  fragment  task  following  contained  schedule  fragment  instead  queryunits  taskscheduler  queryunit  creation  postponed  taskscheduler  receives  task  request  worker  taskscheduler  receives  task  request  worker  dynamically  creates  queryunit  assigns  one  fragment  fragment  scheduling  take  account  disk  load  balancing,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
3551,improve  function  system  currently  function  system  designed  year  ago  lack  key  feature  necessary  function  userdefined  function  discussed  issue  epsilon  could  summary  following  issue  way  describe  explanation  function  user  convenience  tajo  need  show  user  function  information  including  signature  parameter  result  description  example  tajomaster  register  lot  function  startup  time  burden  maintain  registration  code  need  improve  automatically  register  builtin  function  specific  package  currently  way  find  matched  function  strict  due  function  match  system  register  function  parameter  type  combination  function  match  mechanism  consider  type  compatibility  example  countvalinteger  compatibly  countvallong  case  need  register  countvalbigint  function  tajo  find  countvalbigint  even  though  countvalinteger  function  called  need  elaborate  udf  regestration  system  currently  registering  userdefined  function  requires  system  restart  way  register  udfs  runtime  tajo  provide  runtime  udf  registration  system  involve  user  jar  distribution  provide  create  function  drop  function  statement  registration  function  stored  catalog  system  loaded  even  though  tajo  cluster  restarted  umbrella  issue  well  create  one  sub  task  issue,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3552,add  missing  visitor  method  algebravisitor  basealgebravisitor  patch  primarily  add  missing  operator  type  visitor  method  algebravisitor  implement  concrete  method  basealgebravisitor  currently  basealgebravisitor  may  cause  incorrect  planningexception  basealgebravisitor  handle  operator  type  patch  eliminates  potential  bug  addition  patch  contains  two  refactors  order  eliminate  duplicate  name  rename  tajoalgebradatatype  datatypeexpr  rename  tajoalgebratarget  targetexpr,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3553,divide  subquery  fsm  execution  block  part  subquery  play  two  role  finite  state  machine  unit  represent  part  distributed  direct  acyclic  graph  design  code  somewhat  ugly  issue  dividing  subquery  two  part  fsm  subquery  execution  block  representation  issue  would  first  step  improve  tajos  dag  framework,1,0,1,0,1,0,1,1,1,0,1,0,0,0,0,0,0
3554,make  serializerdeserializer  configurable  csvfile  csvfile  serializerdeserializer  fixed  textserializedeserialize  lazytuple  configurable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
3555,improve  integration  hive  hi  guy  wish  discus  hcatalogstore  hivemetastore  type  consists  three  type  embedded  local  remote  type  set  hive  configuration  file  named  hivesitexml  hivemetastoreclient  use  metastore  configuration  file  tajo  add  hive  configuration  file  classpath  tajo  use  hivemetastore  hivemetastoreclient  current  hcatalogstore  set  configuration  hivemetastore  follows  hivemetastoreuris  hivemetastorekerberosprincipal  hivemetastorelocal  hivemetastoresaslenabled  tajo  doesnt  need  tajocataloguri  property  hivesitexml  already  includes  metastore  host  port  look  like  unnecessary  setting  think  suggestion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3556,improve  intermediate  file  currently  intermediate  file  text  format  tajo  change  binary  format  support  configurable  storage  typeraw  csv,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3557,adopt  amrmclient  rmcontainerallocator  rmcommunicator  hadoop  yarn  203  introduced  amrmclient  contains  common  utility  method  amrmprotocol  make  rmcontainerallocator  rmcommunicator  simpler  adopting  amrmclient,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3558,implement  extract  function  extract  field  source  return  field  part  source  source  must  value  expression  type  timestamp  time  interval  date  type  cast  timestamp  used  field  century  day  timestamp  day  month  1  31  interval  number  day  decade  year  divided  10  dow  day  week  sunday0  saturday6  doy  day  year  1  365  epoch  timestamp  number  second  since  19700101  000000  utc  negative  interval  value  total  number  second  interval  hour  isodow  day  week  monday1  sunday7  isoyear  iso  8601  year  begin  monday  week  containing  4th  january  early  january  late  december  iso  year  may  different  gregorian  year  microsecond  millennium  millisecond  minute  month  quarter  quarter  year  1  4  secondthe  second  field  including  fractional  part  timezone  time  zone  offset  utc  measured  second  timezonehour  hour  component  time  zone  offset  timezoneminute  minute  component  time  zone  offset  week  year  detailed  explanation  found  httpwwwpostgresqlorgdocs91staticfunctionsdatetimehtml,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3559,separate  tajojdbc  tajoclient  tajocorebackend  currently  tajoclient  tajojdbc  included  tajocorebackend  depends  lot  thirdparty  library  even  client  program  include  unnecessary  thirdparty  library  patch  separate  tajojdbc  tajoclient  tajocorebackend  individual  maven  module  result  client  jdbcs  dependency  simplified  patch  mvn  package  pdist  command  generates  tajo  jdbc  driver  tajohometajodisttargettajotajoversionsharejdbcdist  following  file  directory  noformat  jodatime23jar  tajocatalogcommon080snapshotjar  tajoclient080snapshotjar  tajocommon080snapshotjar  tajojdbc080snapshotjar  tajorpc080snapshotjar  tajostorage080snapshotjar  noformat  order  load  tajo  jdbc  driver  client  program  must  able  locate  jar  file  hadoops  jar  file  user  set  classpath  jar  file  located  directory  usrlocalsharetajojdbc  hadoop  binary  located  opthadoop  set  classpath  follows  code  export  classpathopthadoopbinhadoop  classpathusrlocalsharetajojdbcclasspath  code  note  command  hadoophomebinhadoop  classpath  print  hadoops  classpaths  via  stdout,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
3560,visit  method  logicalplanvisitor  take  query  block  parameter  logical  plan  composed  multiple  query  block  logical  node  must  belong  one  query  block  query  block  instance  provides  lot  information  essential  information  many  rewrite  rule  optimizer  implementation  however  far  individual  rewrite  rule  optimizer  implementation  dealt  query  block  directly  may  errorprone  cause  duplicated  code  patch  refactors  visitor  method  logicalplanvisitor  take  query  block  parameter  im  expecting  change  provide  convenience  rewrite  rule  optimization  development,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3561,rename  name  partition  actually  meaning  shuffle  shuffle  far  used  word  partition  indicate  shuffle  name  originated  repartition  database  study  however  name  make  u  hard  distinguish  shuffle  table  partition  ned  change  name  prefix  shuffle,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,1,1
3562,supporting  time  type  datumfactorycreatefromint8  datumfactorycreatefromint8  support  time  type,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3563,extract  columnpartitonutils  class  columnpartition  rewrite  columnpartitionedtablestoreexecjava  seqscanexecjava  similar  rewritecolumnpartitionedtableschema  function  extract  util  class  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3564,add  test  development  kit  unit  test  based  execution  query  relational  algebra  numerous  combination  sql  query  also  numerous  case  cant  figure  one  nice  way  various  way  make  keep  tajo  stable  add  lot  unit  test  cover  many  case  many  unit  test  use  frontend  test  execute  sql  query  verify  result  far  implemented  java  code  verify  think  productivity  bad  finally  make  u  lazy  add  various  case  patch  add  querycasetestbase  class  help  developer  add  unit  test  little  effort  querytestcasebase  provides  useful  method  easily  execute  query  verify  result  us  four  resource  directory  srctestresourcesdataset  contains  set  data  file  contains  sub  directory  corresponds  test  class  data  file  sub  directory  used  corresponding  test  class  srctestresourcesqueries  query  directory  contains  sub  directory  corresponds  test  class  query  file  sub  directory  used  corresponding  test  class  srctestresourcesresults  result  directory  contains  sub  directory  corresponds  test  class  result  file  sub  directory  used  corresponding  test  class  example  create  test  class  named  testjoinquery  create  pair  query  result  set  directory  follows  noformat  src  resource  dataset  testjoinquery  table1tbl  table2tbl  query  testjoinquery  testinnerjoinsql  table1ddlsql  table2ddlsql  result  testjoinquery  testinnerjoinresult  noformat  querytestcasebase  basically  provides  following  method  executequery  executes  corresponding  query  return  resultset  instance  executequerystring  filename  executes  given  query  file  included  corresponding  query  file  current  class  query  directory  assertresultset  check  query  result  equivalent  expected  result  included  corresponding  result  file  current  class  result  directory  cleanquery  clean  resource  executeddl  execute  ddl  query  like  create  drop  table  order  make  use  method  query  file  result  file  must  follows  query  file  must  located  subdirectory  whose  structure  must  srcresourcesqueriesclassname  classname  indicates  actual  test  class  simple  name  result  file  must  located  subdirectory  whose  structure  must  srcresourcesresultsclassname  classname  indicates  actual  test  class  simple  name  especially  executequery  assertresultsetresultset  method  automatically  find  query  file  executed  result  compared  corresponding  running  class  method  query  result  file  must  additionally  comply  following  result  file  must  file  extension  result  query  file  must  file  extension  sql,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3565,rename  killquery  qmclientprotocol  closequery  discussed  tajo305  name  killquery  wrong  represent  purpose  patch  renames  killquery  closequery  trivial  change,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3566,umbrella  jira  adding  alter  table  statement  alter  table  statement  necessary  feature  modifying  meta  data  catalog  umbrella  jira  adding  alter  table  statement  make  additional  jira  issue,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3567,add  getparentcount  getparents  getparent  function  directedgraph  see  title  current  implementation  directedgraph  provides  getparent  assumes  one  parent  however  multiple  parent  supported  directedgraph,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3568,extend  tajoclient  run  query  plan  context  serialized  json  form  olap  application  separate  query  engine  tajo  accept  sqllike  language  parse  generate  query  plan  mondrian  representative  example  application  tajoclient  accepts  query  plan  json  form  user  query  efficiently  executed  without  duplicated  parse  phase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3569,rearrange  reserved  nonreserved  keywords  keywords  tajo  classified  reserved  nonreserved  reserved  keywords  cannot  used  table  name  column  name  reserved  keywords  tajo  different  db  like  postgresql  mysql  migrating  table  db  tajo  induces  table  creation  error  sometimes  need  rearrange  reserved  nonresearved  keywords  following  show  keywords  allowed  postgresql  allowed  tajo  noformat  mydb  list  relation  schema  name  type  owner  public  filter  table  ktpark  public  first  table  ktpark  public  format  table  ktpark  public  grouping  table  ktpark  public  hash  table  ktpark  public  index  table  ktpark  public  insert  table  ktpark  public  last  table  ktpark  public  location  table  ktpark  public  max  table  ktpark  public  min  table  ktpark  public  national  table  ktpark  public  nullif  table  ktpark  public  overwrite  table  ktpark  public  precision  table  ktpark  public  range  table  ktpark  public  regexp  table  ktpark  public  rlike  table  ktpark  public  set  table  ktpark  public  unknown  table  ktpark  public  varpop  table  ktpark  public  varsamp  table  ktpark  public  varying  table  ktpark  public  zone  table  ktpark  public  bigint  table  ktpark  public  bit  table  ktpark  public  blob  table  ktpark  public  bool  table  ktpark  public  boolean  table  ktpark  public  bytea  table  ktpark  public  char  table  ktpark  public  date  table  ktpark  public  decimal  table  ktpark  public  double  table  ktpark  public  float  table  ktpark  public  float4  table  ktpark  public  float8  table  ktpark  public  inet4  table  ktpark  public  int  table  ktpark  public  int1  table  ktpark  public  int2  table  ktpark  public  int4  table  ktpark  public  int8  table  ktpark  public  integer  table  ktpark  public  nchar  table  ktpark  public  numeric  table  ktpark  public  nvarchar  table  ktpark  public  real  table  ktpark  public  smallint  table  ktpark  public  text  table  ktpark  public  time  table  ktpark  public  timestamp  table  ktpark  public  timestamptz  table  ktpark  public  timetz  table  ktpark  public  tinyint  table  ktpark  public  varbinary  table  ktpark  public  varbit  table  ktpark  public  varchar  table  ktpark  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3570,cleanup  subquery  patch  clean  tajomastersubquery  patch  follows  add  setstarttime  setfinishtime  method  clean  subquerycleanup  rename  buildandsettablemeta  clean  initandrequestcontainertransition  method  divide  code  multiple  method  named  objective  make  control  flow  simple  add  method  access  member  variable  subquery  remove  tajomasterpriority,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3571,rewrite  projection  part  logical  planning  projection  part  logicalplanner  designed  long  time  ago  evolved  support  many  sql  expression  however  due  rough  design  hard  improved  sql  expression  cause  many  bug  current  logical  planner  following  problem  expression  except  column  used  groupby  clause  tajo422  expression  except  column  used  orderby  clause  tajo444  expression  including  aggregation  function  must  evaluated  groupby  executor  result  aggregation  operator  like  hashaggregateexec  keep  intermediate  result  complex  expression  hash  table  also  cause  frequent  gc  large  memory  consumption  high  code  complexity  also  cause  many  bug  like  tajo434  javalangnullpointerexception  invalid  column  name  tajo428  case  null  condition  problem  using  left  outer  join  tajo463  projectionpushdownrule  incorrectly  rewrite  output  schema  storetablenode  tajo443  order  query  give  nullpointerexception  orgapachetajocatalogschemagetcolumnidschemajava142  major  reason  problem  follows  targetlistmanager  keep  final  target  list  select  col1  sumcol2  col2  final  target  list  targetlistmanager  deal  expression  described  target  list  clause  like  groupby  clause  singleton  expression  main  objective  issue  rewrite  projection  part  logical  planning  order  problem  2  week  ive  rewritten  part  ill  submit  patch  soon,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,1,1
3572,parallel  container  launch  taskrunnerlauncherimpl  taskrunnerlauncherimpl  play  role  launch  remote  container  via  proxy  containermanager  implementation  sequentially  launch  container  may  take  long  time  large  cluster  example  consumes  5  second  starting  128  container  cluster  consisting  32  node  relieve  timeconsuming  work  make  part  parallel  using  executorservice,0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,1,0
3573,upgrade  netty  4  currently  rpc  package  us  netty  3  netty  4  stable  get  significant  performance  benefit  need  upgrade  netty  version  4,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3574,change  evalnodeeval  directly  return  datum  value  tajo501  ensure  expression  except  aggregationfunctioncalleval  evaluated  calling  eval  instead  calling  eval  followed  terminate  addition  current  evalnode  implementation  involves  unnecessary  memory  consumption  keep  evalcontext  expression  even  aggregation  eval  change  evalnodeeval  directly  return  datum  value  would  reduce  memory  consumption  cpu  cost,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
3575,insertnode  createtablenode  play  role  currently  createtablenode  insertnode  intermediate  representation  rewritten  storetablenode  storetablenode  contain  necessary  field  output  table  target  table  target  column  overwrite  flag  create  table  flag  far  field  kept  querycontext  implementation  cause  unnecessary  complex  rewrite  distributedqueryhookmanager  result  hard  maintain  manage  createinsert  plan  main  objective  issue  improve  logicalplanner  use  createtablenode  insertnode  throughout  planning  phase  eliminate  complex  rewrite  distributedqueryhookmanager,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3576,add  method  tajoclient  get  finished  query  list  current  tajoclient  provides  method  retrieving  list  running  query  however  user  may  want  see  query  already  finished  failed  even  started  query  started  immediately  tajo540,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3577,add  sortbased  physical  executor  column  partition  store  columnpartitionstoreexec  keep  numerous  open  file  storing  data  addition  random  write  give  burden  hdfs  namenode  solve  problem  would  like  propose  sortbased  physical  executor  column  partition  store  assumes  input  tuples  sorted  ascending  descending  order  partition  key  mean  need  extra  sort  operation  open  one  file  simultaneously  writes  data  sequentially  many  case  would  best  choice  column  partition  store,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,0
3578,improve  distributed  merge  sort  tajo  sort  operator  similar  merge  sort  work  distributed  manner  first  sort  phase  sort  fragment  local  machine  intermediate  data  shuffled  range  partition  second  sort  phase  node  sort  rangepartitioned  data  however  second  sort  phase  read  shuffled  data  via  one  scanner  miss  opportunity  exploit  alreadysorted  data  patch  improves  second  sort  phase  merge  directly  multiple  alreadysorted  intermediate  data  set  significantly  reduces  response  time  sort  query  carried  simple  benchmark  following  query  tpch  100gb  data  set  codesql  select  lorderkey  lineitem  order  lorderkey  code  lineitem  table  occupies  75gb  query  response  time  dramatically  reduced  480  260  sec  patch  exploit  design  tajo36  patch  requires  tajo36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3579,add  fine  grained  progress  indicator  task  profiling  monitoring  need  information  task  task  progress  inputoutput  data  byte  number  record  locality  scan  rate  memory  usage  sorting  grouping,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
3580,refactoring  tajo  rpc  current  implementation  client  rpc  use  channel  pool  cause  channel  closed  exception  need  shared  pool  new  pool  detail  fix  tajoasyncdispatcher  hang  fix  fetcher  timeout  fix  taskrunner  thread  leak  fix  client  rpc  reconnecting  fix  unittest  failureno  available  resource  improve  rpc  thread  sharing,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,1
3581,improve  distinct  aggregation  query  processing  currently  distinct  aggregation  query  executed  follows  first  stage  shuffle  tuples  hashing  grouping  key  second  stage  sort  executes  sort  aggregation  way  executes  query  including  distinct  aggregation  function  two  stage  lead  large  intermediate  data  shuffle  phase  kind  query  rewritten  two  query  codetitleoriginal  query  select  grp1  grp2  count  total  countdistinct  grp3  distinctcol  rel1  group  grp1  grp2  code  codetitlerewritten  query  select  grp1  grp2  sumcnt  total  countgrp3  distinctcol  select  grp1  grp2  grp3  count  cnt  rel1  group  grp1  grp2  grp3  tmp1  group  grp1  grp2  table1  code  im  expecting  rewrite  significantly  reduce  intermediate  data  volume  query  response  time  case,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3582,explaning  logical  node  use  explainlogicalplanvisitor  currently  many  part  use  logicalnodetostring  explaning  plan  already  explainlogicalplanvisitor  class  generate  pretty  print  string  patch  improves  logical  planning  related  part  use  explainlogicalplanvisitor  instead  tostring  added  plannerutilbuildexplainstring  generating  pretty  print  explain  string  simplified  obsolete  tostring  method  logicalnodes  much  improves  readability  explain  string  expect  would  helpful  debugging  user  understanding  query  plan,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
3583,implement  query  unit  case  hcatalogstore  already  hcatalogstore  catalog  store  already  testhcatalogstore  verifies  catalogstore  method  therefore  cant  verify  physicaloperator  operation  hcatalogstore  lack  hcatalogstore  reference  already  found  nosuchcolumnexception  tajo641httpsissuesapacheorgjirabrowsetajo641,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3584,support  quoted  identifier  sql  standard  nonascii  identifier  supported  using  double  quotation  follows  code  select  b  씨  table1  code  support  quoted  identifier,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3585,improve  operator  support  sub  query  currently  operator  used  set  value  need  improve  support  sub  query  following  example  query  noformat  tajo  select  nation  nregionkey  select  rregionkey  region  noformat,1,1,1,0,1,1,0,0,1,0,1,0,0,0,0,0,0
3586,hashjoin  hashaggregation  slow  many  unique  key  hashjoin  hashaggregation  slow  many  unique  key  java  native  map  inefficient  handle  many  item  case  1  million  item  hashmap  adding  10000  item  take  7  10  second  improved,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3587,refactor  globalengine  handle  ddl  statement  current  implementation  code  handle  ddl  statement  like  create  table  drop  table  distributed  across  clientservicehandler  globalengine  patch  move  code  globalengine  clean,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3588,improve  file  splitting  large  number  split  currently  storagemanager  invoke  getfileblockstoragelocations  per  input  path  occurred  many  rpc  associated  datanodes  reducing  remote  call  datanode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3589,rename  nqlg  sqlg  nql  legacy  name  rename  nqlg  sqlg,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3590,broadcast  join  support  multiple  table  currently  implementation  tajo  us  single  table  broadcast  join  even  several  small  tajo  supported  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3591,support  expression  predicate  tajo  support  expression  statement  noformat  tpch100  select  nation  nnationkey  1  11  12  error  extraneous  input  expecting  line  147  select  nation  nnationkey  1  11  12  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3592,support  executing  linux  shell  command  hdfs  command  see  title  noformat  command  executes  command  tajo  shell  dfs  command  executes  dfs  command  tajo  shell  default  l  al  total  208  drwxrxrx  27  babokim  staff  918  4  2  1734  drwxrxrx  95  babokim  staff  3230  4  2  1728  drwxrxrx  13  babokim  staff  442  4  2  1741  git  rwrr  1  babokim  staff  144  4  2  1729  gitignore  drwxrxrx  12  babokim  staff  408  4  2  1741  idea  rwrr  1  babokim  staff  2117  4  2  1729  buildingtxt  rwrr  1  babokim  staff  34170  4  2  1729  changestxt  rwrr  1  babokim  staff  17172  4  2  1729  licensetxt  rwrr  1  babokim  staff  396  4  2  1729  noticetxt  rwrr  1  babokim  staff  2095  4  2  1729  readme  drwxrxrx  4  babokim  staff  136  4  2  1729  devsupport  defaultdfs  l  tajowarehouse  found  93  item  drwxrxrx  tajo  supergroup  0  20140325  1745  tajowarehousedefault  drwxrxrx  tajo  supergroup  0  20140304  1006  tajowarehouselineitem100gzip  drwxrxrx  tajo  supergroup  0  20140322  1401  tajowarehouselineitem100p  drwxrxrx  tajo  supergroup  0  20140324  1422  tajowarehouselineitem100rc  drwxrxrx  tajo  supergroup  0  20140319  0207  tajowarehouselineitemtmp  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3593,arrange  tajocli  output  message  see  title  tajocli  print  information  error  message  various  format  message  must  arranged  etl  program  us  tajoclis  information  error  message,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3594,apis  tajoclient  jdbc  case  sensitive  identifier  apis  tajoclient  tajo  jdbc  driver  take  normalized  client  api  side  identifier  composed  upper  lower  mixed  character  used  double  quote  convention  different  existing  jdbc  driver  convention  make  ugly  code  user  use  tajoclient  patch  change  apis  case  sensitive  addition  patch  add  missing  jdbc  apis  fix  wrong  behavior  gettables  getcolumns  jdbc  apis,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
3595,implement  function  coalesce  see  title  next  description  postgresql  documenthttpwwwpostgresqlorgdocs91staticfunctionsconditionalhtml  noformat  coalescevalue  noformat  coalesce  function  return  first  argument  null  null  returned  argument  null  often  used  substitute  default  value  null  value  data  retrieved  display  example  codesql  select  coalescedescription  shortdescription  none  code  like  case  expression  coalesce  evaluates  argument  needed  determine  result  argument  right  first  nonnull  argument  evaluated  sqlstandard  function  provides  capability  similar  nvl  ifnull  used  database  system,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3596,jdbc  driver  support  cancel  method  olap  etl  tool  call  jdbcs  cancel  function  query  late  tajos  jdbc  support  cancel  function  statement  preparedstatement  class,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
3597,minor  improvement  hcatalogstore  minor  code  improvement  hcatalogstore,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3598,improve  shuffle  uri  currently  shuffle  uri  use  string  field  params  number  uri  need  change  varint  protocol  buffer  httpsdevelopersgooglecomprotocolbuffersdocsencodingvarints,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3599,refactor  improve  tajocli  patch  improves  tajocli  improvement  backward  compatible  improvement  make  tajocli  intuitive  similar  postgresql  cli  believe  give  user  better  experience  addition  ive  added  useful  option  detail  patch  follows  refactor  tajocli  based  command  pattern  multiple  line  one  sql  statement  recorded  one  history  command  prefix  replaced  command  replaced  list  table  describes  table  jline  version  updated  211  add  help  command  list  command  used  tajocli  add  cli  option  c  running  single  sql  statement  command  add  cli  option  f  executing  statement  included  text  file  add  script  bintsql,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3600,implicit  type  conversion  support  arithmetic  logical  operation  different  operand  usual  sql  query  function  invocation  parameter  different  parameter  function  definition  also  usual  implicit  type  conversion  occur  case  currently  however  tajo  support  implicit  type  conversion  implement  feature,1,0,1,0,1,0,0,0,0,1,0,1,1,1,1,0,1
3601,multiple  distinct  supported  currently  following  query  supported  code  default  select  id  countdistinct  age  countdistinct  name  table2  group  id  error  different  distinct  column  supported  yet  age  name  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3602,add  simple  fifo  scheduler  support  currently  dont  support  query  scheduling  hyunsik  min  zhou  started  implement  tajo  scheduler  tajo540  big  change  many  challenge  issue  temporary  solution  tajo540,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3603,datetime  type  refactoring  currently  tajo  us  joda  time  library  datetime  related  feature  tested  joda  library  next  test  code  difficult  express  various  time  range  joda  library  propose  tajo  us  postgresql  style  datetime  feature  already  migrated  postgresqls  datetime  code  tajo  attach  patch  soon  code  calendar  cal  calendargetinstance  calsetcalendaryear  1582  calsetcalendarmonth  9  calsetcalendardayofmonth  14  simpledateformat  df  new  simpledateformatyyyymmdd  hhmmss  datetime  defaultcaldate  new  datetime1582  10  14  10  0  0  0  chronology  julianchrono  julianchronologygetinstance  datetime  juliancaldate  new  datetime1582  10  14  10  0  0  0  julianchrono  systemoutprintlnjava  calendar  dfformatcalgettime  systemoutprintlniso  calendar  defaultcaldate  systemoutprintlnjulian  calendar  juliancaldate  systemoutprintlniso  calendar  dayofweek  defaultcaldategetdayofweek  systemoutprintlnjulian  calendar  dayofweek  juliancaldategetdayofweek  systemoutprintlniso  calendar  getcenturyofera  defaultcaldategetcenturyofera  systemoutprintlnjulian  calendar  getcenturyofera  juliancaldategetcenturyofera  code  noformat  java  calendar  15821024  164935  iso  calendar  15821014t100000000082752  julian  calendar  15821014t100000000082752  iso  calendar  dayofweek  4  julian  calendar  dayofweek  7  iso  calendar  getyearofcentury  15  julian  calendar  getyearofcentury  16  noformat,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
3604,task  scheduling  considering  disk  load  balance  hdfs3672  hdfs  namenode  provides  block  location  also  disk  location  information  tajo  make  scheduling  decision  considering  locality  disk  load  balancing  improve  query  performance,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3605,null  handling  jdbc  currently  jdbc  doesnt  handle  null  value  wasnull  provided  jdbc  handle  null  data  like  following  rule  text  type  return  java  null  int  float  type  return  0  datetime  type  return  null  boolean  return  false  getobject  return  java  null,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3606,jdbc  support  gettime  getdate  gettimestamp  currently  tajo  jdbc  support  gettime  gettimestamp  tajo825  getdate  return  wrong  result,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3607,clean  task  history  woker  task  history  currently  store  thread  memory  can’t  store  storagehdfs  local  file  would  nice  task  history  separate  taskrunner,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
3608,supporting  mariadbbased  store  compatible  mysql  exists  opensource  database  mariadb  httpmariadborg  replacement  mysql  since  interface  mariadb  perfectly  compatible  mysql  easy  construct  catalogstore  use  mariadb  tajo  therefore  hereby  suggest  mariadbstore  duplicating  mysqlstore,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3609,refactoring  filterpushdown  outer  join  currently  tajo  doesnt  support  filter  outer  join  clause  bug  rule  following  url  httpwwwibmcomdeveloperworksdatalibrarytecharticlepurcell0112purcellhtml  httpscwikiapacheorgconfluencedisplayhiveouterjoinbehavior  briefly  summarized  follows  join  predicate  preserved  row  table  used  join  conditionnot  filter  join  predicate  null  supplying  table  push  table  scan  predicate  preserved  row  table  push  table  scan  predicate  null  supplying  table  used  filter  join  result  data  filter  condition  attached  selection  node,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3610,support  insert  union  currently  insert  union  occurs  following  exception  noformat  20140528  014042105  error  orgapachetajomasterglobalengine  executequery152  stack  trace  javalangruntimeexception  wrong  child  node  type  union  insert  orgapachetajoengineplannerlogicalplannerbuildprojectedinsertlogicalplannerjava1269  orgapachetajoengineplannerlogicalplannerbuildinsertintotableplanlogicalplannerjava1234  orgapachetajoengineplannerlogicalplannervisitinsertlogicalplannerjava1141  orgapachetajoengineplannerlogicalplannervisitinsertlogicalplannerjava59  orgapachetajoengineplannerbasealgebravisitorvisitbasealgebravisitorjava123  orgapachetajoengineplannerlogicalplannercreateplanlogicalplannerjava122  orgapachetajoengineplannerlogicalplannercreateplanlogicalplannerjava109  orgapachetajomasterglobalenginecreatelogicalplanglobalenginejava475  orgapachetajomasterglobalengineexecutequeryglobalenginejava147  orgapachetajomastertajomasterclientservicetajomasterclientprotocolservicehandlersubmitquerytajomasterclientservicejava261  orgapachetajoipctajomasterclientprotocoltajomasterclientprotocolservice2callblockingmethodtajomasterclientprotocoljava495  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3611,implement  truncate  table  tajo  support  truncate  table  feature  noformat  truncate  table  table  name1  table  name2  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3612,integration  tajo  algebra  module  sql  parser  current  implementation  queryanalyzer  transforms  sql  statement  data  structure  represents  parser  tree  query  block  following  limitation  cant  support  multiple  block  query  including  table  scalar  subqueries  tightly  coupled  certain  grammar  asf  incubation  developed  tajoalgebra  tajofrontendsql  tajoalgebra  kind  intermediate  layer  represents  relational  algebraic  expression  interesting  thing  example  enable  user  describe  logical  plan  certain  query  also  helpful  support  another  dsl  work  tajoalgebra  improved  support  full  specification  rewrite  sql  parser  use  tajoalgebra,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,1,1
3613,consteval  included  target  list  projectable  node  application  aliased  constant  value  used  group  order  clause  case  current  planner  evaluates  constant  value  target  list  projectable  node  code  select  1994  end  year  lineitem  group  year  code  approach  work  well  far  room  significant  improvement  main  problem  constant  target  requires  many  workaround  code  namedexprmanager  targetlistmanager  result  make  code  complexity  higher  second  problem  many  constant  value  evaluated  row  consume  unnecessary  io  network  bandwidth  storing  transmitting  solution  seems  simple  logical  planning  phase  rewrite  column  reference  actually  indicates  constant  value,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3614,left  outer  join  case  optimized  broadcast  join  next  query  three  small  table  expected  broadcast  join  codesql  select  count  large1  left  outer  join  large2  large1id  large2id  left  outer  join  small1  large1id  small1id  left  outer  join  small2  large1id  small2id  left  outer  join  small3  large1id  small3id  code  next  upper  query  plan  noformat  eb14044115356950000000011  eb14044115356950000000010  eb14044115356950000000009  join  eb14044115356950000000008  small  eb14044115356950000000007  join  eb14044115356950000000006  small  eb14044115356950000000005  join  eb14044115356950000000004  small  eb14044115356950000000003  join  eb14044115356950000000002  large  eb14044115356950000000001  large  noformat  optimized  plan  next  noformat  eb14044119064260000000005  eb14044119064260000000004  eb14044119064260000000003  broadcast  small1  small2  small3  eb14044119064260000000002  large  eb14044119064260000000001  large  noformat,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3615,runtime  code  generation  evaluating  expression  tree  used  evalnode  two  purpose  logical  planning  expression  evaluation  expression  evalnode  still  nice  purpose  logical  planning  evalnode  tree  take  datum  included  tuple  result  datum  evaluation  result  current  approach  requires  many  object  creation  cause  interpret  overhead  meaning  one  evaluation  involves  tree  traverse  many  function  call  interpretation  involves  also  many  branch  harmful  cpu  pipelining  propose  java  byte  code  generation  expression  ill  use  asm  httpasmow2org  approach  write  native  java  byte  code  eliminating  many  condition  branch  function  call  addition  easier  deal  java  primitive  data  type  expression,1,1,1,1,1,0,0,0,0,0,0,0,0,1,0,0,0
3616,simple  query  nonforwarded  query  supported  partition  table  two  type  query  according  whether  query  executed  across  cluster  node  call  query  executed  across  cluster  node  forwarded  query  meaning  tajomaster  forward  query  query  master  contrast  call  query  without  distributed  execution  simple  query  nonforwarded  query  executed  client  side  following  query  example  simple  query  code  select  table  limit  10  code  currently  simple  query  supported  normal  table  also  support  partitioned  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3617,refactoring  mysqlmaria  catalog  store  mysqlstore  mariadbstore  almost  better  make  one  parent  class,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
3618,session  variable  override  query  configs  tajoconf  currently  use  tajosite  order  change  configuration  related  query  optimization  option  parameter  never  practical  need  restart  tajo  cluster  order  change  config  main  purpose  issue  refactor  system  session  variable  part  recognize  query  configs  accept  session  variable  also  duplicated  configs  session  tajoconf  session  variable  override  existing  config  tajoconf,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3619,output  file  punctuated  depending  file  size  file  format  eg  parquet  splittable  usually  span  multiple  hdfs  block  one  file  large  cause  remote  hdfs  access  limit  parallel  degree  resulting  significant  performance  degradation  solve  problem  storetableexec  colsortbasedpartitionstoreexec  punctuate  final  output  file  according  written  size  addition  need  support  session  variable  determine  per  file  size  final  output  file  tajo928  block  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3620,upgrade  parquet  150  parquet  150  released  may  2014  need  upgrade  parquet  version  150  need  modify  parquet  version  parquet  format  version  stroagepomxml  file,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,1,1
3621,rawfile  release  directbuffer  immediately  rawfile  allocated  memory  native  directbuffer  memory  freed  finalize  method  called  gc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3622,add  database  selection  submit  button  catalogviewjsp  text  based  browse  see  title  user  select  database  text  based  browser  like  elinks  improved,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3623,cleanup  child  block  parent  execution  block  complete  child  execution  block  working  directory  deleted  query  complete  many  file  directory  delete  child  execution  block,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3624,autobuilding  class  constructor  used  identified  trace  output  operation  trace  useful  tracking  ioc  injection  problem  case  slightly  sketchy  ive  elided  class  name  autobuilding  instance  securityfilter  determining  injection  value  parameter  4  pagetitleextractor  resolving  object  type  pagetitleextractor  using  masterobjectprovider  think  line  1  2  saying  using  constructor  pagetitleextract  listing  parameter  type,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3625,tapestry  loading  template  file  caseinsensitive  os  window  trigger  error  file  name  case  incorrect  result  runtime  failure  casesensitive  os  linux  word  window  might  find  file  mycomponenttml  named  mycomponenttml  match  name  class  mycomponent  irritating  find  testing  production  tapestry  able  add  check  case  file  name  match  expected  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3626,live  class  reloading  service  implementation  possible  create  class  loader  service  implementation  reload  service  underlying  class  change  could  imagine  special  proxy  possibly  would  require  particular  service  scope  reloadable  periodically  check  could  occur  let  proxy  see  underlying  service  implementation  class  file  changed  create  new  class  loader  load  specific  class  much  tapestrycore  component  would  involve  moving  number  service  tapestrycore  tapestryioc  implication  related  public  service  think  would  much  support  reloadable  module  service  implementation  therefore  service  constructed  via  builder  method  would  reloadable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3627,validator  macro  combine  multiple  common  validators  single  term  case  particular  type  field  may  series  independent  validation  used  consistently  group  would  nice  way  specify  single  value  bring  group  validators,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3628,provide  access  component  parameter  within  mixins  mixin  cant  access  parameter  component  binding  property  internalcomponentresourcesimpl  class  private  respective  interface  provide  access  method  trying  create  mixin  would  render  value  form  element  without  tag  certain  state  also  might  use  case  mixins  used  collect  data  component  attached  therefore  also  need  access  component  parameter  see  thread  httpwwwnabblecomantwort3at5howtoreadthevalueofacomponentparameterwithinamixintf4487995html  httpwwwnabblecomt5howtoreadthevalueofacomponentparameterwithinamixintf4487597html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3629,place  invalid  key  used  accessed  named  value  tapestry  report  possible  name  better  using  html  list  rather  long  commaseparated  string  use  invalid  name  misspelling  component  type  tapestry  great  listing  possible  name  could  used  however  there  lot  service  id  component  type  page  name  large  application  format  hard  parse  long  long  long  commaseparated  list  better  approach  would  use  two  three  column  ul  li  element  present  option  useful  order,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
3630,rewrite  live  reload  integration  test  use  new  seleniumtestcase  instead  deprecated  abstractintegrationtestsuite  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3631,add  support  startup  method  module  easy  way  add  startup  logic  there  mechanism  adding  startup  logic  contributing  registrystartup  service  configuration  would  nice  optimized  way  accomplish  thing  ie  starutp  method  injected  parameter  easier  way  accomplish  thing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3632,change  tapestry  clientside  javascript  make  tapxconfirm  component  easier  implement  tapxconfirm  component  need  hook  link  submit  component  order  hook  confirmation  currently  implemented  requires  much  internal  knowledge  tapestryjs  internals  approach  ive  taking  replace  simple  click  event  handler  two  part  click  event  handler  cancel  event  fire  tapestryaction  event  handler  tapestryaction  event  using  tapxconfirm  override  default  click  event  handler  get  back  original  logic  confirmation  firing  tapestryaction  event,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3633,provide  hook  postprocess  property  file  rolling  component  message  client  use  case  property  file  contain  keywords  substituted  raw  file  read  hacking  t51  took  lot  effort  read  cutnpaste  would  nice  cleaner  way,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3634,application  global  message  catalog  injectable  service  would  nice  service  could  see  global  message  catalog,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3635,live  class  reloading  extend  proxied  object  objectlocatorproxy  word  proxiable  there  interface  implementation  class  interface  make  live  class  reloading,1,0,1,0,1,0,0,0,0,1,0,1,0,0,0,0,0
3636,zone  initially  render  inside  form  support  update  within  form  kind  mechanism  already  present  forminjector  ajaxformloop  matter  making  global  zone  automatically,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3637,new  annotation  heartbeatdeferred  mark  component  method  execute  end  current  heartbeat  basically  instead  creating  runnable  injecting  heartbeat  environmental  passing  runnable  defer  method  slap  annotation  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3638,introduce  public  service  responsible  handling  page  activation  needed  client  specific  need  extend  semantics  page  activation  adding  second  event  security  check,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3639,define  new  namespace  p  block  parameter  towards  greater  conciseness  making  equivalent  tbeaneditform  tidnew  objectnewposting  submitlabelmessagepost  includetitlecontent  tparameter  namecontent  tlabel  forcontent  br  trichtextarea  tidcontent  rows10  cols80  valuenewpostingcontent  tparameter  tbeaneditform  tbeaneditform  tidnew  objectnewposting  submitlabelmessagepost  includetitlecontent  pcontent  tlabel  forcontent  br  trichtextarea  tidcontent  rows10  cols80  valuenewpostingcontent  pcontent  obviuosly  p  would  need  mapped  tapestry  namespace,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3640,refactor  new  base  class  orgtestngassert  orgapachetapestry5ioctesttestbase  nonmock  related  test  unreachable  extra  assertion  useful  even  dont  want  overhead  managing  mock,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
3641,development  mode  tapestry  prettyprint  json  content  reading  giant  blob  json  challenge  read  given  deeply  tapestry  tends  nest  everything,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3642,javascript  initialization  inside  partial  page  render  ajax  response  unquoted  currently  j  ajax  partial  page  render  update  come  inside  script  key  long  string  inefficient  since  many  character  quote  need  escaped  also  harder  read  debug  especially  since  pretty  printing  turned  since  pretty  printing  inside  string  readable  instead  call  tapestryinit  handled  differently  ajax  response  encoded  new  key  inits  array  tapestryinit  parameter  multiple  call  init  scheduling  early  normal  late,1,1,1,0,1,1,1,0,0,0,0,0,1,0,0,0,1
3643,easy  way  customize  search  location  page  component  template  would  nice  standard  public  way  override  tapestry  default  search  page  component  template,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1
3644,make  better  use  operationtracker  identify  whats  going  request  especially  page  construction  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3645,new  pagelevel  event  decorate  component  event  page  render  link  based  customer  work  customer  really  wanted  url  include  series  optional  value  query  parameter  path  info  make  sense  youd  category  filter  sometimes  name  filter  sometimes  etc  anyway  worked  fine  case  there  method  page  act  like  passivate  event  handler  return  link  query  parameter  added  active  event  handler  would  extract  query  parameter  store  inside  field  got  trickier  handling  event  link  modify  lowlevel  component  fire  decoratelink  event  page  event  handler  could  add  query  parameter  link  would  nice  concept  inside  tapestry  generating  link  via  passivate  event  building  link  using  supplied  page  activation  context  optional  event  perhaps  called  decoratelink  would  triggered  add  extra  query  parameter  ideally  would  two  event  decoratepagerenderlink  decoratecomponenteventlink  first  parameter  would  link  decorate  second  would  pagerenderrequestparameters  componenteventrequestparameters  appropriate  would  give  event  handler  method  enough  information  decide  whether  decorate  link  information  put,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3646,eliminate  page  pooling  using  shared  page  instance  separate  structure  mutable  state  suggested  recent  change  class  transformation  api  make  much  reasonable  accomplish  goal  identify  transient  mutable  state  page  store  via  perthreadmanager  invisible  user  code  page  appear  individual  instance  internal  state  fact  single  instance  per  locale  internal  mutable  state  stored  elsewhere  change  semantics  aspect  component  class  transformation  pipeline  compatibility  mode  allow  page  pooled  51  third  party  library  contribute  worker  update  large  application  complex  page  big  win  tapestry  shown  strain  limit  available  jvm  heap  surprising  apparently  true  dozen  hundred  page  instance  page  type  floating  around,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3647,componentresources  give  access  generic  parameter  bound  type  componentresources  tell  type  bound  given  parameter  via  getboundtypeparametername  great  feature  work  nongeneric  type  generic  type  bound  impossible  access  generic  parameter  example  component  bind  set  something  getboundtype  return  javautilset  parameter  possible  coerce  entry  set  target  type,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
3648,new  annotation  decorate  advise  identify  method  decorate  annotate  service  would  similar  reuse  logic  one  would  hope  contribute  annotation,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
3649,extend  link  new  method  producing  absolute  url  include  scheme  hostname  etc  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3650,beanblockcontribution  split  two  subclass  editblockcontribution  displayblockcontribution  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3651,option  disable  live  service  reloading  via  jvm  system  property  people  uncomfortable  live  class  reloading  feel  may  resource  intensive  even  development  also  leaky  abstraction  around  use  nonpublic  method  livereloaded  class  case  option  turn  desired,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1
3652,define  special  cs  class  prevent  clientside  form  submitting  normally  ajax  use  case  occured  class  right  there  logic  getting  formmanager  form  im  hoping  minimize  kind  thing  locking  javascript  apis  53,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3653,additional  method  link  addparametervaluestringobject  us  contextpathencoder  encode  object  value  string  would  make  adding  parameter  link  consistent  setting  value  page  activation  context  give  raw  value  tapestry  figure  encode  url,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3654,zone  implement  interface  bodyelement  extends  clientelement  provides  body  property  wanted  create  static  utility  method  passed  collection  zone  would  add  create  multizoneupdate  involved  getting  clientid  via  clientelement  interface  getting  body  block  however  standard  classcast  issue  static  method  primary  class  loader  cant  accept  instance  zone  time  getbody  method  defined  interface,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
3655,improve  page  testing  facility  currently  pagetester  returning  document  instance  make  difficult  assert  responserelated  functionality  like  sending  redirect  setting  http  header  implement  new  method  pagetester  returning  testableresponse  instance  also  implement  various  method  testableresponse  throw  nyi  exception,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3656,provide  convenient  method  element  document  find  element  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3657,component  report  accept  multiple  root  package  possible  multiple  root  package  inside  jar  file  possible  generate  component  reference  single  root  package  component  report  accept  multiple  root  package  configuration  rootpackages  rootpackagefoobarbazrootpackage  rootpackageorgexamplerootpackage  rootpackages  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3658,contributing  service  configuration  value  coerced  correct  type  rather  rejected  correct  type  make  much  easier  migrate  behavior  service  long  contribution  old  type  coerced  contribution  new  type  may  also  make  easier  contribute  symbol  constant  possible  pas  true  true  literal  number,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3659,add  zone  parameter  select  component  add  ajax  ability  selection  select  component  allow  classic  chaining  select  component  eg  filtering  car  advertisement  3  select  component  brand  make  model  choosing  brand  cause  make  enabled  showing  possible  make  similarly  choosing  make  cause  model  enabled  showing  possible  model,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3660,provide  support  jsr330  possible  use  jsr330  annotation  injection  point,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3661,autobuild  annotation  parameter  implicitly  invokes  objectlocatorautobuild  rather  injecting  objectlocator  invoke  autobuild  would  nice  could  inject  result  objectlocatorautobuild,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3662,functional  programming  improvement  add  support  tuples  tapestryfunc  library,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
3663,service  used  handle  live  reloading  made  public  user  service  able  register  checkforupdates  andor  invalidation  event  notification  without  use  tapestry  internals  firing  event  still  privateinternal,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
3664,possible  perform  ajax  request  without  linking  component  link  form  zone  specify  want  perform  xhr  request  eventlink  actionlink  form  etc  need  supply  zone  parameter  existence  parameter  flag  tell  component  use  xhr  case  may  useful  although  im  yet  find  one  strike  bad  design  since  necessarily  known  onetoone  relationship  event  zone  updated  return  zone  multizoneupdate  event  handler  actual  zone  supply  requesting  component  irrelevant  since  xhr  event  handler  return  multizoneupdate  ended  creating  dummy  zone  every  page  component  supplying  every  zone  parameter  dummy  zone  always  hidden  never  actually  updated  hack  made  easier  code  maintain  page  without  would  need  search  arbitrary  zone  page  creating  callback  solution  would  add  xhr  parameter  component  eventlink  form  etc  zone  parameter  optional  xhr  true  could  even  hard  set  xhrtrue  zonenull  backwards  compatibility  would  require  tapestry  lose  dependency  zone  create  contextual  xhr  request  think  limiting  design  decision  plaguing  area  tapestry,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3665,tapestry  test  able  run  jetty  tapestry  client  application  may  intentionally  inadvertently  servlet  container  specific  functionality  tapestry  provide  test  tomcat  well  jetty,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0
3666,coercion  list  selectmodel  use  selectmodelfactory  service  use  selectmodelfactory  label  extracted  object  using  strategy  pattern  user  contribute  provider  object,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3667,allow  multiple  application  root  package  contributing  additional  librarymappings  empty  virtual  folder  first  package  defined  webxml  addition  one  defined  componentclassresolver  contribution,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3668,provide  basic  integration  jpa  2  provide  basic  integration  jpa  2  goal  support  multiple  entitymanagers  injection  entitymanager  component  service  provide  way  configure  entitymanagers  programmatically  via  persistencexml  create  valueencoder  entity  onthefly  provide  entity  persistentfieldstrategy  provide  entity  applicationstatepersistencestrategy  provide  commitafter  annotation  also  consider  tapestryorm  similar  project  needed  order  reuse  common  source  code,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3669,deprecate  multizoneupdate  replace  injectable  service  collect  zone  update  multizoneupdate  presumes  there  single  place  zone  updated  known  necessarilly  case  id  like  see  something  like  inject  private  zoneupdater  zoneupdater  object  onsuccess  zoneupdaterupdatefoo  fooblock  zoneupdaterupdatebar  barblock  return  myzonegetbody  main  point  different  event  handler  would  able  invoke  zoneupdaterupdate  would  also  allow  single  response  render  main  content  requesting  zone  client  plus  zone  update  named  zone,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3670,stack  asset  return  404  stead  exception  dont  exist  currently  trying  access  stack  asset  get  following  exception  javalangruntimeexception  invalid  path  stack  asset  request  404,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3671,new  feature  seleniumtestcase  refactor  standard  method  often  added  subclass  opening  page  page  name  ie  avoid  ugliness  getbaseurl  expose  underlying  selenium  object  seleniumtestcase  doesnt  implement  method  selenium  common  operation,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
3672,reduce  memory  utilization  tapestry  page  instance  umbrella  bug  number  change  aimed  reducing  overall  memory  footprint  tapestry  page  tapestry  page  seen  quite  large  production  site  sharedinstance  strategy  introduced  52  still  insufficient  significant  amount  space  consumed  using  map  list  binding  subcomponents  etc  way  optimized  smaller  code  base  efficient  read  access  even  though  information  read  page  first  loaded  rarely  needed  accessed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3673,tapestryspecific  javadoc  plugin  generates  parameter  documentation  etc  split  javadoc  component  reference  always  challenge  would  nicer  javadoc  extended  tapestryspecific  content  component  class  example  optional  xdoc  file  parameteretc  documentation  driven  switch  gradle  build  existing  module  generating  component  reference  maven  specific,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3674,optimize  document  scan  used  tapestryfieldeventmanager  locate  label  icon  actually  needed  creating  field  event  manager  initializing  basic  feature  also  extra  information  use  later  like  label  icon  getting  icon  need  search  element  dom  using  label  searching  dom  specific  label  expensive  operation  ie7  move  initialization  element  really  needed  saving  client  side  timing  eclipse  workspace  patch  10  p  tapestrycore  index  srcmainresourcesorgapachetapestry5tapestryjs  srcmainresourcesorgapachetapestry5tapestryjs  revision  1131061  srcmainresourcesorgapachetapestry5tapestryjs  working  copy  166713  16676  initialize  functionfield  thisfield  field  var  id  thisfieldid  var  selector  labelfor  id  thislabel  thisfieldupformdownselector  thisicon  id  icon  thistranslator  prototypek  var  fem  thisfieldformgetformeventmanager  16987  169124  thisvalidateinputbindaseventlistenerthis  getlabel  function  thislabel  var  id  thisfieldid  var  selector  labelfor  id  thislabel  thisfieldformdownselector  return  thislabel  geticon  function  thisicon  var  id  thisfieldid  thisicon  id  icon  return  thisicon  remove  validation  decoration  present  hide  errorpopup  exists  170611  171611  removedecorations  function  thisfieldremoveclassnameterror  thislabel  thislabelremoveclassnameterror  thisgetlabel  thisgetlabelremoveclassnameterror  thisicon  thisiconhide  thisgeticon  thisgeticonhide  thiserrorpopup  thiserrorpopuphide  173012  174012  thisfieldaddclassnameterror  thislabel  thislabeladdclassnameterror  thisgetlabel  thisgetlabeladdclassnameterror  thisicon  thisiconvisible  new  effectappearthisicon  thisgeticon  thisgeticonvisible  new  effectappearthisgeticon  thiserrorpopup  undefined,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3675,formfragment  allow  fine  grained  control  considered  invisible  52  line  tapestry  introduced  alwayssubmit  parameter  form  fragment  nice  allows  fragment  submitted  even  hidden  however  doesnt  cover  use  case  consider  situation  like  form  div  idtab1tformfragment  ttextfield  validaterequiredtformfragmentdiv  div  idtab2tformfragment  ttextfield  validaterequiredtformfragmentdiv  tsubmit  form  user  reveals  tab  1  reveals  form  fragment  tab1  make  change  user  reveals  tab2  note  fragment  tab1  still  revealed  context  tab1  entire  tab1  hidden  currently  way  make  submit  submit  information  formfragment  tab  behave  correctly  situation  enumerate  definition  clarity  fragmentx  fragment  tabx  fragmentx  visibility  refers  state  actual  fragment  rather  state  containing  tab  fragment1  visible  mean  visible  tab1  active  considering  visible  tab2  active  even  though  entire  tab1  invisible  1  alwayssubmit  false  fragment1  invisible  get  correct  behavior  regardless  tab1tab2  visibility  2  alwayssubmit  false  fragment1  visible  get  correct  behavior  iff  tab1  active  tab2  active  fragment1s  field  submitted  3  alwayssubmit  true  fragment1  invisible  get  incorrect  behavior  well  technically  correct  information  submitted  per  alwayssubmit  case  dont  actually  want  information  submitted  fragment  isnt  visible  4  alwayssubmit  true  fragment  visible  get  correct  behavior  conditionally  alwayssubmit  alwayssubmit  condition  visibility  visible  trigger  problem  come  following  scenario  user  open  page  fragment1  initially  visible  data  yet  required  field  user  mark  fragment1  invisible  user  submits  form  submission  fail  alwayssubmit  true  time  form  rendered  culprit  behind  tapestry  isdeepvisible  method  search  visibility  point  find  form  element  case  form  element  contains  tab  divs  fragment  determined  invisible  data  submitted  inactive  tab  even  user  clicked  trigger  make  fragment  visible  tab  active  something  edge  case  think  handled  cleanly  introducing  new  parameter  formfragment  visiblebound  better  named  idea  allow  developer  specify  element  selector  expression  bound  search  visibility  default  would  containing  form  element  would  preserve  current  behavior,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3676,excessive  warning  tracking  issue  cleaning  compiler  warning,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3677,add  queryparameter  annotation  parameter  event  handler  method  would  nice  case  tapestry  map  query  parameter  event  handler  method  parameter  rather  path  info  typically  ajax  case  reliable  easier  take  url  add  query  parameter  add  extra  path  info  public  void  onactionfromajaxwidgetqueryparameteraction  string  widgetaction  queryparametercount  int  count,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3678,tapestryioc  depend  tapestryjson  tapestryioc  depend  tapestryjson  binding  string  jsonarray  jsonobject  twice  provided  also  tapestrycore,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3679,outofthebox  way  tapestry  replacing  component  would  nice  allow  global  component  replacement  different  component  class  derived  version  original  compared  field  type  provided  injectcomponent  would  behave  le  like  inject  service  without  need  interface  note  current  workaround  decorating  componentinstantiatorsource  thiago  outline  workaround  suboptimal  base  internal  class  might  subject  change  without  notice  suggests  service  contribute  override  replaceing  component  would  introduce  new  level  flexibility  change  implementation  without  touching  tmls  naturally  servicebinder  suggested  place  new  kind  binding  seems  misunderstanding  functional  point  view  thinking  something  like  public  static  void  bindfinal  componentbinder  binder  binderbindcomponentaclass  componentbderivedfromaclass  example,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3680,enable  operationtracker  produce  debug  trace  operation  operationtracker  great  identifying  lead  error  keep  nested  operation  leading  particular  failure  would  nice  could  emit  debug  logging  every  operation  including  timing  operation  way  identify  whats  going  leading  error  tracked  specific  operationtracker  trace,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3681,reduce  thread  contention  inside  componentclassresolverimpl  looking  fair  amount  thread  lock  contention  inside  componentclassresolverimpl  use  concurrentbarrier  appears  sufficient  poorly  tuned,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
3682,component  use  primarykeyencoder  changed  use  valueencoder  primarykeyencoder  deprecated  working  application  noticed  object  serialized  weird  form  loop  component  realized  hadnt  provided  primary  key  encoder  thing  worked  expected  got  thinking  would  nice  loop  component  component  rely  primarykeyencoders  could  check  see  encoder  available  valuetype  none  explicitly  bound  user  way  moduleauthors  could  provide  primarykeyencoders  make  thing  work  like  magic  example  tapestryhibernate  could  contribute  primarykeyencoders  entity  type  object  automatically  properly  encoded  form,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3683,pagelink  page  parameter  accept  pageclasses  pageinstances  page  parameter  pagelink  accept  string  mean  page  containing  pagelink  know  corresponding  logical  page  name  accepting  pageclass  would  typesafe  refactoring  friendly  could  use  injected  propely  configured  page  instance  page  parameter  pagelink  component  could  easily  calculate  activation  context  corresponding  onpassivate  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3684,tapestry  could  create  nonsingleton  service  efficiently  service  may  created  request  tapestry  lot  extra  work  analyze  class  constructor  field  able  roll  information  repeatable  plan  simply  reexecuted  subsequent  instance  creation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3685,use  symbol  default  component  parameter  value  example  grid  component  following  parameter25  private  int  rowsperpage  meaning  wish  pagination  50  row  find  instance  grid  component  application  manually  add  rowsperpage  parameter  parameter  defined  parametersymboltapestrygridrowsperpage  private  int  rowsperpage  would  need  override  symbol  contribution  voilà  change  throughout  whole  application  specific  component  default  would  nice  update  parameter  zone  et  al  classic  yellow  fade  doesnt  work  everyone  date  format  datefield,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3686,tapestrybeanvalidator  isnt  validating  nested  dto  object  doesnt  mark  invalid  field  ui  tapestrybeanvalidator  isnt  validating  nested  object  correctly  problem  component  parameter  ie  textfieldvalue  bound  attribute  doesnt  contain  full  objectpath  using  dto  like  class  testdto  notnull  private  string  firstname  valid  private  embeddedobject  embeddedobject  class  embeddedobject  notnull  private  string  lastname  using  testdto  page  following  way  class  mypage  property  private  testdto  testdto  componentparameters  validatetestdto  private  form  form  componentparameters  valuetestdtofirstname  private  textfield  firstname  componentparameters  valuetestdtoembeddedobjectlastname  private  textfield  embeddedfield  submitting  form  validates  attribute  correctly  also  embedded  object  validation  error  listed  terror  component  come  beanfieldvalidator  lastname  environment  stack  beanvalidationcontext  testdto  doesnt  contain  property  lastname  there  objectpath  available  doesnt  traverse  object  cant  assign  correct  validation  error  outcome  even  property  validated  correctly  there  redframe  cs  error  class  appropriate  field  ui  reference  httptapestry1045711n5nabblecomtapestrybeanvalidationtd4921787html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3687,component  field  need  private  merely  nonpublic  currently  plastic  asset  early  instance  field  private  instead  check  field  transformation  applied  ensure  merely  nonpublic  access  field  class  including  inner  class  must  routed  access  method  inner  class  need  limited  set  transformation  handle  case  protected  package  private  field  directly  accessed  case  appropriate  accessor  method  used  instead  seems  possible  two  transformed  class  access  others  nonpublic  field  might  cause  endless  loop  identified  reported,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3688,kaptchafield  parameter  allow  operate  visible  text  field  rather  password  field  captcha  implementation  based  input  typetext  instead  input  typepassword  would  nice  allow,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3689,merge  functionality  tynamoorgs  tapestryexceptionpage  module  builtin  exceptionhandler  discussed  dev  list  httpmarkmailorgsearchqbringingtynamo27stapestryexceptionpageintothecorequerybringing20tynamo27s20tapestryexceptionpage20into20the20corepage1midwocbkhyqqe7a2tm7stateresults,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3690,improve  error  reporting  javascript  asset  intended  included  page  html  element  know  silly  page  bodybody  element  spent  entire  day  trying  figure  javascript  wasnt  getting  included  error  see  people  making  mistakea  little  errorreporting  would  nice,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3691,extension  component  template  root  textend  element  allow  tblock  element  nested  currently  isnt  possible  tblock  element  must  placed  inside  available  treplace  block  make  sense  defining  block  specific  subcomponent  allowed  even  aspect  containing  template  overridden,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3692,add  submitmode  submit  linksubmit  component  unconditionally  submitting  form  described  tap51856  there  functionality  gap  prevents  button  submitting  form  still  allowing  serverside  processing  occur  submit  component  fire  selected  event,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3693,rendering  component  alert  weve  upgraded  532  checked  new  component  alert  seems  pretty  useful  look  like  possible  pas  string  im  thinking  pretty  common  usecase  would  render  componentsmarkup  like  link  experimented  little  manually  rendering  block  pas  alertmanager  got  inspiration  thread  rendering  block  httptapestry1045711n5nabblecomhowtorenderablockandputitintoajsonreplytd5486823html  rendercommand  rendercommand  rendercommandalertblock  markupwriter  markupwriter  new  markupwriterimpl  renderqueueimpl  renderqueue  new  renderqueueimpllog  renderqueuepushrendercommand  renderqueuerunmarkupwriter  alertmanagerinfomarkupwritertostring  seems  work  bit  clumsy  dont  know  recommended  approach  rendering  block  convenience  method  exist  rendering  blockscomponents  sure  possible  one  could  pas  block  alert  directly  could  pretty  flexible  well  reply  kalle  certainly  recommended  approach  use  provided  render  queue  rather  create  obviously  current  implementation  doesnt  always  allow  completely  agree  rendering  link  general  rendering  block  would  useful  alert  dont  see  major  issue  couldnt  supported  please  open  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3694,ajax  event  handler  method  return  page  instance  page  class  page  name  cause  client  redirect  page  normal  page  navigation  tapestry  work  request  ajax  request  returning  string  class  allowed  returning  page  result  page  rendered  within  zone  target  ajax  request  tapestry  smart  enough  figure  user  want  navigate  page  redirect  client  without  forcing  developer  write  custom  javascript,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3695,typo  interface  localizationsettersetnonperistentlocalefromlocalename  method  missing  peristent,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3696,copy  annotation  service  implementation  proxy  jpa  annotation  expose  implementation  detail  service  interface  commit  persistence  context  annotation  required  service  interface  definition  thereby  exposing  internal  implementation  detail  see  example  doc  detail  implementation  hidden  interface  level  annotation  break  rule  perhaps  code  could  appear  impl  class  provided  configuration  somehow  public  interface  userdao  commitafter  persistencecontextunitname  demounit  void  adduser  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3697,support  multiple  pageactivationcontext  pageactivationcontext  annotation  pageactivationcontextworker  could  improved  accept  index  parameter  way  could  multiple  pageactivationcontext  property  eg  code  public  class  mypage  pageactivationcontextindex0  private  category  category  pageactivationcontextindex1  private  item  item  code  id  expect  tapestry  generate  following  url  mypage  category  item  null  mypagecategory1  item  null  mypagenitem1  category  null  mypagecategory1item1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3698,possible  control  whether  given  javascript  library  minimized  current  closure  compiler  version  fails  minimize  angularjs  httpsgithubcomangularangularjsissues1304  wroruntimeexception  thrown  googleclosurecompressorprocessor  handled  asset  sent  client  asset  cannot  minimized  whatever  reason  tapestry  send  original  asset,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3699,configuration  interface  support  contributing  class  autobuilt  addition  instance  frequently  inject  objectlocator  invoke  autobuild  contribute  result  adding  addinstance  method  take  class  three  configuration  interface  would  simplify  contribution  code  remove  need  inject  objectlocator,0,1,0,1,0,0,0,0,1,0,1,0,0,0,0,1,1
3700,add  support  distributed  documentation  please  add  support  distributed  documentation  system  basic  requirement  1  access  list  pagescompoentsmixins  componentclassresolver  support  page  2  access  map  configuration  map  would  configuration  class  key  contain  object  list  map  contains  configuration  3  access  list  configured  service  possible  build  documentation  running  system  thanks  barry,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3701,make  tapestry5  java8  compatible  stand  tapestry  work  java8  seems  caused  asm  updating  enclosed  asm  50bet  seems  trick,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3702,multiple  form  page  share  property  possible  differentiate  validation  constraint  message  message  catalog  example  login  form  registration  form  collect  userid  property  user  useridrequiredyou  must  provide  user  id  supplied  registerring  applied  login  form  correct  registration  form  inaccurate  confusing  extra  differentiation  needed  loginuseridrequiredyou  must  provide,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3703,hibernate  entity  session  persistent  strategy  store  transient  entity  asis  entity  session  persistence  strategy  right  thing  persistent  entity  however  first  creating  entity  often  useful  store  transient  entity  session  case  entity  stored  entity  type  entity  pk,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3704,unify  injection  allow  inject  annotation  field  service  implementation  come  especially  recent  training  although  im  strongly  favor  constructor  injection  use  final  field  store  dependency  allowed  inject  field  even  requires  use  reflection  would  real  boon,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3705,decrease  number  operation  hashmap  2  profiling  tapestry  framework  found  hashmap  actively  used  following  code  codetitlenamedsetjava  public  void  eachvalueworkert  worker  fflowgetvalueseachworker  code  hashset  internally  us  hashmap  created  inside  getvalues  iterate  changed  code  use  arraylist  instead  hashset  following  patch  time  per  request  decreased  35  m  74  overall  time  measurement  done  apache  benchmark  real  application  warm  phase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3706,prevent  interaction  page  fully  loaded  emphasis  javascript  issue  user  slow  connection  interacts  page  page  fully  loaded  javascript  run  initialization  lead  clientside  javascript  exception  serverside  failure  ordinary  request  sent  url  expect  ajaxxhr  request  right  solution  tapestry  provide  pageloading  mask  div  mask  entire  page  user  input  provides  loading  image  page  initialization  complete  implementaton  us  script  tag  documentwrite  introduce  mask  element  top  page  nonjavascriptenabled  client  able  interact  page  degree  cs  animation  used  fade  mask  delay  presentation  mask  modified  via  cs  override  default  black  50  opacity,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3707,tapestry  identify  template  undefined  component  id  type  matching  embedded  component  located  diagnosing  tap5317  found  lot  way  improve  t5s  exception  reporting  area,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3708,provide  access  annotation  service  implementation  class  situation  would  useful  direct  access  annotation  service  implementation  class  would  allow  u  registry  startup  detect  service  specific  class  method  level  annotation  take  related  action  instance  imagine  tapestryquartz  integration  based  simple  declarative  mechanism  would  possible  use  something  like  public  class  myserviceimpl  implement  myservice  scheduledcronexpression05  public  void  mymethod  framework  would  able  registry  startup  automatically  detect  service  method  annotated  scheduled  annotation  register  scheduler  see  two  possible  solution  1  modify  servicedef  hold  information  service  implementation  class  2  service  proxy  could  inherit  annotation  service  implementation  class  would  able  check  annotation  directly  service  proxy  maybe  another  elegant  solution  detail  see  thread  httpthreadgmaneorggmanecompjavatapestryuser67116focus67116,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3709,cooky  service  interface  could  simplified  using  builder  pattern  there  half  dozen  different  variation  could  simplified  using  builder  pattern  create  cookiebuilder  chain  sequence  method  call  invoke  commit  method  actually  create  add  cookie  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3710,expose  linkcreationhub  service  allow  listener  wish  observe  modify  new  link  instance  currently  linkfactory  internal  service  method  adding  removing  listener  refactored  public  service,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
3711,improve  component  report  providing  link  javadocs  tapestry  class  inspect  text  content  added  instance  orgapachetapestrymojocomponentreportaddchild  include  link  api  doc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3712,tapestryhibernate  split  two  part  tapestryhibernatecore  tapestryhibernate  tapestryhibernatecore  usable  outside  tapestry  web  application  people  often  want  use  facility  tapestryhibernate  batchnonweb  application  currently  bit  difficult  could  easily  simplified  splitting  tapestryhibernate  two,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3713,tapestry  performance  improvement  make  work  make  right  making  fast  t5  fast  faster  jsp  trivial  page  page  render  lot  ie  lot  loop  t5  keeping  may  much  need  narrow  gap,1,0,1,0,1,0,1,0,0,1,0,0,0,0,0,0,1
3714,control  creation  page  render  component  event  request  encapsulated  overridable  service  would  like  propose  extension  link  interface  setabsoluteuristring  absoluteuri  method  something  alike  give  flexibility  handling  link  linkcreationlistener  usecase  need  locale  browser  displayed  first  part  uri  eg  httpdomaincomenusmypage  use  dispatcher  detect  locale  change  completely  copy  linkfactoryimpl  localeawarelinkfactory  get  contributed  alias  able  set  uri  want  link  instantiation  change  uri  later  stage  need  add  linkcreationlistener,1,0,1,0,1,0,0,1,1,1,0,0,0,0,0,1,1
3715,tapestry  encode  user  locale  url  rather  http  cookie  would  nice  user  locale  showed  url  perhaps  context  path  example  contextenarticle  contextdeadminedit  would  make  link  encoding  decoding  rule  complex  still  support  current  url  basically  see  first  folder  request  path  match  one  configured  locale,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
3716,allow  component  library  contribute  extra  resource  global  application  catalog  component  library  desire  share  common  message  string  component  application  earlier  thought  define  way  libproperties  component  library  however  current  thinking  extend  componentmessagessource  source  application  message  catalog  well  component  library  contribute  resource  message  catalog  global  message  catalog  typically  appproperties  file  application  ability  override  specific  component  library  message,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
3717,allow  injection  tapestry  service  spring  bean  0,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0
3718,annotation  service  indicate  service  decorated  often  nice  apply  decorator  wide  range  service  using  regular  expression  glob  matching  however  frequently  result  problem  service  decorated  dependent  service  affected  decoration  example  decorate  many  service  related  masterobjectprovider  likely  get  cycle  dependency  exception  would  nice  annotation  indicates  service  ignored  decoration  much  limited  number  service  provided  tapestryiocmodule,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3719,tapestry  verify  public  method  module  class  meaningful  tapestry  build  decorate  contribute  bind  method  cause  exception  thrown  likely  typo  name  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3720,add  context  binding  prefix  make  supereasy  reference  context  asset  template  yes  assetcontextfoogif  thats  longer  id  like  really  want  use  asset  reference  context  asset  ensure  url  correct  short  relative  even  page  url  shift  due  activation  context  b  get  benefit  gzip  compression  versioning  url  farfuture  expires  header,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
3721,asset  longer  attempt  generate  relative  uris  change  related  localization  unlikely  asset  ever  relative  url  shorter  absolute  url  since  context  classpath  asset  stored  asset  folder  additional  qualifying  folder  version  number  etc  using  nonrelative  uris  also  help  javascript  issue  way  currently  public  way  ask  nonrelative  uri  asset  trip  dynamically  generated  javascript,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3722,create  service  fit  componentclasstransformworker  chain  configured  extract  component  metadata  class  annotation  word  moe  larry  curly  look  like  public  class  moeworker  implement  componentclasstransformworker  public  void  transformclasstransformation  transformation  mutablecomponentmodel  model  moe  annotation  transformationgetannotationmoeclass  annotation  null  modelsetmetametadatamoe  annotationvalue  would  nice  could  make  contribution  configurationaddmetadatamoe  moeclass  moe  larry  curly  instead  would  apply  annotation  single  attribute  whose  type  string,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1
3723,add  lazyadvisor  service  allow  method  invocation  service  lazily  evaluated  lazy  decorator  would  cool  would  allow  method  invocation  deferred  actually  needed  would  work  method  invocation  whose  return  value  interface  type  throw  checked  exception  decorator  ignore  method  qualify  actually  snap  implement  using  aspectdecorator,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3724,common  handlerfilter  pipeline  component  event  page  render  request  make  easier  add  filter  apply  type  request  currently  want  put  filter  place  afects  type  request  contribute  componenteventrequestfilter  componenteventrequesthandler  service  nearly  identical  pagerenderrequestfilter  pagerenderrequesthandler  service  would  nice  service  acted  facade  around  two  existing  pipeline  terminator  pipeline  could  forward  request  one  two  existing  pipeline  common  example  logged  filter  sends  redirect  user  logged  want  type  request,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
3725,maven  repository  location  httparchivaopenqaorgrepositoryreleases  unwanted  trailing  slash  master  pomxml  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3726,tracking  issue  change  required  comformostapestrytapestrytemplate  offapache  project  tapestrytemplate  allows  tapestry  page  used  template  generating  static  file  mail  content  requires  tweak  tapestrycore  following  site  live  soon  httptapestryformoscomnightlytapestrytemplate,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3727,easier  way  expose  parameter  embedded  component  containing  component  would  nice  simple  annotation  allowed  parameter  contained  component  exposed  parameter  containing  component  currently  create  field  apply  parameter  annotation  use  inherit  binding  child  component  note  new  parameter  appear  parameter  containing  component  term  component  reference  documentation,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1
3728,change  unless  render  thier  template  element  provided  ie  using  ttype  well  informal  parameter  use  lot  dummy  text  template  see  page  actually  look  like  rendered  filter  fragment  created  dummy  component  whose  setuprender  method  always  return  false  dont  know  efficient  would  nice  something  like  already  t5s  component  library  efficient  would  special  marker  xml  attribute  template  parser  recognizes  maybe  something  like  ttest  attribute  work  like  tif  testtif  contained  expression  evaluation  false  null  marked  element  filtered  ul  li  ttestshowitemconditional  itemli  li  ttestliteralfalsedummy  itemli  ul,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3729,cleanup  simplfy  pagetester  remove  componentinvocation  invocationtarget  etc  there  huge  amount  unnecessary  clutter  support  pagetester  form  componentinvocationmap  compnentinvication  invocationtarget  etc  make  code  related  generating  link  confusing  need  cleaned  even  consider  allow  application  take  control  link  creation  dispatch,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
3730,rendering  pagelink  necessary  load  target  page  instance  see  there  page  activation  context  currently  generating  page  render  link  inside  linksource  load  instance  target  page  fire  passivate  event  instance  wasteful  tapestry  know  event  page  instance  handle  could  determined  class  transformation  way  determine  render  phase  component  implement  possible  avoid  loading  page  unless  passivate  event  handler  could  make  big  different  application  startup  time  page  referenced  initial  page  must  fully  loaded  downside  often  loading  page  early  cause  early  failure  ie  page  login  error  page  index  page  link  well  see  error  first  request  pagelink  force  load  login  page  improvement  login  page  error  wouldnt  seen  user  navigated  page  see  acceptible,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,1
3731,move  clientbehaviorsupport  public  service  package  generally  useful  environmental  service  interface  nearly  useful  rendersupport  public,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3732,add  parallelexecutor  service  allow  operation  performed  asynchronously  thread  pool  im  looking  area  t5  better  done  parallel  ie  io  bound  im  still  finding  work  code  simple  useful  keep,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
3733,objectlocatorgetserviceclass  expanded  pas  varargs  marker  annotation  type  somemarker  annotation  markersomemarker  void  someservice  buildsomeservice  get  someservice  marker  objectlocator  found  like  method  method  like  getservice  extends  annotation  marker  classt  interface,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3734,exception  report  page  jvm  system  property  orgapachecatalinajspclasspath  displayed  list  like  path  value  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3735,javascript  library  combined  single  request  possible  create  virtual  resource  asset  represents  javascript  library  particular  page  envision  base64  stream  actually  composite  list  path  real  javascript  file  encoded  way  multiple  page  use  set  javascript  library  share  single  stream  combined  stream  gzipped  client  support  packedminimalized  extra  bookkeeping  needed  track  j  file  combined  client  track  loaded  j  library  ajax  partial  update  requires  new  library  required  main  page  render  example  partial  update  includes  form  clientside  validation,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3736,reduce  eden  space  memory  footprint  avoiding  list  map  within  element  5100  element  optional  list  childnodes  caseinsensitivemap  attribute  could  removed  replaced  linked  list  thus  optimized  creation  dom  streaming  le  emphasis  manipulating  dom  fact  significant  decrease  number  shortlived  object  map  mapentry  list  etc,1,0,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0
3737,provide  support  url  rewriting  tapestry  provide  way  configured  via  tapestryioc  provide  url  rewriting,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3738,tapestry  support  ie  conditional  stylesheets  mailing  list  hi  web  application  different  cs  ie6  ie7  link  relstylesheet  mediascreen  projection  hrefassetcontextcssmaincss  ie  7  link  relstylesheet  mediascreen  projection  hrefassetcontextcssie7css  endif  lte  ie  6  link  relstylesheet  mediascreen  projection  hrefassetcontextcssie6css  endif  ie7  ie6  ordinary  html  comment  thats  browser  understands  tapestry  becouse  tapestry  want  assetcontextcssmaincss  include  cs  file  chance  include  ie7css  ie6css  seems  like  something  rendersupport  could  support  much  support  medium  type,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3739,add  service  responsible  encoding  client  data  gzipped  base  64  decoding  data  several  issue  rely  able  override  service  control  exactly  data  represented  client  ie  pointer  data  kept  server  additional  checksum  data  prevent  tampering,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3740,add  method  dom  element  class  allow  collection  attribute  obtained  ive  written  jaxen  httpjaxencodehausorg  extension  use  xpath  tapestry  dom  going  well  far  except  cant  get  sensible  access  attribute  way  iterate  attribute  orgapachetapestry5domelement  please  add  collectionattribute  getattributes  method  element  make  attribute  class  public,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3741,add  simple  pagerenderlinksource  service  allow  service  create  link  page  public  interface  pagerenderlinksource  link  createpagerenderlinkstring  pagename  link  createpagerenderlinkwithcontextstring  pagename  object  context  link  createpagerenderlinkclass  pageclass  link  createpagerenderlinkwithcontetclass  pageclass  object  context,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3742,provide  alternate  approach  decorating  service  based  aspect  would  nice  decorator  could  passed  aspectinterceptorbuilder  could  choose  advise  method  decorator  method  could  return  void  would  need  delegate  passed  difficulty  order  single  service  advised  method  interceptor  via  traditional  50style  decorator  advised  method  change  would  grouped  together  outcome  may  desired  may  required  single  service  50  style  decorator  51  style  aspect,1,0,1,0,1,0,0,0,1,0,0,1,1,0,0,0,0
3743,simple  way  override  automatic  javascript  library  stylesheets  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
3744,urlrewriting  distinguish  incoming  outgoing  request  currently  new  urlrewriting  support  us  single  method  set  rewrite  rule  called  process  method  called  transforming  incoming  request  url  rewriting  outbound  link  generally  however  url  incoming  request  going  translated  tapestryaware  url  url  link  mapped  tapestryaware  url  external  form  facilitate  v  mapping  url  rewriting  provide  mechanism  distinguish  rewriting  incoming  url  v  rewriting  link  three  possible  way  1  separate  service  incoming  v  outgoing  rewriting  2  alter  urlrewriterrule  api  change  single  process  method  two  method  processincoming  processoutgoing  something  along  line  3  alter  urlrewriterrule  api  pas  additional  rewritecontext  method  parameter  context  would  include  single  method  boolean  isincoming  perhaps  boolean  isoutgoing  alternatively  could  change  method  signature  provide  boolean  isoutgoing  parameter  providing  rewritecontext  would  allow  api  evolve  better  future  find  additional  context  information  useful  currently  leaning  towards  2  positive  point  3  could  handled  future  introduction  perthread  helper  service  rewritecontext  could  injected  directly  rewrite  rule,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
3745,allow  page  class  page  suffix  included  url  application  lot  readonly  page  example  page  show  company  would  like  uri  company1234  however  name  page  class  company  get  naming  clash  domain  object  company  would  like  call  tapestry  5  class  companypage  class  represents  certainly  team  refers  thing  internally  business  ie  seen  new  company  page  please  could  componentclassresolverimpl  remove  suffix  page  exists  class  name  construct  logical  page  name,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3746,allow  blackbird  disabled  production  mode  blackbird  use  f2  show  console  interfering  application  us  fkeys  hotkeys  access  various  part  application  possible  either  completely  disable  blackbird  production  mode  avoiding  unnecessary  cs  j  downloads  least  disable  console  hotkey,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3747,add  annotation  contribute  allow  service  contributor  method  arbitrary  named  tapestry  used  require  naming  convention  configuring  service  public  static  foo  buildfoo  public  static  void  contrubutefoo  allowed  first  convention  simplified  public  static  foo  build  would  nice  contribute  method  allow  also  simpler  naming  use  type  configuration  parameter  determine  configured  service  also  type  parameter  example  tapestry  505  tapestrymodulejava  public  servletapplicationinitializer  build  listservletapplicationinitializerfilter  configuration  appmodulejava  tapestry  505  requires  naming  public  void  contributeservletapplicationinitializerorderedconfigurationservletapplicationinitializerfilter  configuration  perhaps  could  simplified  public  void  contributeorderedconfigurationservletapplicationinitializerfilter  configuration  simplified  would  nice  make  documentation  tapestry  ioc  configuration  clear  naming  contribute  method  important  type  configuration  parameter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3748,tapestry  automatically  compress  content  sent  client  client  support  browser  accept  gzip  compression  text  stream  tapestry  identify  content  type  may  compressed  perhaps  minimum  byte  count  trigger  compression  thus  texthtml  textjavascript  stream  might  compressed  jpeg  png  already  compressed  pas  unchanged,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
3749,change  template  parser  use  stax  yet  compatible  google  app  engine  stax  apis  gae  white  list  reasonable  ot  change  code  using  sax  parser  par  template  list  token  iterate  token  list  today  using  stax  end  result  fewer  dependency  boot,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0
3750,javascript  library  automatically  packedminimalized  tapestry  catch  downloads  javascript  library  pack  javascript  remove  comment  unecessary  whitespace  believe  dojo  library  may  even  shorten  variable  name  smart  implementation  would  manage  cache  compressed  j  notice  uncompressed  version  changed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3751,provide  way  component  subclass  merge  template  container  idea  ive  picked  wicket  special  element  similar  tapestry  tbody  used  indicate  child  component  template  go  wicket  page  often  given  common  lf  use  common  component  extending  common  base  class  mixing  base  class  template  subclass,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3752,much  work  hide  t5  page  inside  virtual  folder  use  mixedimplementation  deployment  mixedimplementation  deployment  mixing  tapestry  5  tapestry  4  framework  would  nice  t5  apps  could  hidden  virtual  t5  folder  doable  awkward  ugly  today  ideally  would  matter  changing  webxml  mapping  urlfiltert5urlfilter  making  form  configuration  change  ie  configurationaddconfigurationconstantstapestryappfolder  t5  would  affect  link  generation  prefixing  url  t5  including  virtual  asset  folder  would  t5assets  since  t5  portion  part  url  mapping  would  part  request  pathinfo  existing  dispatch  code  would  need  change  course  websphere  bug  area  might  cause  grief,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3753,zone  include  option  periodically  update  default  rerender  body  unless  renderable  result  return  event  handler  update  event  trigger,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
3754,form  event  validateform  awkwardly  named  replaced  simpler  name  validate  end  method  like  onvalidateformfromlogin  asking  trouble  onformvalidatefromlogin  bit  better  obviously  keep  old  name  well  fire  two  event  validate  form  stage  would  better  name  something  doesnt  form  perhaps  finalvalidation  validate  remember  problem  calling  validate  conflicted  validate  event  form  form  control  element  component  really  problem,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3755,improve  tapestry  property  expression  language  include  ognllike  feature  really  use  prop  typesafeness  still  find  frequently  need  complicated  expression  enough  would  willing  pay  speed  penalty  reflection  order  define  public  getter  situation  cant  actually  make  equivilent  getter  instance  integration  test  ive  one  situation  wanted  call  setter  specific  value  template  ognl  easy  prop  impossible  would  much  like  see  prop  remain  default  binding  ognl  available  needed  think  would  severe  limitation  t5,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3756,provide  applicationstatepersistencestrategy  hibernate  entity  persisting  hibernate  entity  httpsession  good  idea  entity  becomes  detached  hibernate  session  would  nice  applicationstatepersistencestrategy  store  primary  key  entity  session  strategy  make  use  class  persistedentity  like  entitypersistentfieldstrategy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3757,change  proxy  generation  use  volatile  field  rather  synchronized  block  currently  coded  service  proxy  used  tapestry  service  use  synchronized  block  check  see  registry  shut  b  obtain  needed  realized  service  implementation  wrapped  interceptor  etc  seems  juggling  could  largely  replaced  atomicboolean  atomicreferences,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3758,move  away  javassist  longterm  multirelease  strategy  replace  classfactoryclassgen  classtransformation  method  equivalent  tied  javassist  couple  release  method  could  introduced  still  implemented  top  javassist  javassistcentric  method  deprecated  eventually  disabled  notimplementedexception  even  removed  rationale  javassist  unprofessionally  fitfully  maintained  many  user  problem  java6  due  javassist,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3759,context  asset  versioned  provided  far  future  expires  header  like  classpath  asset  asper  yslow  recommendation  asset  context  ie  context  asset  prefix  treated  like  classpath  asset  url  sent  browser  reflect  version  number  defined  application  file  given  far  future  expiration  date  url  might  appassets123imageslogogif  file  referenced  contextimageslogogif  application  would  define  version  number  would  developer  responsibility  advance  version  number  whenever  context  file  change  ie  new  deployment  application,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3760,optimize  page  construction  repeated  construction  page  construction  page  probably  largest  expense  request  involves  considerable  work  identify  component  instantiate  binding  create  template  token  converted  componentpageelements  possible  devise  page  template  list  command  constructing  page  current  pageloaderprocessor  would  generate  list  command  creating  page  instance  would  matter  executing  command  would  decrease  amount  time  needed  generate  2nd  later  instance  page  would  increase  likelyhood  common  page  element  literal  text  could  reused  across  page  instance  making  page  instance  creation  le  expensive  would  allow  tapestry  aggressively  cull  unused  page  instance  ie  shorten  active  window  sacrificing  ability  handle  request  surge,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
3761,add  optional  annotation  mark  contribution  method  ignored  indicated  service  exist  currently  registry  wil  start  module  make  contribution  service  exist  eg  module  service  loaded  make  problem  application  allow  installation  subset  module  started  module  able  contribute  extension  point  available  case  service  exist  contribution  ignored,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3762,objectlocatorautobuild  would  useful  override  allowed  message  object  described  message  would  used  operatontracker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3763,formfragment  component  include  parameter  control  whether  nonvisible  content  included  form  submission  current  behavior  nonvisible  content  submit  form  correct  application  would  nice  selectable  readily  new  parameter  formfragment  allows  removeifnotvisible  logic  disabled  particular  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3764,typecoercer  able  coerce  string  enum  type  even  without  specific  contribution  current  implementation  allow  coersion  form  string  literal  enum  need  add  contribution  typecoercer  working  coersion  performed  default  using  enumvalueof  class  string  required  register  new  coersion  every  used  enum  type  case  whe  lost  case  insensibility  enum  coersions  meaningfull  everyone  still  use  contributed  coersions  one  found  fallback  default  enumvalueof,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
3765,reorganize  componentclasstransformworkers  start  moving  away  javassist  begin  moving  code  form  implemented  without  javassist  creating  new  method  classtransformation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3766,implement  agnostic  tapestryjs  layer  adapter  allow  developer  switch  prototype  jquery  per  discussion  mailing  tapestry  5  jquery  create  jira  compile  toughts  everyone  feature  howard  said  mailing  list  goal  goal  1  backwards  compatibility  goal  2  documented  goal  3  plugability  extensibility  overridablilty  first  design  thought  suggested  howard  extracted  howard  answer  1  tapestryjs  defines  tapestry  namespace  key  function  property  standard  stuff  2  split  current  tapestryjs  smaller  file  3  addition  tapestryjs  include  either  tapestryprototypeadapterjs  plus  prototypejs  scriptaculousjs  tapestryjqueryadapterjs  plus  jqueryjs  4  tapestryjs  smaller  handler  often  fire  additional  event  cascade  event  eventually  result  serverside  request  objective  1  make  certain  part  pluggable  ie  popup  bubble  2  write  javascript  functional  closure  3  element  could  one  active  animation  animation  would  complete  next  one  cf  jquery  animation  queuing  mechanism  challenge  1  remove  prototype  code  tapestryjs  2  keep  backward  compatibility  existing  tapestry  object,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
3767,allow  absolute  filename  fileresourceloader  way  providing  absolute  path  eg  ctempwibbletmp  fileresourceloader  always  attempt  use  2argument  file  constructor  even  path  component  empty  following  fix  resolve  problem  fileresourceloaderfindtemplate  replace  file  file  new  file  path  template  file  file  null  ifequalspath  file  new  file  template  else  file  new  file  path  template  note  introduce  security  risk  fileresourceloader  must  configured  search  empty  path,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3768,resourcefactory  extensible  class  orgapachevelocityruntimeresourceresourcefactory  provides  mechanism  allowing  subclass  template  contentresources  returned  since  resourcemanagerimpl  make  call  resourcefactorygetresource  way  override  behavior  subclass  resourcemanagerimpl  cutpastethenmodify  code  loadresource  least  moving  resourcefactorygetresource  call  separate  protected  method  resourcemanagerimpl  would  greatly  simplify  subclassing  template  andor  contentresources,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3769,cant  load  macro  file  loaded  parse  think  big  bug  ive  used  velocity  project  erveything  ok  want  know  problem  resolved  next  version  abandon  velocity  bug  doc  important  remember  try  parse  template  containing  inline  macro  directive  parse  happens  runtime  parser  decides  vmlooking  element  template  vm  parsetime  parseing  set  vm  declaration  wont  work  expected  get  around  simply  use  velocimacrolibrary  facility  velocity  load  vms  startup,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3770,enhance  velocity  logsystem  internal  use  thereof  several  long  debate  geir  commonslogging  become  largely  convinced  something  hesitation  ie  let  talk  20  ive  also  begun  frustration  commonslogging  work  project  velocitytools  regardless  issue  clear  velocity  logsystem  use  great  need  improvement  need  lower  priority  many  message  eliminate  upgrade  system  useful  specific  unevaluated  offthecuff  idea  make  logging  nullop  logger  found  rather  panic  break  detect  jdk  14  logging  add  trace  level  add  islevelenabled  make  possible  grab  logsystem  instance  sort  velocity  extension  use  sensibly  im  tired  hack  must  tool  idea  might  even  feasible  still  im  hoping  take  whack  hoping  others  help  volunteer  time  still  rather  limited,1,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,1
3771,improved  syntax  map  collection  would  like  see  syntatic  sugar  map  collection  perhaps  object  read  syntax  map  literal  15  thats  first  step  want  something  like  groovy  httpgroovycodehausorgcollections  scroll  slicing  subscript  operator  p  please  never  implement  terrible  confusing  groovy  map  bean  syntax  mapfoo  ist  equivalent  mapgetfoo,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3772,extend  methodinvocation  exception  able  give  velocity  macro  writer  usefull  error  page  use  velocity  macro  invoke  method  java  written  web  engine  invoked  method  fails  exception  possible  use  methodinvocation  exception  give  velocity  macro  writer  usefull  error  page  since  methodinvocation  exception  cause  set  short  reason  method  invocation  failed  routed  back  veloticy  macro  writer  running  system  extended  methodinvocationexceptionjava  method  execute  astmethodjava  proposed  change  methodinvocationexceptionjava  package  orgapachevelocityexception  import  orgapachevelocityexceptionvelocityexception  import  orgapachevelocityruntimeparsertoken  copyright  20012004  apache  software  foundation  licensed  apache  license  version  20  license  may  use  file  except  compliance  license  may  obtain  copy  license  httpwwwapacheorglicenseslicense20  unless  required  applicable  law  agreed  writing  software  distributed  license  distributed  basis  without  warranty  condition  kind  either  express  implied  see  license  specific  language  governing  permission  limitation  license  applicationlevel  exception  thrown  reference  method  invoked  exception  thrown  br  exception  thrown  best  effort  made  useful  information  exception  message  complete  information  consult  runtime  log  author  hrefmailtogeirmoptonlinenetgeir  magnusson  jra  version  id  methodinvocationexceptionjavav  12141  20040303  232254  geirm  exp  public  class  methodinvocationexception  extends  velocityexception  private  string  methodname  private  string  referencename  private  throwable  wrapped  null  private  int  line  added  cx  private  int  column  added  cx  ctor  wrap  passed  exception  examination  later  param  message  param  e  throwable  wrapping  param  methodname  name  method  threw  exception  public  methodinvocationexception  string  message  throwable  e  string  methodname  supermessage  thiswrapped  e  thismethodname  methodname  return  name  method  threw  exception  return  string  name  method  public  string  getmethodname  return  methodname  return  wrapped  throwable  caused  methodinvocationexception  thrown  return  throwable  thrown  method  invocation  public  throwable  getwrappedthrowable  return  wrapped  set  reference  name  threw  exception  param  reference  name  reference  public  void  setreferencename  string  ref  referencename  ref  retrieves  name  reference  caused  exception  return  name  reference  public  string  getreferencename  return  referencename  retrieves  line  number  error  occured  return  line  number  public  int  getline  return  line  set  line  number  error  occured  param  line  public  void  setlineint  line  thisline  line  retrieves  line  number  error  occured  return  column  number  public  int  getcolumn  return  column  set  column  number  error  occured  param  column  public  void  setcolumnint  column  thiscolumn  column  proposed  change  astmethodjava  package  orgapachevelocityruntimeparsernode  copyright  200020012004  apache  software  foundation  licensed  apache  license  version  20  license  may  use  file  except  compliance  license  may  obtain  copy  license  httpwwwapacheorglicenseslicense20  unless  required  applicable  law  agreed  writing  software  distributed  license  distributed  basis  without  warranty  condition  kind  either  express  implied  see  license  specific  language  governing  permission  limitation  license  import  orgapachevelocitycontextinternalcontextadapter  import  orgapachevelocityruntimeparser  import  orgapachevelocityutilintrospectionintrospectioncachedata  import  orgapachevelocityutilintrospectionvelmethod  import  orgapachevelocityutilintrospectioninfo  import  orgapachevelocityexceptionmethodinvocationexception  import  javalangreflectinvocationtargetexception  import  orgapachevelocityappeventeventcartridge  astmethodjava  method  support  reference  foomethod  note  introspection  done  render  time  please  look  parserjjt  file  control  generation  class  author  hrefmailtojvanzylapacheorgjason  van  zyla  author  hrefmailtogeirmoptonlinenetgeir  magnusson  jra  version  id  astmethodjavav  12441  20040303  232259  geirm  exp  public  class  astmethod  extends  simplenode  private  string  methodname  private  int  paramcount  0  public  astmethodint  id  superid  public  astmethodparser  p  int  id  superp  id  accept  visitor  public  object  jjtacceptparservisitor  visitor  object  data  return  visitorvisitthis  data  simple  init  init  subtree  get  ast  public  object  init  internalcontextadapter  context  object  data  throw  exception  superinit  context  data  methodname  getfirsttokenimage  paramcount  jjtgetnumchildren  1  return  data  invokes  method  return  null  problem  actual  return  method  return  something  empty  string  method  return  void  public  object  executeobject  internalcontextadapter  context  throw  methodinvocationexception  new  strategy  strategery  introspection  since  want  thread  well  contextsafe  must  execution  time  innode  caching  careful  context  velmethod  method  null  object  params  new  objectparamcount  try  check  cache  introspectioncachedata  icd  contexticacheget  class  c  ogetclass  like  astidentifier  cache  information  class  object  cache  safe  icd  null  icdcontextdata  c  sadly  need  recalc  value  args  change  visit  visit  int  j  0  j  paramcount  j  paramsj  jjtgetchildj  1valuecontext  get  method  cache  method  velmethod  icdthingy  else  otherwise  introspection  cache  int  j  0  j  paramcount  j  paramsj  jjtgetchildj  1valuecontext  method  rsvcgetuberspectgetmethodo  methodname  params  new  info11  method  null  icd  new  introspectioncachedata  icdcontextdata  c  icdthingy  method  contexticacheput  icd  still  havent  gotten  method  either  calling  method  doesnt  exist  fine  screwed  method  null  return  null  catch  methodinvocationexception  mie  come  dointrospection  arg  value  evaluated  find  right  method  signature  want  propogate  anything  fancy  throw  mie  catch  exception  e  come  dointropection  also  introspector  rsvcerrorastmethodexecute  exception  introspection  e  return  null  try  get  returned  object  may  null  valid  something  declared  void  return  type  since  caller  expecting  something  returned  long  thing  peachy  return  empty  string  astreference  correctly  figure  well  object  obj  methodinvokeo  params  obj  null  methodgetreturntype  voidtype  return  new  string  return  obj  catch  invocationtargetexception  ite  event  invocation  method  throw  exception  want  catch  wrap  throw  dont  log  want  figure  reference  threw  exception  eventcartridge  ec  contextgeteventcartridge  event  cartridge  see  want  veto  also  let  nonexception  throwables  go  ec  null  itegettargetexception  instanceof  javalangexception  try  return  ecmethodexception  ogetclass  methodname  exceptionitegettargetexception  catch  exception  e  methodinvocationexception  miex  new  methodinvocationexception  invocation  method  methodname  ogetclass  threw  exception  egetclass  egetmessage  e  methodname  miexinitcauseitegettargetexception  miexsetlinefirstbeginline  miexsetcolumnfirstbegincolumn  throw  miex  else  event  cartridge  override  throw  methodinvocationexception  miex  new  methodinvocationexception  invocation  method  methodname  ogetclass  threw  exception  itegettargetexceptiongetclass  itegettargetexceptiongetmessage  itegettargetexception  methodname  miexinitcauseitegettargetexception  miexsetlinefirstbeginline  miexsetcolumnfirstbegincolumn  throw  miex  catch  exception  e  rsvcerrorastmethodexecute  exception  invoking  method  methodname  ogetclass  e  return  null,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
3773,remove  exception  type  throwing  use  checkstyle  coding  standard  job  methos  velocity  throw  exception  using  raw  exception  type  checkstyle  point  error  everywhere  use  velocity  unfortunately  thats  fact  cannot  override  source  code  would  nice  throw  exception  replaced  velocity  proper  exception,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
3774,improve  resource  existence  detection  depending  resourceloader  used  testing  existence  resource  somewhat  expensive  resource  opened  test  existence  im  proposing  following  change  1  add  new  method  orgapachevelocityruntimeresourceloaderresourceloader  public  boolean  resourceexistsstring  source  inputstream  null  try  resourceloadergetresourcestreamresourcename  null  return  true  catch  resourcenotfoundexception  e  finally  null  try  isclose  catch  exception  e  return  false  method  keep  compatibility  current  resourceloaders  overriden  subclass  2  orgapachevelocityruntimeresourceresourcemanagerimpl  modify  string  getloadernameforresourcestring  resourcename  method  use  new  resourceloaderresourceexistsstring  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3775,velocity  14  support  iterable  collection  new  loop  java  5  eg  forobject  obj  iterable  collection  iterated  need  type  iterable  however  velocity  foreach  loop  must  either  collection  map  cannot  iterable  suggestion  support  iterable  container,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3776,add  documentation  explain  precedence  resolving  property  velocity  user  guide  clear  precedence  resolving  property  variable  uberspectimpljava  code  precedence  resolve  property  something  like  order  getbar  getbar  getbar  isbar  information  useful  user  suggest  added  user  guide  property  section,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3777,throw  exception  log  le  error  velocity  application  exception  based  runtimeexception  opportunity  use  exception  signal  application  level  problem  im  particularly  concerned  initialization  problem  logged  may  missed  need  review  logged  error  message  see  would  appropriate  throw  exception  instead  place  may  need  leave  backwards  compatibility  reason  eg  macro  global  macro  library  doesnt  parse  properly  llewellyn  falco  made  good  case  dev  list  recently  httpwwwmailarchivecomvelocitydevjakartaapacheorgmsg15067html  still  would  like  put  vote  sending  error  log  incredibly  bad  idea  something  working  loudly  shown  exception  working  dont  really  need  log  velocity  log  velocity  developer  programming  actual  velocity  code  user  dont  ever  care  see  tomcat  log  care  see  thing  log  tomcat  many  many  many  people  check  log  let  alone  frequently,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
3778,user  feedback  wish  oreilly  blog  look  wishlist  httpwwworeillynetcomonjavablog200703velocity15html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3779,support  varargs  method  call  possible  much  possible  without  breaking  jdk  13jdk  14  runtime  support  would  like  see  u  support  varargs  method  call  public  class  mytool  public  list  combinelist  list  set  twolists  mytoolcombinelist1  list2  set  threelists  mytoolcombinelist1  list2  list3  work  box  without  need  user  rebuild  velocity,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3780,add  ablity  add  directive  programatically  directive  may  complex  initialization  setup  requirement  much  simpler  configure  calling  code  thru  reflection  mechanism  attached  patch  add  method  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3781,display  consistent  file  line  number  format  error  provided  patch  change  display  file  error  one  consistent  format  format  implemented  following  filenameline  lnum  column  cnum  filename  available  filename  substituted  unknown  file  consistent  format  help  tool  detect  process  file  reference  velocity  log  exception,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3782,fix  correct  template  name  reporting  enhance  error  logging  information  fix  template  name  reporting  include  parse  exception  occurs  error  reporting  velocity  tends  use  contextgettemplatename  intended  scoping  information  always  provide  template  name  containing  node  directive  generates  error  add  templatename  field  directive  object  assigns  creation  template  name  available  also  added  template  location  info  logging  error  thrown  parse  compliment  pseudostack  trace  already  logged  error  macro  complete  trace  logged  error  macro  template  layer  template  name  location  yea,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3783,parsing  error  content  inside  literal  end  block  velocity  template  include  quit  javascript  inside  javascript  javascrip  template  engine  used  also  us  varname  escaping  occurance  would  make  code  rather  unreable  prevent  velocity  parsing  javascript  code  put  literal  around  however  velocity  still  par  content  block  course  result  parsing  exception  feeling  literal  completely  uninterpreted  content  work  literal  var  myid  someid  testappendtemplatediv  idmyiddivapplymyid  myid  end,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3784,blockmacro  support  allows  ast  macro  body  argument  inspired  velocity583  blockmacro  support  implemented  functionality  slightly  different  way  new  syntax  yourmacronamearg1  arg2  valid  velocity  ast  end  basically  syntax  exactly  normal  macro  except  put  prefix  macro  name  tell  velocity  there  macro  ast  body  passed  actual  macro  macro  refer  passed  body  0n  time  like  macroyourmacroname  foo  bar  bodycontent  end,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3785,minor  performance  tweak  based  findbugs  finding  mainly  change  two  inner  class  static  inner  class  slight  modification  see  patch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3786,macro  pas  value  option  add  configuration  property  would  change  macro  parameter  passing  pas  name  pas  value  think  many  instance  option  provide  behavior  intuitive  user  two  important  exception  reference  created  define  reference  created  blockmacros  bodycontent  allows  user  still  specify  pas  name  semantics  desired  example  definex  iffoofoobarelsenoneend  end  gox  example  iffoofoobarelsenoneend  passed  name  case  pas  value  rule  apply  example  gofoobar  1  2  3  ifbaryeselsenoend  example  parameter  evaluated  value  first  passed  go  potential  performance  improvement  also,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3787,preceding  reference  strict  mode  ignores  null  exception  change  strict  mode  runtimereferencesstrict  true  behavior  velocity  attempt  render  reference  evaluates  null  throw  exception  reference  preceded  foo  simply  render  nothing  ignore  null  value  non  strict  mode,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3788,handle  empty  stringsarrayscollectionsmaps  conveniently  idea  dev  list  sat  feb  7  2009  341  pm  serg472gmailcom  wrote  hello  wanted  share  idea  new  simple  improvement  displaytools  able  make  patch  interested  1  add  new  method  isemptyobject  return  true  object  null  empty  string  zero  length  collection  map  array  zero  size  help  annoying  null  check  probably  better  place  method  would  engine  tool  yeah  something  tool  would  interesting  uberspect  pretend  every  nonnull  reference  isempty  method  perhaps  add  0length  string  empty  collection  empty  map  0length  array  list  thing  foo  considers  false,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
3789,add  macro  default  parameter  add  ability  specify  default  parameter  macro  example  macrofoo  x  ylegitxyend  calling  foo2  would  give  2legit  number  default  parameter  specified  nondefault  parameter  follow  default  parameter  assignment  calling  value  begin  left  right  left  default  argument  assigned  default  value,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3790,stop  specified  stoptemplate  parsing  stop  current  template  rendering  stoptemplate  stop  current  template  template  called  parse  command  rendering  end  within  given  parse  resume  within  calling  template,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3791,vtl  simplicity  control  object  discussion  velocity680  claude  suggested  addition  im  calling  control  object  solution  would  name  block  directive  macro  belong  minimum  would  provide  getkey  setkey  value  stop  method  control  reference  scoping  execution  block  belong  directive  could  extend  basic  control  object  provide  additional  function  index  hasnext  foreach  here  example  foreach  user  user  userif  foreachhasnext  end  foreachcount  10  foreachstop  end  end  macro  foo  bar  blah  blah  bar  bar  foostop  end  set  foowoogie  woogie  foowoogie  end  foreach  item  list  set  outer  foreach  foreach  attr  itemattributes  attr  null  outerstopend  end  end  foovm  blah  blah  templatestop  blah  define  foo  blah  blah  definestop  blah  end  could  allow  u  greatly  simplify  sort  thing  could  remove  break  stop  return  directive  would  longer  need  local  context  foreach  loop  macro  instead  user  could  set  get  local  variable  directly  provided  namespace  else  would  global  may  even  cut  internal  code  complexity  fair  bit  itll  certainly  obviate  need  several  configuration  property  internal  context  everything  becomes  much  explicit  obvious  robust  also  dont  think  look  ugly  would  course  make  sure  stopexceptions  thrown  stop  arent  wrapped  methodinvocationexceptions  wed  make  directive  clean  control  done  rendering  theyre  nested  directive  type  save  restore  reference  parent  control  wed  also  figure  good  default  name  give  control  object  toplevel  control  object  whether  would  different  name  control  object  used  parse  call  template  parse  velocity  wanted  use  templatewhich  think  work  well  toplevel  parsethen  wed  probably  make  configurable  since  thats  likely  conflict  make  configurable  suppose  may  well  make  configurable  others  im  struggling  think  real  downside  replaced  feature  implicit  macro  localscope  stop  break  velocityhasnext  either  default  behavior  new  feature  id  wager  people  would  change  velocitycount  foreachcount  even  thats  big  deal  since  would  major  version  change  worst  think  fact  couple  control  would  mean  keystroke  considering  gain  extensibility  explicitness  simplification  u  user  think  worth  keystroke  guy  think,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3792,implement  default  value  formal  reference  take  profit  formal  reference  syntax  implement  default  value  foobar  could  even  repeated  nested  foobarbaz  foobarbaz,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3793,change  inheritance  model  abstract  filesystem  class  composition  along  factory  class  allows  u  use  different  f  implementation  0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1
3794,remove  downloadhadoop  profile  requirement  cache  downloads  0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
3795,normalize  usergroup  mapping  end  end  test  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3796,setup  automated  patch  testing  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3797,fix  sentry  precommit  test  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3798,merge  master  dbpolicybranch  sentry121,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3799,support  filter  pushdown  db  store  client  reduce  data  transfer  db  store  service  authorization  provider  retrieves  privilege  given  set  group  could  huge  data  set  large  number  privilege  system  downstream  consumer  like  hiveserver2  reading  query  could  impact  db  store  performance  multiple  active  query  numerous  privilege  rule  could  consider  pushing  filter  like  db  object  name  policy  provider  prune  privilege  result  set  source,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3800,hive  binding  enable  mr  level  acls  session  user  hive  sentry  requires  impersonation  turned  file  system  access  mr  job  directly  handled  user  hive  hive  binding  enable  set  mr  job  acls  session  user  access  job  interface  like  hue  done  adding  userid  config  property  mapreducejobaclmodifyjob  mapreducejobaclviewjob,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3801,sentry168  trivial  fix  readme  pomxml  minor  fix  readme  pomxml  cannot  use  mvn  compile  compile  sentry  issue  httpjiracodehausorgbrowsemexec91  need  wget  run  hive  end  end  test  add  description  rat  excludes,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
3802,generate  audit  trail  sentry  dbstore  service  action  sentry  db  store  generate  audit  log  authorization  metadata  change  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3803,add  sentry  service  apis  query  role  privilege  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3804,add  schematool  creating  sentry  store  schema  sql  script  need  tool  similar  hive  schematool  creating  sentry  store  schema,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3805,create  tool  dump  load  entire  sentry  service  storing  entire  content  sentry  service  database  would  useful  sentry  tool  would  able  dump  entire  content  sentry  specific  format  independent  used  database  backend  counterpart  would  able  read  format  load  data  another  instance  sentry  service  tool  helpful  backup  migration  one  backend  store  another  debugging  content  underlying  database,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,1,0
3806,create  tool  convert  policy  file  db  store  new  db  store  user  manually  migrate  existing  configuration  policy  file  db  store  make  path  easy  providing  tool  able  conversion  automatically,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3807,user  group  lookup  sentry  db  policy  server  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3808,show  grant  role  xxx  server  database  table  uri  xxx  handling  filtering  privilege  based  db  object  service  level  also  reduce  amount  privilege  data  transferred  wire,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3809,support  show  current  role  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3810,create  new  mvn  cluster  test  profile  provider  db  test  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
3811,create  diagnostics  tool  configuration  validation  create  tool  offline  troubleshooting  validate  configuration  list  permission  given  user  offline  query  validation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3812,support  auth  admin  delegation  via  sql  construct  grant  option  currently  authorization  admins  created  statically  setting  config  property  sentry  support  admin  delegation  via  grant  option  statement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3813,add  granular  privilege  dbmodel  specifically  would  good  split  privilege  create  drop  alter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3814,support  sentry  service  api  retrieve  applicable  privilege  given  authorizable  object  current  implementation  listsentryprivilegesforprovider  specifically  facilitate  sentry  auth  engine  intended  general  purpose  metadata  query  add  new  api  return  list  privilege  tsentryprivilege  give  authorizable  object  applicable  privilege,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3815,enable  sentry  end  end  test  run  real  cluster  adding  dfs  implementation  clusterdfs  along  unmanagedhiveserver  used  run  test  real  secure  cluster  adding  maven  profile  set  required  classpath  run  test  supported  run  real  secure  cluster  unmanagedhiveserver  test  run  clusterhaoop  profile  testcrossdbops  testendtoend  testmetadataobjectretrieval  testmetadatapermissions  testmovingtoproduction  testperdatabasepolicyfile  testprivilegeattransform  testprivilegesatdatabasescope  testprivilegesattablescope  testsandboxops  testexportimportprivileges  testuripermissions  testruntimemetadataretrieval  test  run  testusermanagement  non  static  usergroup  mapping  testserverconfiguration  us  managed  hive  server  testsentryonfailurehookloading  us  managed  hive  server  testprivilegesatfunctionscope  added  result  failure  due  sentry23  testperdbconfiguration  added  us  special  java  property  running  test  prerequisite  need  setup  secure  cluster  sentry  enabled  need  static  usergroup  mapping  setup  need  set  hiveconfdir  hadoopconfdir  mvn  clean  package  pclusterhadoop  dsentrye2etestpolicyownerkeytabpathtokeytab  dsentrye2etestpolicyownerprincipalprincipal  dhiveserver2thriftbindhosths2host  dhiveserver2authenticationkerberosprincipalhiveprincipal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3816,synchronization  hdfs  permission  sentry  permission  hdfs  file  directory  associated  authorizable  object  managed  sentry  hivemetastore  table  partition  solrsearch  collectiondocument  hbase  table  etc  permission  reflect  grantedrevoked  via  sentry  logic  enforced  sentry  authorization  plugin  would  implementation  hdfs  authorizationprovider  described  hdfs6826httpsissuesapacheorgjirabrowsehdfs6826  umbrella  jira,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3817,high  availability  sentry  servicezookeeper  part  according  feedback  reviewboard  collated  zookeeper  related  jira  one  patch,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0
3818,ban  additional  configs  getconfigval  comment  bcwalrus  email  quote  looking  sentrypolicystoreprocessorjava  forbidden  configs  hardcoded  check  want  also  forbid  sentrystorejdbcpassword  well  itll  get  unwieldy  people  add  new  sensitive  configs  dont  good  idea  keep  uptodate  call  require  admin  privilege  would  normal  user  need  know  server  config  quote  reply  quote  looking  sentrypolicystoreprocessorjava  forbidden  configs  hardcoded  check  want  also  forbid  sentrystorejdbcpassword  well  good  point  might  easier  forbid  jdbc  entirely  cant  see  client  would  wantneed  also  forbid  password  sure  itll  get  unwieldy  people  add  new  sensitive  configs  dont  good  idea  keep  uptodate  config  option  would  kept  date  call  require  admin  privilege  would  normal  user  need  know  server  config  use  case  impala  would  like  able  cache  certain  config  item  like  admingroup  internal  call  client  since  client  trusted  call  simply  pas  name  requester  lack  requesting  user  isnt  big  deal  quote  issue  additionally  ban  jdbc  password,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3819,client  factory  generic  authorization  model  base  sentry600  use  clientfactory  sentrygenericserviceclientfactory  use  create  generic  model  client  sentrygenericserviceclient  need  change  interface  limitation  dynamic  proxy,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,0
3820,improve  grant  role  group  execute  grant  role  role1  group  group1  group  group2  group  group3  execute  3  thrift  call  currently  thrift  api  support  grantrevoke  one  role  tofrom  set  group  improve  client  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3821,improve  metastoreplugin  cache  initialization  time  currently  cache  initialization  logic  sequential  viz  sequentially  retrieves  db  object  table  partition  object  within  bunch  nested  loop  schema  many  tablespartitions  might  take  optimized,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3822,solr  update  authorization  test  sentry  need  implement  endtoend  test  validating  solr  update  authorization,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3823,implement  grant  user  role  currently  sentry  support  grant  group  role  reasonable  feature  grant  user  role  hive  following  command  supported  sentry  grant  rolename  user  user,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3824,add  columnlevel  privilege  hiveimpala  currently  finest  grain  privilege  tableview  level  lead  unwieldy  scenario  different  view  created  combination  column  need  restricted  column  level  privilege  would  required  policy  file  column  privilege  might  potentially  look  like  serverserver1dbdefaulttableemployeescolumnsalaryactionselect,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3825,move  class  policyfileconstants  keyvalue  providercommon  move  class  policyfileconstants  keyvalue  providercommon,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
3826,sentry  client  support  cache  based  kerberos  ticket  secure  zookeeper  connection  sentry  service  client  create  jaas  context  keytab  based  login  connecting  secure  zookeeper  also  support  ticket  cache  based  login  client  dont  keytab  performing  keytab  based  login,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3827,generate  audit  trail  sentry  generic  model  authorization  metadata  change  currently  sentry  generate  audit  log  authorization  metadata  change  request  hive  component  sqoop  solr  used  sentry  generic  model  also  need  function,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,1,1
3828,exception  metastorecacheinitializer  probably  prevent  hm  starting  right  error  condition  evaluating  path  metastorecacheinitializer  one  task  throw  runtime  exception  sentry888  changed  behavior  retry  failed  task  x  time  retry  millis  wait  duration  x  based  upon  user  config  sentryhdfssyncmetastorecacheretrymaxnum  sentryhdfssyncmetastorecacheretrywaitdurationmillis  retry  failure  throw  exception  sync  incomplete  path  update  based  user  config  sentryhdfssyncmetastorecachefailonpartialupdate  default  value  fail  partial  update  throw  runtime  exception  noformat  futurecallresult  result  result  callresult  callresult  resultget  fail  hm  startup  task  successful  fail  partial  update  flag  set  config  callresultgetsuccessstatus  false  failonretry  throw  new  runtimeexceptioncallresultgetfailure  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3829,apply  pmd  plugin  sentry  source  discussed  mailing  list  item  apply  pmd  project  mess  detector  plugin  project  patch  quite  large  although  change  almost  trivial  post  review  board  well  seek  clarification  point  pmd  run  default  use  pnochecks  profile  avoid  running  want,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3830,simple  solr  shell  sentry749  shell  hivebased  model  let  build  solr  version,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
3831,refactor  sentry  integrate  external  component  quickly  problem  currently  many  component  integrated  sentry  eg  solr  sqoop  integration  duplicated  work  need  done  example  sentrycoremodelxxx  sentrypolicyxxx  created  new  component  code  kind  duplicated  make  integration  complex  source  maintenance  hard  considering  others  component  integrated  sentry  eg  kafka  sentry  refactored  easy  integrated  refactor  point  1  policyengine  currently  sentry  many  policyengine  eg  simplesearchpolicyengine  solr  simplesqooppolicyengine  sqoop  one  commonpolicyengine  ok  external  component  2  privilege  currently  searchwildcardprivilege  indexerwildcardprivilege  sqoopwildcardprivilege  implementation  one  commonprivilege  enough  3  action  currently  searchactionfactory  sqoopactionfactory  never  used  privilegeimply  idea  actionfactory  good  component  related  located  sentryxxxbinding  project,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,0
3832,create  enterprise  omrs  connector  enterprise  omrs  connector  provides  connector  implement  omrs  connector  api  defined  jira  atlas1773  able  aggregate  metadata  multiple  metadata  repository  response  metadata  request,1,0,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1
3833,import  transform  option  using  supertype  instead  specific  type  user  provide  tranforms  option  import  replace  cl1  hivetable  cl2  using  following  json  code  option  transforms  hivetable  qualifiedname  replacecl1cl2  code  would  easy  specify  super  type  like  asset  transform  type  export  item  inherit  super  type  cl1  replaced  cl2  like  code  option  transforms  asset  qualifiedname  replacecl1cl2  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3834,export  support  typebased  export  background  atlas  administrator  want  export  data  type  may  needed  scenario  may  necessary  move  data  different  cluster  suggested  approach  within  atlasexportrequest  support  additional  parameter  list  type  additional  option  type  say  fortype  help  identifying  specified  process  list  starting  entity  within  exportservice  example  codejava  itemstoexport  typename  hivedbhdfspathhbasenamespacehbasetable  option  fetchtype  full  matchtype  fortype  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3835,data  migration  moving  data  earlier  version  atlas  recent  background  recent  version  atlas  us  janusgraph  database  earlier  version  used  use  titan  v054  format  used  storing  data  changed  current  version  atlas  also  implement  feature  within  atlas  entity  make  storage  structure  differ  data  migration  approach  thus  becomes  necessary  address  format  incompatibility  approach  earlier  version  atlas  could  use  export  process  extract  data  titan  database  zip  file  would  moved  cluster  newer  version  atlas  installed  import  process  new  cluster  would  update  new  cluster  data  migrated  new  format  possible  data  migration  initiated  ambari  becomes  part  ambaris  upgrade  process  also  possible  see  status  migration  progress  process  hook  message  processed  notification  sent,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3836,rename  entityclassification  edge  label  classifiedas  add  edge  property  currently  store  classification  propagated  classification  name  entity  vertex  property  traitnames  propagatedtraitnames  need  updated  fetch  value  outgoing  edge  entity  vertex  classification  edge  propagated  classification  edge  label  need  updated  static  name  classifiedas  additional  property  need  added  edge  name  name  classification  ispropagated  whether  tag  associated  propagated  one  modify  advanced  dsl  search  handle  searching  edge  instead  vertex  property  tag  based  search,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
3837,lineage  information  include  relationship  guid  currently  atlas  includes  guid  lineage  relation  change  add  relationship  guid  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3838,consistent  class  naming  removal  old  typesystem  code  0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0
3839,atlas  glossary  support  0,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
3840,data  migration  import  add  support  bigdecimal  biginteger  add  ability  migrationimport  import  data  containing  bigdecimal  biginteger  data  type,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3841,update  metric  query  faster  execution  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3842,metric  process  typenames  batch  25  gremlin  query  compilation  fails  number  typenames  within  clause  following  query  exceed  255  noformat  gvhastypename  withinhasstate  activegroupcountbytypenametolist  noformat  updated  implementation  break  call  chunk  25  configurable  typenames  executes  multiple  query  smaller  batch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3843,data  migration  import  infer  type  store  edge  id  background  existing  implementation  data  migration  need  end  user  specify  property  type  need  post  processing  post  processing  essentially  replacing  stored  edge  id  one  newly  migrated  database  error  prone  creator  type  may  aware  hence  may  forget  specify  type  property  migration  result  entity  type  unusable  solution  infer  type  property  following  way  navigating  type  type  registry  find  attribute  array  array  element  object  id  pas  typeproperties  map  migration  process  eliminate  need  letting  user  specify  property,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
3844,update  entity  notification  replace  atlasentity  atlasentityheader  replacing  atlasentity  used  entity  notification  atlasentityheader  includes  fewer  attribute  improve  performance  especially  entity  large  number  attribute  attribute  large  number  arraymap  element  like  hivetable  containing  1000  column  addition  possible  specify  entity  attribute  include  notification  via  typedef  example  updating  atlasattributedef  addition  flag  named  includeinnotification,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
3845,remove  complex  array  map  attribute  edge  information  entity  vertex  currently  entity  complex  type  like  arrayatlasentity  arrayatlasstruct  mapstring  atlasstruct  mapstring  atlasentity  store  list  edge  id  entity  vertex  jira  remove  edge  id  information  vertex  us  edge  label  property  retrieve  attribute,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
3846,enhance  graphtransactioninterceptor  ignore  inner  commitrollback  transaction  need  committed  one  single  shot  right  layer  orchestrates  data  persistence  using  different  store  eg  atlasentitystore  atlasrelationshipstore  see  two  different  commits  introduction  relationship  glossary  become  necessity  entity  relationship  persisted  one  single  transaction  else  object  get  created  partially  lead  inconsistent  state  change  restricts  commitrollback  outermost  method  invocation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3847,change  primitive  map  type  storage  vertex  currently  primitive  map  type  atlas  stored  vertex  typenamemapattr  key1  key2  key3  typenamemapattrkey1  value1  typenamemapattrkey2  value2  typenamemapattrkey3  value3  since  janusgraph  support  map  datatype  store  map  value  within  single  vertex  property  also  need  create  edge  label  property  key  array  map  primitive  type,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3848,glossary  derive  category  qualifiedname  using  hierarchy  currently  qualifiedname  derived  using  displayname  glossary  qualifiedname  patch  qualifiedname  derived  hierarchy  change  hierarchy  trigger  cascaded  update  child  eg  cat1  parent  category  cat2  child  category  derived  qualfiedname  cat2  cat2cat1glossaryqualifiedname  following  action  trigger  cascaded  update  child  category  change  anchor  change  parent  removal  child  parent  similar  2,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3849,export  process  add  support  incremental  export  background  use  case  export  import  process  used  synchronize  data  cluster  data  exported  cluster  imported  another  cluster  subsequent  export  contain  entity  created  updated  since  last  export  help  make  export  process  quicker  payload  smaller  implementation  approach  add  new  fetchtype  incremental  additional  parameter  fromtime  timestamp  export  process  entity  modificationtimestamp  greater  fromtime  would  included  export,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
3850,enhance  atlasclient  use  ugis  authentication  method  initialize  url  connection  handler  currently  atlas  client  check  kerberos  authentication  enabled  using  property  atlasauthenticationmethodkerberostrue  client  need  updated  inspect  ugis  authentication  method  simple  kerberos  initialize  right  url  connection  handler  property  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3851,atlas  cluster  entity  background  case  atlas  data  synchronized  atlas  cluster  necessary  store  information  nature  operation  rest  apis  access  entity  available  used  fetch  data  cluster  entity  use  case  scenario  data  generated  export  operation  one  cluster  say  cl1  used  import  another  cluster  say  cl2  operation  result  data  atlasimportresult  used  later  performing  subsequent  operation  audit  atlascluster  entity  good  home  data  rest  apis  atlascluster  used  retrieveing  data  approach  guidance  create  atlascluster  entity  create  clusterservice  use  ogm  framework  within  atlas  aid  save  load  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3852,atlas  client  support  export  import  apis  background  support  export  import  apis  within  atlasclient  need  improvement  method  available  sufficient  carry  said  operation  guidance  implementation  atlasclient  support  octetstream  medium  type  usage  multipartwriter  need  improvement  line  recommended  approach  integration  test  us  api  added,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3853,export  import  process  add  support  use  detailed  audit  background  implementation  atlas2798  allowed  detailed  audit  captured  implementation  atlas2797  allowed  representation  cluster  entity  jira  capture  integration  2  new  entity  within  export  import  process  approach  guidance  additional  attribute  atlasexportrequest  atlasimportrequest  say  updatemetainfo  indicate  audit  need  captured  within  export  process  value  updatemetainfo  indicate  cluster  export  operation  destined  within  import  process  value  updatemetainfo  indicate  cluster  exported  zip  originated  searching  atlascluster  entity  indicate  operation  performed  cluster  detailed  log  searched  using  approach  ideally  web  user  interface  updated  display  audit  property  view  atlascluster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3854,export  import  process  add  support  replication  attribute  background  scenario  data  continually  replicated  multiple  atlas  cluster  worth  detailed  captured  within  system  detail  apparent  entity  property  approach  guidance  add  2  additional  attribute  referencable  say  replicatedfromcluster  replicatedtocluster  update  exportservice  importservice  entity  part  process  updated  cluster  replicated  update  audit  denote  operation,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
3855,reevaluate  classification  propagation  entity  delete  current  behavior  delete  entity  f1  tag  associate  f1  got  propagated  downstream  entity  removed  –  pii  tag  propagated  process1  t1  removed  proposed  change  soft  delete  entity  f1  deleted  retain  propagated  classification  edge  downstream  entity  –  process1  t1  continue  pii  classification  associated  hard  delete  case  hard  delete  source  entity  f1  deleted  atlas  classification  vertex  pii  continue  exist  continue  propagating  process1  t1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3856,export  process  support  optionally  skip  lineage  entity  exported  background  scenario  importing  lineage  information  cause  ambiguity  worthwhile  option  within  export  skip  exporting  lineage  approach  guidance  create  mechanism  within  exportservice  filter  entity  based  criterion  within  filter  specify  criterion  skip  entity  type  process  atlasexportrequest  option  specify  filter  importservice  impacted,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
3857,export  import  process  add  data  atlascluster  last  successful  import  background  scenario  couple  atlas  cluster  setup  incremental  export  import  setup  via  custom  program  example  cluster  cl1  export  incremental  export  output  imported  cluster  cl2  may  worth  maintain  information  last  successful  import  way  next  incremental  export  correct  parameter  export  approach  guidance  create  new  model  say  atlassyncinfo  store  information  top  level  entity  used  export  timestamp  used  subsequent  incremental  export  utilize  atlasclusters  additionalinfo  field  store  serialized  version  atlassyncinfo  provide  rest  apis  retrieval  information,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
3858,slow  ui  load  rest  improvement  entity  ownedref  approach  check  query  param  color212121minextinfocolortrue  entity  schemaoptions  server  send  attribute  accordingly  referredentities,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3859,import  process  tag  entity  import  replicatedfrom  option  present  background  help  user  identify  entity  part  atlas  cluster  replication  tagged  approach  guidance  within  auditwriter  add  logic  tag  entity  update  entitygraphmapper  tag  entity  without  changing  modificationtimestamp,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
3860,provide  option  whether  delete  propagated  classification  entity  delete  add  classification  default  entity  deleted  associated  classification  propagated  downstream  entity  retained  jira  provides  boolean  option  adding  new  classification  entity  remove  propagation  entity  delete  flag  set  true  propagated  classification  removed  entity  delete  false  propagated  classification  retained  entity  delete,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3861,remove  redundant  encoding  vertex  property  key  janusgraph  reserved  character  restricted  property  key  reservedchars  atlas  encodes  writing  vertexedge  lot  duplicate  encoding  currently  present  encoding  costly  operation  done  jira  refactor  remove  duplicate  encoding,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3862,rename  atlascluster  atlasserver  background  atlascluster  represent  cluster  entity  imported  exported  confusing  user  solution  rename  atlascluster  atlasserver,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3863,export  process  incremental  improve  approach  fetching  changed  entity  background  existing  approach  getting  modified  entity  tends  iterate  entire  set  entity  filter  result  benefit  term  time  effort  incremental  export  benefit  import  smaller  set  imported  approach  user  gremlin  query  fetch  entity  match  criterion  modify  existing  logic  deep  traversal  support  new  logic,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3864,import  process  new  transform  framework  addclassification  action  background  new  transformation  framework  introduced  earlier  provision  applying  transform  add  classification  entity  approach  guidance  new  condition  entitylevel  new  action  applies  entity  mechanism  detect  create  new  classification  necessary  apply  new  action  entity  result  addition  new  classification  entity,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
3865,import  process  handle  import  empty  zip  elegantly  background  existing  implementation  zipsource  always  assumes  zip  passed  valid  data  start  serializing  data  encounter  serialization  error  case  handled  elegant  way  approach  guidance  zipsource  ctor  detect  case  empty  file  throw  error  message  accordingly  handle  case  requested  zipentry  found,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3866,decouple  miniaccumulocluster  integration  test  base  class  apology  already  ticket  somewhere  couldnt  find  integration  test  nice  automated  moment  use  miniaccumulocluster  provision  accumulo  instance  used  shared  instance  run  test  part  work  well  provides  accurate  test  harness  thus  run  integration  test  need  sufficiently  beefy  machine  since  host  running  accumulo  well  performing  client  work  resource  available  use  would  nice  leverage  whether  yarn  mesos  vanila  installation  etc  addition  additional  computational  power  using  extra  hardware  also  encourages  u  use  public  api  much  possible  instead  relying  hidden  impl  method  miniaccumulocluster  propose  making  change  test  base  abstractmacit  simplemacit  configurablemacit  add  extra  step  test  class  allow  injection  generic  accumulo  cluster  associated  mac,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3867,stabilization  bunch  test  still  timeout  parameter  test  annotation  make  scaling  factor  useless  also  reuse  scaling  factor  test  sit  wait  something  happen,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3868,add  ability  create  table  user  specified  initial  property  change  would  allow  table  property  set  default  tablet  created  instead  adding  new  create  method  newtableconfiguration  class  could  created  passed  create  method  deprecated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3869,configuration  object  created  credentialprovider  load  default  unnecessarily  jstacked  tserver  caught  middle  bunch  urlclassloader  jar  stuff  creating  hadoop  configuration  obviously  struck  odd  given  know  arent  fast  method  looking  created  configuration  object  didnt  pas  false  default  getting  loaded  regardless  expensive  actually  unnecessary,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3870,random  port  zk  miniaccumulo  might  unique  start  zookeeper  way  wont  interfere  process  node  choose  random  port  node  configure  accumulo  port  dont  mean  get  random  port  zookeeper  would  bind  problem  delay  choosing  random  port  zookeeper  binding  port  introduces  race  condition,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3871,warning  synconclose  way  spammy  location  warning  dfsdatanodesynconclose  set  true  way  spammy  know  know  every  time  volume  chosen,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
3872,add  introspection  long  running  assignment  least  ive  seen  tablet  assignment  hang  inexplicable  reason  could  track  active  compaction  report  assignment  taking  excessive  amount  time  noformat  assignment  5476  running  least  13445ms  javautilzipdeflaterdeflatebytesnative  method  javautilzipdeflaterdeflatedeflaterjava430  javautilzipdeflaterdeflatedeflaterjava352  orgapachehadoopiocompresszlibbuiltinzlibdeflatercompressbuiltinzlibdeflaterjava54  orgapachehadoopiocompresscompressorstreamcompresscompressorstreamjava81  orgapachehadoopiocompresscompressorstreamwritecompressorstreamjava76  orgapacheaccumulocorefilerfilebcfilecompressionfinishonflushcompressionstreamwritecompressionjava59  javaiobufferedoutputstreamwritebufferedoutputstreamjava122  javaiodataoutputstreamwritedataoutputstreamjava107  javaiodataoutputstreamwritedataoutputstreamjava107  orgapacheaccumulocoredatavaluewritevaluejava163  orgapacheaccumulocorefilerfilerfilewriterappendrfilejava388  orgapacheaccumulotservercompactorcompactlocalitygroupcompactorjava504  orgapacheaccumulotservercompactorcallcompactorjava362  orgapacheaccumulotserverminorcompactorcallminorcompactorjava96  orgapacheaccumulotservertabletminorcompacttabletjava2071  orgapacheaccumulotservertabletaccess4400tabletjava174  orgapacheaccumulotservertabletminorcompactiontaskruntabletjava2158  orgapacheaccumulotservertabletminorcompactnowtabletjava2267  orgapacheaccumulotservertabletserverassignmenthandlerruntabletserverjava2937  orgapacheaccumulotserveractiveassignmentrunnablerunactiveassignmentrunnablejava55  orgapacheaccumulotraceinstrumenttracerunnableruntracerunnablejava47  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1145  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava615  orgapacheaccumulotraceinstrumenttracerunnableruntracerunnablejava47  orgapacheaccumulocoreutilloggingrunnablerunloggingrunnablejava34  javalangthreadrunthreadjava745  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3873,replace  sortedmapkeyvalue  tablet  constructor  tabletserver  read  metadata  table  place  key  value  pair  given  tablet  sortedmap  pass  tablet  constructor  tablet  bunch  custom  code  extract  log  entry  data  file  time  last  location  scan  file  etc  could  encapsulated  class  instead  extra  method  tablet,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
3874,consolidate  thriftrpc  utility  class  package  lot  inner  class  floating  around  tserverutils  could  really  consolidated  thrift  package  inside  serverbase  would  reduce  overall  size  tserverutils  make  thing  bit  consumable,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3875,add  ability  retrieve  property  value  string  key  normally  retrieve  value  property  get  property  enum  instance  since  table  arbitrary  property  dont  property  enum  instance  cant  use  simple  get  instead  retrieve  table  arbitrary  property  create  temporary  map  filtering  function  add  ability  fetch  single  value  based  string  key,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3876,get  visibility  metric  printinfo  add  ability  print  visibility  metric  density  visibility  locality  group  number  block  visibility,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3877,speed  wal  rollover  reading  proposal  hbase10278  realized  many  way  make  accumulo  wal  rollover  faster  open  two  walogs  use  one  reach  walog  rollover  size  rollover  consists  swapping  writer  walog  roll  consists  final  close  happen  parallel  dont  mark  tablet  log  entry  already  marked  tserver  tserver  make  note  logsinuse  metadata  table  part  opening  log  master  copy  log  entry  tablet  unassigning  piggybacking  unassigment  mutation  tablet  server  remove  current  log  entry  metadata  table  tablet  using  two  issue  tablet  empty  file  recovery  nearly  time  recovery  code  already  handle  case  presently  tablet  doesnt  marker  log  use  many  tablet  attempt  recover  unnecessary  would  also  address  accumulo2889,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3878,clean  thrift  clientserver  factory  class  thriftutil  core  tserverutils  serverbase  could  stand  use  general  cleanup  found  working  accumulo2815  whitespace  ensure  clientserver  logic  separation  thriftutiltserverutils  respectively  javadoc  switch  slf4j  logger  better  logging  without  excessive  string  creation  concern,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3879,use  hostandport  instead  string  tracking  address  noticed  accumulo3425  thrift  rpc  factory  class  accept  string  half  time  hostandport  half  time  consolidate  hostandport  since  includes  basic  sanity  check  better  addressindexof  sometimes  let  filter  server  rpc  use  client  api  implementation,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3880,consolidation  tserverutils  bunch  cleanup  thriftutil  tserverutils  part  accumulo2815  upon  review  place  cleanup  could  done  tthreadpoolserver  factory  method  consolidated  across  ssl  sasl  dynamically  resizing  thread  pool  ssl  sasl  like  hsha  server  us  remove  unused  argument  sasl  tserver  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3881,use  java  serviceloader  identify  class  launchable  start  similar  goal  accumulo1496  possible  efficiently  annotation  processor  java  serviceloader  successful  would  supersede  accumulo1496,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3882,create  combiners  wikisearch  example  wikisearch  example  us  aggregator  deprecated  14  since  new  example  14  combiners,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0
3883,batchscanner  optimization  accumuloinputformat  currently  accumuloinputformat  produce  split  reach  range  specified  configuration  table  indexing  scheme  instance  zorder  geospacial  index  produce  large  number  small  range  resulting  large  number  split  specifically  concern  using  accumuloinputformat  source  spark  rdd  split  mapped  rdd  partition  large  number  small  rdd  partition  lead  poor  parallism  read  high  overhead  processing  desirable  alternative  group  range  tablet  single  split  use  batchscanner  produce  record  grouping  tablet  useful  represents  accumulos  attempt  distributed  stored  record  influance  user  table  split  grouping  functionality  already  exists  internal  tabletlocator  class  current  proposal  modify  abstractinputformat  generates  either  rangeinputsplit  multirangeinputsplit  based  new  setting  inputconfigurator  accumuloinputformat  would  able  inspect  type  split  instantiate  appropriate  reader  functinality  tabletlocator  exposed  public  api  17  useful  optimization,1,1,1,0,1,1,0,0,0,0,0,0,1,0,0,0,0
3884,multi  data  center  replication  use  case  people  multiple  data  center  need  replicate  data  accumulo  model  replication  way  hbase  currently  handle  replication  detailed  httphbaseapacheorgreplicationhtml  one  master  cluster  multiple  slave  cluster  accumulo  use  masterpush  model  replicate  statement  master  cluster  wal  various  slave  wals,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3885,seal  jar  default  jar  currently  sealed  release  reason  dont  always  seal  cause  problem  running  integration  test  test  class  package  main  artifact  ensure  test  package  seal  jar  default  would  allow  u  catch  problem  jar  sealing  like  accumulo3801  earlier,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3886,log  recovery  copysort  progress  exceeds  100  regularly  notice  copysort  progress  bar  log  recovery  monitor  exceeds  100  either  find  exceeds  100  fix  computation  cap  value  report  100  doesnt  exceed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3887,add  configuration  change  random  walk  test  add  random  configuration  change  random  walk  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3888,support  map  reduce  directly  file  support  map  reduce  job  directly  read  accumulo  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3889,run  integration  test  mapreduce  job  functional  test  moved  java  lost  ability  run  test  via  mapreduce  would  nice  run  2  hour  take  advantage  entire  cluster  especially  making  large  sweeping  change,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
3890,provide  example  different  configuration  needed  plan  implement  debian  packaging  stuff  current  sitexmlexample  envshexample  file  provides  configuration  small  server  machine  however  feel  many  user  weaker  machine  even  laptop  want  get  accumulo  test  run  provide  least  one  example  file  tiny  configuration  1gb  footprint  perhaps  create  multiple  configuration  different  memory  footprint,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3891,multitable  accumulo  input  format  realized  mr  input  method  support  multiple  table  input  format  would  see  making  table  mapper  key  making  keyvalue  tuple  alternatively  tablekey  key  tuple  stick  value  value,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
3892,add  per  table  sampling  working  prototyping  adding  hash  based  sampling  accumulo  trying  accomplish  following  goal  prototype  rfile  store  sample  per  locality  group  also  store  configuration  used  generate  sample  use  sampling  function  ensure  row  column  exist  across  sample  rfiles  hash  mod  good  candidate  give  random  sample  thats  consistent  across  file  scanner  support  scanning  rfiles  sample  set  scan  fail  rfiles  different  sample  configuration  different  sampling  config  implies  rfiles  sample  set  contain  possibly  disjoint  set  row  column  support  generating  sample  data  rfiles  generated  bulk  import  support  sample  data  memory  map  support  enabling  disabling  sampling  per  table  configuring  sample  function  currently  using  following  function  prototype  determine  data  rfile  store  sample  set  code  always  select  subset  row  rfiles  sample  set  yet  made  function  configurable  codejava  public  class  rowsampler  implement  sampler  private  hashfunction  hasher  hashingmurmur332  override  public  boolean  acceptkey  k  bytesequence  row  kgetrowdata  hashcode  hc  hasherhashbytesrowgetbackingarray  rowoffset  rowlength  return  hcasint  1009  0  code  although  yet  implemented  divisor  rowsample  could  configurable  rfiles  sample  data  would  store  fact  rowsample  divisor  1009  used  generate  sample  data,1,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,1
3893,enable  ab  testing  scan  iterators  table  classpath  context  assigned  table  via  table  configuration  test  scale  cloning  table  assigning  new  classpath  context  cloned  table  however  would  also  need  change  application  use  new  table  name  since  cannot  disable  compaction  would  start  consume  space  filesystem  table  support  user  passing  context  name  use  scan  existing  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3894,improve  validation  configuration  argument  guava  predicate  there  place  code  could  benefit  additional  validation  argument  configuration  using  builtin  guava  predicate  make  check  bit  readable  enables  u  expressive  validation  check  specifically  see  room  improvement  propertytype  validators  currently  limited  regex  validation  lesser  degree  oaacoreutilvalidator  intend  replace  proper  predicate  determine  validity,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3895,number  majorminor  compaction  cannot  changed  onthefly  changed  tservercompactionmajorconcurrentmax  shell  tablet  server  change  number  major  compactors  need  restart  server  change  take  effect,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3896,duplicated  code  iteratorutil  duplicated  code  httpsgithubcomapacheaccumuloblobmastercoresrcmainjavaorgapacheaccumulocoreiteratorsiteratorutiljaval236  code  public  static  k  extends  writablecomparablev  extends  writable  sortedkeyvalueiteratorkv  loaditeratorsiteratorscope  scope  sortedkeyvalueiteratorkv  source  keyextent  extent  accumuloconfiguration  conf  listiterinfo  ssilist  mapstringmapstringstring  ssio  iteratorenvironment  env  boolean  useaccumuloclassloader  throw  ioexception  listiterinfo  iters  new  arraylistiterinfossilist  mapstringmapstringstring  alloptions  new  hashmapstringmapstringstring  parseiteratorconfigurationscope  iters  ssio  alloptions  conf  return  loaditeratorssource  iters  alloptions  env  useaccumuloclassloader  confgetpropertytableclasspath  public  static  k  extends  writablecomparablev  extends  writable  sortedkeyvalueiteratorkv  loaditeratorsiteratorscope  scope  sortedkeyvalueiteratorkv  source  keyextent  extent  accumuloconfiguration  conf  listiterinfo  ssilist  mapstringmapstringstring  ssio  iteratorenvironment  env  boolean  useaccumuloclassloader  string  classloadercontext  throw  ioexception  listiterinfo  iters  new  arraylistiterinfossilist  mapstringmapstringstring  alloptions  new  hashmapstringmapstringstring  parseiteratorconfigurationscope  iters  ssio  alloptions  conf  return  loaditeratorssource  iters  alloptions  env  useaccumuloclassloader  classloadercontext  code  thought  commented  httpsgithubcomapacheaccumulopull51  maybe  forgot,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3897,conditional  mutation  processing  performance  could  improved  processing  conditional  mutation  tablet  read  done  way  current  implementation  tablet  read  lot  overhead  condition  following  done  open  reserve  iterators  file  parse  table  iterators  table  config  involves  scanning  filtering  entire  table  config  merges  condition  iterators  table  iterators  construct  iterator  stack  created  branch  operation  except  constructing  iterator  stack  done  per  tablet  andor  per  batch  conditional  mutation  seeing  3x  speed  conditional  mutation  processing  rate  data  cached,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3898,ttimeouttransport  repeatedly  us  reflection  obtain  method  noticed  following  ttimeouttransport  looking  accumulo4065  code  private  static  inputstream  getinputstreamsocket  socket  long  timeout  try  method  netutilsclassgetmethodgetinputstream  socketclass  longtype  return  inputstream  minvokenull  socket  timeout  catch  exception  e  throw  new  runtimeexceptione  code  really  invoke  getmethod  cache  method  instance  instead  repeatedly  getting  every  time  create  new  connection  often  sure  hot  enough  code  path  noticeable  performance  impact  good  fix  regardless,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3899,eliminate  constant  unnecessary  text  wrapping  immutable  tableids  started  looking  accumulo4138  see  keyextent  used  overlap  noticed  lot  new  keyextentnew  textstring  call  first  parameter  text  version  tableid  appears  even  practice  much  keyextent  builtin  weakreference  caching  tableids  java  gc  dedupe  avoid  creating  many  thing  lot  attempt  optimize  appears  result  unnecessarily  wrapping  immutable  string  tableids  text  object  yet  doesnt  really  seem  buy  u  anything  api  lot  internal  utility  already  string  reference  elsewhere  code  even  dedupe  text  object  anything  string  worse  actually  protective  copying  pas  around  text  object  using  textutil  etc  completely  unnecessary  immutable  copied  wrapped  case  actually  call  tostring  text  object  pas  around  get  flipflopped  time  string  text  depending  internal  api  accepts  best  using  text  object  help  u  serialize  keyextent  thats  questionably  beneficial  since  dataoutput  already  serialize  outwriteutfstring  thats  actually  helpful  benefit  could  possibly  see  compareto  lexicographical  comparison  hard  time  believing  text  compare  faster  javalangstring  shouldnt  difference  result  comparison  utf8  encoding  text  modified  utf  encoding  native  java  string  certainly  base36  character  fixed  constant  special  table  use  tableids  completely  strip  text  version  tableid  wherever  possible  ive  already  done  exercise  16  branch  might  potentially  risky  put  java  map  dont  strict  type  checking  mapgetobject  instance  sometimes  compared  equalsobject  worth  public  api  really  touch  oaacoredatakeyextent  inadvertently  public  api  since  moved  iirc  preserve  old  method  compatibility  necessary  deprecated  course  also  getting  rid  text  object  sticking  immutable  string  object  well  able  take  advantage  future  jvm  improvement  string  deduplication  like  httpjavaperformanceinfojavastringdeduplication,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3900,avoid  copy  rfile  index  block  cache  performance  experiment  rfile  course  experiment  noticed  rfile  fast  case  index  block  cache  rfile  already  open  reason  rfile  code  copy  deserializes  index  data  even  though  already  memory  made  following  change  rfile  branch  avoid  copy  index  data  cache  deserialize  offset  lazily  instead  upfront  binary  search  stopped  calling  lot  synchronized  method  deserialization  index  info  existing  code  use  bytearrayinputstream  result  lot  fine  grained  synchronization  switching  inputstream  offer  functionality  wo  sync  showed  measurable  performance  difference  change  lead  performance  following  two  situation  rfiles  data  cache  open  tserver  rfiles  multilevel  index  index  data  cache  currently  open  rfile  keep  root  node  memory  lower  level  index  node  always  read  cache  dfs  change  made  would  always  avoid  copy  deserialization  lower  level  index  node  cache  seen  significant  performance  improvement  testing  two  case  test  currently  based  new  api  creating  rfile  easily  share  get  pushed  case  tserver  file  frequently  use  already  open  file  single  level  index  change  make  significant  performance  difference  change  result  le  memory  use  opening  rfile  multiple  time  different  scan  data  cache  case  rfiles  would  share  byte  array  holding  serialized  index  data,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
3901,create  user  level  api  rfile  user  bulk  import  rfiles  currently  way  user  create  rfiles  using  accumulos  public  api  via  accumulofileoutputformat  way  read  rfiles  public  api  also  internal  apis  reading  writing  rfiles  cumbersome  use  experimenting  simple  rfile  api  like  following  example  writing  data  codejava  localfilesystem  localfs  filesystemgetlocalnew  configuration  rfilewriter  writer  rfilefactorynewwriter  withfilenametmptest100mrf  withfilesystemlocalfsbuild  writerstartdefaultlocalitygroup  int  r  0  r  10000000  r  int  cq  0  cq  10  cq  writerappendgenkeyr  cq  genvalr  cq  writerclose  code  example  reading  data  codejava  localfilesystem  localfs  filesystemgetlocalnew  configuration  scanner  scanner  rfilefactorynewscanner  withfilenametmptest100mrf  withfilesystemlocalfs  withdatacache250000000  withindexcache1000000build  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3902,tinylfubased  blockcache  lrublockcachehttpsgithubcomapacheaccumuloblobmastercoresrcmainjavaorgapacheaccumulocorefileblockfilecachelrublockcachejava  appears  based  hbases  currently  patch  reviewed  hbase15560httpsissuesapacheorgjirabrowsehbase15560  replaces  pseudo  segmented  lru  tinylfu  eviction  policy  allow  cache  make  better  predictionshttpsgithubcombenmanescaffeinewikiefficiency  based  frequency  recency  improved  scan  resistance  implementation  us  caffeinehttpsgithubcombenmanescaffeine  successor  guava  cache  provide  concurrency  keep  patch  small  full  detail  jira  ticket  think  easy  port  interest,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3903,rate  limiting  major  compaction  discussing  accumulo4166  keith  turner  decided  underlying  issue  major  compaction  overwhelm  tablet  server  rendering  nearly  unresponsive  address  take  cue  apache  cassandra  restrict  quickly  perform  major  compaction  rate  limiting  read  writes  involved  major  compaction  directly  affect  io  load  caused  major  compaction  also  indirectly  affect  cpu  load,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3904,generalized  configuration  object  accumulo  rfile  interaction  taken  httpsgithubcomapacheaccumulopull90filesr59489073  shawnwalkers  pr  accumulo4187  add  ratelimiting  major  compaction  noted  many  change  related  passing  extra  argument  ratelimiter  around  code  related  file  interaction  would  nice  move  centralized  configuration  object  instead  add  new  argument  every  time  new  feature  added  filepath,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3905,allow  per  compaction  iterator  setting  may  useful  allow  compact  command  specify  iterator  used  compaction  example  someone  wanted  apply  filter  table  could  force  compaction  filter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3906,make  batchwriter  conditionalwriter  scannerbase  extend  autocloseable  batchwriter  conditionalwriter  scanner  batchscanner  close  method  howerver  implement  autocloseable  used  trywithresources  would  simple  add  autocloseable  think  change  made  minor  release  allows  writing  code  work  older  version,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3907,stabilize  tablet  assignment  transient  failure  tablet  server  dy  accumulo  attempt  reassign  tablet  hosting  quickly  possible  maintain  availability  multiple  tablet  server  die  quick  succession  rolling  restart  accumulo  cluster  network  partition  behavior  cause  storm  reassignment  rebalancing  placing  significant  load  master  avert  load  accumulo  capable  maintaining  steady  tablet  assignment  state  face  transient  tablet  server  loss  instead  reassigning  tablet  quickly  possible  accumulo  await  return  temporarily  downed  tablet  server  configurable  duration  assigning  tablet  tablet  server,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3908,rowiterator  accumulorowinputformat  require  row  fit  memory  rowiterator  accumulorowinputformat  read  row  listentrykeyvalue  instead  could  produce  iteratorentrykeyvalue,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3909,make  caching  implementation  configurable  would  nice  make  caching  implementation  configurable  accumulo4177  introduced  new  cache  type  instead  accumulo  list  built  cache  implementation  could  configuration  property  specifying  block  cache  factory  class  accumulo  could  ship  multiple  implementation  4177  allow  user  easily  experiment  implementation  accumulo  ship  would  nice  accumulo3384  custom  cache  impls  could  use  custom  config,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
3910,replace  meaningless  method  name  abbreviated  method  name  reused  throughout  code  meaningless  new  user  method  name  nk  nf  ane  helpful  trying  determine  class  work  seems  occur  test  think  would  improve  readability  lot  especially  newbie  one  think  test  good  place  learn  class  work  choosing  brevity  clarity  greater  hinders  readability  test,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3911,update  thrift0100  thrift  released  0100  update  200  branch  shouldnt  much  impact  u  ill  test  itd  good  futureproofing  20x  release  later  thrift  bugfixes,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3912,modify  tableoperations  online  check  table  online  executing  fate  operation  table  operation  online  operation  executes  fate  operation  transaction  lock  table  currently  held  say  table  compaction  online  operation  block  modification  essentially  change  behavior  online  operation  noop  table  currently  online  current  table  state  online  operation  return  immediately  without  queuing  fate  operation  set  online  table  online  eliminates  blocking  behavior  operation  table  already  online,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3913,simplify  accumulo  logging  configuration  current  implementation  accumulo  logging  configuration  confusing  several  configuration  file  conf  dir  hard  know  one  used  situation  refactoring  accumulos  script  20  easier  refactor  accumulos  logging  suggest  improvement  brought  code  review  regarding  genericloggerproperties  rather  produce  system  property  accumulo  code  use  log4j  feature  syshostname  might  log4j2  thats  okay  switch  maybe  shouldnt  enable  rolling  file  appender  default  configs  user  add  want  better  option  would  probably  use  syslog  appender  default,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
3914,limit  use  environment  variable  java  accumulo  limit  use  environment  variable  like  accumulohome  accumuloconfdir  java  environment  variable  easily  set  incorrectly  shell  accumulo  rely  configuration  accumulositexml  accumuloenvsh,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3915,improve  accumulo  classpath  command  accumulo  classpath  command  modified  support  following  noformat  java  cp  pathtomyjaraccumulo  classpath  commyclass  java  cp  accumulo  classpath  jar  pathtomyjar  noformat  current  output  command  list  jar  human  readable  format  could  supported  accumulo  classpath  debug,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3916,simplify  accumulo  memory  configuration  accumulo  memory  configuration  simplified  using  percentage  user  longer  need  use  accumulo  createconfig  create  accumulositexml  accumuloenvsh  configuration  file  accumulo  instead  ship  simple  configuration  file  sane  default  need  limited  change  user,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3917,accumuloclassloader  load  accumulositexml  classpath  currently  expects  accumuloconfdir  set  load  directory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3918,move  user  manual  accumulo  website  current  documentation  accumulo  user  manual  life  accumulo  repo  asciidoc  format  every  release  doc  change  single  page  html  file  must  generated  copied  website  proposal  convert  documentation  starting  20  asciidoc  markdown  move  accumulo  website  serve  using  jekyll  unreleased  documentation  published  warning  linked  release  remove  warning  add  link  wait  week  two  additional  change  copying  documentation  new  directory  next  release  pro  easier  link  page  external  javadocs  documentation  broken  distinct  page  easier  read  better  seo  easier  update  documentation  release  one  commit  necessary  jekyllmarkdown  customizable  becoming  standard  asciidoc  documentation  change  affect  multiple  release  made  one  pr  con  documentation  longer  ship  tarball  developer  cannot  update  code  doc  one  pr,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
3919,back  port  iterator  improvement  improvement  accumulo3079  applied  version  20  non  user  facing  change  could  back  ported  older  version  change  would  respect  existing  user  iterators  would  include  new  iterators  introduced  20,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3920,simplify  use  accumuloconfiguration  working  accumulo4050  ive  realized  there  bunch  simplification  existing  accumuloconfiguration  related  object  generally  lot  small  refactorings  there  sufficient  cleanup  need  separately  accumulo4050  otherwise  going  overhwelm  im  never  going  finish  issue  specific  thing  include  remove  redundant  way  get  default  config  move  static  type  converter  method  clutter  accumuloconfiguration  api  separate  class  streamline  default  config  construction  stream  syntax  simplify  internal  predicate  filtering  property  lambda  rename  serverconfigurationfactorygetconfiguration  reflects  system  config,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
3921,remove  serverconfigurationgetinstance  working  accumulo4050  ive  realized  need  internal  refactoring  get  better  control  hdfszooinstance  would  enable  better  testing  could  inject  mock  instance  easily  place  would  also  allow  u  reuse  object  without  storing  statically  jvm  fully  realizing  would  involve  lot  work  moving  static  state  single  context  object  constructed  server  startup  shared  part  whole  needed  throughout  runtime  server  code  however  think  get  incrementally  starting  eliminating  serverconfigurationgetinstance  method  cause  systemconfigurationfactory  also  getinstance  method  mean  systemconfigurationfactory  used  like  context  object  describe  redundantly  instead  accumuloservercontext  serverspecific  subclass  eliminating  serverconfigurationgetinstance  might  involve  intermediate  step  adding  instance  parameter  many  method  currently  take  systemconfigurationfactory  component  able  get  instance  configuration  factory  longer  however  even  intermediate  step  progress  towards  moving  single  shared  context  object  provides  access  instance  configuration  factory  move  directly  context  object  would  probably  better  would  involve  lot  change  particular  way  server  code  initialized  change  might  good  prioritize  anyway  server  component  seem  initialize  differently  would  nice  rewrite  bootstrap  code  follow  pattern,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
3922,hostregex  balancer  allow  migration  even  pending  migration  hostregextablebalancer  current  halt  migration  pending  migration  propose  fixing  allow  adding  additional  migration  even  pending  migration  specified  amount,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3923,localitygroupiterator  inefficient  large  locality  group  one  system  tracked  scan  taking  extremely  long  time  complete  many  hour  turn  scan  relatively  simple  scanning  tablet  key  specific  column  family  note  little  data  actually  matched  column  familiy  upon  tracing  code  found  spending  large  amount  time  localitygroupiterator  stack  trace  continually  found  code  line  128  129  localitygroupiterator  line  number  consistent  16  series  way  200  master  case  column  family  searched  included  one  dozen  locality  group  table  locality  group  40  column  family  see  several  thing  done  1  code  check  group  column  family  searched  quickly  exit  find  match  2  code  check  group  column  family  searched  look  relative  size  two  group  invert  logic  appropriately  efficient  loop  3  could  create  cached  map  column  family  locality  group  allowing  u  avoid  examining  locality  group  every  time  seek,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3924,allow  property  accumulofileoutputformat  set  mapreduce  job  currently  way  set  configuration  option  accumulofileoutputformat  mapreduce  job  specifically  compression  code  file  block  compression  size  index  block  compression  size  name  since  accumulofileoutputformat  call  fileoperationsgetinstanceopenwriter  take  configuration  accumuloconfiguration  one  could  inside  openwriter  function  check  see  parameter  specified  configuration  object  take  default  parameter  accumuloconfiguration  object,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3925,create  weakreference  map  replace  tableid  constructor  taken  feedback  pr  279  could  maybe  avoid  duplicate  making  constructor  tableid  private  tableidoftableid  draw  internal  weakreference  map  object  deduplication  keyextent  still  valid  pushed  tableid  namespaceid  class  replacing  optimization  keyextent,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3926,address  static  analysis  feedback  fortify  fortify  flagged  thing  accumulo  mostly  17  18  actually  flagged  lot  thing  noticed  minor  wouldnt  hurt  u  fix  jarfile  jarjava  never  closed  boundedrangefileinputstream  invokes  privilegedaction  reason  cant  fathom  way  since  code  import  think  removed  numeric  validate  refresh  cookie  monitor  use  httponly  cooky  create  mark  expect  accessed  browser  put  request  uri  back  page  body  defautlservlet  cant  load  requested  element  putting  usercontrolled  info  http  response  generally  bad  news  trim  data  write  browser  log  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3927,create  official  accumulo  docker  image  accumulo  imageshttpshubdockercomsearchisautomated0isofficial0page1pullcount0qaccumulostarcount0  dockerhub  look  majority  designed  run  singlenode  accumulo  instance  docker  container  development  testing  would  great  accumulo  official  image  running  accumulo  process  container  production  cluster  image  could  published  official  image  apacheaccumulo  dockerhub  order  make  possible  think  work  need  done  allow  configuration  passed  accumulo  process  docker  container  without  using  configuration  file  passing  file  running  container  hard  docker  one  way  add  option  called  uploadaccumulosite  accumulo  init  command  called  outside  docker  user  would  set  property  accumulositexml  system  property  zookeeper  accumulo  initialization  accumulo  process  docker  container  could  started  minimal  configuration  updating  accumulo  service  command  keyvalue  option  override  configuration  change  accumulo  would  enable  following  command  start  accumulo  cluster  docker  noformat  accumulo  init  uploadaccumulosite  docker  pull  apacheaccumulo  docker  run  apacheaccumulo  master  instancezookeeperhostzkhost2181  docker  run  apacheaccumulo  tserver  instancezookeeperhostzkhost2181  docker  run  apacheaccumulo  monitor  instancezookeeperhostzkhost2181  docker  run  apacheaccumulo  tracer  instancezookeeperhostzkhost2181  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3928,apis  configure  iterators  locality  group  new  table  accumulo  17  ability  set  table  property  table  creation  time  added  existing  table  apis  table  operation  allow  setting  locality  group  iterators  existing  table  setting  table  property  table  creation  time  good  api  iterators  locality  group  way  api  may  thing  besides  iterators  locality  group  also  supported  table  creation  time,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
3929,enable  gcm  mode  crypto  enable  use  gcm  optional  encryption  mode  change  allow  gcm  probably  used  java  9  later  httpsdocsoraclecomjavase9whatsnewtochtmjsnewguid71a0970174124499a88d53fa8bfbd3d0  httpopenjdkjavanetjeps246,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3930,inconsistent  name  duplicate  method  iteratorsettings  david  medinets  noticed  quote  property  object  used  hold  keyvalue  information  used  modify  behavior  interator  however  method  available  noformat  getproperties  setproperties  hasproperties  addoption  removeoption  addoptions  clearoptions  noformat  reason  concept  two  name  id  like  settle  one  name  standardise  could  change  name  something  like  getinteratorsettingproperties  know  people  annoyed  longer  method  name  searching  code  base  unique  name  handy  searching  generically  named  method  getproperties  return  lot  false  positive  quote,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3931,replace  table  monitor  datatables  found  javascript  library  httpsdatatablesnet  think  would  give  u  everything  need  display  data  monitor  would  take  work  get  working  would  eliminate  lot  custom  code  give  u  feature,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3932,create  builder  method  connector  simplify  client  api  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3933,improve  thrift  transport  pool  accumulo  pool  recently  opened  connection  tablet  server  connecting  tablet  server  pool  checked  first  pool  built  around  map  list  two  problem  pool  global  lock  around  map  list  trying  find  connection  linear  search  non  reserved  connection  per  tablet  server  could  possibly  move  model  list  unreserved  connection  set  reserved  connection  per  tablet  server  get  connection  could  remove  unreserved  list  add  reserved  set  would  constant  time  operation  locking  could  move  model  using  concurrent  map  locking  per  tserver  instead  locking  entire  map,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
3934,tablet  server  start  scan  authenticates  twice  code  handle  start  scan  rpc  call  check  authentication  twice  call  authenticate  take  bit  time  would  nice  tabletserver  line  479httpsgithubcomapacheaccumuloblobrel181servertserversrcmainjavaorgapacheaccumulotservertabletserverjaval479  call  canscan  made  call  authenticate  tabletserver  line  482httpsgithubcomapacheaccumuloblobrel181servertserversrcmainjavaorgapacheaccumulotservertabletserverjaval482  call  check  authorization  made  also  authenticates,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3935,add  thrift  proxy  server  add  thrift  proxy  server  make  integration  language  besides  java  bit  easier  work  like  httpwikiapacheorghadoophbasethriftapi,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3936,reduce  debugging  level  example  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3937,check  major  compaction  needed  new  file  introduced  currently  tablet  server  scan  tablet  every  30  second  see  tablet  need  major  compact  tablet  minor  compact  import  file  could  check  need  major  compaction  split  could  place  appropriate  queue  would  make  system  little  efficient,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3938,improve  scan  information  available  monitor  page  monitor  page  give  good  awareness  respect  actually  happening  scan  would  interesting  know  following  number  seek  done  server  side  number  entry  read  server  side  number  entry  returned  server  die  filtering  iterator  may  lot  seek  drop  lot  data  really  shown  anyway  monitor  page  displayed  info  user  could  see  filter  seeking  reading  returning  data  currently  amount  data  returned  iterators  displayed  amount  data  read  iterators  also  current  monitor  page  display  scan  session  corresponds  user  starting  scan  tablet  server  give  user  info  many  seek  iterators  running  part  scan  session,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3939,shell  way  specify  instance  name  using  zk  host  configuration  currently  shell  us  hdfszooinstance  unless  otherwise  specified  possible  user  force  zooinstance  case  specify  list  zkhosts  instance  name  however  way  specify  instance  name  utilize  list  zk  host  configuration  file  look  expanding  shell  include  creation  option  possibly  segregating  zookeeper  host  instance  name  two  seperate  argument,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3940,make  shell  command  use  table  option  consistently  shell  command  usually  create  tableopt  option  manually  parse  could  made  easier  utility,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
3941,make  size  batch  scanner  client  size  buffer  configurable  batch  scanner  buffer  client  side  result  read  tservers  stored  buffer  hold  1000  entry  configurable  client  fill  thread  reading  tservers  block,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
3942,create  iterator  fuzz  tester  user  often  write  iterators  without  fully  understanding  limit  lifetime  accumulo  iterator  fuzztester  take  user  data  run  iterator  extreme  condition  example  recreate  reseek  iterator  every  key  returned  could  automatically  compare  result  run  naive  run  seek  beginning  scan  data,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3943,move  test  code  server  package  package  server  package  currently  house  functional  continuous  ingest  random  walk  testing  code  special  connection  test  various  server  could  move  everything  orgapacheaccumuloservertest  package  server  relatively  easily  clean  code  reduce  future  dependency  bloat  eg  new  complex  test  case,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3944,batchwriters  track  throwables  beyond  constraint  violation  working  accumulo259  adapting  security  random  walk  test  account  cached  credential  prevent  crapping  ambiguous  credential  credential  currently  propagating  noticed  client  side  writer  provide  mean  feedback  client  nonconstraintviolationexception  looking  tabletserverbatchwriter  specifically  keep  track  server  error  key  extent  error  constrainviolations  saw  dont  actually  track  actual  throwables  get  aside  constraintviolation  keep  collection  set  throwables  see  client  code  proper  case  checking  well,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3945,remove  deprecate  createuser  call  authorization  argument  creating  user  depends  different  acl  granting  authorization  user  one  still  create  user  float  back  error  confusing  end  user  think  isolate  createuser  creating  user  granted  authorization  need,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3946,improve  iterator  configuration  mapreduces  inputformatbase  currently  us  accumuloiterator  accumuloiteratoroption  configuration  object  serialize  iterator  information  mapreduce  object  predate  iteratorsetting  used  configure  iterators  make  iteratorsetting  writable  used  directly  serializing  iterator  information,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
3947,batch  scanner  need  timeout  batch  scanner  need  user  configurable  time  batch  scanner  used  query  lot  tablet  parallel  one  tablet  tablet  server  unavailable  reason  cause  scan  hang  indefinitely  user  need  control  behavior  seems  like  batch  scanner  could  behave  one  following  way  read  much  data  possible  throw  exception  tablet  tablet  server  timed  throw  exception  soon  tablet  tablet  server  time  even  data  could  still  read  tablet  successfully  timeout  default  max  long  preserve  current  behavior,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3948,batch  writer  need  timeout  batchwriter  need  user  configurable  timeout  current  behavior  tablet  tablet  server  successfully  written  hang  indefinitely  retrying  timeout  could  default  max  long  preserve  current  behavior,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3949,modify  classloader  support  different  application  multitenancy  id  like  expand  current  classloader  support  loading  class  hdfs  different  application  context  ill  modifying  ticket  idea  matures,1,0,1,0,1,0,1,0,1,1,0,0,0,0,0,0,0
3950,add  option  egrep  regexfilter  subsequence  matching  egrep  regexfilter  use  java  matchermatch  return  true  expression  match  entire  string  matcherfind  detect  expression  match  subsequence  string  need  option  use  find  egrep  regexfilter  issue  created  based  discussion  following  two  mailing  list  thread  egrep  usage  134httpmailarchivesapacheorgmodmboxaccumulouser201207mbox3ccap19eqypcnauee4z6tpujt3g3dl2ptlvo92bchclva0lotog40mailgmailcom3e  july  egrep  usage  134httpmailarchivesapacheorgmodmboxaccumulouser201208mbox3ccaggkvpkhoq0xveuvobbdg6tzr2pboskzpjnstqeisvzy2bew40mailgmailcom3e  august  based  discussion  g  global  seem  like  good  candidate  option  add  egrep,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3951,add  hook  shell  transforming  scan  range  hook  shell  manipulate  range  column  passed  scan  range  would  nice  use  case  wanting  undo  formatter  example  suppose  use  new  hexformatter  view  table  binary  data  like  following  scan  table  wo  hex  formatter  hard  read  noformat  roottest15  graph  scan  x06x07dx7fx08xa1x00x08x01x02xefdxc3xd2sxc8  edgecount  1  x06x07dx7fx08xa1x00x08x08x1cxcex8edxe7xda  edgecount  1  x06x07dx7fx08xa1x00x08x0axc7xcedxa54xc0  edgecount  1  x06x07dx7fx08xa1x00x08x0cx04nzx12x92  edgecount  1  x06x07dx7fx08xa1x00x08x0ex95x80x1axa6xeexef  edgecount  1  x06x07dx7fx08xa1x00x08x0excdbhyepxe0  edgecount  1  noformat  add  hexformatter  scan  easier  read  noformat  roottest15  graph  formatter  graph  f  orgapacheaccumulocoreutilformathexformatter  roottest15  graph  scan  060729647f08a100080102ef6440c3d253c8  65646765  636f756e74  31  060729647f08a10008081cce3e8e64e7da  65646765  636f756e74  31  060729647f08a100080ac7ce44a534c02c  65646765  636f756e74  31  060729647f08a100080c045c4e7a127d92  65646765  636f756e74  31  060729647f08a100080e95801aa6eeef2c  65646765  636f756e74  31  060729647f08a100080ecd4248596550e0  65646765  636f756e74  31  060729647f08a1000816ccf83526daf427  65646765  636f756e74  31  060729647f08a1000817b645dcf2b73b65  65646765  636f756e74  31  noformat  however  want  scan  range  table  use  xxx  convention  cumbersome  would  like  following  noformat  scan  b  060729647f08a100  e  060729647f08a101  noformat  propose  adding  following  hook  shell  user  could  configure  scan  interpreter  shell  like  configure  formatter  scan  interpreter  would  take  command  line  argument  translate  interpret  example  hexscaninterpeter  could  take  060729647f08a100  output  binary  representation  hex  string  codejava  public  interface  scaninterpreter  public  text  interpretrowtext  row  public  text  interpretbeginrowtext  row  public  text  interpretendrowtext  row  public  text  interpretcolumnfamilytext  cf  public  text  interpretcolumnqualifiertext  cq  code  originally  thinking  adding  method  formatter  interface  however  christopher  tubbs  convinced  create  separate  interface  argument  may  want  use  something  like  hexscaninterpreter  different  formatters  inorder  make  configuration  easier  discussed  adding  option  shell  formatter  command  option  would  configure  formatter  also  implement  scaninterpreter  interface  saving  user  entering  two  command,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
3952,functionaltest  display  cli  parameter  upon  parse  error  utility  probably  never  run  hand  displaying  option  fairly  simple,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3953,use  cli  library  consistently  parse  parameter  utility  utility  commandline  parsing  pretty  lazy  there  usage  npe  dont  provide  magic  option  commandline  particular  initialize  doesnt  use  offtheshelf  library  commandline  parsing  really  see  accumulo744  addition  many  commandline  utility  able  read  accumulositexml  need  provide  usernamepasswordinstancezookeeper  information  default,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3954,monitor  webpage  bind  interface  monitor  webserver  bind  network  interface  machine  even  specify  ipnumber  master  file  either  bind  interface  given  master  file  configurable  bind  one  specified  interface,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
3955,add  support  importdirectory  mock  instance  adding  import  support  mock  instance  fairly  trivial  useful  testing  mapreduce  pipeline  im  attaching  patch  141  forwardporting  15  pretty  easy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3956,rfile  compress  using  common  prefix  key  element  relative  key  proven  great  way  compress  within  dimension  key  however  could  probably  better  since  know  data  sorted  lexicographically  make  reasonable  assumption  get  better  compression  store  fact  key  portion  key  common  prefix  previous  key  even  exact  match  currently  rfile  unused  bit  delete  flag  byte  used  store  flag  show  whether  element  key  exactly  previous  different  change  semantics  flag  store  three  state  per  element  key  exact  match  previous  key  common  prefix  previous  key  relative  key  compression  dont  want  add  byte  store  2  bit  3  state  per  element  take  ordinal  value  unused  7  bit  delete  flag  field  map  enumeration  relative  key  flag  case  common  prefix  flag  enabled  given  element  current  key  reading  rfile  interpret  first  byte  element  vint  expressing  length  common  prefix  relative  previous  key  element  add  least  one  byte  length  element  want  use  common  prefix  compression  common  prefix  le  2  byte  le  2  byte  common  1  0  byte  common  wed  select  compression  flag  element,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3957,table  namespaces  large  cluster  valuable  shared  resource  current  permission  system  simple  table  naming  structure  allow  delegation  authority  safe  partitioning  within  shared  resource  use  case  create  namespace  like  test  delegate  grant  permission  table  created  namespace  user  would  manage  table  presently  grant  never  delegated  create  simple  test  production  namespaces  trivial  user  switch  example  instead  table  testindex  testdocuments  client  would  support  index  document  api  support  switching  trivially  different  environment  create  set  table  namespace  called  latest  namespace  recreated  periodically  mapreduce  job  code  change  inadvertently  create  corrupt  latest  user  switch  set  table  known  safest  way  user  experiment  provide  feedback  incremental  improvement  safe  fallback  two  application  hosted  cluster  share  table  aliased  namespace  namespacelocal  permission  ignored  likely  readonly  view  table  available  would  helpful  reference  table  quotaspriorities  implement  namespacespecific  priority  resource  allocation  reasonable  run  namespacespecific  query  ingest  production  equipment  large  cluster  resource  always  limited  often  place  nearproduction  quality  software  run  full  scale,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3958,hadoop  20  support  start  thinking  hadoop  2  support  clouderas  recommended  distribution  many  new  hadoop  user  probably  adopting  investigated  first  month  ago  seemed  like  biggest  barrier  mapreduce  related  test  implemented  using  pseudoprivate  constructor  hadoop  10  nolonger  present  hadoop  20  main  strategy  fix  probably  adopt  mapreduce  cluster  test  object  testing  various  accumulo  input  format  instead  instrumenting  directly  used  convenience  object  successfully  test  utilizing  mockinstance  think  work  fine  may  also  filesystem  api  issue  dont  think  severe  main  issue  need  actually  deploy  hadoop  1  2  run  integration  test  start  supporting  headache  release  testing  think,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3959,add  option  pipe  shell  command  file  working  shell  would  useful  direct  scan  output  directly  file  examination  outside  interactive  shell  simple  solution  add  ooutput  file  option  scan  command  shell  command  may  benefit  feature  also,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3960,fate  operation  rolled  shell  fate  nifty  way  deal  directly  calling  utility  jar  roll  functionality  shell  make  easier  manage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3961,add  mutation  constructor  accepting  byte  array  playing  around  reversing  order  key  accumulo  manipulating  key  byte  array  needed  create  mutation  constructor  mutation  accepts  byte  array  wrap  byte  array  text  object  efficient,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3962,columnvisibilities  create  normalized  representation  expression  columnvisibilities  offer  flatten  functionality  attempt  normalize  given  expression  expression  bac  flattend  id  get  back  abc  testing  found  applied  applied  depending  expression  written  instance  something  like  bac  would  get  back  something  like  cab  much  code  provide  correct  normalized  form  expression  well  work  detect  eliminate  expression  boil  exprexpr  exprexpr  ive  attached  sample  program  show  output  current  capability  think  output,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3963,look  replacing  cloudtrace  hbase  created  distributed  tracing  library  today  bumped  zipkin  zipkin  reasonable  visualization  seems  work  thrift  look  replacing  tracing  one,1,1,1,1,1,0,0,0,1,0,1,0,0,0,0,0,1
3964,improve  c  support  thrift  rpc  code  generation  user  emailed  requesting  better  support  cpp  code  generation  thrift  rpc  improved  feature  requested  include  cpp  namespace  add  gen  cpp  line  thriftsh  rename  majorminor  majorsminors  deconflict  sysmacroh,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3965,iterator  transform  key  part  iterators  transform  part  key  tricky  transformation  affect  sort  ordering  implement  iterator  take  care  tricky  detail  come  modifying  sort  order  eg  handling  scantime  iterator  reconstruction  associated  seek,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
3966,support  pluggable  encryption  walogs  case  user  want  encryption  rest  walogs  fairly  trivial  implement  way  insert  cipheroutputstream  data  path  defaulting  using  nullcipher  making  cipher  pluggable  user  insert  appropriate  mechanism  use  case  also  mean  swapping  cipherinputstream  putting  check  make  sure  cipher  type  match  read  write  time  possibly  versioning  mechanism  people  migrate  cipher,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3967,support  side  input  flink  streaming  runner  flink  runner  support  side  input  batch  mode  missing  support  streaming,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3968,make  unboundedsourcewrapper  parallel  unboundedsource  executed  parallelism  1  regardless  split  source  return  corresponding  unboundedsourcewrapper  implement  richparallelsourcefunction  deal  split  correctly,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3969,support  new  state  api  flinkrunner  0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1
3970,set  defaultpartitioner  sourcerddunbounded  sparkrunner  us  mapwithstate  read  manage  checkpointmarks  stateful  operation  followed  shuffle  httpsgithubcomapachesparkblobmasterstreamingsrcmainscalaorgapachesparkstreamingdstreammapwithstatedstreamscalal159  since  stateful  read  map  splitsource  partition  list  read  value  following  shuffle  wont  benefit  way  list  read  value  flatmapped  yet  order  avoid  shuffle  need  set  input  rdd  sourcerddunbounded  partitioner  default  hashpartitioner  since  mapwithstate  would  use  partitioner  skip  shuffle  partitioners  match,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
3971,use  sdk  implementation  writablecoder  spark  runner  currently  us  implementation  writablecoder  use  one  iohdfs  remove  orgapachebeamrunnerssparkcoderswritablecoder,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3972,implement  api  static  display  metadata  described  following  doc  would  like  sdk  allow  associating  display  metadata  ptransforms  httpsdocsgooglecomdocumentd11eneb9jwvp6vo0uoyytmytgkr3tdnfelwwqoiug5zxmedituspsharing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3973,migrate  remaining  test  use  testpipeline  junit  rule  following  beam1176httpsissuesapacheorgjirabrowsebeam1176  following  test  still  direct  call  testpipelinecreate  avroiogeneratedclasstestruntestread  approximateuniquetestrunapproximateuniquewithduplicates  approximateuniquetestrunapproximateuniquewithskeweddistributions  sampletestrunpickanytest  bigtableiotestrunreadtest  consider  using  parametrised  testshttpsgithubcompragmatistsjunitparams  suggested  lcwik,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
3974,auto  set  enableabandonednodeenforcement  testpipeline  moment  one  manually  set  enableabandonednodeenforcementfalse  test  run  testpipeline  otherwise  one  get  abandonednodeexception  account  node  run  could  probably  auto  detected  using  runnableonservice  needsrunner  annotation  presence  indicates  given  test  indeed  use  runner  essentially  need  check  runnableonservice  needsrunner  present  given  test  set  enableabandonednodeenforcementtrue  otherwise  set  enableabandonednodeenforcementfalse  tgroh  kenn,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
3975,replace  public  constructor  static  factory  method  sumfn  class  sumsumdoublefn  sumintegerfn  sumlongfn  using  xof  xfrom  instance  creation  via  static  method  pattern  ubiquitous  beam  following  discussion  dev  list  would  great  preserve  consistent  look  feel  change  creation  pattern  class  something  like  sumfnoflong  etc  see  also  corresponding  dev  list  threadhttpslistsapacheorgthreadhtml5d8e905ee49b116d13811c2a96da65eeb44ab7c002870f50936ee1ad3cdevbeamapacheorg3e,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
3976,align  naming  generateinitialsplits  splitintobundles  better  reflect  intention  see  dev  list  threadhttpslistsapacheorgthreadhtmlac5717566707153e85da880cc75c8d047e1c6606861777670bb9107c3cdevbeamapacheorg3e,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3977,basic  java  harness  capable  understanding  process  bundle  task  sending  data  fn  api  create  basic  java  harness  capable  understanding  process  bundle  request  able  stream  data  fn  api  overview  httpssapacheorgbeamfnapi,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3978,update  flink  runner  flink  120  update  120  use  new  internal  timer  api  available  flink  operator  internaltimerservice  also  use  broadcast  state  store  sideinput  data,1,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1
3979,introduce  io  metric  introduce  usage  metric  api  io  poc  using  countinginput  add  metric  countinginput  runnableonservice  test  creates  pipeline  asserts  metric  close  gap  direct  runner  spark  runner  support  metric,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
3980,use  flinknative  side  output  flink  support  side  output  use  instead  manually  dealing  rawunionvalues  side  output  flink  tracked  httpsissuesapacheorgjirabrowseflink4460,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3981,create  dataflow  runner  package  move  dataflow  runner  sdk  core  new  dataflow  runner  maven  module,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
3982,refactor  hbaseio  hide  visibility  codersserializable  class  0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3983,create  hadoopcommon  module  share  common  code  hadoop  based  io  hdfsio  hbaseio  eventually  hiveio  share  common  class  example  configuration  recent  addition  serializableconfiguration  start  repeated  code  address  issue,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3984,need  sourcesink  spanner  sourcesink  spanner  work  would  gladly  give  shot,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3985,kafkaio  allow  using  kafka  serializers  deserializers  kafkaio  allow  override  serializer  deserializer  setting  kafka  consumer  producer  us  internally  instead  allows  set  coder  simple  kafka  serializerdeserializer  wrapper  class  call  coder  appreciate  allowing  use  beam  coder  good  consistent  rest  system  however  reason  completely  disallow  use  custom  kafka  serializers  instead  limitation  working  avro  schema  registry  instance  requires  custom  serializers  one  write  coder  wrap  custom  kafka  serializer  mean  two  level  unnecessary  wrapping  addition  coder  abstraction  equivalent  kafka  serializer  get  topic  name  input  using  coder  wrapper  would  require  duplicating  output  topic  setting  argument  kafkaio  building  wrapper  elegant  error  prone,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1
3986,add  support  bounded  source  streaming  mode  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3987,support  real  bundle  flink  runner  bundle  important  beam  model  user  use  bundle  flush  buffer  reuse  many  heavyweight  resource  bundle  io  plugins  use  bundle  flush  moreover  flinkrunner  also  use  bundle  reduce  access  flinkstate  first  placed  javaheap  flush  rocksdbstate  invoke  finishbundle  reduce  number  serialization  flinkrunner  call  finishbundle  every  processelement  need  support  real  bundle  think  following  implementation  1invoke  finishbundle  next  startbundle  snapshot  flink  sometimes  bundle  maybe  big  depends  user  checkpoint  configuration  2manually  control  size  bundle  halfbundle  flushed  fullbundle  count  eventtime  processtime  snapshot  need  wait  call  startbundle  finishbundle  right  time  proposal  documenthttpsdocsgooglecomdocumentd1uzelm4nfu8sieuqjkbs0sv7uzd1ux4axxm3cw4s7poedituspsharing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
3988,create  elasticsearch  io  compatible  e  5x  current  elasticsearch  io  see  httpsissuesapacheorgjirabrowsebeam425  compatible  elasticsearch  v  2x  aim  io  compatible  e  v  5x  beyond  able  address  v5x  elasticsearch  instance  could  also  leverage  use  elasticsearch  pipeline  api  also  better  split  dataset  close  possible  desiredbundlesize  thanks  new  e  split  api  allows  e  shard  splitting,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1
3989,withcoder  error  jdbcio  javadoc  example  follow  javadoc  jdbcio  job  fails  exception  code  exception  thread  main  javalangillegalstateexception  jdbcioread  requires  coder  set  via  withcodercoder  comgooglecommonbasepreconditionscheckstatepreconditionsjava176  orgapachebeamsdkiojdbcjdbcioreadvalidatejdbciojava329  orgapachebeamsdkiojdbcjdbcioreadvalidatejdbciojava249  orgapachebeamsdkpipelineapplyinternalpipelinejava419  orgapachebeamsdkpipelineapplytransformpipelinejava350  orgapachebeamsdkvaluespbeginapplypbeginjava58  orgapachebeamsdkpipelineapplypipelinejava172  code  requires  coder  provided  withcoder  need  add  example  point  really  need  specify  coder  user  register  coderregistry  think,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3990,accumulable  metricscontainers  make  metricscontainer  accumulable  reduce  duplication  runner  make  implementing  metric  easier  runner  author,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
3991,apply  change  flinks  statefuldofnrunner  primary  statefuldofnrunner  followup  comment  httpsgithubcomapachebeampull2217  left  unaddressed  order  unblock  release  content  pr  good  user  issue  bit  code  health  correctness  support  code  runner  author  moving  forward,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
3992,autoservice  registration  coder  like  pipelinerunners  today  registering  coder  auxiliary  data  type  library  transform  convenient  appears  outputcovariant  position  might  possible  use  getdefaultoutputcoder  solve  thing  writescontravariant  position  applicable  library  transform  must  contort  avoid  requiring  user  come  coder  type  dont  probably  best  case  today  explicit  call  librarytransformregistercoderspipeline  far  manual  could  likely  solved  quite  easily  autoservice  static  global  coder  registry  pipeline  runner,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
3993,bigtable  improve  user  agent  bigtableclientcore  changed  way  generates  user  agent  string  automatically  provide  information  providing  manually  update  bigtableio  client  code  fit  new  improved  scheme,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3994,fix  use  deprecated  spark  apis  runner  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3995,support  splittable  dofn  flink  streaming  runner  0,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0
3996,thin  java  sdk  core  first  stable  release  need  thin  sdkjavacore  module  candidate  removal  nonexhaustive  list  sdkio  anything  bigquery  related  anything  pubsub  related  everything  protobuf  related  tfrecordio  xmlsink  sdkutil  everything  gc  related  everything  backoff  related  everything  google  api  related  responseinterceptors  retryhttpbackoff  etc  everything  cloudobjectrelated  pubsub  stuff  sdkcoders  jaxbcoder  tablerowjsoncoder,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
3997,add  hadoop  filesystem  implementation  beam  filesystem  beam  filesystem  creates  abstraction  reading  file  many  different  place  add  hadoop  filesystem  implementation  httpshadoopapacheorgdocsr280apiorgapachehadoopfsfilesystemhtml  would  enable  u  read  file  system  implement  filesystem  including  hdfs  azure  s3  etc  im  investigating,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
3998,window  support  therere  several  method  tumblehopsession  introduced  calcite  112  represent  windowaggregation  operation  beamsql  expected  leverage  method  determine  window  function  set  trigger  strategy  also  handle  eventtimewatermark  properly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
3999,move  cloudobject  dataflow  runner  entail  primarily  eliminating  coderascloudobject  adding  needed  accessors  possibly  serialization  registrar  discipline  coder  runner  api  proto,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4000,create  parquet  io  would  nice  support  parquet  file  projection  predicate,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4001,beamkafkacsvtable  support  column  type  string  currently  beamkafkacsvtable  support  string  column  need  support  type  also  use  robust  library  parse  csv,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4002,support  recursive  wildcards  gcspath  working  heavily  nested  folder  structure  google  cloud  storage  great  make  use  recursive  wildcards  current  api  explicitly  support  code  hasnt  touched  2  year  likely  simply  one  gotten  around  yet,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4003,support  custom  user  jackson  module  pipelineoptions  hadoopfilesystem  added  support  passing  hadoop  configuration  pipelineoptions  beam2031  done  making  objectmapper  within  pipelineoptionsfactory  find  load  jackson  module  using  jackson  supported  serviceloader  pattern  serializing  pipelineoptions  requires  runner  also  use  objectmapper  similarly  configured,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
4004,allow  coder  factory  create  coder  wider  range  type  allowing  coderfactory  see  type  look  annotation  type  allowing  defaultcoder  become  coderfactory  creating  protocoderfactory  delegate  protocoder  message  type  creating  serializablecoderfactory  delegate  serializablecoder  serializable  type  creating  writablecoderfactory  delegate  hadoop  writablecoder  hadoop  writable  type  requires  plumbing  typedescriptor  primary  method  looking  coder  within  coderregistry  also  remove  concept  fallback  coder  provider  since  every  coder  factory  treated  fallback,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
4005,kafkaio  support  use  start  read  time  set  start  offset  kafka  010x  add  support  searchable  index  topic  based  message  timestamps  enables  consumer  support  offset  lookup  timestamp  add  start  read  time  set  start  offset,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4006,make  easier  specify  windowed  filename  policy  easier  beam  user  specify  filename  policy  understands  windowing  concept  discussion  httpslistsapacheorgthreadhtmlb53e437894eb511c9161d34fc77c657300b77a7be75f0fab6566b3d63cdevbeamapacheorg3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4007,refine  dsl  interface  part  beam2010  update  interface  explain  sql  query  link  pipeline  part  supported  code  prepare  environment  beamsql  beamsqlenvironment  sqlenv  beamsqlenvironmentcreate  register  table  metadata  sqlenvaddtablemetadatastring  tablename  beamsqltable  tablemetadata  register  udf  sqlenvregisterudfstring  functionname  method  udfmethod  explain  sql  statement  select  return  pcollection  pcollectionbeamsqlrow  phase1stream  sqlenvexplainsqlpipeline  string  sqlstatement  code,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
4008,pcollection  table  support  method  registerpcollectionastable  beamsql  dsl  feature  make  possible  break  complex  query  several  subqueries  assemble  developer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4009,rename  removeduplicates  distinct  really  tough  time  finding  transform  doc  suggest  changing  class  name  distinct  instead  removeduplicates  least  javadoc  removeduplicates  word  distinct  make  findablesearchable,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
4010,make  write  transform  hbaseio  simpler  hbaseio  imitated  interface  cloud  bigtable  easy  migration  path  user  fromto  bigtable  bigtable  mutation  object  include  row  key  bigtableio  needed  kv  row  key  mutation  order  change  data  hbase  restriction  row  key  part  mutation  object  issue  simplify  write  transform  even  make  small  difference,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4011,abstract  stateinternalstest  different  state  internalsrunners  test  inmemorystateinternals  apexstateinternals  flinkstateinternals  sparkstateinternals  etc  common  base  class  state  internals  test  abstract  method  createstateinternals  test  method  actual  implementation  would  derive  implement  method  creating  state  internals,1,0,0,0,0,0,0,0,1,1,1,1,1,0,0,0,1
4012,dsl  sql  reduce  visibility  simplify  backwards  compatibility  package  namespace  flattened  one  java  package  everything  made  package  private  except  public  class  like  beamsql  beamsqlcli  beamsqlrow  beamsqlrowcoder  simplify  backwards  compatibility  story  merging  since  reduces  visible  surface  user  interact,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4013,dsl  sql  public  classesmethods  exposeuse  calcite  type  calcite  internal  implementation  detail  beam  sql  operating  prevent  hard  dependence  calcite  public  method  class  rely  consumingproducing  calcite  type  example  beamsqlrecordtype  us  orgapachecalcitesqltypesqltypename  instead  using  java  sql  type  httpsdocsoraclecomjavase8docsapijavasqltypeshtml  task  create  apisurfacetest  help  find  fix  prevent  orgapachecalcite  exposed  example  apisurfacetest  httpsgithubcomapachebeamblob367fcb28d544934797d25cb34d54136b2d7d6e99sdksjavacoresrctestjavaorgapachebeamsdkcoreapisurfacetestjava,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4014,beamsqlrecordtype  migrate  using  builder  pattern  via  autovalueautobuilder  code  health  usability  issue  performing  migration  use  autovalueautobuilder  make  easier  people  create  table  row  type  without  needing  worry  mutability,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4015,backlog  size  retrieval  kinesis  source  implement  backlog  size  retrieval  kinesis  source  use  amazon  cloudwatch  allow  runner  scale  amount  resource  allocated  pipeline,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
4016,kinesisio  watermark  based  approximatearrivaltimestamp  kinesis  start  reading  stream  point  past  retention  period  7  day  current  approach  setting  record  timestamp  watermark  always  set  current  time  ie  instantnow  cant  observe  actual  position  stream  idea  change  behaviour  set  record  timestamp  based  approximatearrivaltimestamphttpdocsawsamazoncomkinesislatestapireferenceapirecordhtmlstreamstyperecordapproximatearrivaltimestamp  watermark  set  accordingly  last  read  record  timestamp  approximatearrivaltimestamp  still  approximation  may  result  record  outoforder  timestamps  turn  may  result  event  marked  late  however  frequent  issue  even  happens  matter  millisecond  second  handled  even  tiny  allowedlateness  setting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4017,reading  kinesis  record  background  currently  kinesis  record  read  demand  runner  thread  may  instead  read  record  background  separate  thread  store  time  buffer  result  major  performance  improvement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4018,handling  kinesis  shard  split  merges  kinesis  stream  consists  shardshttpdocsawsamazoncomstreamslatestdevkeyconceptshtmlshard  allow  capacity  scaling  order  increasedecrease  capacity  shard  splitmerged  together  operation  currently  handled  properly  end  error,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4019,textio  support  watching  new  file  motivation  proposed  implementation  httpssapacheorgtextiosdf,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4020,improve  error  message  missing  required  option  beam  pipeline  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4021,unify  flink  operator  wrapper  right  flinkabstractpardowrapper  subclass  flinkpardoboundwrapper  flinkpardoboundmultiwrapper  well  flinkgroupalsobywindowwrapper  essentially  thing  slightly  differently  first  three  implemented  flatmapfunction  latter  implemented  streamoperator  lowlevel  give  access  state  timer  unify  one  wrapper  possibly  concise  name  process  also  make  sure  always  use  dofnrunner  via  dofnrunnerscreatedefault  help  reduce  bug  beam241,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1
4022,elasticsearchio  break  non  locally  accessible  db  e  24  database  running  production  accessible  devmachines  vps  firewall  rule  however  create  beam  graph  locally  machine  submit  google  dataflow  execution  however  check  line  213  codejava  private  static  void  checkversionconnectionconfiguration  connectionconfiguration  throw  ioexception  restclient  restclient  connectionconfigurationcreateclient  response  response  restclientperformrequestget  new  basicheader  jsonnode  jsonnode  parseresponseresponse  string  version  jsonnodepathversionpathnumberastext  boolean  version2x  versionstartswith2  restclientclose  checkargument  version2x  connectionconfigurationcreateaddresses  index  type  elasticsearch  version  connect  different  2x  version  elasticsearchio  compatible  elasticsearch  v2x  code  creation  graph  fails  cant  complete  restclient  request  dev  machine  check  probably  happen  early  since  guarantee  database  reachable  building  graph  codejava  exception  thread  main  javanetconnectexception  orgapachehttpniopoolroutespecificpooltimeoutroutespecificpooljava168  orgapachehttpniopoolabstractnioconnpoolrequesttimeoutabstractnioconnpooljava561  orgapachehttpniopoolabstractnioconnpoolinternalsessionrequestcallbacktimeoutabstractnioconnpooljava822  orgapachehttpimplnioreactorsessionrequestimpltimeoutsessionrequestimpljava183  orgapachehttpimplnioreactordefaultconnectingioreactorprocesstimeoutsdefaultconnectingioreactorjava210  orgapachehttpimplnioreactordefaultconnectingioreactorprocesseventsdefaultconnectingioreactorjava155  orgapachehttpimplnioreactorabstractmultiworkerioreactorexecuteabstractmultiworkerioreactorjava348  orgapachehttpimplnioconnpoolingnhttpclientconnectionmanagerexecutepoolingnhttpclientconnectionmanagerjava192  orgapachehttpimplnioclientcloseablehttpasyncclientbase1runcloseablehttpasyncclientbasejava64  javalangthreadrunthreadjava745  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4023,windowfntestutils  allow  using  value  addition  timestamp  element  windowfntestutils  relies  timestamps  everything  related  window  assignment  test  helper  creating  custom  windowfn  likely  customwindow  well  windowfn  might  rely  element  value  addition  timestamp  decide  window  assigned  element  able  test  kind  custom  windowfn  need  version  helper  method  windowfntestutils  allow  passing  timestampedvalues,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4024,apache  apex  runner  like  spark  flink  gearpump  apache  apex  also  advantage  possible  runner  apache  apex,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4025,introduce  createofprovidervalueprovider  valueprovidert  may  may  accessible  construction  time  common  task  wrap  singleelement  pcollectiont  especially  common  migrating  io  connector  used  something  like  createofquery  followed  pardo  query  valueprovider  currently  done  icky  way  eg  httpsgithubcomapachebeamblobmastersdksjavaiogooglecloudplatformsrcmainjavaorgapachebeamsdkiogcpdatastoredatastorev1javal615  convenience  helper,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4026,textio  allow  specifying  custom  delimiter  currently  textio  use  r  n  rn  mix  two  split  text  file  pcollection  element  might  happen  record  spread  across  one  line  case  able  specify  custom  record  delimiter  used  place  default  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4027,make  minlongfn  maxlongfn  mimic  sumlongfn  use  binarycombinelongfn  ditto  optimized  accumulator  combiner  function,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4028,implement  fileiowrite  design  doc  httpsapacheorgfileiowrite  discussion  httpslistsapacheorgthreadhtmlcc543556cc709a44ed92262207215eaa0e43a0f573c630b6360d4edc3cdevbeamapacheorg3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4029,bigtableio  use  valueproviders  httpsgithubcomapachebeampull2057  effort  towards  bigtableio  templatization  issue  request  get  fully  featured  template  bigtableio,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4030,extract  reifytimestampsandwindows  gatherallpanes  reifytimestampsandwindowsfn  gatherallpanes  look  useful  giving  mapelements  filter  etc  access  window  pane  information  jira  represents  proposal  extract  subset  gatherallpanes  functionality  new  class  reifytimestampsandwindows  next  reifytimestamps  similar  functionality  timestampedvalue  gatherallpanes  would  rely  newly  extracted  public  ptransform  previous  functionality,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0
4031,set  userspecified  transform  name  flink  operation  currently  dont  always  set  name  generated  operation  set  wrong  name  example  batch  translation  set  result  ptransformgetname  name  name  ptransform  name  user  specified  creating  pipeline,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4032,samza  runner  apache  samza  distributed  dataprocessing  platform  support  stream  batch  processing  itll  awesome  run  beam  advanced  data  transform  multilanguage  sdks  top  samza,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
4033,improve  log  elasticsearchio  test  utils  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4034,support  file  scheme  textio  user  use  textio  time  provide  full  file  uri  filetmpfoo  unfortunately  file  schema  supported  textio  fails  handler  found  easy  user  figure  support  file  schema  provide  better  flexibility  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4035,elasticsearchio  allow  user  optionally  pas  id  type  index  per  document  dynamic  document  id  today  esio  insert  payload  e  document  elasticsearch  generates  document  id  record  inserted  new  insertion  considered  new  document  user  want  able  update  document  using  io  write  part  io  user  able  provide  document  id  could  update  already  stored  document  providing  id  document  could  also  help  user  indempotency  dynamic  e  type  e  index  case  streaming  pipeline  high  throughput  partitioning  pcollection  allow  plug  different  esio  instance  pointing  different  indextype  practical  user  would  like  able  set  e  indextype  per  document,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4036,add  kinesis  write  transform  currently  kinesisio  read  transform  need  provide  write,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4037,add  serviceendpoint  parameter  kinesisio  kinesisclient  instantiated  different  serviceendpoint  official  amazon  one  allows  user  test  kinesisio  locally  overwriting  endpointurl  pointing  emulator  like  httpsgithubcomlocalstacklocalstack  httpsgithubcommhartkinesalite,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4038,update  kinesisio  use  aws  sdk  111255  kcl  188  current  version  aws  sdk  kinesis  us  include  new  regionsaz  aws  update  solves  well  include  recent  fix  sdk,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4039,change  filtergreaterthan  etc  actually  use  filter  good  starter  task  right  filtergreaterthanhttpsgithubcomapacheincubatorbeamblob315b3c8e333e5f42730c19e89f856d778ce93cabsdksjavacoresrcmainjavaorgapachebeamsdktransformsfilterjaval134  construct  new  dofn  rather  using  filterbypredicate  fix  make  consistent  simpler  also  remove  deprecated  function  file  possible  redundant  display  data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4040,redisio  nonprefix  read  operation  read  operation  redisio  prefix  based  look  ups  used  exact  key  match  well  number  operation  limit  put  function  suggest  exposing  current  readall  operation  readbyprefix  using  simpler  operation  readall  functionality  ex  codejava  string  output  jedisgetelement  output  null  processcontextoutputkvofelement  output  code  instead  httpsgithubcomapachebeamblob7d240c0bb171af6868f1a6e95196c9dcfc9ac640sdksjavaioredissrcmainjavaorgapachebeamsdkioredisredisiojaval292,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
4041,remove  merge  java  8  specific  test  module  main  one  module  beamsdksjavajava8tests  specific  test  core  transforms  written  java  8  syntax  move  java  8  probably  doesnt  make  sense  anymore  module  test  java  8  test  module  merged  main  one  removed  already  covered,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4042,sql  refactor  beamrelnodes  ptransforms  beamrelnode  expose  pcollectionbeamrecord  buildbeampipeline  build  pipeline  parsing  feel  like  instead  implement  ptransformpcollectionbeamrecord  pcollectionbeamrecord  would  receive  prepared  pcollection  apply  subexpressions  instead  manually  invoking  expression  evaluation  get  input  maybe  consider  building  lazily,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4043,support  encryption  s3filesystem  sses3  ssec  ssekms  enable  aws  s3  user  use  encryption  reading  writing  provide  encryption  key  using  server  side  encryption  via  algorithm  key  management  system  km,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4044,dataflow  runner  support  readbounded  streaming  mode  unboundedreadfromboundedsource  done  make  dataflow  runner  use,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4045,make  metricqueryresults  related  class  jsonserialization  friendly  working  pr  httpsgithubcomapachebeampull4548  metricqueryresults  needed  serialized  pushed  metric  sink  required  custom  serializer  call  name  counter  committed  attempted  method  metricqueryresults  close  serializable  default  serializer  need  accessors  renamed  get  creating  dto  object  get  method  call  nonget  method  seems  unnecessary  rename  public  accessors  get  experimental  api,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4046,update  flink  runner  flink  150  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
4047,add  test  flink  dofnoperator  sideinput  checkpointing  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4048,refactor  hbaseio  splitting  produce  bytekeyrange  object  allows  reuse  splitting  logic  future  sdfbased  implementation  reusing  part  splitrestriction  method,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4049,add  hbaseioreadall  based  sdf  since  support  runner  still  limited  probably  wise  create  first  io  based  current  sdf  batch  implementation  java  validatetest  real  datastore  since  hbase  partitioning  model  quite  straightforward  perfect  candidate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4050,portable  flink  runner  jobservice  entry  point  docker  container  portable  flink  runner  exists  job  service  run  somewhere  need  main  entry  point  spin  job  service  artifact  staging  service  main  program  packaged  uberjar  run  locally  submitted  flink  deployment  via  flink  run,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4051,split  iotestpipelineoptions  multiple  testspecific  file  currently  one  big  iotestpipelineoptions  interface  used  many  ioits  contains  test  specific  option  rather  located  next  testing  class  generic  file  let  split  additionally  besides  separation  concern  allow  adding  testspecific  default  required  annotation  validate  option  better,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4052,introducing  gcptemplocation  default  templocation  currently  dataflowpipelineoptionsstaginglocation  default  templocation  requires  templocation  gc  path  another  case  bigqueryio  us  templocation  also  requires  gc  user  cannot  set  templocation  nongcs  path  dataflowrunner  bigqueryio  however  templocation  could  file  system  example  wordcount  default  output  templocation  proposal  add  gcptemplocation  default  templocation  templocation  gc  path  staginglocation  bigqueryio  use  gcptemplocation  default,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4053,enable  partial  update  elasticsearch  expose  configuration  option  elasticsearchio  enable  partial  update  rather  full  document  insert  rationale  case  different  pipeline  process  different  category  information  target  entity  eg  one  taxonomic  processing  another  geospatial  processing  read  merge  possible  inside  batch  call  meaning  way  join  join  approach  slow  also  stop  ability  run  single  process  isolation  eg  reprocess  geospatial  component  doc  use  configuration  parameter  used  conjunction  controlling  document  id  possible  since  beam3201  make  sense  client  api  would  include  withuseupdate  code  sourceapply  elasticsearchiowrite  withconnectionconfigurationconnectionconfiguration  withidfnnew  extractvaluefnid  withuseupdatetrue  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
4054,consider  enabling  spotless  java  format  throughout  codebase  spotless  enforce  automatically  restore  automatic  java  formatting  whenever  formatting  tell  user  exact  command  fix  isnt  code  layout  automation  pretty  strict  style  rule  enforced  checkstyle  efficient  way  fix  file  autoformat  autoformat  hit  bunch  irrelevant  line  annoying  reviewer  obscures  git  blame  enforce  autoformat  time  make  sure  autoformatting  particular  pr  minimal  effect  always  safe,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4055,pipelineresult  need  waituntilfinish  cancel  waittofinish  cancel  two  common  operation  user  interact  started  pipeline  right  available  dataflowpipelinejob  better  move  common  interface  people  start  implement  runner  runner  agnostic  code  interact  pipelineresult  better,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4056,improve  iochannelutilsresolve  accept  multiple  path  currently  iochannelutilsresolve  method  resolve  one  path  base  path  useful  another  method  argument  includes  one  base  path  multiple  others  return  string  directory  start  base  path  append  rest  separated  file  separator,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4057,bigqueryioread  reimplemented  boundedsource  bigqueryioread  currently  implemented  hacky  way  directpipelinerunner  stream  row  table  query  result  directly  using  json  api  singlethreaded  manner  contrast  dataflowpipelinerunner  us  entirely  different  code  path  implemented  google  cloud  dataflow  service  bigquery  export  job  gc  followed  parallel  read  gc  need  reimplement  bigqueryio  boundedsource  order  support  runner  scalable  way  additionally  suggest  revisit  design  bigqueryio  source  process  short  list  use  tablerow  default  value  row  could  mapstring  object  welldefined  type  example  avro  genericrecord  dropping  tablerow  get  around  variety  issue  type  field  named  f  etc  also  reduce  confusion  use  tablerow  object  differently  usual  good  reason  could  also  directly  add  support  rowparser  user  pojo  expose  tableschema  side  output  bigqueryioread  builder  bigqueryioread  useful  keep  possible  also  allow  user  provide  json  object  configure  underlying  intermediate  table  query  export  etc  would  let  user  directly  control  result  flattening  location  intermediate  table  table  decorator  etc  also  optimistically  let  user  take  advantage  new  bigquery  feature  without  code  change  could  use  switch  whether  use  bigquery  export  parallel  scan  v  api  read  based  factor  size  table  pipeline  construction  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4058,use  bigqueryservices  abstraction  bigqueryio  legacy  code  sent  request  bigquery  directly  moved  use  bigqueryservices,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4059,improve  beamsqlline  unit  test  0,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4060,add  integration  test  beamsqlline  test  non  group  window  query  beam  sql  shell  tutorial,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4061,generalize  filechecksummatcher  used  e2e  test  refactor  wordcountonsuccessmatcher  general  reused  test  requirement  given  input  file  path  accept  glob  expected  checksum  generate  checksum  file  verify  expected,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
4062,bigqueryiowrite  reimplement  java  bigqueryiowrite  currently  implemented  somewhat  hacky  way  unbounded  sink  directpipelinerunner  dataflowpipelinerunner  use  streamingwritefn  bigquerytableinserter  insert  row  using  bigquerys  streaming  writes  api  bounded  sink  directpipelinerunner  still  us  streaming  writes  dataflowpipelinerunner  us  different  code  path  google  cloud  dataflow  service  writes  gc  initiate  bigquery  load  job  perwindow  table  destination  work  scalably  see  beamxxx  need  reimplement  bigqueryiowrite  fully  java  code  order  support  runner  scalable  way  additionally  suggest  revisit  design  bigqueryio  sink  process  short  list  use  tablerow  default  value  row  could  mapstring  object  welldefined  type  example  avro  genericrecord  dropping  tablerow  get  around  variety  issue  type  field  named  f  etc  also  reduce  confusion  use  tablerow  object  differently  usual  good  reason  possibly  support  notknowing  schema  pipeline  execution  time  builder  bigqueryiowrite  useful  keep  possible  also  allow  user  provide  json  object  configure  underlying  table  creation  write  disposition  etc  would  let  user  directly  control  thing  like  table  expiration  time  table  location  etc  would  also  optimistically  let  user  take  advantage  new  bigquery  feature  without  code  change  could  choose  streaming  write  api  load  job  based  user  preference  dynamic  job  property  could  use  streaming  write  batch  pipeline  data  small  could  use  load  job  streaming  pipeline  window  large  enough  make  practical  issuing  bigquery  load  job  could  leave  file  gc  import  fails  data  error  debugged  make  perwindow  table  writes  scalable  batch  caveat  possibly  blocker  beamxxx  cleanup  temp  file  management  one  advantage  google  cloud  dataflow  implementation  bigqueryiowrite  cleanup  ensure  intermediate  file  deleted  bundle  job  fail  etc  beam  currently  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4063,optimize  filebasedsinks  writeoperationmovetooutput  movetooutput  method  filebasedsinkwriteoperation  implement  move  copydelete  would  better  use  rename  much  effective  filesystems  filesystem  must  support  crossdirectory  rename  beam4861  related  case  hdfs  filesystem  feature  discussed  httpmailarchivesapacheorgmodmboxbeamdev201807mbox3ccaf9t74mp54pqvrrjrbh9vx0uaknupzdqdhqdm9vxllszwmailgmailcom3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4064,support  e  6x  elasticsearchio  elasticsearch  released  632  elasticsearchio  support  2x5x  support  e  6x  elasticsearchio  httpswwwelasticcoguideenelasticsearchreferencecurrentindexhtml  httpsgithubcomapachebeamblobmastersdksjavaioelasticsearchsrcmainjavaorgapachebeamsdkioelasticsearchelasticsearchiojava,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4065,add  md5  consistency  check  s3  uploads  writes  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4066,pubsubio  reimplement  java  pubsubio  currently  partially  implemented  java  directpipelinerunner  us  nonscalable  api  singlethreaded  manner  contrast  dataflowpipelinerunner  us  entirely  different  code  path  implemented  google  cloud  dataflow  service  need  reimplement  pubsubio  java  order  support  runner  scalable  way  additionally  take  opportunity  add  new  feature  getting  timestamp  arbitrary  lambda  arbitrary  format  rather  message  attribute  2  format  exposing  metadata  attribute  element  produced  pubsubioread  setting  metadata  attribute  message  written  pubsubiowrite,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,1,0
4067,pipeline  execution  naming  change  purpose  change  clarify  difference  two  consensus  runner  unify  implementation  current  state  pipelineoptionsappname  default  mainclass  name  dataflowpipelineoptionsjobname  default  appnameuserdatetime  flinkpipelineoptionsjobname  default  appnameuserdatetime  proposal  1  replace  pipelineoptionsappname  pipelineoptionspipelinename  uservisible  name  specific  graph  default  mainclass  name  use  case  find  execution  pipeline  2  add  jobname  top  level  pipelineoptions  unique  name  execution  default  pipelinename  user  datetime  random  integer  use  case  finding  execution  usera  timex  timey  naming  resource  created  execution  example,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
4068,support  dynamic  pipelineoptions  graph  construction  phase  given  sdk  generates  initial  execution  graph  program  execution  time  graph  executed  either  locally  service  currently  beam  support  parameterization  graph  construction  time  flink  spark  supply  functionality  allows  precompiled  job  run  without  sdk  interaction  updated  runtime  parameter  current  incarnation  dataflow  read  value  pipelineoptions  job  submission  time  requires  presence  sdk  properly  encode  value  job  would  like  build  common  layer  beam  model  dynamic  option  properly  provided  job  please  see  httpsdocsgooglecomdocumentd1iiigwdyasb7zmxbgbhdokik1r1yaj90jg5fz028oedit  highlevel  model  httpsdocsgooglecomdocumentd17i7henqmiifoji0ai70tggmmkosggi8zuhmonfatz8edit  specific  api  proposal,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4069,move  mock  class  sql  srcmain  0,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0
4070,portable  flink  support  maxbundlesizemaxbundlemillis  portable  runner  need  support  larger  bundle  streaming  mode  currently  every  element  separate  bundle  inefficient  due  per  bundle  sdk  worker  overhead  old  java  sdk  runner  already  support  parameter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4071,allow  registering  udf  method  name  different  argument  list  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4072,switch  iochannelfactory  filesystems  right  filebasedsource  filebasedsink  communication  mediated  iochannelfactory  number  issue  global  configuration  eg  g  uris  use  credential  persourcepersinketc  supported  apis  currently  iochannelfactory  nonpublic  api  util  package  subject  change  need  user  able  add  new  backends  s3  hdfs  etc  directly  without  fear  broken  perbackend  feature  eg  creating  bucket  gcss3  setting  expiration  time  etc  update  design  doc  posted  dev  list  part  1  iochannelfactory  redesign  httpsdocsgooglecomdocumentd11tdpyz9zmjokhnwm3idxjsvg3qel2lhdktknmz7medit  part  2  configurable  beamfilesystem  httpsdocsgooglecomdocumentd17vo9nlrseezdgnb562pul4q9muiqzvpcaiyyjw8p8editheadinghp3gc3colc2cs,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4073,simplestreamingwordcounttest  properly  test  fixed  window  orgapachebeamrunnerssparktranslationstreamingsimplestreamingwordcounttest  properly  test  fixedwindows,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4074,splittabledofn  splittabledofn  proposed  enhancement  dynamically  splittable  work  beam  model  among  thing  would  allow  unified  implementation  boundedunbounded  source  dynamic  work  rebalancing  ability  express  multiple  scalable  step  eg  global  expansion  file  sizing  parsing  splitting  file  independentlyprocessable  block  via  composition  rather  inheritance  would  make  much  easier  implement  many  type  source  modify  reuse  existing  source  also  would  improve  scalability  beam  model  moving  thing  like  splitting  source  control  plane  today  glob  listfilebasedsource  sent  service  apis  data  plane  pcollectionglob  pcollectionfilename,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4075,add  public  typedpvaluesettypedescriptor  would  give  fairly  pithy  answer  stackoverflow  question  sometimes  choosing  getoutputcoder  getoutputtypedescriptor  transformdofn  often  choose  type  coder  registry  thing  would  also  give  similar  choice  setcoder  settypedescriptor  anyhow  intention  removing  practice  internal  suffix  one  might  easily  solved  making  public,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4076,use  autovalue  deal  document  instead  string  mongodbio  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4077,migrate  jmsio  use  autovalue  reduce  boilerplate  use  autovalue  functionality  reduce  boilerplate  see  pr  example  httpsgithubcomapacheincubatorbeampull1054,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4078,remove  legacy  credential  flag  related  gcp  adopt  application  default  credential  supported  default  flow  drop  following  gcpoptions  use  adc  httpsdevelopersgooglecomidentityprotocolsapplicationdefaultcredentials  cleanup  credential  story  gcp  authorizationserverencodedurl  tokenserverurl  credentialdir  credentialid  secretsfile  serviceaccountname  serviceaccountkeyfile  also  migrate  apiary  credential  class  google  oauth  credential  class  available  googlecloudjava,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4079,use  composition  inheritance  spark  streamingevaluationcontext  two  context  necessary  working  pr  httpsgithubcomapacheincubatorbeampull1096  felt  easy  forget  updating  spark  streaming  context  current  inheritance  single  evaluationcontext  support  streaming  batch  even  better,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,1
4080,validate  pipelineoptions  default  annotation  shouldnt  allow  override  default  annotation  example  following  broken  interface  defaultinteger1  integer  getfoo  void  setfoo  interface  b  extends  defaultinteger1  override  integer  getfoo  broken  pipelineoptions  default  value  lazily  evaluated  depends  one  two  following  operation  happen  first  optionsasaclass  optionsasbclass  user  want  change  default  value  user  setfoo  explicitly  shouldnt  allow  adding  default  annotation  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4081,support  groupbykey  directly  currently  sparkrunner  support  groupbykey  via  override  groupbykeyviagroupbykeyonly  make  support  groupbykey  directly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4082,pardo  chaining  current  state  apex  runner  creates  plan  place  operator  separate  container  would  process  running  yarn  cluster  often  pardo  operator  collocated  thread  container  use  apex  affinitystream  locality  attribute  efficient  execution  plan,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4083,use  new  dofn  directly  flink  runner  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4084,make  apisurfacetest  detect  java  packagemodule  test  apisurfacetest  sdksjavacore  class  responsible  protecting  public  api  surface  test  walk  public  signature  module  explicitly  verifies  everything  whitelist  control  dependency  expose  user  beam  keep  tight  stable  api  surface  today  must  indicate  java  package  scan  orgapachebeamsdk  would  nice  automatically  determined,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4085,add  ability  writesink  result  mongodbgridfs  03  added  ability  read  file  gridfs  processing  would  good  sink  side  working  allow  writing  result  well,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4086,proxymanager  enhancement  brett  pointed  defaultproxymanager  need  refactoring  especially  point  remove  cache  period  get  ignores  return  getremotefile  make  proxy  check  checksum  metadata  file  first  parsing  path  artifact  getartifactfile  use  artifactsetfile  return  file  anymore  temp  setup  deleteonexit  rename  copytemptotarget  movetemptotarget  rename  preparerelease  checksum  preparerelease  checksumlisteners  use  fileutilsread  applicable,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4087,search  usability  taken  bretts  email  list  noformat  improve  search  result  page  remove  metadata  file  merge  version  search  result  snapshot  show  snapshot  timestamps  show  hit  result  may  possible  needed  better  result  however  existing  jira  complaint  mrm732  tokenizing  mrm495  weighting  mrm609  window  bug  may  fixed  mrm933  hit  count  pagination  completely  busted  advanced  search  improve  appearance  flexibility  maybe  change  add  term  button  default  search  classpackage  search  still  flaky  might  analyzer  rule  etc  splitting  browse  improvement  artifact  version  list  show  basic  shared  project  information  rather  drill  one  version  snapshot  go  page  show  list  version  go  latest  list  previous  snapshot  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4088,proxyconfiguration  enhancement  according  brett  need  improvement  make  repocache  member  proxymanager  remove  artifactrepositoryfactory  browsable  configuration  webapp  remove  field  storage  layout  use  plexus  lookup  valid  value  loadmavenproxyconfiguration  separate  reader  class,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4089,use  cachefailure  configuration  remote  repository  currently  todo  source  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4090,option  force  scanning  artifactrepository  regardless  file  date  often  try  browse  artifact  see  unable  find  project  model  even  though  know  artifact  repository  default  archiva  scan  repo  see  file  added  since  last  time  scan  run  currently  way  know  reset  touch  file  disk  appear  newer  delete  database  archiva  start  scanning  neither  ideal  need  way  force  scanning  artifact  entire  repository  regardless  file  date  last  scanned  date  repository  page  configurable  would  allow  set  date  far  back  time  file  would  appear  new  would  scan  everything  way  give  groupid  groupidartifactid  go  fix  database  subset  repo  content,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4091,remove  unnecessary  mavenproxy  class  remoteproxy  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4092,log  configuration  repository  change  made  log  change  made  configuration  repository  added  logging  following  operation  purge  artifact  removed  repository  scanning  configuration  database  scanning  configuration  add  edit  delete  managed  remote  repository  add  delete  repository  group  including  add  delete  repository  group  change  logged  archivaauditlog,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
4093,add  r  view  repository  manager  possibly  need  new  component  jira  item  could  r  particular  search  preset  latest  added  artifact  preset  new  version  artifact  preset  new  artifact  given  sync  partner,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4094,reduce  memory  used  indexing  process  archivaindexertask  scheduling  task  use  quite  bit  memory  per  file  particularly  name  also  field  unused,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4095,introduce  metadata  content  repository  api  see  mrm1025  justification,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4096,migrate  archivas  browse  functionality  use  metadata  content  repository  api  first  step  removing  direct  interaction  database  see  mrm1025  information  test  apis  implementation  utilise  directly  webapp  action  class  without  introducing  additional  business  logic  comfortably  use  way  xmlrpc  module  however  also  want  presentationrelated  logic  least  organisation  information  screen  repository  implementation  needed  simpler  replacement  abstraction  repositorybrowsing  may  appropriate,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4097,remove  dependencygraph  favour  mavendependencytree  library  dependency  graph  module  used  render  dependency  tree  artifact  information  page  currently  reproduces  lot  maven  functionality  heavily  tied  archivarepositorylayer  archivamodel  instead  use  standard  maven  library  handling  maven  dependency  tree  later  encounter  different  type  tree  provide  alternative  implementation  unlikely  something  generic  needed  though  code  still  revisited  svn  case  arises,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
4098,migrate  repository  statistic  metadata  content  repository  currently  every  scan  repository  statistic  persisted  database  could  easily  stored  metadata  repository  present  keep  perscan  approach  future  might  better  represented  regularly  stored  snapshot  built  versioning  metadata  could  potentially  adding  information  fly  instead  scan  adding  callback  repository  api  artifact  project  created  however  approached  later  migrating  functionality  offered  standalone  plugin  dependency  webapp  need  render  information  trigger  cleanup  following  change  needed  save  statistic  archivarepositoryscanningtaskexecutor  archivarepositoryscanningtaskexecutortest  reset  statistic  editmanagedrepositoryaction  editmanagedrepositoryactiontest  location  change  query  prior  successful  scan  repositoryarchivataskscheduler  retrieve  last  scan  info  repositoryaction  update  corresponding  jsp  display  information  correctly  generate  report  action  query  scan  statistic  given  date  aggregate,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
4099,improve  search  result  page  currently  search  result  plain  provide  information  artifact  provide  information  relevance  result  provide  information  search  hit  occurred  field  paginate  result,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4100,complete  artifact  browsing  currently  feature  artifact  display  page  implemented  link  dependency  displaying  information  pom,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4101,implement  alternative  improve  repository  metadata  storage  biggest  thing  look  metadatarepositoryfile  threw  together  property  file  quickly  there  optimisation  even  exception  handling  need  look  right  way  approach  robust  implementation  file  system  store  property  xml  definitely  workable  would  need  combined  something  like  lucene  index  archiva  09  make  operation  fast  enough  would  like  look  instead  using  jcr  file  system  persistence  database  see  well  reacts  lot  operation  tell  doc  storage  tailored  living  hierarchical  content  repository  whatever  form  take  storage  isolated  behind  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4102,improve  performance  browse  interface  currently  browser  read  entire  index  able  present  page  able  read  term  information  cached,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4103,add  simple  crud  page  projectlevel  metadata  along  generic  metadata  plugin  see  detail  httpmailarchivesapacheorgmodmboxarchivadev201003mbox3c70ca8566051f4cdaa09d622641ad8548apacheorg3e,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
4104,add  user  management  basic  security  issue  need  ability  create  manage  user  group  log  restrict  access  administration  interface  operation  may  add  need  security  later,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4105,complete  proxy  interface  current  proxy  interface  well  integrated  test  failing  complete  integration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4106,generic  metadata  searcheable  archiva  search  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4107,web  service  repository  merging  artifact  promotion  think  crud  managed  repository  prerequisite,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4108,remove  use  plexusspring  remove  use  plexus  annotation  inject  annotation  dont  use  anymore  plexusspring  done  redback,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
4109,expose  archiva  service  trough  rest  0,1,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0
4110,search  artifact  osgi  metadata  field  ability  search  osgi  metadata  symbolicname  version  exportpackages  see  improvmenents  mavenindexer  mindexer36  need  update  mavenindexer,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
4111,add  new  module  repository  administration  management  currently  part  logic  regarding  repository  administration  done  webapp  part  duplicate  xmlrpc  adding  rest  service  order  avoid  duplication  logic  moved  new  module  archivarepositoryadmin,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
4112,downloading  optionnaly  remote  index  display  remote  artifact  search  result  managed  repo  remote  repos  artifact  available  display  search  result  configure  optionnel  remote  index  url  running  download  configurable  schedule,1,0,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0
4113,configure  http  connection  pool  value  wagon  http  setup  resource  maxtotal  maxperroute,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4114,used  maven1  proxy  archiva  handle  relocation  maven2  pom  maven1  client  asks  servletapijarsservletapi24jar  archiva  convert  path  maven2  location  artifact  maven1  relocation  support  jar  required  repo  archiva  proxy  download  artifact  pom  read  relocation  info  return  relocated  jar  attached  patch  add  new  applyrelocation  defaultproxymanager  ive  tried  code  servletapi  example  may  bad  designed  discovered  maven  archiva  apis,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4115,add  rest  method  delete  artifact  rest  call  delete  artifact  repository,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
4116,ability  multiple  report  currently  report  aggregated  one  representation  execution  possible  separate  group  health  one  tied  indexing  others  run  demand,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
4117,download  artifact  coming  search  result  search  based  maven  index  user  result  artifact  going  artifact  info  display  empty  result  must  download  artifact,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
4118,allow  different  implementation  transfer  mechanism  defaultrepositoryproxyconnectors  class  would  like  use  different  implementation  transferring  artifact  remote  proxy  particular  remote  proxy  maven  repository  transport  library  handle  bridging  work  would  like  use  instead  default  implementation  using  wagon  could  make  change  defaultrepositoryproxyconnectors  extendable  would  want  override  transport  method  us  wagon  please  take  look  submitted  patch  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4119,ldap  configuration  editable  ui  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4120,chaining  user  manager  implementation  would  really  helpful  chain  authentication  module  first  one  fails  second  one  queried  main  usecase  one  ldap  user  auth  configured  typical  corporate  environment  also  need  technical  user  like  jenkins  instance  corporate  ldap  side  benefit  one  hardcode  backupadministrator  used  one  accidentally  break  ldap  configuration  ldap  isnt  available,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4121,path  merged  index  group  configurable  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4122,build  merged  index  group  cron  schedule  current  merged  index  group  generated  fly  caching  avoid  generation  request  add  cron  schedule  generate,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4123,add  remote  repository  health  check  cron  based  check  remote  repository  cron  value  per  remote  option  disable  repository  next  check  send  email  user  admin  role,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4124,repogroup  merged  index  ttl  configurable  per  repository  group  currently  ttl  system  property  value  must  configurable  per  repository  group,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4125,provide  mechanism  obtain  latest  version  artifact  useful  convenient  user  able  download  latest  version  artifact  sonatype  nexus  provides  mechanism  please  see  httpstackoverflowcomquestions7911620usingthenexusrestapitogetlatestartifactversionforgivengroupidartfic  httpsmavenjavanetnexuscoredocumentationplugincoredocsrestartifactmavenredirecthtml  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4126,add  xmlrpc  search  0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4127,upload  deploy  artifact  repository  via  web  form  using  wagon  web  interface  allow  upload  artifact  repository  m1  one  could  ftp  artifact  neededm  m2  go  filedeploy  plugin  pain  archiva  could  help  lot,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4128,update  archiva  latest  plexus  appserver  container  etc  attached  patch  update  plexusappserver  related  dependency  tested  working  archivaplexusruntime  also  altered  context  path  archivaplexusapplication  archiva  inline  continuum,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4129,repository  purge  feature  snapshot  need  way  purge  repository  snapshot  older  certain  date  optionally  retaining  recent  one  fixing  metadata,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1
4130,caching  repository  query  interface  need  able  query  repository  see  artifact  exist  version  available  etc  need  interoperate  indexing  applicable  cache  information  balancing  need  keep  low  memory  overhead  avoid  repetitive  disk  read  metadata  file,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1
4131,create  missing  test  repository  purge  comment  mrm294  general  thought  later  might  worth  reviewing  exception  occur  purge  see  recover  better  rather  bubbling  test  think  remove  many  component  test  xml  file  default  suffice  keep  registry  jdo  factory  test  lot  bolierplate  probably  turned  method  generate  test  data  missing  test  test  consumer  released  snapshot  purge  day  old  test  testing  file  age  also  test  metadatadriven  snapshot  general  thought  archiva  long  term  setting  database  test  probably  pain  stub  implementation  indexer  daos  avoid,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4132,justintime  consumption  repository  change  need  simple  reusable  way  able  trigger  consumer  given  artifact  justintime  thing  like  addition  via  proxy  removal  via  purge  etc,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4133,proxy  work  transparently  either  maven  1x  2x  repository  mavenproxy  act  either  maven  1x  maven  2x  repository  depending  client  access  brett  believed  managable  aliasing  originally  posted  mavenproxy  feature  httpjiracodehausorgbrowsemavenproxy39,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4134,add  minimal  hook  legacypathparser  allow  exception  management  artifact  resolution  existing  artifact  available  maven1  jaxen10fcsfull  example  use  core  maven1  plugins  obtained  specifying  classifier  full  maven1  request  jaxenjarsjaxen10fcsfulljar  converted  artifact  jaxen  jaxen  10fcsfull  doesnt  exist  legacypathparser  allready  complex  work  many  artifact  cannot  handle  classifier  string  solution  help  archiva  manager  use  resolution  exception  list  exceptionscontains  path  string  exception  exceptionsgetproperty  path  string  ref  exceptionsplit  artifactsetgroupid  ref0  artifactsetartifactid  ref1  artifactsetversion  ref2  reflength  3  artifactsetclassifier  ref3  return  artifact  based  simple  property  file  jaxenjarsjaxen10fcsfulljar  jaxenjaxen10fcsfull  would  allow  admins  quickly  fix  issue  require  archiva  find  way  make  legacy  path  deterministic,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
4135,validator  report  artifact  place  report  artifact  place  tell  m2  pom  packaged  artifact  metainfmavenpomxml  information  ass  weather  artifact  right  location  happen  tool  used  deploy  would  good  check,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
4136,virtual  repository  repository  grouping  number  managed  repository  grouped  together  group  one  url  need  specify  url  settingsxml  file  archiva  receives  request  via  url  would  look  artifact  repository  belonging  group  detail  dicussed  httpwwwnabblecomarchiva11roadmaptd15262645htmla15263879,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4137,improve  r  feed  generation  add  check  control  file  size  generated  r  feed  make  sure  client  request  r  get  right  header  try  update  hasnt  changed  performance  get  url  feed  r  feed  request  info  httpwwwnabblecomre3asvncommit3ar645833inarchivatrunk3aarchivajettysrcmainconfjettyxmlarchivamodulesarchivawebarchivarsssrcmainjavaorgapachearchivarssprocessornewartifactsrssfeedprocessorjavatd16562163html,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
4138,support  inclusion  pom  file  deploying  artifact  via  web  upload  form  currently  web  upload  form  support  pom  generation  uploading  m2  artifact,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4139,removal  archivawebdav  implementation  favor  jackrabbitwebdav  patch  remove  plexuswebdav  favor  jackrabbit  webdav  servlet  implementation  yet  100  completed  tested  http  get  put  work  correctly  following  need  happen  integration  1  new  jackrabbit  class  need  correctly  unit  tested  2  webdav  property  need  implemented  3  testing  common  webdav  client  mac  o  x  window  wagondav  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4140,aggregate  index  repository  group  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4141,replace  company  pom  feature  simple  appearence  customisation  see  httpwwwnabblecommrm604companypomforappearancetd17395296html  feature  replaced  simple  form  allows  set  organisation  image  url  name,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4142,deploying  artifact  repo  added  index  instantly  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4143,searching  within  search  result  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4144,remove  versionedreferenceprojectreferenceartifactreference  repositoryproxyconnectors  remove  versionedreferenceprojectreferenceartifactreference  repositoryproxyconnectors  converting  request  path  versionedreferenceprojectreferenceartifactreference  always  100  correct,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4145,create  second  index  subset  information  compressed  required  eclipse  plugin  need  follow  jason  exactly  data  required,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4146,ability  delete  artifact  web  interface  sometimes  viewing  artifact  archiva  web  ui  id  like  delete  repository  currently  way  deleting  managed  repository  filesystem,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4147,allow  plugins  handle  deletion  artifact  repository  purge  currently  repository  purge  directly  call  database  index  cleanup  purging  artifact  couple  core  consumer  module  also  prevents  plugins  wish  store  artifact  metadata  note  also  issue  cleanup  released  snapshot  doesnt  cleanup  fixed  moving  deletion  logic  respective  module  using  event  purge  trigger  call,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4148,patch  several  issue  processing  pom  effective  model  expression  resolving  storing  database  im  submitting  bigger  patch  serveral  issue  drived  crazy  installation  archiva  company  patch  111  112  release  patch  fix  problem  expression  resolving  pomversion  dependency  add  support  parentgroupid  artifactid  version  property  fix  issue  jdo  detachcopy  called  projectmodeltodatabaselistener  creating  effective  pom  fix  inconsistency  key  format  used  effective  model  cache  add  merging  parentproject  property  creating  effective  pom  archivaprojectmodelsetorginfilesystem  moved  reader  imo  add  new  test  case  happy  apply  patch  code  base  save  bit  work  merging  change  new  release  future,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4149,make  membership  management  depend  principal  name  uri  principal  since  principal  name  already  unique  per  thread  slingdev  probably  right  principal  name  sufficient  find  authorizable  make  patch  thanks  fri  jun  19  2009  743  ian  boston  iebtfdcouk  wrote  wondering  curl  fmembersystemusermanageruserieb  httpadminadminlocalhost  8080systemusermanagergroupggroup1updatejson  appears  way  add  member  group  curl  fmemberieb  httpadminadminlocalhost  8080systemusermanagergroupggroup1updatejson  see  code  look  bit  odd  slightly  hard  ui  developer  work  curl  fmemberieb  httpadminadminlocalhost  8080systemusermanagergroupggroup1updatejson  would  worked  reason  missing  like  would  like  change  happy  patch  ian,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4150,remove  dependency  d  currently  jcr  install  requires  declarative  service  order  minimal  dependency  activator  combination  service  tracker  used  instead,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4151,make  script  resolution  cacheable  resourcecollector  object  need  enhanced  order  use  key  caching  script  resolution  besides  extension  selector  etc  contain  resource  type  resource  super  type,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4152,correct  resource  super  type  handling  resource  return  super  resource  type  configured  one  currenty  jcr  resource  node  implementation  lookup  resource  representing  resource  type  get  resource  super  type  doesnt  super  type  set  logic  solely  called  script  resolver  tied  resource  implementation  respect  bundle  resource  return  slingbundleresource  super  type  null,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
4153,replace  mimetypeservice  commonsmime  slingservletcontext  registered  service  commonsmime  project  mimetypeservice  introduced  able  provide  mime  type  mapping  content  loader  former  slingcontentjcr  bundle  servletcontext  access  mime  type  mapping  available  extensibility  reached  defining  mimetypeprovider  service  might  implemented  bundle  enhance  mime  type  mapping  mimetypeservice  new  sling  api  defined  new  servletresolver  interface  real  sling  resolve  resource  type  servlets  registered  osgi  service  servlets  initialized  servletconfig  servletcontext  want  provide  servletresolver  implementation  outside  core  project  strive  way  provide  servletcontext  main  sling  servlet  servletresolver  propose  main  sling  servlet  slingmainservlet  register  servletcontext  javaxservletservletcontext  service  would  available  intersted  party  remove  commonsmime  project  mime  type  mapping  may  used  accessing  servletcontext  service  drop  mimetyperesovler  interface  functionality  completely  extend  registered  servletcontext  service  new  mapping  servletcontext  service  managedservice  whose  configuration  able  configure  mime  type  mapping,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4154,use  smaller  orderable  task  jcrinstalls  osgi  installer  see  proposal  httpmarkmailorgmessagea6xx4dawsokl6lpx  help  improve  bundle  management  discussed  httpmarkmailorgmessageld6tkz6fdseknntx,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,0
4155,recompile  jsps  modification  avoid  periodic  check  currently  jsp  script  handler  check  jsp  modification  jsp  called  check  configurable  time  intervall  latest  change  resource  event  therefore  could  recheck  jsps  event  avoid  per  request  check  completly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4156,use  common  dynamic  class  loader  jsp  scripting  use  new  common  class  loader  instead  dynamic  import  package  using  repository  class  loader,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4157,use  new  common  dynamic  class  loader  instead  dynamic  import  package  new  common  dynamic  class  loader  provides  robust  way  dynamic  class  loading  relying  dynamic  import  package,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4158,ensure  recent  commonslog  bundle  build  installed  sling  3  current  build  commonslog  require  availability  orgosgiframework  package  14  since  bundle  really  use  14  version  functionality  well  require  version  13  thus  able  deploy  recent  build  sling  3  release  based  felix  framework  104  hence  orgosgiframework  13  another  issue  registration  log  service  panel  since  version  sling  engine  bundle  installed  sling  3  202incubator  cause  classcastexception  servlet  service  registered  either  slingcoreservletname  componentname  service  property  log  bundle  web  console  plugin  provides  slingcoreservletname  property  prevent  error  property  effect  preventing  failure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4159,slingfileuploadhandler  remove  existing  node  preventing  file  upload  versioning  uploading  file  location  existing  file  slingfileuploadhandler  remove  old  node  creating  new  one  thats  sometimes  necessary  example  case  typehint  provided  upload  differs  type  existing  node  always  required  current  behaviour  prevents  u  maintaining  version  history  uploaded  resource  ill  attach  patch  sec,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4160,try  encode  map  key  value  map  implementation  current  value  map  implementation  jcrpropertymap  jrmodifiablepropertymap  try  directly  use  provided  map  key  property  name  name  contains  illegal  character  jcr  settinggetting  property  fails  therefore  encoding  used  avoid  case  well  use  iso9075  encoding  start  adding  encoding  compatible  current  implementation  add  new  use  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4161,jsonqueryservlet  return  calendar  property  format  jsonrendererservlet  jsonqueryservlet  return  calendar  property  doesnt  use  date  format  jsonrendererservlet  order  better  consistency  servlets  jsonqueryservlet  use  jsonresourcewriter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4162,replace  resourcegetrawdata  getobject  method  better  api  david  brought  issue  dev  list  1  regarding  resourcegetrawdata  method  short  david  suggests  replace  getrawdata  method  signature  closely  reflects  definition  sling  web  application  framework  jcr  general  consesus  list  getrawdata  method  badly  named  method  show  jcr  integration  yet  tie  api  much  jcr  propose  following  remove  getrawdata  getobject  method  resource  interface  add  new  interface  noderesource  objectresource  resource  backed  jcr  node  public  interface  noderesource  extends  resource  node  getnode  resource  mapped  using  jcr  ocm  example  public  interface  objectresource  extends  resource  object  getobject  way  resource  interface  completely  storageagnostic  provide  wide  range  extension  urlresource  may  backed  url  entry  osgi  bundle  1  httpwwwmailarchivecomslingdevincubatorapacheorgmsg00906html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4163,framework  update  unstable  framework  api  specifies  calling  bundleupdateinputstream  update  framework  sling  launcher  implemented  functionality  storing  frameworkjar  file  filesystem  along  slingproperties  file  creating  class  loader  jar  file  launch  framework  thus  sling  work  perfectly  added  benefit  make  sure  framework  really  isolated  environment  something  always  guaranteed  certain  servlet  container  problem  current  implementation  twofold  1  urlclassloader  load  jar  file  using  jar  url  default  us  caching  consequence  replacing  existing  jar  file  new  one  name  cause  resource  loaded  class  loader  classgetresourceasstream  classloadergetresourceasstream  actually  come  old  jar  file  instead  new  one  2  replacing  jar  file  used  class  loader  always  possible  particularly  window  system  file  still  opened  process  cannot  removed  thus  cannot  replaced  unix  system  situation  different  removing  file  really  delete  remove  directory  entry  thus  enables  create  new  file  name  problem  fixed  good  using  generational  jar  file  name  startup  jar  file  generation  checked  file  except  recent  one  removed  recent  jar  file  renamed  base  name  also  used  initial  startup  system  bundle  update  new  generation  jar  file  created  new  framework  launched  new  generation  jar  file  drawback  solution  live  update  possible  fixed  part  launcher  replaced  le  problem  servlet  container  environment  using  sling  web  app  launcher  situation  web  simply  replaced,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4164,update  script  system  jsr223  compatible  currently  sling  microsling  use  custom  scripting  framework  framework  updated  jsr223  compatible,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4165,form  based  authentication  new  bundle  provides  implementation  form  based  authentication  sling  loginlogout  servlets  orgapacheslingcommonsauth  used  authenticationhandler  use  http  basic  auth  credential  request  otherwise  use  userpwd  posted  login  form  login  form  html  generated  set  script  1  loginhtmlesp  full  login  page  includes  loginbodyhtmlesp  form  markup  2  loginbodyhtmlesp  login  form  may  useful  drawing  login  form  ajax  context  3  loginerrorhtmlesp  full  loginerror  page  4  loginerrorbodyhtmlesp  loginerror  form  login  error  ajax  context  script  included  bundleresources  libsslingservletdefault  bundle  also  couple  test  script  show  example  usage  1  logintesthtmlesp  show  logged  link  login  logout  2  logintest2htmlesp  show  script  check  permission  show  login  page  anonymous  user  doesnt  permission  see  page  example  usage  1  httphostportpathtonodeloginhtml  show  login  page  goto  httphostportpathtonode  authenticated  2  httphostportpathtonodeloginhtmlsedithtml  show  login  page  goto  httphostportpathtonodeedithtml  authenticated  3  httphostportsystemslinglogout  invalidate  session  switch  back  anonymous  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4166,display  mime  type  tree  table  list  mime  type  rather  big  displaying  single  table  get  quite  confusing  since  mime  type  hierarchic  nature  displaying  tree  table  two  level  enhances  display  dramatically,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4167,script  resolution  consider  partial  selector  string  currently  sling  defaultslingscriptresolver  class  considers  full  selector  string  one  available  finding  script  actually  gradually  cut  element  selector  string  script  found  complete  selector  string  cut,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,0,1
4168,provide  resourceresolver  mapping  information  configurationprinter  currently  resource  resolver  mapping  configuraiton  available  jcr  resource  resolver  page  would  helpful  support  purpose  information  available  part  configuration  status,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4169,add  structure  slingrequestprogresstracker  message  slingrequestprogresstracker  message  contain  useful  timing  information  structuring  bit  would  allow  parsing  generate  representation  here  example  current  info  httplocalhost8888systemconsolerequests  0  20091007  111030  starting  request  processing  0  20091007  111030  methodget  pathinfoindexhtml  0  20091007  111030  starting  resourceresolution  6  20091007  111030  uriindexhtml  resolve  resourcejcrnoderesource  typentfile  supertypenull  pathindexhtml  elapsed  6ms  6  20091007  111030  resource  path  info  slingrequestpathinfo  pathindexhtml  selectorstringnull  extensionnull  suffixnull  6  20091007  111030  starting  servletresolution  6  20091007  111030  starting  resolveservletjcrnoderesource  typentfile  supertypenull  pathindexhtml  6  20091007  111030  using  servlet  orgapacheslingservletsgetdefaultgetservlet  elapsed  0ms  6  20091007  111030  uriindexhtml  handled  servletorgapacheslingservletsgetdefaultgetservlet  elapsed  0ms  6  20091007  111030  applying  request  filter  6  20091007  111030  calling  filter  orgapacheslingengineimpldebugrequestprogresstrackerlogfilter  6  20091007  111030  starting  orgapacheslingservletsgetdefaultgetservlet0  6  20091007  111030  using  orgapacheslingservletsgetimplhelpersstreamrendererservlet  render  extensionnull  7  20091007  111030  orgapacheslingservletsgetdefaultgetservlet0  elapsed  1ms  7  20091007  111030  request  processing  end  elapsed  7ms,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4170,add  resource  node  mapped  object  defined  object  slingdefineobjects  tag  slingdefineobjects  tag  defines  number  object  variable  jsp  eg  slinghttpservletrequest  resource  would  practical  node  mapped  object  resource  resource  implement  nodeprovider  objectprovider  interface  resp  would  also  defined,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4171,add  logout  method  authenticator  sling  engine  204  authenticator  interface  introduced  support  generic  way  user  authenticated  allows  authentication  agnostic  way  force  user  login  drawback  current  solution  neither  authentication  handler  authenticator  interface  provide  api  logout  user  fixed  follows  add  authenticatorlogout  method  log  user  similar  way  login  method  log  user  add  new  authenticationhandler2  interface  extending  authenticationhandler  interface  providing  dropauthentication  method  mirror  authenticationhandlerrequestauthentication  method  add  logoutservlet  calling  authenticatorlogout  similar  manner  loginservlet  call  login  method  authentication  handler  supporting  logging  implement  authenticationhandler2  interface  still  registering  plain  authenticationhandler  authenticator  implementation  sling  engine  bundle  identifies  authentication  handler  correctly  call  call  dropauthentication  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4172,resourceproviderentry  us  iterators  rather  map  becomes  expensive  apps  many  servlets  resourceproviderentry  us  iterators  many  servlets  probably  ok  resource  resolution  come  servlet  resolution  many  tested  expensive  especially  many  servlets  imho  class  refactored  use  tree  map  discussed  list  intention  create  contrib  version  explore  wanting  impact  active  version  trunk,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4173,provide  helper  class  simpler  unit  testing  sling  code  writing  unit  test  bit  integration  sling  often  need  following  jcr  repository  registered  node  type  jcrbased  resource  resolver  adapter  manager  support  adaptto  method  code  cover  done  run  unit  test  service  without  osgi  container  running  written  helper  class  product  would  like  contribute  sling  especially  write  unit  test  sling1131  patch  follow,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4174,allow  uploading  json  file  create  content  structure  currently  uploading  json  file  create  file  node  hand  would  useful  uploading  node  request  extension  json  json  would  unpacked  handled  would  modification  request  json  data  content  store  would  similar  json  upload  supported  couchdb,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4175,add  support  set  resource  login  requested  currently  slingauthenticator  us  httpservletrequestgetpathinfo  method  select  applicable  authentication  handler  situation  notably  login  servlet  script  eg  sling  engine  loginservlet  registered  systemslinglogin  incorrect  path  info  path  login  servlet  desired  actual  resource  path  fix  login  servlets  able  convey  path  behalf  login  effected  since  engine  loginservlet  already  support  resource  request  parameter  convey  authentication  handler  go  successful  login  use  request  attribute  name  indicate  situation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4176,extend  resource  interface  provide  abstractresource  base  class  currently  resource  interface  bare  bone  api  access  local  attribute  like  getpath  getresourcetype  accessing  resource  context  parent  child  currently  possible  requires  getting  resource  resolver  resource  asking  resource  resolver  convenience  add  following  method  getparent  return  parent  resource  resourceutilgetparentthis  getname  return  name  resource  resourceutilgetnamethis  listchildren  getresourceresolverlistchildrenthis  getchildstring  getresourceresolvergetresourcethis  path  isresourcetypestring  resourceutilisathis  string  new  abstractresource  class  implement  method  indicated  implementors  resource  interface  advised  actually  extend  abstractresource  interface  future  provide  default  implementation  method  added  resource  interface  make  sense,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4177,move  nodetype  management  jcrcontenthelper  slingcontentjcr  abstractslingrepository  slingjackrabbitapi  currently  slingcontentjcr  bundle  contentmanagerfactory  implementation  jcrcontenthelper  used  access  sling  contentmanager  instance  listens  bundle  registered  register  node  type  registered  bundle  load  initial  content  stored  bundle  additionally  class  care  setup  sling  contentmanager  instance  used  access  ocm  functionality  working  slingevent  bundle  discovered  race  condition  node  type  registration  repository  use  overcome  race  condition  propose  move  node  type  registration  part  contentmanagerfactory  implementation  abstractslingrepository  class  slingjackrabbitapi  bundle  class  base  class  service  registered  provide  repository  class  contact  repository  service  registered  made  available  user  repository  background  information  race  condition  jcrcontenthelper  implemented  osgi  component  requires  repository  activated  repository  available  abstractrepositoryeventhandler  slingevent  bundle  also  requires  repository  also  implemented  osgi  component  component  waiting  repository  become  available  abstractrepositoryeventhandler  may  activated  jcrcontenthelper  activated  therefore  node  type  required  abstractrepositoryeventhandler  available  yet  jcrcontenthandler  able  yet  register,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4178,use  tagsoup  html  parser  instead  nekohtml  currently  use  nekohtml  parser  buggy  b  large  tagsoup  parser  httphomeccilorgcowanxmltagsoup  small  seems  work  perfectly  tika  using  well  instead  nekohtml,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4179,add  mechanism  access  resource  place  repository  sometimes  resource  accessed  located  jcr  repository  example  resource  script  provided  bundle  executed  directly  bundle  without  copy  repository  add  support  strong  versioning  lifecylce  functionality  script  also  available  normal  bundle  code,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4180,add  branding  apache  felix  web  console  whiteboard  prototyp  branding  bundle  apache  felix  web  console  1  web  console  support  branding  published  propagate  included  base  set  bundle  1  httpssvnapacheorgreposasfslingwhiteboardfmeschbewebconsolebranding,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4181,redesign  thread  pool  management  current  thread  pool  management  drawback  api  contract  slightly  confusing  eg  create  new  configuration  could  called  new  configuration  completly  ignored  reference  counting  thread  pool  thread  pool  shutdown  bundle  shutdown  thread  pool  manageable  config  admin,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,1
4182,implement  resourceresolverfactory  concept  see  httpcwikiapacheorgslingaddresourceresolverfactoryserviceinterfacehtml,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4183,remove  direct  dependency  web  console  new  web  console  provides  way  define  plugins  without  direct  dependency  web  console,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4184,utility  bundle  version  comparison  handling  jar  file  bundle  object  sling1273  need  compare  version  launchpad  base  jar  comparison  logic  reusable  ill  create  utility  class  orgapacheslingcommonsosgi  bundle,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0
4185,rename  method  new  authenticationhandler  interface  currently  authenticationhandler  interface  defines  following  method  authenticate  extract  credential  request  requestauthentication  ask  client  credential  dropauthentication  forget  current  credential  authenticate  requestauthentication  name  historic  date  back  internal  code  time  uthenticationhandler  exist  yet  imho  name  good  since  defining  new  api  anyway  might  probaby  good  time  rename  method  extractcredentials  extract  credential  request  requestcredentials  ask  client  credential  dropcredentials  forget  current  credential  see  also  discussion  httpmarkmailorgthreadbocbtx2q5js4i2gf,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4186,add  functionality  redirect  new  request  target  successful  authentication  time  would  desirable  get  redirected  new  target  authentication  successful  sling  authenticator  extended  support  functionality,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4187,allow  bundle  contribute  value  script  binding  described  httpmarkmailorgmessagecjsjywo3rsgfujks  id  like  see  way  bundle  contribute  script  binding  value  proposed  interface  public  interface  slingscriptbindingvaluesprovider  void  addbindingsbindings  binding  binding  object  made  readonly  via  facade,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4188,add  support  login  feedback  authenticator  authentication  handler  might  situation  authenticationhandlers  actually  desiring  get  feedback  outcome  authentication  providing  authentication  credential  moment  feedback  limited  case  failed  login  slingauthenticator  call  back  authenticationhandler  request  credential  indirect  feedback  failure  case  propose  extend  feedback  transfer  follows  add  authenticationfeedbackhandler  interface  two  method  called  authentication  failed  handler  expected  send  response  since  slingauthenticator  call  requestcredentials  void  authenticationfailedhttpservletrequest  httpservletresponse  authenticationinfo  called  authentication  succeeded  handler  may  write  response  particularly  setting  cookie  like  possible  void  authenticationsucceededhttpservletrequest  httpservletresponse  authenticationinfo  add  two  method  authenticationinfo  class  pas  feedback  handler  may  called  authenticationhandler  request  feedback  authentication  void  setauthenticationfeedbackhandlerauthenticationfeedbackhandler  forward  configured  feedback  handler  ignored  none  void  authenticationfailedhttpservletrequest  httpservletresponse  forward  configured  feedback  handler  handle  redirect  request  none  void  authenticationsucceededhttpservletrequest  httpservletresponse  slingauthenticator  call  new  authenticationinfo  method  success  failure  login  default  behaviour  authenticationinfoauthenticationsucceeded  redirect  desired  target  move  slingauthenticatorhandleredirect  method  probably  new  static  method  called  authenticationinfo  class  may  also  called  implementation  authenticationfeedbackhandler,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4189,include  jackrabbit  classloader  code  adjust  sling  need  use  jackrabbit  classloader  15  starting  version  16  code  dropped  jackrabbit  therefore  longer  maintained  addition  dont  need  feature  using  source  code  could  improve  classloader  therefore  copy  code  start  modifying,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1
4190,autoreconnect  jcr  repository  found  lost  affect  jackrabbitclient  bundle  accessing  remote  repository  currently  respective  component  try  access  repository  give  fails  enhanced  retry  configurable  interval  whether  repository  available  find  repository  may  gone  try  reconnect  configurable  interval  care  must  taken  second  case  drop  close  session  still  connected  old  disappeared  repository,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4191,launchpad  plugin  able  load  additional  bundle  defs  file  0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,0,1
4192,microsling  resource  resolver  default  renderers  support  property  currently  assuming  contenttestingfoo  node  exists  text  property  requesting  contenttestingfootexttxt  extension  fails  classcastexception  resolution  rendering  chain  support  node  fairly  easy  use  jcrpropertyresource  microslingresourceresolver  find  item  property  let  default  renderers  handle  one  use  case  working  clientside  form  fill  textarea  example  value  property  based  relative  url  dont  think  need  handle  post  property  get  useful  case  testing  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4193,support  multivalue  slingalias  resolution  currently  single  slingalias  value  resource  honoured  even  though  slingalias  defined  singlevalue  multivalue  property  1  reproduce  1  create  node  node  2  set  multivalue  slingalias  property  node  value  alias1  alias2  3  browse  httplocalhost8080alias2  expected  result  resource  node  returned  actual  result  404  found  still  browsing  alias1  return  node  resource  mailing  list  discussion  httpn3nabblecommultivalueslingaliastd140425htmla140425  1  httpsvnapacheorgviewvcslingtrunkbundlesjcrresourcesrcmainresourcesslinginfnodetypesmappingcndviewmarkupl32,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4194,post  servlet  handle  typehint  reference  value  path  param  somepath  paramtypehint  reference  nodeparam  uuid  node  somepath,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4195,move  jsongroovybuilder  new  module  new  module  oasextensionsgroovy,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4196,path  based  resource  type  provider  work  ntunstructured  node  samplespathbasedrtp  module  handle  ntunstructured  node  would  useful  optionally  support  node  type  done  extending  configuration  string  follows  content2  applies  ntunstructured  node  content  us  second  path  element  resource  type  content3ntfile  applies  ntfile  node  content  us  third  path  element  resource  type  content2nt  applies  node  match  supplied  regular  expression  parenthesis  us  second  path  element  resource  type,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4197,check  parallel  property  job  value  false  currently  parallel  property  processing  job  checked  existing  nonexisting  however  handling  little  bit  confusing  example  parallel  property  value  false  job  still  processed  parallel  check  value  false,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4198,add  component  allows  bundle  configure  session  returned  slingrepository  discussion  httpmarkmailorgthreadumuk7beuisp6zoqs,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4199,limit  number  parallel  job  currently  job  either  processed  parallel  series  per  topic  however  parallel  processing  used  many  job  available  processed  parallel  limit  change  meaning  parallel  property  false  parallel  processing  positiv  number  n  parallel  processing  max  n  job  parallel  anything  else  parallel  processing  currently  false  parallel  processing  anything  else  parallel  processing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4200,break  scriptresolver  implementation  separate  project  sling  scriptresovler  interface  currently  implemented  slingcore  project  able  flexible  handle  script  resolution  implementation  broken  project,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4201,align  openid  authentiction  handler  new  common  auth  openid  authentication  handler  contains  much  today  common  auth  support  login  form  feedback  provisioning  refactored  make  authentication  handler  simpler  align  common  auth  functionality,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
4202,recompile  java  script  modification  avoid  periodic  check  currently  java  script  handler  check  java  file  modification  script  called  check  configurable  time  intervall  latest  change  resource  event  therefore  could  recheck  source  event  avoid  per  request  check  completly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4203,web  console  plugin  configuration  printer  scripting  core  register  web  console  plugin  display  available  script  engine  rather  configuration  printer  web  console,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4204,defaultscriptresolver  also  listen  scriptenginefactory  service  currently  defaultscriptresolver  considers  bundle  javaxscriptscriptenginefactory  spi  file  factory  might  registered  service  require  setup  would  available  using  instantiation  spi  api  therefore  defaultscriptresolver  also  consider  scriptenginefactory  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4205,add  method  slingintegrationtestclient  accept  multiple  parameter  name  currently  slingintegrationtestclientcreatenode  take  mapstringstring  cant  support  multiple  parameter  value  key  need  method  accepts  namevalue  pair  list,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4206,create  separate  project  servletresolver  currently  servletresolver  part  sling  core  project  core  project  currently  one  biggest  sling  broken  apart  one  part  broken  servletresolver  implementation,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4207,add  replaceaccesscontrolentry  method  accesscontrolutil  modifyaceservlet  defaultcontentcreator  need  merge  new  privilege  given  principal  existing  resource  acl  involves  rather  complex  logic  easy  get  wrong  sakai  3  project  found  quite  service  developer  needed  functionality  patch  move  functionality  shared  utility  method  eliminate  tempatations  copyandpaste  worse  rewrite  incorrectly  besides  consolidating  logic  removing  modifyaceservlet  defaultcontentcreator  patch  introduces  couple  change  ace  merge  conservative  sling997  broke  apart  specified  existing  aggregated  privilege  tried  recombine  possibly  new  combination  patch  instead  maintains  exactly  client  specified  possible  already  create  new  aggregate  better  match  jackrabbit  default  behavior  minimize  client  surprise  eliminates  subtle  bug  candidate  aggregate  privilege  need  checked  isabstract  modifyaceservlet  javadoc  corrected  expanded  bad  logging  format  fixed,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4208,remove  dependency  jcr  common  auth  module  independent  functionality  wrt  jcr  therefore  make  work  without  jcr  sling1262  implemented  use  resourceresolverfactory  login  instead  going  slingrepository  addition  drop  setter  getter  method  credential  authenticationinfo  keep  constant  though  drop  setter  getter  method  workspace  authenticationinfo  keep  constant  make  import  jcr  package  optional  required  compatibility  support  old  engine  package  someone  want  use  support  hell  need  jcr  api  anyway,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4209,compact  syntax  esp  expression  html  attribute  current  syntax  esp  expression  value  parallel  jsp  syntax  hard  read  used  html  attribute  hreflink  name  propose  syntax  addition  allows  inline  esp  expression  html  compact  way  le  intrusive  xml  structure  basis  syntax  jsp  expression  language  xslt  example  would  rephrased  new  syntax  hreflinkname,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4210,move  threadpool  interface  impl  package  threadpool  interface  intendet  used  client  internal  marker  interface  move  impl  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4211,multipart  parameter  support  multipart  parameter  support  missing  attached  patch  enable  multipart  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4212,add  start  stop  goal  mavenlaunchpadplugin  0,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
4213,script  resolved  current  workspace  currently  nondefault  workspace  specified  authenticationinfo  script  still  resolved  default  workspace  script  resolved  first  workspace  used  request  ie  authenticationinfo  default  workspace  backup,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4214,support  resource  path  containing  workspace  name  via  configuration  itd  nice  able  specify  multiple  workspace,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4215,clean  compiler  api  use  classloading  infrastructure  current  interface  common  compiler  unnecessary  complicated  use  feature  common  classloading  infrastructure  remove  compilerenvironment  interface  handled  internally  remove  classwriter  interface  classloaderwriter  interface  common  classloader  change  option  interface  extend  map  allows  u  add  new  option  without  changing  interfacesapi  compile  unit  interface  changed  compileunit  inputstream  getsource  string  getmaintypename  simplifies  integration  rest  sling  resource  based  javacompiler  interface  take  array  compile  unit  error  handler  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4216,move  slingsettingsservice  new  setting  bundle  discussed  mailinglist  slingsettings  service  moved  api  bundle  add  interface  api  oasapiservices  package  deprecate  interface  enigne  bundle  let  extend  interface  api  let  service  impl  engine  bundle  register  interface,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
4217,provide  number  processed  request  status  monitoring  would  useful  number  total  processed  request  since  restart  jvm  possible  statistic  component  could  provide  number  manual  way  would  writing  simple  requestfilter  increment  counter  expose  object  osgi  component,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
4218,mark  conflict  package  import  bootdelegation  currently  sling  console  list  package  exported  imported  bundle  request  case  package  listed  orgosgiframeworkbootdelegation  property  wiring  actually  ignored  parent  class  loader  used  situation  might  confusing  result  may  unexpected  help  solving  possible  issue  problem  wired  import  match  entry  bootdelegation  property  marked  indicate  respective  package  loaded  parent  class  loader  wired  import,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4219,common  log  export  osgi  configuration  admin  package  dynamic  dependency  currently  common  log  module  export  osgi  configuration  admin  package  able  register  managedservicefactory  service  probably  bad  style  done  log  mechanism  configurable  soon  configuration  admin  service  registered  better  solution  problem  though  osgi  configuration  admin  package  imported  using  dynamicimportpackage  allows  dynamic  wiring  api  used  managedservicefactory  service  registered  servicefactory  service  mean  actual  configuration  admin  api  managedservicefactory  interface  configurationexception  need  wired  service  actually  accessed  turn  case  configurationadmin  service  registered  start  working  thus  solve  exact  problem  common  log  active  configuration  admin  configurable  soon  configurationadmin  service  active,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4220,create  sling  launchpad  based  microslingcore  code  following  rt  shall  merge  microsling  sling  1  µsling  20  requirement  2  thread  slingdev  need  merge  microsling  sling  requirement  discussed  2  taking  account  felixs  comment  webdav  michael  comment  switching  jcr  repository  µsling  20  preconfigured  instance  sling  meant  allow  web  developer  test  drive  sling  building  scripted  web  rest  application  backed  jcr  repository  µsling  20  distribution  requires  java  5  vm  run  installation  needed  fifteen  minute  enough  start  µsling  understand  basic  concept  based  selfguiding  example  µsling  ideally  delivered  single  runnable  jar  file  java  programming  required  build  web  rest  application  µsling  20  serverside  clientside  javascript  code  presentation  template  used  process  http  request  scripting  templating  language  jsp  bsfsupported  one  plugged  easily  µjax  application  protocol  clientside  javascript  jcr  proxy  library  make  easy  write  powerful  ajaxish  jcrbased  application  µsling  20  µsling  20  built  codebase  sling  specific  configuration  sling  µsling  20  feature  available  sling  application  long  enabled  sling  configuration  sling  µsling  run  core  code  us  osgi  modularize  framework  µsling  require  osgi  skill  make  osgi  largely  invisible  beginner  sling  feature  module  also  activated  µsling  20  instance  installing  activating  required  osgi  bundle  µsling  20  pass  integration  test  existing  microsling  test  suite  svn  revision  605206  minor  adaptation  needed  µsling  20  includes  webdav  server  module  make  easy  copy  script  jcr  repository  1  httpmarkmailorgmessage2s7agnu5kklti6da  2  httpmarkmailorgmessageatbjzjjp2wflkotb,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4221,update  jcr  2  api  jcr  api  deprecated  jcr  20  change  call  deprecated  stuff,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4222,allow  subclass  jsonqueryservlet  modify  statement  query  type  would  useful  jsonqueryservlet  enables  subclass  override  statement  andor  query  type,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4223,enable  pluggable  node  name  generation  bundle  able  implement  nodenamegenerator  interface  customize  node  name  generation  logic,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4224,add  package  dep  info  console  would  helpful  bundle  installed  bundle  list  could  show  list  imported  package  maybe  mark  red  cannot  resolved,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4225,expose  scriptenginemanager  managed  sling  id  like  add  new  service  interface  called  scriptenginemanagerfactory  scriptingapi  slingscriptadapterfactory  implement  allow  infrastucture  bundle  use  javaxscript  engine,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
4226,remove  dependency  sling  jcr  api  currently  servlet  resolver  depends  sling  jcr  api  new  resourceresolverfactory  sling  api  directly  use  remove  dependency  sling  jcr  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4227,decouple  assertjavascript  httptestbase  assertjavascript  method  httptestbase  extracted  separate  class  make  reusable  independently,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4228,upgrade  gwt  extension  203  current  gwt  contrib  module  use  1460  pretty  old,0,1,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0
4229,contentloader  overwrite  file  content  file  node  file  node  created  contentloader  underlying  jcrcontent  node  removed  recreated  problem  ntresource  referenceable  deleted  recreated  new  uuid  defined  instead  modify  property  jcrcontent  node  keep  uuid,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4230,switch  slingauthenticator  use  resourceresolverfactory  api  rather  jcr  directory  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
4231,allow  access  node  property  method  scriptablenode  scriptableproperty  would  like  propose  access  jcr  node  method  scriptablenode  access  jcr  property  recently  wanted  access  propertygetlength  method  esp  script  didnt  find  good  way  starting  convenient  scriptablenode  discussion  already  talk  similar  issue  httpwwwmailarchivecomslingdevincubatorapacheorgmsg01481html  ideally  somthing  like  automatic  getter  mapping  know  earlier  rhino  project  would  mean  could  access  information  example  proplength  propgetlength  think  would  great  jcr  property  node  method  would  exposed  otherwise  hiding  jcr  feature  script  user  think  maybe  solution  also  requires  scriptableproperty  wdyt,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4232,usermanager  permission  manipulation  service  api  would  nice  jackrabbitusermanager  bundle  exposed  osgi  service  map  exactly  functionality  rest  service  one  use  feature  also  programmatic  way  useful  application  manage  user  group  without  explicit  request  object  ex  eventlistener  case  user  manipulate  account  case  doesnt  administrative  account  request  permitted  modify  user  also  think  certain  situation  could  cleaner  simpler  write  servlet  script  directly  invoke  method  instead  find  way  invoke  rest  service  think  simple  exaustive  way  achieve  direct  mapping  rest  service  described  httpslingapacheorgsitemanagingusersandgroupsjackrabbitusermanagerhtml  httpslingapacheorgsitemanagingpermissionsjackrabbitaccessmanagerhtml  using  wellknown  jcr  class  example  obtaining  user  list  could  simple  getting  usermanager  osgi  service  invoking  method  like  public  nodeiterator  listusers  changing  permission  could  achieved  getting  accessmanager  osgi  service  invoking  method  like  public  void  modifypermissionstring  nodepath  string  principalid  string  privilegename  string  privilegevalue  string  order  perhaps  best  way  standardize  service  dedicated  api  formalizes  underlying  concept  ex  user  group  privilege  nodeaccesscontrol  think  case  could  propose  think  simple  rest  service  mapping  could  already  nice  readytogo  feature  developer,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4233,allow  form  authentication  handler  include  login  form  servlet  resource  rather  redirect  intended  option  default  redirect,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4234,formauth  bundle  export  formreason  class  without  exporting  formreason  class  bundle  cannot  properly  interpret  value  jreason  parameter,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4235,osgi  event  contain  userid  possible  building  system  track  user  movement  system  one  thing  tracking  osgi  event  emitted  sling  dont  contain  userid  however  since  hapens  jcrresourcelistener  jcr  observation  listener  getting  userid  fairly  straightforward  ill  attach  patch  includes  functionality  afaict  location  emits  user  generated  event  missed  spot  id  happy  try  patch  one  well,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4236,support  loading  initial  configuration  configadmin  would  nice  support  initial  configuration  like  initial  bundle  think  apply  logic  installupdate  like  bundle  support  cfg  file  location  bundle,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4237,slingservlet  service  sling550  need  call  slingmainservlet  outside  web  container  requestresponse  cycle  ill  attach  patch  introduces  new  slingservlet  interface  slingmainservlet  implement,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
4238,create  servlet  get  effective  access  control  list  pathacljson  return  declared  acl  patheacljson  return  effective  acl,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1
4239,jsonqueryservlet  support  tidy  selector  provide  pretty  printed  result  sling562  provided  ability  apply  tidy  rendering  jsonrendererservlet  technique  would  useful  formatting  result  jsonqueryservlet  example  httplocalhost8888querytidyjsonquerytypexpathstatementelementntunstructured,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4240,expose  subset  authentication  info  property  resourceresolver  attribute  property  authentication  info  credential  map  provided  resoureresolverfactory  create  new  resourceresolver  exposed  resourceresolver  exception  apply  password  jcr  credential  identifiable  sensitive  information  course  exposed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4241,cleanup  authentication  info  constant  implementation  constant  defined  authenticationinfo  class  common  auth  bundle  moved  follows  user  username  resourceresolverfactory  interface  password  userpassword  resourceresolverfactory  interface  credential  userjcrcredentials  jcrresourceresolverfactory  interface  addition  support  checking  type  credential  property  removed  authenticationinfo  class  likewise  following  constant  currently  internal  jcrresourceresolverfactoryimpl  class  moved  authinfoworkspace  internaluserjcrworkspace  jcrresourceresolverfactory  interface  change  value  userjcrworkspace  removing  internal  prefix  sessionattrimpersonator  impersonator  resourceresolverfactory  interface  finally  following  constant  resourceresolverfactory  interface  changed  sudouserid  sudouserid  change  value  userimpersonation  end  use  constant  ensured  mostly  jcrresourceresolverfactoryimpl  jcrresourceresolver  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4242,support  reading  jackrabbit  configuration  file  launchpad  archive  downstream  user  sling  able  put  repositoryxml  either  launchpad  jar  war  get  work  without  additional  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4243,default  json  rendering  selectable  depth  discussed  list  1  default  json  rendering  work  follows  mynode0json  return  node  property  mynode1json  return  node  property  direct  child  node  property  mynode2json  two  level  deep  child  node  hierarchy  mynodeinfinityjson  return  entire  subtree  mynodejson  behaves  like  mynode0json  1  httpmailarchivesapacheorgmodmboxincubatorslingdev200801mbox3c227048280801090142x32b75287ifc06ca901b329ed0mailgmailcom3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4244,let  usermanager  post  servlets  return  json  sling1336  added  ability  return  json  response  slingpostservlet  usermanager  post  servlets  capability  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4245,jobstatusprovider  lazy  load  event  returning  current  implementation  job  status  provider  query  load  job  return  list  want  know  many  job  available  want  return  first  x  job  implementation  expansive  one  solution  would  return  kind  range  iterator  instead  list  load  job  demand  two  potential  problem  jcr  query  return  count  cant  return  count  either  without  going  hole  result  set  might  job  cant  loaded  missing  class  case  job  count  query  result  higher  count  job  get  processed  think  neglect,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4246,change  osgi  installer  interface  discussed  mailing  list  current  osgi  installer  three  method  registerresources  used  register  resource  installer  client  like  jcr  install  usually  invoked  startup  addresource  add  resource  runtime  removeresource  remove  resource  runtime  api  simple  fine  sufficient  however  small  glitch  client  detects  several  change  like  set  bundle  removed  updated  call  addresource  removeresource  change  separately  osgi  installer  could  run  install  cycle  inbetween  method  call  causing  part  process  done  first  cycle  part  second  cycle  osgi  dynamic  nature  isnt  problem  two  cycle  everything  installed  expected  still  feeling  would  nicer  client  could  submit  several  change  add  maybe  instead  addresource  removeresource  method  updateresources  addedresources  removedresources,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4247,move  slingadaptable  adapter  bundle  api  slingadaptable  default  implementation  adaptable  current  adapter  bundle  implementation  contains  caching  api  depend  sling  bundle  abstractresource  cant  extend  implementation  addition  one  want  use  slingadaptable  together  sling  api  need  several  bundle  clean  adding  slingadaptable  api  deprecate  slingadaptable  adapter  bundle  let  extend  api  version  make  abstractresource  extend  new  slingadaptable  move  adaptermanager  code  abstractresource  new  slingadaptable,1,1,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0
4248,register  internal  post  operation  service  consumption  servlets  slingpostservlet  discussed  1  would  useful  internal  operation  sling  post  servlet  available  service  bundle  reuse  1  httpmarkmailorgmessagea7vrtyhictf7tv4m,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4249,add  state  management  resource  currently  state  management  hard  tell  resource  installed  installed  uninstalled  etc  situation  lead  endless  loop  something  tried  although  nothing  need  done  anymore  cant  done  add  proper  state  management  resource  installer  know  need  done  act  accordingly,1,0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,1
4250,improvement  event  bundle  currently  eventing  store  event  immediately  repository  order  quickly  respond  back  event  admin  order  get  blacklisted  incoming  event  put  queue  picked  would  safer  separate  write  queue  independent  processing  queue  write  event  soon  repository  possible,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0
4251,resourceresolver  go  path  get  request  sling117  change  need  ported  sling,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4252,mavenlaunchpadplugin  add  way  transform  bundle  list  arbitrary  manner  purpose  using  instrumented  bundle  bundle  list  able  transformed  way  currently  im  thinking  groovy  script  investigate  using  actual  rule  engine  instead  example  rule  groupid  orgapachesling  version  end  snapshot  set  classifier  emma,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
4253,support  lazy  activated  bundle  installer  wait  installed  bundle  become  active  case  lazy  bundle  bundle  get  active  used  therefore  relaxchangeadapt  logic,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4254,add  support  range  request  streamrendererservlet  support  kind  streaming  support  range  http  header  built  streamrendererservlet  tomcat  defaultservlet  1  used  basis  implementation  1  httpsvnapacheorgviewvctomcattrunkjavaorgapachecatalinaservletsdefaultservletjavaviewmarkup,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4255,make  sling  post  servlet  dynamically  configurable  currently  slingpostservlet  regaular  d  10  component  stopped  restarted  updated  osgi  configuration  give  certain  amount  downtime  configuration  update  also  place  load  system  make  configuration  update  transparent  low  latency  possible  would  probably  good  support  new  d  10  functionality  dynamic  configuration  update  using  modify  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4256,custom  thread  pool  get  optional  label  custom  thread  pool  created  java  api  pool  get  uuid  name  make  later  difficult  associate  usage  therefore  additional  label  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4257,prevent  login  request  loop  depending  authenticationhandler  specific  conceivable  sling  authenticator  support  may  enter  endless  redirect  loop  client  consider  1  client  provides  wrong  credential  eg  cookie  http  basic  authentication  header  2  authenticator  decides  call  authenticationhandlerrequestcredentials  3  authentication  handler  sends  redirect  client  4  client  request  redirect  target  providing  wrong  credential  5  authenticator  decides  call  authenticationhandlerrequestcredentials  6  continue  step  3  loop  broken  authenticator  soon  authenticator  recognizes  potential  redirect  loop  authentication  handler  called  instead  immediate  error  response  sent  back,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4258,remove  direct  dependency  web  console  using  new  configuration  printer  support  latest  web  console  possible  implement  configuration  printer  web  console  use  interface  invoked  via  reflection,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0,1
4259,remove  direct  dependency  web  console  using  new  configuration  printer  support  latest  web  console  possible  implement  configuration  printer  web  console  use  interface  invoked  via  reflection,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
4260,make  slingexception  runtimeexception  derive  exception  slingexception  assuming  lazy  consensus  change  proposed  mail  thread  rethinking  exception  sling  1  change  whiteboard  2  applied  1  httpwwwmailarchivecomslingdevincubatorapacheorgmsg01520html  2  httpsvnapacheorgreposasfincubatorslingwhiteboardfmeschbeeffectiveexceptionsapi,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4261,upgrade  gwt  21  gwt  21  released  httpgooglewebtoolkitblogspotcom201010announcingfinalreleaseofgwt21html  contrib  module  upgraded,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4262,add  bolding  declared  node  type  info  following  felix2570  possible  differentiate  declared  property  child  node  definition  inherited  light  html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4263,adapt  common  log  web  console  panel  jquery  ui  functionality  web  console  plugin  common  log  bundle  still  format  output  old  ui  convert  support  webconsoles  jquery  ui  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4264,status  information  stored  outside  bundle  data  directory  currently  status  information  stored  inside  private  bundle  data  area  installer  core  bundle  fine  long  core  bundle  updated  soon  updated  data  lost  data  recalculated  information  bundle  config  installed  installer  way  lost  therefore  store  data  outside  bundle  private  data  like  config  admin,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4265,make  locking  strategy  configurable  cluster  usage  sling  eventing  currently  us  session  scoped  lock  prevent  two  cluster  node  process  job  unfortunately  jackrabbit  currently  support  session  scoped  lock  cluster  another  way  would  use  open  scoped  lock  could  implement  heartbeat  functionality  detects  cluster  node  available  anymore  node  cluster  unlocks  locked  node  unfortunately  doesnt  work  jackrabbit  either  lock  handling  implemented  strict  way  session  created  lock  unlock  session  need  lock  token  ill  create  enhancement  bug  jackrabbit  cluster  used  could  skip  locking  completly  therefore  reduce  load  repository  therefore  could  make  lock  manager  locking  mode  configuration  session  scoped  open  scoped  none  additional  note  one  want  use  jackrabbit  sling  eventing  clustered  environment  one  working  approach  disable  job  execution  single  cluster  node  done  setting  jobmanagerenabled  configuration  property  jobmanager,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4266,use  time  based  folder  structure  job  without  id  currently  job  without  job  id  stored  artifical  folder  structure  avoid  large  flat  hierarchy  folder  structure  created  randomly  generating  uuid  avoid  concurrency  problem  clustered  environment  folder  never  deleted  resulting  large  empty  folder  structure  could  use  time  based  folder  structure  instead  create  new  folder  every  minute  folder  get  empty  another  minute  started  safely  remove  folder  addition  include  sling  id  folder  name  avoid  folder  creation  problem  clustered  environment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4267,jst  script  engine  microslingcore  jst  script  engine  ported  slingscripting,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4268,make  installers  pluggable  currently  osgi  installer  support  bundle  configuration  add  service  interface  allow  installation  resource  like  deployment  package  etc,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
4269,allow  resource  transformer  processing  installable  resource  case  installable  resource  directly  installable  end  product  example  jar  dropped  installer  bundle  service  could  bundlize  jar,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0
4270,improve  internal  resource  handling  current  resource  handling  drawback  one  resource  always  copied  local  data  store  even  change  another  one  integrating  new  concept  like  resource  transformer  etc  difficult  error  prone  first  thing  change  resource  type  currently  config  bundle  assumes  client  know  resource  providing  however  task  client  decide  many  case  client  even  knowledge  therefore  introduce  two  new  resource  type  property  file  however  client  really  know  dealing  use  one  two  new  type  osgibundle  osgiconfig  introduce  new  type  compatible  old  constant  config  bundle  deprecated  alias  property  file  new  resource  provider  registering  update  resource  take  place  merging  resource  done  immediately  sync  first  general  sanity  check  incoming  data  us  url  digest  data  check  updatesremoves  resource  url  digest  already  available  assumed  processing  required  avoids  unnecessary  copy  decide  incoming  resource  type  usually  property  file  processing  resource  type  new  resource  transformer  service  responsible  transformation  maybe  combination  data  transformation  resource  transformer  omit  one  resource  resource  type  data  resource  processing  resource  type  resource  used  processed  osgi  installer  task  factory  long  resource  processing  resource  type  processed,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
4271,remove  dependency  web  console  since  version  web  console  provides  way  register  plugins  without  directly  depending  web  console  api  use  well,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4272,launchpad  installer  depend  scr  current  launchpad  installer  implementation  requires  scr  rather  implement  activator  service  listener  soon  osgi  installer  service  resource  provider  available  service  start  action,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4273,support  serverside  junit  test  injected  running  sling  instance  ive  working  prototype  junit  extension  framework  1  allows  junit  test  injected  sling  instance  executed  via  test  runner  servlet  test  yet  osgiaware  first  prototype  dynamically  injected  exported  class  bundle  point  testpackage  header  apart  100  normal  junit3  4  test  next  step  use  annotation  inject  service  test  im  thinking  something  like  testreference  slingrepository  repository  maybe  test  optionaltestrequiredservicerepository  public  void  sometest  would  ignore  test  repository  service  present  prototype  consists  two  bundle  extension  test  detection  runner  service  testbundle  provides  example  test  play  install  two  bundle  access  test  servlet  systemslingjunit  1  httpsvnapacheorgreposasfslingwhiteboardbdelacretazjunit,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4274,persist  configuration  change  made  installer  currently  config  bundle  change  done  way  installer  like  web  console  persisted  sometimes  creating  confusion  making  change  example  clustered  env  error  prone  provider  register  write  back  hook  installer  core  detects  change  invokes  correct  hook  persist  configuration,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4275,extend  resourceresolver  make  flexible  result  defining  virtual  resource  tree  sling197  need  modify  resourceresolver  api  two  respect  1  add  resourceresolverresolvestring  abspath  method  behaves  exactly  resourceresolverresolvehttpservletrequest  except  latter  method  may  make  use  additional  request  property  request  header  parameter  resolvestring  method  string  work  currently  resolvehttpservletrequest  method  nothing  use  httpservletrequestgetpathinfo  resolve  resource  thus  implementation  would  actually  equivalent  abspath  argument  absolute  path  resolution  fails  relative  path  2  support  relative  path  resourceresolvergetresourcestring  path  currently  method  defined  throw  slingexception  path  relative  changed  resourceresolver  applies  search  path  logic  find  resource  given  relative  path  search  path  logic  comparable  nix  system  use  path  environment  variable  method  may  used  multiple  user  servletscript  resolution  3  add  resourceresolvermapstring  method  method  applies  reverse  mapping  resourceresolverresolvestring  abspath  method  return  path  suitable  resolver  method  allows  creation  link  path  resource,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4276,post  servlet  patching  multivalue  property  described  sling  list  httpslingmarkmailorgthreadxxaaqowtx7jgfo3p  allow  patching  multivalue  property  new  patch  suffix  mypropertytypehintstring  mypropertypatchtrue  mypropertyvalue1  mypropertyvalue1  patch  present  property  value  request  expected  start  either  followed  actual  value  two  would  represent  operation  want  executed  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4277,last  modified  java  file  compared  compiled  class  file  modified  java  file  modified  observation  event  sent  b  observation  event  arrived  last  modified  java  file  compared  last  modified  compiled  class  available  last  modified  java  file  older  recompilation  done  creates  unexpected  result  eg  package  downgraded  older  version  java  file  installed  older  last  modified  value  new  java  file  would  still  used  last  modified  check  actually  still  avoid  recompilation  startup  distinguish  two  case  last  modified  check  startup  last  modified  check  based  observation  event,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4278,junitservlet  replaceable  junitservlet  testingjunitcore  module  replaceable  mean  factoring  actual  test  selection  listing  execution  logic  separate  service  allowing  disabling  servlet  mounting  different  path  configuration,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
4279,support  configuration  default  request  parameter  encoding  proposed  httpmarkmailorgmessagemv6jfc26x43keg6i  new  configuration  property  sling  main  servlet  introduced  overwrite  default  request  parameter  encoding  currently  request  parameter  decoded  encoding  provided  charset  request  parameter  set  request  parameter  set  provide  encoding  supported  platform  default  iso88591  applied  application  always  using  response  encoding  eg  utf8  specifiying  charset  request  parameter  tedious  would  helpful  default  parameter  could  configured  something  different  iso88591,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4280,move  property  support  class  currently  osgiutil  class  two  purpose  support  propertyconfiguration  handling  support  event  creation  embedding  class  another  bundle  bundle  requires  import  event  package  although  never  really  used  therefore  split  osgiutil  class  several  class  specific  purpose  osgiutil  implementation  call  method  new  class,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4281,support  deep  folder  structure  installation  currently  jcr  installer  installs  artifact  directly  contained  install  folder  nested  structure  beneath  folder  traversed  support  traversing  folder  structure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4282,creating  initial  configuration  use  relative  path  name  repository  configuration  home  jackrabbit  server  creates  configuration  initial  startup  none  available  configuration  admin  service  configuration  contain  absolute  path  name  repository  configuration  file  well  repository  home  directory  make  hard  relocate  sling  home  folder  configuration  still  point  old  location  instead  default  configuration  unless  overwritten  framework  property  use  relative  path  name  resolved  slinghome  repository  startedcreated,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4283,provide  sling  servlet  run  serverside  junit  test  testingjunitcore  module  currently  us  plain  servlet  run  outside  sling  request  cycle  however  test  depend  custom  sling  filter  example  need  run  sling  request  cycle  keep  junitcore  module  reusable  outside  sling  ill  implement  second  servlet  active  sling  environment  existing  plain  servlet  disabled  configuration  needed,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
4284,replace  file  logger  logback  rather  work  internally  writing  log  message  disk  internal  log  mechanism  use  logback  handle  heavy  lifting  also  add  ability  add  appenders  nifty  logback  feature,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,0
4285,add  limit  job  query  jobmanagerqueryjobs  provide  limit  reduce  load  manager  add  additional  method  limit  parameter  use  case  first  entry  interest  though  query  done  memory  moment  reduce  load  large  queue  low  limit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4286,clean  content  data  request  data  handling  contentdata  requestdata  dispose  method  actually  really  used  could  completly  remove  addition  remove  stack  contentdata  object  requestdata  handling  locally  slingrequestprocessimpldispatch  method  simplifies  data  object,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4287,upon  installation  fragment  bundle  refreshpackages  call  made  host  bundle  fragment  bundle  dont  get  started  become  attached  host  refreshpackages  must  called  host  bundle  assuming  host  bundle  started,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4288,properly  provide  locale  inheritance  support  resourcebundle  class  intended  used  inheritance  resource  parent  resource  bundle  thus  resourcebundlegetobjectstring  implemented  along  line  object  obj  handlegetobjectkey  obj  null  parent  null  obj  parentgetobjectkey  obj  null  throw  new  missingresourceexception  return  obj  jcrresourcebundlehandleobjectstring  key  method  implemented  like  object  value  get  repository  resource  return  value  null  key  value  key  returned  value  though  break  inheritance  chain  intended  resourcebundlegetobjectstring  method  fix  along  line  jcrresourcebundleprovider  provides  root  resourcebundle  implementation  follows  handleobjectstring  key  always  return  key  getlocale  return  empty  locale  getkeys  always  return  empty  enumeration  root  resourcebundle  used  parent  jcrresourcebundle  instance  locale  induced  parent  jcrresourcebundlehandlegetobjectstring  key  return  value  given  locale  way  keep  guarantee  getobjectstring  key  method  resourcebundle  provided  jcrresourcebundleprovider  never  throw  missingresourceexception,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4289,launchpad  installer  support  nested  structure  installer  support  nested  structure  return  resource  first  level,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4290,upgrade  groovy  18  groovy  18  released  upgrade,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,1
4291,preload  configured  set  resource  bundle  repository  would  convienent  able  preload  resource  bundle  repository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4292,accessmanager  permission  manipulation  service  api  would  nice  jackrabbitaccessmanager  bundle  expose  osgi  service  map  exactly  functionality  rest  service  one  use  feature  also  programmatic  way  useful  application  manage  permission  without  explicit  request  object  ex  eventlistener  case  user  manipulate  account  case  doesnt  administrative  account  request  permitted  modify  user  also  think  certain  situation  could  cleaner  simpler  write  servlet  script  directly  invoke  method  instead  find  way  invoke  rest  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4293,adding  support  call  sling  resource  jsp  page  exception  handler  page  errorpage  moment  jsp  page  exception  handler  page  errorpage  supported  jsp  engine  cant  resolve  path  jsp  repository  resource  see  also  user  mailing  list  0  detail  0  httpwwwmailarchivecomusersslingapacheorgmsg01369html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4294,add  support  partial  bundle  list  project  able  define  bundle  list  applied  unit  bundle  list  see  httpmarkmailorgmessageqvil2wqdkh26zbhs  information,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
4295,add  functionality  ignore  parameter  post  request  certain  situation  post  request  accompanied  request  parameter  ignored  currently  sling  post  servlet  two  mechanism  handle  parameter  parameter  starting  colon  ignored  eg  operation  parameter  starting  considered  least  one  parameter  format  certain  situation  parameter  might  submitted  ending  post  servlet  written  repository  example  user  try  authenticated  form  based  authentication  supplying  jusername  jpassword  parameter  sling  post  servlet  erroneously  hit  value  might  get  written  repository  add  functionality  specify  regular  expression  parameter  ignored  apart  existing  mechanism  default  would  j  ignore  parameter  starting  j  generally  used  authentication,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4296,improve  support  osgi  installer  distinguishing  bootstrap  app  bundle  currently  bundle  put  launchpad  resourcesbundles  installed  sling  launchpad  bootstrap  installer  sling  osgi  installer  make  use  provide  way  install  bootstrap  bundle  like  osgi  installer  launchpad  everything  else  handled  osgi  installer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4297,apply  validation  requested  redirects  authentication  currently  defaultauthenticationfeedbackhandlerhandleredirect  abstractauthenticationhandlersendredirect  method  apply  validity  check  requested  redirect  target  apply  check  ensure  valid  target  accessible  within  sling  application  target  valid  method  would  redirect  servlet  context  root  path  obeying  contract  redirecting  client  necessairily  desired  target  case  error  level  message  written  log  indicating  redirect  target  honoured  check  made  available  authenticationhandler  implementation  may  apply  check  redirects,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4298,ujax  post  servlet  respond  status  page  instead  default  redirect  desirable  ujax  post  serlvet  responds  status  page  rather  default  redirect  allows  client  javascriptformpost  ajax  based  react  better  modification  provide  patch  post  servlet  responds  status  page  old  redirect  behavior  still  achieved  sending  ujaxredirect  input  parameter,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0
4299,add  configurationprinter  output  repository  descriptor  itd  nice  webconsole  configurationprinter  output  repository  descriptor,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4300,remove  check  sling  engine  bundle  sling  setting  service  currently  wait  sling  engine  bundle  first  startup  compatiblity  reduce  startup  problem  remove  extra  handling  upgrade  old  engine  bundle  happening  first  updating  sling  setting  102  version  updating  110  higher  trick,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4301,support  write  back  configuration  file  installer  support  writing  back  changed  configuration,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4302,dont  copy  resource  always  available  like  file  system  resource  provided  installer  core  always  first  copied  file  system  basic  reasioning  behind  provider  like  jcr  repository  might  unavailable  installation  bundle  update  etc  avoid  unnecessary  round  trip  complicated  handling  situation  resource  made  available  case  first  copying  file  system  resource  already  file  system  loaded  class  loader  within  jar  resource  always  available  need  copying  first,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4303,leverage  framework  interface  better  control  framework  startup  startup  bootstrap  installer  may  install  update  uninstall  system  extension  fragment  require  framework  restarted  action  properly  complete  current  implementation  solves  problem  like  initialize  framework  frameworkinit  start  framework  startlevel  1  frameworkstart  call  bootstrap  installer  install  update  uninstall  check  whether  restart  required  yes  restart  otherwise  set  start  level  originally  requested  start  level  clumsy  dilutes  startup  particularly  frameworkstarted  event  fired  without  framework  startup  actually  completed  fix  solve  easily  using  framework  interface  like  framework  tmpframework  createframeworknotifiable  logger  prop  inittmpframework  new  bootstrapinstallertmpframeworkgetbundlecontext  logger  resourceproviderinstall  inittmpframework  tmpframeworkstart  thisframework  tmpframework,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4304,provide  resource  bundle  request  currently  request  served  sling  main  servlet  resource  bundle  provider  i18n  filter  called  however  request  directly  served  sling  could  still  support  i18n  define  new  interface  requestlocaleresolver  take  httpservletrequest  service  get  resource  resolver  request  attribute  see  authentication  support  httpservletrequest  method  get  resource  bundle  store  resource  bundle  request  attribute  reduce  overhead  create  bundle  request  request  attribute  queried  lazily  create  resource  bundle  requestlocaleresolver  available  precedence  localeresolver  addition  deprecate  localeresolver,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
4305,provide  way  specify  additional  bootstrap  command  currently  possible  easily  add  command  bootstrap  command  file  read  srcmainslingbootstraptxt  add  potentially  existing  bootstrap  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4306,bundle  configuration  sling  file  bundlelist  maven  launchpad  plugin  read  configuration  srcmainconfig  special  sling  configuration  file  srcmainsling  bundle  list  partial  bundle  list  used  bundle  list  would  nice  configuration  file  combined  partial  bundle  list  avoids  repeating  configuration  using  bundle  list  allows  better  separation  concern,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4307,add  servlet  container  name  version  sling  server  info  sling  expose  servletcontext  implementation  servlets  filter  deployed  sling  return  sling  specific  string  getserverinfo  method  replaces  information  returned  servlet  container  help  support  information  purpose  add  container  name  version  servlet  container  server  info  sling  server  info  example  current  sling  server  info  sample  apache  sling2xx  jdk  60  linux  32  sample  platform  server  info  jetty6  jdk  60  linux  32  info  yet  info  proposed  sling  server  info  apache  sling2xx  jetty6  jdk  60  linux  32,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4308,installer  able  update  currently  possible  update  installer  core  bundle  installer  result  deadlock,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4309,add  listener  installer  add  listener  installer  allows  keep  track  action  done  installer  first  step  could  notify  start  installation  cycle  suspension  installer  processed  resource,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4310,allow  better  configuration  sling  home  folder  currently  file  folder  slinghome  folder  freely  located  others  orgapacheslinglaunchpadbasejar  file  expected  inside  slinghome  hardcoded  slingproperties  file  expected  inside  slinghome  hardcoded  start  folder  containing  initial  bundle  install  expected  inside  slinghome  hardcoded  felix  framework  cache  location  configured  orgosgiframeworkstorage  property  location  configuration  admin  configuration  configured  felixcmdir  property  location  file  installer  osgi  install  facility  configured  slinginstallerdir  property  flexibility  two  new  property  added  slingproperties  default  slinghomeslingproperties  provides  path  name  slingproperties  file  contains  configurable  property  used  starting  sling  becoming  framework  property  accessible  bundlecontextgetpropertystring  method  property  also  available  framework  property  set  default  value  sling  launcher  already  set  property  must  contain  reference  another  property  absolute  path  resolved  slinghome  slinglaunchpad  default  slinghome  defines  location  sling  launchpad  related  file  folder  moment  location  orgapacheslinglaunchpadbasejar  library  provides  osgi  framework  startup  folder  take  bundle  install  framework  startup  property  must  contain  reference  another  property  absolute  path  resolved  slinghome  default  defined  account  backwards  compatibility  little  code  inspection  probably  following  area  updated  sling  class  must  ensure  property  value  sling  class  loadconfigproperties  method  must  modified  read  slingproperties  file  location  indicated  slingproperties  property  launcher  class  must  modified  look  place  launcher  jar  slinglaunchpad  folder  instead  slinghome  bootstrapinstaller  class  must  modified  expect  bundle  slinglaunchpadstartup  folder,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4311,support  different  property  bootstrap  command  standalone  webapp  sling2134  sling2182  possible  provide  additional  sling  property  bootstrap  command  entry  bundle  list  project  enhance  support  allow  different  property  command  based  artifact  type,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4312,add  spi  interface  injecting  customalternate  postresponse  implementation  discussed  sling2156  necessarily  tied  issue  basically  possible  implement  interface  produce  implementation  postresponse  interface,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4313,improve  support  embedding  sling  launcher  java  application  way  embed  sling  launcher  today  build  array  command  line  option  call  static  mainmainstring  args  method  application  kind  weird  allows  small  subset  configuration  property  easily  supplied  calling  application  addition  handling  command  line  option  currently  split  main  maindelagate  class  main  class  implement  usage  functionality  h  command  line  option  maindelegate  class  implement  actual  conversion  command  line  option  internal  configuration  property  improved  support  real  command  line  consolidated  main  class  map  configuration  property  supplied  maindelagate  class  contain  actual  configuration  property,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
4314,add  configuration  skip  sessionsave  abstractpostoperation  sling1725  postservlet  operation  exposed  service  consumed  servlets  use  create  two  node  modifyoperation  one  request  however  second  node  creation  might  fail  postprocessors  case  want  return  error  user  nothing  stored  cant  done  moment  abstractpostoperation  always  save  independently  context  first  node  get  saved  second  node  think  make  lot  sense  let  caller  operation  control  session  saved  introduced  flag  skip  save  requested  modeled  isskipcheckin  flag,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4315,add  re  extension  launchpad  defaut  servlet  launchpad  serlvet  also  handle  re  extension  adaptables  stream  reason  ntresource  node  name  extension  hard  request,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4316,add  slinghttpservletrequestgetrequestdispatcherstring  path  requestdispatcheroptions  option  method  currently  slinghttpservletrequest  interface  allows  creation  requestdispatcher  option  resource  available  also  possible  create  requestdispatcher  option  path,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4317,improve  jcrresourceresolverresolve  performance  big  number  vanitypath  present  moment  performance  jcrresourceresolverresolve  tight  number  slingvanitypath  present  repository  large  number  vanitypath  mean  large  response  time  specially  worse  case  scenario  namely  huge  number  vanitypath  request  doesnt  match  vanitypath  also  average  case  sling  currently  employ  generic  regexps  also  vanitypath  since  regex  behind  vanitypath  well  know  room  optimization  ill  attach  graph  show  situation  potential  patch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4318,dont  pas  request  intended  handled  terminated  authentication  handler  discussed  mailing  list  1  sling  authenticator  pas  request  intended  handled  authentication  handler  terminated  either  error  redirecting  client  1  httpmarkmailorgmessageggsxgaigluwktjyv,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4319,create  abstractmavenlifecycleparticipant  implementation  add  artifact  bundle  list  dependency  list  capability  created  httpjiracodehausorgbrowsemng4224  allow  u  add  nonpom  dependency  external  bundle  list  file  dependency  list  project  execution  order  calculated,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4320,implement  generic  retry  mechanism  currently  task  fails  retried  basically  kind  endless  loop  however  two  retries  nothing  changed  likely  retry  failing  basic  code  bundle  handling  tied  bundle  b  reusable  c  working  perfectly  instead  come  generic  mechanism  retries  task  signal  want  retried  addition  need  notification  mechanism  notifies  installer  retry  something  eg  service  listening  bundle  event  would  notify  installer  time  bundle  event  occurred  etc,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4321,updating  fragment  different  version  content  work  update  bundle  jcr  package  updated  apache  felix  actual  content  changed  enough  version  number  changed  problem  usually  multimodule  maven  build  increase  version  contained  bundle  although  might  changed  release  unfortunately  new  version  deployed  therefore  webconsole  still  show  old  version  problem  applies  bundle  fragment,1,0,1,0,1,0,0,0,1,0,1,0,1,0,0,0,0
4322,register  web  console  plugin  using  servicefactory  currently  web  console  plugin  tried  directly  registered  fails  javaxservlet  api  available  moment  result  missing  plugin  osgi  installer  start  javax  servlet  package  instead  directly  trying  register  could  register  service  factory  instead  first  time  queried  web  console  started  required  apis  available,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4323,usermanager  convert  scr  java  doc  tag  scr  annotation  scr  annotation  provides  flexibility  support  respect  referring  actual  java  code  thus  reducing  risk  copypaste  error  addition  annotation  fully  supported  ides  thus  provide  support  editing,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4324,sling  performance  testing  tool  describeddiscussed  0  would  nice  performance  test  tool  sling  useful  different  situation  eg  micro  benchmark  feature  patch  follow  0  httpslingmarkmailorgmessagebz44im7aqeae4r57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4325,add  changestatetask  utility  task  changestatetask  useful  changing  state  resource,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4326,provide  support  versioned  resource  currently  transformationresult  set  id  arbitrary  attribute  currently  support  specific  version  attribute  turn  picked  core  compare  resource,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4327,way  add  multiple  adapter  annotation  class  adapterfactory  instance  support  multiple  adaptable  class  would  useful  able  support  multiple  annotation  per  class  since  language  spec  doesnt  allow  need  container  annotation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4328,correctly  sort  resource  sorting  resource  pointing  artifact  100  correct  digest  compared  artifact  either  snapshot  artifact  version  information,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4329,add  getters  setter  defined  entry  ease  use  slingbindings  resourcemetadata  class  extended  explicit  getters  setter  defined  map  entry,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4330,jcrresourcelistener  asynchronously  post  event  eventadmin  currently  jcrresourcelistener  post  event  osgi  eventadmin  process  jcr  event  may  create  considerable  delay  repository  observation  queue  processing  call  eventadminpostevent  must  immediately  extract  appropriate  eventhandler  service  service  registry  jcr  event  processing  generate  osgi  event  post  pone  actual  posting  event  separate  thread,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4331,serversetup  utility  flexible  way  setting  serverside  integration  test  need  flexible  way  setting  slingbased  server  integration  testing  allows  various  phase  server  setup  start  runnable  jar  wait  ready  install  additional  bundle  create  test  content  etc  selectively  run  ignored  useful  server  setup  slow  example  testing  upgrade  one  slingbased  system  another  mean  starting  old  version  setting  content  stopping  starting  new  version  running  test  check  test  content  preserved  suitably  adapted  etc  able  selectively  disable  setup  task  allows  restarting  test  saved  state  often  much  faster  redoing  whole  setup  debugging  resulting  system  test  ill  create  corresponding  utility  testingtools  use  testingsamples  example,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4332,detect  startup  mode  currently  bootstrap  installer  detects  new  startup  contains  newer  bundle  installsupdates  accordingly  could  generalize  provide  startup  mode  detection  able  distinguish  fresh  startup  install  simple  restart  update,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4333,new  startup  feature  sling2372  mechanism  decide  kind  startup  currently  processed  could  leverage  create  new  functionality  enhance  lauchpad  api  startup  mode  possibility  register  listener  informed  startup  mode  progress  another  feature  would  directly  go  beginning  start  level  framework  stop  intermediate  level  installs  update  increase  start  level  one  one  make  update  installs  much  smoother  information  ill  write  email  dev  list,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0
4334,make  repositorytestbases  repository  usable  junit  4x  style  test  test  currently  need  inherit  class  get  testrepository  force  use  old  junit3x  style  ill  add  static  method  class  junit  4x  test  use  get  repository,1,0,1,0,1,0,0,0,1,1,0,0,0,0,0,0,0
4335,separate  requestaccess  logging  sling  engine  currently  request  access  log  entry  generated  sling  engine  bundle  consequence  request  going  sling  main  servlet  actually  logged  fix  hook  request  access  logging  infrastructure  serlvet  container  servlet  api  filter  run  early  late  possible  importantly  global  level  catch  request  addition  since  filter  nothing  sling  engine  would  make  sense  create  bundle  common  area  along  commonslog  commonslogservice  bundle,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4336,make  resourceresolverfactory  independent  jcr  discussed  httpmarkmailorgthreadwp6cghi5nqprpusn  would  like  create  resourceresolverfactory  implementation  dependent  jcr  make  easier  create  custom  resourceresolverfactories  thing  like  domain  mapping  vanity  path  resource  provider  resolution  could  reimplemented  whiteboard  area  created  httpsvnapacheorgreposasfslingwhiteboardresourceresolverfactory,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,0
4337,logging  panel  always  provided  sling  log  support  web  console  page  problem  log  bundle  started  without  servlet  api  wiring  case  panel  available  made  available  upon  rewiring  log  bundle  fix  register  plugin  servicefactory  lazily  instantiate  class  requiredused  dynamically  import  servlet  api  lazily  wire  required,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4338,installer  start  event  already  sent  resource  provisioned  currently  installer  report  startedsuspended  event  run  loop  new  resource  arrive  provider  preparation  might  take  time  like  copying  file  system  etc  case  started  event  reported  way  later  resource  provided  would  make  sense  report  started  event  right  new  resource  arrive  resource  removed,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
4339,install  bundle  order  start  level  bundle  install  task  currently  sorted  url  doesnt  provide  advantage  rather  sort  sort  level  allows  bundle  lower  start  level  resolved  one  higher  start  level,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4340,handle  get  request  method  name  request  extension  currently  name  script  call  handle  request  based  request  extension  get  head  request  request  method  request  work  fairly  well  script  handling  single  extension  scale  well  servlets  script  btw  able  handle  single  extension  launchpad  default  servlet  therefore  gethead  request  script  name  looked  request  extension  script  found  request  method  name  like  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4341,support  configuration  old  pid  rewrite  jcr  installer  pid  changed  orgapacheslingjcrinstallimpljcrinstaller  orgapacheslinginstallerproviderjcrimpljcrinstaller  support  potential  configuration  old  pid  registering  managed  service  old  pid  configuration  arrives  old  pid  value  overwrite  value  new  pid  log  warning  case  mechanism  like  trying  merge  configs  bound  fail  user  configuration  service  anyway  best  possible  solution,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4342,classloaderwriter  provide  class  loader  loading  written  classesresources  follow  sling2445  classloaderwriter  enhanced  return  class  loader  used  load  dynamically  loaded  class  written  writer  writer  use  dynamic  class  loader  parent  implement  dynamicclassloader  interface  allows  check  class  loader  still  current  returned  classloader  cached  client  get  class  loader  time  require  one  writer  ensures  always  fresh  loader  returned  java  jsp  scripting  use  class  loader  instead,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,0
4343,replace  resourcegetresourceprovider  resourcegetresourceresolver  currently  resource  provides  access  resourceprovider  created  resource  really  practical  probably  correct  resourceprovider  something  operating  behind  scene  behalf  resourceresolver  thefore  method  replaced  method  providing  access  resourceresolver  causing  resource  object  created  resourceprovider  change  due  resource  getresourceresolver  getresourceprovider  resourceprovider  add  resourceresolver  argument  method  creating  resource  instance,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4344,allow  mapping  node  internet  domain  sling  support  hosting  multiple  domain  different  jcr  root  eg  httpwwwdomain1com  could  map  contentdomain1com  httpwwwdomain2com  could  map  contentdomain2com  developing  website  fully  qualified  domain  might  available  ideally  mapping  could  configured  flexible  way  one  option  would  maintain  set  regular  expression  match  url  regexp  would  match  path  jcr,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4345,add  currentnode  variable  scripting  context  language  discussed  httpmarkmailorgmessagevokst7wb4k322zdc  currentnode  resourceadapttonodeclass  value  null  resource  point  node,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4346,improve  package  refresh  behaviour  right  package  installed  updated  refresh  bundle  could  improve  collecting  changedinstalled  bundle  resp  host  bundle  fragment  refresh,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4347,improve  internal  task  handling  currently  internal  task  handling  like  restarting  bundle  package  refreshs  handled  properly  especially  survice  restart  installer  guess  easiest  way  would  create  artifical  resource  handle  special  task  factory  would  persists  task  ootb  would  also  allow  add  arbitrary  information  task,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
4348,allow  resource  queried  osgi  installer  service  osgiinstaller  service  currently  allows  resource  registration  update  would  interesting  query  interface  ask  osgiinstaller  service  currently  installed  resource  known  resource  empty  array  none  installableresource  getresources  could  example  used  expose  bundle  known  osgi  installer  maven  repository  simple  setup  development  environment  based  existing  sling  instance,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
4349,implement  crud  based  resource  need  full  crud  support  based  resource  general  need  api  allows  create  update  delete  resource  method  call  delegated  underlying  resource  provider,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4350,remove  fallback  code  old  resource  implementation  see  sling2457  example  currently  unusal  handling  resourceutilabstractresource  method  basically  support  old  implementation  resource  api  predate  210  release  extended  resource  interface  well  resource  resolver  stuff  think  time  support  old  stuff  anymore  clean  code,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4351,launchpad  war  optionally  use  external  repository  without  requiring  change  bundle  would  useful  allow  launchpad  use  external  repository  accessed  via  jndi  rmi  without  modify  war  file  loadunload  bundle  ill  search  solution  along  line  1  launchpad  includes  jackrabbitserver  embedded  repository  jackrabbitclient  access  external  repository  via  jndi  rmi  bundle  default  jackrabbitclient  provide  repository  2  startup  sling  class  search  classpath  andor  environment  additional  configuration  property  3  specific  configuration  property  prevents  jackrabbitserver  bundle  providing  repository  let  jackrabbitclient  provide  way  web  container  could  setup  advance  define  repository  use  new  release  launchpad  war  file  could  dropped  without  requiring  configuration  war  file  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4352,allow  threadpool  process  callablerunnable  return  future  currently  sling  threadpool  0  returning  future  executing  task  however  handle  future  result  computation  useful  case  requiring  fine  grained  synchronization  among  task  instance  one  could  require  execute  task  mixing  parallel  sequential  execution  barrier  synchronization  example  could  take  following  queue  task  queue  task1task2  task3  task4task5task6task7  group  task  task1  …  taskn  group  task  executed  sequentially  task  group  executed  parallel  could  easily  implemented  based  future  object  returned  threadpool  thus  would  nice  enable  0  orgapacheslingcommonsthreadsthreadpool,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4353,installer  detect  installer  bundle  refreshed  another  bundle  update  eg  logging  bundle  updated  osgi  installer  cause  logging  bundle  refreshed  turn  cause  osgi  installer  restarted  however  osgi  installer  aware  fact  waiting  package  refresh  event  holding  reference  async  thread  turn  sometimes  cause  bundle  stopstart  installer  bundle  fail  therefore  osgi  installer  detect  situation  stop  already  updating  r43  wiring  api  easily  detect  without  get  harder  implementation  detects  whether  r43  available  us  functionality  available  use  fallback,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
4354,potential  deadlock  may  caused  adaptermanager  adaptermanager  us  cascade  three  synchronized  block  adapterfactorydescriptorgetfactory  method  called  synchronizedcache  synchronizedfactories  synchronizedthis  potential  deadlock  may  happen  adapterfactorydescriptorgetfactory  method  asks  declarative  service  runtime  service  may  cause  servicefactory  service  instantiated  whole  cascade  potential  secondary  action  depending  happens  instantiation  last  block  probably  simply  removed  others  definitely  refactored  cause  participant  deadlock  situation  reason  synchronized  block  must  large  b  java  lock  held  calling  osgi  framework  happens  adapterfactorydescriptorgetfactory  method,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4355,resourceresolverfactory  available  specific  resourceproviderfactories  registered  resourceresolverfactory  available  configurable  set  provider  available  add  string  array  property  whose  value  either  pid  filter  expression  starting  configured  value  matching  provderfactory  available  rrfactory  registered,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4356,introduce  mapconfigurationprovider  introduce  help  test  mapentries  trying  build  unit  test  mapentries  helpful  extension  resourceresolverfactory  interface  easily  mocked  resourceresolverfactoryimpl  class,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
4357,improvement  sling  performance  tool  added  improvement  sling  performance  testing  tool  1  added  possibility  run  test  method  class  performance  test  test  represented  class  new  test  add  new  java  class  2  added  performancetest  annotation  used  discover  test  method  java  class  3  added  possibility  provide  performancetest  annotation  configuration  parameter  test  like  warmup  time  run  time  warm  invocation  run  invocation  default  warmuptime  runtime  used  user  choose  count  time  prefer  setting  number  test  invocation  want  made  test  run  4  created  new  maven  project  contains  sling  performance  test  left  frameworktool  related  part  base  project  would  like  use  framework  performance  testing  project  also  5  added  possibility  parameter  sent  test  suite  object  added  suite  suite  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4358,provide  job  queue  jmx  bean  interface  one  query  get  information  status  service  implementing  interface  eg  public  interface  healthcheckable  public  int  getstatus  return  value  method  could  use  static  int  ok  0  static  int  warning  1  static  int  critical  2  static  int  unknown  3  value  nagios  us  return  value  plugins  see  httpnagiosplugsourceforgenetdeveloperguidelineshtmlaen76  decision  value  returned  delegated  service  maybe  need  configuration  define  point  ok  becomes  warning  via  osgi  whiteboard  pattern  collect  service  providing  status  information  calculate  overall  status  system,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4359,use  repositoryurloverrideproperty  jackrabbitclient  bundle  sling254  implement  mechanism  jackrabbitserver  bundle  us  system  property  named  repositoryurloverrideproperty  override  configuration  mechanism  implemented  jackrabbitclient  bundle  allow  people  create  slingbased  webapps  dropped  web  container  use  containerprovided  repository  without  requiring  webapp  configuration  change,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4360,tooling  logging  framework  slingclipse  need  logging  framework  slingclipse  see  two  option  moment  using  log  framework  slf4j  logger  similar  using  embedded  eclipse  logging  framework,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4361,add  support  run  mode  add  run  mode  support  launchpad  installer  like  jcr  installer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4362,manually  trigger  sync  filesdirectories  able  manually  publish  subtree  content  opposed  sync  happening  background  one  use  case  autosync  disabled  user  want  publish  change  manually,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4363,replace  old  json  content  import  new  importer  sling194  introduced  new  json  importer  currently  support  xjson  file  new  importer  support  standard  json  export  provided  default  servlet  json  format  mentioned  sling194  old  format  supporting  json  file  removed  favor  new  one,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
4364,enhance  run  mode  handling  often  need  provide  different  feature  user  might  ability  choose  whether  feature  installed  easily  done  run  mode  feature  put  run  mode  run  mode  activated  user  feature  installed  however  case  two  feature  might  concurrent  either  feature  feature  b  installed  still  run  mode  used  defining  two  run  mode  b  case  user  choose  one  run  mode  nothing  installed  user  selects  run  mode  installed  could  support  use  case  configuration  property  setting  service  define  property  contains  run  mode  usually  always  active  b  addition  define  property  contains  whether  run  mode  active  unless  another  run  mode  active  use  case  define  run  mode  always  active  also  set  second  property  define  active  b  activated  user  could  also  define  third  property  contains  set  run  mode  choosable  first  startup  installation  example  property  defined  b  user  selection  first  startup  preserved,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4365,web  console  plugin  tenant  management  extending  support  tenant  api  need  add  console  plugin  createremove  tenant  also  need  pluggable  support  register  tenant  setup  handler  various  modulesimplementations  plugged,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4366,resource  access  security  service  resource  provider  without  backing  acls  adding  minmal  resource  access  gate  discussed  1  first  step  define  api  interface  minimal  implementation  allows  define  read  access  rest  crud  follow  later  1  httpmarkmailorgthread4ctczoiy533tquyl,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4367,support  chunked  file  upload  sling  use  case  1  large  file  upload  high  speed  internet  connection  advent  cloud  hd  going  mainstream  sling  support  large  file  2gb  upload  2  fault  tolerant  uploads  sling  provide  capability  resume  upload  failure  point  require  client  restart  complete  upload  process  3  faster  upload  sling  support  client  initiate  multiple  connection  upload  file  chunk  parallel,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4368,define  tenantmanager  api  tenant  currently  administered  create  update  remove  web  console  addition  tenantprovider  service  interface  allows  looking  tenant  read  administrative  purpose  would  good  tenantmanager  service  interface  allows  administrative  task  something  like  public  interface  tenantmanager  extends  tenantprovider  tenant  createstring  tenantid  mapstring  object  property  void  setpropertytenant  tenant  string  name  object  value  void  removetenant  tenant,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
4369,add  integration  test  error  handling  mechanism  would  nice  integration  test  error  handling  mechanism  described  httpslingapacheorgsiteerrorhandlinghtml  attaching  patch  contain  skeleton  test  committed  extend  wdyt,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4370,add  resource  type  inheritance  discussed  devlist  1  resource  type  inheritance  scriptservlet  resolution  implemented  follows  define  optional  property  slingresourcesupertype  may  take  resource  type  used  super  type  resource  type  property  stored  node  script  located  resource  type  node  see  resourcesupertype  property  resource  resourcesupertype  parent  node  plus  property  name  define  slingresourcesupertype  mixin  node  type  defines  slingresourcetype  property  attachable  node  add  resourcegetresourcesupertype  returning  super  type  resource  type  null  super  type  exists  add  support  servlet  resolver  resolve  script  resource  type  also  super  type  defined  super  type  resolution  take  place  falling  back  default  script  sample  type  type1  type2  slingresourcesupertype  type1  type3  content  en  slingresourcetype  type2  en  slingresourcetype  type2  slingresourcesupertype  type3  resource  super  type  defined  follows  typestype1  super  type  typestype2  type1  due  slingresouresupertype  property  contenten  type1  due  slingresourcesupertype  property  typestype2  conentde  type3  due  slingresourcesupertype  property  1  httpwwwmailarchivecomslingdevincubatorapacheorgmsg02365html,1,1,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0
4371,make  resourcemetadata  readonly  delivered  client  code  recently  discussed  mailing  list  resourcemetadata  object  provides  additional  metadata  information  resource  intended  changed  client  code  resourcemetadata  extends  hashmap  readwrite  default  might  potentially  changed  client  code  update  api  doc  object  readonly  also  enforce  implementation  seems  far  one  changing  resourcemetadata  left  resource  resolver  therefore  make  readonly  returned  resource  resolver,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4372,optionally  run  sling  apache  oak  would  nice  runmode  sling  run  top  apache  oak  0  0  httpjackrabbitapacheorgoak,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
4373,servicelocator  clean  recently  discussed  following  change  proposed  therefore  propose  following  change  remove  service  locator  support  scheduler  b  remove  service  locator  add  functionality  slingscripthelper  c  make  sure  scripting  implementation  provide  way  access  script  helper  script  remove  getservicelocator  method  request,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4374,simplify  sling  aka  component  api  jira  issue  track  simplification  sling  aka  component  api  see  httpwwwmailarchivecomslingdevincubatorapacheorgmsg00177html  discussion  mailing  list,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0,1
4375,ujax  post  serlvet  able  insert  new  node  specified  location  current  version  support  ujaxorder  0  order  newly  created  node  sibling  suggest  implement  following  variant  ujaxorder  name  example  b  c  ujaxorderabove  b  newnode  b  c  ujaxorderabove  newnode  b  c  ujaxorderabove  newnode  b  c  ujaxorderbelow  b  abnewnodec  ujaxorderbelow  c  abcnewnode  ujaxorderbelow  abcnewnode  please  note  jcr  support  ordering  handling  different  think  scripting  environment  loop  list  make  sense  since  dont  need  know  next  list  item  drawing  insert  form,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4376,provide  jacoco  agent  servlet  expose  code  coverage  data  http  client  sling  junit  test  execution  create  simple  rest  endpoint  jacoco  agent  systemslingjacocoexec  expose  jacoco  agent  status  head  systemslingjacocoexec  contenttype  applicationoctetstream  200  jacoco  agent  attached  exposed  jmx  404  jacoco  agent  found  return  iagentgetexecutiondatafalse  get  systemslingjacocoexec  contenttype  applicationoctetstream  200  execution  data  returned  response  entity  404  jacoco  agent  found  reset  execution  data  return  jacocoexec  file  post  systemslingjacocoexec  optional  param  sessionid  set  specific  sessionid  reset  contenttype  applicationoctetstream  200  agent  reset  new  sessionid  specified  prior  execution  data  returned  response  entity  404  jacoco  agent  found  jacoco  instrumentation  osgi  rather  limited  sense  one  agent  per  jvm  resetting  execution  data  reset  across  board  mean  concurrent  request  service  shared  integration  test  server  need  restricted  test  execution  avoid  corrupting  coverage  data,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4377,extensible  sling  system  health  checking  tool  created  prototype  httpsgithubcombdelacretazmuppetprototype  might  want  move  contrib  folder  muppet  like  puppet  different  allows  check  health  system  defining  rule  box  verify  thing  like  presence  specific  osgi  bundle  jmx  mbeans  value  junit  test  execution  including  scriptable  one  thanks  sling  testing  tool  correct  disabling  default  sling  credential  etc  new  rule  type  defined  adding  rulebuilder  osgi  service  several  example  initial  code  ill  add  howto  initial  version  known  issue  output  indicate  value  cause  rule  fail  servlet  output  json  yet  tag  rule  would  nice  able  run  performance  security  rule  example  rule  checking  osgi  configuration  parameter  would  useful  credit  joerg  hoh  one  well  inspiration  httpsgithubcomjoerghohcq5healthcheck,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4378,discoveryimpl  resource  based  implementation  discoveryapi  ticket  contributing  resource  based  implementation  discovery  api  see  0  named  discoveryimpl  sling  implementation  attached  targz  md5  hash  d8891e5401114b2a629d3ff01044a1d6  short  description  discoveryimpl  discoveryimpl  outofthebox  implementation  discoveryapi  using  standard  feature  sling  discoveryapi  provides  view  topology  consisting  number  individual  slinginstances  instance  loosely  coupled  except  part  topology  implicitly  necessarily  share  anything  else  instance  though  form  cluster  ie  connected  repository  api  abstraction  called  clusterview  discoveryimpl  us  two  mechanism  discovering  instance  store  information  local  instance  unique  location  repository  thus  allowing  instance  access  repository  see  recognize  connects  remote  instance  via  plain  http  post  announcing  instance  see  getting  back  instance  counterpart  done  regularly  using  heartbeat  thus  allowing  get  view  currently  live  instance  discoveryapi  additionally  support  leaderelection  within  cluster  ensures  one  one  instance  elected  leader  stay  leader  disappearsshuts  downdies  discoveryimpl  us  repositorybased  voting  instance  cluster  establish  common  cluster  view  based  established  view  discoveryimpl  able  deterministically  elect  one  instance  view  leader  namely  one  lowest  id  also  support  propertyprovider  concept  discoveryapi  property  instance  propagated  instance  using  heartbeat  piggyback  either  via  repository  via  http  post  remote  instance  get  idea  discoveryimpl  build  add  start  two  bundle  orgapacheslingdiscoveryapi  orgapacheslingdiscoveryimpl  sling  installation  open  browser  provided  simplistic  topology  webconsole  httplocalhost4502systemconsoletopology  please  let  know  anything  need  explanation  detail  looking  forward  included  sling  cheer  stefan  0  httpsvnapacheorgreposasfslingtrunkcontribextensionsdiscoveryapi,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4379,add  api  starting  job  service  interface  executing  job  currently  requires  sending  special  job  event  event  admin  create  job  event  sent  sender  knowledge  whether  job  received  job  implementation  executing  job  currently  done  sending  event  osgi  event  admin  waiting  handler  process  job  add  lot  overhead  uncertainty  especially  job  handling  know  upfront  whether  processor  job  exists,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
4380,make  functiontag  name  consistent  right  name  consistent  tag  el  function  sling  api  corrected  allow  easy  usage,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
4381,avoid  unnecessary  classloader  creation  change  done  class  loader  writer  class  loader  notified  change  classloader  exists  one  created  avoided  classloader  created  change  need  yet  create  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4382,simplify  handling  multiple  reference  post  processor  node  name  generator  post  operation  current  handling  multiple  reference  post  processor  node  name  generator  post  operation  based  old  d  specification  requires  lot  additional  syncing  handling  newer  d  version  get  service  property  bindunbind  method  without  additional  method  call  simplifies  handling  reference  dont  wait  bind  component  activated  delayed  handling  removed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4383,add  inventory  printer  json  output  new  apache  felix  inventory  printer  add  json  output  web  console  plugins  precisely  inventory  printer  could  output  job  information  json  well,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4384,replace  administrative  login  servicebased  login  start  sling  tried  solve  problem  providing  service  access  repository  resource  tree  without  hard  code  configure  password  done  first  slingrepositoryloginadministrative  later  resourceresolverfactorygetadministrativeresourceresolver  method  time  mechanism  proved  hammer  hit  nail  particularly  method  truly  useful  disadvantage  providing  full  administrative  privilege  service  specific  kind  privilege  would  enough  example  jsp  compiler  would  enough  able  read  jsp  source  script  write  java  class  jsp  compiler  target  location  access  required  similarly  manage  user  user  management  privilege  enough  access  content  really  required  solve  problem  new  api  service  authentication  proposed  httpscwikiapacheorgconfluencedisplayslingserviceauthentication  prototype  implemented  httpsvnapacheorgreposasfslingwhiteboardfmeschbedeprecateloginadministrative  issue  merging  prototype  code  back  trunk  thus  fully  implementing  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4385,specify  nodetype  node  creation  would  nice  specify  node  type  new  node  created  post  servlet  perhaps  specifying  node  type  parameter  like  ujaxnodetype,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4386,improve  processing  performance  job  processed  locally  currently  job  processing  completely  observation  based  even  job  added  locally  also  processed  locally  immediately  put  queue  creates  unnecessary  delay  adding  job  processing  easily  avoided  directly  putting  job  queue,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4387,create  simpler  flexible  scheduler  service  api  current  api  scheduler  service  two  problem  time  add  new  feature  le  duplicate  method  add  new  method  exactly  new  feature  method  throw  checked  unchecked  exception  although  usually  useless  client,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4388,tooling  show  content  contentxml  project  explorer  irrespective  chosen  serialization  content  contentxml  shown  tree  structure  project  explorer  achieved  using  navigator  content  extension  nce  part  common  navigator  framework  cnf  eclipse,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
4389,merged  resource  provider  exchanged  felix  meschberger  idea  implement  custom  resource  provider  ability  merge  multiple  resource  based  search  path  instance  search  path  apps  libs  hitting  mergemyresourceishere  check  appsmyresourceishere  libsmyresourceishere  option  like  addoverride  property  delete  property  resource  libs  reorder  node  available  intend  submit  patch  soon  possible  code  currently  located  httpsgithubcomgknobslingresourcemerger,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4390,simplified  health  check  service  prototyping  health  check  tool  ready  rewrite  make  simpler  osgi  friendly  functionality  similar  much  le  code  focused  actual  use  case  emerged  prototyping  new  api  discussed  list  httpmarkmailorgthreadi6ib7tgax4cn2sss,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4391,support  wildcard  regular  expression  ip  whitelist  discoverytopology  connector  currently  ip  white  listing  feature  discoveryimpl  requires  explicit  ip  address  fully  qualified  hostnames  complex  setup  useful  define  regular  expression  eg  hostnames  eg  mydomaincom,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4392,tooling  support  autodeploy  osgi  bundle  eclipse  running  sling  launchpad  eclipse  bundle  type  maven  project  possible  autodeploy  built  bundle  configured  sling  launchpad  ideally  optionally  wed  hotcode  replacement  individual  class  bundle  auto  redeploying  entire  bundle  fine  start  look  tool  like  eclipse  libra  httpwwweclipseorglibra  springloaded  httpsgithubcomspringsourcespringloaded  help  redeployhotcode  replacement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4393,improve  karaf  integration  test  separate  testing  support  test  package  jar  use  maven  failsafe  plugin  test  update  pax  exam  491  enable  test  remove  ignore  annotation  increase  timeouts  300000  m  test  feature,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4394,provide  mechanism  install  bundle  based  directory  ide  integration  incremental  build  would  great  mechanism  installupdate  bundle  based  output  directory  project  ill  start  prototype  bundle  receives  post  request  containing  path  local  directory  servlet  either  install  update  bundle  directory  work  scr  descriptor  file  project  go  bundle  configure  scr  plugin  like  plugin  groupidorgapachefelixgroupid  artifactidmavenscrpluginartifactid  configuration  outputdirectoryprojectbuilddirectoryclassesoutputdirectory  configuration  plugin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4395,immutable  healthcheck  result  discussed  list  ill  change  result  class  immutable  allow  singlevalue  logbased  result  result  immutable  result  two  constructor  one  take  status  message  string  one  take  resultlog  set  result  status  resultloggetstatus  resultlog  list  message  status  message  string  getstatus  method  return  highest  status  added,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4396,use  service  property  hc  meta  data  improve  jmx  registration  discussed  mailing  list  simplify  health  check  api  using  service  property  meta  data  hc  addition  jmx  registration  bridge  need  update  handle  two  hc  service  using  name  registration  mail  thread  httpmailarchivesusapacheorgmodmboxslingdev201308mbox3ccakkcf4r89jbsvprqkr304wbl8gqpzaq4rw3z9sijwbbo8ygmailgmailcom3e  httpmailarchivesusapacheorgmodmboxslingdev201308mbox3ccakkcf4q79no26va542sqghof1f1uvsjnyls6as2xqczrecpgmailgmailcom3e,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4397,improve  karaf  feature  break  slingkaraf  feature  finegrained  feature  better  reusability  add  description  version  add  feature  update  integration  test  update  pax  exam  latest  update  karaf  4x  update  maven  failsafe  plugin  217  add  workaround  karaf1972  update  readme  cleanup,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4398,support  progress  tracking  job  keeping  job  longrunning  job  would  useful  mean  track  progress  shown  console  user  include  following  eta  completeness  value  computed  optional  default  10  max  current  value  eg  42  23100  log  output  stream  detailed  progress  information  failure  reason  case  job  failed  afaics  requires  change  existing  implementation  job  need  additional  support  setting  property  eg  max  current  progress  value  job  need  kept  least  completedfailed  give  access  failure  informationlog  stream,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1
4399,make  ujaxhtmlresponse  public  usable  current  ujax  html  response  used  ujaxpostservlet  would  useful  also  used  class,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,1,0
4400,tooling  support  auto  deploy  contentbundles  similar  sling3009  eclipse  possible  auto  deploy  contentbundle  easily  using  configured  launchpadserver  feature  eventually  integrate  sling2985,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4401,tooling  add  whitelabel  support  slingclipse  slingclipse  plugin  certain  location  possible  brand  plugins  eg  add  custom  icon  label  etc,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4402,filter  populate  slf4j  mdc  request  detail  common  log  moving  logback  possible  use  mdc  1  support  slf4j  sling  get  better  log  also  enable  better  filtering  log  patch  add  new  extension  module  register  mdcinsertingfilter  filter  extract  information  incoming  request  add  mdc  feature  supported  1  default  expose  detail  like  request  path  query  string  etc  based  3  2  expose  osgi  config  one  define  http  header  parameter  cookie  need  added  mdc  3  expose  session  id  user  information  requestresolver  associated  current  thread  execution  information  later  exposed  via  log  like  shown  expose  sessionid  part  log  dddmmyyyy  hhmmsssss  level  thread  logger  xjcrsessionid  msgn  information  also  used  filter  log  based  userurl  etc  used  custom  logging  event  evaluator  detail  refer  2  1  httpwwwslf4jorgmanualhtmlmdc  2  httpsgithubcomchetanmehslinglogbacktreemastermdc  3  httplogbackqoschmanualmdchtmlmis,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4403,apt  parser  default  servlet  id  like  use  wikilike  format  create  interactive  doc  launchpad  ive  done  test  doxiamoduleapt  used  maven  provides  customizable  apt  parser  including  macro  easily  provide  osgibased  needed  code  ill  create  two  new  module  first  shot  parser  module  simple  wrapper  around  doxiamoduleapt  default  apt  servlet  render  apt  file  stored  repository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4404,tooling  separate  m2eclipse  dependent  extension  others  slingclipse  moment  slingclipse  contains  extension  require  m2eclipse  plugin  installed  harddependency  slingclipse  extension  minimum  separated  remaining  extension  user  choose  install  technically  separation  bundled  separate  feature,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4405,enable  logback  use  osgi  service  filter  turbofilters  currently  logback  integration  enabled  use  osgi  service  appenders  1  would  helpful  also  enabled  using  osgi  service  logback  filter  turbofilters  2  filter  used  precisely  extract  required  log  certain  flow  prove  useful  debugging  complex  issue  1  httpsgithubcomchetanmehslinglogbackappendersandwhiteboardpattern  2  httplogbackqoschmanualfiltershtml,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4406,jsonqueryservlet  would  nice  way  specify  jcr  query  url  order  query  underlying  jcr  repository  attached  patch  work  follows  new  query  servlet  called  extension  json  selector  set  query  pas  following  parameter  url  statement  jcr  query  statement  xpath  sql  querytype  xpath  sql  none  specified  xpath  taken  property  specifies  property  relative  path  put  result  set  parameter  added  multiple  time  excerptpath  specifies  relative  node  path  excerpt  built  result  returned  json  string  eg  nameee0repexcerptexcerptfragmentgeometrixxcomponentscontentpage  eefragmentexcerptjcrpathcontentee0jcrscore528cqcontentjcrtitleee  namenewsrepexcerptexcerptfragment  geometrixxcomponentscontentpage  news  geometrixfragmentexcerptjcrpathcontentgeometrixxenaboutnewsjcrscore521cqcontentjcrtitlenews  example  query  call  httplocalhost8080slingmyhomequeryjsonstatementelementcqpagejcrcontainsslingrepexcerptpropertycqcontentjcrtitleexcerptpathcqcontent,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4407,repository  api  need  single  method  create  node  set  nonbinary  property  repository  addupdate  method  follows  code  commandvoid  newaddnodecommandfileinfo  fileinfo  commandvoid  newupdatecontentnodecommandfileinfo  fileinfo  resourceproxy  resourceproxy  code  add  command  knowing  jcrprimarytype  node  create  guessing  one  ntfile  ntfolder  unified  command  newaddorupdatenodecommand  could  possibly  receive  resourceproxy  repository  path  set  would  enough  information  vlt  resourcebased  implementation  need  adjusted  api  change,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
4408,improve  authentication  handling  following  scheme  improve  authentication  handling  anonymous  user  access  content  he  allowed  access  resource  resolution  access  control  exception  thrown  exception  catch  point  request  authentication  send  back  authenticated  user  access  content  he  allowed  access  resource  resolution  access  control  exception  thrown  404  send  back,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4409,tooling  integrate  decentxml  minimal  change  contentxml  modification  currently  modifying  property  addingremoving  node  contentbrowser  ie  contentxml  xml  get  rewritten  loos  formatting  newlines  within  element  attribute  default  contentxml  generated  vault  decentxml  httpcodegooglecompdecentxml  new  bsd  license  tool  allows  retain  formatting  saxdomparsers  dont  integrate  tool  keep  source  change  minimum,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4410,record  loaded  content  reload  inadvertedly  currently  content  loader  always  reloads  content  indicated  initial  content  bundle  repository  contain  respective  content  sometimes  may  desirable  remove  content  repository  get  content  reloaded  bundle  system  restart  prevent  content  reload  content  loader  take  note  loaded  content  try  reload  content  marked  loaded  regardless  whether  actual  content  still  exists,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
4411,allow  installingupdating  install  support  bundle  server  view  currently  way  install  supportinstall  bundle  creating  new  server  creating  new  bundle  option  available  server  editor  page  implementation  plan  extract  osgiclient  make  part  apicore  create  osgiclientfactory  make  scr  componentservice  make  access  archetype  resource  public  probably  part  separate  bundle  followup  bug  make  bundle  contain  embedded  resource  implement  bundle  install  server  page  maybe  special  logic  snapshot,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4412,centralize  improve  embedded  artifact  handling  probably  keep  embedded  artifact  handling  support  case  user  dont  access  artifact  use  provide  consistency  user  experience  imagine  least  embedding  archetype  generate  project  embedding  additional  developmenttime  bundle  sling  installation  make  reusable  multiple  context  propose  1  package  embedded  artifact  single  plugin  eclipsecore  plugin  id  prefer  something  like  orgapacheslingideartifacts  2  create  osgi  d  component  read  artifact  using  bundle  context  3  hardcode  version  rather  read  embedded  manifest  bundle  pomproperties  nonosgi  maven  artifact  possibly  cache  information  lazily  retrieved,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4413,provide  way  schedule  job  current  way  scheduling  job  user  friendly  requires  send  event  via  event  admin  add  java  api  create  scheduled  job  creation  addition  could  add  new  queue  type  maintenance  queue  order  queue  difference  running  job  exactly  point  time  created  scheduled  maintenance  job  executed  exactly  scheduled  time  unless  another  job  currently  running  apart  starting  job  stopping  job  would  another  nice  addition,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4414,implement  support  feature  flagstoggles  sling  would  nice  sling  provide  support  feature  flag  also  called  toggle  pattern  1  thinking  implementation  could  provide  following  1  integrate  existing  framework  togglz  2  implement  something  similar  uiconfiguration  toggle  feature  2  create  jcr  property  slingfeature  added  resource  type  node  conditional  logic  slinginclude  get  post  servlets  determines  resource  rendered  resource  type  contains  property  1  httpenwikipediaorgwikifeaturetoggle  2  httpwwwtogglzorg,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4415,add  topology  message  verification  discovery  service  discovery  service  provides  support  whitelisting  source  topology  information  cluster  topology  creates  reconfiguration  load  order  mnn1  n  number  node  topology  number  change  load  rise  rapidly  number  change  andor  node  increase  address  2  proposal  1  provide  spi  exported  discovery  impl  bundle  allows  implementors  implement  whitelisting  based  request  need  support  creating  request  validating  request  2  embed  functionality  within  discovery  impl  bundle  support  validation  encryption  topology  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4416,deprecating  jobutil  class  follow  sling3028  based  comment  stefan  seifert  jobutil  class  deprecated  90  perhaps  better  deprecated  completely  move  remaining  10  new  location  class  suitable  would  solve  inconsistency  jobutiljobpriority  enum  well  part  job  interface  whereas  jobtype  part  job  interface,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4417,job  state  related  enumeration  follow  sling3028  based  comment  stefan  seifert  find  enum  name  jobjobtype  ideal  stand  type  state  job  jobstate  enum  consumer  api  package  already  find  enum  class  name  jobstate  jobstatus  consumer  package  ideal  stand  state  job  result,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0,1,1
4418,add  new  simple  project  content  wizard  include  new  wizard  creates  simple  content  project  project  would  simply  create  faceted  project  according  facet  set  set  additional  type  specific  property  eg  content  would  create  jcrroot  directory  although  wizard  would  trivial  task  imo  help  user  kickstart  project  get  mindset  slingclipse  initial  content  something  like  code  ├──  jcrroot  │  ├──  content  │  └─────  example  └──  metainf  └──  vault  ├──  configxml  ├──  filterxml  └──  settingsxml  code,1,0,0,0,0,0,0,0,1,1,1,0,1,0,0,0,0
4419,thread  pool  configuration  per  queue  better  controlling  thread  usage  wrt  queue  queue  configurable  thread  pool  name  pool  exists  queue  use  one  default  default  eventing  thread  pool,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4420,implement  webconsolesecurityprovider2  integration  sling  authenticator  current  security  provider  implement  webconsolesecurityprovider  interface  auth  based  username  password  trying  login  repository  web  console  run  within  sling  context  rather  use  sling  authenticator  authentication  would  allow  seamless  integration  without  need  retype  password  keeping  exact  check  could  enhance  module  register  type  2  interface  sling  authenticator  available  old  implementation  compatibility,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
4421,avoid  duplicated  request  mbeans  creating  resource  current  implementation  optimal  query  attribute  value  mbean  especially  whole  mbean  outputted  resource  tree  eg  converted  json,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4422,allow  refering  osgi  appenders  within  logback  config  default  logback  config  allows  referring  appenders  defined  within  config  file  enable  better  integration  osgi  would  better  one  refer  appender  implemented  osgi  service  within  config  case  logging  system  must  attach  appender  logger  whenever  appender  service  registered,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4423,enable  logback  changeleveldispatcher  default  jul  integration  enabled  logback  possible  use  changeleveldispatcher  1  minimize  performance  impact  currently  one  need  explicitly  enable  logbackxml  via  codexml  configuration  contextlistener  classchqoslogbackclassicjullevelchangepropagator  configuration  code  would  better  logback  integration  logic  add  listener  orgapacheslingcommonslogjulenabled  set  true  without  requiring  explicit  user  effort  tweak  logback  xml  config  1  httplogbackqoschmanualconfigurationhtmllevelchangepropagator,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
4424,rename  µjax  sling  client  library  discussed  recently  1  reducing  number  name  different  sling  component  help  people  make  sense  idea  rename  µjax  stuff  sling  client  library  suppose  ujaxpostservlet  renamed  slingpostservlet  discussion  using  catapult  name  thats  good  name  well  keep  store  later  1  httpmarkmailorgmessage5yeuwlbsj6m7da6o,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4425,implement  suggestion  sling3223  sling  replication  umbrella  issue  track  implementation  improvement  sling  replication  suggested  sling3223  comment  main  one  refer  test  fix  javadoc  typo  avoid  adapterfactory  installing  package  fix  action  name  refactor  authenticationhandlers,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
4426,singauthenticator  improve  repository  sanity  check  currently  slingauthenticator  sometimes  behaves  funny  way  repository  available  accepting  logins  reason  anonymous  access  allowed  example  login  box  might  appear  repository  becomes  unavailable  make  thing  confusing  attached  patch  improves  situation  verifying  admin  session  obtained  repository  throw  missingrepositoryexception  allow  better  handling  repository  problem  higher  application  layer  im  sure  implication  assume  admin  session  required  thing  work  please  review  patch  apply  feel  free  apply  ill  mostly  offline  easter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4427,make  sling  import  dynamic  currently  import  sling  auth  core  sling  api  resource  mandatory  mean  security  provider  active  sling  running  import  rather  dynamic  provider  also  run  repository  available,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4428,switch  login  page  user  allowed  access  web  console  right  current  user  allowed  access  web  console  forbidden  returned  rather  redirect  login  page  instead,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4429,provide  healthcheckexecutor  service  goal  able  get  overall  aggregated  result  quickly  possible  ideally  2sec  whenever  possible  return  current  result  eg  memory  check  provide  declarative  way  async  check  async  check  exception  though  approach  run  check  parallel  make  sure  long  running  even  stuck  check  timed  health  check  must  run  asynchronously  execution  time  cannot  optimized  enough  specify  service  property  eg  hcasync  see  also  httpapachesling73963n3nabblecomhealthcheckimprovementstd4029330htmla4029402  httpapachesling73963n3nabblecomhealthchecksexecutionservicetd4028477html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4430,leverage  improved  observation  support  oak  oak1120  introduces  better  support  observation  could  used  sling  example  jcrresourcelistener  could  rewritten  leveraging  oak  observer  since  oak  observer  already  run  background  thread  decoupling  like  currently  done  necessary  make  unnecessary  queue  potentially  lot  event  sling  since  neither  oak  queue  event  generated  need  probably  greatly  improve  scalability  face  many  event  furthermore  osgi  filter  could  passed  translated  oak  filtering  done  much  closer  source  event  finally  instead  using  centralised  event  dispatcher  like  jcrresourcelistener  currently  would  better  install  dedicated  observer  osgi  event  listener  since  dispatching  already  handled  oak  thread  pooling  ie  assigning  thread  dispatching  call  back  observer  controlled  sling  thread  pool  support  advantage  making  individual  stats  available  listener  jmx  register  oakexecutor  backed  eg  sling  thread  pool  picked  oak,1,0,1,0,1,0,0,0,1,0,1,1,1,0,0,0,1
4431,long  startup  time  many  vanitypath  many  vanitypath  alias  present  system  take  long  time  startup  vanitypathalias  removed  updated  reason  behind  usage  query  update  global  mapentry  added  new  test  performance  test  suite  outcome  code  0  vanitypath  16ms  1  vanitypath  19ms  10  vanitypath  70ms  100  vanitypath  111ms  1000  vanitypath  200ms  10000  vanitypath  1173ms  30000  vanitypath  3358ms  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4432,optimize  jcrpropertymapescapekeyname  escaping  use  sessiongetnamespaceprefixes  method  every  single  property  relatively  heavy  method  called  per  instance  stored  member  variable  reduce  significantly  number  call  prefix,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4433,allow  flushing  external  caching  system  allow  signaling  http  external  caching  system  content  hierarchy  changed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4434,provide  annotationdriven  approach  create  model  object  ive  working  model  factory  approach  whiteboard  think  state  formally  named  sling  model  moved  extension  httpsvnapacheorgreposasfslingwhiteboardjustinyamf  code  would  repackage  renamed  appropriate  see  httpscwikiapacheorgconfluencedisplayslingyamfyetanothermodelfactory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4435,remove  package  processed  replication  package  used  cleanup  resource  occupied,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4436,allow  asynchronous  package  import  let  replicationpackageimporter  able  import  replication  package  stream  asynchronously  involve  queue  future  may  worth  moving  functionality  directly  polling  agent  existing  queue  provider  queue  distribution  strategy  used  also  package  import,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4437,add  ability  replicate  multiple  enpoints  add  ability  replicate  multiple  endpoint  order  support  broadcasting  clustered  environment  implementation  also  configurable  strategy  broadcast  one  cluster  support  also  polling  multiple  source,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1
4438,simplify  feature  flag  api  feature  flag  api  currently  quite  complex  involving  helper  object  making  query  featureflag  status  quite  complex  also  setting  current  context  clumsy  currently  two  filter  propose  change  remove  clientcontext  object  checking  feature  enablement  simple  calling  featuresisenabledfeaturename  currently  curent  clientcontext  retrieved  isenabled  method  called  b  feature  flag  value  egerly  evaluated  done  demand  making  context  setup  much  quicker  lightweight  added  performance  evaluation  result  still  cached  c  duplicate  filter  removed  code  directly  grabbing  resourceresolver  request  attribute  like  slingmainservlet  thanks  carstenz  hint  dont  currently  need  explicit  context  management  servlet  filter  directly  using  internal  api  e  wonder  whether  need  feature  accessors  feature  service  look  like  convenience  method  particularly  one  getfeaturenames  getfeatures,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
4439,expose  osgi  configuration  via  http  need  safe  way  expose  osgi  configuration  via  http  requirement  configs  certain  factory  manageable  associated  jcr  node  contain  config  property  configs  available  configurationadmin  available  http  url  friendly  name  optional  implementation  general  enough  used  configs  replication  needed  example  configuration  name  publish  orgapacheslingreplicationagentimplreplicationagentservicefactory  mapped  etcreplicationagentpublish  problem  current  implementation  jcr  node  created  jcr  installed  configuration  file  read  created  appsconfig  libsconfig  easy  way  determine  active  configurationadmin  way  restrict  repository  path  create  configuration  specified  factory  making  unusable  relaxed  acls  url  configuration  unfriendly  contains  fully  qualified  name  factory  node  type  homogenous  making  hard  use  client  application  ntfile  slingosgiconfig,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
4440,expose  import  queue  reverse  replication  replicationagent  interface  replication  agent  3  main  queue  request  queue  transport  queue  response  queue  queue  accessible  manageable  replicationagent  interface  issue  relates  implementation  response  queue  inside  replicationagent  making  accessible  replicationagentgetqueue  api  response  queue  queue  reverse  replication  author  store  package  publish,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4441,bootdelegation  support  third  party  library  requirement  1  bootdelegate  third  party  library  sling  osgi  framework  2  bootdelegated  class  resource  looked  configured  third  party  jar  similar  class  parent  classloaders  leak  system  case  arises  usually  web  deployment  scenario  infact  want  bootdelegate  rsa  library  time  prevent  interference  parent  classloaders  web  deployment  model  approach  1  extend  slinglauncherclassloader  scan  predefined  path  say  launchpadhomelibetx  jar  file  add  classpath  done  startup  slinglauncherclassloader  try  load  class  classpath  trying  parent  classloaders  currently  done  orgapacheslinglaunchpadbasejar  2  package  configured  bootdelegation  using  sling  property  slingbootdelegationclassany  bootdelegated  classbootdelegated  package,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4442,reduce  memory  footprint  jcrresourcelistener  jcrresourcelisteneroneventeventiterator  keep  reference  event  instance  passed  iterator  turned  memory  bottleneck  eg  scenario  large  subtree  copied  nodeadded  event  node  subtree  generated  furthermore  oak  able  handle  arbitrarily  large  transaction  sessionsave  case  eventiterator  might  contains  million  event,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4443,introduce  backoff  strategy  topology  connector  frequency  currently  topology  heartbeat  sent  every  15  30  sec  might  seem  lot  –  especially  way  chatty  fixed  sling3377  suggestion  fmeschbe  lower  heartbeat  frequency  main  reason  high  heartbeat  frequency  quicker  failure  detection  –  obviously  tradeoff  increase  load  here  proposal  tackle  introduce  two  different  set  heartbeat  one  repository  one  connector  repository  one  would  remain  current  frequency  suggested  default  30sec  interval  60sec  timeout  idea  would  want  detect  crash  within  cluster  rather  quickly  quickly  topology  general  connector  would  get  backoff  behavior  initially  value  30sec60sec  send  le  frequent  heartbeat  time  reaching  max  eg  5min  would  controlled  receiving  side  ie  side  connector  agree  interval  timeout,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4444,simplify  abstractslingrepository  implementation  introduction  slingrepositoryloginservice  method  existing  setup  abstractslingrepository  became  quite  complex  hack  slingrepository  proxy  able  register  slingrepository  service  implement  new  method  additional  problem  abstractslingrepository  class  expects  implementation  implemented  using  declarative  service  simple  easy  beginning  created  runtime  dependency  go  well  osgi  framework  propose  create  new  couple  abstract  class  simplify  setup  implementation  slingrepository  service  another  feature  original  abstractslingrepository  base  class  access  foreign  repository  well  repository  pinging  turn  functionality  usefull  abstract  base  class  rather  would  something  actual  implementation  know  deal  preexisting  foreign  repository  instance,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
4445,discovery  reduce  write  activity  discovery  heartbeat  discussed  list  0  way  reduce  writes  repository  topology  connector  announcement  ticket  1  2  mentioned  thread  completeness  sake  1  store  announcement  lastheartbeat  value  ie  created  value  separate  property  instead  part  json  plus  update  json  anything  changed  2  dont  store  announcement  lastheartbeat  created  instead  change  logic  announcement  valid  long  containerinstance  instance  received  stored  announcement  alive  increase  reaction  time  slightly  worst  case  x2  case  containing  instance  instance  part  announcement  crash  within  heartbeat  interval  0  httpmarkmailorgthread2ev5sy3b3mr5klc5,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
4446,implement  job  acknowledge  currently  acknowledge  someone  interested  processing  job  result  problem  job  might  end  locked  repository  ever  noone  interested  processing  kind  job  couldbe  solved  requiring  job  processor  acknowledges  receival  job  thereby  indicates  process  job  could  also  used  deny  processor  job  job  acknowledged  specified  timeout  job  removed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4447,support  multiple  bundle  jarwebsupport  launchpad  plugin  allows  define  http  service  implementation  specified  jarwebsupport  property  property  currently  support  single  bundle  felix  jetty  http  service  implementation  refactored  felix4427  export  api  anymore  thus  http  service  api  servlet  api  provided  one  additional  bundle  hence  jarwebsupport  property  extended  support  multiple  bundle,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4448,improve  parameter  support  discussed  dev  list  1  sling  request  parameter  support  extended  improved  provide  list  request  parameter  order  specified  request  servlet  api  define  order  servlet  container  may  may  respect  order  parameter  map  official  api  get  list  request  parameter  actual  order  defined  request  support  servlet  api  30  style  multipartformdata  request  make  sure  request  parameter  uniformely  supported  servlet  conainers  respect  character  encoding  size  restriction  corollary  servlet  api  3  support  request  parameter  might  also  want  extend  servletcontext  api  implement  servlet  api  3  method  even  though  throw  1  httpslingmarkmailorgthreadysz5sxpb6wkuelzd,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4449,enable  webdav  sling  default  workspace  sling  currently  jcrwebdav  module  provides  webdav  simplewebdavservlet  servlet  context  configurable  default  dav  default  support  requires  including  name  workspace  access  url  additional  support  webdav  added  allows  webdav  access  default  workspace  used  sling  sling  main  servlet  sling  servlet  registered  implement  webdav,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4450,resourceaccesssecurity  secure  access  update  operation  resourceaccesssecurity  use  gate  registered  update  operation  order  secure  access  modifiable  value  map,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4451,get  foohtml  return  equivalent  empty  node  discussed  slingdev  get  magic  star  thread  1  1  httpwwwmailarchivecomslingdevincubatorapacheorgmsg03603html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4452,avoid  shared  resource  resolver  usage  servlet  resolver  us  single  shared  rsource  resolver  resolve  script  resource  resolvers  thread  safe  therefore  used  time  different  thread  apart  creates  bottleneck  repository  implementation  jackrabbit  oak  synchronize  access  case  ultimately  synchronises  request  even  problematic  servlet  resolver  hit  alot  single  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4453,webconsoleclient  support  bundle  start  level  webconsoleclientinstallbundle  need  optional  start  level  parameter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4454,internal  refactoring  better  support  metaannotations  metaannotations  currently  support  source  code  flexible  note  issue  doesnt  actually  add  metaannotation  support  make  addition  support  easier  future,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4455,add  sling  replication  exposed  resource  provide  integration  test  resource  exposed  sling  replication  check  one  exposed  given  certain  runmode  possibly  restrict  access,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1
4456,facilitate  writing  integration  test  multiple  instance  facilitate  writing  integration  test  multiple  instance  needed  better  testing  feature  like  replication  topology  discovery  create  base  class  test  way  configure  multiple  instance  also  sample  integration  test,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0
4457,expose  json  servlet  helper  right  following  class  used  jsonrendererservletare  exported  bundle  developer  perspective  may  want  use  class  remix  resource  json  functionality  without  rewrite  code  httpssvnapacheorgreposasfslingtrunkbundlesservletsgetsrcmainjavaorgapacheslingservletsgetimplhelpersjsonobjectcreatorjava  httpssvnapacheorgreposasfslingtrunkbundlesservletsgetsrcmainjavaorgapacheslingservletsgetimplhelpersresourcetraversorjava  propose  refactor  class  package  orgapacheslingservletsgethelpers  expose  osgi  container,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4458,make  compositehealthcheck  use  healthcheckexecutor  parallel  execution  compositehealthcheck  used  fairly  heavily  wellknown  product  1  2  would  good  make  parallel  execution  available  compositehealthcheck  well  would  also  line  web  console  already  using  healthcheckexecutor  attached  patch  us  healthcheckexecutor  shortening  implementation  compositehealthcheckexecute  quite  bit  need  detect  cycle  configuration  different  way  threadlocal  work  anymore  come  unit  test  test  execution  cycle  detection  1  httplocalhost4502systemslingmonitoringmbeansorgapacheslinghealthcheckhealthchecksystemchecksjson  2  httplocalhost4502libsgraniteoperationscontenthrhtmlsystemslingmonitoringmbeansorgapacheslinghealthcheckhealthchecksecuritychecks,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4459,improve  handling  update  mapping  alias  vanity  path  update  handling  mapping  including  alias  vanity  path  simple  algorithm  simply  update  whole  mapping  especially  large  mapping  info  spread  across  repository  simple  update  single  property  result  whole  mapping  info  recreated  would  great  could  improved  right  active  mapping  hold  memory  change  single  property  might  cause  activate  totally  different  mapping  one  changed  eh  ordering  changed  update  need  complex  information  need  hold  memory  addition  consider  like  vanity  path  info  changed  new  value  available  old  gone,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4460,add  ability  configure  osgi  component  crank  file  user  able  specify  osgi  configs  inside  cranktxt  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4461,separate  node  name  content  type  content  loader  extend  api  node  name  content  type  currently  taken  file  name,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
4462,integration  test  running  live  sling  launchpad  instance  lot  moving  part  still  quite  bug  come  transporting  content  tofrom  sling  instance  would  helpful  create  test  harness  validates  way  transportreadwritefilter  content  correct  help  fixing  various  bug  related  content  sync,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4463,run  findbugs  fix  accordingly  sling  replication  code  sling  replication  code  grown  time  id  like  fix  current  problem  reported  findbugs  b  add  reporting  entry  pomxml  order  continuously  able  check  eventual  problem,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4464,allow  importing  content  arbitrary  location  current  import  wizard  process  whole  project  problematic  large  project  import  would  take  lot  time  also  time  developer  make  small  change  repository  want  sync  back  workspace  support  scenario  need  allow  importing  content  arbitrary  location  content  sync  root,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4465,make  repositoryfactory  statefull  allow  repository  stopped  moment  stateless  repositoryfactory  ie  provides  newrepository  creates  new  repository  time  fine  long  repository  stateless  introduction  nodetyperegistry  example  repository  initialization  also  heavyweight,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4466,allow  performance  test  report  custom  class  name  report  logger  allow  performance  test  overwrite  class  name  passed  junit  runner  report  logger  useful  test  factory  like  sling3294  break  sling2727  force  tostring  method  test  class  proposed  solution  allows  test  case  implement  identifiableclassnametestclassname,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4467,remove  embedded  tomcat  juli  jar  overriding  logfactory  delegate  slf4j  datasource  provider  bundle  currently  embed  tomcat  juli  jar  38  kb  required  tomcat  jdbc  easily  removed  inlining  overriding  orgapachejulilogginglogfactory  implementation  delegate  slf4j,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1
4468,sling  console  keep  console  history  since  start  idea  currently  slingconsoleeventlistener  throw  away  event  console  showing  null  even  though  might  standard  imho  could  useful  listener  keep  history  limit  show  soon  console  started  reasoning  dont  always  start  console  right  away  startup  likely  run  issue  point  dont  history  yetanymore,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4469,usability  improvement  sling  bundle  module  wizard  couple  issue  improved  wizard  archetype  selection  dropdown  span  multiple  line  misaligned  server  selection  page  default  add  existing  server  one  already  exists  server  location  preselect  existing  server  one  exists,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4470,debug  based  bundle  deployed  server  offline  discussion  mpetria  following  item  came  debugging  sling  application  large  number  bundle  hard  synchronise  source  workspace  server  would  good  able  debug  application  based  information  running  bundle  eg  maven  artifact  retrieve  source  associated  project  trivial  worth  looking,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
4471,add  slinghealthcheck  annotation  add  slinghealthcheck  annotation  similar  slingservlet  metatype  property  set  true  per  default  since  probably  common  configure  healthchecks  usage  example  codetitleexamplesborderstylesolid  slinghealthcheckname  bundlesstartedcheckhcname  label  apache  sling  health  check  bundlesstartedcheckhcname  description  check  whether  bundle  started  tag  osgi  slinghealthcheckname  diskspacecheckhcname  label  apache  sling  health  check  diskspacecheckhcname  description  check  whether  enough  disk  space  available  tag  resource  configurationfactory  true  configurationpolicy  configurationpolicyrequire  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4472,add  support  resourcebundle  base  name  httpmarkmailorgmessage6ikv4wfabqtnmajk  1  base  name  concept  resourcebundle  base  name  derived  resourcebundlegetbundlestring  basename  factory  method  return  resourcebundle  given  base  name  resourcebundlegetbundle  factory  method  look  resourcebundle  implementation  eg  listresourcebundle  class  property  file  propertyresourcebundle  class  sling  implementation  new  resourcebundle  resourcebundleprovidergetresourcebundlestring  basename  locale  locale  method  us  extended  query  find  matching  resource  basic  query  find  resource  node  node  type  mixlanguage  property  jcrlanguage  whose  value  string  representation  locale  extended  query  would  also  consider  new  property  slingbasename  lanugage  node  considered  jcrlanguage  property  match  locale  slingbasename  property  match  basename  slingbasename  property  defined  new  mixin  node  type  slinglanguage  mixlanguage  mixin  slingbasename  string  slingbasename  string  multiple  slingbasename  may  singlevalued  multivalued  property  thus  language  node  may  apply  multiple  basenames  base  name  generally  application  identifier  addition  slinghttpservletrequest  interface  extended  resourcebundle  getresourcebundlestring  basename  locale  locale  allows  request  easily  get  basenamed  resource  bundle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4473,support  modifying  datasource  property  runtime  without  restart  tomcat  jdbc  pool  support  changing  connection  pool  property  runtime  also  sling  datasource  provider  support  avoid  deregistration  datasource  service  much  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4474,checkin  versionable  node  initial  content  discussed  1  bundle  developer  able  decide  wether  versionable  node  initial  content  checked  content  imported  1  httpwwwmailarchivecomslingdevincubatorapacheorgmsg03804html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4475,jcr  property  view  boolean  value  validated  according  type  property  value  jcr  property  view  validated  according  boolean  property  type  possible  enter  value  boolean  type,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4476,refine  connected  state  vlt  repository  cache  node  type  disconnection  properly  currently  serverutilgetdefaultrepository  always  return  valid  repository  getnodetyperegistry  turn  connects  server  load  node  type  seemed  convenient  problem  doesnt  give  user  control  connect  server  result  connection  error  place  user  maybe  didnt  intend  know  connection  would  done  hence  new  simpler  schema  server  stopped  repository  connection  established  including  node  type  registry  hence  stopped  server  node  type  registry  null  hence  action  require  adjustment  situation  server  started  connected  repository  connected  node  type  registry  loaded  stage  node  type  registry  used  various  action  including  code  completion  property  type  display  server  stopped  node  type  registry  cached  still  provided  various  action  without  server  interaction  going  though  intuitive  make  initial  contentbrowsing  offline  mode  simpler,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4477,add  cut  copy  paste  node  content  navigator  daytoday  activity  able  manipulate  node  content  navigator  cut  copy  paste  operation  really  critical  cc  fvisser,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4478,better  default  handling  script  selection  currently  scriptedcomponent  analyzes  registered  script  fall  back  default  script  called  jspstartjsp  default  selection  extended  request  selector  see  componentrequestgetselectors  contrubute  script  selection  follows  first  apply  registered  script  mapping  scriptedcomponent  next  use  request  selector  find  script  scripted  component  node  second  step  resolve  script  selector  exist  use  startjsp  script  component  node  second  step  need  explanation  selector  request  joined  interleaving  slash  form  relative  path  path  appended  path  scripted  component  name  script  assumed  startjsp  path  exist  trailing  element  removed  longest  match  tried  found  example  1  request  samplehtml  selector  exist  startjsp  script  component  used  2  request  sampleimagegif  selector  single  entry  list  image  first  script  imagestartjsp  checked  exist  startjsp  used  3  request  sampleimage80x80gif  selector  twoentry  list  image  80x80  following  script  tested  order  image80x80startjsp  imagestartjsp  startjsp,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4479,sling  model  allow  caller  deal  exception  currently  due  specification  adapttomethod  return  null  adaptation  possible  caller  notified  exception  caught  within  modeladapterfactory  eg  necessary  deal  validation  exception  properly  ie  required  field  injection  possible  problem  also  discussed  briefly  httpapachesling73963n3nabblecomsilngmodelsvalidationframeworktd4033411html  exception  either  thrown  postconstruct  method  caused  fieldmethod  injection  propagated  basically  swallowed  sling  model  would  great  able  catch  exception  either  view  servlet  filter  think  possible  throw  unchecked  exception  modeladapterfactorygetfactory  method  requested  ie  global  osgi  configuration  flag  sling  model  wdyt  would  accept  patch  think  break  api  also  compare  httpsissuesapacheorgjirabrowsesling2712focusedcommentid13561516pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment13561516  work  adaptto  slingmodels  provide  alternative  way  instanciating  model  propagating  exception  although  kind  tricky  internally  relies  adaptto  well  eg  httpsgithubcomapacheslingblobtrunkbundlesextensionsmodelsimplsrcmainjavaorgapacheslingmodelsimplmodeladapterfactoryjaval647,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
4480,sling  model  add  support  constructor  dependency  injection  currently  sling  model  support  dependency  injection  field  interface  getter  method  constructor  argument  ticket  discussing  constructor  dependency  injection  support  perhaps  finally  provide  patch  implement  somewhat  related  sling3715  classbased  dependency  injection  would  come  especially  handy  constructor  injection,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,1,1
4481,osgi  installer  intelligently  manage  start  level  artifact  handling  osgi  installer  made  intelligent  deciding  handle  bundle  update  multiple  bundle  need  updated  eg  lowering  system  start  level  updating  important  bundle  updating  large  number  bundle  reduce  oscillation  system  thus  reduce  update  time  increase  stability  thought  around  per  fmeschbe  bundle  installation  problematic  dont  need  treated  specially  bundle  update  uninstallations  may  cause  system  oscillated  service  may  come  go  update  package  refreshes  bundle  central  bundle  example  bundle  providing  jcr  repository  service  used  almost  system  bundle  may  important  certain  threshold  api  importing  bundle  reached  eg  sling  api  bundle  one  registered  service  used  certain  threshold  consumer  least  one  important  bundle  updated  uninstalled  single  batch  osgi  installer  reduce  system  start  level  handling  batch  raise  start  level  batch  start  level  system  reduced  lower  start  level  osgi  installer  helper  bundle  probably  task  provides  start  level  important  bundle  handled  batch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4482,i18nperformance  optimize  initialization  resourcebundle  cache  ran  performance  issue  described  sling2881  jcrresourcebundleprovider  clear  cache  mixlanguage  change  updated  sling  i18n  bundle  version  228  however  preloadbundles  flag  set  false  default  system  stalled  put  load  according  analysis  lot  cuncurrent  http  request  requesting  i18n  resourcebundle  cache  yet  initialized  started  loading  repository  system  practically  came  hold  recover  removing  load  waited  10min  believe  might  eventually  recovered  could  identify  deadlock  series  threddumps  suggest  three  improvement  change  default  preloadbundles  true  avoid  http  request  waiting  cache  initialized  ensure  resourcebundle  loaded  cache  cache  empty  order  limit  io  adjust  query  languagerootpaths  return  node  jcrlanguage  property  attached  patch  implement  point  2  3  includes  test  verifies  correct  concurrent  behaviour  test  run  current  implementation  fail  reliably  fail  machine  additionally  verified  fix  local  sling  instance  using  apache  bench  ab  finally  production  system  production  system  loaded  resourcebundles  four  language  recovered  load  second  could  kindly  review  patch  apply  change  thank,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4483,jsonrendererservlet  provide  way  list  child  array  default  json  renderer  print  child  node  another  keyvalue  attribute  browser  respect  order  printed  response  object  attribute  since  standard  describe  lot  case  continue  writing  servlets  print  child  json  array  respect  order  imo  default  renderer  provide  selector  change  output  print  child  array  pr  httpsgithubcomapacheslingpull23,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
4484,add  test  refactor  json  string  conversion  there  code  duplication  jsonobject  jsonarray  jsonwriter  come  creating  json  string  test  coverage  low  improve  allow  extension  like  sling3776  introduced  without  breaking  existing  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4485,use  flow  operation  forward  reverse  replication  current  replication  code  treat  differently  forward  reverse  replication  forward  replication  creates  content  package  add  queue  transport  instance  reverse  replication  creates  dummy  poll  package  transport  instance  retrieves  result  queue  installs  current  instance  current  flow  reverse  replication  complicates  code  structure  simplified  using  three  main  entity  1  package  importer  importinstall  replication  package  1a  replicationpackageimporter  1b  replicationpackageimporterservlet  bound  replicationimporter  resource  type  1c  httplocalhost4502libsslingreplicationimportersjson  2  package  exporter  export  create  replication  package  2a  replicationpackageexporter  2b  replicationpackageexporterservlet  bound  replicationexporter  resource  type  2c  httplocalhost4502libsslingreplicationexportersjson  3  replication  agent  coordinate  interaction  exporter  importer  using  following  flow  export  package  add  queue  import  package  3a  replicationagent  3b  replicationagentservlet  bound  replicationagent  resource  type  3c  httplocalhost4502libsslingreplicationagentsjson  basically  forward  replication  exporter  local  importer  remote  reverse  replication  difference  exporter  remote  importer  local,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4486,add  simple  javascript  rhino  wrapper  version  versionhistory  interface  sling382  reported  issue  handling  jcr  version  versionhistory  object  wrapped  jcr  node  cause  wrapper  interface  version  versionhistory  extend  node  node  wrapper  used  prevents  using  version  versionhistory  method  sling382  implemented  workaround  think  correct  solution  would  add  simple  wrapper  version  versionhistory  object  extend  scriptablenode  wrapper  thus  provide  version  versionhistory  method  well  node  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
4487,cleanup  replicationagent  interface  replicationagentconfiguration  replicationagent  minimal  interface  specifically  client  able  schedule  replicationrequest  visualize  replicationqueues  decide  synchronous  execution  needed  properly  implemented  current  version  synchronous  also  agent  configuration  particular  simplereplicationagent  implementation  true  single  implementation  cannot  api  unless  decide  fixed  set  property  agent  implementation  either  way  configuration  currently  accessible  custom  resource  provider,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0
4488,allow  deep  v  shallow  replication  option  user  replication  way  choose  whether  replicate  node  deep  including  subtree  shallow  including  node  property  typically  user  editing  content  visually  trigger  replication  edited  content  shallow  however  user  importing  lot  content  trigger  deep  replication  content  imported  shallow  replication  targeted  produce  least  change  system  probably  best  fitted  default  replication  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4489,reorganize  replicationpackage  related  api  single  java  package  currently  replicationpackage  apis  implementation  split  serialization  transport  need  unify  packaging  keep  internal  subpackages  serialization  transport  utils  apis,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4490,jcrnoderesource  take  long  initializes  much  soon  performance  test  expected  reflect  reasonably  realworld  condition  50  concurrent  user  mixed  load  forum  type  application  found  orgapacheslingjcrresourceinternalhelperjcrjcrnoderesourcejcrnoderesourceresourceresolver  node  classloader  taking  20  time  used  majority  time  spent  setting  resource  metadata  lesser  extent  resource  type  metadata  especially  often  accessed  even  resource  type  always  accessed  delaying  initialization  led  noticeable  performance  improvement  attached  patch  delay  resourcetype  lookup  metadata  lookup  needed,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
4491,add  configuration  option  restrict  service  user  mapper  system  user  jcr3802  introduces  concept  system  user  distinct  regular  user  account  never  password  set  api  extension  include  following  ability  discover  given  user  actually  system  user  userissystemuser  would  good  service  user  mapping  configuration  option  would  restrict  mapping  dedicated  service  user  ie  user  defined  system  user  case  sling  running  jcr  repository  implement  jackrabbit  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4492,sling  model  max  recursion  depth  configurable  currently  maximum  recursion  depth  hard  set  20  modeladapterfactory  made  configurable,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4493,configure  continous  event  polling  using  exclusively  rule  string  replicateonqueueeventrule  trigger  poll  request  using  server  side  event  remote  endpoint  initially  obtained  configuration  inspecting  configuration  transport  handler  however  introduced  tight  coupling  obtaining  piece  configuration  provided  directly  rule  code  remote  trigger  url  user  user  password  password  code,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
4494,create  replicationtriggers  http  accessible  variant  replicationrule  replicationrules  way  signaling  replicationrequest  external  user  however  take  configuration  time  handler  registration  need  concept  completely  configured  via  osgi  order  make  accessible  via  http  able  expose  rule  via  http  order  trigger  replication  event  published  remote  instance  example  url  trigger  generates  poll  request  fixed  interval  look  like  code  httplocalhost4503libsslingreplicationservicestriggersscheduledpoll  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4495,add  resource  path  injector  useful  able  inject  resource  path  either  static  path  path  defined  property,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4496,sling  model  support  adapter  model  different  implementation  class  currently  adapter  adaption  target  implementation  class  annotated  model  annotation  supported  either  interface  class  model  simple  model  class  complex  business  logic  following  scenario  required  service  interface  defined  service  interface  ist  directly  mapped  injected  value  provides  higherlevel  method  implementation  class  model  annotation  implemented  get  required  value  injectd  internally  implement  interface  outside  access  currently  possible  sling  model  attached  patch  extends  following  feature  extends  model  annotation  optional  adapter  attribute  defined  listed  adapter  registered  adapter  factory  implementation  class  unless  listed  adapter  attribute  well  adapter  attribute  implementation  class  interface  implement  superclass  defined  scenario  perfectly  possible  unit  test  included  simulate  bundle  addremove  usecases  required  indirect  implementation  class  mapping,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4497,resourceresolvermock  make  compatible  jcr  resource  attached  patch  enhances  resourceresolvermock  implementation  feature  missing  make  behave  jcrlike  support  resource  property  support  converting  date  object  calendar  vice  versa  support  storing  retrieving  binary  data  using  inputstreamclass  return  value  property  jcrprimarytype  resource  type  resource  type  defined  add  unit  test  whole  sling  crud  behavior  speciality,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4498,method  constructor  injection  support  adapting  list  element  currently  listadaptable  object  converted  listsomethingelse  necessary  happens  field  injection  universal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
4499,add  replication  agent  factory  create  agent  component  single  configuration  file  currently  simplereplicationagentfactory  configure  replicationagent  subcomponents  order  make  management  agent  simpler  need  way  fully  configure  agent  one  configuration  file  retain  also  possibility  referencing  osgi  service,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1
4500,access  content  replication  behalf  user  triggered  replication  currently  content  accessed  via  administrative  session  need  pas  resourceresolver  via  apis  ensure  content  accessed  user  right  rule  triggered  request  action  done  behalf  replicationserviceuser,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
4501,replication  transport  authenticator  hide  credential  transport  authentication  credential  present  configuration  agent  currently  see  sling3898,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4502,allow  configuration  trigger  agent  configuration  file  currently  rule  configurable  agent  however  rule  verbose  configuration  scheme  inappropriate  complex  configuration  able  configure  directly  trigger  agent  key  value  pair  configuration  see  sling3898  similar  config  style  code  trigger  trigger0typescheduled  trigger0actionpoll  trigger0interval30  trigger1typeremote  trigger1endpoints0httplocalhost4503libsslingreplicationservicestriggerscontentevent3600000  trigger1authenticationpropertiesuseradmin  trigger1authenticationpropertiespasswordadmin  trigger1endpoints0httplocalhost4503libsslingreplicationservicesexportersreverse  trigger1authenticationfactorytypeservice  trigger1authenticationfactorynameuser  code,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,1
4503,launchpad  controllistener  improvement  involved  customer  report  indicating  controllistener  would  work  customer  issued  stop  command  upon  system  shut  seems  case  customer  tried  issue  stop  time  though  connection  control  port  could  opened  command  answered  looking  situation  look  like  first  command  issue  shutdown  caused  deadlock  server  side  socket  terminating  control  thread  waiting  sling  shutdown  waiting  shutdown  control  thread  could  course  accept  new  command  even  though  tcpip  connection  setup  prevent  situation  proposing  extension  launchpad  controllistener  listens  tcpip  control  port  status  stop  command  calling  stop  start  separate  thread  shutdown  sling  asynchronously  controllistener  thread  issued  stop  command  controllistener  reply  stopping  status  command  adding  new  thread  command  controllistener  print  thread  dump  similar  jdk  jstack  command  includes  thread  well  dumping  potential  deadlock  new  unit  test  contains  two  thread  class  provoke  deadlock  show  thread  dumper  report  deadlock,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4504,remove  saveprefix  support  saveprefix  parameter  intended  identify  required  prefix  parameter  name  considered  content  modification  use  case  behind  prefixing  might  want  form  contain  mix  gui  provided  parameter  gui  toolkits  seem  add  parameter  used  content  update  case  content  parameter  could  prefixed  could  considered  reality  value  used  prefixing  saveprefix  never  used  fact  slingpostservlets  modification  operation  scan  parameter  prefixed  saveprefix  set  decides  upon  using  prefix  thus  issue  following  change  remove  saveprefix  parameter  support  prefix  used  hardcoded  parameter  prefix  found  parameter  starting  considered  content  update  parameter  prefix  found  parameter  starting  operation  parameter  prefix  considered  content  update,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4505,refactor  replicationqueue  api  eliminate  multiagent  queue  currently  queue  related  api  replicationqueueprovider  replicationqueuedistributionstrategy  take  argument  agentname  reason  happen  typically  queue  provider  configured  single  agent  also  replicationqueuedistributionstrategy  two  method  add  offer  one  used  clear  reason  two,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
4506,errorawarequeuedistributionstrategy  implemented  importerdistributionstrategy  treating  replication  error  done  right  import  package  queuing  done  hence  might  need  define  different  extension  point  importerdistributionstrategy  treat  error  place,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4507,resourceproviderentry  poll  viable  modifyingresourceproviders  creation  deletion  currently  resourceproviderentry  creation  deletion  resource  send  creation  deletion  request  first  viable  modifyingresourceprovider  problematic  multiple  modifyingresourceproviders  may  viable  particular  path  consider  following  situation  create  resource  provider  listens  content  participate  resource  listing  call  path  however  necessarily  handle  resource  content  root  jcrresourceprovider  also  expected  handle  resource  path  work  fine  various  get  method  however  modification  custom  resource  provider  always  get  chosen  first  able  create  resource  creation  request  fall  back  le  specific  provider  root  provider  even  though  provider  might  well  able  create  resource  common  pattern  across  many  resourceresolver  operation  poll  viable  resource  provider  example  getresource  iterate  viable  resource  provider  order  path  specificity  stopping  one  able  return  resource  attached  patch  implement  similar  mechanism  create  delete  command  create  iterate  viable  modifyingresourceproviders  order  specificity  stopping  one  actually  produce  resource  delete  iterate  viable  modifyingresourceproviders  giving  crack  deleting  resource,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4508,export  transportauthenticationprovider  replicationcomponentprovider  replication  bundle  export  transportauthenticationprovider  replicationcomponentprovider  replication  bundle  need  interface  able  provide  custom  transportauthenticationprovider  implementation,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4509,make  dependency  config  admin  optional  setting  bundle  requires  config  admin  heavy  dependency  simply  setting  bundle  make  optional  lazy,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1
4510,simplify  dependency  management  letting  caller  supply  implementation  replication  core  bundle  expose  generic  component  factory  creates  replication  component  based  property  map  caller  createcomponent  also  provide  map  default  implementation  service  done  passing  componentprovider  allows  define  specialized  osgi  factory  bind  directly  service  simplifies  dependency  management,0,1,0,1,0,0,0,0,1,0,1,0,0,0,0,0,1
4511,define  proper  contentresolver  service  mapping  request  uri  path  content  object  currently  implemented  urlmapperfilter  registered  request  filter  sling  functionality  currently  usable  instead  mapping  functionality  defined  separate  service  could  name  contentresolver  like  componentresolver  selects  component  service  may  implemented  specifialized  class  class  might  even  provide  extensibility  urlmapperfilter  renamed  contentresolverfilter  match  service  name  would  refactored  use  contentresolver  service  available  log  appropriate  messges  missing  actually  filter  could  service  ensured  filter  would  available  even  absence  repository  provide  meaningfull  error  handling,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4512,separate  content  loading  resource  bundle  content  loading  jcr  resource  handling  split  two  different  bundle  jcrcontentloader  bundle  content  loading,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4513,add  error  marker  project  content  sync  root  exist  various  scenario  lead  content  project  content  sync  root  correctly  configured  moving  directory  although  could  hook  refactoring  participant  nonstandard  location  copying  project  new  workspace  property  perworkspace  saved  setting  directory  prevent  problem  add  error  marker  project  content  sync  root  exist,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
4514,allow  validationmodel  node  jcr  contain  wildcards  child  property  according  httpsgithubcomapacheslingblobtrunkcontribvalidationreadmemd  node  jcr  specifying  validation  model  must  always  give  explicit  property  name  child  node  name  sometimes  possible  subnodesproperties  generated  automatically  therefore  would  great  element  directly  child  property  would  allow  wildcards,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4515,move  osgicommons  commonsosgi  goal  keep  common  stuff  common,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4516,move  jcrdefaultrtp  sample  sample  change  integration  test  theyre  testing  sample  code  well,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4517,testing  donate  slingmock  jcrmock  osgimock  implementation  donate  suite  mocking  library  run  osgiscr  jcr  esp  sling  simulated  inmemory  environment  unit  test  ensuring  minimal  setup  time  us  either  mocked  inmemory  jcr  resourceresolvermock  implementation  already  part  sling  project  additional  convenience  feature  like  bulkloading  json  content  binary  simulated  resource  tree  via  content  loader  make  easy  setting  complex  text  fixture  unit  test,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4518,avoid  keeping  job  memory  currently  job  single  instance  hold  memory  put  queue  optiomal  especially  large  amount  job  addition  make  configuration  change  queue  update  etc  complicated  revert  let  queue  pick  job  resource  tree  free  processing  space,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4519,add  notification  job  added  job  notification  cover  case  except  job  added  shoud  also  clarify  notification  send  locally  never  across  cluster  using  remote  event,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4520,drop  support  propertynotificationjob  event  property  propertynotificationjob  property  notification  event  deprecated  time  still  send  event  remove  property  event,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4521,replication  component  factory  declare  property  accepts  building  component  currently  contract  replicationcomponentfactory  hidden  accepted  property  public  client  factory  able  discover  property  configured  component,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
4522,api  capturemeasure  applicationlevel  metric  provide  api  help  capturemeasure  application  level  metric  ie  timing  counter  etc  running  largemid  scale  application  good  know  statistic  ie  number  request  time  taken  process  request  number  active  request  number  active  job  link  doc  httpsslingapacheorgdocumentationbundlesmetricshtml  code  httpssvnapacheorgreposasfslingtrunkbundlescommonsmetrics  dl  thread  httpmarkmailorgthreadqty2pfxfhgzwcar2  older  httpmarkmailorgthreadcyjc2v34l3lxrtxb,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4523,clean  code  logging  statement  could  clean  unused  code  based  refactorings  done  340  release  addition  logging  statement  might  wrong  log  level  might  missing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4524,jcrslingresourceresolver  mock  support  providing  authentication  info  currently  supported  pas  custom  authentication  info  mocked  resource  resolversession  changed  optionally  allow  eg  simulate  two  different  sessionresource  resolver  two  different  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4525,use  safe  id  replication  package  user  cannot  access  random  file  disk  currently  filevault  package  id  made  file  path  wrap  package  something  le  revealing  like  path  repository,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
4526,sling  model  optimize  performance  read  sling  model  annotation  first  performance  test  sling  application  make  intensive  usage  sling  model  see  potential  hotspot  cost  performance  esp  area  sling  model  attached  filtered  view  jprofile  session  showing  method  call  inside  sling  model  implementation  141028adapttojprofilerslingmodelsgif  good  part  performance  spent  inspection  annotation  sling  model  class  call  graph  first  method  141028adapttojprofilerslingmodelsgetannotationgif  think  especially  case  inspection  take  place  adaptto  call  although  underlying  model  class  never  change  osgi  bundle  stay  place  possible  come  optimization  caching  inspection  result  annotation  exist  fieldsmethodstypes  parameter  injection  part  adaptto  invocation  bundle  change  cache  cleared  think  next  day  perhaps  come  implementation  proposal,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,0
4527,compact  specific  log  requestprogresstrackerlogfilter  requestprogresstracker  currently  log  rpt  message  separate  log  entry  considering  potentially  large  number  log  entry  add  significantly  size  log  file  io  involved  logging  rpt  message  single  log  entry  overhead  reduced  addition  filtering  extension  request  duration  minmax  reduce  log  size  simplify  analysis,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4528,allow  job  consumer  register  topic  subtopics  right  job  consumerexecutor  register  topic  topic  within  package  using  however  event  admin  based  job  processor  consumer  could  subscribe  subtopics  regardless  depth  add  new  pattern  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4529,allow  validator  support  arbitrary  type  currently  validatorvalidate  method  act  string  value  since  type  conversion  already  built  valuemap  would  good  leverage  allow  validator  act  arbitrary  type  also  type  conversion  valuemap  leveraged  type  check  validationserviceimplvalidatepropertyvalue  rather  implementing  new  thing  typeisvalid,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
4530,create  debianubuntu  package  sling  launchpad  standalone  jar  i’m  setting  development  env  team  work  sling  asset  manager  app  wanted  make  env  setup  simple  put  together  debianubuntu  package  orgapacheslinglaunchpad8snapshotstandalonejar  us  jdeb  maven  plugin  it’s  crossplatform  here’s  patch  offchance  it’s  compatible  upstream  policy  need  tuning  let  know  it’s  missing  comment  dev  list  mind  creating  jira  preference  would  contrib  instead  launchpad  folder,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4531,support  sling  validation  new  field  model  annotation  current  way  integrating  sling  validation  sling2803  sling  model  inject  validation  service  call  within  postconstruct  method  httpwwwslidesharenetraducotescuapacheslinggenericvalidationframework16  drawback  validationservice  need  injected  postconstruct  need  implemented  injection  need  marked  optional  otherwise  validation  never  triggered  case  eg  missing  required  valuemap  value  instead  would  good  support  use  case  additional  field  annotation  model  named  validate  default  false  backwards  compatible  true  sling  validation  called  value  injected  model  validation  fails  modeladapterfactory  never  instanciate  model  rather  return  null  throw  meaningful  exception  sling3709,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
4532,introduce  osgicontext  junit  rule  osgi  osgicontextimpl  currently  sling  mock  slingcontext  rule  provides  access  osgi  context  convenience  method  managing  osgi  service  mock  method  moved  new  osgicontext  rule  osgicontextimpl  osgi  mock  used  project  want  use  osgi  sling  well  sling  mock  context  updated  inherit  osgi  context,1,1,0,0,0,1,0,0,0,0,1,0,0,0,0,0,0
4533,osgi  mock  failfast  calling  method  requiring  scr  metadata  present  feature  signature  variant  osgi  mock  require  scr  metadata  available  classpath  currently  ignored  silently  missing  feature  may  fail  without  notice  perhaps  leading  npes  eg  dependency  injected  may  lead  strange  unit  test  failes  esp  using  ides  cannot  generate  scr  metadata  via  maven  plugin  like  eclipse  m2e  fails  sometimes  eg  refreshing  project  without  rebuilding,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
4534,osgi  mock  support  modified  scr  lifecycle  method  currently  activate  deactivate  method  supported  service  support  modified  method  well  required  support  mock  able  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4535,move  slingthreads  commonsthreads  0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4536,add  basic  code  completion  sightly  sightly  part  sling  proper  would  interesting  add  basic  support  autocompletion  html  file  starter  target  wellknown  datasly  attribute  require  introspection  u  angulareclipse  something  similar  see  angular  j  completion  proposal  declarationhttpsgithubcomangelozerrangularjseclipseblobf4c3848bd346260cee7afbce0181043ddb75d598orgeclipseangularjsuipluginxmll171l190  angular  j  completion  proposal  implementationhttpsgithubcomangelozerrangularjseclipseblobf4c3848bd346260cee7afbce0181043ddb75d598orgeclipseangularjsuisrcorgeclipseangularjsuicontentassisthtmlangulartagscompletionproposalcomputerjava,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4537,merge  default  get  servlets  single  one  implementing  sling387  cause  new  scriptservlet  resolution  order  whereas  default  servlets  handled  would  servlets  resource  super  type  resource  type  request  resource  may  happen  example  default  script  registered  handle  gethtml  request  would  selected  instead  script  defined  resource  type  fix  issue  regular  default  get  servlets  html  txt  json  merged  single  default  servlet  registered  get  method  actual  renderes  still  separate  class  new  default  servlet  arbitrates  amongst  renderers,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,1,0
4538,slingpostservlet  refactor  execute  one  operation  time  slingpostservlet  anything  restful  example  possible  request  resource  might  cause  resoure  xy  moved  ef  much  nastier  thing  providing  accurate  response  operation  acting  upon  response  almost  impossible  introducing  multistatus  therefore  slingpostservlet  simplified  follows  servlet  modified  execute  single  operation  per  request  operation  may  createmodify  delete  move  copy  actual  operation  execute  indicated  new  parameter  operation  take  following  value  unset  empty  string  createmodify  request  delete  delete  current  resource  move  move  current  resource  copy  copy  current  resource  addition  mechanism  could  implemented  actual  operation  might  extensible  operation  act  current  resource  requestgetresource  delete  move  copy  operation  fail  current  resource  nonexisting  resource  distinction  create  modify  depends  resource  current  resource  exist  yet  created  special  treatment  resource  creation  happens  path  terminated  slash  proposed  carsten  roy  earlier  message  slashstar  like  currently  name  newly  created  node  defined  today  using  special  parameter  name  namehint  wellknown  content  title  keep  notation  support  request  like  printa4html  operation  create  move  copy  handle  parameter  order  defines  ordering  relation  newly  created  item  behaviour  current  implementation  copy  move  operation  default  fail  item  already  exists  destination  behaviour  may  overwritten  setting  replace  paramter  true  replaces  current  replace  value  copyflags  moveflags  parameter  copy  move  operation  require  another  parameter  dest  destination  path  name  resource  operation  fails  parameter  missing  redirect  parameter  cause  client  redirected  desired  target  case  operation  successfull  behaviour  today  status  parameter  cause  http  status  code  nonstandardscompliant  parameter  value  browser  status  code  always  200ok  even  case  failure  otherwise  status  code  reflect  actual  status  regardless  status  parameter  value  response  always  complete  rundown  operation  executed  actual  status  code  eventual  exception  unless  course  client  redirected  successfull  operation  instructed  redirect  parameter  behaviour  today  rundown  status  code  expected  200ok  statusbrowser  operation  succeeded  201created  required  successful  move  copy  destination  exist  yet  also  sent  current  resource  created  404not  found  current  resource  missing  copy  move  delete  412precondition  failed  destination  copy  move  operation  exists  replace  parameter  set  true  consistent  webdav  spec  copymove  situation  302found  aka  temporary  redirect  operation  succeeded  redirect  parameter  set  500internal  server  error  case  processing  error  eg  exception  thrown,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,0,0
4539,make  content  loader  extensible  support  new  import  format  current  content  loader  support  basic  set  import  format  identified  extension  xml  jcrxml  json  jar  zip  user  requesthttpmailarchivesapacheorgmodmboxslingusers201412mbox3cd0a6198c20fbeb25bruceedgenextissuemediacom3e  support  custom  format  like  adobe  folio  idea  implementhttpmailarchivesapacheorgmodmboxslingusers201412mbox3ca2ab572ffa834ae2806e49cce87b9fbeadobecom3e  create  new  orgapacheslingcontentloaderreader  package  exported  version  10  move  contentcreator  providertype  contentreader  consumertype  new  package  convert  baseimportloader  standalone  contentreader  service  holder  used  defaultcontentimporter  contentloaderservice  component  contentreader  service  interface  define  service  registration  property  service  expose  file  name  extension  maybe  content  type  reader  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4540,move  additional  mock  class  servletresolver  commonstesting  slingservletresolver  module  contains  mock  class  may  general  interest  therefore  moved  commonstesting  module,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4541,improve  sightly  engine  performance  several  area  engine  implementation  improved  greatly  reduce  compilation  rendering  time  rely  dynamic  classloaders  cache  rather  compile  useapi  pojos  time  reduce  number  repository  read  favour  event  deducing  sightly  script  useapi  pojo  need  recompiled  use  per  thread  admin  resource  resolver  instead  creating  many  resolvers  various  component  lifecycle  request  optimise  rendercontext  implementation  code  handle  object  method  field  detection,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0
4542,improve  sightly  j  provider  performance  sightly  javascript  use  provider  optimised  javascript  context  run  j  useapi  script  instead  creating  j  context  every  sightly  request  downside  optimisation  value  provided  slybindingsvaluesprovider  available  used  directly  sightly  script  making  available  j  useapi  object,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4543,configuration  value  compared  string  comparison  configutilissamedata  logic  compare  two  configuration  dictionary  value  dictionary  number  special  handling  done  result  string  compare  value  b  number  well  otherwise  equal  used  contains  string  b  contains  number  representing  value  dictionary  considered  special  handling  questionable  work  one  direction  think  relax  always  string  compare,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4544,json  representation  calendar  value  preserve  timezone  im  currently  thing  date  sling  involve  timezones  find  documentation  regarding  particularly  clear  according  httpsslingapacheorgdocumentationbundlesmanipulatingcontenttheslingpostservletservletsposthtmldateproperties  several  format  defined  found  format  save  provided  timezone  iso8601  format  rest  relies  date  object  timezones  could  clearly  stated  also  iso8601  parser  problematic  relies  jackrabbit  parser  us  format  ±yyyymmddthhmmssssstzd  according  httpwwww3orgtrnotedatetime  iso  format  millisecond  ss  hard  find  way  keep  timezone  information  dig  code  figure  could  please  replace  iso8601  actual  format  ±yyyymmddthhmmssssstzd  clearer,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4545,enable  dumping  remote  server  log  case  test  failure  case  large  test  suite  running  ci  server  hard  make  log  created  due  execution  testcase  make  determining  cause  testcase  failure  difficult  often  server  log  also  avialable  build  completed  source  information  system  log  captured  via  junit  framework  client  side  debugging  process  made  simpler  testcase  also  dump  server  side  log  generated  testcase  executes  locally  upon  failure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4546,support  nested  config  path  bundlelistcontentprovider  bundlelistcontentprovider  handle  nested  config  path  noted  sling4283  required  support  run  mode  based  config,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4547,avoid  caching  jcr  property  value  support  valuemap  currently  caching  jcr  value  object  also  jcr  property  object  value  map  object  held  might  prevent  garbage  collection  within  oak  value  object  hold  reference  revision  check  whether  caching  needed  example  could  cache  value  jcr  value  object,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4548,register  osgi  service  available  service  user  order  activate  osgi  component  service  user  mapping  available  would  useful  osgi  service  registered  service  user  component  reference  registered  service  name  start  becomes  available  code  referencetargetnameservicename  serviceuserexists  userexists  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
4549,create  individual  factory  distribution  trigger  currently  trigger  created  using  generic  factory  localdistributiontriggerfactory  generic  factory  split  several  specific  factory  property  customized  meaningful  way,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1
4550,sightly  reduce  number  repository  read  instance  still  use  jackrabbit  repository  read  operation  become  problematic  system  exposed  high  number  request  therefore  sightly  scripting  engine  optimised  reduce  number  repository  read  much  possible,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4551,expose  distribution  log  information  http  expose  distribution  log  information  http  non  admin  operator  see  ui  distribution  log,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
4552,improve  handling  unregistering  resourceproviderfactories  right  resourceproviderfactory  unregistered  resourceresolverfactory  first  unregistered  registered  order  clean  usage  resourceresolvers  might  reference  unregistered  provider  factory  reregistration  lead  nearly  whole  system  going  therefore  several  unregistrations  row  system  might  go  several  time  circular  dependency  might  also  result  endless  downup  loop,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4553,properly  version  package  exported  sling  query  sling  query  export  seem  generous  locked  module  version  instead  independent  fix  versioning  also  see  remove  export  also  discussed  devsling  slingquery  exported  aphttpmarkmailorgmessagehiadkgnx7mi7y7xf  noformat  warning  orgapacheslingquery  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryapi  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryapifunction  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryfunction  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryiterator  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryiteratortree  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingquerypredicate  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryresource  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryresourcejcr  version  increased  analysis  detected  change  detected  201  suggested  200  warning  orgapacheslingqueryresourcejcrquery  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryselector  excessive  version  increase  detected  201  suggested  200  warning  orgapacheslingqueryselectorparser  excessive  version  increase  detected  201  suggested  200noformat,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4554,use  finalize  resourceresolver  lead  performance  issue  currently  finalizer  implemented  resourceresolverimpl  httpsvnapacheorgreposasfslingtrunkbundlesresourceresolversrcmainjavaorgapacheslingresourceresolverimplresourceresolverimpljava  defers  garbage  collection  detailed  analysis  also  metric  around  look  httpsissuesapacheorgjirabrowsejcr2768  similar  approach  like  patch  attached  jcr2768  implemented  resourceresolverimpl,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4555,rename  scriptingresolver  module  scriptingcore  discussed  1  bundle  currently  named  scriptingresolver  scriptresolver  anymore  contains  core  functionality  scripting  nb  actual  scriptresolver  implemented  slingservletresolver  bundle  1  httpmarkmailorgmessagejl2l6c274e3i6lcf,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4556,sling  nosql  resource  provider  couchbase  want  create  lightweight  sling  resource  provider  using  couchbasehttpwwwcouchbasecom  storage  backend  without  need  underlying  jcr  oak  infrastructure  similar  approach  like  mongodb  resource  providerhttpssvnapacheorgreposasfslingtrunkcontribextensionsmongodb  discussed  mailing  listhttpapachesling73963n3nabblecomrtslingresourceprovidersfornosqldatabasesmongodbcouchbasett4046669html  would  make  sense  create  generic  shared  codebase  nosql  resource  provider  shared  module  could  used  nosql  database  well,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
4557,validation  support  validation  resource  child  resource  currently  validationservicevalidate  possible  trigger  validation  connected  single  jcr  validation  model  would  useful  able  trigger  validation  resource  would  also  comprise  validation  child  resource  dedicated  validation  model  determined  automatically  resourcetype,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4558,use  sling  mock  validation  core  test  orgapacheslingvalidationcore  bundle  utility  mock  httpssvnapacheorgreposasfslingtrunkcontribextensionsvalidationcoresrctestjavaorgapacheslingvalidationimplsetup  replaced  new  sling  mock  benefit  would  le  maintenance  validation  core  project  exposurecoverage  sling  mock,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4559,add  test  distribution  request  type  add  test  distribution  request  type  executed  without  altering  repository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4560,useapi  return  falsy  value  useprovider  able  solve  requested  object  case  useprovider  resolve  identifier  useruntimeextension  return  falsy  value  null  case  instead  throwing  sightlyexception,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4561,make  default  bundle  location  configurable  make  default  bundle  location  new  configuration  handled  installer  configurable  version  10x  null  110  switched  revert  default  null  provide  way  change  default,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4562,provide  oak  feature  provide  feature  oak  jackrabbit  oaksling  slingjcroak  slinglaunchpadoak  slinglaunchpadoaktar  slinglaunchpadoakmongo,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
4563,distribution  servlets  use  slingcommonsjson  build  json  response  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4564,sling  mock  mockmodeladapterfactory  compatible  latest  sling  model  impl  current  sling  mock  mockmodeladapterfactory  implementation  compatible  latest  sling  model  implementation  support  injectannotationprocessorfactory2  staticinjectannotationprocessorfactory  interface  better  solution  current  hardwired  mock  wiring  injector  would  enhance  osgi  mock  bindunbind  dynamically  new  interface  would  supported  well,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0
4565,mockjcrresourceresolverfactory  allow  register  service  dynamically  mockjcrresourceresolverfactory  class  creates  mocked  osgi  bundlecontext  us  create  resourceresolverfactory  part  osgi  environment  initialization  performed  class  registering  osgi  service  available  mocked  resolver  default  one  service  slingrepository  however  recent  version  resourceprovider  implementation  requires  service  eg  pathmapper  right  way  inject  service  mocked  osgi  container  mockjcrresourceresolverfactory  allow  register  custom  service  itll  compatible  future  version  resourceresolvers  provider,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4566,osgi  mock  handle  dynamic  service  reference  update  currently  service  reference  injected  registering  service  update  eg  another  service  referenced  matching  optional  multiple  reference  currently  ignored  handle  mock  context  well  least  basic  way  support  unit  test  required  eg  resolve  sling4434,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4567,improve  javauseprovider  fall  back  simple  pojo  instantiation  case  java  class  model  annotation  cannot  instantiated  currently  case  java  class  sling  model  ie  model  annotation  cannot  instantiated  eg  required  injection  possible  sightly  fall  back  instantiate  simple  pojos  never  good  since  lot  nullpointerexception  might  happen  injection  performed  therefore  following  code  used  instead  code  modelfactoryismodelclassresource  cl  modelfactorycancreatefromadaptableresource  cl  obj  modelfactorycreatemodelresource  cl  else  modelfactorycancreatefromadaptablerequest  cl  obj  modelfactorycreatemodelrequest  cl  else  throw  new  illegalstateexceptioncould  adapt  given  sling  model  neither  resource  request  cl  code  way  exception  would  propagated  case  sling  model  cannot  instantiated  developer  easily  see  sling  model  work  instead  running  nullpointerexceptions  model  instantiated  simple  pojo,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4568,schedule  job  n  time  currently  possible  schedule  job  either  one  forever  would  nice  schedule  job  n  time  perhaps  also  starting  given  time  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4569,provide  way  remove  setting  artifact  feature  model  model  merged  another  model  add  change  existing  setting  way  remove  framework  setting  configuration  artifact  complete  feature  provide  way,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4570,reduce  number  controller  thread  queue  right  queue  using  controller  thread  taken  pool  lot  queue  result  lot  thread  although  queue  started  job  queue  still  significant  number,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4571,refactor  jcr  installer  jcr  installer  code  old  grew  lot  past  year  think  time  clean  little  bit,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
4572,extend  slingpostservlet  support  reference  existing  repository  content  sling422  interesting  application  important  side  effect  old  slingpostservlet  gone  old  implementation  possible  file  uploaded  repository  one  request  follow  request  create  another  content  move  previously  uploaded  file  newly  created  content  better  illustrate  assume  cm  edit  kind  content  content  composed  one  image  uploaded  image  file  title  body  text  field  cm  want  present  user  friendly  interface  implemented  cool  file  upload  dialog  show  upload  progress  feature  used  preupload  image  file  temporary  location  upon  sending  rest  content  title  body  text  image  file  course  also  moved  temporary  location  final  destination  place  title  body  text  old  slingpostservlet  image  file  could  moved  simply  including  movesrcmovedst  parameter  pair  image  file  new  slingpostservlet  currently  possible  make  thing  possible  modifyoperation  slingpostservlet  extend  recognize  special  parameter  similar  solution  proposed  sling130  valuefrom  suffix  refer  value  another  form  field  propose  following  parameter  name  suffix  copyfrom  copy  item  repository  location  indicated  parameter  value  movefrom  move  item  repository  location  indicated  parameter  value  example  use  move  image  file  uploaded  previously  tmpimage000gif  image  child  node  html  form  submit  content  along  title  text  field  could  defined  form  methodpost  actionsomenewcontent  input  typehidden  nameimagemovefrom  valuetmpimage000gif  input  typetext  nametitle  value  input  typetext  nametext  value  submit  form  item  referred  copyfrommovefrom  parameter  node  type  ntfile  treatment  special  natural  type  destination  item  ntfile  addressed  node  simply  copied  moved  otherwise  jcrcontent  child  node  copied  moved  case  move  ntfile  node  course  also  removed  example  use  continued  processing  request  defined  form  original  item  tmpimage000gif  gone  content  located  somenewcontentimage,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4573,use  single  listener  registered  multiple  path  jcr  installer  sling  jcr  installer  currently  register  one  listener  per  watched  folder  application  like  aem  result  150  listener  total  210  belong  jcr  installer  recently  jackrabbit  introduced  support  adding  additional  pathhttpsgithubcomapachejackrabbitblobtrunkjackrabbitapisrcmainjavaorgapachejackrabbitapiobservationjackrabbiteventfilterjaval232  listen  part  jcr3745  leveraged  jcr  installer  avoid  registering  multiple  listener  instead  use  one  listener  feature  used  following  form  code  string  path  searchpathstoarraynew  string  jackrabbiteventfilter  eventfilter  new  jackrabbiteventfilter  setabspathpaths0  seteventtypeseventnodeadded  eventnoderemoved  eventnodemoved  eventpropertyadded  eventpropertychanged  eventpropertyremoved  setisdeeptrue  setnolocalfalse  setnoexternaltrue  pathslength  1  eventfiltersetadditionalpathspaths  jackrabbitobservationmanager  observationmanager  jackrabbitobservationmanager  adminsessiongetworkspacegetobservationmanager  observationmanageraddeventlistenerthis  eventfilter  code  would  allow  efficient  observation  processing  avoid  putting  load  system  oak  currently  maintains  one  queue  per  listener,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4574,get  array  namespace  prefix  jcrmodifiablevaluemap  cache  array  namespace  prefix  right  expensive  repository  operation  instead  every  value  map  could  per  resource  provider,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4575,enhance  slingpostservlet  multiple  operation  implementing  sling422  slingpostservlet  execute  one  single  operation  show  time  required  actually  evaluate  multiple  operation  example  1  cm  system  provides  dialog  modfiy  existing  content  one  content  element  stored  multivalue  property  represented  dialog  series  checkbox  user  check  checkboxes  respective  request  parameter  sent  server  box  property  touched  case  would  required  remove  respective  property  actually  modifying  existing  content  addition  modification  operation  delete  operation  must  executed  2  administration  application  operation  moving  item  may  applied  multiple  item  way  specifying  item  would  required  use  case  require  multiple  request  sling422  implementation  goal  come  solution  simple  box  provides  functionality  really  required,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4576,vlt  package  constructed  starting  closest  parent  order  necessitate  smaller  set  privilege  trying  build  package  varslingdistributiondiffdiff1  requires  read  privilege  var  work  also  user  privilege  varslingdistributiondiff  fixed  using  root  mount  path  vlt  package  1  httpsgithubcomapachejackrabbitfilevaultblobtrunkvaultcoresrctestjavaorgapachejackrabbitvaultpackagingintegrationtestmappedexportjaval45,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4577,performance  xssapigetvalidhref  based  html  filtering  around  3  rendering  time  spent  getvalidhref  us  antisamy  html  filter  job  obviously  hack  add  lot  unnecessary  overhead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4578,performance  use  jackrabbitsessiongetitemornull  speed  jcrresourceprovidercreateresource  current  session  jackrabbitsession  jcrresourceprovider  use  getitemornull  soon  exported  save  rendering  time  see  referenced  issue  following  mail  thread  information  httpmailarchivesapacheorgmodmboxjackrabbitoakdev201504mbox3cd1495a093b67025anchela40adobecom3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4579,discoveryoak  oakbased  discovery  implementation  discovery  used  stack  based  jackrabbit  oak  repository  current  way  discoving  instance  somewhat  sound  like  duplicating  work  oak  precisely  documentnodestore  lowlevel  lease  mechanismhttpjackrabbitapacheorgoakdocsnodestoredocumentmkhtml  store  information  cluster  node  including  leaseend  indicating  time  others  consider  particular  node  deadcrashed  corresponds  pretty  much  discoveryimpl  heartbeat  mechanism  stack  built  ontop  oakdocumentmk  could  making  use  fact  delegate  decision  whether  node  cluster  alive  oak  layer  also  oak2597  relevant  information  activeclusternodes  nicely  exposed  via  jmx  become  new  source  truth  defining  cluster  view  replacing  discoveryowned  heartbeat  oakowned  one  one  important  detail  watched  longer  easily  determined  another  instance  cluster  whether  new  discovery  bundle  activated  hence  given  voting  happens  active  node  reported  oakdocumentmk  actually  going  respond  silent  instance  due  deactivated  discovery  bundle  case  need  special  attentionhandling  given  normal  case  active  node  bundle  activated  voting  mechanism  stay  discoveryimpl  topology  connector  treated  storing  announcement  respective  vardiscoveryclusterinstancesslingidannouncementsannouncerslingid  node  property  handled  storing  property  node  thing  get  replaced  heartbeat  note  order  oakbased  discoveryimpl  oaklease  mechanism  must  robust  interest  already  however  currently  issue  probably  first  resolved  discovery  based  oak2739  oak2682  oak2681  currently  known  area,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4580,performance  consider  optimizing  mergedresourcegetparent  getchild  page  29  rendering  time  spent  abstractresourcegetchild  case  75  resource  mergedresources  rest  jcrnoderesources  already  opened  sling4596  therefore  would  suggest  implementing  following  optimization  merged  resource  stored  mergedresource  getchild  called  would  use  getchild  directly  merge  child  resource  would  advantage  parenthidinghandler  would  called  parent  resource  could  even  make  sling4568  obsolete  moreover  would  leverage  optimization  merged  resource  implementation  eg  sling4596  jcrnoderesourcegetchild  problem  approach  possible  jcr  maybe  also  resource  provider  set  acls  allow  read  child  parent  therefore  getchild  addition  check  search  path  isnt  covered  merged  resource  path  really  exist,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4581,discovery  add  jmx  method  start  new  voting  sling4516  additional  way  controlling  instance  ordering  cluster  thus  become  leader  defined  via  alphabetical  ordering  leaderelectionid  introduced  leaderelectionid  change  automatically  trigger  new  vote  however  since  conflict  discovery  api  demand  leader  stable  order  still  support  use  case  leader  knowingly  explicitly  want  changed  admin  jmx  method  starting  new  voting  introduced  would  simply  cause  new  ongoingvotings  created  based  existing  set  instance  would  fiddle  way  leader  chosen  way  would  based  leaderelectionids  would  elect  potentially  new  leader  would  support  management  possibility  around  forcing  different  specific  leader  extend,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4582,jst  scripting  engine  render  indexable  html  separate  javascript  code  jst  scripting  engine  output  default  html  rendering  meant  indexed  search  engine  script  element  point  separate  javascript  resource  render  page  idea  javascript  code  cached  client  browser  resource  slingresourcetype  html  rendering  include  meaningful  title  element  using  value  property  named  title  description  present  node  name,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4583,move  httptestbase  integration  testing  utility  commonstesting  launchpad  httptestbase  class  related  utility  class  move  commonstesting  module  reusable  example  reuse  testing  additional  scripting  engine  without  include  launchpad  build,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
4584,periodically  perform  full  topic  scan  per  instance  job  handling  know  job  topic  exist  periodic  scan  topic  therefore  independent  potential  problem  observation  however  work  long  instance  get  least  one  observation  event  new  topic  full  topic  scan  periodically  would  solve  problem,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4585,decouple  scheduled  job  observation  right  scheduling  job  tied  observation  event  whatever  reason  observation  event  sent  scheduling  pick  change  general  job  handling  solved  periodic  scan  use  similar  approach  scheduled  job,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,0
4586,logservice  logger  implement  locationawarelogger  library  specifically  spring  case  requires  logger  locationawarelogger  fail  locationawarelogger  logger  log  fqcn  extends  logger  interface  currently  implemented  slinglogger,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4587,decouple  sightly  jcr  compiler  current  implementation  sightly  scripting  engine  depends  jcr  compiler  generating  java  class  sightly  script  file  however  jcr  compiler  slow  system  due  jcrs  locking  mechanism  since  sling  also  provides  orgapacheslingcommonsfsclassloader  implement  faster  filesystembased  classloaderwriter  would  better  use  generic  approach  generating  java  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4588,osgimock  support  osgi  component  name  different  implementation  class  possible  define  different  component  name  implementation  class  via  scr  element  implemention  contains  correct  implementian  class  name  case  osgimock  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4589,let  servletcontextresourceprovider  fall  back  loading  class  path  let  servletcontextresourceprovider  search  class  path  resource  found  servlet  context  allows  launcherbase  jar  used  directly  within  war  without  exploding  making  much  easier  reuse  specifically  find  slingproperties  friend  found  base  jar  rather  war,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4590,slingmock  fully  support  resourceresolverfactoryactivator  jcrmock  slingmock  120  stripped  version  resourceresolverfactoryactivator  used  supported  single  jcr  resource  provider  underlying  jcrmock  prohibits  usage  testing  custom  resource  provider  detected  registered  osgimock,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4591,allow  vlt  package  builder  customized  path  temporary  package  one  able  specify  temporary  filesystem  folder  temporary  jcr  folder  vlt  package  aggregated  stored,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4592,crankstart  use  sling  provisioning  model  crankstart  converted  use  sling  provisioning  model  created  meantime  preserve  following  feature  set  initial  classpath  select  framework  version  set  default  variable  override  system  property  set  osgi  framework  property  variable  install  configs  early  soon  configadmin  available  osgi  configs  typed  value  guard  multiple  factory  config  creation  crankstartconfigid  ability  register  new  startup  command  mvnprotocol  optional  also  use  http  log  message  startup,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4593,sling  mock  add  none  resource  resolver  type  none  resource  resolver  type  initialize  real  sling  resource  resolver  factory  implementation  without  registering  resource  provider  esp  jcr  root  provider  useful  testing  resource  provider  registered  root  provider  without  jcr,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,1,0
4594,log  tracer  enable  log  specific  category  specific  level  specific  request  tracer  1  simplifies  enabling  log  specific  category  specific  level  specific  request  provides  fine  level  control  via  config  provided  part  http  request  around  logging  performed  given  category  eg  determining  node  written  given  post  request  simply  done  including  extra  request  parameter  tracer  noformat  curl  u  adminadmin  jcrcontentjcrtitlesummer  collection  namesummercollection  jcrprimarytypeslingfolder  jcrcontentjcrprimarytypentunstructured  tracersoakwrites  httplocalhost8080contentdam  noformat  one  also  specify  actual  category  part  request  param  complete  detail  refer  1  doc  moved  sling  site  refer  1  related  discussion  1  httpmarkmailorgthreadmijnl2mpxu4nzqkb,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4595,new  resource  provider  api  mail  thread  mailing  list  httpmailarchivesapacheorgmodmboxslingdev201505mbox3c555983ed108080040apacheorg3e  starting  mail  resource  provider  api  grown  lot  time  started  didnt  really  think  potential  extension  api  today  time  add  new  feature  come  new  marker  interface  also  distinction  resource  provider  singletonstateless  factory  creating  stateful  provider  although  api  intended  used  average  resource  api  user  extension  put  package  minor  thing  therefore  think  time  start  new  api  future  proof  solves  known  problem  ive  created  draft  prototype  1  performance  analysis  joel  found  getparent  call  resource  pretty  expensive  end  string  based  therefore  eg  jcr  implementation  cant  simply  call  getparent  node  wrap  resource  therefore  think  add  getparentresource  method  resource  resolver  better  way  handle  resource  provider  instead  resource  provider  resource  provider  factory  define  single  resourceprovider  singleton  provider  need  authentication  andor  need  keep  state  per  user  propertyauthenticate  need  set  true  case  authenticate  method  called  one  return  data  object  passed  every  method  auth  required  method  called  null  passed  data  object  authentication  provider  support  login  administrative  anymore  user  service  user  provider  mounted  single  root  support  mounting  different  path  time  provider  always  owns  root  provider  return  resource  given  path  provider  asked  allows  improved  implementation  resource  resolving  decided  need  compatibility  solve  differently  instead  using  marker  interface  define  resourceprovider  abstract  class  allows  u  add  new  method  without  breaking  existing  provider  method  get  resolvecontext  containing  resource  resolver  previously  mentioned  state  data  object  thing  eg  parameter  support  recently  added  resource  resolving  future  pas  additional  data  without  breaking  interface  apart  resource  provider  similar  aggregation  already  existing  marker  interface  two  exception  observation  query  ill  handle  different  email  1  httpssvnapacheorgreposasfslingwhiteboardcziegelerapiv3srcmainjavaorgapacheslingapiresourceprovider,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4596,new  observation  support  mail  thread  httpmailarchivesapacheorgmodmboxslingdev201505mbox3c555983f22040240apacheorg3e  starting  mail  right  resource  change  propagated  event  admin  time  sounded  like  good  idea  time  shown  bottle  neck  basically  least  three  problem  sender  resource  event  know  whether  receiver  therefore  event  every  change  need  sent  event  object  immutable  therefore  relevant  data  need  calculated  upfront  even  used  example  resource  event  contains  resource  type  need  fetched  repository  even  one  interested  receiver  event  cant  easily  act  behalf  user  initiated  change  created  new  listener  api  1  defines  resourcelistener  interface  way  specify  event  one  interested  user  aware  resource  listener  allows  act  behalf  user  information  available  side  new  service  observationreporter  2  defined  resource  provider  report  change  interface  payload  event  interface  allows  lazy  retrieval  information  also  use  mechanism  compatibility  implementation  observation  reporter  might  sent  event  via  event  admin  1  httpssvnapacheorgreposasfslingwhiteboardcziegelerapiv3srcmainjavaorgapacheslingapiresourceobservation  2  httpssvnapacheorgreposasfslingwhiteboardcziegeler,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4597,limit  number  job  retries  default  configuration  job  configured  job  event  sent  number  retries  indicating  often  job  rescheduled  something  go  wrong  configuration  available  job  event  event  retried  forever  jobeventhandler  get  default  configuration  used  case  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4598,decouple  model  provider  actual  validation  service  mentioned  sling4027  would  good  completely  decouple  model  providing  capability  actual  validation  would  make  codebase  cleaner  would  ease  testing  b  allow  plugin  service  provide  model  eg  based  annotation  file,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4599,slingconfigurationprinter  use  mode  aware  stream  full  log  zip  version  avoid  duplicate  information  currently  slingconfigurationprinter  mode  aware  produce  log  filestxt  contains  combine  log  one  issue  really  lot  log  large  also  zip  version  contains  output  combined  log  attached  improve  would  easier  use  mode  aware  interface  modeawareconfigurationprinter  define  different  output  style  text  mode  list  log  file  available  tail  last  n  line  could  added  zip  mode  attache  log  eventually  option  add  log  n  day  old  n  line  avoid  large  zip  file  also  sometime  problem  trying  analyze  recent  issue  quick  test  based  current  release  possible  achieve  least  mode  awareness  cziegeler  check  done  future  release  common  log,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4600,allow  automatically  undeploy  deployed  bundle  execution  property  slingadditionalbundle  already  possible  deploy  bundle  running  integration  test  derived  slingtestbase  also  supported  automatically  undeploy  bundle  test  finished,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4601,provide  option  disable  set  logger  via  config  logsupport  web  console  plugin  simplifies  configuring  logger  content  assist  time  debugging  purpose  user  route  log  set  logger  specific  file  post  debugging  logger  deleted  would  helpful  ui  provides  option  turn  logger  ie  config  applied,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4602,mockvaluemap  implement  containskey  mockvaluemap  inherits  valuemapdecorator  us  underlying  map  method  using  map  take  care  deep  path  feature  mockvaluemap  eg  mockvaluemapcontainskeypathproperty  return  false  even  mockvaluemapgetpathproperty  return  property  value  mockvaluemap  therefore  override  method  like  containskey,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4603,support  resource  type  inheritance  validator  model  currently  must  direct  match  resource  type  given  validation  model  resource  type  content  resource  resource  type  inheritance  also  taken  account  validation  model  given  resource  type  one  super  resource  type  taken  account  result  merged,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
4604,slingstart  maven  plugin  allow  read  variable  pom  default  provisioning  variable  resolved  variable  section  defined  inside  provisioning  file  processed  slingstart  maven  plugin  optionally  possible  reference  variable  defined  within  pom  plugin  executed  additionally  possible  attach  resolved  effective  model  variable  replaced  storing  artifact  useful  property  required  within  pom  provisioning  file  avoids  define  maintain  two  location,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
4605,slingstart  maven  plugin  allow  get  artifact  version  pom  currently  possible  define  exact  artifact  version  provisioning  file  define  version  latest  used  case  automatically  explicit  version  defined  provisioning  file  optionally  possible  use  version  defined  dependency  dependencymanagement  section  maven  project  pom  file  especially  useful  dependency  defined  anyway  set  maintained  two  location,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
4606,provide  mojo  create  maven  like  structure  referenced  artifact  would  nice  mojo  executed  creates  maven  like  directory  structure  referenced  artifact,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
4607,allow  register  servlet  resourcetype  path  following  use  case  id  like  register  servlet  handle  modification  given  resourcetype  order  fallback  id  like  register  servlet  fixed  path  fallback  case  could  first  resource  given  type  created  declaration  use  case  would  look  like  slingservletpaths  myfallbackpath  slingservletresourcetypes  myexampleresourcetype  servlet  resolution  path  property  respected  property  ignored  would  suggest  change  resolution  combination  path  resourcetype  method  evaluated,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4608,osgimock  add  support  componentcontextgetusingbundle  method  throw  unsupportedoperationexception  return  null  using  bundle  set  optionally  possible  set  using  bundle  mocked  component  context  simulate  bundlescoped  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4609,log  webconsole  plugin  provide  link  actual  log  file  currently  sling  log  panel  log  component  webconsole  plugin  provide  listing  active  log  file  config  printer  dump  content  active  log  file  would  better  one  direct  access  log  file  content  specific  file  also  possible  specify  many  line  included,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4610,sling  mock  make  compatible  oasjcrresource  250  currently  using  slingmock  14  dependencymanagement  setting  version  jcrresource  25  following  error  observed  executing  test  code  orgapacheslingtestingmockosgireferenceviolationexception  unable  inject  mandatory  reference  pathmapper  class  orgapacheslingjcrresourceinternalhelperjcrjcrresourceproviderfactory  matching  service  found  orgapacheslingtestingmockosgiosgiserviceutilinjectservicereferenceosgiserviceutiljava313  orgapacheslingtestingmockosgiosgiserviceutilinjectservicesosgiserviceutiljava289  orgapacheslingtestingmockosgimockosgiinjectservicesmockosgijava118  orgapacheslingtestingmockslingmockjcrresourceresolverfactorygetresourceresolverinternalmockjcrresourceresolverfactoryjava66  orgapacheslingtestingmockslingabstractmockresourceresolverfactorygetadministrativeresourceresolverabstractmockresourceresolverfactoryjava106  orgapacheslingtestingmockslingcontextslingcontextimplresourceresolverslingcontextimpljava179  orgapacheslingtestingmockslingcontextslingcontextimplloadslingcontextimpljava237  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4611,sightly  rendercontextimpl  contains  utility  method  dont  belong  current  implementation  sightlys  rendercontext  contains  lot  utility  method  examplehttpsgithubcomapacheslingblob90d2ed9e42deb144a7f6e1610871e72726cd810abundlesscriptingsightlyenginesrcmainjavaorgapacheslingscriptingsightlyimplengineruntimerendercontextimpljaval142  related  actual  context  belong  utility  class  also  unrelated  specific  instancestate  made  static  refactoring  rendercontextimpl  allow  u  avoid  unnecessarily  passing  object  class  part  code  use  utility  method  examplehttpsgithubcomapacheslingblob90d2ed9e42deb144a7f6e1610871e72726cd810abundlesscriptingsightlyenginesrcmainjavaorgapacheslingscriptingsightlyimplcompilerexpressionnodebinaryoperatorjaval31,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4612,deprecate  asynchronous  javascript  api  provided  sightly  j  use  provider  improvement  api  provided  orgapacheslingscriptingjavascript  bundle  asynchronous  promisebased  api  provided  sightly  j  use  provider  bundle  redundant  deprecating  api  together  conditionally  loading  support  detecting  use  object  actually  need  api  namespaces  help  optimising  execution  speed  javascript  use  object,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4613,optimise  sightlyjavacompilerservice  provide  object  faster  sightlyjavacompilerservice  optimised  provide  object  faster  getinstance  method  delaying  repository  search  pojo  object,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4614,slingmock  support  httpsession  invalidate  new  lastaccessedtime  maxinteractiveinterval  mockhttpsession  support  method  well  invalidate  isnew  getlastaccessedtime  getmaxinteractiveinterval  setmaxinteractiveinterval,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4615,check  synchronization  requestprocessormbeanimpl  every  request  go  requestprocessormbeanimpladdrequestdata  synchronized  block  think  rather  heavy  bottleneck  request  processing  addition  method  additional  calculation  synced  like  getstandarddeviationdurationmsec  others  like  getstandarddeviationpeakrecursiondepth  seems  little  bit  arbitrary,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
4616,logic  whiteboardhandler  hard  follow  find  logic  whiteboardhandler  hard  follow  refactor  improve  readability,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4617,allow  enable  usage  regular  jcr  user  service  resolvers  sling3854  serviceuservalidator  interface  introduced  basically  osgi  service  implementing  interface  may  decide  whether  certain  user  used  backing  user  call  resourceresolverfactorygetserviceresolver  implementation  sling  jcrsystemuservalidator  allows  use  jcr  system  user  list  service  bound  serviceusermapperimpl  dynamically  example  want  use  service  relax  policy  introduced  sling3854  eg  allow  user  service  user  may  register  service  returning  true  user  method  isvalid  unfortunately  dont  know  serviceuservalidator  service  bound  due  dynamic  restart  behaviour  service  therefore  service  cannot  rely  fact  serviceuservalidator  available  certain  point  time  therefore  call  resourceresolverfactorygetserviceresolver  may  fail  rely  nonsystem  jcr  user  therefore  mechanism  suitable  disable  enforcing  jcr  system  user  instead  would  propose  following  allow  configure  jcrsystemuservalidator  via  osgi  property  named  allowonlysystemusers  default  true  within  method  jcrsystemuservalidatorisvaliduser  either  allow  user  leave  current  logic  place  case  allowonlysystemusers  true  way  would  possible  reliably  allow  user  service  user  especially  helpful  development  certain  feature  although  probably  config  would  set  production  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4618,allow  set  multiple  validation  error  message  one  validator  currently  validator  set  one  error  message  string  return  value  sling4010  possible  one  validatorvalidate  call  set  multiple  validation  message  maybe  solution  raducotescu  proposed  httpsissuesapacheorgjirabrowsesling4027focusedcommentid14219170pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment14219170  used  pas  validationresult  around,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
4619,simplified  serverside  test  teleporterrule  ive  working  prototype  1  make  much  easier  create  serverside  test  using  junit  rule  teleport  server  edit  removed  obsolete  description  serversidetestrule  useful  along  something  like  httpsgithubcomfizzedmavenplugins  quickly  update  bundle  development  modified  1  httpssvnapacheorgreposasfslingwhiteboardbdelacretaztestrules,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4620,clarify  order  iterator  given  rankedservices  currently  iterator  rankedservices  return  service  ascending  order  lowest  highest  ranking  different  order  used  osgi  internally  1  usually  interested  iterator  give  service  highest  ranking  first  would  also  one  returned  bundlecontextgetservicereference  dont  change  iterator  logic  least  make  clearer  javadoc  iterator  really  give  service  ascending  order  service  ranking  property  probably  add  useful  iterator  give  back  service  highest  ranking  first  issue  came  context  sling5035  1  httpsosgiorgjavadocr4v42orgosgiframeworkbundlecontexthtmlgetservicereferencejavalangstring,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4621,repositorypinger  make  log  unusable  debug  mode  debug  logging  used  every  two  second  lot  debug  message  added  repository  pinger  make  log  nearly  unusable  grows  way  fast,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
4622,slingmock  register  jcr  node  type  osgi  bundle  class  path  resource  resolver  type  jcrjackrabbit  jcroak  node  type  required  store  data  certain  nodetypes  query  classpath  osgi  bundle  present  define  node  type  definition  slingnodetypes  bundle  header  picked  registered  automatically  repository  correct  order  multiple  bundle  registering  node  type  known  try  reregister  multiple  time  5  time  get  right  order  chance,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
4623,introduce  consistencyservice  discoverycommons  described  sling4627httpsissuesapacheorgjirabrowsesling4627focusedcommentid14532334pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment14532334  kind  discovery  implementation  top  eventually  consistent  repository  requires  synchronization  repository  order  ensure  event  old  incarnation  view  processed  new  incarnation  view  announced  everybody  thus  clusterwide  synchronization  required  synchronization  achieved  fairly  straightforward  storing  welldefined  sync  token  location  known  everybody  else  cluster  everybody  wait  seeing  token  continuing,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4624,hapi  add  java  hapi  microdata  client  hapi  tool  extension  could  make  use  java  html  microdata  client  consume  html  markup  annotated  using  hapi,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4625,add  test  sightly  editor  autocompletion  sling4189  sightly  editor  autocompletion  added  tested  found  simple  way  testing  except  uidriven  test  task  open  though  make  sure  eventually  add  test  autocompletion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4626,generate  osgi  subsystem  intermediary  file  slingstartmavenplugin  enhance  slingstartmavenplugin  support  osgi  subsystem  modeled  via  sling5148  maven  plugin  generate  esa  file  artifact  defined  osgi  subsystem  provisioning  model  resulting  esa  file  embedded  generated  archive,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4627,make  dependency  handling  code  reusable  want  build  maven  plugins  dealing  provisioning  model  currently  little  bit  hard  reuse  dependency  lifecycle  handler  extend  functionality,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0
4628,optimise  last  modified  information  retrieval  unitchangemonitor  unitchangemonitors  mechanism  storing  last  modified  date  sightly  compiled  class  optimised  provide  better  cache  creation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4629,refactor  merging  model  separate  utility  class  add  merge  option  move  merge  method  modelutility  mergeutility  provide  mergeoptions  class  allows  specify  remove  run  mode  handled  latest  artifact  default  artifact  highest  version  win,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4630,add  path  pathset  often  need  check  whether  resource  path  equal  sub  path  given  path  lot  different  solution  throughout  code  base  therefore  think  provide  basic  functionality  directly  api  reuse,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4631,remove  loginadministrative  usage  orgapacheslingbgservlets  counted  1  occurrence,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4632,allow  fine  grained  logging  configuration  currently  sling  logging  allows  global  log  file  file  console  global  log  level  setting  application  development  issue  tracking  required  able  fine  grained  control  configuration  multiple  log  file  log  level  per  category,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
4633,ensure  new  establishedview  different  synctokenid  always  trigger  topologychanged  sling5256  unerlying  mechanism  viewstatemanager  etc  ensure  topology  passed  handlenewview  contains  instancesproperties  differs  localclustersyncid  resource  name  voting  discoveryimpl  case  properly  generates  topologychanged  topologychanging  first  required  sling5058  suggesting  different  approach  achieving  add  viewcnt  sling5058  really  becomes  obsolete  sling5256  properly  verified  first  hence  ticket,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4634,requestprogresstracker  log  microsecond  requestprogresstracker  log  timing  millisecond  request  fast  millisecond  range  resolution  required  fine  tuning,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4635,allow  item  copy  distribution  queue  order  retry  item  error  queue  able  copy  item  error  queue  original  queue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4636,support  setting  basename  resource  bundle  backing  sightly  i18n  extension  currently  possible  set  basename  sightly  i18n  extension  addition  option  hint  locale  option  basename  supported  part  spec  httpsgithubcomadobemarketingcloudsightlyspecblobmasterspecificationmd123i18n  sling  context  additional  option  would  handy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4637,osgimock  support  osgi  r6  fieldbased  reference  binding  osgi  r6  field  reference  set  directly  using  bindunbind  method  additionally  field  reference  type  list  collection  supported  well  support  osgimock  start  keep  implementation  simple  support  subset  osgi  r6  feature  support  field  collection  type  service  reference  serviceobjects  map  tuple  ignore  service  policy  option  act  always  greedy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4638,osgimock  support  target  filtering  d  reference  reference  d  optional  target  attribute  filter  service  reference  property  supported  osgimock  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4639,introduce  timedifference  healthcheck  discoveryoak  oak2682  introduces  timedifference  detection  documentmk  via  jmx  method  determineservertimedifferencemillis  determines  much  local  vms  clock  differs  vm  documentstore  sling  healthcheck  verifies  determineservertimedifferencemillis  within  reasonable  limit  suggested  default  lowwater  mark  1  sec  lower  fine  higher  warn  issued  highwater  mark  5  sec  higher  critical  message  issued  verifying  clock  documentmk  cluster  clock  within  crosscluster  topology  also  verified  achieved  independent  underlying  oak  nodestore  use  still  existing  created  json  property  discovery  topology  announcement  check  intercluster  clock  checked  direction  http  put  use  higher  water  mark  since  involved  http  roundtrips  well  doesnt  criticality  intracluster  clock  suggested  default  lowwater  mark  5  sec  highwater  mark  10  sec,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4640,osgimock  support  osgi  r6  component  propert  type  configuration  osgi  r6declarative  service  13  add  new  support  passing  configuration  lifecycle  method  activate  deactivate  modified  via  component  property  type  annotation  class  supported  osgimock  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4641,mavenslingplugin  allow  installing  bundle  slingpostservlet  mechanism  add  additional  route  installing  bundle  mavenslingplugin  slingpostservlet  mechanism  currently  two  methodology  supported  installing  uninstall  bundle  posting  felix  web  console  puting  webdav  adding  ability  install  slingpostservlet  bundle  deployed  resource  tree  jcr  webdav  installed  maintaining  fullbackwards  compatibility  proposition  addition  another  boolean  flag  mojo  named  useslingpost  default  false  altering  new  flag  value  true  trigger  use  new  methodology,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4642,slingmock  support  remote  add  remote  host  remote  port  mockslinghttpsevletrequest  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4643,meaningful  thread  name  discussed  mailing  list0  would  good  assign  meaningful  name  thread  managed  sling  thread  pool  0  httpmarkmailorgthreadltq4fdyo5himfwo3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4644,create  service  user  acls  provisioning  model  discussed  removing  loginadministrative  test  service  username  convention  thread  dev  list  1  need  able  create  service  user  set  corresponding  acls  provisioning  model  implemented  using  distinct  utility  class  one  user  one  acls  take  simple  minilanguages  input  allow  reusing  utility  test  code  example  1  httpmarkmailorgmessagekcvuhwfdald2dyuz  edit  highlevel  requirement  discussed  sling5355  configs  v  content  acls  service  user  thread  httpmarkmailorgmessagetzno2via2wjckhuc  hr1  create  service  user  set  acls  defined  sling  instance  provisioning  model  hr2  create  initial  path  like  vardiscovery  acls  set  hr3  make  full  text  acl  definition  available  runtime  auditing  purpose  see  michael  marths  dec17  comment  sling5355  also  useful  upgrade  merging  conflict  detection  needed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4645,new  resourcebuilder  module  fluent  api  create  content  structure  discussed  recently  dev  list  contentbuilder  currently  provided  sling  mock  library  1  useful  testing  edit  implementing  diverged  idea  created  new  powerful  resourcebuilder  api  contentbuilder  stay  unchanged  order  make  usable  clientside  serverside  testing  well  serverside  code  im  planning  extract  module  define  api  allows  creating  node  property  importing  json  file  via  sling  contentloader  providing  simple  way  cleanup  test  content  implement  first  serverside  version  api  implement  second  priority  clientside  version  used  test  run  via  http  shouldnt  affect  existing  sling  mock  library  user  except  maybe  forcing  rebuild  test  use  new  api  1  httpsslingapacheorgdocumentationdevelopmentslingmockhtmlbuildingcontent,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4646,jcrinstaller  listen  move  jcrinstaller  currently  registering  jcr  listener  move  event  root  node  setting  deep  property  true  come  processing  underlaying  oak  observation  queue  combination  inefficient  allow  oak  filter  change  path  afaiu  move  listener  covering  use  case  installer  artifact  moved  fromto  installer  root  folder  therefore  wanted  propose  register  move  listener  configured  root  folder,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4647,support  renaming  bundle  via  sling  provisioning  model  sling  osgi  installer  allows  single  osgi  bundle  given  bsn  sometimes  necessary  rename  bundle  bsn  enable  installed  make  renaming  simple  fly  extend  slingstartmavenplugin  renaming  automatically  configuration  like  codeorgfoobarblah123  renamebsncomadobefoobarblahcode  one  note  case  multiple  model  file  reference  artifact  example  base  model  model  inherits  base  model  codeorgfoobarblah123code  without  rename  case  rename  still  happens  attribute  inherited,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4648,provide  support  running  singleton  job  non  leader  cluster  node  also  sling2979  support  running  singleton  job  specific  instance  provided  case  want  run  job  singleton  want  pin  specific  node  schedulerrunon  need  set  single  however  per  current  implementationhttpsgithubcomapacheslingbloborgapacheslingcommonsscheduler2414srcmainjavaorgapacheslingcommonsschedulerimplquartzjobexecutorjaval64  single  treated  leader  effectively  cause  singleton  job  get  executed  leader  thus  putting  extra  load  better  utilization  cluster  resource  possible  distribute  singleton  job  cluster  node  still  ensure  singleton  contract  honoured  would  like  make  use  feature  ensure  oak  asyncindextask  run  different  cluster  node  oak2749,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4649,use  priorityqueues  instead  selectivequeues  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4650,clear  info  logging  distribution  improve  info  logging  distribution  agent  log  info  level  execute  requestdetails  noofpackages  exporttime  noofqueues  enqueuetime  deliver  queuename  packagedetails  importtime  standalone  exporter  log  export  requestdetails  exporttime  standalone  importer  log  import  packagedetail  importtime,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4651,review  naming  convention  used  jmxreporter  register  metric  mbeans  current  setup  jmxreporter  would  register  metric  orgapachesling  domain  pfaffmadobecom  suggested  cause  confusion  metric  registered  non  sling  bundle  would  also  show  sling  jmx  domain  customize  jmx  objectname  logic  account  bundle  registered  metric  one  approach  used  expose  metricservice  servicefactory  use  custom  bundle  header  else  fallback  bundle  symbolic  name  discussion  thread  mailing  list  httpmarkmailorgthreadsj6yvmyhgze6jn22,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4652,enable  findbugs  sightly  scripting  engine  findbugs  run  part  normal  build  process  sightly  scripting  engine,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0
4653,content  repository  initialization  language  discussion  dev  list  colleague  around  sling5355  acl  definition  language  show  need  initialize  number  thing  starting  new  existing  content  repository  create  base  tree  path  like  libs  apps  var  many  module  use  sometimes  compete  create  create  service  user  set  acls  base  tree  service  user  maybe  setup  jcrspecific  thing  like  node  type  custom  privilege  content  repository  would  ignore  ill  create  general  module  created  sling5355  hasnt  released  cover  thing  put  commonsrepoinit  shouldnt  dependency  sling  might  donate  jackrabbit  matures  goal  implement  whole  cycle  inside  sling  primary  customer  jcrspecific  apis  use  jcr  session  handle  content  repository  keep  independent  sling  allow  used  context  like  test  edit  changed  path  commonsjcrinit  commonsrepoinit  even  part  specific  jcr  repoinit  language  mostly  generic,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4654,add  helper  class  construct  valid  path  working  path  easy  combine  two  valid  path  invalid  one  instance  parent  child  parentchild  parent  child  parentchild  add  simple  helper  class  allows  build  path  fluent  syntax,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4655,implement  slingrepositoryinitializer  plugins  setup  repository  id  like  implement  slingrepositoryinitializer  extension  point  use  case  like  setting  service  user  acls  creating  base  tree  content  described  sling5449  also  useful  handle  content  migration  cleanup  operation  upgrade  scenario  registering  slingrepository  service  active  slingrepositoryinitializer  service  called  order  service  ranking  passing  upcoming  slingrepository  service  act  exception  thrown  processing  cause  slingrepository  service  registration  canceled  slingrepositoryinitializer  javadocs  must  stress  service  need  take  clustered  scenario  account  necessary  implement  locking  mechanism  avoid  stepping  others  toe,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
4656,recording  tracer  log  sling  log  tracer  currently  provides  support  fine  grained  control  enabling  log  specific  request  make  log  accessible  would  useful  feature  client  also  fetch  log  specific  request  http  feature  would  work  like  client  sends  http  request  header  slingtracerrecord\u200b  set  true  noformat  curl  u  adminadmin  h  slingtracerrecord  true  jcrcontentjcrtitlesummer  collection  namesummercollection  jcrprimarytypeslingfolder  jcrcontentjcrprimarytypentunstructured  tracersoakwrites  httplocalhost4802contentdam  noformat  server  includes  request  id  part  slingtracerrequestid  response  header  noformat  http11  201  created  date  wed  27  jan  2016  073022  gmt  slingtracerrequestid  9b5b01f6f26947c3a8892dc8d4d7938f  xcontenttypeoptions  nosniff  xframeoptions  sameorigin  location  contentdamsummercollection  contenttype  texthtml  charsetutf8  transferencoding  chunked  noformat  log  json  format  fetched  like  httplocalhost4802systemconsoletracer9b5b01f6f26947c3a8892dc8d4d7938fjson  see  attached  outputtracerrecordingjson  includes  following  data  extended  per  need  requestprogresstracker  log  jcr  query  made  key  point  request  id  randomly  generated  access  request  log  via  web  console  plugin  servlet  hence  accessible  admin  user  account  request  data  would  recorded  request  \u200bslingtracerrecord  header  set  data  would  kept  memory  time  assumption  client  would  fetch  soon  time  data  would  expire  feature  would  need  explicitly  enabled  via  config  option  feature  somewhat  similar  recent  request  support  however  expose  json  rendition  keep  data  request  client  requested  feature  dependency  added  guava  cache  make  use  space  boundexpiring  cache  extent  use  linkedhashmap  given  guava  used  sling  oak  make  sense  make  use  feature  required  look  embedding  minimum  required  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4657,hapi  move  sightly  use  object  different  package  move  hapiuse  typeview  use  object  sightly  subpackage,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4658,run  distribution  integration  test  launchpad  8  moment  integration  test  distribution  module  run  launchpad  7  run  latest  launchpad  8,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4659,add  possibility  extract  archive  repository  currently  content  bundle  put  asis  repository  could  add  new  feature  user  specify  archive  zip  jar  start  together  path  manifest  archive  extracted  repository  given  path,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4660,consolidate  path  utility  orgapacheslingapiresourcepath  release  vote  sling  api  2100  pointed  split  path  utility  oasapiresourceutil  oasresourcepath  httpmarkmailorgmessageiushkixwgxw7hgur  consolidate  oasapiresourcepath  instead,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4661,provide  additional  hamcrest  matcher  currently  hamcrest  matcher  provided  sling5063  match  child  name  exact  match  missing  desired  would  method  like  resourcematcherscontainschildren  resourcematcherscontainschildreninanyorder  similar  matchercontains  matcherscontainsinanyorder  addition  would  good  matcher  single  resource  given  name  like  resourcematchersresourcewithname  also  combination  name  matcher  property  matcher  resourcematchersresourcewithnameandprops,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4662,allow  discovery  source  bundle  currently  deployed  sling  runtime  sling3605  need  find  bundle  installed  sling  application  identify  source  artifact  separate  bundle  servlet  living  toolingsupport,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4663,remove  deprecated  feature  jcr  base  deprecated  several  feature  jcr  base  230  remove,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4664,create  new  sightly  file  wizard  sling4076  fixed  would  convenient  also  new  file  wizard  new  sightly  html  file  new  sightly  j  usescript  new  sightly  java  usescript,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4665,update  sling  api  211  dependency  sling  api  211  related  new  implementation  resourceresolver  jcrresource  introduce  deep  change  resource  provider  interface  internal  registration  process  jcr  resource  provider  making  incompatible  slingmock  1x  thus  introduce  new  version  slingmock  2x  compatible  latest  sling  api  relevant  dependency  old  slingmock  1x  version  still  available  httpssvnapacheorgreposasfslingbranchestestingmocksslingmock1x,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4666,optimize  acquire  package  operation  make  fewer  save  currently  shareddistributionpackageacquire  called  queue  save  repo  done  time  send  array  queue  package  acquired  one  save  queue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4667,improve  webdav  support  installing  bundle  webdav  support  installing  bundle  useputtrue  improved  several  regard  webdav  method  used  even  creating  intermediate  folder  checking  folder  already  able  deal  redirect  issued  sling  webdav  plugin  see  sling5557  compare  also  httpapachesling73963n3nabblecommavenslingpluginanduseputwithintermediatefolderstd4059733html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
4668,move  health  check  core  integration  test  core  module  number  integration  test  found  module  depend  core  bundle  moving  core  module  make  easier  measure  aggregate  coverage  unit  integration  test,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,0
4669,distribution  package  implementation  independent  serialization  currently  different  implementation  distributionpackage  interface  orgapacheslingdistributioncore  orgapacheslingdistributionextensions  based  plain  file  filevault  package  backed  file  jcr  content  however  itd  good  package  would  agnostic  serialization  type  simply  based  resource,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4670,move  slingvalidationexception  package  orgapacheslingvalidation  current  validation  api  contains  single  exception  slingvalidationexception  package  orgapacheslingvalidationexceptions  dont  see  added  value  slingvalidationexception  think  remove  package  use  javaxvalidationvalidationexception  instead  cziegeler  kwin  wdyt  see  e  sling4027,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4671,use  plural  method  validationmodelprovidergetmodelcollectionvalidationmodel  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4672,pretty  print  json  dump  current  json  export  using  jsonwriter  writes  compact  json  certainly  good  performance  big  pain  developping  debugging  would  cool  pretty  print  flag  passed  export  enables  nice  formatted  jsons  eg  httplocalhostcontentsiteen3jsontidytrue  patched  current  jsonwriter  jsonitemwriter  added  respective  flag  servlet  wdyt,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4673,provide  job  api  implementation  suitable  widely  distributed  job  processing  issue  track  work  proof  concept  create  job  api  implementation  work  distributed  environment  job  submitter  job  consumer  necessarily  jvm  sling  cluster  work  done  branch  httpsgithubcomiebslingtreejobs28contribextensionsjobs  since  implementation  need  supporting  apiscapabilities  already  present  sling  subtasks  associated  issue  address,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4674,distribution  package  persisted  file  also  ref  file  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4675,make  jcrpropertymap  public  current  jcrpropertymap  orgapacheslingjcrresourceinternalhelperjcr  package  protected  although  node  resource  adapted  valuemaps  sometimes  node  structure  would  convenient  using  jcrpropertymap  directly  readapt  via  resource,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4676,make  thymeleaf  templateengine  available  service  sling  scripting  thymeleafscriptengine  strongly  tied  http  request  rendering  template  outside  web  context  service  orgthymeleafitemplateengine  better  choice,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4677,special  json  array  import  sling  post  servlet  post  orderered  structure  possible  right  post  ordered  structure  json  data  0  ticket  implementing  bdelacretaz  proposal  use  json  array  noformat  title  parent  node  slingordered  slingname  first  title  come  first  slingname  second  title  come  second  noformat  need  triggered  selector  contenttype  switch  existing  post  behavior  unchanged  suppose  slingordered  also  set  appropriate  mixin  parent  node  0  httpslingmarkmailorgthreadplov2u7kibscn7sx,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4678,make  scriptengine  factory  configurable  0,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4679,avoid  creating  file  package  small  enough  fit  memory  resourcepackagebuilder  creates  temporary  file  holding  actual  package  stream  itd  good  avoid  size  stream  small  enough  quickly  fit  memory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4680,add  light  checkpointing  mechanism  inmemory  queue  advantage  using  inmemory  queue  avoid  writing  eg  repository  intensively  however  itd  good  could  implement  light  checkpointing  mechanism  allows  instance  crashed  able  recover  least  item  restarted,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4681,allow  configure  resource  resolver  mapping  currently  resourceresolverfactoryactivator  registered  httpsgithubcomapacheslingblobtrunktestingmocksslingmocksrcmainjavaorgapacheslingtestingmockslingresourceresolverfactoryinitializerjaval123  configured  since  resource  resolver  mapping  topic  often  implemented  wrong  way  possible  setup  mapping  slingcontext  allow  test  realistic  way,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4682,allow  distribution  config  stored  content  using  distribution  endpoint  libsslingdistributionsettingsagentsagentname  one  able  also  edit  replication  property  noformat  replicationtriggeronmodificationtrue  noformat,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
4683,modularise  sightly  script  engine  sightly  script  engine  broken  three  module  sightly  frontend  compiler  interprets  sightly  script  produce  abstract  syntax  tree  ast  sightly  java  backend  compiler  interprets  ast  produce  java  class  file  compilable  script  engine  reuses  previous  two  module,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,0,1
4684,expose  distributioncontentserializer  expose  distributioncontentserializer  api  orgapacheslingdistributioncore  order  allow  implementation  custom  serialization  format  eg  avro  kryo  defined  orgapacheslingdistributionextensions,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4685,make  sling  pipe  writer  persistent  configuration  right  way  configure  output  pipe  add  json  parameter  pipe  request  sometimes  output  importantcomplex  pipe  persisted  could  also  opportunity  rewrite  writer  managed  far  ideal  ifelse  block  servletplumber  always  take  writer  account  call  time  default  path  writer  writer  still  overridable  request  parameter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4686,implement  file  system  resource  provider  idea  implement  resourceprovider  access  file  folder  platform  filesystem  virtual  resource  tree  functionality  serve  multiple  purpose  1  show  implement  resourceprovider  easily  2  support  simple  development  3  may  used  support  following  use  case  resource  provider  exist  maybe  rapid  development  goal  implement  sling  application  script  stored  repository  loaded  osgi  bundle  part  application  without  filesystem  resource  provider  script  stored  bundle  start  stored  repository  moved  bundle  later  first  approach  tedious  requires  bundleredeployment  script  change  second  tedious  easy  forget  copying  file  repository  bundle  done  filesystem  resource  provider  script  may  developed  favourite  ide  persisted  exact  location  later  use  anyway  bundle  inclusion  source  control  system  project  location  simply  create  configuration  filesystem  provider  map  script  resource  tree  exact  location  later  provide  bundle  change  script  ide  immediately  visible  sling  support  ever  wanted  access  sling  log  file  remote  server  wanted  inspect  actual  slingproperties  file  even  wanted  look  actual  configuration  admin  configuration  file  filesystem  resource  provider  friend  create  configuration  mapping  slinghome  resource  tree  start  looking  simple  remote  filesystem  browsing  browsing  remote  filesystem  beginning  idea  ton  picture  would  like  access  sling  application  instead  copying  picture  repository  something  might  make  sense  future  filesystem  resource  provider  allows  mapping  folder  containing  picture  resource  tree  view,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4687,support  different  thread  pool  scheduled  task  right  scheduler  us  single  thread  pool  thread  pool  configured  mean  scheduled  task  share  pool  order  prioratize  different  task  others  avoid  blocking  important  job  unimportant  could  maybe  add  configuration  property  select  thread  pool  name  pool  name  exists  used  default  used,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
4688,register  jcr  nodetypes  provisioning  model  create  repository  path  provisioning  model  1  need  able  register  nodetypes  case  node  need  created  nondefault  nodetypes  use  mechanism  similar  orgapacheslingrepoinitjcrrepositoryinitializer  read  provisioning  model  using  url  scheme  configured  point  another  data  source  case  sling  started  via  provisioning  model  need  documented  httpslingapacheorgdocumentationbundlesrepositoryinitializationhtml  1  httpslingapacheorgdocumentationbundlesrepositoryinitializationhtml,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0
4689,new  functionality  resolve  script  name  im  looking  way  include  jsp  script  within  another  respecting  resource  type  hierarchy  example  myapp  ajsp  contentjsp  b  slingresourcesupertype  bjsp  bjsp  want  include  contentjsp  respecting  resource  type  hierarchy  suggest  add  slnginclude  scriptselectorcontent  internally  overwrites  request  selector  script  selection  phase  see  httpmarkmailorgmessagela4rvmcdd6whpvhl,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
4690,defaultgetservlet  obtains  input  stream  binary  even  request  head  per  current  implementation  head  request  handled  defaultheadservlet  majorly  two  change  1  covert  response  output  stream  null  message  body  response  2  covert  head  request  get  request  request  dispatched  served  defaultgetservlet  approach  get  desired  output  response  delayed  read  complete  binary  data  resource  also  increase  data  transfer  needed  imo  approach  improved  thanks,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
4691,hapi  client  make  orgapacheslinghapiclient  bundle  orgapacheslinghapiclient  could  bundle  would  make  usable  server,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4692,sling  contextaware  configuration  initial  contribution  discussed  mailing  list  see  post  april  2016httpapachesling73963n3nabblecomrtusecasesforcontentspecificconfigurationsinslingampcontributiontd4060813html  want  contribute  wcmio  configuration  part  aemspecific  current  feature  wcmio  configuration  described  httpwcmioconfig  main  goal  support  contextspecific  configuration  mean  configuration  different  different  content  path  eg  site  tenant  contribution  change  refactorings  requiredplanned  eg  remove  dependency  wcmio  build  environment  guava  others  remove  application  distinction  currently  part  wcmio  configuration  favor  pathbased  distinction  refactor  userfaced  configuration  api  simplify  support  osgi  r6style  annotation  classed  typed  configuration  access  update  discussed  httpslingmarkmailorgthreadka3ewlswfgjy7rpu  name  new  module  contextaware  configuration,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4693,jcrpropertymap  shoud  allow  retrieving  property  jcrpropertymap  check  javaxjcrproperty  type  class  return  property  exists,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4694,provide  default  launchpad  oak  tar  configuration  option  pax  exam  orgapachefelixhttp  orgosgiservicehttpport  orgapachejackrabbitoakpluginssegmentsegmentnodestoreservice  repositoryhome  name  orgapachejackrabbitoakpluginsindexluceneluceneindexproviderservice  localindexdir,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4695,fail  test  default  unresolved  bundle  testoptionsbaseconfiguration  default  ensure  test  fails  unresolved  bundle  codejavasystempropertypaxexamosgiunresolvedfailvaluetruecode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4696,point  alternative  repository  specified  commandline  basically  sling2847  sling2848  applied  new  module  help  situation  snapshot  dependency  design  arent  resolved  reactor  paxexam,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4697,move  web  console  plugin  separate  bundle  log  implementation  currently  contains  web  console  plugin  us  dynamic  package  import  log  impl  wired  bundle  providing  servlet  api  bundle  updatedremoved  cause  log  implementation  refresh  usually  mean  complete  restart  system  every  bunde  us  logging  reduce  coupling  remove  dependency  servlet  api  logging  implementation,1,0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1
4698,add  pre  post  processing  hook  sling  post  servlet  currently  post  slingpostoperation  selected  executed  post  operation  everything  performing  change  saving  think  could  reintroduce  change  interface  several  implementation  like  add  remove  copy  etc  interface  knowledge  change  slingpostoperation  would  return  list  change  interface  slingpostoperation  list  change  prepareslinghttpservletrequest  first  step  post  come  still  select  post  operation  operation  generates  list  change  without  changing  anything  repository  introduce  pre  post  processor  interface  final  name  yet  interface  preprocessor  void  processslinghttpservletrequest  listchange  interface  postprocessor  void  processslinghttpservletrequest  listchange  several  pre  post  processor  registered  property  processor  used  order  guarantee  ordered  execution  pre  processor  alter  list  change  pre  processor  run  change  applied  repository  sling  post  processor  executed  finally  change  saved,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4699,register  filter  using  http  whiteboard  instread  using  proprietary  way  registering  servlet  filter  registered  http  whiteboard,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4700,refactor  simpledistributionagent  inner  class  simpledistributionagent  2  inner  class  created  time  ago  grew  importance  complexity  time  itd  good  refactor  class  reading  testing  code  comfortably,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
4701,use  custom  converter  adaption  valuemap  annotation  class  contextaware  configuration  httpssvnapacheorgreposasfslingtrunkcontribextensionscontextawareconfig  currently  use  outofthebox  functionality  osgi  converter  server  map  resource  valuemap  property  annotation  class  work  well  however  thing  need  improved  need  custom  conversion  adapter  rule  dynamic  proxy  created  converter  see  convertingimplcreateproxyhttpsgithubcomapachefelixblobtrunkconvertersrcmainjavaorgapachefelixconverterimplconvertingimpljaval311  know  map  interface  valuemap  thus  access  directly  raw  type  value  map  conversion  magic  exists  jcr  value  map  implementation  applied  converter  magic  always  produce  result  jcr  mapping  magic  thus  need  adaption  rule  valuemap  annotation  class  used  valuemap  get  method  type  required  property  second  argument  problem  converter  service  currently  support  explicit  mapping  type  b  mapping  type  type  rule  method  variant  currently  implemented  felix  converter  impl  post  question  issue  felix  mailing  list  custom  conversion  rule  place  improvement  create  slingvariant  conversionexception  make  sure  thrown  relevant  case  conversion  property  access  instead  builtin  one  conversion  service  support  nested  configuration  nested  configuration  list  access  subresource  detected  currently  work  valuemap  return  null  adapt  subresource  valuemap  convert,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4702,remove  deprecated  jcr  resource  api  jcr  resource  api  deprecated  time  used  anymore  codebase  remove  jcr  resource  bundle  also  remove  deprecated  pathmapper,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4703,scd  support  deep  property  filter  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4704,improve  auth  requirement  whiteboard  implementation  current  auth  requirement  whiteboard  implementation  could  improved  service  registration  modified  currently  existing  registration  removed  new  registration  added  result  lot  churn  going  implementation  improved  make  diff  old  new  array  apply  diff,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4705,contextaware  config  support  adapting  configuration  resource  carsten  introduced  rev  1758332  new  feature  configurationbuilderas  method  also  support  adapting  object  sling  adapter  manager  exit  configuration  annotation  class  currently  reflected  api  unit  test  missing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
4706,contextaware  config  add  pluggable  context  path  strategy  default  context  path  configuration  linked  defined  existence  slingconfig  property  node  want  keep  default  behavior  getting  cumbersome  massive  multitenant  scenario  used  hundred  site  grouped  region  etc  follow  consistent  repository  scheme  case  would  easier  forced  create  slingconfig  property  site  root  link  correct  configuration  move  site  moved  provide  strategy  implementation  context  path  detected  new  strategy  registered  osgi  service  service  ranking  control  asked  first  via  service  property  possible  register  special  strategy  subpath  eg  contenttenant1  apply,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,1,0
4707,contextaware  config  introduce  bucket  name  parameter  configurationresourceresolver  followup  discussion  httpapachesling73963n3nabblecomcontextawareconfigwhyslingconfigsnodett4064393html  want  introduce  bucketname  parameter  configurationresourceresolver  interface  make  explicit  highlevel  configurationlike  resolver  define  one,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4708,contextaware  config  provide  configuration  parameter  metadata  order  support  configuration  editor  gui  need  provide  metadata  configuration  parameter  metadata  defined  application  mean  list  configuration  registered  singleton  collection  nested  respective  configuration  name  label  optional  description  optional  list  parameter  configuration  parameter  metadata  name  type  supported  stringintlongdoubleboolean  array  label  optional  description  optional  default  value  custom  property  may  customized  configuration  editor  eg  widget  type  use  optional  application  need  possibility  provide  configurationparameter  metadata  default  annotation  interface  class  used  detected  runtime  classpath  new  bundle  deployed  using  osgi  extender  pattern  quite  similar  sling  model  annotation  class  annotation  applied  class  property  level  provide  additional  metadata  label  description  etc  currently  support  automatic  detection  parameter  metadata  configuration  defined  accessed  annotation  class  application  used  direct  valuemap  access  lowlevel  configurationresourceresolver  making  configuration  metadata  provider  pluggable  via  spi  ship  default  configuration  providing  metadata  detected  deployed  annotation  class  leave  door  open  add  source  well,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4709,contextaware  config  adapt  defaulting  strategy  discusesd  mail  thread  httpapachesling73963n3nabblecomcontextawareconfigdefaultconfigurationandnamingtd4064399html  change  default  folder  name  conf  rename  slingconfig  property  name  slingconfigref  change  way  default  configuration  detected  following  example  content  structure  like  noformat  content  tenant1  context  path  contenttenant1  region1  context  path  contenttenant1region1  site1  context  path  contenttenant1region1site1  page1  noformat  configuration  looked  path  order  noformat  conftenant1region1site1  conftenant1region1  conftenant1  confglobal  appsconf  libsconf  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4710,teleportergetservice  wait  required  service  junit  teleporterrule  provides  getservice  method  get  osgi  service  test  run  may  return  null  service  yet  started  workaround  integration  test  implement  waitfor  pattern  httpssvnapacheorgreposasfslingtrunkbundlesextensionsrepoinititsrctestjavaorgapacheslingrepoinititwaitforjava  supported  teleporter  rule  directly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4711,sling  pipe  sling  pipe  working  reference  sling  pipe  would  useful  output  nothing  referred  pipe  output  output  input  referred  pipe  output,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4712,update  sightly  bundle  parent  pom  28  sightly  bundle  update  use  version  28  apache  sling  parent  pom,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4713,resourcebuilder  split  resourcebuilder  resourcebuilderfactory  understand  combine  use  case  resource  builder  creation  resource  builder  usage  one  single  resourcebuilder  interface  two  implementation  supporting  one  part  another  throwing  exception  method  used  think  would  quite  cleaner  easier  understand  create  separate  resourcebuilderfactory  interface,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4714,improve  java  package  gav  oak  restriction  right  bundlesymbolicname  orgapacheslingslingoak  restriction  placed  contribextensions  rather  named  orgapacheslingoakrestrictions,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4715,sling  model  automatic  registration  sling  model  via  bnd  plugin  currently  package  sling  model  class  registered  slingmodelpackages  bundle  header  bundle  deployed  classpath  get  scanned  model  package  subpackages  registered  developer  add  header  manually  bundle  eg  via  pommavenbundleplugin  additionally  provide  alternative  model  class  registration  introduce  new  header  slingmodelclasses  list  class  name  sling  model  bundle  deployed  header  supported  bundle  slingmodelclasses  class  path  scanning  required  add  bnd  plugin  scan  project  class  file  compile  time  class  sling  model  annotation  automatically  add  fill  slingmodelclasses  header  thus  using  bnd  plugin  manual  configuration  bundle  header  required  bnd  plugin  work  mavenbundleplugin  bndmavenplugin  using  bnd  directly  approach  quite  similar  recently  discussed  sling6025,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4716,slingmock  contentbuilder  support  creating  resource  object  vararg  parameter  similar  resourcebuilder  slingmocks  contentbuilder  support  creating  resource  object  vararg  array  specifying  properrties  additionally  supporting  mapstringobject,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4717,resourcebuilder  support  map  resource  property  additionally  supporting  providing  resource  property  via  object  varargs  array  mapstringobject  property  accepted  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4718,osgimock  support  passing  mapdictionary  property  object  vararg  parameter  various  osgi  mock  method  map  dictionary  object  passed  eg  service  property  also  offer  variant  passing  keyvalue  paris  object  vararg  parameter,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
4719,contextaware  config  property  inheritancemerging  currently  contextaware  config  implementation  support  resource  inheritance  property  inheritance  mean  property  get  merged  resource  inheritance  chain  long  discussion  mailing  list  topic  argument  support  support  httpapachesling73963n3nabblecomcontextawareconfigsmergingtt4063382html  goal  ticket  support  make  configurable  switched,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4720,contextaware  config  make  resource  inheritance  configuration  collection  configurable  currently  automatic  mergingcombining  configuration  resource  item  take  place  example  noformat  confsite1featurea  confsite1featurec  confglobalfeatureb  libsconffeaturec  noformat  return  abc  config  resource  collection  feature  requested  c  confsite1featurec  libsconffeaturec  inconsistent  support  property  currently  merging  supported  undesired  effect  furthermore  problematic  saving  configuration  collection  via  configurationmanager  interface  sling6026  storing  set  config  resource  confsite1  stored  child  confsite1feature  reading  automatically  merged  others  fallback  path  user  possibility  prevent  either  disable  merging  path  implement  correctly  giving  user  control  merging  take  place  confmgr  special  property,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4721,contextaware  config  configuration  property  override  provider  add  support  similar  httpwcmioconfigcoreoverrideprovidershtml  esp  useful  testqa  system  bunch  content  configuration  package  imported  production  system  need  overwritten  eg  ip  address  host  name  override  provider  active  default  perhaps  go  separate  package  need  spi  core  implementation  somewhat  related  sling6058  information  overriding  place  provided  configuration  management  api  configurationmanager  well,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4722,slingstartmavenplugin  allow  start  quickstart  jar  based  provisioning  model  even  non  slingstart  packaging  currently  slingstartmavenplugin  start  server  based  textual  model  definition  case  maven  module  packaging  slingstart  httpsslingapacheorgdocumentationdevelopmentslingstarthtmlstartingaserver  often  beneficial  module  tested  class  case  packaging  bundle  therefore  would  nice  even  packaging  value  model  definition  srcmainprovisioning  would  considered  goal  start  must  first  build  quickstartjar  model  start  compare  also  readme  httpsgithubcomapacheslingblobtrunktestingsamplesbundlewithitpomxmll196  would  especially  helpful  leveraging  teleporterrule,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4723,hamcrest  match  resource  path  matcher  matching  resource  given  path  added,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4724,make  sling  ide  independent  m2etycho  currently  sling  ide  requires  installation  m2etycho  added  httpsissuesapacheorgjirabrowsesling3608  mavenbundleplugin  ship  m2e  support  ootb  felix4009  get  rid  dependency  also  important  since  newer  version  mavenbundleplugin  conflict  extension  httpsissuesapacheorgjirabrowsefelix4009focusedcommentid15192263pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment15192263  see  also  discussion  httpwwwmailarchivecomdevslingapacheorgmsg60112html,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,1
4725,hamcrest  simplify  resourcematchers  method  signature  resource  matching  method  resourcematchers  simplified  100  release  eliminate  resource  prefix  method  name  resource  already  resourcematchers  class  name  child  method  contain  prefix  well  allow  specify  property  map  either  map  object  vararg  array  similar  resource  builder  sling  mock  existing  sling  project  using  snapshot  release  updated  well,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4726,handle  empty  tracer  config  header  gracefully  case  tracer  config  header  null  request  fails  following  exception  noformat  08102016  144743920  warn  qtp84031089162  orgeclipsejettyservletservlethandler  contentgeometrixxoutdoorsenwomenhtml  javalangillegalargumentexception  header  cannot  empty  string  orgapacheslingcommonsosgimanifestheaderparsemanifestheaderjava116  orgapacheslingtracerinternaltracersetparsetracerconfigstracersetjava71  orgapacheslingtracerinternaltracersetinittracersetjava50  orgapacheslingtracerinternallogtracergettracercontextlogtracerjava250  orgapacheslingtracerinternallogtracertracerfilterdofilterlogtracerjava356  orgapachefelixhttpbaseinternalhandlerfilterhandlerdohandlefilterhandlerjava108  noformat,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4727,ability  specify  ttl  separate  health  check  currently  ability  specify  ttl  separate  health  check  ex  case  hc  validating  repository  35  minute  therefore  couldnt  specify  ttl  globally  impact  hc  result  hc  couldnt  execute  scheduler  prevent  cpu  high  loading  also  result  check  remains  relevant  13  hour  therefore  make  sense  ive  added  pull  requesthttpsgithubcomapacheslingpull180  functionality  property  hcttl  specified  within  hc  used  ttl  result  otherwise  cache  use  default  ttl  value,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4728,restrict  access  principal  everyone  move  configuration  repoinit  currently  everyone  read  configured  oakslingrepositorymanager  access  everyone  restricted  read  restricted  content  configuration  principal  acls  done  repoinit  change  path  content  oakslingrepositorymanager  r1764259httpssvnapacheorgr1764259  fix  module  sample  relying  unrestricted  read  access  move  configuration  acls  repoinit  discussion  devhttpslistsapacheorgthreadhtml36908ed62ac93c63cad594a897f8abceb93f08da5bcea30dbce98e583cdevslingapacheorg3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4729,contextaware  config  config  reference  detected  contextpathstrategy  currently  defaultcontextpathstrategy  check  availability  slingconfigref  prop  return  value  done  defaultconfigurationresourceresolvingstrategy  bit  inconsistent  leading  configure  lookup  sling6149  multiple  place  make  difficult  define  scenario  config  reference  build  conventionsbased  pattern  eg  derived  content  path  instead  explicit  slingconfigref  property  logic  implementation  detail  strategy  remain  untouched,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4730,improve  mapentries  implementation  looking  mapentries  implementation  thing  case  several  time  handling  change  event  optimize  also  verify  everything  handled  test  current  unit  test  check  single  method  whole  functionality,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4731,contextaware  config  change  java  package  name  oascaconfig  change  java  package  name  orgapacheslingcontextawareconfig  orgapacheslingcaconfig  see  discussion  httpslistsapacheorgthreadhtml844a6e56c5b5020106d145edc7fd9faa721642b2c905987c81a1b5483cdevslingapacheorg3e,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4732,provide  better  filter  option  search  job  currently  possible  search  job  activate  job  filter  exact  matching  topic  enhanced  allow  pattern  matching  job  topic  like  osgi  eventing  provide  map  property  must  match  well  map  act  like  search  template,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4733,expose  service  sling  scripting  provides  requestscoped  resource  resolvers  scripting  dependency  new  sling  scripting  service  scriptingresourceresolverprovider  implemented  order  provide  access  requestbased  resourceresolvers  solving  script  dependency  following  method  available  noformat  provides  requestscoped  link  resourceresolver  read  access  search  path  resolver  used  script  resolution  context  request  rendering  process  code  resourceresolver  closed  consumer  calling  link  resourceresolverclose  doesnt  anything  since  service  handle  closing  operation  automatically  code  resourceresolver  shared  scripting  dependency  render  part  response  request  resourceresolver  getrequestscopedresourceresolver  noformat  slingdev  email  threadhttpslistsapacheorgthreadhtmldb2a78249baf2d6234a4549a5aff8b5474256add9829f86ac78d1c563cdevslingapacheorg3e,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4734,use  jackrabbitoak  globbing  support  recently  switched  back  use  jcr  listener  sling6138  unfortunately  jackrabbit  support  glob  pattern  atm  jcr4044  fixed  use  jr  api  support  glob  support  come  different  solution  today  either  switch  back  oak  observer  register  single  jcr  listener  root  filtering  internally,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4735,sling  ide  allow  disable  wtp  naturesfacets  contentpackage  project  configurator  added  sling3100  always  wtp  nature  according  facet  added  contentpackage  project  always  desired  eg  lead  fact  metainfmanifestmf  automatically  generated  jcrroot  folder  httpswikieclipseorgm2ewtpfaqwhatisthiswebresourcesfolder3f  httpstackoverflowcomquestions14659891m2ewtperrorpathtargetm2ewtpwebresourcesmetainfmanifestmfnosuch  another  drawback  validators  eg  javascript  working  reliably  one  package  autonomous  piece  code  often  reference  code  outside  content  package  invisible  eclipse  since  contentpackages  quite  different  war  project  would  propose  add  naturesfacets  explicitly  configuredrequested  instead  add  native  sling  ide  naturesfacets  original  idea  behind  making  contentpackage  similar  war  support  code  assist  jsps  better  ie  tag  library  never  reliably  worked  therefore  rather  get  rid  approach,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
4736,installer  persist  optional  error  text  per  resource  currently  osgi  installer  web  console  expose  state  like  „ignored“  „install“  case  bundleconfigpackage  could  installed  would  helpful  especially  context  sling5014  additionally  persist  error  text  last  action  successful  error  text  exposed  web  console  way  one  could  easily  determine  even  afterwards  specific  artifact  installed  installer  see  also  discussion  httpwwwmailarchivecomdevslingapacheorgmsg60872html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4737,use  official  osgi  annotation  orgapacheslingresourceresolver  resourceresolverfactoryactivator  use  consistenly  propertiesutil  favor  cast  also  use  default  value  scr  annotation  activate  method  harmonized,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4738,allow  creating  user  repoinit  seems  possible  create  user  repoinit  would  useful  sample  apps  testing  example  slingshot  sample  app  currently  need  admin  user  create  sample  user  account  therefore  slingshot  need  whitelist  admin  usage  good  thing  suggest  add  create  user  name  create  user  name  password  delete  user  name  pw  provided  create  user  create  random  pw,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4739,log  perform  initial  configuration  framework  property  synchronously  logbackmanager  us  logconfigmanager  support  traditional  logging  configuration  including  initial  global  configuration  framework  property  everything  setup  logbackmanagerconfigchanged  method  called  initiate  logging  first  time  unfortunately  configchanged  processed  asynchronously  leading  initial  configuration  applied  later  special  use  case  even  complete  application  already  started  proposed  replace  call  configchanged  call  configure  actually  implement  configuration  change  started  flag  set  true  proposed  patch  code  index  srcmainjavaorgapacheslingcommonsloglogbackinternallogbackmanagerjava  srcmainjavaorgapacheslingcommonsloglogbackinternallogbackmanagerjava  revision  1767024  srcmainjavaorgapacheslingcommonsloglogbackinternallogbackmanagerjava  arbeitskopie  1678  16713  registerwebconsolesupport  registereventhandler  initial  configuration  must  done  synchronously  aka  immediately  addinfologbackmanager  begin  initial  configuration  configure  addinfologbackmanager  end  initialconfiguration  open  gate  regular  configuration  started  true  configchanged  public  void  shutdown  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4740,allow  configuration  fallback  property  defaultcontextpathstrategy  currently  defaultcontextpathstrategy  look  property  slingconfigref  property  looked  eg  migration  adobe  confmgr  done  additional  contextpathstrategy  performance  drawback  allow  define  additional  property  name  used  order  appearance  value  property  found  value  used  others  queried  anymore  slingconfigref  property  always  first  one  used  need  configured  also  mean  possible  deviate  rule,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4741,support  relative  reference  defaultconfigurationresourceresolvingstrategy  value  slingconfref  property  relative  parent  hierarchy  context  resource  traversed  find  context  resource  absolute  property  found  concatenated  example  contenta  slingconfrefconfa  contentab  slingconfrefb  try  find  configuration  contentab  search  confab  first  confa,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4742,provide  separate  queue  specific  job  would  great  able  run  specific  job  separate  queue  instead  using  main  queue  job  queue  running  job  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4743,implement  loginadminwhitelist  jcr  base  jcr  base  provide  default  implementation  abstractslingrepositorymanagerallowloginadministrativeforbundlebundle  configurable  loginadminwhitelist  implementation  want  different  logic  still  choose  overwrite  method  cc  cziegeler  bdelacretaz,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4744,caconfig  separate  spi  property  inheritance  currently  property  merging  support  part  defaultconfigurationresourceresolvingstrategy  together  support  resource  collection  merging  conflict  custom  configurationpersistencestrategy  redirect  root  resource  eg  jcrcontent  child  node  property  merging  broken  definition  configurationpersistencestrategy  knowledge  configurationpersistencestrategys  higher  level  dedicated  configuration  solution  create  separate  spi  property  merging  apply  configurationresolver  configurationmanager  generic  configurationresourceresolver,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4745,contextaware  config  web  console  configuration  printer  alongside  sling6115  would  nice  also  inventory  plugin  list  registered  strategiesproviders  ranking  defined  override  string  etc,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
4746,support  slingmodelsclasses  bundle  header  discussed  sling6048  support  new  bundle  header  slingmodelsclasses  explicit  class  listing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4747,clarify  description  contentdispositionfilter  configuration  description  apache  sling  content  disposition  filter  component  httpsgithubcomapacheslingblob02fb326a008418c51482090814e4bff3cac657c7contribextensionssecuritysrcmainjavaorgapacheslingsecurityimplcontentdispositionfilterjaval52  clear  circumstance  contentdispositionattachment  set  current  resource  either  jcrdata  jcrcontentjcrdata  property  found  important  information  want  understandconfigure  filter  correctly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4748,jcrinstallercounters  accessed  threadsafe  manner  jcrinstallercounter  thread  final  long  array  however  ensure  change  performed  safely  published  since  potentially  accessed  multiple  thread  including  unit  test  lead  randomlooking  hardtodebug  issue,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4749,resourceresolverimplisresourcetype  compare  relative  resource  type  ignore  search  path  prefix  currently  following  two  expression  return  false  resourceresolverimplisresourcetyperesource  resourcetypeslingsometype  libsslingsometype  resourceresolverimplisresourcetyperesource  resourcetypelibsslingsometype  slingsometype  since  cannot  always  influenced  whether  given  resource  absolute  relative  usually  work  rendering  perspective  talk  current  request  resource  case  actually  return  true  see  also  related  discussion  httpwwwmailarchivecomdevslingapacheorgmsg62351html,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4750,serverside  test  use  servicetracker  wait  service  rather  polling  inside  serversideteleportergetservice  bundlecontext  polled  presence  service  every  50ms  instead  servicetracker  could  used  wait  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4751,implement  resourceresolverwrapper  resourceresolverwrapper  would  help  consumer  implement  resourceresolver  interface  define  restrictive  import  range  orgapacheslingapiresource  api  package  implementation  delegate  call  wrapped  resource  resolver  similar  resourcewrapper,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4752,contextaware  config  properly  support  nested  configuration  class  spi  mangement  api  currently  nested  configuration  class  supported  configuration  resolver  properly  supported  annotationclassconfigurationmetadataprovider  spi  implementation  management  api  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4753,contextaware  config  access  inheritance  property  management  api  spi  configuration  management  api  related  configuration  persistence  spi  provide  access  readwrite  inheritancerelated  property  eg  controlling  resource  collection  inheritance  resource  property  inheritance  depending  resource  resolving  strategy  apis  route  control  property  without  interpreting,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4754,allow  extend  loginadminwhitelist  multiple  configuration  discussed  mailing  listhttpslingmarkmailorgthread7xfcefaufczvsdgk  would  desirable  allow  multiple  configuration  contribute  loginadminwhitelist  issue  marked  blocker  current  implementation  yet  released  thus  allowing  arbitrary  change  without  backwards  compatibility  headache  propose  remove  whitelistbundlesdefault  whitelistbundlesadditional  property  replace  additional  configuration  allow  provide  list  whitlisted  bundle  symbolic  name  main  configuration  loginadminwhitelist  propose  retain  flag  bypass  whitelist  completely  uncertain  whether  really  need  whitelist  regexp  testing  fairly  simple  list  hand  full  required  bundle  keep  suggest  make  metatype  private  optionally  could  consider  possibility  allow  configuring  list  required  additional  configuration  would  leave  find  real  requirement  would  complicate  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4755,osgimock  slingmock  add  support  context  plugins  osgimock  provide  osgicontextbuilder  well  context  builder  accept  list  context  callback  lifecycle  phase  introduce  generic  contextcallback  used  mock  variant  better  solution  add  support  context  plugins,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4756,contextaware  config  sling  mock  context  plugin  using  new  mock  context  plugin  feature  sling6359  provide  plugin  setting  contextaware  configuration  unit  test  environment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4757,slingmock  automatically  register  sling  model  classpath  version  sling  model  unit  test  worked  registered  beforehand  addmodelsforpackage  method  running  unit  test  sling  mock  existing  bundle  header  manifest  file  class  path  scanned  slingmodelpackages  slingmodelclasses  entry  registered  automatically,1,0,1,0,1,0,0,0,0,1,0,0,0,0,1,1,1
4758,contextaware  config  delete  configuration  via  configurationmanager  currently  possible  delete  singleton  configuration  clear  property  add  delete  method  configurationmanager  api  related  configurationpersistencestrategy  spi,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4759,log  warning  case  resource  resolver  closed  sling  rr  finalizer  thread  currently  dangling  resource  resolvers  longer  referenced  automatically  closed  sling  httpsgithubcomapacheslingblobtrunkbundlesresourceresolversrcmainjavaorgapacheslingresourceresolverimplcommonresourceresolverfactoryimpljaval100  unfortunately  happens  silently  since  resource  resolvers  closed  explicitly  code  rely  thread  clean  according  warn  log  whenever  unclosed  resourceresolver  detected  closed  similar  logging  statement  seen  httpsgithubcomapachejackrabbitblobtrunkjackrabbitcoresrcmainjavaorgapachejackrabbitcoresessionimpljaval1372  course  would  helpful  stack  trace  resource  resolver  opened  would  logged  well  see  also  related  discussion  httpwwwmailarchivecomdevslingapacheorgmsg62779html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4760,contextaware  config  support  default  value  configurationresolver  valuemaps  currently  default  value  defined  configuration  annotation  class  supported  configurationresolver  accessing  via  annotation  class  using  valuemap  real  data  stored  repository  returned  configurationmanager  default  value  also  supported  valuemaps  support  configurationresolver  well  consistency  make  available  eg  sightly  template  via  sling6384,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4761,contentloader  shouldnt  commit  change  least  allow  disable  auto  commit  contentloader  always  automatically  persists  change  made  given  resoureresolver  make  hard  use  test  class  implementing  transactional  change  example  highlevel  apis  change  resourceresolver  allowing  automatically  commiting  pagemanager  assetmanager  aem  implementation  top  sling  keep  abstract  let  say  class  specificbinaryfilesetresource  method  addbinaryfile  goal  implement  mock  im  using  contentloader  create  binary  file  resourceresolver  automatically  commit  change  let  extend  addbinaryfile  accept  boolean  parameter  automatically  commit  change  maybe  want  make  multiple  change  rolling  back  error  isnt  supported  far  using  contentloader,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4762,implement  support  date  number  formatting  htl  version  13  htl  specification  extends  functionality  format  option  providing  support  also  formatting  date  number  httpsgithubcomadobemarketingcloudhtlspecblob13specificationmd122format,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4763,add  provider  status  information  timed  event  currently  possible  start  stop  timed  event  sending  event  new  interface  timedeventstatusprovider  added  allows  query  something  scheduled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4764,enhance  conversion  rule  valuemapdecorator  background  discussion  mailing  listhttpslistsapacheorgthreadhtml696deaf2f6b67d99ee969aad19e5b8b00d9c53c78e9ad75633e9e8093cdevslingapacheorg3e  conversion  rule  valuemapdecorator  unified  conversion  rule  jcr  valuemap  implement  long  jcr  specific  conversion  rule  currently  supported  outlined  httpscwikiapacheorgconfluencexoqkib  ticket  want  add  support  convert  number  type  long  byte  short  integer  double  float  bigdecimal  string  vice  versa  convert  date  type  calendar  date  string  vice  versa  make  existing  implementation  bit  efficient  avoid  string  parsing  possible,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1
4765,allow  specifying  oak  restriction  repoinit  allow  specifying  oak  restriction  repoinit  currently  repoinit  allows  one  add  remove  acls  way  specify  oak  restriction  httpjackrabbitapacheorgoakdocssecurityauthorizationrestrictionhtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4766,filesystem  resource  provider  support  mounting  content  resource  json  file  would  nice  filesystem  resource  provider  support  serving  binary  file  folder  also  arbitrary  resource  stored  json  file  folder  hierarchy  normally  extracted  installing  bundle  slinginitialcontent  necessary  explicitly  switch  feature  per  configuration  may  desired  directly  serve  json  file  binary  file  case,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
4767,context  aware  configuration  multiplexer  exposed  outside  bundle  caconfigs  service  provider  interface  spi  allows  overlay  enhance  replace  default  implementation  adapt  need  custom  implementation  outside  caconfig  bundle  need  access  multiplexer  api  reuse  piece  framework,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0
4768,remove  dependency  jcrresource  api  jcrresource  api  deprecated  replace  usage  resource  api,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4769,remove  dependency  orgjson  ide  code  using  orgjson  replace  list  file  using  code  toolingideapisrcorgapacheslingideosgiimplhttposgiclientjavaimport  orgjsonjsonarray  toolingideapisrcorgapacheslingideosgiimplhttposgiclientjavaimport  orgjsonjsonexception  toolingideapisrcorgapacheslingideosgiimplhttposgiclientjavaimport  orgjsonjsonobject  toolingideapisrcorgapacheslingideosgiimplhttposgiclientjavaimport  orgjsonjsontokener  toolingideeclipsetestsrcorgapacheslingidetestimplhelpersexternalslinglaunchpadjavaimport  orgjsonjsonarray  toolingideeclipsetestsrcorgapacheslingidetestimplhelpersexternalslinglaunchpadjavaimport  orgjsonjsonobject  toolingideeclipsetestsrcorgapacheslingidetestimplhelpersexternalslinglaunchpadjavaimport  orgjsonjsontokener  toolingideimplresourcesrcorgapacheslingideimplresourcetransportgetnodecontentcommandjavaimport  orgjsonjsonarray  toolingideimplresourcesrcorgapacheslingideimplresourcetransportgetnodecontentcommandjavaimport  orgjsonjsonobject  toolingideimplresourcesrcorgapacheslingideimplresourcetransportlistchildrencommandjavaimport  orgjsonjsonobject,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4770,filesystem  resource  provider  support  mounting  content  resource  filevault  jcr  xml  file  would  nice  filesystem  resource  provider  support  serving  binary  file  folder  also  arbitrary  resource  stored  filevault  jcr  xml  file  folder  hierarchy  normally  packaged  uploaded  necessary  explicitly  switch  feature  per  configuration  may  desired  directly  serve  json  xml  file  binary  file  case,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4771,slingstartmavenplugin  make  enriching  maven  classpath  optional  currently  oasmavenslingstartdependencylifecycleparticipant  take  care  enriching  maven  classpath  project  referencing  maven  plugin  although  case  may  desired  necessarily  case  eg  bundle  module  contains  leveraging  slingmocks  others  leveraging  eg  teleporter  test  merged  classpath  often  conflict  slingmocks  using  model  leveraging  slingstart  project  like  sling  launchpad  merged  classpath  huge  may  negatively  affect  also  executed  remotely  therefore  propose  make  extension  classpath  optional  initially  done  slingstart  slingfeature  changed  project  referencing  plugin  sling6068,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
4772,slingstartmavenplugin  keeplaunchpadrunning  replaced  option  used  start  andor  stop  right  parameter  keeplaunchpadrunning  block  start  mojo  one  server  terminated  easy  explicitly  terminate  server  though  maven  propagate  ctrlc  server  usually  much  useful  instead  block  stopping  server  ie  stop  mojo  would  propose  deprecate  keeplaunchpadrunning  instead  introduce  following  parameter  may  used  together  start  andor  stop  blockuntilkeyispressed  leverage  prompter  component  httpstackoverflowcoma219772695155923  force  mojo  wait  user  entered  value,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1
4773,remove  getadministrativeresourceresolver  sling  validation  3  occurrence  oasvalidationimplresourcemodelresourcevalidationmodelproviderimpl  oasvalidationimplvalidationmodelretrieverimpl  probably  latter  deal  resource  resolvers  compare  httpwwwmailarchivecomdevslingapacheorgmsg64770html  oasvalidationimplvalidationserviceimpl  retrieve  search  path  relativizing  resource  type,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4774,merge  ithttp  module  core  module  0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
4775,granularly  invalidate  cached  validationmodels  currently  validationmodelproviders  asked  validation  model  specific  resource  type  result  cached  may  invalidated  whole  validationmodelprovider  well  work  always  requires  full  cache  invalidation  whenever  new  model  come  play  consider  following  use  case  one  model  resource  type  available  applicablepath  content  model  retrieved  validationmodelprovider  validation  resource  contenttestc  new  model  resource  type  becomes  available  applicablepath  contenttest  new  model  take  precedence  applicable  path  specific  would  work  2  3  cache  fully  invalidated  new  model  actually  never  leveraged  unless  full  cache  invalidated,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4776,jcr  content  parser  different  usecases  around  file  system  resource  provider  sling  mock  see  related  ticket  need  parse  content  structure  file  file  system  eg  json  format  jcr  xml  format  put  code  new  common  library  reused  different  project,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4777,slingmock  use  file  system  content  parser  parsing  json  file  parsing  json  file  content  loading  switched  new  file  system  content  parser  get  also  rid  orgapacheslingcommonsjson  dependency  license  problem,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4778,improve  logging  healthcheckmbeancreator  0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4779,defaultvalidationfailure  defaultvalidationresult  use  validationcontext  parameter  validationcontext  noformat  public  defaultvalidationfailurenonnull  validationcontext  validationcontext  nonnull  string  messagekey  object  messagearguments  noformat  instead  location  severity  resourcebundle  validationcontext  noformat  public  defaultvalidationfailurenonnull  string  location  integer  severity  nonnull  resourcebundle  defaultresourcebundle  nonnull  string  messagekey  object  messagearguments  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4780,mavenslingplugin  add  fsmount  fsunmount  goal  feature  add  osgi  configuration  file  system  resource  provider  quite  hidden  optional  mountbyfs  property  installuninstall  goal  additionally  add  two  explicit  goal  fsmount  fsunmount  allowing  add  remove  configs  without  installinguninstalling  bundle  time,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1
4781,add  possibility  execute  sling  pipe  background  thread  way  execute  pipe  http  wait  servlets  response  end  long  pipe  issue  well  fact  pending  change  might  impact  memory  well  error  prone  case  pipe  executed  several  time  ticket  adding  new  execution  mode  write  running  status  pipe  configuration  make  pipe  executed  separate  thread  servlet  thread,1,0,1,0,1,0,0,0,1,0,0,1,0,0,0,0,1
4782,mavenslingplugin  support  mount  filevault  xml  file  system  resource  provider  sling6537  file  system  resource  provider  also  used  mount  filevault  xml  file  system  layout  enhance  mavenslingplugin  support  layout  well  fsmount  fsunmount  goal  sling6622,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4783,move  validationmodelretriever  package  orgapacheslingvalidationmodelspi  move  validationmodelretriever  package  orgapacheslingvalidationmodelspi  remove  package  orgapacheslingvalidationimpl  completely,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4784,move  defaultvalidationfailure  defaultvalidationresult  package  orgapacheslingvalidationspi  move  defaultvalidationfailure  defaultvalidationresult  validation  core  package  orgapacheslingvalidationsupportbase  keep  validation  api  lean,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4785,contextaware  config  control  resource  path  configuration  persistence  strategy  currently  spi  interface  configurationpersistencestrategy  offer  two  method  getresource  getresourcepath  rewrite  resource  path  persisting  resource  eg  insert  additional  jcrcontent  hierarchy  bit  limited  known  resource  path  belongs  singleton  resource  resource  collection  item  config  name  possible  change  parent  resource  configuration  collection,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1
4786,support  caconfig  impl  130  class  caconfig  130  implementation  moved  need  update  mock  plugin  support  change  unit  test  mock  plugin  support  caconfig  impl  version  since  10,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4787,contextaware  config  separate  exception  persist  failes  due  missing  access  right  persisting  configuration  failes  due  missing  access  right  eg  readonly  access  implementation  throw  dedicated  exception  handled  separately  upper  layer  eg  configuration  editor  gui,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4788,replace  usage  orgapacheslingcommonsjson  orgjson  launchpad  relevant  bundle  following  deprecation  orgapacheslingcommonsjson  sling6536  need  replace  usage  everywhere  else  least  want  able  release  module  depend  umbrella  issue  getting  done  idea  create  subissues  patch  individual  component  review  patch  done  close  issue  general  discussion  problem  go  issue  specific  one  subissue  question,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4789,make  metricsservice  accessible  easily  logger  metric  useful  class  osgi  component  getting  metricsservice  useful  getting  logger  example  ill  add  public  metricsservicefactory  class  metric  module  usable  like  code  metricsservice  m  metricsservicefactorygetmetricsservicethisgetclass  code  there  already  private  metricsservicefactory  class  module  ill  rename  internalmetricsservicefactory  avoid  confusion,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4790,loginadminwhitelistfragment  metatype  descriptor  intended  metatype  description  loginadminwhitelistfragment  factory  configuration  intended  whitelistregexp  description  whitelistbundlesdefault  deprecated  metatype  still  work  configured  whitelistbundlesadditional  deprecated  metatype  still  work  configured,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4791,slinginfoservlet  overengineered  slinginfoservlet  little  bit  overengineered  using  extensible  provider  concept  however  provider  interface  private  single  implementation  fact  extensible,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4792,migrate  r6  annotation  clean  dependency  migrate  r6  annotation  check  whether  remove  dependency,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4793,migrate  r6  annotation  clean  dependency  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4794,align  accessors  api  currently  getvalidationmodel  getmodelgetmodels  use  one  also  remove  validated  validationmodelgetvalidatedresourcetype,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4795,drop  workspace  support  dropped  workspace  support  module  long  time  ago  seems  missed  servlets  post  module  remove  well  needed  anymore,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4796,rename  validationcontextimpl  validatorcontextimpl  validationcontextimpl  implement  validatorcontext  named  accordingly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4797,enable  rhino  debugger  framework  property  currently  server  side  rhino  debugger  enabled  placing  file  tmp  directory  see  sling193  appropriate  replaced  framework  property  set  enable  rhino  debugger,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4798,contextaware  config  make  filtered  property  name  configuration  persistence  configurable  currently  hardcoded  list  filtered  property  name  applied  configuration  manager  implementation  default  configuration  persistence  implementation  noformat  jcrprimarytype  jcrmixintypes  jcrcreated  jcrcreatedby  jcrlastmodified  jcrlastmodifiedby  jcruuid  noformat  list  made  configurable  upstream  application  property  might  need  filtered  eg  track  replication  status  possibility  filter  list  property  name  name  regex  made  accessible  configurationmanager  api  part  management  api  configuration  persistence  application  may  use  well,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4799,add  support  multivalues  expression  write  pipe  configuration  expression  mv  write  pipe  configuration  systematically  reproduced  writepipecomputevalue  reproduce  expression  passed  object  string  case  string  mv  compute  expression  string,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4800,request  allow  health  check  servlet  directly  query  single  health  check  name  am  request  able  access  individual  health  check  name  example  httplocalhost4502systemhealthnamedsling20get20servletjson  return  result  named  health  check,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4801,migrate  r6  annotation  clean  dependency  check  dependency  move  r6  osgi  annotation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4802,fsresource  support  node  descriptor  file  folder  binary  file  binary  file  folder  possible  add  additional  content  definition  file  name  add  additional  mixins  property  imported  ntfilentfolder  resource  change  jcr  primary  type  supported  fsresource  well  also  add  support  xml  descriptor  file  format  see  sling6828,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4803,provide  custom  navigator  provisioning  model  feature  file  working  slingstart  project  often  tedious  always  drill  srcmainprovisioning  viewedit  provisioning  model  file  provide  custom  contribution  simply  pull  srcmainprovisioning  folder  top  level,1,1,1,0,1,1,0,0,0,0,0,1,1,0,0,0,1
4804,migrate  parent  pom  32  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4805,jcr  content  parser  support  tick  well  double  quote  parsing  json  file  currently  content  parser  support  json  file  strict  format  plus  support  comment  json  file  also  support  tick  quoting  name  string  value  sling6871  content  loader,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4806,bundle  resource  provider  support  mounting  json  file  think  similar  sling6440  support  mounting  json  file  bundle  resource  provider  dont  need  support  file  format  xml  vault,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4807,maven  sling  plugin  deploy  fsresource  bundle  fsmount  goal  required  currently  osgi  configuration  created  fsmount  goal  fsresource  bundle  installed  effect  freshlyinstalled  instance  bundle  often  present  goal  fsmount  automatically  deploy  bundle  deployed  already  configurable  activated  default  minimum  version  fsresource  bundle  configured  via  plugin  property  bundle  deployed  old  version  deployed  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4808,implement  requestdispatcherforward  currently  slingrequestdispatcher  class  implementing  requestdispatcher  interface  inside  sling  implement  forward  method  since  method  may  used  certain  environment  also  implemented,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4809,referrer  filter  allow  regex  user  agent  exclusion  case  would  desirable  skip  referrer  check  altogether  certain  resource  path  instead  simply  setting  allow  empty  referrer  thus  weakening  security  overall  instead  well  known  set  path  would  desirable  reason  id  like  propose  adding  path  whitelist  referrer  filter  configuration  patch  attached,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4810,support  oauth  20  server  server  authentication  distribution  transport  scd  transport  support  oauth  20  authorization  grant  flow  0  flow  access  token  passed  via  authorization  header  every  request  simplehttpdistributiontransport  extended  support  authorization  header  provided  via  distributiontransportsecret  custom  distributiontransportsecretprovider  implementation  would  provide  access  token  distributiontransportsecrets  credential  map  0  httpstoolsietforghtmlrfc7523,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4811,adjust  abstractslingrepository2  reflect  sling6963  splitting  adjustment  abstractslingrepository2  sling6963  order  make  sure  enhancement  serviceusermapping  bundle  treated  separately  optional  change  abstractslingrepository2  imho  make  sense  also  reflect  enhancement  jcrbase  module  actually  illustrated  intention  inside  sling  code  base,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4812,pipesbuilder  api  rigid  thing  missing  pipe  api  workaround  additional  binding  writer  async  complicated  structure  write  filter  parameter  forgot  trying  groovy  pipebuilder  rather  cool  ui  generate  test  pipe  would  cool  everything  pipe  dont  want  enhancement  trigger  major  bump  version  id  like  change  10x,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
4813,add  utility  method  modelfactory  help  proper  model  creation  child  resource  request  context  present  somewhat  complex  generate  sling  model  object  really  adapter  class  included  resource  especially  true  adaptable  slinghttpservletrequest  object  different  case  problematic  1  want  inject  object  adapted  child  resource  adaptable  request  object  ie  want  override  requestgetresource  child  resource  2  want  inject  object  adapted  child  resource  regardless  adaptable  model  class  depends  upon  script  binding  first  case  currently  requires  creating  wrapper  request  second  case  complex  solve  correctly  requires  reinvoking  bindingsvaluesproviders  entail  creating  fake  scriptengine  solve  issue  would  like  add  new  method  named  getmodelfromwrappedrequest  parameter  would  slinghttpservletrequest  resource  class  method  would  create  wrapped  request  passed  resource  set  binding  new  object  reinvoke  bvps  patch  follow  wanted  file  early  get  feedback,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4814,add  slingforward  tag  sling692  implement  requestdispatcherforward  method  sling  taglib  enhanced  include  forward  tag,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
4815,add  slingscripthelperforward  method  sling692  implement  requestdispatcherforward  method  slingscripthelper  interface  enhanced  forward  method,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4816,update  common  lang  2x  35  module  still  using  old  common  lang  2x  version  update  maintained  3x  version,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
4817,access  control  setup  repositorylevel  permission  ie  null  path  mistaken  currently  possible  create  access  control  setup  principal  null  path  according  jsr  283  used  setup  repository  level  permission  node  type  definition  management  ie  registering  new  node  type  namespace  management  ie  registering  new  namespaces  privilege  management  ie  registering  new  privilege  workspace  management  ie  creatingremoving  workspace  operation  bound  path  like  eg  removing  item  creating  new  version  given  node  instead  take  global  effect  whole  jcr  repository  thats  permission  operation  cannot  granted  given  path  default  authorization  model  shipped  jackrabbit  oak  null  path  access  control  policy  stored  dedicated  reprepopolicy  node  located  root  node  service  user  definition  need  able  define  entry  null  path  policy  reason  explained  thanks  extending  repoinit  accordingly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4818,support  mixins  repoinit  create  path  statement  repoinit  create  path  statement  currently  support  nodetypes  mixins  add  support  current  create  path  syntax  like  code  create  path  slingfolder  vardiscoveryntunstructuredsomefolder  create  path  onetwothree  create  path  threefourntfolkfiventjazzsix  code  first  bracketed  statement  path  default  nodetype  subpaths  subpath  specific  nodetype  add  mixin  support  suggest  syntax  example  bracketed  statement  code  slingfolder  mixin  mixa  mixb  ntunstructured  mixin  mixc  mixin  mixa  mixin  mixa  mixb  code  last  two  form  without  nodeteype  meaning  set  mixins  keep  default  nodetype  example  code  create  path  slingfolder  varfoomixin  mixb  code  mean  varfoo  type  slingfolder  mixin  mixb  whereas  example  code  create  varbarmixin  mixc  code  varbar  us  default  type  defined  var  type  mixc  added,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4819,rename  metric  file  configuration  change  metric  reporter  introduced  sling7055  overwrites  existing  metric  file  configuration  changed  would  useful  keep  existing  file  renaming  otherwise  valuable  metric  data  gathered  far  lost,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4820,add  csv  pipe  would  cool  pipe  able  ingesting  csv  à  la  jsonpipe  repeating  input  output  outputing  line  value  binding  share  parent  class  could  also  add  possibility  consume  input  stream  request,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0
4821,pipe  builder  improvement  needed  improvement  would  cool  usage  pipe  builder  add  buildstring  method  allows  build  pipe  random  path  case  location  matter  searching  moving  executed  pipe  bit  tedious  allow  work  first  subpipe  would  affect  container  pipe  allowing  property  add  runwithstring  shorter  version  runmap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4822,allow  framework  restart  certain  operation  may  cause  osgi  framework  restart  calling  bundleupdate  system  bundle  calling  bundlestop  system  bundle  maybe  even  cause  application  terminate  removing  framework  extension  bundle  sling  launcher  control  felix  framework  launch  therefore  easily  cope  framework  restart  request  addition  osgi  bring  information  framework  terminating  decide  whether  launcher  relaunch  framework  simply  terminate,1,0,1,0,1,0,0,1,0,1,0,0,0,0,0,0,1
4823,sling  query  support  java  8  sling  query  written  java  7  us  number  concept  introduces  java  8  eg  predicate  function  replace  interface  native  javalang  type  also  possible  transform  slingquery  java  8  stream,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4824,htlmavenplugin  add  option  precompile  htl  script  would  cool  htl  maven  plugin  could  precompile  htl  script  similar  jspc  plugin  would  following  advantage  project  need  specify  compile  time  dependency  script  need  make  project  robust  change  dependency  easier  detectable  compiled  class  could  used  source  generate  importpackage  statement  filevaultpackagemavenplugin,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4825,add  pipemodel  add  pipe  model  allowing  quick  content  aggregation  java  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4826,nodebased  configs  jcrinstall  besides  existing  cfg  file  format  nodebased  configuration  would  make  granular  easier  patch  ill  implement  additional  config  source  jcrinstall  us  node  property  including  multivalue  taking  property  type  account,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
4827,add  configuration  default  get  servlet  produce  kind  response  would  desirable  configure  default  behavior  default  get  servlet  eg  reportdump  wil  generate  sort  dump  today  reportdirlisting  generate  dir  listing  subnodes  reportnumber  send  error  eg  403,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4828,process  resource  detection  installation  sequence  instead  asynchronously  currently  repositoryobservers  resource  detection  loop  osgicontrollers  installationupdatedelete  loop  run  separate  thread  running  detection  installation  operation  sequence  would  make  debugging  testing  easier  downside  except  maybe  slightly  slower  processing  installed  bundle  configs  think  tradeoff  worth  simple  implement  ill  add  executescheduledoperations  method  osgicontroller  interface  called  repositoryobserver  end  repository  observation  loop,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4829,improve  sling  embedded  repository  config  make  flexible  discussed  1  would  necessary  make  sling  embedded  repository  configuration  flexible  use  case  work  another  persistent  manager  node  rather  default  one  already  supported  jackrabbit  see  2  custom  login  module  access  manager  change  name  repository  propossal  three  new  property  name  jcr  repository  default  jackrabbit  slingrepositoryname  jcr  repository  home  directory  default  slinghomeslingrepositoryname  slingrepositoryhome  jcr  repository  url  config  file  repositoryxml  default  repositoryxml  bundle  embedded  jcr  repository  slingrepositoryconfigfileurl  property  set  slingproperties  system  property  web  app  initparams  property  mandatory  default  beahaviour  jackrabbit  repo  sling  home  property  set  1  httpmarkmailorgsearchcustomizingtheslingembeddedrepository  2  httpmarkmailorgmessage2mtvc3egw5omcrbdqcustomizingtheslingembeddedrepository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4830,support  start  level  assignment  bundle  contained  launchpad  package  currently  sling  launcher  support  assign  start  level  bundle  installed  resourcescorebundles  resourcesbundles  location  support  assigning  specific  start  level  folder  resource  folder  supported  denote  requested  start  level  way  assign  different  bundle  different  start  level  bundle  corebundles  would  default  using  start  level  1  bundle  bundle  would  default  default  start  level  defined  startlevel  service  likewise  bundle  folder  0  zero  would  assigned  default  start  level  folder  whose  name  cannot  parsed  positive  integer  ignored,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4831,web  console  plugin  osgi  installer  changed  title  discussion  moved  creating  console  plugin  making  servlet  jcrinstall  repositoryobserver  class  introduces  dependency  sling  api  servlet  bundle  desired  jcrinstall  dependency  kept  minimum  ill  move  servlet  bundle  currently  needed  integration  testing  might  useful  monitoring  purpose,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
4832,provide  better  configurability  integration  webdav  current  implementation  simple  webdav  support  provide  little  support  configuration  inner  operation  addition  mime  type  resolution  integrated  sling  support  mime  type  resolution  fix  sling  webdav  add  configuration  mean  extending  jackrabbit  resourceconfig  class  overwriting  method  along  line  mime  type  resolution  delegated  sling  mime  type  resolution  providing  slingmimeresolver  iomanager  propertymanager  hard  coded  use  default  implementation  dirlistingexporthandler  defaulthandler  registered  used  configuration  osgi  configuration  admin  defined  following  configuration  possible  supported  node  type  defining  noncollection  resource  item  filter  setting  namespace  uri  prefix  node  type  node  type  collection  noncollection  content  node  realm  string  url  root  separate  webdav  servlet,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4833,create  filesystem  provider  configuration  initial  content  sling  install  maven  sling  plugin  could  improved  generate  file  system  provider  factory  configuration  initial  content  slinginstall  plugin  read  generated  manifest  extract  initial  content  directive  us  post  new  configuration  felix  webconsole,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4834,add  possibility  force  reprocess  queued  job  entry  fifo  job  event  queue  process  job  proper  sequence  job  cannot  processed  scheduled  retry  certain  period  queue  wait  retry  delay  pas  new  job  added  queue  sometime  might  useful  bypass  wait  time  manually  let  queue  reprocess  job  immediately  example  config  change  per  userinteraction  via  gui  add  something  like  jobstatusproviderforcereprocessstring  queuename,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4835,improve  maven  module  layout  make  sling  easier  understand  discussed  slingdev  1  wed  like  restructure  source  code  split  sling  smaller  piece  make  easier  understand  suggested  maven  module  follows  thats  general  idea  detail  filled  slingapi  used  microsling  sling  microsling  microslingwebapp  us  slingapi  microslingcargotesting  im  planning  write  integration  test  sling  slingosgi  osgirelated  module  console  slingjcr  jcr  utility  module  wrapper  slingjsp  jasper  compiler  jsp  script  engine  slingcore  slingcommons  mailing  list  proposal  probably  useful  slingmavenplugins  existing  plugins  1  httpthreadgmaneorggmanecompapacheslingdevel555focus57,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4836,valuemapdecorator  support  array  albeit  jcrpropertymap  support  array  wrapper  yield  unexpected  problem  using  eg  use  following  code  get  detached  copy  jcr  property  map  node  content  nodegetnodejcrcontent  valuemap  prop  new  jcrpropertymapcontent  create  detached  copy  valuemap  property  new  valuemapdecoratornew  hashmapstring  objectprops  following  work  string  value  propertiesgetmyprop  new  string0  although  work  jcrpropertymap  p  provide  patch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4837,removereduce  90  second  wait  time  current  event  processor  wait  90  second  since  service  activation  start  processing  job  might  long  smallfast  system  even  low  bigslow  system  especially  job  processing  start  soon  respective  queue  listener  registered,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4838,openid  authenticationhandler  implementation  authenticationhandler  authenticating  user  openid  provider  includes  basic  ui  login  logout,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4839,support  getting  versioned  resource  using  uri  path  parameter  getting  versioned  content  support  thorough  uri  path  parameter  like  somethinghellov11  jcr  based  resource  value  version  either  point  version  name  label  order  change  existing  apis  introduce  new  utility  method  remove  uri  path  parameter  return  map  every  resource  provider  could  use  utility  method  decide  act  parameter  requested  version  exists  404  returned  requested  node  directly  point  versionable  node  algorithm  check  parent  hierarchy  versionable  node  found  try  get  version  node  go  path  versionable  node  requested  version  child  404  returned,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4840,pluggableloginmodule  provide  defaultloginmodule  extension  via  bundle  service  enhance  jackrabbit  server  module  adding  pluggabledefaultloginmodule  extending  defualtloginmodule  loginmoduleplugin  interface  pluggabledefaultloginmodule  us  loginmoduleplugin  instance  verify  credential  presented  user  pluggabledefaultloginmodule  fall  back  defaultloginmodule  implementation  support  credential  instance  presented  approach  allows  custom  authenticationhandlers  provide  custom  login  behavior  credential  pas  slingauthenticator  particularly  useful  password  made  available  handler  authentication  process,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4841,add  http  put  support  mavenslingplugin  addition  standard  post  tailored  felix  webconsole  mavenslingplugin  install  goal  also  useful  support  simple  put  uploads  bundle  jar  useful  combination  jcrinstall  extension  could  put  jar  file  via  jackrabbit  sling  webdav  folder  watched  jcrinstall  therefore  implemented  feature  using  put  install  goal  delete  uninstall  goal  new  config  option  slinguseput  must  set  true  using  put  delete  default  false  post  behaviour  stay  default  make  configuration  plugin  multimodule  pom  structure  simpler  also  added  new  config  slingurlsuffix  present  appended  slingurl  case  post  put  delete  allows  specify  base  path  parent  pom  slingurlhttplocalhost8080  define  different  path  project  slingurlsuffixlibsmyprojectinstall  jcrinstall  place  different  location  repository  wish  also  slingmimetypeforput  option  set  contenttype  put  request  default  applicationjavaarchive  reference  since  config  name  different  specify  pom  using  java  field  name  mojo  rather  defined  expression  sample  configuration  plugin  groupidorgapacheslinggroupid  artifactidmavenslingpluginartifactid  version203incubatorsnapshotversion  configuration  slingurlhttplocalhost8080slingurl  slingurlsuffixlibsmyprojectinstallslingurlsuffix  useputtrueuseput  configuration  plugin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4842,use  new  common  compiler  java  servlet  scripting  currently  java  servlet  scripting  bundle  embeds  version  eclipse  compiler  changed  use  new  common  compiler,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,0,0
4843,new  bundle  resourceprovider  sling  post  operation  interacting  jackrabbit  usermanager  new  bundle  provides  custom  resourceprovider  slingpostoperations  interacting  jackrabbit  usermanager  resourceprovider  expose  user  path  systemusermanageruserusername  group  path  systemusermanagergroupgroupname  order  custom  slingpostoperations  work  patch  sling651  must  applied  first  custom  slingpostoperations  provided  1  createuser  2  creategroup  3  changepassword  4  updateauthorizable  5  deleteauthorizable  sample  usage  operation  sampleshtmlesp  attachment,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,1,1
4844,use  slingapi  sling28  microsling  agree  sling28  microsling  ported  api  microsling  sling  use  make  sure  tag  httpsvnapacheorgreposasfincubatorslingwhiteboardmicrosling,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4845,allow  servlets  registered  extension  request  method  sling754  introducedfixed  registering  servlets  nonget  method  selector  eg  appsmyappselectorpostservlet  possible  extension  appsmyappextensionpostservlet  use  case  symmetric  url  import  export  stuff  given  resource  path  export  get  somepathfooext  importupdate  post  somepathfooext  currently  forced  either  use  selector  post  case  somepathfooextext  sling  resource  type  set  somepathfoo  could  single  post  servlet  resource  type  regardless  extension  unpractical  example  resource  type  like  calendar  want  import  various  calendar  format  separated  file  extension,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4846,rename  simplewebdavservlet  avoid  confusion  jackrabbit  discussed  httpmarkmailorgmessagemzw5p6ydarklwsyb  ill  rename  slingsimplewebdavservlet  slingwebdavservlet  already  used,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4847,microjax  lightweight  ajax  client  servlet  microsling  discussed  mailing  list  1  ill  contribute  microsling  experimental  rjax  stuff  2  wrote  together  david  nuescheler  main  change  1  default  microsling  servlet  need  handle  post  clever  way  provide  useful  service  javascript  client  2  get  default  microsling  servlet  need  provide  json  representation  json  extension  used  extensible  xml  output  format  1  httpthreadgmaneorggmanecompapacheslingdevel721  2  httpwwwdaycommavenrjax,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4848,json  item  renderer  microsling  sling92  need  json  renderer  ill  attach  json  output  rjax  prototype  example,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4849,refine  initiaition  authentication  process  currently  authentication  process  initiated  explicitly  calling  login  page  provided  authenticationhandler  implementation  bundle  way  initiate  authentication  process  within  servlet  script  eg  user  log  404not  found  error  handler  support  kind  functionality  existing  slingauthenticatorrequestauthentcation  method  publicly  accessible  service  interface  servlets  script  want  request  authentication  client  current  request  may  call  service  method  method  applies  authentication  handler  selection  algorithm  given  httpservletrequest  object  finding  authentication  handler  authenticate  process  ensures  given  request  appropriate  authentication  handler  called  able  initiate  authentication  appropriately  example  drawing  form  full  detail  refer  httpcwikiapacheorgslingauthenticationinitiationhtml,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4850,add  suppport  tcpip  based  control  connection  sling  standalone  app  currently  sling  standalone  application  stopped  stopping  system  bundle  killing  sling  process  better  control  sling  control  connection  support  based  tcpip  would  nice  way  sling  standalone  application  may  used  start  sling  check  running  sling  instance  stop  running  sling  instance  following  command  line  argument  added  start  sling  open  tcpip  server  socket  control  conneciton  status  check  whether  sling  instance  listening  tcpip  socket  stop  stop  sling  instance  listening  tcpip  socket  none  start  sling  without  listening  tcpip  socket  socket  listen  start  option  send  command  status  stop  configured  j  command  line  option  option  take  argument  following  form  hostport  host  name  ip  address  port  number  socket  port  port  number  localhost  inetaddressgetlocalhost  socket  none  j  specified  default  port  63000  localhost  note  setting  host  name  ip  address  reachable  remote  system  may  considered  security  issue  since  connection  secured  password  reason  default  interface  listen  local  host  server  socket  created  explicitly  asked  start  parameter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4851,mimetypeservice  expose  default  mime  type  config  osgi  web  console  please  consider  exposing  default  mime  type  currently  defined  launchpad  webxml  osgi  configuration  accessible  web  console  repository  based  content  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4852,ensure  official  mime  type  cannot  overwritten  bundle  andor  configuration  currently  mimetype  service  implemented  mime  type  registration  overwrites  registration  already  existing  may  cause  thirdparty  bundle  mime  type  provider  overwrite  official  mapping  core  mime  type  file  service  modified  core  mime  type  file  read  first  later  mapping  cannot  overwrite  existing  mapping,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4853,allow  sling  log  configured  rotate  time  instead  file  size  log4j  ability  rotate  log  dailybased  time  parameter  rather  file  size  make  system  administration  easier  since  right  log  file  easily  identified  based  problem  occurred  similar  feature  inside  sling  logging  would  useful,1,0,1,0,1,0,0,0,0,0,1,1,0,0,0,0,1
4854,allow  atom  syndication  format  output  json  output  sling  quite  nice  many  web  application  require  rssatom  support  day  extension  module  provides  tag  library  creating  atom  feed  atom  entry  jcr  node  would  helpful,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4855,stormelasticsearch  expose  transportclient  configuration  map  esconfig  stormelasticsearch  hardcoded  configuration  transportclient  clienttransportsniff  true  user  may  want  change  value  may  also  want  add  another  configuration  please  refer  httpswwwelasticcoguideenelasticsearchclientjavaapicurrenttransportclienthtml  want  pas  configuration  transportclient  think  would  better  expose  map  esconfig  put  thing  inside  map  immutablesettingssettingsbuilder,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0,1
4856,storm  cassandra  connector  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4857,make  statsmetrics  fast  stats  built  metric  slow  make  fast  either  process  data  sample  much,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4858,support  operator  stormsql  jira  proposes  compile  operator  java  source  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4859,iconnection  push  batch  instead  buffering  messaging  layer  currently  buffer  tuples  wait  one  thread  take  tuples  route  need  go  add  extra  thread  tuple  go  processed  place  tuple  linkedblockingqueue  waiting  one  thread  ready  process  data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4860,support  string  operation  stormsql  jira  track  effort  implementing  string  operation  stormsql,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4861,reduce  thread  usage  netty  transport  user  start  create  large  topology  storm  netty  messaging  layer  us  lot  thread  resulted  ooms  default  ulimit  linux  distros  around  4000  process  look  like  messaging  layer  want  one  thread  per  server  connected  mean  total  number  worker  system  one  particular  case  saw  1  curator  delay  thread  1  curator  event  processor  1  finalizer  1  gc  1  storm  messaging  recv  thread  asking  netty  message  1  thread  pool  polling  synchronous  queue  1  zk  connection  1  zk  epoll  2  2  netty  epoll  6  timer  thread  15  disruptor  consume  batch  104  netty  thread  pool  taking  message  sent  process  dieing  ooms  could  create  netty  thread  looking  code  appears  come  two  different  thing  first  client  code  using  thread  pool  client  instead  sharing  thread  pool  also  protocol  block  thread  takemessages  message  send  need  make  thread  pool  shared  client  modify  protocol  takemessages  block  blocking  also  need  way  clientsend  write  directly  channel  situation  message  still  sent,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4862,support  collation  primary  key  jira  proposes  add  support  specifying  collation  primary  key  collation  provide  information  uniqueness  monotonicity  column  information  essential  implement  aggregation  function  streaming  data,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4863,support  distributed  deployment  stormsql  stormsql  compiles  sql  statement  java  class  trident  topology  executes  class  order  execute  sql  statement  class  need  properly  distributed  nimbus  topology  run  distributed  mode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4864,migrate  apis  orgapachestorm  try  provide  backwards  compatability  bridge  want  move  storm  classpaths  orgapachestorm  wherever  possible  also  want  provide  backwards  compatibility  user  facing  apis  whenever  possible,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4865,port  backtypestormsecurityauthauthutilstest  java  test  moving  junit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4866,port  backtypestormcommanduploadcredentials  java  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4867,port  backtypestormutilstest  java  junit  test  migration,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4868,port  backtypestormdaemonnimbus  java  httpsgithubcomapachestormtreejstormimportjstormcoresrcmainjavacomalibabajstormdaemonnimbus  possible  example,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4869,port  backtypestormdaemonworker  java  httpsgithubcomapachestormtreejstormimportjstormcoresrcmainjavacomalibabajstormdaemonworker  example,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4870,port  backtypestormdaemonlogviewer  java  providing  ui  accessing  searching  log  hiccup  need  replaced  possibly  hard  coded  html  escaping,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4871,port  backtypestormtesting  java  lot  helper  functionsmacros  running  test  might  need  stay  cojure  java  equivalent  used  test  ported,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4872,port  backtypestormuicore  java  user  interface  rest  java,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
4873,port  backtypestormworkertest  java  test  worker,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4874,trident  support  writing  multiple  kafka  cluster  current  impossible  instantiate  two  instance  tridentkafkastate  class  write  different  kafka  cluster  tridentkafkastate  obtains  location  kafka  producer  configuration  multiple  instance  get  configuration  prepare  method  jira  proposes  introduce  configuration  class  like  tridentkafkaconfig  allow  multiple  instance  tridentkafkastate  write  different  kafka  cluster,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4875,support  writing  kafka  stream  storm  sql  jira  proposes  add  support  write  sql  result  kafka  stream,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4876,support  group  clause  stormsql  jira  track  effort  implement  support  group  clause  stormsql,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
4877,support  explain  statement  stormsql  useful  support  explain  statement  stormsql  allow  debugging  customizing  topology  generated  stormsql,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4878,compile  calcite  logical  plan  storm  trident  logical  plan  suggested  httpsissuesapacheorgjirabrowsestorm1040focusedcommentid15036651pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment15036651  compiling  logical  plan  calcite  storm  physical  plan  clarify  implementation  stormsql  motive  behind  big  change  benefit  started  julian  commenthttpsissuesapacheorgjirabrowsestorm1040focusedcommentid15034472pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment15034472  also  milindas  commenthttpsissuesapacheorgjirabrowsestorm1040focusedcommentid15035182pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment15035182  relational  algebra  rel  several  advantage  push  operator  handling  logic  rel  traverse  calcite  logical  rel  tree  postorderrelnodevisitor  visitor  need  handle  calcite  rel  directly  logic  configure  trident  topology  handled  separate  rels  sometimes  want  derived  rels  compared  calcite  logical  operator  one  example  join  there  one  logical  rel  regarding  join  calcite  logicaljoin  converting  logicaljoin  equijoin  condition  met  various  type  join  make  difference  prepared  yet  streaming  scan  v  table  scan  streaming  insert  v  table  insert  case  code  tridentstormaggregaterelgroup0  expr1count  tridentstormcalcrelexpr04inputs  expr50  expr6t0  t5  deptidt3  empidt0  conditiont6  tridentstormequijoinrelcondition2  3  jointypeinner  tridentstormstreamscanreltableemp  tridentstormstreamscanreltabledept  code  even  override  method  represent  rel  explain  string  think  calcite  explain  le  informational  example  showing  initial  parallelism  support  scan  apply  query  optimization  defining  derived  rels  help  query  optimization  like  filter  pushdown  calcite  rels  aware  data  source  characteristic  include  rels,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0
4879,fix  bug  refactor  code  resourceawarescheduler  code  refactored  1  refactor  rasnodes  pushed  functionality  rasnodes  rasnode  initialized  map  assignment  rasnode  also  figure  resource  used  available  removed  unnecessary  function  2  made  workerslot  immutable  scheduling  strategy  wont  mistakenly  modify  3  added  wrapping  layer  rasnode  feed  scheduling  strategy  semantics  scheduling  strategy  clear  scheduling  strategy  shouldnt  actually  assigning  anything  strategy  calculate  scheduling  bug  fix  1  minor  bug  displaying  assigned  resource  supervisor  ui  function  updatesupervisorresources  placed  wrong  place  2  minor  bug  fix  freeing  memory  rasnode  wrong  math  done,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4880,stormhdfs  support  writing  multiple  file  example  needed  include  one  avro  bolt  writing  multiple  schema  require  different  file  schema  evolution  common  use  avro  avro  bolt  support  seamlessly  partitioning  output  different  directory  based  tuple  content  example  tuple  contains  user  field  possible  partition  based  value,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
4881,load  balancing  shuffle  grouping  httpsgithubcomnathanmarzstormissues571  hey  nathanmarz  think  current  shuffle  grouping  creating  obvious  hotspot  load  host  twitter  reason  randomized  message  distribution  worker  susceptible  ball  bin  problem  httppagescswiscedushuchicourses787f07scribenoteslecture07pdf  odds  particular  queue  get  bogged  youre  assigning  task  randomly  high  solve  problem  loadaware  shuffle  grouping  shuffling  prefer  task  lower  load  would  take  implement  feature  sritchie  look  like  rap  genius  heavily  affected  heroku  started  running  shuffle  grouping  task  dynos  httprapgeniuscomjamessomersherokusuglysecretlyrics  50x  performance  degradation  intelligent  loadbalancing  scheme  sent  task  nonbusy  dynos  seems  relevant  storm  nathanmarz  randomized  round  robin  fully  random  distribution  every  downstream  task  get  number  message  yes  agree  would  great  feature  basically  requires  making  stats  downstream  task  available  stream  grouping  code  best  way  implement  would  implement  broadcast  message  type  networking  code  one  efficiently  send  large  object  task  worker  rather  send  n  copy  large  message  single  executor  every  topology  poll  nimbus  accumulated  stats  per  minute  broadcast  information  task  worker  wire  task  code  pas  information  along  task  outgoing  stream  grouping  task  adding  appropriate  method  customstreamgrouping  interface  receive  stats  info  sorenmacbeth  nathanmarz  sritchie  progress  ever  get  made  description  still  relevant  storm  090  getting  bitten  problem  would  love  see  something  like  implemented,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4882,minor  refactoring  resource  aware  scheduler  refactored  following  1  api  interface  define  custom  scheduling  strategy  api  exposed  ra  per  topology  scheduling  strategy  messy  need  cleaned  2  ra  state  scheduler  held  several  member  variable  cleaner  scheduler  state  represented  single  object  help  reduce  amount  code  need  checkpointing  state  scheduler  potentially  restoring  state  future  bad  scheduling  happens,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
4883,drpcspout  attempt  reconnect  fail  cannot  reach  client  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4884,optimize  kryo  instaces  creation  hbasewindowsstore  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4885,abstract  batch  processing  common  api  batchhelper  external  projectsstormhbase  stormhive  stormmongodb  batch  processing  logic  abstracting  could  make  code  simpler  cleaner,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
4886,cap  number  retries  failed  message  kafka  spout  kafkaspout  module  based  newer  apis  cap  number  time  message  retried  good  feature  add  older  kafka  spout  code  well,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4887,better  algorithm  server  rack  selection  ra  currently  getbestclustering  algorithm  ra  find  best  clusterrack  based  rack  available  resource  may  insufficient  may  cause  topology  able  scheduled  successfully  even  though  enough  resource  schedule  cluster  attempt  find  rack  resource  find  rack  biggest  sum  available  memory  available  cpu  method  effective  since  consider  number  slot  available  method  also  fails  identifying  rack  schedulable  due  exhaustion  one  resource  either  memory  cpu  slot  current  implementation  also  try  initial  scheduling  one  rack  try  schedule  rack  giving  may  cause  topology  failed  scheduled  due  mentioned  shortcoming  current  method  also  current  method  consider  failure  worker  executor  topology  get  unassigned  need  scheduled  current  logic  getbestclustering  may  inadequate  complete  wrong  executor  need  rescheduled  due  fault  getbestclustering  likely  return  cluster  different  majority  executor  topology  originally  scheduling  thus  propose  different  strategyalgorithm  find  best  cluster  come  ordering  strategy  dub  subordinate  resource  availability  ordering  inspired  dominant  resource  fairness  sort  rack  subordinate  dominant  resource  availability  example  given  4  rack  following  resource  availability  code  generate  alot  memory  little  cpu  rack3  avail  cpu  1000  mem  2000000  slot  40  total  cpu  1000  mem  2000000  slot  40  generate  supervisor  depleted  one  resource  rack2  avail  cpu  00  mem  800000  slot  40  total  cpu  00  mem  800000  slot  40  generate  lot  cpu  little  memory  rack4  avail  cpu  61000  mem  100000  slot  40  total  cpu  61000  mem  100000  slot  40  generate  another  rack  supervisor  le  resource  rack0  rack1  avail  cpu  20000  mem  400000  slot  40  total  cpu  20000  mem  400000  slot  40  rack0  avail  cpu  40000  mem  800000  slot  40  total  cpu  40000  mem  800000  slot  40  cluster  overall  avail  cpu  122000  mem  4100000  slot  200  total  cpu  122000  mem  4100000  slot  200  code  clear  rack0  best  cluster  since  balanced  potentially  schedule  executor  rack2  worst  rack  since  rack2  depleted  cpu  resource  thus  rendering  unschedulable  even  though  resource  available  first  calculate  resource  availability  percentage  rack  resource  computing  code  resource  available  rack  resource  available  cluster  code  calculation  normalize  value  otherwise  resource  value  would  comparable  example  code  rack3  avail  cpu  0819672131147541  mem  4878048780487805  slot  200  effective  resource  000819672131147541  rack2  avail  00  mem  1951219512195122  slot  200  effective  resource  00  rack4  avail  cpu  500  mem  24390243902439024  slot  200  effective  resource  0024390243902439025  rack1  avail  cpu  1639344262295082  mem  975609756097561  slot  200  effective  resource  00975609756097561  rack0  avail  cpu  3278688524590164  mem  1951219512195122  slot  200  effective  resource  01951219512195122  code  effective  resource  rack  also  subordinate  resource  computed  code  minresource  availability  percentage  cpu  memory  free  slot  code  order  rack  effective  resource  thus  example  code  sorted  rack  rack0  rack1  rack4  rack3  rack2  code  also  deal  presence  failure  topology  partially  scheduled  find  rack  scheduled  executor  topology  try  schedule  rack  first  thus  sorting  rack  first  sort  number  executor  already  scheduled  rack  subordinate  resource  availability,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
4888,add  simple  equijoin  support  stormsql  standalone  mode  provide  simple  equi  join  support  storm  sql  standalone  mode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4889,kinesis  spout  storm  increasingly  used  cloud  environment  great  kinesis  spout  integration  apache  storm,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
4890,one  topology  cant  use  hdfs  spout  read  two  location  hdfs  uri  passed  using  config  code  confputconfigshdfsuri  hdfsuri  code  see  two  problem  approach  1  someone  want  used  two  hdfsuri  different  spout  seem  feasible  httpsgithubcomapachestormblobd17b3b9c3cbc89d854bfb436d213d11cfd4545ecexamplesstormstartersrcjvmstormstarterhdfsspouttopologyjaval117l117  httpsgithubcomapachestormblobd17b3b9c3cbc89d854bfb436d213d11cfd4545ecexternalstormhdfssrcmainjavaorgapachestormhdfsspouthdfsspoutjaval331l331  code  confcontainskeyconfigssourcedir  logerrorconfigssourcedir  setting  required  throw  new  runtimeexceptionconfigssourcedir  setting  required  thissourcedirpath  new  path  confgetconfigssourcedirtostring  code  2  fail  fast  ie  time  topology  submissing  fail  fast  hdfs  path  invalid  credentialspermissions  ok  error  time  detected  runtime  looking  worker  log  httpsgithubcomapachestormblobd17b3b9c3cbc89d854bfb436d213d11cfd4545ecexternalstormhdfssrcmainjavaorgapachestormhdfsspouthdfsspoutjaval297l297,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4891,upgrade  jetty  ring  jetty  7  eol  upgrade  jetty  9  ring  could  also  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4892,kafka  new  client  api  support  topic  wildcards  0,1,0,1,0,1,0,0,0,0,1,0,0,0,1,1,1,0
4893,topology  submission  improvement  support  adding  local  jar  maven  artifact  submission  jira  track  actual  work  proposal  design  document  httpscwikiapacheorgconfluencedisplaystormadesigndoc3aaddingjarsandmavenartifactsatsubmission  proposal  discussion  thread  httpmailarchivesapacheorgmodmboxstormdev201608mbox3ccaf5108i9tjanz0lgrktmkvqel7f53k9uyzxct6zhsu6ohx9qmailgmailcom3e  let  post  discussion  thread  opinion  idea  instead  leaving  comment  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4894,simplify  threading  model  supervisor  trying  roll  cgroup  enforcement  right  running  number  race  condition  supervisor  using  cgroups  timing  operation  different  exposing  issue  would  see  without  order  make  progress  testingdeploying  cgroup  ra  going  try  refactor  supervisor  simpler  threading  model  likely  thread  base  code  java  code  currently  master  may  replace  20  release  plan  part  1x  truly  stable  try  keep  jira  date  architecture  keep  community  informed  need  move  quickly  meet  company  goal  shove  welcome  feedback  design  code  go  community,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
4895,support  join  statement  storm  sql  would  great  support  join  statement  storm  sql  httpstormapacheorgreleases101tridentapioverviewhtml  according  page  trident  support  join  across  multiple  spout  done  synchronizing  spout  might  good  start  storm  sql  join  feature  restricts  boundary  join  batch  ok  since  aggregation  implemented  via  restriction,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4896,blacklist  scheduler  company  gone  fault  production  critical  switch  cause  unstable  network  set  machine  package  loss  rate  3050  fault  supervisor  worker  machine  definitely  dead  easy  handle  instead  still  alive  unstable  lost  heartbeat  nimbus  occasionally  nimbus  circumstance  still  assign  job  machine  soon  find  invalid  result  slow  convergence  stable  status  deal  unstable  case  intend  implement  blacklist  scheduler  add  unstable  node  supervisor  slot  blacklist  temporarily  resume  later,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4897,supervisor  v2  merge  async  localizer  localizer  mere  storm2018  httpsgithubcomapachestormpull1642  look  merging  two  localizers  single  class,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
4898,replace  consumer  isqltridentdatasource  statefactory  stateupdater  currently  isqltridentdatasource  expose  function  consumer  provides  single  row  update  maximize  performance  changed  statefactory  statespec  stateupdater  also  includes  change  stormsqlkafka,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4899,improve  logging  trident  core  example  improve  logging  make  code  easier  debug  extend,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4900,introduce  new  sql  external  module  stormsqlmongodb  issue  track  adding  stormsqlmongodb  new  sql  external  module,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4901,supervisor  v2  use  lot  memory  launching  worker  supervisor  read  complete  topology  get  small  amount  data  large  past  would  launch  worker  one  time  needed  enough  memory  read  parallel  lot  tend  show  close  one  another  need  find  way  make  read  data  one  ideally  cache  someplace  everyone  share,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4902,use  calcite  implementation  rex  compiler  looking  calcite  found  calcite  interpreter  also  rex  compiler  word  dont  need  handle  rex  operation  borrow  provide  calcite  support  rex  handling  pulling  need  make  test  check  storm  sql  provides  functionality  sql  reference  calcite  page  httpcalciteapacheorgdocsreferencehtml,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
4903,improving  current  scheduling  strategy  ra  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
4904,let  shellbolts  shellspouts  run  script  blob  would  nice  able  use  script  executable  file  distributed  blob  store  rather  resource  directory  jar  nice  allows  use  tgz  preserve  execute  bit  file  like  script  biggest  issue  shellprocess  switch  current  working  directory  process  code  dir  storm  jar  extracted  simple  way  child  process  find  way  back  blob  add  new  option  change  cwd,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4905,storm  sql  trident  mode  back  code  generate  compile  trident  topology  storm  sql  convert  rex  code  block  pas  evaluation  class  class  evaluate  code  block  runtime  change  made  code  greatly  simplified  expect  performant  compiling  execute  natively  linq4j  calcite  provides  utility  method  make  code  nicely  going  really  really  verbose  really  better  string  concatenated  code  block  since  doesnt  guard  let  convert  back  code  generation  elegant,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
4906,storm  sql  support  avro  input  output  format  support  avro  input  output  format  try  generalize  regardless  data  source  cant  address  data  source  datasources  compatible  avro  documented,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4907,refactor  storm  kafka  example  module  refactor  stormkafkaclient  stormkafka  example  similarly  done  storm1970,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4908,dynamic  scheduler  configuration  loader  would  useful  scheduler  configuration  multitenant  resource  aware  scheduler  could  loaded  updated  dynamically  local  file  change  update  configuration  archive  artifactory  repository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4909,finish  porting  drpc  java  drpcclj  gone  remains  main  rest  api  finish  translating  java,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4910,expose  method  override  computing  field  given  tuple  fieldselector  orgapachestormcassandraqueryselectorfieldselector  give  way  customize  computing  field  value  tuple,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4911,storm  kafka  client  support  manual  partition  management  currently  storm  kafka  client  relies  kafka  assign  partition  spout  may  cause  unnecessary  rebalance  case  storm  eg  worker  restart  slow  processing  tuples,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
4912,kafka  spout  refactoring  increase  modularity  testability  per  discussion  httpsgithubcomapachestormpull1826  kafkaspout  class  split  bit  unit  test  improved  use  time  simulation  break  encapsulation  spout  test,1,0,1,0,1,0,0,1,0,1,0,0,0,0,0,0,1
4913,send  activate  deactivate  command  shellspout  deactivate  activate  called  shellspout  call  send  corresponding  shellprocess  multilang  command  example  shellspout  poll  data  source  resouces  gracefully  allocated  deallocated  deactivation  otherwise  possibility  react  event  via  multilang  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4914,abstract  class  configurabletopology  class  run  topology  often  repeat  code  pattern  populate  configuration  file  instead  storm  determine  whether  run  locally  remotely  set  ttl  topology  flux  provides  elegant  way  dealing  sometimes  simpler  define  topology  java  code  stormcrawlerhttpstormcrawlernet  implemented  abstract  class  named  configurabletopology  extended  save  user  hassle  write  code  thing  open  pr  containing  class  discus  comment  whether  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4915,cgroup  metric  isolation  cgroups  would  really  nice  could  also  monitoring  various  usage  metric  cgroups  part  look  like  reading  special  file  exist  able  read  procselfcgroup  see  cgroup  part  cgroup  read  config  cgroup  mounted  stormcgrouphierarchydir  read  httpslwnnetarticles529927  memoryusageinbytes  current  usage  byte  memorylimitinbytes  current  limit  byte  httpskernelgooglesourcecompubscmlinuxkernelgitglommermemcgcpustatdocumentationcgroupscputxt  cpuacctusage  aggregate  cpu  time  nanosecond  consumed  task  group  cpuacctstat  aggregate  user  system  time  consumed  task  group  format  user  x  system  note  cpuacct  need  mounted  cgroup  support  work  file  dont  exist  dont  register  metric  dont  report  anything,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4916,stormredis  use  binary  type  state  management  currently  stormredis  provides  rediskeyvaluestate  us  string  type  method  additional  base64  encodingdecoding  change  use  binary  type  method  get  rid  base64  usage  maybe  need  provide  tool  convert  base64  encoded  state  origin  there  another  thing  correct  doesnt  support  redis  cluster,1,0,1,0,1,0,1,1,0,0,0,1,1,0,0,0,0
4917,stormelasticsearch  switch  e  client  java  rest  api  following  documentation  httpsstormapacheorgreleases101stormelasticsearchhtml  httpsgithubcomapachestormblobmasterexternalstormelasticsearchpomxmll40  cause  error  writing  elastic  5x  codelanguagejava  javalangnoclassdeffounderror  orgelasticsearchcommonbasepreconditions  orgapachestormelasticsearchcommonesconfiginitesconfigjava62  stormelasticsearch102jar102  orgapachestormelasticsearchcommonesconfiginitesconfigjava49  stormelasticsearch102jar102  caused  javalangclassnotfoundexception  orgelasticsearchcommonbasepreconditions  javaneturlclassloaderfindclassurlclassloaderjava381  180112  javalangclassloaderloadclassclassloaderjava424  180112  sunmisclauncherappclassloaderloadclasslauncherjava331  180112  javalangclassloaderloadclassclassloaderjava357  180112  261538  elasticsearchringleadergenerict2  info  oectransport  ringleader  failed  get  node  info  transport1svaddiinetlocalhost1270019200  disconnecting  orgelasticsearchtransportreceivetimeouttransportexception  inetlocalhost1270019200clustermonitornodesinfo  requestid  26  timed  5005ms  orgelasticsearchtransporttransportservicetimeouthandlerruntransportservicejava529  elasticsearch160jar  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1142  180112  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava617  180112  javalangthreadrunthreadjava745  180112  code  elastic  log  codelanguagejava  20170223t154704487warn  oetnnetty4transport  qt9qlnv  exception  caught  transport  layer  id  0x8f15e875  l1270019300  r12700152031  closing  connection  javalangillegalstateexception  received  message  unsupported  version  100  minimal  compatible  version  500  orgelasticsearchtransporttcptransportmessagereceivedtcptransportjava1199  elasticsearch500jar500  orgelasticsearchtransportnetty4netty4messagechannelhandlerchannelreadnetty4messagechannelhandlerjava74  transportnetty4500jar500  ionettychannelabstractchannelhandlercontextinvokechannelreadabstractchannelhandlercontextjava372  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextinvokechannelreadabstractchannelhandlercontextjava358  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextfirechannelreadabstractchannelhandlercontextjava350  nettytransport415finaljar415final  ionettyhandlercodecbytetomessagedecoderfirechannelreadbytetomessagedecoderjava293  nettycodec415finaljar415final  ionettyhandlercodecbytetomessagedecoderfirechannelreadbytetomessagedecoderjava280  nettycodec415finaljar415final  ionettyhandlercodecbytetomessagedecodercalldecodebytetomessagedecoderjava396  nettycodec415finaljar415final  ionettyhandlercodecbytetomessagedecoderchannelreadbytetomessagedecoderjava248  nettycodec415finaljar415final  ionettychannelabstractchannelhandlercontextinvokechannelreadabstractchannelhandlercontextjava372  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextinvokechannelreadabstractchannelhandlercontextjava358  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextfirechannelreadabstractchannelhandlercontextjava350  nettytransport415finaljar415final  ionettychannelchannelinboundhandleradapterchannelreadchannelinboundhandleradapterjava86  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextinvokechannelreadabstractchannelhandlercontextjava372  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextinvokechannelreadabstractchannelhandlercontextjava358  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextfirechannelreadabstractchannelhandlercontextjava350  nettytransport415finaljar415final  ionettychanneldefaultchannelpipelineheadcontextchannelreaddefaultchannelpipelinejava1334  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextinvokechannelreadabstractchannelhandlercontextjava372  nettytransport415finaljar415final  ionettychannelabstractchannelhandlercontextinvokechannelreadabstractchannelhandlercontextjava358  nettytransport415finaljar415final  ionettychanneldefaultchannelpipelinefirechannelreaddefaultchannelpipelinejava926  nettytransport415finaljar415final  ionettychannelnioabstractniobytechannelniobyteunsafereadabstractniobytechanneljava129  nettytransport415finaljar415final  ionettychannelnionioeventloopprocessselectedkeynioeventloopjava610  nettytransport415finaljar415final  ionettychannelnionioeventloopprocessselectedkeysplainnioeventloopjava513  nettytransport415finaljar415final  ionettychannelnionioeventloopprocessselectedkeysnioeventloopjava467  nettytransport415finaljar415final  ionettychannelnionioeventlooprunnioeventloopjava437  nettytransport415finaljar415final  ionettyutilconcurrentsinglethreadeventexecutor5runsinglethreadeventexecutorjava873  nettycommon415finaljar415final  javalangthreadrunthreadjava745  180121  code,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
4918,stormhbase  support  hbase  state  backend  providing  redis  state  backend  someone  may  claim  1  redis  suitable  persistent  storage  memory  cheap  enough  2  user  install  maintain  redis  even  redis  cluster  even  stack  also  hadoop  environment  supporting  hbase  state  backend  address  two  thing  open  possibility  make  state  scalable,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4919,support  list  childopts  beyond  worker  following  worker  childopts  configuration  option  support  string  value  list  string  value  code  workerchildopts  workerprofilerchildopts  workergcchildopts  topologyworkerchildopts  topologyworkergcchildopts  topologyworkerlogwriterchildopts  code  currently  following  childopts  configuration  option  support  string  code  nimbuschildopts  logviewerchildopts  uichildopts  pacemakerchildopts  drpcchildopts  supervisorchildopts  code  please  could  list  supported  across  childopts  option  make  configuration  management  building  easier  using  automated  tool  chef  puppet,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4920,record  version  revision  information  build  effect  shown  code  titlefor  subversion  project  storm  version  storm  092incubatingsnapshot  subversion  httpsgithubcomapacheincubatorstormtrunkstormcore  r  1959  compiled  somebody  wed  feb  19  112338  cst  2014  source  checksum  9347aded8a39f3ddf8e8f2f9bf56186f  code  code  java  classpath  stormcore092incubatingsnapshotjar  backtypestormutilsversioninfo  storm  092incubatingsnapshot  subversion  httpsgithubcomapacheincubatorstormtrunkstormcore  r  1959  compiled  somebody  wed  feb  19  112338  cst  2014  source  checksum  9347aded8a39f3ddf8e8f2f9bf56186f  code  code  titlefor  git  project  storm  version  ➜  stormcurrent  storm  version  running  storm  0100snapshot  subversion  httpsgithubcomcaofangkunapachestormgit  r  ffba148cc47a92185fa1a5db11f72982de10f106  branch  storm243  compiled  caokun  thu  jan  8  104748  cst  2015  source  checksum  97e7c942939e3e82dcb854b497991a51  code  ui,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4921,ondemand  resource  requirement  scaling  first  step  towards  true  elasticity  storm  topology  propose  allowing  rebalance  also  modify  resource  requirement  boltspout  topology  automatic  let  user  scale  cpumemory  needed  component,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
4922,break  stormcore  extract  client  worker  artifact  interest  client  side  artifact  modularize  storm  storm30  storm117  id  like  give  credit  revans2  since  idea  issue  based  discussion  bobby  especially  link  httpmailarchivesapacheorgmodmboxstormdev201703mbox3c9860378793649881149062380729940mailyahoocom3e  issue  focus  extract  client  stormcore  intended  address  hiding  local  mode  changing  base  classpath  worker  may  need  file  new  issue  great  address  one  huge  artifact  stormcore  supporting  thing  recently  extracted  stormdrpcserver  due  dependency  issue  also  struggling  handle  shade  relocation  lot  artifact  fact  artifact  need  relocate  worker  related  thing  extracting  worker  related  class  separate  artifact  assigning  different  classpath  storm  cluster  help  remedying  may  still  need  struggle  relocation  count  target  artifact  much  smaller  another  thing  need  consider  localcluster  pull  daemon  user  topology  still  need  pull  need  separate  artifact  localcluster  maybe  also  daemon  without  webapp  last  need  consider  ui  logviewer  porting  artifact  stormdrpcserver  generic  think  group  ui  logviewer  drpc  http  server  artifact  artifact  name  changed,0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,0,0
4923,make  local  cluster  transparent  part  work  storm2441  would  like  split  storm  classpath  client  jar  need  everything  else  separate  classpaths  daemon  process  one  issue  local  mode  built  almost  example  us  separate  api  normal  storm  client  api  work  around  really  add  new  option  storm  jar  include  everything  classpath  set  systemproperty  call  special  main  method  new  main  method  1  start  localcluster  2  configure  sotrmsubmitter  nimbusclinet  drpcclient  talk  localcluster  instead  3  run  regular  main  method  4  optionally  sleep  configurable  amount  time  5  shut  local  cluster,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
4924,support  running  worker  using  older  jvmsstorm  version  part  storm2441  separating  classpaths  clientworker  process  everything  else  storm  great  really  make  user  upset  rolling  upgrade  need  recompile  topology  done  really  good  job  maintaining  compatibility  older  version  storm  use  thrift  communication  state  storage  mean  new  supervisor  nimbus  able  talk  existing  clientworker  explicitly  support  add  config  option  supervisor  stormsupportedjvms  map  version  jvm  javahome  path  stormlegacyworkerclasspath  map  version  storm  classpath  used  launch  legacy  worker  process  set  supervisor  nimbus  also  add  metadata  client  submits  nimbus  along  topology  namely  version  storm  client  running  version  jvm  running  nimbus  decide  possibly  another  config  probably  convention  config  override  version  client  jvm  compatible  version  storm  jvm  currently  cluster  let  pick  version  jvm  storm  compatible  none  available  reject  request  also  allow  end  user  set  configs  work  well  need  good  version  matchingsorting  code  lenient  even  rolling  upgrade  example  user  submits  topology  103  client  200  cluster  nimbus  see  103  installed  great  start  running  rolling  upgrade  cluster  upgrade  move  104  supervisor  able  launch  worker  topology  104  classpath  part  worker  heartbeat  also  include  version  storm  jvm  worker  running  display  ui  display  version  submitted  ui,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
4925,remove  clojure  stormclient  would  great  remove  clojure  dependency  stormclient  start  looking  moving  much  stormclient  possible  initial  separation  left  thing  part  client  easy  separate  yet,0,0,0,0,0,0,0,0,0,1,1,0,0,1,1,0,0
4926,configs  generic  config  since  beginning  really  generic  map  really  consistent  everywhere  mapstring  object  reduce  number  warning  code  base  lot,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4927,refactor  storm  auto  credential  plugins  usable  currently  auto  credential  plugins  part  respective  external  module  like  stormhdfs  stormhbase  etc  user  want  use  need  place  jar  stormhdfs  stormhbase  dependency  ext  lib  currently  plugins  accept  hadoop  configuration  programatically  set  placing  config  file  like  hdfssitexml  class  path  scale  well  allow  user  connect  fetch  token  different  cluster  say  two  different  name  node  single  topology  make  auto  cred  plugins  usable  1  refactor  autohdfs  autohbase  etc  separate  storm  external  module  say  stormautocreds  jar  along  dependency  packaged  extracted  folder  like  libautocreds  loaded  class  path  storm  run  secure  mode  eg  setting  stormextclasspath  required  plugins  would  loaded  nimubsworkers  based  user  configuration  stormyaml  2  modify  plugins  accept  configkeys  via  topology  config  configkeys  would  list  string  key  user  would  pas  topology  config  noformat  hdfs  topoconfsethdfscredentialsconfigkeys  arraysaslistnew  string  cluster1key  cluster2key  put  respective  config  map  config  key  topoconfsetcluster1key  configmap1  topoconfsetcluster2key  configmap2  noformat  way  support  credential  multiple  cluster  3  topology  submission  nimbus  invokes  populatecredentials  configkeys  specified  plugins  login  hadoop  config  key  fetch  credential  delegation  token  store  respective  key  storm  cluster  state  cluster  state  already  store  credential  mapstring  string  change  needed  worker  download  credential  invoke  populatesubject  plugin  would  populate  credential  configured  configkeys  subject  similar  step  would  performed  updatesubject  4  nimbus  periodically  invokes  renew  credential  time  plugin  fetch  credential  configured  configkeys  ie  user  different  cluster  renew  respective  credential  5  user  could  specify  different  principal  keytab  within  config  key  map  plugin  use  appropriate  user  logging  respective  cluster  also  need  enhance  auto  cred  adding  plugins  eg  hbase  kafka  delegation  token  missing  currently  could  separate  jiras,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
4928,lambda  support  past  want  print  tuples  need  write  following  code  code  class  pritingbolt  extends  basebasicbolt  override  public  void  executetuple  input  basicoutputcollector  collector  systemoutprintlninput  override  public  void  declareoutputfieldsoutputfieldsdeclarer  declarer  nothing  buildersetboltbolt2  new  pritingbolt  code  patch  code  buildersetboltbolt2  tuple  systemoutprintlntuple  code  simplest  demo  patch  provides  new  method  topologybuilder  allow  use  java8  lambda  expression  code  setspoutstring  id  serializablesupplier  supplier  setspoutstring  id  serializablesupplier  supplier  number  parallelismhint  receiving  tuple  emitting  downstream  setboltstring  id  serializablebiconsumertuplebasicoutputcollector  biconsumer  string  field  setboltstring  id  serializablebiconsumertuplebasicoutputcollector  biconsumer  number  parallelismhint  string  field  receiving  tuple  never  emitting  downstream  setboltstring  id  serializableconsumertuple  consumer  setboltstring  id  serializableconsumertuple  consumer  number  parallelismhint  code  another  example  including  three  interface  usage  code  example  spout1  generate  random  string  bolt1  get  first  part  string  bolt2  output  tuple  buildersetspoutspout1  uuidrandomuuidtostring  buildersetboltbolt1  tuple  collector  string  part  tuplegetstringbyfieldlambdasplit  collectoremitnew  valuesparts0  fieldshufflegroupingspout1  buildersetboltbolt2  tuple  systemoutprintlntupleshufflegroupingbolt1  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4929,support  shared  memory  scheduling  ra  case  bolt  spout  share  memory  scheduler  good  way  express  able  support,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
4930,implement  auto  credential  plugin  hive  currently  auto  credential  plugins  available  hdfs  hbase  jira  implement  similar  auto  credential  plugin  apache  hive  plugin  fetch  delegation  token  using  hcatclient  distributes  worker  build  top  storm2482,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4931,abstractautocreds  look  configkeys  nimbus  topology  configs  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4932,resolve  checkstyle  violation  stormwebapp  module  checkstyle  violation  issue  clean  checkstyle  violation  module  stormwebapp,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
4933,deprecate  stormkafkaclient  kafkaconsumersubscribe  api  subscription  1x  remove  option  2x  copied  mailing  list  post  weve  recently  seen  issue  raised  user  using  default  subscription  api  new  kafkaspout  httpsissuesapacheorgjirabrowsestorm2514  httpsissuesapacheorgjirabrowsestorm2538  ago  alternative  subscription  implementation  added  httpsgithubcomapachestormpull1835  us  kafkaconsumerassign  api  instead  subscribe  api  used  default  cause  kafka  assign  partition  available  consumer  automatically  allows  consumer  group  keep  processing  even  presence  crash  partition  reassigned  consumer  becomes  unavailable  assign  api  used  alternative  subscription  implementation  leaf  consuming  code  figure  reasonable  partition  distribution  among  consumer  group  assign  api  essentially  equivalent  old  stormkafka  spout  distributes  partition  across  spout  instance  far  know  worked  well  storm  already  ensures  spout  instance  running  restarts  crash  really  gaining  much  using  subscribe  api  disadvantage  using  subscribe  api  whenever  executor  crash  kafka  cluster  reassigns  partition  cause  kafkaspout  instance  consumer  group  pause  reassignment  complete  partition  assignment  random  difficult  user  predict  partition  assigned  spout  task  subscribe  api  extremely  likely  cause  hang  weird  behavior  kafkaspout  configured  run  multiple  task  executor  kafkaconsumerpoll  called  partition  reassignment  block  reassignment  complete  multiple  consumer  thread  first  consumer  get  called  block  consumer  get  ejected  list  active  consumer  timeout  didnt  manage  call  poll  rebalance  see  example  code  httpsissuesapacheorgjirabrowsestorm2514  run  two  kafkaconsumers  one  thread  result  flip  flop  active  poll  take  30  second  kafka  session  timeout  random  assignment  partition  cause  message  duplication  necessary  executor  crash  executor  partition  reassigned  make  likely  lose  partition  inflight  tuples  unable  commit  kafka  message  reemitted  whichever  kafkaspout  instance  assigned  partition  see  httpsissuesapacheorgjirabrowsestorm2538  id  like  drop  support  subscribe  api  switch  using  assign  api  default  kafkaconsumer  javadoc  even  mention  application  like  storm  case  subscribe  api  doesnt  really  add  value  quote  process  highly  available  restarted  fails  perhaps  using  cluster  management  framework  like  yarn  mesos  aws  facility  part  stream  processing  framework  case  need  kafka  detect  failure  reassign  partition  since  consuming  process  restarted  another  machine  quote,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
4934,simplify  kafkaspoutconfig  suggestion  simplifying  kafkaspoutconfig  mailing  list  duplicate  property  user  would  normally  set  kafkaconsumer  property  map  setter  setprop  setting  property  map  instance  setgroupid  duplicating  setting  user  able  set  directly  consumer  property  get  rid  keyvalue  deserializer  setter  setting  deserializers  class  something  user  well  using  setprop  serializabledeserializer  class  removed  offering  extra  type  safety  case  user  defining  deserializer  type  opportunity  subclass  serializabledeserializer  setter  dont  work  built  kafka  deserializers,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
4935,break  auto  class  nimbus  plugin  worker  submitter  plugin  current  implementation  auto  class  implement  nimbus  plugin  interface  workersubmitter  plugin  interface  make  implementation  complicated  hard  debug  could  break  implementation  two  class  auto  class  complexity  would  lower  since  break  backward  compatibility  ill  also  initiate  discussion  dev,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4936,method  getting  nimbus  cilent  doenot  accept  timeout  parameter  method  getting  nimbus  cilent  cannot  receive  timeout  parameter  storm  cannot  reached  take  lot  time  wait  result,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4937,need  drpcclient  command  line  simple  way  send  drpc  request  command  line  really  one  debuggingtesting  minimum  also  example  work  use  drpc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4938,spout  throtteling  metric  unusable  helping  someone  debug  issue  backpressure  realized  metric  collecting  spout  mistakenly  multiplied  rate  even  though  subsampling  result  value  default  20  time  higher  thinking  would  use  metric  debug  issue  also  showed  skippedmaxspout  skippedthrottle  correspond  1  m  sleep  skippedinactive  corresponds  100  m  sleep  1  m  sleep  configurable  could  different  one  topology  another  even  code  around  pluggable  could  anything  sleeping  sleeping  random  amount  time  think  need  scrap  record  long  sleep  use  metric  instead  metric  also  dont  appear  documented  anywhere  going  change  mean  document  actually  useful  correct,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4939,enhance  stateful  windowing  persist  window  state  right  tuples  window  stored  memory  limit  usage  window  fit  memory  source  tuples  cannot  acked  window  expiry  persisting  window  transparently  state  backend  cachingiterating  need  could  support  larger  window  also  windowed  bolt  userapplication  state,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4940,improvement  access  topology  listing  user  topologyusers  mean  user  see  topology  storm  ui  view  log  also  affect  topology  kill  restart  worker  profiling  heap  dump  want  give  user  access  ui  log  let  impact  topology  proposing  add  new  configs  topologyuiusers  topologyuigroups  split  get  operation  others  simpleaclauthorizer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4941,apply  new  code  style  stormsqlkafka  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4942,kafka  spout  cant  show  acksfails  complete  latency  auto  commit  enabled  stormkafkaclient  spout  currently  emits  tuples  message  id  auto  commit  enabled  cause  ackfailcomplete  latency  counter  storm  ui  0  case  desirable  user  may  care  doesnt  want  overhead  storm  tracking  tuples  avermeerbergen  expressed  desire  able  use  auto  commit  without  counter  disabled  presumably  monitor  topology  performance  add  toggle  allows  user  enabledisable  tuple  anchoring  auto  commit  case,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
4943,update  config  validation  check  give  better  information  part  submitting  topology  need  serialize  config  json  check  right  rather  bad  call  utilsisvalidconf  throw  generic  exception  problem  httpsgithubcomapachestormblobmasterstormclientsrcjvmorgapachestormutilsutilsjaval978l980  would  much  better  new  functionmethod  would  check  equal  would  walk  looking  configs  different  find  one  includes  configs  different  exception,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4944,provide  stormkafkaclient  spout  example  example  topology  stormkafkaclient  trying  new  user  requires  modify  stormkafkaclient  pom  add  shading  rebuild  stormkafkaclient  copy  jarwithdependencies  storm  extlib  take  test  jar  run  topology  think  needlessly  complicated  move  example  topology  examplesstormkafkaclient  make  stormkafkaclient  pom  produce  jar  dependency  since  including  example  source  storm  distribution  dont  see  reason  try  minimize  jar  size  cost  adding  step  user  try  example  stormstarter  good  example  user  friendly  example  test  topology  since  contains  dependency  want  make  user  aware  extlib  used  reduce  jar  size  add  note  commented  provided  scope  example  pom,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4945,debugging  allow  user  tell  scheduler  node  would  prefer  case  debugging  would  nice  let  user  tell  scheduler  want  run  host  x  run  host  mostly  case  saw  odd  issue  topology  running  specific  host  unblock  user  giving  ability  avoid  specific  host  helpful  time  may  want  reproduce  issue  causing  topology  scheduled  bad  node  helpful,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4946,stormkafkaexamples  stormkafkaclientexamples  difficult  new  user  run  stormkafkaexamples  stormkafkaclientexamples  project  configure  dependency  way  make  difficult  run  new  user  example  project  set  provided  dependency  stormclient  otherwise  include  dependency  shaded  jar  stormkafkaclient  default  produce  jar  without  several  necessary  dependency  eg  kafka  client  library  providedscope  maven  parameter  intended  used  allow  user  produce  shaded  jar  dependency  provided  scope  set  compile  resulting  jar  also  contain  stormclient  prevents  jar  running  real  cluster  user  work  around  producing  slim  jar  using  artifact  submitting  topology  unnecessarily  tedious  produce  fat  jar  default  mention  example  documentation  artifact  user  want  make  slimmer  jar  edit  issue  includes  simplifying  stormkafkaexamples  stormkafkaclientexamples  general  example  demonstrate  use  state  drpc  focus  use  stormkafkaclient  also  cause  module  undesirable  dependency  eg  depend  stormstarter,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1,0
4947,topology  submission  kill  take  much  time  topology  grow  hundred  storm  cluster  40  host  32  cores128g  memory  hundred  topology  nimbus  submission  killing  take  minute  finish  example  cluster  300  hundred  topologies，it  take  8  minute  submit  topology  affect  efficiency  seriously  check  nimbus  code  find  two  factor  effect  nimbus  submissionkilling  time  scheduling  round  read  existingassignments  zookeeper  every  topology  take  4  second  300  topology  cluster  read  worker  heartbeat  update  state  nimbus  cache  take  30  second  300  topology  cluster  key  storm  use  zookeeper  collect  heartbeat  rpc  also  keep  physical  plan  assignment  using  zookeeper  totally  local  nimbus  think  make  change  storm  heartbeat  assignment  management  assignment  promotion  1  nimbus  put  assignment  local  disk  2  restart  ha  leader  trigger  nimbus  recover  assignment  zk  local  disk  3  nimbus  tell  supervisor  assignment  every  time  rpc  every  scheduling  round  4  supervisor  sync  assignment  fixed  time  heartbeat  promotion  1  worker  report  executor  ok  wrong  supervisor  fixed  time  2  supervisor  report  worker  heartbeat  nimbus  fixed  time  3  supervisor  die  tell  nimbus  runtime  hook  let  nimbus  find  aware  supervisor  survive  4  let  supervisor  decide  worker  running  ok  invalid  supervisor  tell  nimbus  executor  every  topology  ok,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4948,better  load  generation  testing  tool  tool  test  load  generation  would  nice  standardize  bit  clean  thing,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
4949,add  caching  blob  nimbus  improve  performance  nimbus  read  topology  topology  config  blob  store  time  even  multiple  time  single  thrift  call  would  really  great  could  cache  instead  rereading  time  found  cause  ui  slow  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4950,let  user  indicate  worker  restart  blob  download  blob  like  jar  file  really  tied  life  cycle  worker  new  blob  ready  worker  restarted  otherwise  way  pick  content  newly  downloaded  blob  storm2438  already  set  ground  work,1,0,1,0,1,0,1,0,1,0,1,0,0,0,1,0,1
4951,refactor  stormkafkaclient  kafkaspout  processing  guarantee  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4952,refactor  partial  key  grouping  greater  flexibility  organization  needed  behavior  similar  partialkeygrouping  port  refactoring  make  possible  use  partialkeygrouping  new  way  simplest  usecase  would  send  tuples  one  n  downstream  instance  instead  always  one  two,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4953,clean  ra  remove  possible  loop  code  ra  rather  complex  found  mismatch  priority  strategy  eviction  strategy  result  infinite  loop  make  simpler  really  one  strategy  prioritize  topology  scheduling  happens  highest  priority  topology  eviction  happens  lowest  priority  one,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
4954,clean  configs  topology  builder  lot  topology  builder  storing  array  map  configs  array  get  smashed  together  single  map  topology  actually  submitted  make  code  really  confusing  completely  unnecessary,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4955,give  user  option  disable  login  cache  currently  cache  login  using  logincachekey  titlehttpsgithubcomapachestormblobmasterstormclientsrcjvmorgapachestormsecurityauthkerberoskerberossasltransportpluginjaval57  logincachekey  failed  work  correctly  use  tgt  cache  instead  keytab  proposed  solution  add  option  jaasconf  user  disable  login  cache  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4956,integration  test  shut  topology  immediately  test  integration  test  kill  topology  default  30  second  timeout  unnecessary  delay  following  test  killed  topology  still  occupying  worker  slot  integration  test  kill  topology  try  sending  kill  message  nimbus  may  fail  quietly  break  following  test  default  storm  install  4  worker  slot  test  topology  take  3  topology  shut  prevents  following  topology  assigned,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4957,clean  ra  resource  map  new  generic  ra  code  use  mapstring  number  mapstring  double  resource  really  inefficient  look  normalizing  map  array  faster  hopefully  make  code  cleaner,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
4958,ra  constraint  solver  strategy  use  case  user  old  native  code  need  work  storm  sadly  code  thread  safe  need  sure  instance  specific  bolt  worker  without  instance  bolt  also  cannot  coexist  bolt  similar  reason  know  fairly  strange  use  case  help  fix  issue  wrote  strategy  ra  simple  search  state  space  trying  honor  constrains  thought  best  push  back  keep  internal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4959,expose  ieventlogger  make  event  logging  pluggable  first  time  event  logger  feature  designed  make  implementation  pluggable  thats  ieventlogger  exists  didnt  actual  use  case  writing  file  time  simplified  case  use  case  also  write  event  file  awareness  structure  event  easily  parseable  log  feeder  would  want  custom  ieventlogger  represent  event  format  case  there  another  issue  well  eventinfo  t  store  epoch  defined  string  long,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4960,add  kerberos  support  solr  bolt  update  solr  bolt  work  kerberized  solr  cluster  instruction  solrj  client  httpsluceneapacheorgsolrguide66kerberosauthenticationpluginhtmlkerberosauthenticationpluginusingsolrjwithakerberizedsolr,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4961,improvement  stormrocketmq  module  upgraded  rocketmq  version  420  brings  improvement  new  feature  like  batch  sending  imporved  retry  policy  rocketmq  consumer  push  mode  avoid  data  loss  scene  batch  sending  supported  bolt  trident  state  allow  running  several  consumer  instance  one  process  say  different  topic  one  worker  possible,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
4962,new  metric  reporting  api  200  proposal  provide  new  metric  reporting  api  based  coda  hale  metric  library  httpmetricsdropwizardio310  aka  dropwizardyammer  metric  h2  background  discussion  dev  mailing  list  httpmailarchivesapacheorgmodmboxstormdev201610mbox3ccagx0urh85nfh0pbph11pmc1oof6htycjcxsxgwp2nnofukq0pqmailgmailcom3e  number  community  pmc  member  recommended  replacing  storm’s  metric  system  new  api  opposed  enhancing  existing  metric  system  objection  existing  metric  api  include  metric  reported  untyped  java  object  making  difficult  reason  report  eg  gauge  counter  etc  difficult  determine  metric  coming  consumer  preaggregated  storm’s  metric  collection  occurs  specialized  bolt  addition  potentially  affecting  system  performance  complicates  certain  type  aggregation  parallelism  bolt  greater  one  discussion  developer  mailing  list  growing  consensus  replacing  storm’s  metric  api  new  api  based  coda  hale’s  metric  library  approach  following  benefit  coda  hale’s  metric  library  stable  performant  well  thought  widely  adopted  among  open  source  project  eg  kafka  metric  library  provides  many  existing  metric  type  meter  gauge  counter  histogram  library  pluggable  “reporter”  api  publishing  metric  various  system  existing  implementation  jmx  console  csv  slf4j  graphite  ganglion  reporter  straightforward  implement  reused  project  us  metric  library  ie  would  broader  application  outside  storm  noted  earlier  metric  library  support  pluggable  reporter  sending  metric  data  system  implementing  reporter  fairly  straightforward  example  reporter  implementation  found  example  someone  develops  reporter  based  coda  hale’s  metric  could  used  pushing  storm  metric  also  system  used  metric  library  kafka  h2  scope  effort  effort  implement  new  metric  api  storm  broken  following  development  area  implement  api  storm  internal  worker  metric  latency  queue  size  capacity  etc  implement  api  user  defined  topologyspecific  metric  exposed  via  orgapachestormtasktopologycontext  class  implement  api  storm  daemon  nimbus  supervisor  etc  h2  relationship  existing  metric  would  new  api  would  affect  existing  metric  api  upon  completion  old  metric  api  would  presumably  deprecated  kept  place  backward  compatibility  internally  current  metric  api  us  storm  bolt  reporting  mechanism  proposed  metric  api  would  depend  storm  messaging  capability  instead  use  metric  library  builtin  reporter  mechanism  httpmetricsdropwizardio310manualcoremancorereporters  would  allow  user  use  existing  reporter  implementation  stormspecific  would  simplify  process  collecting  metric  compared  storm  imetriccollector  interface  implementing  reporter  metric  library  much  straightforward  example  found  httpsgithubcomdropwizardmetricsblob32developmentmetricscoresrcmainjavacomcodahalemetricsconsolereporterjava  new  metric  capability  would  use  affect  zookeeperbased  metric  used  storm  ui  h2  relationship  jstorm  metric  tbd  h2  target  branch  tbd  h2  performance  implication  tbd  h2  metric  namespaces  tbd  h2  metric  collected  worker  namespace  metric  type  description  nimbus  namespace  metric  type  description  supervisor  namespace  metric  type  description  h2  userdefined  metric  tbd,1,0,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0
4963,remove  enableautocommit  support  stormkafkaclient  enableautocommit  option  cause  kafkaconsumer  periodically  commit  latest  offset  returned  poll  convenient  use  case  message  polled  kafka  processed  synchronously  loop  due  httpsissuesapacheorgjirabrowsestorm2913  wed  really  like  store  metadata  kafka  spout  commits  possible  enableautocommit  took  look  setting  actually  cause  kafkaconsumer  call  commitasync  poll  operation  eg  close  assign  interval  ideally  id  like  get  rid  processingguaranteenone  since  think  processingguaranteeatmostonce  cover  use  case  likely  almost  fast  primary  difference  atmostonce  commits  synchronously  really  want  keep  processingguaranteenone  think  make  processingguaranteenone  setting  cause  spout  call  commitasync  poll  never  use  enableautocommit  option  allows  u  include  metadata  commit,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
4964,use  new  wait  strategy  spout  well  storm2306  introduced  new  configurable  wait  strategy  system  situation  backpressure  wait  used  spout  bolt  incoming  data  used  bolt  another  wait  situation  spout  emits  generated  nexttuple  maxspoutpending  reached  jira  transition  spout  wait  strategy  old  model  new  model  thereby  uniform  model  dealing  wait  strategy,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4965,decouple  stormhive  ut  hive  unit  test  stormhive  running  hive  instance  interact  hive  creates  unnecessary  directory  likely  easier  broken  given  theyre  ut  would  better  decouple  hive  stormhive  test,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4966,upgrade  zk  instance  security  would  great  ability  move  existing  cluster  zk  insecure  secure  without  wiping  everything  clean  allow  rolling  upgrade  running  topology  credential  need  dont  need  manual  step  deleting  root  zk  node,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4967,ra  scheduling  performance  improvement  even  fixing  lot  loop  ra  scheduling  still  make  performance  even  better  especially  true  generic  resource  aware  strategy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4968,partitionedtridentspoutexecutor  use  getpartitionsfortask  httpsissuesapacheorgjirabrowsestorm2407  added  method  iopaquepartitionedtridentspoutemitter  interface  called  getpartitionsfortask  used  delegate  partitioning  task  previously  partitioning  hard  coded  round  robin  want  able  delegate  partitioning  dont  see  reason  make  change  ipartitionedtridentspoutemitter  interface  partitioning  still  hard  coded  use  round  robin  eg  compare  httpsgithubcomapachestormblob4137328b75c06771f84414c3c2113e2d1c757c08stormclientsrcjvmorgapachestormtridentspoutpartitionedtridentspoutexecutorjaval131  httpsgithubcomapachestormblob4137328b75c06771f84414c3c2113e2d1c757c08stormclientsrcjvmorgapachestormtridentspoutopaquepartitionedtridentspoutexecutorjaval131,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4969,cache  storm  id  executor  mapping  master  avoid  repeat  computation  nimbus  collect  topology  conftopologyserstormbase  compute  scheduling  round  heavy  work  scheduling  still  take  minute  even  change  rpc  heartbeat  assignment  distribution  decide  redesign  scheduler  schedule  topology  need  dead  worker  enough  number  worker  checkout  code  found  idexecutors  mapping  computed  every  time  every  topology  really  heavy  computation  totally  necessary  mapping  fixed  invariable  topology  unless  rebalance  kill  refactor  code  little  powerful  scheduler  resigned  deltascheduling  lightweight  even  thousand  topology  one  cluster  enough  u,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4970,topology  name  need  validated  stormclient  current  behavior  execute  topology  invalid  topology  name  throwing  exception  uploading  jar  improvement  validating  topology  name  client  side  uploading  jar  codejava  20180605  161619461  oasdnnimbus  pool21thread53  info  uploading  file  client  manugitstormstormdistbinaryfinalpackagetargetapachestorm200snapshotstormlocalnimbusinboxstormjar22979659517646fd9027ffdde13f595ajar  20180605  161620596  oasdnnimbus  pool21thread35  info  finished  uploading  file  client  manugitstormstormdistbinaryfinalpackagetargetapachestorm200snapshotstormlocalnimbusinboxstormjar22979659517646fd9027ffdde13f595ajar  20180605  161620624  oasdnnimbus  pool21thread29  info  received  topology  submission  test123  storm200snapshot  jdk180162  conf  topologyusersnull  topologyackerexecutorsnull  stormzookeepersuperaclnull  topologyworkers3  topologysubmitterprincipal  topologydebugtrue  topologynametest123  topologykryoregister  stormidtest12371528195580  topologykryodecorators  topologyeventloggerexecutors0  topologysubmitterusermvanam  topologymaxtaskparallelismnull  20180605  161620624  oasdnnimbus  pool21thread29  info  uploadedjar  manugitstormstormdistbinaryfinalpackagetargetapachestorm200snapshotstormlocalnimbusinboxstormjar22979659517646fd9027ffdde13f595ajar  20180605  161620624  oasbblobstore  pool21thread29  error  test12371528195580stormjarjar  appear  valid  must  match  w  cant  null  empty  string  20180605  161620625  oasbblobstore  pool21thread29  error  test12371528195580stormconfser  appear  valid  must  match  w  cant  null  empty  string  20180605  161620626  oasdnnimbus  pool21thread29  warn  topology  submission  exception  topology  nametest123  javalangillegalargumentexception  test12371528195580stormconfser  appear  valid  blob  key  orgapachestormblobstoreblobstorevalidatekeyblobstorejava66  stormclient200snapshotjar200snapshotcode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4971,extend  metric  supervisor  worker  drpc  patch  serf  extend  metric  supervisor  worker  currently  following  metric  implemented  including  limited  worker  kill  count  category  assignment  changehb  oldheap  space  time  spent  state  time  actually  kill  worker  identifying  need  supervisor  actual  change  state  worker  per  worker  time  start  worker  topology  reading  assignment  first  time  worker  cleanup  timeworker  cleanup  retries  worker  suicide  count  category  internal  error  assignment  change  supervisor  supervisor  restart  count  blobstore  request  download  time  download  time  individual  blob  inside  localizer  localizer  gettting  requst  actually  download  hdfs  request  finish  download  rate  individual  blob  inside  localizer  supervisor  localizer  thread  blob  download  long  outside  localizer  blobstore  update  due  version  change  cnts  blobstore  storage  user  drpc  avgmax  time  respond  http  request  might  metric  added  later  patch  also  refactor  code  relevant  file  bug  found  process  reported  issue  handled  separately,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,0,0
4972,add  admin  command  get  zookeeper  shell  time  zk  might  get  messed  user  may  want  see  storm  would  nice  simple  command  line  tool  pop  u  zk  start  look  issue,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
4973,refactoring  method  component  supervisor  drpc  supplement  issue  page  storm3099  separating  refactoring  work  metric  addition  misc  bug  discovered  refactoring  incorporate  issue  well  see  link  information,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4974,extend  metric  nimbus  logviewer  include  limited  logviewer  1  cleanup  time  2  time  complete  one  clean  loop  time  3  disk  usage  log  cleanup  cleanup  loop  like  gc  4  failuresexceptions  5  search  request  cnt  category  archivednonarchived  6  search  request  response  time  7  search  request  0  result  cnt  8  search  result  open  file  9  file  partial  read  count  10  file  download  request  cnt  size  served  11  disk  io  logviewer  12  cpu  usage  unzipping  file  nimbus  additional  topology  stormjarserstormconfserstormserser  file  upload  time  scheduler  related  metric  would  long  list  generic  specific  different  strategy  cluster  summary  pushed  metric  restart  cnt  nimbus  loss  leadership  jiraimagesiconsemoticonshelp16pngwidth16height16alignabsmiddle  ui  responding  httpsjiraouroathcombrowseystorm4838  negative  resource  scheduling  event  httpsjiraouroathcombrowseystorm4940  excessive  scheduling  time  jiraimagesiconsemoticonshelp16pngwidth16height16alignabsmiddle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4975,add  support  junit  5  test  think  would  nice  could  use  new  junit  5  apis  testing  since  junit  5  run  junit  4  test  shouldnt  much  work  add  support,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
4976,improve  gauge  registration  stormmetricsregistry  make  registergauge  registerprovidedgauge  generic  clean  code,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
4977,use  custom  callback  kafkabolt  currently  kafkabolt  completely  encapsulates  kafkaproducer  there  way  inject  custom  callback  sending  message  kafka  change  add  method  allows  injection  callback  function  passed  color333333kafkaproducersendcolor  reasoning  behind  change  expose  exception  occur  kafka  publishing  logged  metric  built  around  would  provide  customized  way  could  build  alerting  around  kafka  publishing  failure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4978,improve  security  credential  push  pushing  credential  topology  check  right  verify  topology  allowing  given  user  push  also  need  protect  user  pushing  wrong  topology  really  issue  user  push  setup  kind  cron  like  job  topology  rare  eliminate  race  condition  nimbus  either  verify  topology  owned  user  one  push  optional  user  client  expects  topology  owned,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4979,display  version  storm  offered  cluster  ui  storm  200  option  older  version  storm  installed  cluster  backwards  compatibility  happens  display  ui  others  know  everything  installed  cluster,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
4980,fix  cascading  storm  failure  improving  reconnection  strategy  buffering  message  note  original  title  ticket  add  option  config  message  handling  strategy  connection  timeout  address  concern  brought  uphttpsgithubcomapacheincubatorstormpull103issuecomment43632986  work  storm297  quote  revans2  wrote  logic  make  since  call  blocking  biggest  concern  around  blocking  case  worker  crashing  single  worker  crash  block  entire  topology  executing  worker  come  back  case  see  something  would  want  case  see  speed  primary  concern  user  would  like  get  partial  data  fast  rather  accurate  data  later  could  make  configurable  follow  jira  max  limit  buffering  allowed  block  throw  data  away  zeromq  quote  worker  crash  suddenly  handle  message  supposed  delivered  worker  1  buffer  message  infinitely  2  block  message  sending  connection  resumed  3  config  buffer  limit  try  buffer  message  first  limit  met  block  4  neither  block  buffer  much  choose  drop  message  use  builtin  storm  failover  mechanism,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
4981,add  kafka  trident  state  message  sent  kafka  topic  currently  storm  bolt  writing  kafka  implementation  trident  state  need  trident  state  implementation  allows  wrting  tuples  directly  kafka  topic  part  trident  topology,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
4982,common  core  stormtrident  tuple  interface  currently  core  storm  trident  tuples  share  common  interface  developer  creating  library  perform  tuple  processing  logic  used  core  storm  trident  topology  mean  logic  must  implemented  twice  tuple  type  would  nice  could  eliminate  limitation,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
4983,secure  impersonation  storm  storm  security  add  feature  authenticating  kerberos  us  principal  tgt  way  authorize  user  operation  topology  operation  currently  storm  ui  user  need  part  nimbusadmins  get  detail  user  submitted  topology  ideally  storm  ui  need  take  authenticated  user  principal  submit  request  nimbus  authorize  user  rather  storm  ui  user  feature  also  benefit  superusers  impersonate  user  submit  topology  secured  way,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4984,lack  static  helper  registermetricsconsumer  backtypestormconfig  backtypestormconfig  concept  design  use  regular  map  providing  helper  operate  map  method  using  concept  providing  static  version  example  registerserialization  method  code  public  static  void  registerserializationmap  conf  class  klass  getregisteredserializationsconfaddklassgetname  public  void  registerserializationclass  klass  registerserializationthis  klass  code  however  recently  added  metric  interface  doesnt  follow  approach  unfortunately  break  concept  using  hashmap  configuration  container  user  still  hashmap  inside  storm  also  static  version  registermetricsconsumer  introducing  metric  feature  break  configuration  code  clojure  previosly  map  without  static  helper  code  instance  backtypestormconfig  class  possible  keep  configuration  simple  pseudocode  example  submitter  call  code  let  topologyconfig  doto  topologydebug  false  topologystatssamplerate  001  topologyreceiverbuffersize  32  topologytransferbuffersize  4096  topologyexecutorreceivebuffersize  2048  using  static  helper  add  serialization  class  config  stormbacktypeconfigregisterserialization  exmplserializer  serializer  stormsubmittersubmittopology  topologyname  topologyconfig  mktopology  code  proposed  solution  create  static  version  registermetricsconsumer  way  done  backtypestormconfig  helper,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4985,add  stormjdbc  list  external  connector  several  question  apache  mailing  list  around  use  storm  write  tuples  relational  database  storm  add  jdbc  connector  list  external  connector  general  implementation  insert  data  relational  db  part  topology,1,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,1
4986,storm  trident  support  slidingtumbling  window  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4987,simpleaclauthorizer  provide  way  restrict  submit  topology  simpleaclauthorizer  currently  allows  anyone  valid  kerberos  ticket  submit  topology  case  storm  admins  want  allow  selected  user  submit  topology  proposing  nimbususers  config  option  added  stormyaml  listed  user  deploy  storm  topology  cc  revans2,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4988,stormredis  add  basic  lookup  persist  bolt  currently  stormredis  provides  abstractredisbolt  normal  trident  bolt  jedis  easy  use  may  enough  also  provide  implementation  abstractredisbolt  simple  usage  eg  store  key  value  pair  get  key  value  since  redis  various  data  type  command  cant  cover  whole  thing  seems  like  thing  could  considered  type  read  write  string  get  key  set  key  value  hash  hget  key  field  hset  key  field  value  list  lpop  key  rpush  key  value  set  scard  key  sadd  key  member  sorted  set  zscore  key  member  zadd  key  score  member  hll  hyperloglog  pfcount  key  pfadd  key  element  btw  since  normally  get  key  value  tuple  external  module  hash  set  sorted  set  need  additional  key  process,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1
4989,stormjdbc  support  customer  insert  query  currently  stormjdbc  insert  boltstate  support  specify  table  name  construct  query  form  insert  tablename  value  based  table  schema  fails  support  use  case  like  insert  select  special  case  like  phoenix  jdbc  driver  support  upsert  add  way  user  specify  custom  query  insert  bolt  already  pointed  revans2  pr  review  concrete  case  benefited  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4990,multilang  introduce  overflow  control  mechanism  storm738  httpsissuesapacheorgjirabrowsestorm738focusedcommentid14394106pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment14394106  shellbolt  side  control  modify  shellbolt  sent  tuple  id  list  stop  sending  tuples  list  exceeds  configured  max  value  order  achieve  subprocess  notify  tuple  id  complete  shellbolt  introduces  new  command  multilang  proceed  better  name  shellbolt  store  inprogressofprocessing  tuples  list  overhead  could  big  subprocess  always  notify  shellbolt  tuples  processed  b  subprocess  side  control  modify  subprocess  check  pending  queue  reading  tuple  exceeds  configured  max  value  subprocess  request  delay  shellbolt  slowing  shellbolt  receives  delay  boltwriterrunnable  stop  polling  pending  queue  continue  polling  later  long  shellbolt  wait  resending  unit  would  delay  time  tuple  count  dont  know  better  yet  introduces  new  command  multilang  delay  better  name  dont  think  would  introduced  soon  subprocess  request  delay  based  statistic  ex  pending  tuple  count  average  tuple  processed  time  time  unit  average  pending  tuple  count  count  unit  leave  much  request  delay  user  user  make  hisher  algorithm  control  flooding  opinion  b  seems  natural  cause  current  issue  subprocess  side  would  better  let  subprocess  overcome,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4991,localstate  use  java  serialization  want  rolling  upgrade  need  move  away  java  serialization  provide  good  rolling  upgrade  path  zookeeper  using  thrift  think  want  continue  path,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4992,storm  elasticsearch  connector  would  nice  provide  storm  driver  elasticsearch  like  hive  redis,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4993,storm  solr  connector  storm  solr  connector  provide  bolt  trident  implementation  allow  user  index  data  coming  topology  solr,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
4994,add  priority  per  user  resource  guarantee  resource  aware  scheduler  multitenant  environment  would  like  able  give  individual  user  guarantee  much  cpumemorynetwork  able  use  cluster  would  also  like  know  topology  user  feel  important  keep  running  enough  resource  run  topology  user  able  specify  topology  production  staging  development  within  category  user  able  give  topology  priority  0  10  10  highest  priority  something  like  enough  resource  cluster  run  topology  assume  topology  running  using  resource  find  user  guaranteed  resource  shoot  lowest  priority  topology  user  repeat  topology  able  run  topology  would  one  shot  ideally  dont  actually  shoot  anything  know  would  made  enough  room  cluster  oversubscribed  everyone  guarantee  topology  would  put  user  guarantee  shoot  lowest  priority  topology  worker  resource  pool  enough  room  run  topology  topology  one  would  shot  might  also  want  think  going  shoot  production  topology  oversubscribed  case  perhaps  shoot  nonproduction  topology  instead  even  user  guarantee,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
4995,hdfs  bolt  end  unrecoverable  state  body  hdfsboltexecute  method  essentially  one  trycatch  block  catch  block  report  error  fails  current  tuple  case  bolt  fsdataoutputstream  object  named  unrecoverable  state  subsequent  call  execute  succeed  produce  scenario  process  tuples  hdfs  bolt  put  underlying  hdfs  system  safemode  process  tuples  receive  correct  closedchannelexception  take  underlying  hdfs  system  safemode  subsequent  tuples  continue  fail  exception  three  fundamental  operation  execute  take  writing  syncing  rotating  need  isolated  error  specifically  handled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4996,listindexofgroovylangclosure  closure  friend  groovy  jdk  findgroovylangclosure  closure  findallgroovylangclosure  closure  method  really  useful  would  also  good  listindexofgroovylangclosure  closure  listindexofint  startindex  groovylangclosure  closure  startindex  tell  index  start  looking  int  listindicesofallgroovylangclosure  closure  return  type  may  also  listinteger  whatever  listlastindexofgroovylangclosure  closure  groovy  jdk  sometimes  important  know  element  fullfilling  given  condition  list,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
4997,change  signature  groovyresourceloaderloadgroovyfile  support  url  groovyresourceloaderloadgroovyfile  return  url  instead  much  friendly  using  filesystem  also  using  jar  possibly  even  remote  jar  method  renamed  refactored  return  url  groovyresourceloaderloadgroovysource,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
4998,provide  feature  declare  testcases  notyetimplemented  thus  expected  fail  provide  notyetimplemented  htmlunit  use  right  away  groovy  build,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
4999,patch  provide  ace  script  object  groovyscriptengine  patch  provide  ace  script  object  groovyscriptengine  allow  dependency  injection  multiple  return  value  script  ace  setproperty  getproperty,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5000,additional  helper  method  domcategory  make  feel  like  xmlparserslurper  attached  patch  testcase  extends  domcategory  also  support  nodetext  nodename  nodeparent  nodelistiterator  strictly  necessary  extension  make  dom  processing  closer  xmlslurper  xmlparser  usage  discrepancy  domcategory  xmlslurper  xmlparser  usage  make  subject  subsequent  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5001,implement  groupby  map  well  list  method  groupby  work  list  work  map  well  code  functionality  respective  test  commented  defaultgroovymethods  groovymethodstest  public  static  map  groupbymap  self  closure  closure  final  map  answer  new  hashmap  final  iterator  iter  selfentrysetiterator  iterhasnext  groupcurrentelementclosure  answer  iter  return  answer,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5002,allow  addition  metabeanproperty  instance  metaclassimpl  need  able  add  metabeanproperty  instance  metaclassimpl  allow  dynamic  property  added  patch  attached,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5003,improve  doc  collectiongroupby  add  new  collectioncollateclosure  small  breaking  change  documentation  collectiongroupby  little  ambiguous  make  absolutely  clear  return  value  map  key  pointing  value  arraylists  new  method  collectioncollateclosure  would  nice  addition  allow  collation  collection  object  map  keyed  value  provided  closure  without  returning  list  every  value  might  implemented  code  javautilmap  collateclosure  collator  def  result  thiseach  resultcollatorcallit  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5004,sql  pipeline  improvement  groovysqlsql  usefull  sql  pipeline  code  fetch  person  sqleachrowselect  person  person  fetch  unit  process  person  data  personstatus  active  sqleachrowselect  unit  unitid  seq  personunit  unit  process  unit  data  job  fetch  job  description  personjob0  personjob1  personjob2each  jobdes  sqleachrowselect  job  jobid  jobdes  process  job  description  else  code  groovysqlsqleachrowstring  list  closure  preparedstatement  ever  evaluated  iteration  would  easy  add  preparedstatement  cache  feature  improve  speed  avoid  useless  evaluation  maybe  could  create  new  top  wrapping  statement  persistent  example  code  sqlpersistent  sqleachrowselect  person  person  code  code  public  void  persistentclosure  clos  setpersistenttrue  closcall  setpersistentfalse  closeresources  code  therefore  could  code  public  void  eachrowstring  sql  list  params  closure  closure  throw  sqlexception  connection  connection  createconnection  preparedstatement  statement  null  resultset  result  null  try  logfinesql  ispersistent  statement  preparedstatement  cachegetsql  statement  null  statement  connectionpreparestatementsql  cacheputsql  statement  else  statement  connectionpreparestatementsql  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5005,provide  security  sandbox  executing  script  would  great  secure  sandbox  script  could  evaluated  restricting  kind  script  available  package  used,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5006,printf  work  printstream  support  sprintf  printf  currently  sends  systemout  work  systemerr  printstreams  file  etc  also  available  via  string  eg  per  sprintf,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5007,gdk  add  eachdirmatch  eachdirrecurse  file  file  gdk  following  method  void  eachdirclosure  void  eachfileclosure  void  eachfilematchfilter  closure  void  eachfilerecurseclosure  coherence  would  good  void  eachdirmatchfilter  closure  void  eachdirrecurseclosure  see  discussion  dev  mailing  list  httpwwwnabblecomaddingeachdirmatchandeachdirrecursetf3473673htmla9694265,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5008,expose  unary  plus  unary  minus  operator  interceptable  method  call  positive  negative  im  writing  groovy  builder  compass  lucene  query  would  nice  use  closure  since  mirror  lucenes  query  string  syntax  eg  code  def  query  builderbuild  termkeywords  book  termkeywords  audio  querystringcolor  theory  code  would  create  query  lucene  query  string  syntax  look  like  keywordsbook  keywordsaudio  allcolor  alltheory  incidentally  query  mean  keywords  must  value  book  must  value  audio  may  may  color  theory  ok  dont  mirror  exactly  familar  lucene  query  string  syntax  think  feel  right  operator  made  interceptable  method  call  think  opinion  list  use  positive  negative  method  name  httpwwwnabblecomuseof2bandindsltf3623677html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
5009,would  useful  dgm  socketwithobjectstreams  complement  socketwithstreams  wii  currently  socketwithstreams  input  output  similar  suggestion  mirror  object  variant  socketwithobjectstreams  ois  oos  would  make  setting  proxy  type  object  socket  streamlined,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5010,need  get  metadata  even  get  resultsid  like  easier  way  get  metadata  sql  class  able  find  way  get  sql  metadata  even  row  returned  current  groovy  sql  stuff  subclassed  groovysqlsql  added  new  version  eachrow  row  take  additional  metaclosure  feed  metaclosure  result  set  meta  data  way  even  dont  row  returned  sure  meta  data  dont  delve  row  processing  closure  get  meta  data  first  row  anything  like  made  subclass  added  following  method  public  list  row  final  string  sql  final  closure  metaclosure  public  void  eachrow  final  string  sql  final  closure  metaclosure  final  closure  rowclosure  def  metadata  def  result  sqlrows  query  metadata  didnt  make  groovier  version  metadata  class  way  there  groovyrowresult  groovyresultset  class  impressed  easy  needed  attached  method  added  approved  groovy  format,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5011,force  swingbulder  execute  builder  method  edt  avoid  problem  gui  elt  user  simple  way  creating  gui  wihtout  thinking  edt  swingbuilder  invoke  builder  method  frame  dialog  edt,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5012,dynamically  added  static  getters  cant  called  property  stringmetaclassstaticgetsomething  something  assertequalssomething  stringsomething  fails  property  something  class  javalangclass,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5013,allow  customisation  closure  variable  resolving  strategy  need  something  like  def  c  cresolvestrategy  closuredelegatefirst  cresolvestrategy  closuredelegateonly  cresolvestrategy  closureownerfirst  cdelegate  foo  ccall,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5014,simpletemplateengine  poentially  templateengines  allow  caller  specify  classloader  simpletemplateengine  doesnt  allow  caller  specify  parent  classloader  creates  groovyshell  us  loader  class  code  index  srcmaingroovytextsimpletemplateenginejava  srcmaingroovytextsimpletemplateenginejava  revision  6601  srcmaingroovytextsimpletemplateenginejava  working  copy  698  6914  public  template  createtemplatereader  reader  throw  compilationfailedexception  ioexception  return  createtemplategroovyshellclassgetclassloader  reader  public  template  createtemplateclassloader  parentloader  reader  reader  throw  compilationfailedexception  ioexception  simpletemplate  template  new  simpletemplate  groovyshell  shell  new  groovyshell  groovyshell  shell  new  groovyshellparentloader  string  script  templateparsereader  verbose  systemoutprintlnn  script  source  code  template  engine  consistent  feature  enhancement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5015,add  support  method  missing  behaviour  groovy  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5016,add  jline  support  groovysh  hiya  id  like  add  jline  support  groovysh  jline  httpjlinesourceforgenet  dont  know  really  cool  little  library  similar  editlinereadline  allows  java  cli  apps  rich  buffer  editinghistorycompletion  modern  interactive  cli  tool  generally  tiny  library  60k  highly  portable  working  well  modern  window  posix  compatible  unix  system  posix  system  leverage  stty  command  initialize  terminal  unbuffered  mode  window  us  tiny  dll  get  affect  work  well  far  ive  heard  anyone  problem  using  also  fallback  mode  case  neither  stty  dll  bit  work  simply  behave  like  normal  java  console  inputoutput  though  ive  yet  actually  see  case  fallback  mode  kicked  jline  also  bsd  licensed  worry  tainting  distribution  gpl  muck  change  relatively  small  imo  benefit  large,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5017,change  sleep  variant  closure  enable  continued  sleep  following  possible  new  sleep  variant,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5018,iteration  method  inject  provided  object  map  well  object  collection  iteration  method  implemented  object  map  well  collection  object,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5019,rewrite  interactiveshell  aka  groovysh  groovy  currently  interactiveshell  aka  groovysh  class  written  java  well  afaict  good  reason  rewrite  groovy,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5020,increase  closure  performance  using  specialized  closure  metaclass  closure  generated  groovy  compiler  special  nature  thing  runtime  could  use  optimize  call  performance  instead  runtime  us  standard  metaclass  contains  special  logic  closure  general  special  generated  closure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5021,enum  support  allow  definition  enums  groovy,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5022,metaclassgetmetamethods  return  method  dgm  return  meta  method  0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5023,groovy  transpose  method  groovy  transpose  method  like  ruby  transpose  method  array  python  zip  method  expected  behaviour  assert  b  1  2  3transpose  1  b  2  assert  transposea  b  1  2  3  1  b  2  assert  transpose1  2  3  4  5  6  1  4  2  5  3  6  assert  transpose1  2  3  4  5  9  6  7  8  1  4  9  6  assert  transpose1  2  3  1  2  3  assert  transpose,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5024,change  groovyc  ant  task  enable  embedding  javac  ant  task  instead  using  jointcompilation  property  providing  option  compiler  command  line  like  manner  would  nice  able  reuse  ant  javac  task  run  joint  compilation  process  example  codexml  groovyc  srcdirtestsourcedirectory  destdirtestclassesdirectory  javac  source14  target14  groovyc  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5025,dgm  method  object  min  max  sum  perhaps  unique  sort  discussed  httpwwwnabblecomgroovyequivalentofpythonzipfunctiontf4209158html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
5026,alltestsuite  support  excludes  pattern  well  current  includes  pattern  would  allow  test  included  suite  according  supplied  pattern,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5027,gpath  allow  attribute  reference  using  unquoted  selector  xmlparser  node  making  consistent  xmlslurper  suggested  way  access  xml  attribute  result  produced  xmlparser  use  form  xattrname  note  quote  around  attribute  name  xmlslurper  style  gpath  leave  quote  write  xattrname  doesnt  appear  supported  xmlparse  style  groovy  action  book  table  table  124  page  410411  show  variation  restriction  form  xname  also  used  general  groovy  specify  direct  field  access  see  groovy  action  page  203  section  titled  field  access  somehow  appears  xmlslurper  result  use  name  form  access  attribute  would  nice  name  form  dont  quote  name  worked  also  xmlparse  result  node,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5028,expose  gse  groovyservlet  subclass  may  add  extra  configuration  exposing  gse  protected  method  help  tweaking  compilerconfiguration  subclass  groovyservlet  external  strategy  like  groovyservletconfigurator  set  initparam  subclass  needed  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5029,allow  script  base  class  specified  groovyshell  groovyclassloader  eg  allow  bunch  function  added  current  script  class  interactiveshellscript  could  add  shellrelated  stuff  groovletscript  could  add  servletgroovlet  related  stuff  david  ejb  container  telnet  client  us  groovy  could  add  ejbcontainer  helper  method  gap  dynaop  stuff  could  dynaopscript  add  helper  method  etc  kind  compilerconfig  object  something  set  groovyshell  groovyclassloader  allow  kinda  thing  overloaded,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5030,process  gettext  gdk  method  block  operating  system  pulled  user  email  group  11142007  executing  maven  report  inside  certain  folder  code  new  fileeachdir  ignore  configdirs  ifitnamestartswith  return  println  executing  sitedeploy  task  für  itpomxml  def  processoutputmvnbat  f  itpomxml  sitedeployexecutetext  print  processoutput  code  case  somehow  process  hang  dont  know  processoutput  get  displayed  process  exited  possible  print  continously  stdoutstderr  process  console  anycommandexecute  javadoc  javalangprocess  native  platform  provide  limited  buffer  size  standard  input  output  stream  failure  promptly  write  input  stream  read  output  stream  subprocess  may  cause  subprocess  block  even  deadlock  two  simple  solution  come  mind  1  gettext  actively  read  buffer  stderr  stdout  two  separate  thread  2  subclass  javalangprocess  stderr  stdout  stream  overridden  read  buffered  stream  using  separate  thread  extra  credit  issue  synchronizing  output  stderr  stdout  reading  separate  thread  printing  console  log  file  output  come  wrong  order  depending  thread  executed  order  maybe  better  way  solve  problem  perhaps  easy  way  pipe  stringbuffer  calling  critical  bug  able  run  external  process  simply  elegantly  pretty  central  scriptinglanguagetype  us  current  implementation  clearly  broken  subtle  way,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5031,extending  xmlnodeprinter  support  namespaces  modified  xmlnodeprinter  file  patch  well  unit  test  case  attached  one  potential  change  ive  uploaded  make  namespace  awareness  optional  like  xmlparser  add  would  recommend  adding  namespace  prefix  namespace  awareness  15  namespace  prefix  printed  without  xmlns  attribute  lead  printing  xml  cannot  parsed  sax,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5032,rename  map  method  collect  consistent  map  could  reserved  method  creates  map  using  collect  mean  consistent  ruby  smalltalk,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5033,allow  subclass  xmlparser  customize  creation  new  node  patch  add  new  createnode  method  xmlparser  allow  subclass  customize  creation  new  node  allows  subclass  store  additional  information  node  tree  way  impact  memory  footprint  base  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5034,allow  junit  4  test  run  groovy  command  groovy  allows  junit  38x  test  groovytestcases  invoked  command  line  would  good  also  support  junit  4  test  way  attached  patch  pro  con  simply  save  junitcoremainmytestname  added  bottom  script  manually  invokes  runner  adding  code  groovy  codebase  small  saving  allow  script  left  test  class  ides  would  run  using  runner  doesnt  require  polluted  junitcore  manual  runner  code  make  sense  ide  runner  given  groovy  15  offering  java  15  support  round  nicely  junit  4  support  often  used  jump  java  15  hence  improves  case  using  groovy  testing  language  java  15  project  eg  making  tdd  bdd  easier  box  showing  favouritism  v  alternative  eg  testng  already  testng  runner  direct  junit  runner  happy  apply  wanted  attach  discussion  occur  around  whether  152  16  feature  included  paul,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5035,numeric  literal  default  bigdecimal  decimal  support  suffix  issue  recent  groovydev  list  discussion  concering  use  bigdecimal  default  numeric  type  literal  decimal  point  also  numeric  literal  suffix  supported  specify  type  discussion  james  strachan  said  bigdecimal  default  type  floating  point  number  literal  nondecimals  choose  best  size  integer  long  biginteger  based  length  number  folk  use  b  big  decimal  postfix  explict  use  double  f  float  explicit  control  call  typesafe  method  lower  type  double  float  either  use  doublevalue  floatvalue  method  cast  foofloat  p  x  1234  foo  float  x  foo  xfloatvalue  unless  x  1234f  foox  concerning  nondecimals  choose  best  size  integer  long  biginteger  based  length  number  automatically  choose  size  use  suffix  b  biginteger  also  mean  bigdecimal  literal  dot  integer  l  long,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5036,sum  min  friend  work  type  collect  friend  work  123sum  work  nicely  123iteratorsum  fails  contrast  code  123iteratoreach  println  work  fine  aesthetic  ground  shouldnt  difference  work  doesnt  importantly  situation  iterator  available  due  preexisting  apis  collection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5037,support  multiple  namespaces  namespacebuildersupport  major  limitation  using  buildersupport  doesnt  support  multiple  namespaces  common  eg  want  create  xml  message  invoke  google  calendar  codexml  entry  xmlnshttpwwww3org2005atom  xmlnsgcalhttpschemasgooglecomgcal2005  content  typehtmltennis  john  april  11  3pm330pmcontent  gcalquickadd  valuetrue  entry  code  cannot  build  message  current  namespacebuildersupport  one  namespace  could  specified  create  one  namespacebuildersupport  create  message  groovy  code  def  builder  new  namespacebuildersupport  dombuildernewinstance  buildernamespacehttpwwww3org2005atom  buildernamespacehttpschemasgooglecomgcal2005  gcal  def  data  builderentry  gcalquickaddvaluetrue  titletennis  john  contenttypehtml  tennis  wen  bing  pku  february  5  3pm330pm  code  reference  impl  following  code  public  class  namespacebuildersupport  extends  buildersupport  private  mapstring  string  nsmap  new  hashmapstring  string  public  namespacebuildersupportbuildersupport  builder  superbuilder  protected  namespacebuildersupport  namespacestring  namespaceuri  nsmapput  namespaceuri  return  protected  namespacebuildersupport  namespacestring  namespaceuri  string  prefix  nsmapputprefix  namespaceuri  return  protected  object  getnamestring  methodname  string  prefix  string  localpart  methodname  int  idx  methodnameindexof  idx  0  prefix  methodnamesubstring0  idx  localpart  methodnamesubstringidx  1  string  namespaceuri  nsmapgetprefix  namespaceuri  null  namespaceuri  prefix  return  new  qnamenamespaceuri  localpart  prefix  override  protected  object  createnodeobject  name  return  name  override  protected  object  createnodeobject  name  object  obj1  return  name  override  protected  object  createnodeobject  name  map  map  return  name  override  protected  object  createnodeobject  name  map  map  object  obj1  return  name  override  protected  void  setparentobject  obj  object  obj1  code  thanks  advance  hope  could  helpful,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5038,datasets  allowing  sorting  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5039,support  halfmocks  halfmocks  mock  class  dynamic  method  property  one  example  grail  domain  object  would  use  implemented  domain  specific  method  want  mock  gorm  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5040,plus  collection  try  keep  similar  type  original  collection  linkedlist  return  linkedlist  dgmplus  collection  original  linkedlist,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5041,intersect  collection  try  keep  similar  type  original  collection  like  plus  intersect  set  return  set  etc  per  plus,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5042,preserve  linecolumn  information  userdefined  occurrence  variable  thissuper  literal  nulltruefalse  currently  userdefined  occurrence  variable  super  literal  null  true  false  represented  singleton  ast  variableexpressionthisexpression  constantexpressionnull  etc  mean  linecolumn  information  lost  causing  trouble  tool  relying  information  ides  code  analyzer  transformation  etc  isnt  even  easy  detect  linecolumn  information  missing  expression  return  arbitrary  value  attached  patch  change  antlrparserplugin  creates  new  instance  variableexpressionconstantexpression  every  userdefined  occurrence  variablesliterals  mentioned  thus  preserving  linecolumn  information  singleton  still  used  internal  purpose  like  representing  implicit  method  call  however  order  test  presence  one  expression  necessary  call  one  new  method  isxxxexpression  eg  myvaristhisexpression  instead  comparing  singleton  eg  myvar  variableexpressionthisexpression  keep  change  code  base  minimum  avoiding  problem  defining  equality  astnodes  way  overriding  equal  affected  code  groovycore  adapted  accordingly  groovycore  build  successfully  ant  install  applying  patch  local  machine  initial  manual  test  indicate  patch  work  intended  course  automated  test  would  preferable  already  easy  way  get  expression  ast  node  unit  test  might  write  transformation  allows  capture  declaration  ast  node  certain  compiler  phase  please  look  patch  give  feedback  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5043,sqlrows  sqleachrow  consistent  behaviour  groovy  allows  sqlrowssomequeryeach  map  row  def  item  new  itemthattakesamaprow  sqleachrowsomequery  map  row  def  item  new  itemthattakesamaprow  shoudnt  sqleachrow  also  implement  map  interface  best  regard,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5044,global  transforms  executed  intellij  idea  intellij  idea  build  groovy  project  dependency  containing  global  transform  reason  transform  executed  twice  compile  groovyc  run  filesystemcompiler  idea  transform  executed  expected  ive  studied  transform  implementation  specifically  asttransformationvisitor  havent  found  cause  problem  know  transform  invoked  twice  modulenode  instance  sourceunit  report  phase  conversion  instead  semantic  analysis  guess  thats  sourceunitphase  longer  incremented  phase  conversion  reproduce  problem  ive  attached  jar  containing  transform  create  file  transformlogtxt  user  home  append  transform  invokedn  every  time  transform  invoked  whats  preferred  way  produce  debuginfo  output  transform  output  also  shown  idea  idea  add  jar  dependency  groovy  project  rebuild  build  groovyc  type  groovyc  cp  transformtestjaryourpathgroovyall16beta2snapshotjar  anygroovyfile  dont  forget  delete  transformlogtxt  compiler  invocation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5045,generictypes  ast  local  variable  generic  local  variable  werent  represented  ast  classnode  representing  type  built  using  code  type  maketypenode  instead  type  maketypewithargumentsnode  code  app  method  declarationexpression  generictype  node  cst  type  typeparameter  typeargument  used  set  linecol  info,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5046,create  identity  annotation  autogenerate  equal  hashcode  tostring  new  bindable  annotation  great  reduces  amount  boilerplate  code  required  groovy  bean  next  logical  step  identity  annotation  applied  one  attribute  telling  groovy  property  define  identity  business  key  whateveryouwanttocallit  bean  object  equal  hashcode  tostring  would  behave  accordingly  may  related  groovy27  im  sure  marked  wont  fix,1,0,1,0,1,0,0,0,1,0,1,1,0,0,0,0,1
5047,a1  b2  c3  flatten  1  2  3  a1  b2  c3  updated  listflattensetflatten  map  unadulterated  going  approach  mean  map  safely  used  list  commonly  done  kind  pseudobean  unit  testing  first  encountered  behavior,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5048,would  good  able  name  thread  using  dgsm  start  variant  well  threadstart  would  good  variation  allow  thread  naming  would  make  easier  perform  subsequent  thread  management  task,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5049,groovy  provide  immutable  annotation  make  creating  immutable  object  easy  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5050,groovy  sql  api  support  stored  procedure  output  parameter  return  result  set  stored  procedure  output  parameter  return  one  result  set  cant  get  output  using  groovy  sql  api  get  output  parameter  something  like  code  sqlcall  call  someproc  sqloutsqlintegertypesqloutsqlvarchartype  param1  param2  println  returned  param1  param2  code  get  single  resultset  output  parameter  something  like  code  sqlquery  call  someproc  null  null  resultset  println  returned  resultset  code  cant  stored  proc  return  multiple  result  set  luck  well  sqlcall  method  probably  use  callablestatement  getresultset  getmoreresult  method  get  result  set  pas  parameter  closure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5051,ability  create  static  groovy  method  currently  possible  create  instance  groovy  method  file  new  filetexttxt  fileeachline  line  println  cannot  currently  add  static  method  groovy260  thread  threadstart  process  long  running  processexecute  processwaitfor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5052,include  transaction  closure  standard  api  set  write  operation  sometimes  statementset  follow  transaction  semantics  thus  closure  like  withtransaction  inside  groovysqlsql  class  would  handy  discussion  see  also  httpwwwnabblecomgroovysqlsqlanddoingsqlstatementsinonetransactiontd2594039htmla20562605,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5053,open  antrlparserplugin  extension  error  recovery  parser  good  idea  currently  supported  groovy  grammar  groovy  eclipse  team  come  solution  patching  grammar  adding  antrlparserplugin  implementation  subclass  original  antrlparserplugin  current  implementation  antrlparserplugin  make  coding  subclass  rather  cumbersome  specifically  ast  field  private  error  recovery  code  must  injected  middle  execution  parsecst  feature  proposes  opening  antrlparserplugin  extension  initially  modifying  accessibility  ast  field  provide  protected  mutator  subclass  refactoring  parsecst  template  method  ill  provide  patch  shortly  would  love  merged  16  ship  patch  would  help  groovy  eclipse  plugin  also  specialized  tool  like  swingpad  reapt  benefit  error  recovery  parser,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5054,markupbuilder  performance  markupbuilderescapexmlvalue  us  algorithm  xml  escaping  unneccessary  space  time  requirement  attached  patch  trunk  le  memory  consumption  seems  increase  performance  factor  5  25,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5055,remove  ant  dependency  groovydoctool  patch  groovy3132  added  support  multiple  source  path  also  created  dependency  ant  core  groovydoctool  using  groovydoctool  mean  driving  doc  generation  plan  including  ant  providing  patch  push  ant  dependency  groovy  ant  package  also  included  testcase  multiple  source  bit  simple  validate  lookup  working  correctly,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5056,improved  class  loading  ast  transformation  currently  groovyc  load  ast  transformation  class  loader  also  responsible  loading  compile  dependency  lead  problem  compiler  client  provide  custom  class  loader  loading  compile  dependency  class  loader  might  able  meet  requirement  loading  ast  transformation  prominent  example  gmaven  us  custom  class  loader  prevent  classpath  pollution  without  fork  groovyc  unfortunately  also  mean  gmaven  cannot  compile  program  make  use  ast  transformation  patch  allows  compiler  client  optionally  provide  separate  class  loader  loading  ast  transformation  thereby  decoupling  class  loading  ast  transformation  compile  dependency  make  possible  compiler  client  gmaven  possibly  gradle  support  ast  transformation  pave  way  class  loading  improvement  future  version  groovyc  patch  fairly  small  try  keep  change  existing  codebase  absolute  minimum  apart  applying  moderate  change  two  transformrelated  class  add  line  code  class  compilationunit  existing  compiler  client  see  change  behavior  please  consider  patch  inclusion  groovy  16  16  maintenance  release  also  attached  corresponding  gmaven  patch  feedback  welcome,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5057,support  multiple  label  statement  unlike  java  groovy  doesnt  support  multiple  label  statement  instead  ast  builder  discard  first  label  class  multiplelabels  static  void  mainargs  label1  label2  true  break  label1  ok  break  label2  compile  error  break  missing  label  discussion  see  httpwwwnabblecommultiplelabelsonthesamestatementtd21543898html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5058,objectgraphbuilder  support  multiple  association  class  doesnt  seem  possible  something  like  class  company  string  name  employee  md  employee  cio  class  employee  string  name  def  builder  new  objectgraphbuilder  def  company  buildercompany  name  acme  md  name  billy  bob  cio  name  joey  john  class  associated  mutliple  time  different  field  use  field  name  builder  node  objectgraphbuilder  determine  class  using  reflection  attached  patch  unfortunately  trouble  building  groovycore  wasnt  able  run  objectgraphbuilder  add  extra  test  anyway  wanted  see  anyone  thought  good  idea  maybe  finish  patch  slightly  change  meaning  classnameresolver  would  apply  root  class  maybe  renamed  doc  updated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5059,add  stripmargin  multiline  string  explained  following  thread  httpwwwnabblecomgstringstripmargintd21679146html  scals  provides  stripmargin  method  multiline  string  helpful  overall  situation  something  fancier  covered  default  behavior  user  roll  impl  link  scala  api  doc  httpwwwscalalangorgdocufilesapiscalaruntimerichstringhtmlstripmargin,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5060,patch  enhance  string  class  find  method  take  regular  expression  groovy  make  working  regular  expression  much  easier  java  still  couple  hole  16  implementation  ive  attached  patch  add  couple  simple  method  make  regular  expression  much  easier  use  one  common  use  case  search  string  regular  expression  pattern  match  found  something  matched  value  currently  groovy  recommended  way  create  matcher  use  index  work  match  might  found  assert  10292  new  york  ny  10292  d50  try  string  doesnt  actually  match  regular  expression  youll  get  indexoutofboundexception  safe  need  check  matcherfind  match  requires  entire  string  match  see  string  actually  def  new  york  ny  d50  def  zip  mfind  zip  m0  also  inconsistent  behavior  regular  expression  happens  capture  group  return  array  containing  match  capture  group  forcing  index  array  actually  get  match  want  assert  c  foo  car  baz  ar01  groovy  already  added  closure  aware  replace  method  string  class  patch  add  complimentary  find  method  string  return  string  matched  closure  without  needing  worry  matcher  object  array  index  either  call  without  closure  get  full  found  match  back  even  group  assert  10292  new  york  ny  10292findd5  safely  return  null  match  isnt  found  clean  boilerplate  safety  check  quite  bit  user  check  null  using  groovy  truth  want  def  zip  new  york  nyfindd5  return  null  zip  want  work  capture  group  manipulate  value  pas  closure  find  method  passed  full  match  well  capture  group  collection  based  regular  expression  method  work  capture  group  match  passed  closure  assert  bar  foo  bar  bazfindar  match  return  match  one  capture  group  assert  b  foo  bar  bazfindar  match  firstletter  return  firstletter  many  capture  group  passed  closure  full  match  assert  2339999  adsf  2339999  adsffindd3d3d4  match  areacode  exchange  stationnumber  assert  2339999  match  assert  null  areacode  assert  233  exchange  assert  9999  stationnumber  return  exchangestationnumber  patch  also  includes  number  unit  test  exercise  demonstrate  functionality  get  traffic  blog  post  explaning  regular  expression  groovy  think  people  struggle  bit  current  implementation  think  patch  make  working  regular  expression  much  easier  intuitive,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5061,add  include  mechanism  groovlets  gsps  add  include  mechanism  groovlets  gsps  similar  jspinclude  discussed  httpwwwnabblecomgroovletsandlayoutingtd23047636html,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
5062,dataset  class  could  support  batch  operation  perhaps  described  httpmarkmailorgthreadciai2znkexfnrwot,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5063,would  good  delegate  didnt  delegate  deprecated  method  rare  would  want  deprecated  method  subject  delegation  would  nice  werent  carried  default  switch  force  rare  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5064,groovy  support  annotation  package  declaration  import  would  good  support  annotation  package  definition  import  statement  would  allow  script  like  code  grabgroupcommonslang  modulecommonslang  version24  package  foo  grabgroupcomgooglecollections  modulegooglecollections  version10rc2  import  comgooglecommoncollecthashbimap  import  static  orgapachecommonslangwordutils  def  fruit  grapepurple  lemonyellow  orangeorange  hashbimap  assert  capitalizefruitinverseyellow  lemon  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5065,enhance  swing  class  model  additional  method  swing  model  follow  naming  standard  common  operation  like  getint  setintelement  clear  provide  iterator  method  make  sense  request  enhance  swing  class  model  additional  method  bridge  gap  useful  collectiongroovy  method  port  httpjiracodehausorgbrowsegriffon44,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5066,allow  subclass  groovysqlsql  get  resultset  order  application  perform  optimally  multiple  large  database  use  important  iterate  result  set  without  using  closure  one  use  case  merge  record  multiple  database  company  several  division  order  database  day  order  sku  must  totalled  across  division  desired  solution  submit  query  database  parallel  string  query  select  sku  sumqty  orderitems  group  sku  order  sku  result  various  db  combined  using  merge  algorithm  cannot  accomplished  current  api  since  impractical  load  result  query  list  object  done  row  method  attached  patch  provides  path  implementing  desired  solution  adding  new  protected  method  also  refactors  consolidate  logic  remove  exposure  npe  addition  new  protect  method  static  method  create  list  resultset  made  public  log  field  made  static  patch  includes  new  test  case  added  sqltestgroovy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5067,grape  resolve  ivy  could  generate  ivy  dependency  please  add  option  grape  generate  ivy  dependency  command  line  like  ant  do  option  example  command  grape  resolve  ivy  orgapachepoi  poi  35beta6  orgapachepoi  poiooxml  35beta6  could  generate  following  output  dependency  orgorgapachepoi  namepoi  revision35beta6  dependency  orgorgapachepoi  namepoiooxml  revision35beta6,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5068,enhance  consistency  regexpattern  dgm  method  regexpattern  based  dgm  method  try  allow  regex  string  pattern  counterexample  code  string  string  replacefirstpattern  pattern  string  replacement  boolean  matchespattern  pattern  object  spliteachlinestring  regex  match  string  replaceallstring  regex  match  string  replaceallpattern  pattern  string  replacement  file  object  spliteachlinestring  sep  match  reader  object  spliteachlinestring  sep  match  inputstream  object  spliteachlinestring  sep  string  charset  match  object  spliteachlinestring  sep  match  code  special  case  minus  particularly  bad  provide  regex  string  treated  regex  since  would  conflict  stringminusstring,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5069,provide  control  grape  exclude  transitive  adjust  classloader  current  grab  grape  annotation  provide  simplified  way  bring  dependency  limitation  get  transitive  dependency  way  exclude  particular  unwanted  transitive  dependency  sometimes  dont  get  right  classloader  consider  enhancing  support  overcome  limitation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5070,round  eachrows  row  variant  taking  metadataclosure  currently  sql  variant  eachrows  row  code  eachrowstring  sql  closure  closure  eachrowstring  sql  closure  metaclosure  closure  closure  eachrowstring  sql  list  params  closure  closure  eachrowgstring  sql  closure  closure  rowsstring  sql  rowsgstring  sql  rowsstring  sql  closure  metaclosure  rowsstring  sql  list  params  code  patch  round  support  metadataclosures  used  variant  taking  params  gstrings  ive  needed  method  one  occasion  another  dont  see  reason  variant  supported  code  eachrowstring  sql  closure  closure  eachrowstring  sql  closure  metaclosure  closure  closure  eachrowstring  sql  list  params  closure  closure  eachrowstring  sql  list  params  closure  metaclosure  closure  closure  eachrowgstring  sql  closure  closure  eachrowgstring  sql  closure  metaclosure  closure  closure  rowsstring  sql  rowsstring  sql  closure  metaclosure  rowsstring  sql  list  params  rowsstring  sql  closure  metaclosure  list  params  rowsgstring  sql  rowsgstring  sql  closure  metaclosure  code  expanded  test  cover  variant  ive  renamed  test  method  name  according  signature  method  test  systematic  naming  convention  seems  required  variant  noticed  couple  test  misleading  name  example  currently  trunk  code  void  testrowsgstring  def  sql  createsql  def  table  person  gstring  query  select  table  def  result  sqlrowsquerytostring  assert  resultsize  3  code  either  misunderstanding  test  else  wrong  calling  tostring  gstring  test  passing  gstring  exercising  gstring  variant  row  method  perhaps  test  modified  previous  form  patch  ive  corrected  row  gstring  test  left  alone  another  test  method  called  testfirstrowwithgstring  im  right  fix  cam  come  back  another  patch  im  right  created  patch  using  git  diff  tested  svn  trunk  linux  using  gnu  patch  thus  code  patch  p1  metaclosurepatch  code  work  please  let  know  there  anything  make  patch  convenient  format  hope  find  agreeable  john  hurst,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5071,markupbuilder  alignment  special  mkp  command  compared  streamingmarkupbuilder  streamingmarkupbuilder  support  mkpcomment  mkppi  mkpxmldeclaration  emulated  using  mkpyieldunescaped  markupbuilder  also  support  convenience  method  ease  learning  two  approach,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5072,ast  transforms  groovyasttransformationclass  annotation  allow  parameter  type  class  string  annotation  groovyasttransformationclass  mark  another  annotation  ast  transformation  annotation  required  parameter  string  parameter  store  fully  qualified  class  name  invoked  transformation  phase  convenience  parameter  type  class  instead  string  allows  programmer  specify  class  string  represents  class  cannot  remove  string  would  break  backwards  compatibility  could  add  2nd  parameter  require  1  one  two  parameter  specified  originally  requested  venkat  subramanium  2gx  2009,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5073,add  reader  support  groovyshell  groovycodesource  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5074,objectgraphbuilder  add  general  purpose  bean  factory  swingbuilder  sport  bean  capable  wiring  existing  bean  instance  build  process  ogb  cant  great  feature  developer  able  tweak  bean  instance  using  builder  syntax  code  company  acme  fetch  company  webservice  perhaps  ogbbeanacme  add  employee  employeename  duke  employeename  tux  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5075,add  mapsynchronized  listsynchronized  method  mapimmutable  also  able  mapsynchronized  listsynchronized  trivial  helper  method  map  collectionutilssynchronizedmapmap  ditto  list  save  mucho  typing  importing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5076,implicit  reference  inner  class  handled  automatically  currently  inner  class  instantiated  following  way  new  myinnerclassthis  passed  explicitly  npe  propertymissing  occurs  highly  irritating  groovyc  take  care  handling  like  javac  classified  issue  improvement  according  jochen  nonanoymous  inner  class  yet  officially  supported,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5077,make  groovy  truth  value  nan  false  similar  null  emptystring  groovy  evaluate  nan  false  rather  true  noformat  def  result  abcalcx  result  valid  nonnull  number  noformat  javascript  treat  nan  like  groovy  design  choice  make  sense  discussed  thread  httpoldnabblecomshouldntthegroovytruthvalueofnanbefalsett27348256html  nan  false  following  work  assert  doublenan  assert  doublenan  boolean  true  assert  doublenan  boolean  false,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5078,groovy  equality  set  map  currently  groovy  equality  extends  array  list  set  map  example  code  assert  1  1l  pass  assert  1  set  1l  set  fails  code  surprising  ungroovy  would  nice  groovy  equality  set  map  drawback  would  make  setmap  equality  inconsistent  lookup  result  ie  two  set  equal  setcontains  yield  different  result  hand  problem  already  exists  groovy  list  equality  map  one  could  avoid  lookup  inconsistency  using  groovy  equality  value  would  good  discussion  proposal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5079,gapi  document  generation  ignores  access  modifier  set  groovydoc  orgcodehausgroovyantgroovydoc  support  attribute  like  privateprotectedpublic  seems  like  ignored  gapi  documentation  generation  documentation  generated  contains  packageprivate  detail  related  information  see  groovy4135,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
5080,groovys  sql  class  could  support  batch  operation  leveraging  javasqlstatementexecutebatch  command  perhaps  described  httpmarkmailorgthreadciai2znkexfnrwot,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5081,statically  imported  property  describe  class  code  class  foo  static  def  getbar  static  def  setbardef  bar  code  script  code  import  static  foobar  print  bar  print  getbar  code  print  getbar  throw  missingmethodexception  imho  getbar  resolved  foogetbar  without  explicit  import  thing  setter  aliased  import  code  import  static  foobar  setbar2  code  code  import  static  foobar  baz  setbaz2  print  getbaz  code  code  import  static  foogetbar  print  bar  code  code  import  static  foosetbar  bar  2  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5082,bigdecimal  division  currently  implemented  using  pre  java  15  code  implementation  bigdecimalmath  divide  done  prior  java  15  improve  implementation  making  use  newer  facility  proposed  implementation  code  arbitrary  value  picked  reasonable  choice  precision  typical  user  math  nonterminating  result  would  otherwise  occur  public  static  final  int  defaultminimumprecision  10  public  number  divideimplnumber  left  number  right  bigdecimal  bigleft  tobigdecimalleft  bigdecimal  bigright  tobigdecimalright  try  return  bigleftdividebigright  catch  arithmeticexception  e  set  default  precision  otherwise  nonterminating  int  precision  mathmaxmathmaxbigleftprecision  bigrightprecision  defaultminimumprecision  return  bigleftdividebigright  new  mathcontextprecision  code  example  code  println  1000g  30g  println  1000000000g  30g  println  0000000000000000000000000000000001  3  println  0000000000000000000000000000000001  8  println  0000000000000000000000000000000001  8toplainstring  println  1000  10  println  100000000000000000000000000000000000  3  println  100000000000000000000000000000000000  8  println  1e35  8  println  1e35  8toplainstring  println  100000000000000000000000000000000000  0000001  println  1000000000000000000000000000000000000000000  0000001  println  1000000000000000000000000000000000000000000  0000001striptrailingzeros  try  use  divide  direct  override  groovy  behavior  10gdivide3g  catcharithmeticexception  ae  println  caught  aemessage  code  output  running  example  noformat  3333333333  3333333333  3333333333e34  125e34  0000000000000000000000000000000000125  100  333333333333333333333333333333333333  12500000000000000000000000000000000  125e34  12500000000000000000000000000000000  100000000000000000000000000000000000e41  1000000000000000000000000000000000000000000  1e41  caught  nonterminating  decimal  expansion  exact  representable  decimal  result  noformat,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5083,open  observablelist  observablemap  extension  observablelist  observablemap  closed  extension  would  great  class  expose  functionality  subclass  like  collection  delegate  event  firing  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5084,groovy  mechanism  create  classlevel  field  script  script  variable  locally  defined  variable  within  run  method  script  hence  arent  available  instance  method  call  proposed  patch  add  classscope  annotation  promotes  variable  declaration  field  declaration,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5085,collection  map  function  improvement  add  following  method  set  union  completeness  synonym  plus  match  intersect  improvement  add  following  method  map  set  domain  synonym  keyset  set  codomain  return  set  unique  value  set  range  synonym  codomain  map  domainrestrictset  return  map  entry  whose  key  appear  set  map  rangerestrictset  return  map  entry  whose  value  appear  set  set  imageset  return  set  unique  value  map  whose  domain  appears  set  note  image  equivalent  mapdomainrestrictsrange  map  invertmap  return  map  key  value  relationship  inverted,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5086,power  asserts  use  defaultgroovymethodstostring  instead  plain  tostring  defaultgroovymethodstostring  would  lead  groovyier  output  eg  map  would  printed  a1  b2  instead  a1  b2,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5087,assert  closure  call  look  like  per  following  conversation  httpgroovymarkmailorgsearchqpower20assert20question20when20asserting20closure20callsquerypower20assert20question20when20asserting20closure20callspage1midbzbavvzceem3dd2zstateresults  make  closure  call  look  like  method  call  code  def  closure  assert  closurefalse  code  instead  code  assert  closurefalse  consolescript1runclosure1575fa5  code  get  code  assert  closurefalse  false  code  one  really  wan  see  tostring  closure  could  still  code  assert  closurecallfalse  false  consolescript2runclosure1f1584a  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5088,add  multiple  file  extension  support  compiler  regarding  need  groovy  support  file  extension  groovy  really  useful  others  well  submitting  revised  version  patch  put  entry  like  following  orgcodehausgroovytransformasttransformation  dont  belong  noformat  filesgppgrunit  noformat  defined  separate  file  orgcodehausgroovysourceextensions  class  listed  file  need  implement  following  interface  register  extension  compiler  call  back  collect  file  extension  caller  interest  code  public  interface  sourceextensionsupport  setstring  getextensions  code  review  comment  welcome,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5089,parser  support  method  declaration  script  creating  script  itd  cool  able  create  method  script  eg  foox  printlnx  1  2  3each  fooit  kinda  thing  might  impact  parser  implementation  somewhat  ast  handle  right  need  parser  handle  eg  astbuilder  datatypedeclaration  method  currently  check  class  interface  statement  making  detect  method  declaration  calling  moduleaddmethodmethodnode  would  fix  though  im  leaving  gonna  easy  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5090,add  paging  groovysql  patch  provided  add  offset  maxrows  argument  eachrow  method  could  also  applicable  method  left  implementation  look  scrollable  result  applies  resultsetabsolute  method  forward  result  set  next  invoked  offset  number  time  maxrows  arg  implemented  calling  resultsetnext  maxrows  number  time  able  run  test  dev  mailing  list  thread  topic  ive  included  patch  theyre  comprehensive  correct  im  able  run  test  able  verify  implementation  mean,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5091,implement  way  direct  method  call  methodcallexpression  already  got  setgetmethodtarget  method  enable  ast  writer  direct  method  call  logic  behind  implemented,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5092,support  preparedstatementaddbatch  create  new  version  sqlwithbatch  support  prepared  statement  preparedstatementaddbatch  vast  majority  case  perform  better  sqlwithbatch  using  statement  statementaddbatchstring  ive  added  patch  perform  suggested  change  patch  file  generated  using  diff  u  basefile  modifiedfile  groovy  175  used  base  additional  information  httpgroovy329449n5nabblecomgroovysqlandbatchupdatestp4339851p4339851html  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5093,add  new  urleachline  method  working  url  like  file  object  similarly  may  want  urlaswritable  like  file  well  urlgettext  urleachbyte  urlwithreader  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5094,add  createtempdir  file  would  nice  possible  easily  create  temporary  directory  java  file  class  method  creates  temporary  file  doesnt  create  file  object  also  file  disk  instead  might  create  object  user  could  decide  point  whether  create  file  directory  name  straight  forward  approach  would  add  new  method  called  createdir  current  workaround  create  file  delete  file  make  directory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5095,includes  attribute  equalsandhashcode  continue  late  discussion  groovy2879httpjiracodehausorgbrowsegroovy2879  stopped  since  issue  closed  use  case  includes  attribute  usefulness  equalsandhashcode  typical  jpa  entity  implement  equivalence  natural  key  basis  usually  natural  key  one  two  property  entity  contain  dozen  property  listed  excludes  moment  example  entity  person  firstname  lastname  represent  natural  key  dont  want  anything  else  equal  codetitleusing  current  implementation  entity  equalsandhashcodeexcludes  idageemailaddressoccupationspousecontactsinterestsrelativesfriendswhatever  class  person  id  int  id  string  firstname  lastname  def  age  email  address  occupation  spouse  contact  interest  relative  friend  whatever  code  codetitleproposed  entity  equalsandhashcodeincludes  firstnamelastname  class  person  id  int  id  string  firstname  lastname  def  age  email  address  occupation  spouse  contact  interest  relative  friend  whatever  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5096,rename  dgm  collectall  collectnested  keep  original  alias  time  view  deprecatingremoving  eventually  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5097,swingbuilder  binding  update  happen  inside  edt  target  ui  component  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5098,memoized  ast  transformation  method  whole  idea  similar  existing  great  lazy  annotation  differs  concept  instead  applied  field  applied  method  thus  providing  wider  field  use  applied  getters  serf  alternative  lazy  applied  method  provides  lazy  cant  thus  eliminates  need  heavy  refactoring  certain  situation  simply  letting  user  add  annotation  method  suggestion  could  work  codecached  createx  new  t1  2  3  codegets  transformed  code  private  createxresult  createx  new  t1  2  3  createx  resultlocal  createxresult  resultlocal  null  return  resultlocal  else  synchronized  createxresult  null  createxresult  createx  return  createxresult  code  whole  thing  could  extended  cache  different  result  method  depending  argument  topic  discussion,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5099,swingbuilder  add  component  support  buttondemo  test  relative  size  ease  groovy  swing  applicaiton  though  reimplementing  swingset  jfc  demo  groovy  wound  third  size  original  really  groovy  job  needed  add  item  concept  swingbuilderjar  notable  change  add  methiods  javaxswingbox  glue  strut  rigid  area  add  buttongroup  case  abstractbuttons  dont  dive  model  set  button  group  checkbox  radiobutton  tweak  add  support  adding  component  tabbed  pane  explicitly  introduce  pas  node  widget  nesscicarily  created  provided  user  elaboration  widget  node  groovy333  widget  action  tablemodel  refactor  code  attribures  set  java  bean  proeprties  widget  patch  may  contain  stuff  groovy333  patch  dont  thuink  applied  yet  also  buttondemogroovy  portion  button  tab  swingset  buttondemojava  sans  image,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5100,unnecessary  casttotype  boxed  type  subclass  implement  target  type  following  code  code  int  method  1  void  test  int  method  println  test  code  compiler  produce  uncessary  casttotype  call  convert  boxed  int  aka  integer  object,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5101,make  tupleconstructor  work  enums  intent  would  make  following  example  work  currently  tupleconstructor  annotation  ignored  unless  explicit  constructor  added  example  fail  code  groovytransformtupleconstructor  enum  operator  plus  minus  string  symbol  assert  operatorplusnext  operatorminus  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5102,tostring  optionally  exclude  field  null  value  particularly  object  high  number  field  ability  exclude  field  null  output  generated  tostring  would  nice,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5103,implement  lowest  upper  bound  algorithm  type  inference  important  determine  lowest  upper  bound  two  type  current  implementation  called  findcommonsuperclass  fine  limited  example  two  type  common  superclass  implement  interface  findcommonsuperclass  would  return  object  could  return  interface  idea  replace  current  implementation  smarter  one  computes  lowest  upper  bound  lub  two  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5104,bytecode  optimization  make  use  ldc  class  literal  class  literal  currently  loaded  using  generated  getclass  method  increase  bytecode  size  may  prevent  optimization  situation  though  may  use  lcd  bytecode  instruction  load  class  literal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5105,groovy  could  benefit  dgm  takewhile  dropwhile  method  currently  take  method  collection  return  first  n  item  collection  language  scala  haskell  also  provide  takewhile  method  similar  instead  taking  fixed  number  item  take  item  condition  form  closure  met  example  code  def  item  123454321  def  sublist  itemstakewhile  5  assert  sublist  1234  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5106,groovydoc  error  equalsandhashcode  looking  groovydoc  equalsandhashcode  groovydoc  missing  method  httpgroovycodehausorggapigroovytransformequalsandhashcodehtml  seen  javadoc  httpgroovycodehausorgapigroovytransformequalsandhashcodehtml  glitch  groovydoc  processing  andor  formatting  within  equalsandhashcode  source  file  need  tweaking,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5107,process  method  called  closestreams  java  doesnt  close  stream  finalization  result  many  open  file  error  sometimes  avoid  problem  one  need  proactively  close  stream  process  finished  currently  requires  3  method  call  propose  simple  one  added  process  called  closestreams  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5108,add  base  script  option  groovyc  ant  task  please  provide  way  tell  groovyc  ant  task  base  script  compiled  script  extend  already  possible  using  groovyshell  gaelyk  project  precompiling  script  gain  better  runtime  preformance  currently  precompile  pure  groovlets  groovy  template  dont  need  extend  special  base  script  would  like  able  also  able  precompile  script  relies  particular  base  script  route  plugins,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5109,expression  x  5  return  5  outer  expression  x  5  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5110,delegatesto  annotation  idestypechecker  add  annotation  closure  parameter  allows  document  method  resolved  closure  example  code  exec  executable  foo  args  bar  baz  class  project  execresult  execdelegatestoexecspec  closure  closure  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5111,remove  runtime  dependency  asmutil  0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5112,support  dsl  type  checking  improve  support  dsl  type  checking  allow  user  customize  behaviour  type  checker  provide  mean  support  static  compilation  provide  higher  level  api  simple  customizations,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5113,provide  way  assemble  annoation  consisting  several  idea  give  alias  annotation  representing  group  annotation  alias  encountered  replaced  annotation  contains,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5114,provide  mechanism  allow  type  checker  know  expected  argument  type  closure  method  like  collect  time  take  closure  argument  type  checker  doesnt  enough  type  information  infer  expected  argument  type  closure  example  following  case  code  liststring  string  abcdef  stringscollect  ittouppercase  code  there  enough  type  information  signature  collect  type  checker  know  type  string  upcoming  lambda  support  jdk8  becomes  critical  u  provide  information,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5115,tostring  allow  caching  tostring  value  immutable  object  hashcode  value  tostring  value  need  computed  cached  hashcode  tostring  method  return  cached  value  tostring  equalsandhashcode  ast  transformation  option  allow  caching  example  tostringcachetrue  equalsandhashcodecachetrue  also  immutable  annotation  use  tostring  equalsandhashcode  transformation  caching  capability  enabled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5116,dgmcollectmany  overload  accepts  iterable  dgmcollectmany  overload  accepts  iterable  even  object  like  dgmcollect,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5117,try  iterating  transforming  object  collection  defaultgroovymethods  like  count  sort  collection  method  let  say  following  utils  class  xml  taken  groovykoansorg  code  class  utils  static  string  moviesxml  moviecatalog  movie  id6  titletotal  recalltitle  year1990year  movie  movie  id4  titlethe  terminatortitle  year1984year  movie  movie  id5  titlethe  expendablestitle  year2010year  movie  movie  id1  titleconan  barbariantitle  year1982year  movie  movie  id3  titlepredatortitle  year1987year  movie  movie  id2  titletrue  liestitle  year1994year  movie  movie  id7  titlekindergarten  coptitle  year1990year  movie  moviecatalog  static  def  getmovies  new  xmlslurperparsetextutilsmoviesxmlmovie  code  would  like  count  movie  id  greater  5  doesnt  work  throw  missingmethodexception  code  assert  utilsmoviescountitidtext  5  2  code  code  assert  utilsmoviesiteratorcountitidtext  5  2  code  work  code  assert  utilsmoviescollectcountitidtext  5  2  code  behaviour  applies  utilsmoviessortitidtext  also  collectentries  collectmany  sum  join  many  collection  method  collect  method  work  expected  something  like  would  useful  groovydefaultmethods  code  public  static  number  countobject  self  closure  closure  return  countcollectself  closure  public  static  list  sortobject  self  return  sortcollectself  public  static  list  sortobject  self  closure  closure  return  sortcollectself  closure  etc  code  noticed  also  groovyutilslurpersupportnodechildren  doesnt  implement  iterable  class  maybe  changing  code  public  abstract  class  gpathresult  extends  groovyobjectsupport  implement  writable  buildable  code  code  public  abstract  class  gpathresult  extends  groovyobjectsupport  implement  writable  buildable  iterable  code  would  solve  problem,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5118,support  ast  transforms  field  generated  field  script  following  snippet  script  wont  currently  work  code  lazy  field  sql  db  new  sql  code  copy  nonast  transforms  creating  field  ast  one  intentional  moment  align  limitation  annotation  collected  traversed  could  attempt  add  fact  collected  known  transforms,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5119,configure  gradle  eclipse  plugin  groovycore  make  easier  eclipse  user  contribute  groovy  would  nice  get  groovycore  build  eclipse  therefore  gradle  eclipse  plugin  configured  similar  idea  plugin  know  possible  quote  cã©dric  quote  know  groovy  code  written  groovy  build  bootstrap  compiler  first  use  compile  groovy  file  allow  complete  compiler  build  add  fact  unit  test  written  groovy  depend  groovytestcase  turn  dependency  groovytest  example  might  idea  eclipse  find  cyclic  dependency  cyclic  dependency  scope  compiletest  yes  eclipse  build  need  kind  hack  idea  build  quote  httpgroovy329449n5nabblecomgroovyrepogradleeclipseintellijideatd5715559html  maybe  somebody  eclipse  knowhow  like  volunteer,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5120,support  dynamic  method  call  static  compilation  might  interesting  instruct  compiler  method  call  groovy  made  dynamically  even  compilestatic  section  example  want  enable  compilestatic  grail  controller  still  want  able  call  dynamic  finder  method  call  starting  find  recognized  dynamic  call  idea  write  type  checking  extension  instruct  compiler  method  meant  called  dynamically  expected  inferred  return  type  call  latter  important  order  keep  grooviness  code  otherwise  would  need  add  explicit  cast  dynamic  method  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5121,singleton  transform  complain  constructor  found  singleton  transform  creates  private  noarg  constructor  fact  provides  implementation  throw  exception  doesnt  complain  constructor  already  present  constructor  would  allow  singleton  pattern  violated  result  compiletime  error,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5122,new  groovy  jdk  method  improve  consistency  august  2004  email  ive  quick  look  groovy  jdk  ie  defaultgroovymethods  defaultgroovystaticmethods  many  method  class  little  hard  take  ive  knocked  quick  script  groovy  collates  method  object  become  attached  hacky  script  httpjavanicuscomgroovymunggroovysourcecodegroovy  result  pretty  table  method  left  hand  side  class  attached  along  top  method  implemented  crossover  placed  small  graphic  hover  cursor  give  bit  detail  method  httpjavanicuscomgroovygroovyjdkcrossreferencehtml  ive  quick  look  method  thought  would  defined  quick  inspection  ab  thru  leftshift  far  believe  following  candidate  available  mean  exhaustive  list  possible  missing  non  static  method  collectionasimmutable  objectasimmutable  objectassynchronized  setcount  byteeachbyte  filefilterline  inputstreamfilterline  listfindindexof  collectionflatten  dategetat  get  year  etc  conjunction  calendar  readergettext  collectionintersect  bufferedwriter  object  charsequence  file  map  another  map  process  processout  socket  socketout  objectmax  objectmin  collectionminus  mapminus  could  compare  rh  key  value  objectminus  urlnewinputstream  urlnewreader  charsequencepadleft  charsequencepadright  objectpop  charsequenceputat  collectionputat  always  ordered  collectiongetat  dateputat  eg  easy  access  component  date  matcherputat  inputstreamreadbytes  urlreadbytes  urlreadlines  charsequencereverse  objectreverse  sortedmapreverse  sortedsetreverse  collectionreverseeach  like  collectioneach  could  indeterminate  mapreverseeach  mapeach  matcherreverseeach  objectreverseeach  objectreverseeach  perhaps  fooreverseeach  fooreverseeach  objectrightshift  thing  like  foo  log  objectsort  inputstreamspliteachline  urlspliteachline  outputstreamwithwriterappend  bufferedwriterwrite  outputstreamwrite  filewriteline  outputstreamwriteline  im  quite  sure  difference  append  supposed  perhaps  fileappend  become  file  eachbyte  would  good  idea  also  eachcharacter  reader  thanks  jeremy  p  based  entirely  existing  method  existing  owner  object  would  nice  think  object  method  could  include  current  owner  object  come  javalang  javautil  javautilregex  javaio  javanet,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5123,indy  dttcasttotype  usage  indy  mode  yet  path  groovy  cast  least  check  null  objectclasstype  could  done  indy  simply  return  object  avoid  call  casttotype  casttotype  poisson  jit  avoiding  possible  important,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5124,closure  sam  interface  coercion  doesnt  handle  contravariant  type  correctly  coercing  closure  interface  method  take  contravariant  type  groovy  create  implementation  accepts  special  type  code  class  testcase  interface  actiont  void  executet  thing  static  class  wrappert  private  final  thing  wrappert  thing  thisthing  thing  void  contravarianttakeaction  super  action  actionexecutething  void  invarianttakeactiont  action  actionexecutething  static  wrappert  wrapcallablet  callable  new  wrappercallablecall  static  integer  dubinteger  integer  integer  2  static  void  mainstring  args  wrap  1  contravarianttake  dubit  fails  static  compile  known  integer  wrap  1  invarianttake  dubit  pass  static  compile  known  integer  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5125,improve  parser  speed  groovy  json  parser  maintaining  backward  compatability  discussed  mailing  list  private  conversation  basic  plan  take  idea  boon  json  parser  add  groovy  groovy  depend  boon  2  five  class  moved  groovy  later  effort  approved  move  java  object  json  serialization  work  done  boon  jsonproperty  jsonview  etc  small  part  boon  json  parsing  large  part  boon  effort  map  json  java  object  groovy  already  allows  easy  conversion  map  java  object  boon  style  json  parser  may  suite  groovy  well  intermediate  state  object  tree  look  like  map  actually  hierarchy  value  object  index  overlay  object  boon  json  parse  found  httpsgithubcomrichardhightowerboonwikiboonjsoninfiveminutesprocessingmodeldatabinding  early  benchmark  appear  new  boon  style  json  parser  inmemory  parse  would  around  2x  5x  faster  common  popular  json  parser  20x  faster  existing  groovy  parser  effort  made  create  large  file  parser  bc  boon  initially  restwebsocket  json  consumption  streaming  mode  boon  created  windowing  buffer  parser  could  better  support  migration  although  created  boon  project  intended  target  windowing  buffer  groovy  2mb  file  use  inmemory  parser  default  2mb  use  windowing  buffer  default  detail  mailing  list  search  json  groovy  benchmark,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
5126,enhance  groovyassert  junit  4  support  right  groovy  221  groovyassert  class  offer  way  embed  shouldfail  junit  4  test  method  also  used  internally  groovytestcase  issue  making  groovyassert  official  api  class  supporting  junit  4  integration  providing  bunch  static  method  imported  case  orgjunitassert  purpose  class  need  javadoc  documentation  mentioned  new  groovy  language  documentation  plus  would  like  move  method  groovytestcase  groovyassert  way  done  shouldfail  issue  consists  writing  documentation  groovyassert  applying  refactoring  groovytestcase,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5127,allow  basescript  import  package  definition  would  nice  basescript  could  used  packageimport  definition  like  code  basescriptmyscript  import  groovytransformbasescript  println  ok  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5128,reflection  api  trait  need  kind  reflection  api  trait  program  reason  trait  runtime  example  one  thing  need  know  spock  whether  method  according  java  reflection  declared  class  x  actually  declared  groovy  class  inherited  trait,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5129,domcategory  trim  whitespace  default  domcategory  trim  whitespace  returned  text  default  reduces  usefulness  many  scenario  since  trimming  easy  fact  offer  little  utililty  see  also  groovy5360,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5130,allow  implement  register  type  checking  extension  subclass  typecheckingextension  type  checking  extension  implemented  via  typecheckingdsl  registered  via  compilationcustomizer  would  nice  one  could  also  extend  le  magic  typecheckingextension  somehow  register,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5131,move  method  collection  iterable  move  many  method  collection  iterable  added  method  iterable  containsobject  containsallobject  eachpermutationclosure  injectclosure  head  tail  ascollection  plusiterable  plusobject  multiplynumber  intersectiterable  toset  deprecated  method  collection  eachpermutationclosure  add  method  iterable  gpathresult  conflict  read  httpsgithubcomgroovygroovycorepull444  detail  toliststring  toliststringint  also  added  method  defaultgroovymethodssupportcreatesimilarcollectioniterable  cannot  move  method  exists  object  groovy  cannot  handle  properly  move  collection  iterable  grepobject  grep  collectclosure  collect  collectcollection  closure  findclosure  find  findresultobject  closure  findresultclosure  findallclosure  findall  splitclosure  injectclosure  injectobject  closure  pull  request  httpsgithubcomgroovygroovycorepull444,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5132,move  collate  permutation  list  iterable  added  collate  iterable  moved  permutation  list  iterable  patch  depends  related  httpsgithubcomgroovygroovycorepull444  move  method  collection  iterable  patch  httpsgithubcomgroovygroovycorepull449,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5133,add  ability  layout  inherit  model  markup  template  engine  layout  use  model  independent  original  model  would  nice  option  inherit  model  parent  template  order  avoid  lot  code  duplication,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5134,add  disjoint  minus  tospreadmap  iterable  added  method  iterable  disjointiterable  minusobject  minusiterable  tospreadmap  added  method  collection  minuscollection  pull  request  httpsgithubcomgroovygroovycorepull476,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5135,dgm  collection  improvement  highlight  proposed  improvement  unique  dgm  method  follow  java  default  mutate  place  called  instance  collection  also  boolean  flag  nonmutating  behavior  iterable  variant  method  one  mutate  flag  wouldnt  make  sense  noncollection  iterables  iterator  variant  flag  wouldnt  make  sense  anyway  array  variant  one  wouldnt  make  sense  mutate  flag  rather  complicating  unique  improvement  add  iterable  iterator  array  variant  tounique  method  always  return  new  collectionlike  structure  similar  situation  exists  sort  unique  improvement  add  iterable  iterator  array  map  variant  tosorted  method  always  return  new  collectionlike  structure  noniterable  variant  deprecated  favor  iterable  variant  collate  containsall  tail  take  multiply  iterables  disjoint  minus  iterables  nonreleased  list  variant  init  takeright  dropright  elided  provided  marginal  performance  benefit  compared  extra  api  complexity  iterator  variant  added  returned  collection  type  kept  similar  original  possible  iterable  variant  tail  init  take  takeright  drop  dropright  takewhile  dropwhile  multiply  iterables  two  new  addall  variant  collection  addalliterator  addalliterable  possible  iterator  variant  mentioned  method  modified  necessary  dont  create  extra  copy  collectionlike  structure  ie  iterators  used  instead  logic  involving  example  tolist  followed  operation  list  make  work  better  possibly  infinite  stream  data  eg  code  int  1  def  infiniterator  hasnext  true  next  iterator  assert  infiniteratordrop3dropwhile  9  tounique  100  inittailtake3tolist  10  11  12  code,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5136,align  parameter  delegatesto  closureparams  currently  delegateto  allows  use  generic  type  another  argument  call  actually  need  delegate  one  generic  parameter  enclosing  class  ie  signature  code  pipelinebuildert  map  boolean  passthroughnulls  true  closureparamsvaluefromstringclass  optionst  closuret  mapper  code  want  mapper  closure  able  refer  payload  delegate  well  parameter  unfortunately  delegatesto  wont  let  written  prior  closureparams  support  thing  like  firstparam  fromstring  aligning  config  params  deleatesto  closureparams  make  powerful  easier  learn,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5137,groovyservlet  generate  binary  content  allow  groovy  servlets  generate  binary  content,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5138,inheritconstructors  replicate  annotation  super  constructor  want  use  guice  inject  dependency  hierarchy  testng  test  using  inject  constructor  injection  since  many  test  use  exactly  object  inheritconstructors  would  perfect  inheritconstructors  replicate  inject  annotation  superclass  causing  guice  complain  injectable  constructor  constructor  created  inheritconstructors  replicate  annotation  constructor  method  theyre  copying,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1
5139,base64  url  safe  encoder  encodinggroovymethods  support  encodebase64  also  support  mime  encoding  using  chunked  parameter  support  base64  url  safe  encoding  implementation  maybe  trivial,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5140,include  inherited  property  tostring  tostring  annotation  includes  property  directly  declared  current  class  property  inherited  small  hierarchy  spring  data  document  inherit  common  abstract  base  id  status  key  like  natural  tostring  include  property  one  declared  concrete  class  includesuper  usable  workaround  awkward  base  class  never  instantiated  splitting  property  bit  confusing  would  helpful  able  tell  tostring  include  inherited  property  generating  tostring,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5141,listwithindex  method  zip  list  index  missing  implementaion  code  public  static  list  withindexlist  self  return  withindexself  0  public  static  list  withindexlist  self  int  offset  return  transposearraysaslistself  new  intrangefalse  offset  offset  selfsize  code  use  like  code  assert  0  b  1  bwithindex  assert  1  2  b  bwithindex1collect  str  idx  idx  str  code  language  method  name  like  scala  zipwithindex  kotlin  withindices  ruby  withindexoffset  0  python  enumeratesequence  start0  chose  withindex  eachwithindex  listcollectwithindex  missing  call  withindexcollect  send  pull  request  github,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5142,optimize  primitive  type  initialization  compilestatic  static  compiler  able  optimize  constant  initialization  case  example  code  double  x  25  code  static  compiler  creates  intermediate  bigdecimal  although  direct  constant  initialization  could  done,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5143,extend  builder  initializerstrategy  support  adding  annotation  constructor  added  ast  transformation  pojobuilder  creates  given  provided  pojo  builder  class  method  allow  set  value  pojo  together  build  method  allows  instantiate  example  pojo  person  code  class  person  string  firstname  string  surname  code  personbuilder  code  pojobuilderforclass  person  class  personbuilder  code  building  code  def  person  personbuilderwithfirstnamerobertwithsurnamelewandowskibuild  code  verification  code  assert  personfirstname  robert  assert  personsurname  lewandowski  code  also  added  building  validation  closure  code  try  def  person  personbuilderwithfirstnamerobertbuild  itsurname  null  throw  new  illegalstateexception  failshould  fail  due  validation  closure  catchexception  exception  code  possible  extension  pojos  class  right  object  constructed  picking  default  constructor  changed  picking  largest  constructor  basing  type  name  etc  create  proper  method  withcustomlogic  method  take  closure  argument  performs  custom  logic  object  built  immutablebuilder  method  creates  new  builder  instead  setting  value  pull  request  httpsgithubcomgroovygroovycorepull341,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5144,groovydocs  help  option  misleading  specify  help  option  groovydoc  noformat  groovydoc  help  noformat  sound  like  default  protected  public  field  method  included  documentation  noformat  protected  show  protectedpublic  class  member  default  noformat  true  generates  documentation  public  protected  package  class  member  package  option  noformat  package  show  packageprotectedpublic  class  member  noformat  kind  think  option  removed  statement  use  groovydoc  tool  document  default  behavior  noformat  usage  groovydoc  option  packagenames  sourcefiles  default  groovydoc  generates  documentation  publicprotectedpackage  class  member  noformat  another  issue  public  option  explicitly  state  generates  documentation  public  class  member  noformat  public  show  public  class  member  noformat  true  either  generates  documentation  public  package  class  member,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5145,optimize  foreach  style  loop  array  static  compiler  able  optimize  foreach  style  loop  collection  type  array  type  code  int  arr  forint  x  arr  code  currently  relies  iterator  making  much  slower  could,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5146,annotationcollector  could  provide  control  annotation  added  presence  existing  explicit  annotation  expanding  meta  annotation  alias  annotation  collection  sometimes  useful  able  control  annotation  added  particular  presence  existing  explicit  annotation  issue  proposes  adding  annotation  parameter  annotationcollection  let  addition  collected  annotation  controlled  flexible  way  following  mode  proposed  ac  code  duplicate  annotation  annotation  collection  always  inserted  transforms  run  error  multiple  annotation  excluding  source  retention  exist  prefercollector  annotation  collector  added  existing  annotation  name  removed  preferexplicit  annotation  collector  ignored  existing  annotation  name  found  prefercollectormerged  annotation  collector  added  existing  annotation  name  removed  new  parameter  found  within  existing  annotation  merged  added  annotation  preferexplicitmerged  annotation  collector  ignored  existing  annotation  name  found  new  parameter  collector  annotation  added  existing  annotation  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5147,tupleconstructor  allow  mechanism  switch  automatic  parameter  default  using  tupleconstructor  automatically  provides  default  parameter  particularly  useful  behavior  since  allows  parameter  remain  default  user  provided  null0false  left  constructor  particular  noarg  constructor  corresponds  case  argument  left  exactly  kind  constructor  groovy  need  default  namedargument  processing  said  time  required  single  simple  constructor  class  property  issue  allows  parameter  defaultsfalse  set  enable  new  behavior  class  code  tupleconstructor  class  person  string  first  last  int  age  code  following  normal  constructor  produced  code  personstring  firstnull  string  lastnull  int  age0  thisfirst  first  etc  code  groovys  compilation  phase  complete  following  constructor  visible  java  code  personstring  first  string  last  int  age  personstring  first  string  last  thisfirst  last  0  personstring  first  thisfirst  null  person  thisnull  code  adding  defaultsfalse  parameter  tupleconstructor  mean  first  produced  property  default  value  setting  made  false  error  flagged,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5148,groovyutilnodedepthfirst  provide  way  specify  preorder  postorder  ordering  please  provide  way  specify  ordering  depth  1st  traversal,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5149,invokerhelper  formatting  method  inconsistent  api  class  orgcodehausgroovyruntimeinvokerhelper  method  used  print  object  method  sometimes  maxsize  verbose  safe  argument  consistently  suggest  changing  private  api  method  collectionmap  type  api  functionality  see  httpsgithubcomapacheincubatorgroovypull96,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5150,objectrange  method  duplicate  functionality  rely  size  method  iterator  step  get  size  sublist  step  range  stepping  implementation  make  class  complex  need  also  get  sublist  iterator  rely  method  size  nonnumeric  case  bruteforce  iteration  element  cause  unnecessary  performance  overhead  several  case  even  value  size  cached  first  computation  overhead  may  arbitrarily  large  case  size  exceed  maxinteger  reliance  lead  error  also  see  groovy2972  groovy5426  suggest  unifying  stepping  semantics  relying  size  pr  follow,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5151,builder  option  include  superclass  property  one  annotates  groovy  class  builder  class  extends  another  class  generated  builder  support  setting  parent  class  property  especially  problematic  mixin  groovy  builder  java  code  eg  following  class  show  compile  codejava  animalgroovy  import  groovytransformbuilderbuilder  import  groovytransformbuildersimplestrategy  builderbuilderstrategy  simplestrategy  class  animal  string  color  int  leg  petgroovy  import  groovytransformbuilderbuilder  import  groovytransformbuildersimplestrategy  builderbuilderstrategy  simplestrategy  class  pet  extends  animal  string  name  pettestjava  import  orgjunittest  import  static  orgjunitassert  public  class  pettest  test  public  void  createpet  pet  pet  new  petsetcolorwhitesetlegs4setnamebobby  compile  pet  pet  pet  new  petsetnamebobbysetcolorwhitesetlegs4  asserttruepetgetlegs  4  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5152,add  support  iterable  closure  jsonbuilderstreamingjsonbuilder  jsonbuilder  streamingjsonbuilder  currently  support  passing  collection  closure  closure  applied  item  collection  improvement  would  support  general  iterable  type  see  httpsgithubcomapachegroovypull203,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5153,groovy  could  implement  autoimplement  transform  groovy  provides  numerous  facility  dynamically  creating  proxy  implementation  interface  eg  code  def  emptyiterator  hasnext  false  iterator  code  special  support  closure  map  closure  sam  method  coercion  various  proxy  generator  class  typically  dynamic  creation  exactly  required  eg  oneoff  usage  object  testing  stub  kind  time  compile  time  creation  class  would  useful  proposal  suggests  transform  reduce  boilerplate  code  number  common  scenario  code  created  proposal  numerous  configuration  option  doesnt  try  support  everything  dynamic  option  provide  eg  map  closure  supported  create  class  manually  case  transform  allows  example  follows  code  autoimplement  class  emptystringiterator  implement  iteratorstring  boolean  hasnext  false  code  provides  method  signature  string  next  implementation  return  default  value  return  type  null  string  alternatively  make  throw  exception  follows  code  autoimplementexceptionunsupportedoperationexception  class  emptystringiterator  implement  iteratorstring  boolean  hasnext  false  code  would  fact  closer  match  initial  dynamic  case  shown,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5154,missingmethodexception  limit  argument  type  getmessage  getmessage  method  missingmethodexception  us  invokerhelpertotypestringobject  argument  generate  type  argument  exception  occurs  large  parameter  list  create  large  string  format  method  used  2  line  later  print  value  us  40  character  limit  id  like  propose  use  similar  logic  type  well  trivial  code  snippet  groovysh  log  message  grow  unbounded  code  groovy000  missingtestgetbytes  error  groovylangmissingmethodexception  signature  method  groovyshevaluatemissing  applicable  argument  type  javalangbyte  javalangbyte  javalangbyte  javalangbyte  value  84  101  115  116  possible  solution  tostring  tostring  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5155,public  constructor  groovytransformimmutable  anotated  class  groovytransformimmutable  annotation  generates  public  constructor  annotated  class  want  able  create  class  constructor  another  modifier  e  g  private  constructor  define  static  method  createbuildfrom  way  create  immutable  class  pull  request  provided,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5156,groovy  templateservlet  npe  fixed  totally  revamped  hello  groovy  dev  team  revamped  version  templateservlet  class  didnt  produce  diff  use  another  code  formatter  groovy  project  team  must  sit  front  wide  screen  fix  change  improvement  fixed  npe  logcalls  calling  super  init  rewrote  template  source  file  finding  according  jspservlet  found  apachetomcat  added  setvariablesservletbinding  method  allowing  extension  bind  variable  implemented  simple  template  cache  using  weakhashmap  javadoced  lot  removed  15  syntax,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5157,make  junit34  groovyrunners  current  groovyshell  currently  reflective  method  detect  run  junit3  junit4  class  method  might  work  god  groovyrunner  class  could  added  runnerregistry  groovysystem  runner  able  registered  class  loading  like  thing  rather  grape  processing,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0
5158,add  suppressed  exception  withautocloseable  method  trywithresources  statement  multiple  exception  thrown  exception  closure  returned  exception  closing  added  suppressed  exception  currently  withcloseablewithautocloseable  method  return  closure  exception  log  warning  exception  thrown  call  close  improvement  exception  close  would  also  added  suppressed  exception  exception  thrown  closure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5159,groovystarterconf  could  extended  support  configscript  groovystarterconf  could  extended  support  statement  like  code  configscript  groovyhomeconfautofinalconfgroovy  configscript  userhomegroovyautoimportbuildergroovy  configscript  userhomegroovycompilestaticeverywheregroovy  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5160,defaultgroovymethods  missing  array  support  method  every  collect  support  instance  iterable  iterator  include  equivalent  method  support  array,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5161,immutable  annotation  revamped  metaannotation  0,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5162,support  native  lambda  static  compilation  mode  pr  httpsgithubcomapachegroovypull654,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5163,final  variable  analysis  doesnt  account  early  exit  trycatchfinally  example  early  return  method  code  def  methodstring  foo  final  str  try  str  footrim  catche  println  e  return  null  int  exitcode  strisinteger  strtointeger  null  exitcode  strisinteger  strtointeger  null  doesnt  trigger  error  println  methodnull  code  slight  rearrangement  code  def  methodstring  foo  final  str  try  return  footrim  catche  str  1  int  exitcode  strtointeger  variable  str  may  uninitialized  exitcode  println  methodnull  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5164,immutablerelated  transformation  configurable  would  allow  immutability  library  leveraged  eg  guava  immutable  collection  proposal  provide  property  handler  class  control  generated  code  getting  setting  initializing  property  see  preliminary  documentation  propertyoptions  detail,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5165,dgmintersect  provide  variant  comparator  performance  penalty  using  numberawarecomparator  feature  required,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5166,migrate  groovyc  picocli  migrate  orgcodehausgroovyantgroovyc  commonscli  picocli,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5167,migrate  groovyuigroovymain  picocli  migrate  groovyuigroovymain  commonscli  picocli,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5168,sqlgroovymethods  could  moved  avoid  split  package  part  1  intended  two  step  process  1  move  new  package  leave  behind  deprecated  delegating  skeleton  file  old  location  2  remove  deprecated  file  future  release,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
5169,annotate  generated  method  generated  generated  annotation  added  couple  release  ago  indicate  methodclass  generated  compiler  likely  via  ast  transformation  annotation  already  applied  method  defined  groovyobject  however  yet  applied  many  generated  method  added  core  ast  transformation  see  following  link  context  httpsgithubcomapachegroovypull617issuecomment336249772  httpsgithubcomjacocojacocopull733,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5170,implement  listputatrange  work  like  listputatsplice  list  012345  assert  list01  list00  assert  list23  list25  list25  x  assert  list  01x  list22  2345  assert  list  012345,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5171,remove  propertyvalue  objectallproperties  eachproperty  refactor  method  use  map  objectallproperties  eachpropertypv  deal  propertyvalue  object  merely  encapsulate  namevalue  pair  consistent  map  general  handling  keyvalue  pair  throughout  gdk  namevalue  pv  v  keyvalue  map  b  eachproperty  doesnt  allow  keyvalue  like  map  reason  calling  allproperties  instead  get  let  return  map  instead  list  propertyvalue  object  even  remove  eachproperty  eachpropertyname  objpropertieseach  job  opinion  sound  like  wise  consistent  change  go  guillaume  laforge,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
5172,provide  size  stringbuilder  groovy920  resulted  size  implemented  stringbuffer  size  also  implemented  stringbuilder  jdk15  platform,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0
5173,entitylinking  sort  suggestion  score  based  entity  ranking  vocabulary  entitylinkingengine  link  define  entityranking  entity  ranking  defines  popularity  similar  pagerank  entity  within  knowledge  base  wikipedia  eg  generated  number  incoming  link  wikipedia  page  entityranking  defined  internal  api  entitylinkingengine  currently  used  score  linked  entity  mainly  score  represent  well  label  entity  match  section  processed  text  introduce  new  option  allows  suggestion  would  score  typically  10  exact  match  get  score  slightly  le  01  changed  ranked  based  entity  ranking  linking  wikipedia  ensure  paris  france  slightly  higher  ranking  paris  texas  u  change  must  change  order  suggestion  entity  score  user  able  enabledisable  feature  via  setting  entity  linking  configuration  default  feature  activated,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5174,slim  common  issue  follows  mailing  list  discussion  httpmailarchivesapacheorgmodmboxstanboldev201305mbox3ccaa7lao2kuanr4wqqbdsvjpy5rpqtqkk2sv8svrerbciwqoajqmailgmailcom3e  umbrella  creating  new  slimmer  commonslibrary  make  stanbol  module  portable  foster  restfull  ap,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5175,improvement  entitylinking  issue  cover  several  improvement  entitylinking  engine  general  goal  improvement  reduce  number  lookup  vocabulary  consume  90  processing  time  reduce  number  result  need  processed  without  loosing  recall  skipping  possible  match  eg  using  better  ranking  fix  issue  require,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5176,implement  lucene  fst  based  entity  linking  engine  based  opensextant  solrtexttagger  implement  inmemory  entitylinking  enhancementengine  based  lucenes  fst  finite  state  transducer  technology  engine  could  make  direct  use  class  contained  opensextant  solrtexttagger  code  1  us  two  layered  fst  1  represent  word  2  map  word  phrase  possible  efficiently  hold  big  vocabulary  memory  300mbyte  geonamesorg  see  presentation  2  detail  license  fully  compatible  asl  20  library  currently  available  maven  central  need  contact  author  regarding  1  httpsgithubcomopensextantsolrtexttagger  2  httpwwwlucenerevolutionorg2013texttaggingwithfinitestatetransducers,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
5177,add  coreference  resolution  dependency  tree  support  stanbol  nlp  processing  api  extend  stanbol  nlp  processing  api  annotation  coreference  resolution  dependency  tree  also  add  support  json  serialisationparsing  coreference  dependency  tree  annotation  restful  nlp  analysis  service  provide  coreference  information,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5178,kres  component  manage  store  individually  kres  adapter  managing  interaction  ontology  store  eg  clerezza  tcmanager  jena  tdb  inmemory  iks  persistence  store  euiksprojectkresstorage  euiksprojectkresstorageprovider  old  setting  orgapachestanbolontologymanagerstore  stanbol  component  removed  clerezza  storage  tcmanager  weightedtcprovider  directly  interacted  component  ontologymanager  reengineer  rule  independently,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
5179,update  commonssolr  solr  44  initial  check  showed  update  come  api  change  solr  affect  several  component  currently  aware  solrcore  osgisolrcore  osgiresourceloader  lucene  based  nlp  component  api  creating  analyzer  instance  changed  topicengine  need  adapt  unit  test  use  new  api  create  corecontainer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5180,add  lookup  cache  entitylinking  engine  entitylinkingengine  cache  result  lookup  entitysearchers  entity  often  reoccurring  analyzed  document  caching  result  look  upped  token  provide  considerable  performance  improvement  tatistics  show  90  processing  time  entitylinking  engine  contributed  entity  lookup  20  entity  mention  reoccurring  entity  processing  time  reduced  18  cache  use  list  search  string  key  list  returned  entity  value  cache  collect  lookup  result  currently  analyzed  document  entitylinking  statistic  updated  include  cache  hit  percentage  issue  affect  trunk  100snapshot  well  stable  012  releasing  branch,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5181,make  entityhub  serializer  extendable  serialization  entityhub  model  implemented  jaxrs  messagebodywriter  model  class  serialized  include  representation  entity  queryresultlist  entity  constructed  two  representation  data  metadata  queryresultlists  include  string  id  representation  entity  currently  two  implementation  model  serializer  1  implementation  entityhub  specific  json  format  2  implementation  based  clerezza  support  various  rdf  format  implementation  registered  jaxrs  via  supported  interface  supported  medium  type  stanbol1165  support  sesame  added  stanbol  entityhub  serialization  sesame  backed  representation  rdf  based  medium  format  still  done  clerezza  serializers  extremely  inefficient  1  sesame  model  need  converted  clerezza  backed  model  requiring  copy  data  field  field  2  clerezza  internally  use  jena  serializer  via  clerzzajena  adapter  avoid  entityhub  requires  extendable  serializer  framework  allows  register  modelwriter  specific  entityhub  model  implementation  sesame  done  within  stanbol1234  messagebodywirter  extension  point  provided  jaxrs  used  native  implementation  entity  queryresultlist  also  use  generic  type  option  entity  interface  use  issue  introduce  new  extension  point  called  modelwriter  implemented  module  need  provide  native  serialization  support  representation  implementation  modelwriter  registered  osgi  service  modelwriterregistry  responsible  tracking  three  messagebodywriter  implementation  representation  entity  queryresultlist  use  registry  forward  call  jaxrs  best  fitting  modelwriter  service  addition  provide  two  modelwriter  implementation  1  applicationjson  specific  native  type  2  various  rdf  format  native  support  clerezza  model  implementation  stanbol1234  provide  third  implementation  modelwriter  sesame  model  implementation,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
5182,add  fallbackmode  uri  pattern  uri  prefix  support  dereferenceengine  generic  implementation  dereferenceengine  extended  following  option  1  fallbackmode  enabled  dereference  entity  already  triple  present  enhancement  structure  2  uri  prefix  allows  configure  prefix  uris  dereferenced  3  uri  pattern  allows  configure  regex  pattern  uris  dereferenced  entity  scheduled  dereferenceing  fallbackmode  triple  available  prefixesisempty  patternsisempty  entity  uri  match  prefix  pattern  allows  multiple  engine  instance  different  field  ldpath  configuration  different  data  set  eg  geonames  dbpedia  skos  also  allows  avoid  necessary  call  dereferencer  might  need  much  time  check  dereference  entity  default  fallback  mode  enabled  prefix  pattern  empty,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5183,fst  linking  engine  linkable  token  filter  consider  chunk  linkabletokenfilter  solr  tokenfilter  used  fst  linking  engine  add  taggingattribute  supported  solr  text  tagger  library  token  looked  fst  vocabulary  implementation  improved  taking  chunk  consideration  chunk  representing  named  entity  processable  typically  noun  phrase  verb  phrase  linkable  token  chunk  two  matchable  token  chunk  token  chunk  classified  tagable  setting  taggingattribute  true,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5184,upgrade  opennlp  15  opennlp  15  release  make  easier  train  new  custom  model,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5185,add  support  custom  entity  reference  dereference  engine  currently  entitydereferenceengine  support  fiseentityreference  allow  user  parse  list  property  reference  entity  configuration  enhancerenginesdereferencereferences  property  used  supported  value  string  single  value  string  collectionstring  qname  configuration  nslocalname  supported  namespaceprefixservice  present  configuration  present  fiseentityreference  assumed  default  entitydereferencer  implementation  need  addapted  extension,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5186,allow  enhancementengines  get  chain  scoped  enhancement  property  currently  enhancementengines  retrieve  merged  view  enhancement  property  defined  stanbol488  includes  chain  scoped  property  defined  enhancement  chain  configuration  well  request  scoped  property  defined  single  enhancement  request  required  implementing  enhancementengines  want  react  property  provided  chain  configuration  want  allow  overriding  enhancement  request  eg  configuration  external  service  endpoint  userpwd  external  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5187,enhancer  benchmark  tool  im  working  benchmark  tool  stanbol  enhancer  content  fed  enhancer  output  checked  according  set  expectation  here  example  benchmark  syntax  might  evolve  implement  explains  general  idea  run  benchmark  well  post  plain  text  document  containing  one  several  benchmark  get  html  document  back  result  input  bob  marley  born  kingston  jamaica  expect  comment  one  ignored  expect  defines  group  predicateobject  matcher  expect  find  output  group  applies  one  given  enhancement  expectation  succeed  least  one  enhancement  must  match  line  group  httpfiseiksprojecteuontologyentityreference  uri  httpdbpediaorgresourcekingston2cjamaica  httppurlorgdctermscreator  string  orgapachereferencedsiteentitytaggingenhancementengine  group  separated  empty  line  here  new  one  httpfiseiksprojecteuontologyentitytype  uri  httpdbpediaorgontologymusicalartist  httpfiseiksprojecteuontologyentityreference  uri  httpdbpediaorgresourcebobmarley  httppurlorgdctermscreator  regexp  orgapacheentitymentionenhancementengine  complain  complain  statement  similar  expect  expect  fulfilled  enhancer  output,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5188,add  nif  20  support  nlp2rdf  engine  nlp2rdf  engine  based  nif  10  string  ontology  add  2nd  engine  module  output  nlp  result  analysedtext  content  part  following  nif  20  specification  1  especially  nifcore  ontology  2  1  httppersistenceunileipzigorgnlp2rdf  2  httppersistenceunileipzigorgnlp2rdfontologiesnifcorenifcorehtml,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5189,improve  fst  corpus  handling  update  lucene  fst  linking  engine  manages  fst  corpus  need  rebuild  solr  core  update  every  fst  corpus  know  solr  version  built  currently  checked  every  call  lucene  fst  linking  engine  version  fst  corpus  still  sync  version  solrcore  recreation  fst  corpus  enqueued  however  conpletion  task  enhancement  request  processed  using  older  version  fst  corpus  initial  idea  prevent  long  wait  huge  index  eg  dbpedia  creation  fst  corpara  take  minute  reality  fst  corpus  typically  built  second  mean  case  would  better  wait  recreation  corpus  rather  using  outdated  version  issue  change  fst  corpus  management  use  future  component  wait  corpus  created  code  also  use  reasonable  wait  time  corpus  built,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5190,extract  stateful  enhancer  http  endpoint  independant  bundle  named  contenthub  enhancerjersey  bundle  provides  engine  endpoint  another  endpoint  currently  named  store  allows  browse  recently  enhanced  content  item  posting  new  content  analyze  store  extracted  dedicated  bundle  renamed  contenthub  emphasize  focused  around  content  item  listing  furthermore  later  extended  implement  faceted  semantic  search  using  solr  extraction  osgified  solr  component  developed  initially  entityhub,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5191,referencedsites  entityhub  need  provide  metadata  configuration  restful  api  currently  url  service  available  referencedsites  need  extended  following  parameter  id  name  description  optional  offlineonline  mode  side  us  local  cache  depends  remote  service  license  license  used  provided  data  attribution  parameter  also  java  api  need  extended,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5192,rule  management  must  support  offline  mode  ontologymanagerontonet  rule  component  provide  heuristic  loading  recipe  networked  ontology  offline  resource  possibly  hijacking  dependency  resolve  locally  recursively,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1
5193,jenabased  reasoner  add  jena  rule  based  reasoner  new  separate  inference  module  inside  reasoner  package  implement  reasoner  owlapi  interface  adapt  jena  rule  based  inference  engine  owl  lite  profile  remove  hermit  fro  within  reasoner  module,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5194,extendable  indexing  infrastructure  entityhub  currently  entityhub  includes  utility  create  index  dbpedia  geonames  dblp  exists  also  generic  rdf  indexer  used  dbpedia  dblp  however  also  implementation  extendable  really  suitable  add  feature  requested  issue  like  stanbol92  stanbol93  stanbol163  goal  create  infrastructure  provides  implementation  indexing  workflow  configuration  initialization  defines  interface  allows  plug  different  data  source  entity  ranking  implementation  entity  data  mapper  eg  filtering  field  schema  translation  indexing  target  yard  store  indexed  entity  existing  indexing  utility  need  moved  use  new  infrastructure,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,0,1
5195,migration  cmsadapter  component  cmsadapter  component  previously  known  ontology  generator  migrated  stanbol  mainly  aim  generate  ontology  using  bridge  definition  content  management  system  ontology  generated  eg  create  individual  using  node  hierarchy  cm  time  support  cm  implementing  jcr  interface  graphical  user  interface  migrated  license  issue  two  simple  restful  resource  one  provides  submission  bridge  definition  one  provides  submission  updated  item  cm  reflect  change  ontology  component  located  trunkcmsadapter  decided  telco  april  20  next  task  enrich  restful  service  adapt  cmis  bundle  previously  implemented,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0
5196,integration  test  framework  create  framework  running  test  build  time  starting  runnable  jar  testing  via  http,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5197,processor  become  osgi  component  bridge  processor  become  osgi  component  implement  processor  interface  way  possible  plug  processor  implementation  based  specific  need,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5198,add  support  named  solr  configuration  solryard  already  support  initialise  solr  core  based  default  configuration  default  configuration  currently  loaded  solrcore  solryard  bundle  idea  extend  allowing  load  named  solr  configuration  goal  use  stanbol  datafileprovider  service  similar  opennlpner  engine  also  support  load  language  specific  configuration  via  classpath  required  file  present  datafile  directory  used  path  load  configuration  via  classpath  solrcorename  current  default  config  located  configsolrcoredefault  within  solryard  bundle  generally  useful  configuration  index  storage  value  entitytagging  configuration  similar  index  currently  used  autotagger  engine  also  included  within  stanbol  distribution,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5199,update  jsonld  implementation  specification  version  20110911  current  jsonld  implementation  based  version  20110201  implementation  updated  support  newer  specification  version  20110911  20110911  version  online  httpjsonldorgspeced20110911,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5200,implement  factstore  implement  factstore  according  specification  httpwikiiksprojecteuindexphpfactstorespecification  would  help  make  stanbol  easy  use  storing  relation  entity,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5201,refactor  solr  specific  utilits  solryard  bundle  currently  solr  specific  utility  managing  internal  embeddedsolrserver  loading  solrindex  via  datafileprovider  infrastructure  initializing  solrcore  based  configuration  managed  slinginstaller  infrastructure  functionality  also  relevant  future  component  stanbol  contenthub  mentioned  functionality  become  core  new  bundle  orgapachestanbolcommonssolr  bundle  also  export  solrj  package  therefore  ease  use  solr  stanbol  package  development  extension  new  bundle  covered  additional  jira  issue,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
5202,add  support  selective  ontology  library  lazy  loading  supplied  ontology  registry  ontonet  currently  load  ontology  library  referenced  registry  overkill  user  want  manage  single  library  load  scope  registry  management  configurable  support  laziness  actual  ontology  resource  loaded  corresponding  model  touched  eg  request  made  owl  ontology  contained  library  add  possibility  provide  id  library  load  avoid  loading  library  java  rest  api,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5203,make  root  ontology  management  implicit  ontology  space  root  ontology  ontology  space  eg  scopeidcorerootowl  scopeidcustomrootowl  managed  actual  owlontology  object  like  actual  ontology  loaded  scope  however  bring  benefit  creates  clutter  managing  import  statement  serialization  ontology  scope  space  restful  service  root  ontology  generated  onthefly  get  service  scope  space  import  statement  swiftly  moved  across  space  without  worrying  reloading  whole  import  closure  also  since  map  actual  file  remove  owl  extension  reserved  included  ontology  consequence  ontologyspacesettopontology  method  would  longer  make  sense  deprecated  api  removed  altogether  contrary  gettopontology  could  still  used  dynamically  generate  root  ontology  existing  resource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5204,ontonet  manage  graph  clerezza  natively  ontonet  managing  scope  space  session  far  creating  owl  api  object  live  throughout  whole  stanbol  lifecycle  serialized  web  service  current  implementation  creates  owl  ontology  object  persist  memory  even  used  advantage  provide  axiomoriented  view  rdf  graph  useful  application  user  dig  owl2  however  also  inefficient  number  reason  memory  occupation  data  essentially  replicate  content  persistence  layer  slick  reaction  change  lowlevel  graph  imported  ontology  updated  new  import  added  preexisting  axiom  reinterpreted  eg  classification  reasoning  task  generally  doesnt  happen  unless  ontology  serialized  reloaded  owl  api  ontology  manager  non  owlaware  application  use  ontonet  java  api  forced  handle  owl  need  access  rdf  graph  ideal  solution  would  avoid  loading  ontology  owlontologymanager  object  ontology  scope  session  set  ontology  network  information  could  stored  clerezza  tcmanager  like  every  rdf  graph  content  scope  requested  owl  ontology  brought  way  garbagecollected,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0
5205,clerezza  converter  handle  triplecollection  instead  mgraph  owl  transformation  apis  owlapitoclerezzaconverter  transform  mgraph  object  unnecessary  need  modify  graph  internally  developer  might  obtain  mgraph  object  sake  passing  api  replacing  mgraph  triplecollection  accommodate  graph  mgraph  alike  make  transformation  api  versatile,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5206,long  term  operation  job  reasoning  service  current  implementation  reasoning  service  execute  operation  real  time  reasoning  task  often  time  consuming  case  cannot  completed  lifetime  http  request  reason  need  way  running  reasoning  operation  background  web  service  ping  running  operation  retrieve  result  ready,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5207,make  solrcores  corecontainer  available  osgi  service  provide  solrcores  corecontainer  also  osgi  service  component  depend  service  implemented  efficiently  main  advantage  approach  would  ability  react  change  solrcores  eg  index  updated  new  data  addition  feature  also  required  implementation  stanbol353,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
5208,removing  enhancement  listener  contenthub  contenthub  keeping  graph  enhancement  registering  listener  corresponding  graph  tcmanager  instead  listener  enhancement  retrieved  upon  submission  content  item  global  enhancement  graph  managed  without  listener  improvement  also  brings  additional  feature  removal  content  item  also  remove  enhancement  global  enhancement  graph  change  edit  functionality  content  item  reflected  solr  backend  global  enhancement  graph  addition  removal  enhancementlistener  presentation  recently  submitted  document  processed  solr  instead  global  enhancement  graph  would  decrease  dependency  system  enhancement  graph  document  submitted  enhancement  also  presented  recently  submitted  document  solr  provides  efficient  pageoffset  mechanism  support  feature,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
5209,adding  new  feature  cm  adapter  able  submit  content  repository  object  contenthub  feature  possible  submit  content  repository  object  contenthub  based  content  repository  id  path  first  step  based  requirement  selection  object  may  improved  also  possible  delete  content  item  contenthub  property  object  eg  jcrtitle  cmiscreatedby  indexed  metadata  content  item  contenthub  thanks  external  metadata  content  item  faceted  search  possible  document  submitted  contenthub,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
5210,rename  rick  java  package  new  name  discussed  mailing  list  orgapachestanbolentityhub,0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,0,1
5211,rename  kres  java  package  new  name  orgapachestanbolreasoning  orgapachestanbolreasoner  dont  remember  decided  cannot  find  email  please  comment,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0
5212,rename  fise  java  package  fise  package  splitted  new  top  level  package  orgapachestanbol  namespace  orgapachestanbolcommon  common  utility  orgapachestanbolstore  store  api  blend  clerezza  triple  store  content  item  binary  attachements  orgapachestanbolanalysis  engine  related  compenent  orgapachestanbolweb  default  web  interface  rest  api  need  make  pluggable  orgapachestanbolontology  common  utility  kres  initial  persistencestore  handle  registered  ontology  definition  managed  web  interface  used  orgapachestanbolreasoning  packaged  utility  sling  based  launcher  extracted  toplevel  maven  artifact,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,1
5213,refactor  enhancementengine  support  content  multiple  related  part  note  discussion  rupert  olivier  contentitem  getblob  return  blob  type  multipartmime  iff  contentitem  created  multipartmime  content  cigetblob  eq  cigetpart0  blobclass  cigeturimain  eq  cigetparturi0  rest  enhancer  enhancerengineengineid  enhancerchainschaiid  query  params  optional  inputwithmetadata  expects  multipartmime  2  section  first  rdf  optional  outputwithcontentpartssectionordinal  result  multipart  instead  rdf  containing  rdf  first  section  part  second  section  one  part  second  section  multipart  argument  might  repated  different  section  optional  omitmetada  metadate  result  make  sense  outputcontentparts  argument  result  correspond  second  section  malipart  returned  without  argument,1,0,1,0,1,0,0,0,1,0,1,1,1,0,0,0,0
5214,improve  enhancer  rest  endpoint  stanbol414  reto  rest  enhancer  enhancerengineengineid  enhancerchainschainid  query  params  optional  inputwithmetadata  expects  multipartmime  2  section  first  rdf  optional  outputwithcontentpartssectionordinal  result  multipart  instead  rdf  containing  rdf  first  section  part  second  section  one  part  second  section  multipart  argument  might  repated  different  section  optional  omitmetada  metadate  result  make  sense  outputcontentparts  argument  result  correspond  second  section  malipart  returned  without  argument,1,1,1,0,1,1,0,0,0,1,1,1,1,0,0,0,0
5215,add  session  management  using  new  session  operation  currently  operation  cm  adapter  new  session  obtained  provided  connection  parameter  instead  newly  created  session  would  cached  used  later  furthermore  already  available  session  used  would  make  osgi  based  integration  easier  slingstanbol  case  using  rest  service  first  session  would  created  cached  session  used  subsequent  operation  session  key  corresponding  cached  session,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
5216,enabling  scr  factory  configuration  multiple  refactor  engine  component  via  felix  console  order  multiple  refactor  engine  component  active  enhancement  one  mapping  recipe  would  appropriate  enable  scr  factory  refactor  engine  configuration  component  via  felix  console,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5217,ldpath  integration  contenthub  ldpath  integrated  module  contenthub  operate  ldpath  program,1,1,1,1,1,0,0,0,1,0,1,0,0,0,0,1,0
5218,change  metaxa  engine  create  plaintext  version  contentpart  change  engine  retrieve  plaintext  version  contentpart  instead  addingreading  textplain  version  contentitem  tofrom  metadata  contentitem  new  contentpart  api  used  require  metaxa  engine  store  literal  value  triple  contentitemgeturi  subject  httpwwwsemanticdesktoporgontologies20070119nieplaintextcontent  property  blob  add  contentpart  contentitem  enhancementengines  need  search  blob  mimetype  textplain  instead  retrieving  plain  text  metadata,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
5219,web  ui  ldpath  integration  contenthub  web  user  interface  submitdelete  ldpath  program  needed  contenthub  store  search  service  html  page  aligned  ldpath  program  name  selection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
5220,store  ontologyiri  graphname  mapping  persistently  ontonet  clerezzaontologyprovider  includes  hashmap  map  ontology  iris  physical  logical  eg  id  owlontology  resource  clerezza  graph  name  uriref  backed  storage  mapping  lost  ontonet  stanbol  reactivated  see  mapping  preserved  across  stanbol  running  instance,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
5221,support  owl  2  versioniri  ontologyiriversioniri  combination  owl  ontology  powerful  tool  determine  ontology  shared  across  multiple  scope  session  version  used  time  time  matter  fact  setting  versioniri  way  claim  ownership  particular  instance  ontology  example  ontology  space  set  id  version  iri  ontology  versioniri  also  used  determine  ontology  outlive  owner,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,1,1
5222,allow  usage  similarityconstraints  via  restful  api  entityhub  currently  similarityconstraints  introduced  stanbol202  supported  restful  api  allow  parserwriter  constraint  must  added  fieldquery  readerwriter  part  entityhub  jersey  module,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
5223,google  refine  reconciliation  service  support  add  support  reconciliation  service  api  stanbol  entityhub  restful  api  google  refine  reconciliationserviceapi  allows  reconcile  string  value  entity  documentation  service  found  1  entityhub  well  suited  implementing  service  execute  query  efficiently  based  solryard  implementation  1  httpcodegooglecompgooglerefinewikireconciliationserviceapi,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5224,add  stress  test  utility  integration  test  test  intended  test  stanbol  enhancer  enhancement  engine  multiple  concurrent  request  used  normal  integration  testing  also  useable  stanbol  user  test  server  specific  data,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5225,allow  load  kind  opennlp  model  opennlp  service  currently  opennlp  service  provides  method  load  model  following  default  naming  convention  opennlp  eg  getsentencemodelstring  langauge  would  try  load  model  name  languagesentbin  suggests  add  additional  method  allows  load  type  model  file  available  via  datafileprovider  framework  getmodelclasst  modeltype  string  modelname  mapstringstring  property,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5226,stanbol  nlp  processing  issue  cover  nlp  processing  component  discussed  httpmarkmailorgmessageqxusiup3mim2lhpx  goal  1  provide  modular  infrastructure  nlprelated  thing  many  task  nlp  computationally  intensive  one  fit  nlp  approach  analysing  text  therefore  wanted  nlp  infrastructure  configured  wired  together  needed  specific  use  case  several  specialised  module  build  upon  many  optional  2  provide  unified  data  model  representing  nlp  text  annotation  many  szenarios  necessary  implement  custom  engine  building  result  previous  generic  analysis  text  eg  po  tagging  chunking  example  project  identifying  socalled  noun  phrase  use  lemmatizer  build  ground  form  convert  singular  nominative  form  gramatically  correct  label  use  tag  cloud  build  generic  nlp  functionality  last  step  specific  use  case  therefore  wanted  also  implement  generic  nlp  data  model  allows  representing  text  annotation  attached  individual  word  also  span  word,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5227,get  rid  usage  comsunjerseyapiviewviewable  longer  use  comsunjerseyapiviewviewable  mainly  two  reason  comsunjerseyapiviewviewable  provided  jersey  server  package  part  jaxrs  standard  tha  main  advantage  adhering  standard  portability  lost  implementation  specific  class  used  business  jaxrs  resource  class  care  presenation  resource  method  return  object  rendered  many  format  using  messagebodywriters,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
5228,sentiment  summarization  enhancementengine  enhancementengine  consumes  word  level  sentiment  annotation  sum  noun  phrase  sentence  whole  document  note  enhancementengine  expected  create  enhancement  need  define  sentimentannotation  represented  using  stanbol  enhancement  structure  engine  also  support  detection  negation  eg  nice  trip  weather  bad  forecast  suggested,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5229,extract  jersey  specific  part  webcore  webcorejersey  project  jersey  specific  implementation  moved  webcore  webfragment  used  without  jersey  dependency  alternative  implementation  become  possible,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0
5230,porting  geonamesorg  indexer  entityhub  indexing  tool  geonamesorg  indexer  ported  entityhub  indexing  tool  part  stanbol187  issue  cover  exactly  task  feature  current  version  changed  follows  reading  main  geonames  data  geonamesindexingsource  implementing  entitydataiterable  interface  providing  hierarchy  information  converted  entityprocessor  providing  alternate  label  converted  entityprocessor  storage  solrcore  removed  covered  solryard  indexing  destination  mapping  geonamesorg  property  ontology  removed  covered  fieldmapping  processor  andor  ldpath  processor  oasentityhubindexinggeonames  module  provide  standalone  jar  come  default  configuration  entityhubindexingtool  suitable  indexing  geonamesorg,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
5231,improve  parameter  response  type  parameter  validation  rest  service  contenthub  parameter  validation  restful  sevices  contenthub  effective  existence  check  mandatory  parameter  done  accordingly  service  also  return  correct  status  code  furthermore  type  parameter  eg  formparam  queryparam  etc  service  consistent  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5232,implement  lucene  tokenizer  based  labeltokenizer  lucene  support  tokenizers  lot  language  opennlp  whitespace  character  based  tokenizers  fine  language  allows  user  use  special  one  eg  chinese  smartcn  analyzer  package,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
5233,move  kresformat  class  jersey  euiksprojectkresapifomatkresformat  class  us  javaxwsrscoremediatype  hence  implying  jersey  dependency  api  module  would  otherwise  needed  class  best  moved  kres  jersey  bundle  one  using  euiksprojectkresapi  pom  refactored  accordingly  include  dependency,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5234,move  bundletemplateloader  bundle  bundletemplateloader  relates  freemarker  independent  viewablearchitecture  go  bundle  providing  support  utility  using  freemarke  osgi  environment,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5235,make  possible  define  expansion  rdfviewable  resource  method  according  httpssvnapacheorgviewvcstanboltrunkcommonswebrdfviewablewritersrcmainjavaorgapachestanbolcommonswebviewableldpathwriterimplrdfserializingwriterjavaviewmarkuppathrev1447265  expansion  widened  using  query  parameter  xpropobj  xprosubj  would  nice  could  specify  bit  fine  grained  server  side  get  templatepath  used  html  export  influence  result  value  look  like  would  like  similar  functionality  rdf  representation  something  similar  framework  interfacing  rdf  based  data  use  called  recipe  define  rdfproperties  im  interested  current  vocab  found  httpvocabnetlabsorgrecipe,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5236,improve  header  mediator  addremove  transport  header  currently  header  mediator  used  set  remove  header  current  soap  infoset  header  mediator  improved  set  remove  header  transport  well  though  achieved  also  property  mediator  using  header  mediator  make  configuration  readable  clearer  syntax  noformat  header  nameqname  valueliteral  expressionxpath  actionset  scopedefaulttransport  noformat  example  noformat  header  nameaccept  valuetexthtml  scopetransport  noformat  please  note  affect  already  existing  configuration  nulldefault  scope  still  mean  altering  soap  header,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5237,update  synapse  axis2  13  final  release  hi  folk  please  see  enclosed  patch  update  synapse  latest  axis2  13  final  release  one  test  failure  added  exclude  modulescorepomxml  thanks  dims,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5238,able  define  seperate  policy  incoming  outgoing  message  able  specify  different  policy  incoming  outgoing  message  proxy  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5239,possible  reuse  jms  connection  information  axis2xml  jmssender  specifying  jms  eprs  jmssender  support  definition  connection  factory  entry  follows  transportsender  namejms  classorgapachesynapsetransportjmsjmssender  parameter  namemyqueueconnectionfactory  parameter  namejavanamingfactoryinitialcomswiftmqjndiinitialcontextfactoryimplparameter  parameter  namejavanamingproviderurlsmqp1025513818000typecomswiftmqnetjssesocketfactorytimeout10000parameter  parameter  nametransportjmsconnectionfactoryjndinamequeueconnectionfactoryparameter  parameter  namejavanamingsecurityprincipalxxxadapterparameter  parameter  namejavanamingsecuritycredentialsxxxadapterparameter  parameter  transportsender  thus  possible  refer  information  specifying  jms  epr  synendpoint  namemyjmsendpoint  synaddress  urijmsqueuenamesomewheretransportjmsconnectionfactorymyqueueconnectionfactory  synendpoint  instead  specifying  ic  class  url  username  password  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5240,allow  xpath  expression  specified  relative  envelope  body  via  attribute  would  make  xpath  expression  simpler  without  consideration  soap  11  12  rest  etc  default  could  envelope  ie  backward  compatibility  optional  attribute  could  specify  relative  body,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5241,add  ability  configure  fault  detial  dynamically  makefault  mediator  add  ability  configure  fault  detial  dynamically  makefault  mediator,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5242,remove  duplicate  code  axis2flexiblemepclient  messagehelper  moment  removeaddressingheaders  method  orgapachesynapseutilmessagehelper237  duplicate  code  removeaddressingheaders  method  orgapachesynapsecoreaxis2axis2flexiblemepclient532  sould  merged  method  detachaddressinginformation  also  behavior  messagehelper  axis2flexiblemepclient  duplicate  code  removed  merged  single  method,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5243,dynamic  load  balancing  limitation  current  load  balancer  implementation  eg  2  identical  service  2  different  worker  node  fronted  synapse  load  balancer  instance  case  need  provide  4  endpoint  synapsexml  file  seen  scalable  solution  hence  implemented  dynamic  load  balancing  mechanism  application  member  discovered  runtime  endpoint  need  statically  specified  synapsexml  file  currently  application  endpoint  calculated  replacing  ip  port  incoming  request  member  request  forwarded  tested  http  moment  detail  concept  design  found  httpafkhamorg200806faultresilientdynamicloadbalancinghtml,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5244,static  load  balancing  across  static  group  current  load  balance  endpoint  implementation  need  provide  endpoint  service  able  simply  provide  information  application  group  member  load  balance  across  group,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5245,simplify  way  logging  done  mediator  mediator  log  message  three  different  log  usual  log  category  set  class  name  trace  log  service  log  extremely  useful  preserved  way  mediator  coded  leverage  logging  facility  could  improved  indeed  following  problem  current  situation  identified  code  using  logging  method  defined  abstractmediator  cant  reused  anything  else  mediator  random  example  springmediatorbuildappcontext  method  code  method  quite  easily  reused  another  mediator  provided  mediator  common  base  class  eg  startup  implementation  reason  us  traceordebug  method  abstractmediator  general  code  mediator  split  several  method  reusing  method  several  mediator  required  pas  traceordebugon  traceon  one  method  quite  annoying  someone  start  writing  new  mediator  obvious  correctly  use  various  logging  method  addition  current  implementation  doesnt  enforce  consistent  use  logging  facility  one  reason  log  trace  attribute  abstractmediator  accessible  subclass  eg  mediator  simply  call  logerror  thereby  bypassing  trace  service  log  improve  situation  proposal  1  introduce  interface  called  synapselog  set  logging  method  error  info  traceordebug  auditwarn  etc  mainly  equivalent  defined  abstractmediator  set  corresponding  isxxxenabled  method  following  pattern  commonslogging  2  add  getlogmessagecontext  method  abstractmediator  return  appropriate  implementation  synapselog  interface  mediator  implementation  would  call  method  beginning  mediate  method  exclusively  rely  returned  object  send  message  log  code  mediator  split  several  method  share  common  method  another  mediator  object  would  passed  argument  method  instead  traceordebugon  traceon  3  create  synapselogadapter  class  implement  synapselog  delegate  call  single  orgapachecommonslogginglog  instance  instance  class  would  used  code  executed  outside  mediator  need  call  method  shared  mediator  implementation  summarize  general  idea  expose  set  synapse  specific  logging  category  well  defined  interface  completely  hide  underlying  implementation  behind  interface  note  proposal  implemented  without  breaking  existing  code  coexist  existing  logging  method  abstractmediator  would  later  tagged  deprecated  potentially  removed  future  version  synapse,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5246,securing  password  datasource  definition  currently  password  datasource  definition  clear  text  format  synapseproperties  encrypted,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0
5247,improve  mediatordeployer  support  startup  embedded  jar  mediatordeployer  could  improved  support  1  embedded  jar  lib  folder  inside  archive  way  axis2  service  module  archive  would  allow  bundle  extension  mediator  together  dependency  jar  2  startup  deployer  discover  register  startupfactory  implementation  way  mediatorfactory  implementation  startup  good  candidate  hot  deployment  would  still  useful  conjunction  first  improvement  note  1  implemented  would  useful  define  standard  file  extension  kind  archive  distinguish  normal  jar  maybe  sxar  synapse  extension  archive,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
5248,improve  performance  xslt  mediator  xsltmediator  performance  improved  using  various  methodology  idea  enable  configuration  point  user  specify  optimized  methodology  configuration  methodology  stax  based  source  streamsource  streamresult  better  write  axiomsource  axiomresult  pair  give  best  performance  also  use  feature  enable  methodology  obvious  one  set  feature  used  given  xslt  config  might  introduce  priority  level  two  feature  used  highest  priority  one  used,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5249,improve  synapse  memory  footprint  http  10  synapse  serializes  soap  envelope  order  calculate  content  length  message  http  10  serialization  done  inside  class  axis2httprequest  inside  transport  module  serialized  byte  stored  message  context  future  use  streammessagecontents  method  inside  class  thus  entire  content  soap  envelope  stored  inside  memory  leading  possible  memory  situation  xml  data  large  solution  would  write  data  permanent  storage  like  hard  disk  based  threshold  value  temporarydata  class  inside  core  module  good  solution  kind  work  would  however  incur  cyclic  dependency  used  inside  axis2httprequest  class  resolve  issue  probably  moving  temporarydata  class  utility  module  making  core  depend  great  use  improving  memory  footprint  synapse,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5250,improvement  datasource  connection  pool  improvement  datasource  connection  pool  1  db  connection  pool  defined  synapseproperties  need  accessed  providing  data  source  name  simply  differentiates  accessing  datasources  created  datasources  looking  access  datasources  defined  example  dblookup  mediator  pool  dsnamelookupdsdsname  pool  external  datasources  pool  dsnamelookupdsdsname  icclasscomsunjndirmiregistryregistrycontextfactoryicclass  urlrmilocalhost2199url  useresbuser  passwordesbpassword  pool  11  datasources  defined  intended  use  application  never  want  register  jndi  tree  local  pool  currently  registered  jndi  need  configurable  someone  want  avoid  jndi  registration  tell  configuration  option,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5251,adding  tracing  capability  mediator  hi  adding  new  feature  enable  tracing  capability  mediatorendpoint  proxy  service  flexible  trace  specific  information  local  particular  mediator  thanks  regard  indika,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5252,source  code  hessianmessageformatterbuilder  could  improved  test  case  added  attached  find  second  part  change  hessianmessagebuilderhessianmessageformatter  hopefully  make  hessianmessageformatter  hessianutil  readable  add  javadoc  test  coverage  functional  change  please  review  commit  everything  fine,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5253,send  synapse  generated  hessian  fault  http  status  200  synapse  generates  fault  using  fault  mediator  using  nhttp  transport  currently  always  send  using  http  status  500  hessian  client  requires  message  arrive  http  status  200  differentiation  normal  message  fault  message  http  500  reserved  real  internal  server  error  attached  patch  introduces  message  context  property  advice  nhttp  transport  use  http  200  status  code  hessian  case  message  builder  set  advice  httpcoreniosender  pick  advice  case  fault  message  logic  detect  proper  http  status  extracted  separate  private  method  improve  readability  think  approach  even  better  approach  discussed  dev  list  modifying  faultmediator  set  another  property  value  http  status  faultmediator  stay  transport  independent  property  directly  evaluated  transport  regarding  naming  place  new  constant  nhttpconstants  would  appreciate  review  applies  extracted  status  code  logic  change  existing  bahavior  tried  make  bit  readable  also  changing  comment  feedback  welcome,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5254,enhanced  jmxsupport  synapse  hi  currently  possible  use  java  outofthebox  jmx  solution  configured  via  system  property  andor  property  file  sufficient  many  case  anyway  following  advantage  using  according  remote  api  create  configure  deploy  management  agent  server  connector  programatically  1  easier  configuration  average  user  2  exporting  rmi  server  remote  object  certain  port  allow  passage  firewall  important  enterprise  deployment  possibility  configure  specific  network  interface  also  sometimes  important  enterprise  deployment  multihomed  system  3  possibility  use  custom  jmxauthenticator  handle  credential  configuration  including  use  secretapi  encrypt  password  plain  text  file  requiredprefered  setting  o  permission  accordingly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5255,possibility  put  server  maintenance  mode  reload  synapse  configuration  via  jmx  unfortunately  find  old  issue  created  new  one  provided  patch  extends  existing  server  state  maintenance  state  entering  maintenance  mode  transport  supporting  pause  operation  paused  new  request  accepted  request  progress  finished  server  safely  restarted  load  changed  configuration  running  clustered  environment  behind  loadbalancer  allows  dynamic  configuration  update  server  state  change  triggered  via  jmx  using  extended  servermanagermbean  also  used  query  current  server  state  working  patch  thought  moving  class  synapse  top  level  package  new  server  subpackage  actually  perform  change  ease  review  still  think  would  good  idea  moving  following  class  axis2synapsecontroller  jmxadapter  serverconfigurationinformation  serverconfigurationinformationfactory  servercontextinformation  servermanager  serverstate  serverstatedetectionstrategy  synapsecontroller  synapsecontrollerfactory  synapseserver  synapseserver  servermanagerview  servermanagerviewmbean  synapseservermbean  maybe  also  renaming  servermanagercontrol  servermanagercontrolmbean,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
5256,synapse  able  act  native  proxy  service  rest  service  synapse  able  act  native  proxy  rest  service  thus  http  support  method  get  put  head  delete  post  option  available  per  rfc  2616  related  synapse477  synapse186  synapse386  eg  implementation  proxy  namesynapseresteasy  startonloadtrue  target  endpointrestep  insequence  log  levelfull  property  namemethod  expressiongetpropertyaxis2  httpmethod  property  namerest  url  postfix  expressiongetpropertyaxis2  resturlpostfix  property  nameservice  prefix  expressiongetpropertyaxis2  serviceprefix  log  insequence  outsequence  send  outsequence  target  proxy  endpoint  namerestep  address  urihttplocalhost8080simplejettyrestservices  formatrest  address  endpoint,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5257,implement  support  multiple  ssl  configuration  currently  synapse  one  ssl  configuration  http  transport  sender  defined  parameter  http  transport  sender  axis2xml  however  could  instance  want  sender  use  different  ssl  configuration  connect  different  endpoint  able  specify  multiple  ssl  configuration  transport  level  refer  configuration  endpoint  level,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5258,xslt  mediator  possibility  creating  multiple  template  mutiple  thread  current  code  multiple  thread  create  xslt  template  seeing  cache  expired  also  always  synchronization  creating  template  costly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5259,using  usertransaction  interfacr  instead  transactionmanager  interface  tx  mediator  sure  transactionmanager  interface  used  implementing  tx  mediator  documentation  say  need  move  tx  mangement  boundries  application  server  need  use  transactionmanager  interface  ever  using  thistransactionmanager  one  data  source  caused  resource  enlist  exception  switched  usertransaction  interface  work  fine  one  datasources  attaching  change  patch  anybody  interested  attach  configuration  file  used,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5260,abstractdbmediatorfactory  createlookup  data  source  process  building  inmemory  object  representation  synapse  configuration  separated  initialisation  mediator  attached  patch  move  creationlookup  data  source  abstractdbmediator  factory  read  xml  confguration  transforms  object  model  allows  create  synapse  configuration  including  data  source  xml  file  without  fully  initialized  synapse  environment  available,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
5261,make  multixmlconfigurationserializer  reliable  currently  multixmlconfigurationserializer  mxcl  save  configuration  file  system  1  backup  existing  synapseconfig  directory  2  create  new  synapseconfig  directory  necessary  child  directory  3  serialize  configuration  file  fail  due  io  error  eg  running  file  handle  system  4  delete  backup  step  2  3  fails  mxcl  try  restore  backup  practical  scenario  io  operation  fail  fail  chunk  therefore  time  restoration  operation  never  succeeds  leave  synapse  either  partially  done  synapseconfig  directory  make  process  reliable  implementing  following  strategy  1  create  temp  directory  2  serialize  entire  configuration  temp  directory  leave  original  synapseconfig  directory  intact  3  serialization  completed  move  temp  directory  new  synapseconfig  directory  way  something  go  wrong  serialization  original  synapseconfig  directory  wont  affected,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5262,implement  ability  intercept  admin  level  message  fix  transport  currently  fix  transport  intercept  application  level  message  would  useful  ability  intercept  admin  level  message  well  basically  able  add  custom  field  outgoing  admin  level  message,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5263,combine  script  mediator  inline  external  script  support  see  post  httpmarctheaimsgroupcomlsynapsedevm117212280327926w2  script  inline  script  mediator  could  combined  single  script  mediator,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
5264,implement  url  rewrite  mediator  implement  mediator  rewrite  url  efficiently  based  set  user  defined  rule,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5265,improvement  dynamiclbendpoint  support  session  affinity  based  load  balancing  per  discussion  synapsedev  listsubjectimproving  dynamiclbendpoint  support  session  affinity  based  load  balancing  ive  improved  dynamiclbendpoint,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5266,extend  evaluator  framework  support  evaluation  soap  envelope  content  message  property  allow  one  evaluate  message  context  property  soap  payload  content  using  evaluator  like  matchevaluator  equalevaluator  particularly  come  handy  urlrewritemediator,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1
5267,add  serialization  test  endpoint  currently  serialization  test  endpointssince  bunch  endpointserializers  synapse  core  better  test  keep  correctness  code  monitor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5268,improve  synapse  serverworker  pluggable  http  get  request  processor  currently  synapse  doesnt  support  mechanism  adding  custom  http  get  processor  working  improvement  enhance  synapse  way  user  write  http  get  processor  work  synapse  regard  heshan,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5269,supporting  dynamic  registry  key  mediator  currently  synapse  supporting  static  registry  key  mediator  example  xslt  mediator  allows  static  key  creating  mediator  patch  synapse  able  provide  support  dynamic  key  like  xpath  expression  case  user  able  use  xpath  kind  approach  dynamically  generate  key  instead  static  key  improvement  synapse  support  static  dynamic  key  following  example  using  static  key  xslt  keyxsltkeyreq  using  dynamic  key  xslt  keyxpathexpressiontoevaluatekey  also  improvement  xslt  mediator  able  support  multiple  template  caching,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5270,functiontemplates  synapse  configuration  implementing  function  template  synapse  used  reduce  lot  complexity  well  eliminate  redundancy  synapse  configuration  moment  large  portion  esb  configuration  micro  level  user  individually  configure  every  mediator  achieve  high  level  task  need  high  level  abstraction  user  easily  use  model  scenario  example  consider  following  scenario  proxy  namesplitaggregateproxy  target  insequence  iterate  expressionm0getquotem0  request  preservepayloadtrue  attachpathm0getquote  xmlnsm0httpservicessamples  target  sequence  send  endpoint  address  urihttplocalhost9000servicessimplestockquoteservice  endpoint  send  sequence  target  iterate  insequence  outsequence  aggregate  oncomplete  expressionm0getquoteresponse  xmlnsm0httpservicessamples  send  oncomplete  aggregate  outsequence  target  proxy  user  really  want  look  three  configuration  parameter  1  two  xpath  expression  2  endpoint  address  hide  lot  complexity  introducing  template  configuration  parameterize  like  function  known  pattern  oneparameterization  done  using  xpath  expression  function  template  look  like  following  synapse  config  1  template  namefunc  name  parameter  function  template  parameter  namep1  sequence  sequence  template  template  extension  sequence  hence  template  body  contain  sequence  general  mediatorcomp  inside  template  body  refer  parameter  like  normal  function  xpath  function  scope  iefunc  variable  ie  aggregate  oncomplete  xmlnsm0httpservicessamples  expressionfuncp2  log  levelfull  send  oncomplete  aggregate  log  levelcustom  property  namep1value  expressionfuncp1  property  namep2value  expressiongetpropertyfuncp2  log  2to  invoke  template  synapse  define  invoke  mediator  following  form  using  invoke  mediator  within  sequence  synapse  would  able  execute  template  passed  value  parameter  p1p2etc  invoke  targettarget  func  template  parameter  namep2  valueany  xpath  plainvalue  invoke,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5271,upgrading  quartz  version  used  synapsetask  current  synapsetask  implementation  used  quartz  160  version  something  old  quartz  latest  stable  version  211  seem  many  functional  improvement  new  feature  160  version  good  idea  upgrade  quartz  version  211  future  enhancement  synapsetask,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5272,ocspcrl  certificate  validation  feature  synapse  please  find  implementation  feature  along  unit  test  working  sample  attached  certificatevalidationfeaturezip  file  feature  plugged  nhttp  passthru  transport  information  please  read  readme  thanks  jeewantha,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5273,messageinjector  task  improvement  current  implementation  messageinjector  main  sequence  invoked  want  invoke  different  sequence  main  filter  message  coming  task  main  sequence  direct  message  sequence  good  following  functionality  messageinjector  ability  invoke  named  sequence  without  going  main  sequence  ability  invoke  proxy  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5274,new  blocking  sender  implementation  currently  following  two  main  place  use  blocking  client  invoke  service  1  callout  mediator  2  forwarding  message  processor  component  use  axis2  service  client  invoke  service  blocking  manner  since  implementation  simple  provided  functionality  limited  currently  following  major  limitation  support  soap  message  format  conversion  supported  qos  functionality  wssecurity  wsa  supported  cannot  specify  endpoint  service  endpoint  reference  message  processor  specify  address  endpoint  none  endpoint  functionality  supported  implemented  new  blocking  client  used  common  blocking  sender  component  new  implementation  provide  following  functionality  support  leaf  endpoint  type  support  rest  support  endpoint  functionality  endpoint  format  conversion  soap11soap12pox  etc  wssecurity  wsa  endpoint  timeout  nhttp  transport  specific  functionality  supported  message  format  conversion  ability  use  messagetypecontenttype  property,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
5275,allow  bookie  garbage  collection  triggered  manually  test  current  gc  test  rely  waiting  timeout  gc  run  never  certain  whether  run  still  running  patch  allows  test  trigger  gc  run  give  client  future  know  completed  gc  algorithm  unchangedi  run  scheduled  executor  rather  thread  work  originally  done  ivan  kelly  pushing  back  open  source,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5276,move  netty4  part  yahoo  push  back  general  would  like  move  netty  4  preferably  netty  41x  client  server  communication  lay  ground  work  zero  copy  nearly  zero  copy  handling  server  side,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
5277,add  fencing  bookkeeper  bookkeeper  designed  use  write  ahead  log  system  primarybackup  architecture  primary  write  state  update  wal  primary  dy  backup  come  online  read  wal  get  latest  state  start  serving  request  however  primary  partitioned  network  stuck  long  gc  split  brain  occurs  primary  backup  service  client  request  fencinghttpenwikipediaorgwikifencing28computing29  ensures  cannot  happen  fencing  backup  close  wal  primary  cause  subsequent  attempt  primary  write  wal  give  error  fence  ledger  whenever  opened  another  client  using  bookkeeperopenledger  bookkeeperopenledgernorecovery  fence  opening  client  mark  ledger  fenced  zookeeper  sends  readentry  message  bookie  dofencing  flag  set  least  1  bookie  possible  quorum  bookie  responded  proceed  opening  ledger  subsequent  attempt  write  ledger  fail  able  write  quorum  without  one  bookie  quorum  responding  ledger  fenced  error  client  also  unable  change  quorum  without  seeing  ledger  marked  fenced  zookeeper,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5278,disk  full  start  bookie  ro  mode  ro  mode  enabled  disk  full  start  bookie  ro  mode  ro  mode  enabled  work  isforcegcallowwhennospace  allowed  since  ledgerdirsmanagergetwritableledgerdirsfornewlog  able  find  new  writableledgerdir  even  disk  full  bookie  died  abruptly  may  missed  flushing  entrymemtable  indexinmemorypagemanager  next  time  start  disc  full  fails  create  index  file  shuts  bookie  able  create  index  file  though  reached  diskusagethreshold  starting  bookie  readonly  mode  ofcourse  config  safeguard  disk  usable  space  low,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5279,optimize  handling  masterkey  case  empty  request  client  bookie  exchanging  ledger  masterkey  20  byte  mac  digest  ledger  password  request  considerable  overhead  allocating  byte  array  parsing  addread  request  client  passing  empty  password  optimize  data  path  skip  allocation  related  masterkey  instead  rely  static  byte  array,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5280,removed  packetheader  serializationdeserialization  allocation  parsing  request  packet  header  use  static  method  avoid  creating  packetheader  instance,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
5281,add  configuration  support  bk  ivans  comment  bookkeeper39  use  lot  system  property  bk  better  use  proper  configuration  object  manager,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5282,bookie  server  need  compaction  entry  log  file  reclaim  disk  space  bookie  server  aggregate  entry  entry  log  file  suppose  lot  ledger  ledger  little  message  entry  log  file  would  contains  message  lot  different  ledger  one  ledger  deleted  entry  log  file  would  removed  whose  occupied  disk  space  could  reclaimed,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1
5283,add  versioning  support  journal  file  add  versioning  journal  add  new  feature  journal  without  breaking  backward  compatibility,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
5284,message  bounding  subscription  hedwig  message  subscription  queue  forever  subscriber  offline  usecases  undesirable  eventually  mean  resource  exhaustion  jira  propose  optional  change  subscription  contract  allows  user  set  bound  number  message  queued  subscription  offline,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5285,bookie  code  coupled  bookie  owns  entrylogger  ledgercache  ledgerdescriptors  depend  strange  way  sometimes  access  ledgercache  directly  sometimes  ledgerdescriptors  etc  etc  messy  there  hierarchy  propose  refactor  bookie  contain  entrylogger  journalling  code  factored  stage  also  entrylogger  ledgercache  ledgerdescriptors  would  entanglement  observed  bookkeeper160,0,0,0,0,0,0,1,0,0,0,1,0,0,1,0,0,0
5286,delay  ledger  directory  creation  ledger  index  file  created  index  file  creation  delayed  absolutely  necessary  bookkeeper137  dont  delay  creation  parent  directory  index  file  would  hurt  performance,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5287,provide  tool  readcheck  data  file  bookie  server  written  tool  readcheck  data  file  including  index  file  journal  file  entry  log  file  bookie  server  help  user  findingdebugging  issue  would  like  contribute  back,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5288,hub  server  change  ledger  write  consumed  message  chance  garbage  collected  currently  hub  server  write  entry  one  ledger  topic  doesnt  change  ownership  entry  added  ledger  consumed  message  dont  chance  garbage  collected,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5289,define  interface  bookie  ledger  storage  entrylogger  ledgercache  part  interdependent  storage  mechanism  entry  interleaved  single  logentrylogger  index  file  maintained  ledgercache  id  like  experiment  scheme  im  convinced  interleaving  required  high  performance  zookeeper507  brought  change  also  brought  lot  stuff  think  stuff  specifically  taking  writing  separate  file  critical  path  gave  u  performance  boost  cleanly  need  well  defined  storage  interface  jira  provide  future  work  move  interleaved  implementation  another  package  orgapachebookkeeperbookie  getting  little  crowded,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5290,separate  write  quorum  ack  quorum  use  case  bookkeeper  may  require  submitting  add  request  write  set  returning  upon  receiving  confirmation  ack  set  ack  set  must  subset  write  set  important  special  case  writing  returning  upon  hearing  majority  another  important  use  case  avoiding  slow  disk  writing  f  1  returning  upon  receiving  f  1  response  currently  write  set  ack  set  ledger  internal  change  support  case  include  change  ledgerhandle  pendingaddop  also  need  add  call  client  api  accept  different  size  write  set  ack  set  upon  ledger  creation  also  open  discussion  need  implement  new  distribution  schedule  far  look  like  reuse  round  robin  implementation  currently  would  need  implement  new  one  example  initial  bookie  add  operation  must  always,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5291,provide  journal  manager  manage  journal  related  operation  currently  put  journal  related  operation  bookie  class  would  better  provide  journal  manager  provide  journal  related  operation  would  make  bookie  logic  clearly  besides  admin  tool  like  bookkeeper183  need  provide  could  use  journalmanager  readcheck  journal  file  directly,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
5292,benchmarking  improvement  latest  round  benchmarking  improvement  benchmark  harness  latest  round  benchmarking  done,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5293,hedwig  provide  subscription  mode  kill  subscription  channel  hedwig  client  used  proxystyle  server  case  need  hedwigclient  proxy  server  provide  messaging  service  user  client  proxy  server  1  hedwig  proxy  server  2  client  would  connect  either  proxy  server  receive  message  proxy  server  would  setup  subscription  channel  hedwig  server  want  client  simple  channel  client  proxy  server  broken  client  try  connect  proxy  server  thru  vip  might  connect  proxy  server  example  first  time  client  connects  proxy  server  1  client  found  connection  broken  connects  proxy  server  2  proxy  server  2  tried  setup  subscription  channel  hedwig  hedwig  found  subscription  existed  occupied  proxy  server  1  panic  proxy  server  1  disconnect  old  subscription  channel  detected  channel  client  broken  detection  might  delayed  due  several  reason  might  increment  latency  message  pushed  real  client  try  introduce  subscription  mode  called  createorattachorkill  mode  subscriber  use  subscription  mode  would  kill  old  existed  subscription  channel  using  subscription  mode  would  turn  autoreconnect  functionality  hedwig  client  tell  client  channel  disconnected  event  client  could  logic  channel  detected  order  provide  admin  tool  admin  guy  debugoperate  provide  admin  mode  subscriber  attach  subscription  using  admin  mode  subscription  channel  would  never  killed  safe  guarantee  admin  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5294,create  bookie  format  command  provide  bookie  format  command  admin  would  run  command  machine  prepare  bookie  env  zookeeper  path  znodes  ledger  root  path  bookie  available  path  directory  journal  directory  ledger  directory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5295,add  length  offset  parameter  addentry  email  dev  list  im  issue  ledgerhandleaddentry  api  1  best  illustrates  im  buffering  namenode  transaction  stream  transmitting  either  flush  called  enough  data  pas  threshold  mean  byte  buffer  class  fill  new  transaction  come  transmit  set  buffer  entry  bookkeeper  ie  n  whole  namenode  transaction  contained  1  single  bk  entry  problem  byte  buffer  dataoutputbuffer  case  reuse  buffer  buffer  fixed  size  transmit  full  whole  buffer  size  transmitted  anyhow  buffer  reused  retransmit  old  transaction  order  example  first  use  buffer  fill  abcde  add  entry  reset  byte  buffer  transaction  f  added  flushed  case  fbcde  transmitted  need  ability  set  offset  length  byte  passed  addentry  reason  wasnt  added  initial  implementation  agree  valid  usecase  ill  open  jira  add  functionality  im  getting  around  extra  arraycopyof  le  ideal  email,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5296,provide  support  zookeeper  authentication  jira  add  support  protecting  state  bookkeeper  znodes  multitenant  zookeeper  cluster  use  case  user  try  run  zk  cluster  multitenant  mode  one  client  service  would  like  share  single  zk  service  instance  cluster  case  client  service  typically  want  protect  data  zk  znodes  access  service  tenant  cluster  say  running  bk  hbase  zkfc  instance  etc  authenticationauthorization  znodes  important  security  helping  ensure  service  dont  interact  negatively  touch  others  data  presently  bookkeeper  support  authentication  authorization  accessing  zk  added  bk  clientsserver  accessing  zk  cluster  general  mean  calling  addauthinfo  session  established,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5297,compositeexception  message  useful  exception  logged  via  slf4j  dont  actually  tostring  method  called  current  behaviour  overriding  tostring  compositeexception  rarelynever  triggered  client  code  composing  better  message  field  compositeexception  would  make  loggable,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5298,let  hub  server  configure  write  quorum  ack  quorum  since  support  ack  quorum  bookkeeper208  would  better  let  hub  server  could  configure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5299,simplify  abstractsubscriptionmanager  difficult  maintain  duplicatedcached  count  local  subscriber  weve  experienced  issue  due  getting  sync  actual  set  subscriber  since  count  local  subscriber  calculated  top2sub2seq  map  let  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5300,provide  separate  read  write  thread  bookkeeper  server  current  bookkeeper  server  single  threaded  thread  handle  read  writes  read  slow  possibly  excessive  seek  add  entry  operation  suffer  term  latency  providing  separate  read  write  thread  help  reducing  add  entry  latency  increasing  throughput  even  facing  slow  read  single  read  thread  also  result  low  disk  utilization  seek  cant  ordered  efficiently  o  multiple  read  thread  would  help  improving  read  throughput  discussion  found  httpmailarchivesapacheorgmodmboxzookeeperbookkeeperdev201209mbox3ccaolhydqpznv10zynfwudh0qzrxtmjgttx7a9eofohyytyjbamailgmailcom3e  reviewboard  httpsreviewsapacheorgr7560,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
5301,duplicate  definition  cookiesnode  necessary  two  definition  cookiesnode  one  cookiejava  one  abstractzkledgermanager,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5302,multiple  thread  delivery  manager  similar  bookkeeper461  one  thread  running  processing  delivery  would  bottleneck  subclosesub  throttle  became  frequently,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
5303,stopservingsubscriber  delivery  manager  remove  stub  callback  readaheadcache  currently  subscriber  would  insert  stub  callback  wait  newly  published  message  scanning  result  waiting  scan  result  ok  callback  would  triggered  removed  scan  callback  arrived  wait  newly  published  would  problem  subclosesubsub  become  frequent  closesub  doesnt  remove  installed  callback  stub  callback  accumulated  cause  memory  increased  finally  oom  would  better  remove  installed  stub  callback  closesub,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5304,avoid  journal  polluting  page  cache  writing  data  journal  force  data  o  buffer  cache  used  hot  read  could  negative  affect  performance  similar  solution  cassandra1470,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5305,better  checkpoint  mechanism  currently  syncthread  made  checkpoint  frequently  affect  performance  data  writing  entry  logger  file  might  blocked  syncing  entry  logger  file  affect  bookie  achieve  higher  throughput  could  schedule  checkpoint  rotating  entry  log  file  new  incoming  entry  would  written  newer  entry  log  file  old  entry  log  file  could  synced,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
5306,allow  application  recommend  ledger  data  locality  application  like  hbase  wal  useful  application  like  hbase  give  hint  bk  application  preferred  ledger  location  way  application  fail  specific  machine  one  ledger  replica  located  recovery  time  faster  another  scenario  hbases  support  hot  standby  region  server  read  request  served  different  machine  active  region  server  requires  hot  standby  region  server  read  ledger  ledger  machine  standby  region  server  performance  better,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5307,speed  bookkeeper  test  test  use  addentry  using  asyncaddentry  leading  test  taking  much  long  others  timeouts  set  high  case  expected  fail,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5308,add  tag  oabnet  indict  release  hadoop  came  move  dns  oabnet  indent  didnt  reformat  code  bringing  hadoop  common  patch  bookkeeper618,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5309,turn  readonly  back  writable  space  reclaimed  able  turn  bookie  readonly  back  writable  space  reclaimed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5310,major  gc  kick  immediately  remaining  space  reach  warning  threshold  high  throughput  case  major  gc  kick  immediately  remaining  space  reach  warning  threshold,1,1,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0
5311,stats  autorecovery  idea  jira  provide  jmx  interface  get  statistic  auto  recovery  activity,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5312,move  fence  request  read  thread  move  fence  request  read  thread  address  todo,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5313,add  tryreadlastaddconfirmed  api  add  tryreadlastconfirmed  read  last  confirmed  without  coverage  checking  reader  poll  lac  need  lac,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5314,bookkeeper  delay  ensemble  change  doesnt  break  ack  quorum  requirement  flag  allow  delay  ensemble  change  set  change  ensemble  change  break  ack  quorum  requirement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5315,reorder  read  sequnce  reorder  read  sequence  base  location  bookie  availability  latency  consideration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5316,recovery  tool  doesnt  remove  cookie  recovering  one  bookie  ran  bookie  recovery  tool  recover  bookie  encountered  hardware  issue  recovery  tool  doesnt  remove  cookie  finished  recovery  fixed  bookie  added  back  cluster  couldnt  start  cookie  exists  zookeeper  disk  want  tool  could  delete  cookie  recover  bookie  maybe  provide  another  tool  remove  cookie  bookie,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5317,support  journal  rolling  bookkeeper  writing  single  journal  file  journal  file  chance  garbage  collected  disk  space  keep  growing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5318,change  throttle  garbagecollector  use  either  entry  byte  current  bookie  compaction  garbagecollector  setting  compactionrate  throttling  limiting  compaction  entry  bandwidth  perspective  would  good  could  throttle  limit  compaction  byte  would  really  reflect  bandwidth  disk  enhancement  added  another  byte  option  compaction  garbagecollector  boolean  isthrottlebybytes  true  use  byte  false  use  entry  int  compactionratebyentries  entry  number  concurrent  entry  int  compactionratebybytes  byte  number  byte  entry  flush,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5319,added  versioning  flag  bookie  protocol  concept  version  bookkeeper  protocol  moment  patch  address,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5320,bookie  calculate  ledger  map  writing  new  entry  log  file  bookie  calculate  ledger  map  writing  new  entry  log  file  bookie  doesnt  need  scan  entry  log  file  would  improve  garbage  collection  efficiency,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5321,collect  stats  submilliseconds  precision  operation  bookie  taking  1ms  stats  collected  nanos  expecially  since  latency  already  measured  nanos,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5322,configurable  ledgerstorageimplementation  allow  configure  different  implementation  ledgerstorage  interface  bookie  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5323,add  tracing  stats  orderedsafeexecutor  debugging  slow  task  porting  change  form  twitter  branch  improve  stats  logging  orderedsafeexecutor  change  helpful  u  debugging  latency  issue  bookkeeper  serverclient  summary  change  add  config  option  op  stats  add  stats  task  execution  time  task  pending  time  add  config  option  logging  warning  op  take  longer  x  micros  add  tostring  implementation  submitted  task  make  easier  track  slow  ops  start  using  builder  orderedsafeexecutor  add  simple  test  make  sure  slow  op  logging  path  exercised  came  sijie  originally  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5324,dispatch  individual  callback  journal  different  thread  currently  journal  sending  response  single  thread  entry  batch  synced  since  thread  pool  configured  better  spread  sendresponse  task  available  thread,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5325,bookkeeper  api  change  initial  bookkeeper  release  change  follows  bookkeepercreateledger  parameter  named  passwd  key  used  ledgerhandle  api  bookkeepergetbookieclient  shouldnt  public  bookkeepercreatecomplete  shouldnt  public  bookkeeperopencomplete  shouldnt  public  bookkeeperdeletecomplete  shouldnt  public  bookkeeperhalt  could  changed  close  throw  bkexception  ledgerhandlegetledgerkey  passwd  used  bookkeeper  possibly  private  ledgerhandlegetledgermetadata  shouldnt  public  ledgerhandlegetdigestmanager  shouldnt  public  ledgerhandlegetdistributionschedule  shouldnt  public  ledgerhandlewriteledgerconfig  shouldnt  public  ledgerhandleaddentry  return  void  error  go  exception  ledgerhandlereadcomplete  public  ledgerhandleaddcomplete  public  ledgerhandlereadlastconfirmedcompelte  public  ledgerhandleclosecomplete  public  asynccallbackrecovercallback  shouldnt  public,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
5326,read  ledger  entry  bookie  shell  bookie  shell  tool  read  ledger  entry  bookkeeper  cluster  optional  argument  startentryid  endentryid  solution  implement  readentries  bookkeeperadmin  return  iterable  iterating  fetch  individual  entry  instead  fetching  entry  also  lastentryid  specified  read  entry  till  get  nosuchentryexception,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5327,bookie  retain  ledger  longer  belong  bookie  clean  ledger  disk  exist  zookeeper  assigned  ensemble  definition  happens  bookie  ledger  went  offline  replicated  elsewhere  bookie  come  back  extra  copy  ledger  solution  bookie  handle  case  garbage  collector  since  read  ledger  metadata  go  ensemble  set  determine  bookie  exists  ensemble  expensive  operation  thus  run  task  every  day,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
5328,hedwig  api  change  initial  bookkeeper  release  hedwigclientgetsslfactory  shouldnt  public  hedwigclientgetconsumecallback  shouldnt  public  hedwigclientdoconnect  shouldnt  public  hedwigclientgethostfromchannel  shouldnt  public  hedwigclientgetresponsehandlerfromchannel  shouldnt  public  hedwigclientgethostfortopic  shouldnt  public  hedwigclientclearalltopicsforhost  shouldnt  public  hedwigclientgetclienttimer  shoulndt  public  hedwigclientstop  throw  sort  exception  case  error  hedwigpublisherpublish  shouldnt  use  protobuf  bytestring  requires  user  import  protobufs  hedwigpublishergetchannelforhost  shouldnt  public  hedwigsubscriberhedwigsubscriber  shouldnt  public  hedwigsubscriberdoconsume  shouldnt  public  hedwigsubscriberhassubscription  probably  shouldnt  public  hedwigsubscribergetsubscriptionlist  shoulndt  exist  hedwigsubscribergetchannelfortopic  shouldnt  public  hedwigsubscribersetchannelfortopic  shouldnt  public  hedwigsubscriberremovechannelfortopic  shoundt  public  messagehandlerconsume  called  deliver  hedwig  client  netty  package  there  nothing  netty  specific  api  orgapachehedwigclient  package,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
5329,add  authentication  framework  authentication  framework  able  add  auth  mechanism  communication  client  bookie,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5330,bookkeeper  hedwig  client  use  log4j  directly  using  log4j  directly  requires  application  using  bookkeeper  hedwig  client  configure  log4j  use  something  like  common  logging1  slf4j2  1  httpcommonsapacheorgloggingindexhtml  2  httpwwwslf4jorg,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5331,create  generic  kv  map  store  ledger  metadata  introduced  ctime  ledger  metadata  httpsissuesapacheorgjirabrowsebookkeeper879  token  would  like  introduce  createrid  also  128  bit  uuid  caller  write  tool  group  ledger  createrid  future  even  enhance  run  query  based  createrid,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5332,option  disable  bookie  networking  issue  related  bookkeeper896  introduced  ability  use  netty  builtin  local  channel  idea  disable  bookie  networking  networkless  junit  testing  introduce  disableserversocketbind  option  skip  serverside  bind  bookienettyserverlistenon  another  use  case  use  bookkeeper  writeahead  log  single  machine  application  note  zookkeeper  still  need  network  another  issue,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5333,publish  source  javadocs  maven  central  push  source  javadocs  maven  central  release  process  useful  artifact  ides,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
5334,upgrade  protobuf  26  update  protobuf  definition  internal  experiment  found  working  protobuf  24  rather  inconvenient  cannot  installed  brew  mac  building  mac  always  result  build  error  hence  leaf  option  switching  linux  run  protoc  decided  upgrade  26  instead  compatible  24  wire  shaded  create  problem  test  passed  please  ignore  change  java  file  attached  patch  review  autogenerated,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5335,multiple  issue  improvement  bk  compaction  identified  multiple  issue  bk  compaction  issue  list  one  jira  ticket  1  majorcompaction  minorcompaction  basic  either  won’t  proposal  add  low  water  marklwm  high  water  markhwm  disk  space  different  compaction  frequency  reclaim  disk  space  low  water  mark  lwm  hwm  hwm  2  majorcompaction  minor  compaction  strictly  frequency  based  least  time  day  based  also  run  low  system  load  system  load  raise  reduce  compaction  depending  disk  availability  3  current  code  disables  compaction  disk  space  grows  beyond  configured  threshold  exit  point  option  keep  reserved  space  compaction  least  2  entrylog  file  size  isforcegcallowwhennospace  enabled  4  current  code  toggle  readonly  status  bookie  soon  fall  disk  storage  threshold  imagine  keep  95  threshold  bookie  becomes  rw  soon  fall  95  writes  push  95  turn  back  ronly  use  set  defines  another  set  lwmhwm  bookie  turn  ro  high  end  wont  become  rw  hit  low  end  5  current  code  never  check  compaction  enabled  disabled  majorminor  compaction  started  bookie  go  disk  threshold  95  compaction  going  never  check  finish  may  disk  available  compaction  take  place  check  compaction  enabled  processing  every  entrylog  6  current  code  change  bookie  cookie  value  even  new  storage  added  cookie  change  bookie  becomes  new  one  bk  cluster  treat  new  bookie  mechanism  keep  valid  cookie  even  adding  additional  disk  space  may  chance  bring  bookie  back  healthy  mode  compaction  going  7  bug  checkpoint  never  attempted  complete  sync  failure  todo  code  area  8  disk  threshold  bookie  go  ro  restart  bookie  way  back  bookie  try  create  new  entrylog  file  fail  disk  usage  threshold  hence  bookie  refuse  come,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5336,provide  option  delay  auto  recovery  lost  bookie  auto  recovery  enabled  bookie  go  upgrade  even  loos  zk  connection  intermittently  auditor  detects  lost  bookie  start  replication  detection  replication  worker  bookie  node  start  replicating  replicated  ledger  stop  bookie  come  ledger  would  get  replicated  given  fact  multiple  copy  data  probably  necessary  start  recovery  soon  bookie  go  probably  wait  hour  start  recovery  cover  case  like  planned  upgrade  intermittent  network  connectivity  loss  etc  amount  time  wait  option  default  would  wait  allie  retain  current  behavior  course  one  bookie  go  within  short  interval  could  decide  start  auto  recovery  without  waiting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5337,provide  option  add  ledgerindex  directory  bookie  addition  new  ledger  index  directory  existing  bookie  disallowed  via  cookie  check  bookie  start  path  attempt  add  new  storage  rejected  bookie  doesnt  come  need  add  additional  storage  bookie  jira  providing  option  add  additional  storage  bookie,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5338,assing  readwrite  request  ledger  single  thread  entry  ledger  processed  bookie  avoid  reordering  request  currently  multiple  readwrite  thread  configured  request  passed  executor  writes  ledger  spread  across  multiple  thread  pose  2  issue  mutex  contention  access  ledgerdescriptor  client  receives  addentry  acks  order  anyway  wait  acks  previous  entry  acknowledging  whole  sequence  application  practice  reordering  increasing  latency  experienced  application,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5339,bump  zookeeper  version  35  dl  need  leverage  asynchronous  version  multi  zookeeper  jira  bump  zookeeper  version  35  support  async  multi,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5340,package  datagen  script  standalone  systemml  distribution  random  data  generation  script  scriptsdatagen  useful  way  people  become  familiar  systemml  assuming  generate  data  file  manner  easily  consumed  algorithm  executed  right  scriptsdatagen  directory  packaged  standalone  distribution  probably  include  directory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5341,crc  file  created  output  file  run  standalone  mode  dml  script  executed  standalone  mode  eg  runstandalonesystemmlsh  algorithmsdatagengenlinearregressiondatadml  nvargs  numsamples1000  numfeatures50  maxfeaturevalue5  maxweight5  addnoisefalse  b0  sparsity1000  outputlinregdatacsv  formatcsv  crc  file  created  file  example  script  following  file  written  file  system  linregdatacsv  linregdatacsvcrc  linregdatacsvmtd  linregdatacsvmtdcrc  litter  file  system  lot  basically  unnecessary  file  several  script  executed  number  crc  grows  rapidly  mechanism  one  following  1  dont  generate  crc  file  first  place  2  delete  generated  crc  file  3  option  generate  crc  file  option  default  set  false,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5342,new  unary  aggregate  operation  variance  standard  deviation  numerical  stability  normally  compute  standard  variation  variance  via  second  central  moment  however  central  moment  currently  limited  input  vector  without  support  matrix  requires  user  misuse  parfor  dataparallel  computation  follows  cause  unnecessary  performance  problem  r  matrix0  rows1  colsn  parfori  1n  r1i  sqrtnn1momentai2  two  way  addressing  generalize  moment  matrix  add  new  builtin  unary  aggregate  standard  deviation  variance  go  latter  common  operation  note  reason  moment  part  unary  aggregate  framework  scalar  order  parameter  standard  deviation  constant  2,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5343,new  rev  builtin  function  various  script  permutation  matrix  used  order  reverse  matrix  via  matrix  multiplication  intuitive  requires  materialization  large  ultrasparse  permutation  matrix  accordingly  task  aim  add  new  builtin  function  rev  reversing  matrix  builtin  function  similar  semantics  r  rev  function  general  supporting  matrix  instead  vector,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5344,jmlc  api  support  text  analytics  usecases  working  text  analytics  use  case  eg  document  classification  entity  extraction  would  like  use  jlmc  interface  scoring  time  cant  find  right  method  orgapachesysmlapijmlcpreparedscript  entity  extraction  need  feature  associated  every  token  document  case  feature  conceptually  represented  table  3  column  tokenid  integer  consecutive  integer  number  representing  position  token  document  entity  extraction  essentially  problem  classifying  every  token  beginentity  insideentity  outsideentity  hence  order  token  document  important  featurename  string  name  feature  example  whether  token  capitalized  word  surface  form  token  etc  featurevalue  integer  integer  case  always  1  since  include  feature  absent  document  classification  order  token  document  may  may  important  simplest  case  assume  order  important  document  use  surface  form  token  document  feature  name  number  time  surface  form  appears  document  feature  value  feature  conceptually  represented  table  2  column  featurename  string  surface  form  token  featurevalue  integer  number  time  surface  form  appears  within  document  essentially  use  case  would  like  pas  jmlc  table  schema  column  known  basic  datatype  think  string  integer  float  boolean  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5345,read  matrix  url  ability  read  matrix  url  increase  usability  systemml  eliminating  need  already  existing  local  cluster  data  invoking  systemml  instance  rather  something  like  code  wget  httpexamplecommlmatrixcsv  runstandalonesystemmlsh  exampledml  nvargs  xmatrixcsv  code  someone  could  code  runstandalonesystemmlsh  exampledml  nvargs  xhttpexamplecommlmatrixcsv  code  one  way  useful  small  set  example  data  algorithm  sitting  server  documentation  could  show  single  command  invoked  algorithm  reference  serverbased  example  data  would  mean  user  essentially  copypaste  single  command  documentation  would  run  using  server  example  data,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5346,mlcontext  redesign  jira  proposes  redesign  java  mlcontext  api  several  goal  •  simplify  user  experience  •  encapsulate  primary  entity  using  objectoriented  concept  •  make  api  extensible  external  user  •  make  api  extensible  systemml  developer  •  locate  userinteraction  class  interface  etc  single  api  package  •  extensive  javadocs  class  api  •  potentially  fold  jmlc  api  mlcontext  single  programmatic  api,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5347,cleanup  exception  handling  apiscompilerruntime  1  remove  unnecessary  exception  eg  various  subclass  cacheexception  dmlunsupportedoperationexception  appexception  2  fuse  unnecessary  deep  exception  hierarchy  eg  dmlparseexception  3  reinvestigation  uncaught  v  caught  exception,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5348,compare  performance  lenet  script  without  using  systemmlnn  jira  issue  track  comparison  performance  lenet  script  without  using  systemmlnn  goal  equal  performance  term  accuracy  time  difference  indicate  area  engine  improvement  script  mnistlenettraindml  httpsgithubcomapacheincubatorsystemmlblobmasterscriptsstagingsystemmlnnexamplesmnistlenettraindml  lenet  script  use  systemmlnn  library  lenettraindml  httpsgithubcomapacheincubatorsystemmlblobmasterscriptsstaginglenettraindml  lenet  script  use  systemmlnn  library  current  status  forced  singlenode  equal  performance  running  script  standalone  mode  exec  singlenode  flag  20gb  memory  using  data  input  systemml  binary  format  see  runsh  perfsh  information  result  run  1  script  time  accuracy  mnistlenettraindml  2987400704441  9932  lenettraindml  2816369435579  9928  run  2  script  time  accuracy  mnistlenettraindml  2847790531812  9916  lenettraindml  2950520494210  9918  accuracy  runtime  singlenode  mode  current  status  spark  local  two  script  performance  spark  local  mode  nonsinglenode  equivalent  performance  forced  singlenode  mode  due  creation  cp  job  fully  reproduce  basically  created  directory  placed  two  attached  bash  script  grabbed  copy  nn  library  placed  directory  ran  examplesgetmnistdatash  script  library  get  data  placed  examplesdata  used  attached  convertdml  create  binary  copy  data  script  ran  runsh  also  copied  examplesdata  base  directory  well  adjust  exec  related  variable  perfsh  switch  standalone  spark  memory  size  explain  stats  etc,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5349,update  mlcontext  matrix  method  mlcontext  matrix  class  allows  easy  conversion  different  format  dataframes  rdds  etc  using  several  method  updating  method  would  closely  follow  spark  conversion  method  convention  documentation  also  updated,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5350,add  additional  class  mlcontext  frame  support  create  implement  frame  class  enhance  mlcontext  api  frame  support  classesenums  create  include  frame  frameformat  framemetadata  frameschema  binaryblockframe  add  support  class  mlcontextutil  mlcontextconvertutil  script  mlresults  related  class  code  quite  similar  code  matrix  support,0,0,0,0,0,0,1,0,0,1,1,0,0,0,0,0,1
5351,improve  frameobject  tostring  output  currently  frameobject  us  default  tostring  implementation  would  good  override  tostring  frameobject  similar  matrixobject  override  tostring  example  using  mlcontext  api  currently  output  matrixobject  frameobject  look  similar  following  code  scala  val  re  mlexecutedmlscript  re  orgapachesysmlapimlcontextmlresults  1  matrix  ta  matrix  scratchspacep766793111712t0ta290  3  x  2  nnz6  block  1000  x  1000  binaryblock  dirty  2  frame  tam  orgapachesysmlruntimecontrolprogramcachingframeobject6c6c4579  code  matrixobject  provides  useful  information  via  tostring  whereas  frameobject  doesnt,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
5352,add  vector  supported  type  frame  conversion  currently  able  pas  spark  dataframes  vector  type  column  input  systemml  script  converted  systemml  matrix  add  vector  type  frame  conversion  code  example  given  spark  dataframe  schema  double  vector  string  able  convert  systemml  frame  bunch  double  column  final  string  column  cc  mboehm7  ac,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5353,performance  improve  vector  dataframe  conversion  currently  performance  vector  dataframe  conversion  leaf  much  desired  regard  frequent  oom  error  overall  slow  performance  scenario  spark  dataframe  3745888  row  row  contains  one  vector  column  vector  dense  length  65539  note  256x256  pixel  image  stretched  appended  3column  onehot  encoded  label  ie  forced  workaround  get  label  feature  systemml  efficiently  possible  systemml  script  mlcontext  invocation  python  simply  accept  dataframe  input  save  systemml  matrix  binary  form  note  im  grabbing  output  matrix  literally  written  systemml  code  script  writetrain  train  formatbinary  script  dmlscriptinputtraintrainyx  mlexecutescript  code  im  seeing  large  amount  memory  used  conversion  mappartitionstopair  rddconverterutilsjava311  stage  example  scenario  read  14932  gb  input  performed  shuffle  write  25  tb  subsequent  stage  saveashadoopfile  writespinstructionjava261  shuffle  read  25tb  output  18291  gb  simple  script  took  dataframes  vector  column  wrote  disk  binary  format  kept  running  heap  space  memory  kept  increasing  executor  memory  3x  finally  ran  additionally  latter  stage  skewed  execution  time  across  partition  1hour  first  1000  paritions  20000  20  minute  next  18000  partition  1  hour  final  1000  partition  passed  dataframe  average  180  row  per  partition  max  215  min  155  cc  mboehm7,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5354,add  api  support  creating  multiple  resource  single  request  add  ability  create  multiple  resource  type  providing  array  resource  property  http  body  example  create  multiple  service  resource  cluster  named  mycluster  post  htpmyhost8080apiv1clustersmyclusterservices  serviceinfo  servicename  pig  serviceinfo  servicename  oozie  serviceinfo  servicename  hive,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5355,rolecommandorderjson  stack  level  current  stack  definition  rolecommandorderjson  stack  level  example  hdp22rolecommandorderjson  service  definition  nicely  separated  different  directory  like  hdp22serviceshdfsyarn  rolecommandorder  would  neater  separate  rolecommandorder  per  service  would  useful  adding  new  service  ambari  looking  something  hdp22serviceshdfsrolecommandorderjson  hdp22servicesyarnrolecommandorderjson  ambari  server  starting  merge  rolecommandorderjson  create  dependency  accordingly  extremely  useful  custom  service  potentially  added  cluster  install,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5356,principal  creation  active  directory  account  configurable  property  used  create  account  active  directory  related  principal  creation  configurable  user  may  specify  required  field  value  variable  replacement  may  done  using  simple  structure  like  xml  json  however  template  facility  like  jinja2  may  useful  since  conditional  path  may  built  template  stored  kerberosenv  configuration  example  need  conditional  path  template  related  service  account  v  user  account  service  account  nnhostrealm  serviceprincipalname  field  set  service  principal  value  shouldnt  set  user  account  hdfsrealm,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5357,test  principal  keytab  required  service  check  created  part  kerberos  service  check  action  intercept  call  execute  servicecheck  kerberos  service  necessary  create  distribute  test  user  keytab  hard  coded  test  user  information  taken  smokeuser  identity  relevant  cluster  kerberos  descriptor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5358,view  min  max  version  add  support  including  optional  min  max  minmax  ambari  version  viewxml  include  exact  version  variable  example  minambariversion170minambariversion  minambariversion17minambariversion  maxambariversion1maxambariversion  deploy  ambari  validate  view  meet  minmax  specified  deploy  produce  error  log  detail  example  view  requires  minimum  ambari  version  17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5359,refactor  rolling  upgrade  prerequisite  check  expose  repackage  utility  class  logic  orgapacheambariserverstateupgradecheckhelper  exposed  resource  may  use  following  step  taken  move  static  class  orgapacheambariserverstateupgradecheckhelper  package  named  orgapacheambariserverchecks  rename  upgradecheckdescriptor  abstractcheckdescriptor  create  orgapacheambariservercheckscheckhelper  move  orgapacheambariserverstateupgradecheckhelperperformpreupgradechecks  adjust  orgapacheambariservercontrollerinternalpreupgradecheckresourceprovider  accordingly  upgradecheckrequest  upgradecheck  similar  resource  encapsulate  check  data  generalized  prereqcheckrequest  prerequisitecheck,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,1,0
5360,enable  flume  metric  sink  am  ambari  metric  need  able  collect  metric  flume  httpsgithubcomapacheflume  create  timelinemetricssink  class  implement  monitorservice  look  orgapacheflumeinstrumentationgangliaserver  configure  flume  ambari  metric  deployed  use  timelinemetricssink  classpath  httpflumeapacheorgflumeuserguidehtmlcustomreporting  look  support  get  query  flume  agent  stackshdp206servicesflumemetricsjson  user  unaware  group  name  channel  name  given  agent  key  point  store  appid  flume  allow  regex  query  get  api  example  flume  metric  look  like  agentnamegroupnamechannelnamemetricname  user  query  am  api  wwwmetricname  transforms  like  sql  clause  need  added  timeline  service  api  httpphoenixapacheorglanguageindexhtmlexpression,1,0,0,0,0,0,1,0,1,1,1,1,1,0,0,1,0
5361,add  support  add  host  specifying  host  name  blueprint  name  host  group  name  provide  higher  level  api  host  provisioning  api  accept  host  name  blueprint  name  host  group  result  api  call  fully  operational  host  added  existing  cluster  configuration  component  defined  specified  blueprinthostgroup  component  added  host  installed  started  host  must  reachable  via  ambari  server  ambari  agent  running  registered  ambari  server  prior  using  api  asynchronous  api  return  standard  asynchronous  response  code  202  accepted  href  httpambarihost8080apiv1clustersc1requests2  request  id  2  status  inprogress  code  api  support  adding  single  host  multiple  host  h4  single  host  code  post  httpambarihost8080apiv1clustersc1hostsnewhostnamedomain  blueprint  myblueprint  hostgroup  slave  code  h4  multiple  host  code  post  httpambarihost8080apiv1clustersc1hosts  blueprint  myblueprint  hostgroup  slave  hostname  host2domain  blueprint  myblueprint  hostgroup  slave  hostname  host5domain  code,1,0,1,0,1,0,0,0,0,0,1,0,1,0,0,0,0
5362,update  configurationresourceprovider  handle  kerberos  administrative  credential  special  case  certain  configuration  setting  need  handled  specialcase  scenario  example  shortlived  setting  stored  per  request  session  scope  secure  data  must  stored  ambari  database  example  type  data  administrative  credential  used  manage  kdc  server  configuration  data  short  lived  per  session  sensitive  therefore  must  handled  special  case  determine  configuration  request  contains  data  type  configuration  used  specific  case  configuration  type  kerberosadminidentity  trigger  special  case  secure  store  administrative  credential  file  ideally  session  data  available  see  ambari8426  sessionbased  encryption  key  would  created  stored  session  key  would  used  encrypt  data  request  encrypted  data  key  would  retrieved  session  decrypted  used  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5363,view  pig  ui  update  flow  change  popup  tab  name  script  name  script  scriptname  log  scriptname  completed  scriptname  result  use  capital  letter  tab  add  link  history  page  detail  popup  make  pig  editor  window  35  line  deep  v  current  20  “copy  created”  “copy  created”  “copy  created”  popup  change  “stay  continue  editing  check  go  copy”  “do  want  check  copy”  “nameofcopy  created  successfully”  note  spelling  successfully  move  “add”  button  next  text  input  field  script  page  change  “last  run”  “last  executed”  change  “last  run”  “last  results”  add  feature  backend  deleting  history  pig  script  execution  user  deletes  script  “script”  tab  greyed  tool  tip  available  “script”  tab  say  “the  script  deleted  longer  available”  history  table  order  show  recent  run  first  default,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
5364,provide  stage  resource  information  via  rest  api  currently  possible  query  ambari  via  rest  api  detail  asynchronous  request  related  task  useful  trying  obtain  progress  information  however  information  necessary  ui  indicate  meaningful  progress  available  information  related  stage  generated  note  asynchronous  request  broken  1  stage  stage  contains  1  task  stage  information  available  via  rest  api  would  possible  caller  maybe  ui  track  highlevel  task  stage  level  rather  lowerlevel  unit  work  task  level  allow  new  api  resource  associated  handler  need  created  resource  readonly  like  request  task  provide  information  stored  stage  table  ambari  database  following  property  returned  stage  stageid  requestid  clusterid  requestcontext  probably  renamed  something  appropriate  like  stagecontext  stagename  etc  starttime  endtime  progresspercent  status  expected  resource  would  queried  using  code  get  apiv1clustersclusteridrequestsrequestidstages  code  also  subset  stage  data  provided  querying  detail  specific  request  like  code  get  apiv1clustersclusteridrequestsrequestid  code  see  request  task  resource  example,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5365,create  ability  disable  protocol  http  connection  ambari  create  ability  disable  protocol  http  connection  ambari  port  patch  ear660  170  trunk,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5366,implement  logic  ambari  support  common  service  implement  logic  ambari  support  common  service  see  design  discussed  ambari7201,0,0,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1
5367,view  capscheduler  service  endpoint  operator  expose  endpoint  operator  setting  cleanup  unused  code  upd  version  020,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5368,include  configuration  exported  blueprint  include  host  group  cluster  scoped  configuration  exported  blueprint  export  blueprint  use  api  ambarihost8080apiv1clustersclusternameformatblueprint  exported  blueprint  contain  entire  configuration  associated  cluster  property  included  marked  input  required  stack  password  marked  required  exported  also  hostnames  configuration  property  replaced  hostgroup  token  hostgroupgroup1  cluster  provisioned  blueprint  hostgroup  token  resolved  host  name  target  cluster,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,1,1
5369,freeipa  support  ambari  freeipa  powerful  tool  unifying  identity  kerberos  credential  across  cluster  great  value  add  ambari  would  provide  support  using  freeipa  kerberize  service  would  allow  1  better  hcfs  interoperability  first  class  giduid  critical  certain  file  system  glusterfs  lustre  file  system  us  kernel  fuse  apis  determining  identity  2  better  enterprise  interoperability  fact  freeipa  make  easy  interop  different  identity  solution  like  active  directory  would  make  ambari  easier  adopt  various  enterprise  3  broadens  ambaris  scope  ambari  could  also  allow  people  setup  user  cluster  least  security  feature  cluster  one  interface  manual  handling  tgts  could  done  quite  easily  via  ambari  ui  could  make  call  underlying  freeipa  client,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5370,define  component  term  xml  define  component  term  xml  rather  java  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5371,view  pig  property  checking  log  explicit  failure  incorrectly  set  property  pig  view  obviously  cant  use  view  error  cryptic,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5372,customize  hadoop  metric  sink  write  mysql  store  sqlserversink  support  pushing  metric  mysql  store  jira  address  change  needed  support  sink  mysql  store,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5373,call  fetch  metric  take  20  second  cpu  consumed  nagiospropertyprovider  jmxpropertyprovider  jmxpropertyprovider  execution  confighelperisstaleconfigs  take  1015  time  isstale  could  easily  cached  guava  cache  isstale  may  changed  4  case  1  configuration  change  2  configgroup  createddeleted  3  startrestart  report  receiving  4  host  registeration  could  invalidate  appropriate  recorrd  cache  point  api  call  code  httpserver8080apiv1clustersc1componentsservicecomponentinfocategorymasterfieldsservicecomponentinfoversionservicecomponentinfostarttimeservicecomponentinfoheapmemoryusedservicecomponentinfoheapmemorymaxservicecomponentinfoservicenamehostcomponentshostroleshostnamehostcomponentshostrolesstatehostcomponentshostrolesmaintenancestatehostcomponentshostrolesstaleconfigshostcomponentsmetricsjvmmemheapusedmhostcomponentsmetricsjvmheapmemorymaxhostcomponentsmetricsjvmheapmemoryusedhostcomponentsmetricsjvmmemheapcommittedmhostcomponentsmetricsmapredjobtrackertrackersdecommissionedhostcomponentsmetricscpucpuwiohostcomponentsmetricsrpcrpcqueuetimeavgtimehostcomponentsmetricsdfsfsnamesystemhostcomponentsmetricsdfsnamenodeversionhostcomponentsmetricsdfsnamenodedecomnodeshostcomponentsmetricsdfsnamenodetotalfileshostcomponentsmetricsdfsnamenodeupgradefinalizedhostcomponentsmetricsdfsnamenodesafemodehostcomponentsmetricsruntimestarttimehostcomponentsmetricshbasemasterisactivemasterservicecomponentinfomasterstarttimeservicecomponentinfomasteractivetimeservicecomponentinfoaverageloadservicecomponentinforevisionservicecomponentinforegionsintransitionmetricsapiclustersummaryhostcomponentsmetricsyarnqueueservicecomponentinformmetricsclusteractivenmcountservicecomponentinformmetricsclusterunhealthynmcountservicecomponentinformmetricsclusterrebootednmcountservicecomponentinformmetricsclusterdecommissionednmcountminimalresponsetrue1400808845240  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5374,provide  topology  validation  creating  blueprint  provide  topology  validation  blueprint  created  topology  validated  based  dependency  cardinality  information  provided  associated  ambari  stack  definition  addition  validation  component  mostly  client  autodeployed  present  topology  behavior  specified  corresponding  stack  topology  validation  fails  400  response  returned  descriptive  message  code  status  400  message  cluster  topology  validation  failed  invalid  service  component  count  mysqlserveractual0  required1  hivemetastoreactual0  required1  hiveserveractual0  required1  disable  topology  validation  create  blueprint  add  following  end  url  validatetopologyfalse  code  create  blueprint  doesnt  validate  user  disable  topology  validation  url  via  validatetopologyfalse  following  case  currently  supported  blueprint  topology  validation  require  user  disable  validation  creating  blueprint  external  reference  mysqlserver  hivemetastore  ha  topology  1  nn  1snn  topology  default  cardinality  conditional  topology  information  ha  one  example,1,0,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0
5375,moving  cluster  node  container  object  controller  moving  cluster  node  container  object  controller  currently  part  cliententities,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
5376,provide  ability  rebalance  hdfs  use  case  example  put  cluster  maintenance  add  5  node  hit  rebalance  take  maintenance  rebalance  optionally  allow  user  override  threshold  percentage  value,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5377,validate  required  field  including  password  blueprint  cluster  creation  blueprint  creation  validate  nonpassword  required  property  set  blueprint  cluster  creation  via  blueprint  validate  required  password  property  set  configuration  defaultpassword  property  included  request  password  property  set  blueprint  cluster  host  group  configuration  part  cluster  create  call  either  cluster  host  group  property,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5378,provide  basic  validation  field  blueprint  create  api  task  non  topology  related  validation  blueprint  create  api  call  following  validation  included  blueprint  name  host  group  host  group  name  host  group  component  component  specified  name  invalid  component  name  stack  noinvalid  stack  name  noinvalid  stack  version  validation  failure  result  400  response  descriptive  message  problem,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5379,add  dependency  related  information  stack  rest  api  added  dependency  related  information  stack  rest  api  information  describes  dependency  component  part  stack  new  dependency  resource  added  child  stacksservicesservicecomponent  soon  renamed  servicescomponent  resource  example  get  http1721819238080apiv1stackshdpversions133stackserviceshbaseservicecomponentshbasemasterfieldsdependencies  code  href  http1721819238080apiv1stackshdpversions133stackserviceshbaseservicecomponentshbasemasterfieldsdependencies  stackservicecomponents  componentname  hbasemaster  servicename  hbase  stackname  hdp  stackversion  133  dependency  href  http1721819238080apiv1stackshdpversions133stackserviceshbaseservicecomponentshbasemasterdependencieshdfsclient  dependency  componentname  hdfsclient  dependentcomponentname  hbasemaster  dependentservicename  hbase  scope  host  servicename  hdfs  stackname  hdp  stackversion  133  autodeploy  enabled  true  href  http1721819238080apiv1stackshdpversions133stackserviceshbaseservicecomponentshbasemasterdependencieszookeeperserver  dependency  componentname  zookeeperserver  dependentcomponentname  hbasemaster  dependentservicename  hbase  scope  cluster  servicename  zookeeper  stackname  hdp  stackversion  133  autodeploy  enabled  true  location  hbasehbasemaster  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
5380,allow  host  group  scoped  configuration  specified  blueprint  allow  configuration  specified  host  group  configuration  provide  override  host  assigned  host  group  configuration  specified  inline  within  host  group  example  simple  one  host  group  blueprint  cluster  scoped  host  group  scoped  configuration  code  configuration  coresite  fstrashinterval  480  ipcclientidlethreshold  8500  myawesomeproperty  excellent  mapredsite  tasktrackerhttpthreads  45  hostgroups  name  hostgroup1  configuration  coresite  fstrashinterval  475  component  name  hdfsclient  name  gangliaserver  name  ambariserver  name  mapreduceclient  name  gangliamonitor  name  datanode  name  namenode  name  jobtracker  name  historyserver  name  secondarynamenode  name  nagiosserver  name  tasktracker  cardinality  1  blueprint  blueprintname  singlenodetest  stackname  hdp  stackversion  133  code  note  allowing  service  configuration  specified  external  host  group  definition  allow  configuration  reuse  across  host  group  handled  subsequent  jira,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
5381,allow  custom  configuration  property  specified  blueprint  allow  user  specify  custom  property  blueprint  ui  currently  allows  custom  property  set  eventually  exported  blueprint  currently  property  blueprint  isnt  specified  stack  configuration  ignored,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5382,provision  cluster  ambari  blueprint  allow  cluster  fully  provisioned  via  ambari  rest  api  single  rest  api  call  specifying  blueprint  name  mean  single  simple  asynchronous  rest  api  call  cluster  provisioned  initstarted  process  provision  cluster  via  rest  api  using  blueprint  follows  create  blueprint  resource  instance  ambari  instance  going  used  provision  cluster  blueprint  may  hand  created  exported  running  cluster  post  myambariserver8080apiv1blueprintssinglenodetest  code  hostgroups  name  hostgroup1  component  name  historyserver  name  jobtracker  name  namenode  name  oozieserver  name  nagiosserver  name  secondarynamenode  name  ambariserver  name  gangliaserver  name  gangliamonitor  name  datanode  name  tasktracker  name  hdfsclient  name  mapreduceclient  name  oozieclient  name  gangliamonitor  cardinality  1  blueprint  blueprintname  singlenodetest  stackname  hdp  stackversion  133  code  information  exporting  blueprint  see  httpsissuesapacheorgjirabrowseambari4786  information  blueprint  resource  see  httpsissuesapacheorgjirabrowseambari4467  invoke  post  cluster  endpoint  specify  blueprint  related  information  host  information  must  provided  host  group  deployed  cluster  host  specified  run  component  associated  host  group  host  group  name  specified  request  must  match  host  group  specified  blueprint  post  myambariserver8080apiv1clustersc1  code  blueprint  singlenodetest  hostgroups  name  hostgroup1  host  fqdn  myhostnovalocal  ip  172181923  code  call  asynchronous  return  information  used  check  status  request  code  202  accepted  href  httpyourambariserverapiv1clustersc1requests1  request  id  1  status  inprogress  code  limitation  change  addressed  shortly  patch  configuration  information  included  blueprint  processed  meaning  cluster  provisioned  default  configuration  ambari  agent  must  running  registered  server  host  cluster  prior  invoking  rest  api  provision  cluster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5383,add  ability  export  blueprint  running  cluster  export  blueprint  running  cluster  using  alternate  rendering  cluster  resource  apiv1clustersc1formatblueprint  change  blueprint  minimal  contain  node  group  configuration  subsequent  patch  introduce  configuration  cluster  data  code  hostgroups  name  hostgroup1  component  name  historyserver  name  oozieclient  name  jobtracker  name  namenode  name  oozieserver  name  tasktracker  name  nagiosserver  name  secondarynamenode  name  mapreduceclient  name  ambariserver  name  gangliaserver  name  hdfsclient  name  datanode  name  gangliamonitor  cardinality  1  blueprint  blueprintname  blueprintc1  stackname  hdp  stackversion  133  code,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0
5384,add  stack  extension  support  pluggable  service  h1  proposal  inheritance  rule  schema  ver  20  service  metainfo  h2  package  repository  information  perstack  repository  information  subject  stack  extension  done  time  osspecifics  section  containing  perservice  repo  package  description  present  metainfo  inherited  service  completely  override  appropriate  information  parent  service  deletion  inherited  osspecifics  section  possible  make  sense  service  able  install  h2  command  script  custom  command  command  script  definition  child  override  parent  command  script  definition  custom  command  script  definition  child  override  parent  custom  command  script  definition  command  name  h2  hook  script  file  template  allow  reusing  python  script  template  parent  stack  limitation  full  package  directory  may  overridden  implementation  resolving  hook  pretty  similar  done  reading  stack  startup  ambariserver  determines  service  folderspackage  foldershooks  folder  missing  inherited  parent  appropriately  adjusts  serviceinfo  sending  execution  command  server  populates  servicemetadatafolder  hooksfolder  variable  located  commandparams  section  appropriate  path  h2  done  separate  jiras  complete  list  stack  extension  functionality  scope  current  jira  please  feel  free  append  perfile  override  script  template  get  list  stack  search  path  server  look  every  file  running  via  pythonexecutor  hook  script  command  script  template  file  list  stack  starting  child  stack  file  imported  scrip  using  import  statement  overridden  maybe  packaging  file  downloaded  agent  tar  file  every  stack  exist  packagetar  file  one  per  service  one  hookstar  file  one  per  stack  every  file  separate  download  unit  exposing  file  server  agent  resolving  authentification  issue  stack  cache  management  downloading  stack  server  agent  first  use  cache  invalidation  proposed  stack  extension  rule  child  stack  metainfo  lightweight  enough  case  minor  change  like  adjusting  repository  information  package  name  editing  file  template,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5385,run  various  request  parallel  one  wait  run  stage  belong  different  request  affect  different  set  host  parallel  one  wait  example  startingstopping  component  different  host  done  parallel  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5386,create  new  stack  gluster  support  132  hdp  version  feature  extends  ability  ambari  support  hadoop  compatible  file  system  outside  hdfs  stack  definition  introducing  use  glusterfs  provides  good  road  map  hadoop  compatible  file  system  also  able  leverage  ambari  featurepatch  remove  hdfs  patch  simply  provides  alternative  selecting  service  within  installer,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5387,extending  stack  definition  remove  duplication  stack  metadata  info  idea  allow  extending  stack  definition  overriding  value  current  stack  definition  structure  file  directory  noformat  stack  distname  versionnumber  metainfoxml  repos  repoinfoxml  service  servicename  metainfoxml  configuration  configuration  file  noformat  introduce  extends  element  top  level  stack  version  level  link  parent  stack  definition  stack  version  rule  extension  1  parent  stack  service  automatically  part  child  stack  unless  explicitly  excluded  2  one  parent  stack  extended  child  stack  3  stacksdistnamereposrepoinfoxml  overridden  4  service  configuration  unless  explicitly  excluded  part  child  service  definition  1  extending  stack  definition  file  stacksdistnameversionnumbermetainfoxml  eg  stackshdp131metainfoxml  noformat  metainfo  version  upgrade120upgrade  version  activetrueactive  extends130extends  metainfo  noformat  2  extending  service  definition  stacksdistnameversionnumberservicenamemetainfoxml  eg  stackshdp121serviceshdfsmetainfoxml  noformat  metainfo  userrootuser  commentapache  hadoop  distributed  file  systemcomment  version112version  deletedfalsedeleted  metainfo  noformat  21  extending  component  definition  component  added  deleted  stack  noformat  component  nameyarnclientname  categoryclientcategory  deletedtruedeleted  component  noformat  3  extending  service  configuration  file  stacksdistnameversionnumberservicenameconfigurationconfigurationfile  eg  stackshdp131serviceshdfsconfigurationhdfssitexml  noformat  configuration  property  namedfsnamedirname  deletedtruedeleted  property  configuration  noformat  note  property  disappear  reappear  extension  graph  noformat  130  131  132  135  b  c  c  noformat,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5388,allow  skipping  part  add  service  request  validation  provide  ability  disable  part  validation  add  service  request  eg  configuration  validation  topology  validation  part  still  need  validated  eg  probably  make  sense  add  unknown  service,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5389,cleanup  rest  entity  want  clean  configuration  entity  streamline  xmljson  representation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5390,improve  add  service  request  validation  improve  request  validation  add  service  request  eg  reject  request  add  existing  service,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
5391,add  am  metric  publisher  infra  solr,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5392,rename  agent  rest  url  agent  public  rest  api  rest  separating  public  api  private  api  may  best  rename  v1  agent  rest  respectively,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
5393,add  ability  masterhostresolver  resolve  namespace  time  upgrade  behavior  figure  restart  order  namenodes  need  become  namespace  aware  support  nn  federation  ambari,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5394,infra  manager  define  scheduling  archiving  infra  solr  document,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1
5395,add  new  ambari  infra  manager  component  ambari  infra  stack,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5396,show  onefs  jmx  metric  ui  metric  like  namenode  uptimestarttime  hdfs  disk  usagecapacity  cannot  shown  widget  widget  support  am  based  metric  normally  metric  shown  service  specific  dashboard  hardcoded  ui  summaryjsservicecustomviewsmap  code  servicecustomviewsmap  function  return  hbase  appmaindashboardservicehbaseview  hdfs  appmaindashboardservicehdfsview  storm  appmaindashboardservicestormview  yarn  appmaindashboardserviceyarnview  ranger  appmaindashboardservicerangerview  flume  appmaindashboardserviceflumeview  hive  appmaindashboardservicehiveview  propertyservicename  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5397,infra  manager  hdfs  upload  support  archiving  infra  solr  upload  exported  document  infa  solr  specified  hdfs  server  hdfs  configuration  defined  ambariinframanagerproperties  file  job,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5398,infra  manager  scheduled  deleting  infra  solr  document  delete  document  infra  solr  specified  interval  also  archiving  mode  delete  document  successfully  exported  uploaded,1,0,1,0,1,0,1,1,1,0,1,0,1,0,0,1,1
5399,service  able  implement  server  action  package  add  jar  loaded  eu  xsitypeserveraction  task  defined  euru  upgrade  pack  xml  file  currently  class  ambari  source  code  limites  server  action  custom  service  service  mpacks  perform  jira  proposes  way  allow  service  implement  server  action  class  package  jar  loaded  eu  1  service  serveractions  support  stack  inheritance  varlibambariserverresourcesstackshdp25serviceszookeeperserveractions  dir  contains  jar  server  action  class  varlibambariserverresourcesstackshdp25serviceszookeeperserveractions  root  serveractions  total  8  rwrr  1  root  root  7510  oct  30  1049  testfulljar  2  upgrade  pack  invoke  server  action  shown  server  action  test  without  specifying  service  execution  stage  group  xsitypecluster  nametesta  titletest  abc  executestage  titleaaaa  task  xsitypeserveraction  classorgapacheambariserverserveractionupgradessatestwithoutservice  executestage  group  server  action  test  service  specified  execution  stage  executestage  servicezookeeper  componentzookeeperserver  titleparame  terizing  zookeeper  log4j  property  task  xsitypeserveraction  classorgapacheambariserverserveractionupgradessatestwithservice  summaryzkpr  testsummary  task  executestage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5400,able  switch  extension  version  stack  version  linked  currently  way  switch  extension  version  stack  version  linked  perform  following  action  stop  extension  service  reregister  delete  extension  service  unlink  old  extension  version  link  new  extension  version  add  extension  service  back  rest  api  allow  u  update  action  extension  link  manner  running  upgrade  hdp  261  263  something  similar  use  hdp  26  stack  version  could  perform  extension  link  switch  manual  step  upgrade  process,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5401,log  search  config  separated  server  log  feeder  interface  log  search  config  getting  complex  serf  many  kind  thing  separated  two  interface  one  server  one  log  feeder  make  cleaner,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1
5402,log  feeder  property  handled  one  class  log  feeder  property  scattered  code  documentation  putting  large  block  code  several  class  instead  handled  one  class  together  documentation  default  value  rest  class  asking  one  value,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5403,log  search  solr  output  property  provided  config  api  solr  output  property  persisted  config  api  log  search  server  output  initialized  fetched  log  feeder,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5404,create  new  rest  resource  handling  ldap  possibly  ambari  configuration  develop  support  handling  ldap  possibly  ambari  ralated  configuration  rest  resource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5405,add  kerberos  http  spnego  authentication  support  accumulo  subtask  ambari14384  ambari  metric  doesnt  use  spnego  authenticate  kerberos  enabled  cluster  spnego  enabled  hadoop  apis  ambari  metric  collector  webconsole  kerberos  http  spnego  enabled  accumulo  sink  client  ambari  metric  collector  currently  support  kerberos  http  spnego  authentication  eg  varlogaccumulotservertserverhostdebuglog  20170606  230739918  timelinehadooptimelinemetricssink  info  received  wwwauthentication  headernegotiate  url  httpmetricscollectorhost6188wsv1timelinemetrics  20170606  230739927  timelinehadooptimelinemetricssink  info  live  collector  send  metric  metric  sent  discarded  message  skipped  next  20  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5406,change  storage  data  requeststagetask  reduce  redundency  trunk  move  stageclusterhostinfo  requestclusterhostinfo,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
5407,log  search  use  pojos  input  configuration  instead  parsing  input  configuration  jsons  logfeeder  configuration  api  return  pojos  input  filter  description,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,1
5408,allow  extension  autolink  supported  stack  version  would  possible  link  extension  supported  stack  version  parsing  stack  extension  commonservices  directory  would  allow  extension  avoid  making  rest  api  call  set  link,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5409,add  log  level  filter  log  search  config  api,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,1,0
5410,support  removal  pending  host  request  topologyrequest  blueprint  deployment  supported  specify  host  predicate  host  count  control  host  many  host  automatically  join  host  group  case  later  decided  le  host  used  host  group  thus  host  le  original  host  count  provisioned  currently  way  remove  pending  host  request  created  host  never  joined  cluster  actually  reducing  host  count  host  group,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5411,host  tab  clicking  red  badge  toggle  alert  filter  clicking  red  badge  host  tab  toggle  alert  filter  host  page  clicking  anywhere  host  tab  go  host  page  selected,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5412,change  hoststackversionresourceprovider  able  install  package  single  host  belonging  cluster  improvement  create  possibility  preinstalling  package  host  host  added  cluster  given  stack  component  new  request  parameter  component  added  hoststackversionresourceprovider  able  pas  list  component  want  install  package,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5413,allow  acceptor  seclector  configuration  api  agent  connector  objective  allow  acceptor  agent  api  connector  configurable  thread  pool  configuration  take  account  2way  1way  connector  configured  agent  every  time  although  one  used  mixedmode  cause  insufficient  thread  agent  threadpool  high  cpu  core  environment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5414,rolling  restart  datanode  cluster  name  show  null  rolling  restart  service  egdatanode  cluster  name  audit  log  show  null  20160913t1729220330800  useradmin  remoteip127001  operationrequest  server  requesttypepost  urlhttplocalhost8080apiv1clustersamabrirequests  resultstatus202  accepted  commandrestart  cluster  namenull  20160913t1729220420800  useradmin  operationparserollingrestartdatanode11  statusinprogress  requestid15,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5415,ambari  server  work  mysql  oracle  ambari  server  data  might  stored  ambari  server  work  mysql  oracle  ambari  server  data  might  stored  need  create  ddl  script  setup  already  running  mysql  serveroracle  server  ambari  server  need  configured  use  right  adaptor  connecting  either  mysql  oracle,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5416,provide  support  s3  first  class  destination  log  event  ambari17045  added  support  uploading  hadoop  service  log  machine  s3  intended  usage  one  time  trigger  ondemand  log  file  matching  certain  path  uploaded  given  s3  bucket  path  useful  use  case  might  need  one  time  activity  particularly  cluster  deployed  ephemeral  machine  cloud  instance  machine  running  logfeeder  could  irrevocably  lost  case  would  able  retrieve  log  copying  log  one  time  generated  long  period  time  time  copy  log  end  could  extend  cluster  uptime  cost  would  nice  ability  support  s3  another  output  destination  logsearch  like  kafka  solr  etc  jira  track  work  towards  enhancement,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5417,controller  mark  node  unhealthy  upon  command  execution  failure  ambari171  handle  retries  command  agent  side  jira  make  controller  aware  node  repeated  try  command  execution  failed  mark  node  unhealthy  node  put  back  healthy  state  agent  restarted,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5418,add  ability  start  stop  service  service  page,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5419,fix  misnamed  zookeeper  connect  string  log  search  variablesproperties  holding  zookeeper  connect  string  misnamed  zkhost  zkhosts  may  misleading  variable  property  name  fixed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5420,support  loading  log  s3  upload  log  s3  archived  analyzed  offline,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5421,implement  am  collector  batch  insert  operation  amshbase  check  performance  boost  replacing  insert  operation  bulk  loading  yes  implement  provide  switch  property  enablingdisabling  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5422,ambari  suspend  alert  notification  upgrade  ambari  report  alert  trigger  notification  stack  upgrade  case  alert  notification  suppressed  upgrade  prevent  false  positive  however  alert  dont  related  cluster  remain  fully  operational  host  disk  space  upgrade  finalized  ambari  server  performance,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5423,provide  ability  pas  jpa  eclipselink  property  datasource  currently  way  pas  jpa  eclipselink  specific  connectiondatasource  property  ambariproperties  although  exists  configurationgetdatabasecustomproperties  actually  driver  specific  property  property  eclipselink  example  wanted  pas  jdbc  driver  foobar  could  set  serverjdbcpropertiesfoobar  get  translated  eclipselinkjdbcpropertyfoobar  however  wanted  set  eclipselink  jpa  specific  datasource  property  see  httpwwweclipseorgeclipselinkapi26orgeclipsepersistenceconfigpersistenceunitpropertieshtml  would  able  proposal  add  something  similar  custom  driver  property  code  serverpersistencepropertieseclipselinkjdbcbatchwritingsize25  code  could  get  translated  code  propertiesputeclipselinkjdbcbatchwritingsize  25  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5424,incremental  change  logsearch  bring  date  trunk  initial  logsearch  commit  change  included  jira  track  addition  item  1  use  standard  tokenizer  indexing  2  configuring  log  level  filter  logfeeder  3  tab  graph  clean,1,0,1,0,1,0,0,0,0,0,1,1,0,0,0,1,1
5425,automate  creation  ambari  server  proxy  user  securenonsecure  cluster  principal  keytab  setup  jaas  secure  cluster  aim  improvement  automate  following  creation  proxy  user  ambari  server  necessary  view  file  hive  pig  tez  etc  creation  ambari  server  principal  keytab  setup  jaas  currently  manual  step  documented  httpdocshortonworkscomhdpdocumentsambari2100bkambarisecurityguidecontentoptionalsetupkerberosforambariserverhtml  case  non  secure  cluster  ambari  proxy  user  set  user  account  ambari  server  running  specified  ambariserverproperties  ambariserveruser  adjusted  running  ambariserver  setup  stackadvisor  responsible  configuring  proxy  user  secure  nonsecure  cluster  wizard  blueprint  based  deployment  therefore  case  blueprint  based  deployment  proxy  user  created  configrecommendationstrategy  alwaysapply  cluster  template  following  proxy  user  configured  stackadvisor  code  hadoopproxyuserambariproxyusergroups  hadoopproxyuserambariproxyuserhosts  hadoopproxyuserhcatgroups  hadoopproxyuserhcathosts  webhcatproxyuserambariproxyusergroups  webhcatproxyuserambariproxyuserhosts  yarntimelineservicehttpauthenticationproxyuserambariproxyuserhosts  yarntimelineservicehttpauthenticationproxyuserambariproxyuserusers  yarntimelineservicehttpauthenticationproxyuserambariproxyusergroups  code  secure  eg  securitytypekerberos  cluster  proxy  user  setup  based  ambari  server  principal  new  identity  ambariserver  added  default  kerberos  descriptor  principal  name  specified  modified  either  kerberos  setup  wizard  screen  submitting  custom  kerberos  descriptor  blueprint  case  default  principal  name  codeambariserverclusternamerealmcode  generate  principal  keytab  set  jaas  configuration  file  generation  ambari  server  principal  keytab  enabled  disabled  setting  config  property  createambariprincipal  true  false  kerberosenv  config  create  ambari  principal  keytab  keberos  setup  wizard  screen  enabled  default  new  functionality  kerberos  related  handling  configuration  recommended  stackadvisor  property  marked  delete  flag  stackadvisor  removed  configuration  running  enable  kerberos  wizard  necessary  able  remove  old  ambari  proxy  user  nonsecure  mode  scenario  multiple  ambari  server  managing  single  cluster  operation  master  ambari  server  affected  ambari  server  instance  need  manually  updated  meaning  ambari  server  keytab  file  need  manually  distributed  ambari  server  host  also  ambari  server  jaas  file  need  manually  updated  either  editing  etcambariserverconfkrb5jaasloginconf  file  executing  ambariserver  setupsecurity  selecting  option  3  setup  ambari  kerberos  jaas  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5426,ambari  ldap  integration  cannot  handle  ldap  directory  multiple  entry  user  problem  case  ldap  set  multiple  domain  joined  forrest  trust  different  domain  user  may  appear  different  location  ldap  since  user  want  access  ambari  domain  ambari  search  whole  forrest  user  appearing  multiple  domain  identical  ambari  cannot  filter  one  user  entry  lead  following  error  message  try  login  ambari  one  user  multiple  entry  code  servlethandler563  apiv1usersusername  orgspringframeworkdaoincorrectresultsizedataaccessexception  incorrect  result  size  expected  1  actual  2  orgspringframeworksecurityldapspringsecurityldaptemplatesearchforsingleentryinternalspringsecurityldaptemplatejava243  orgspringframeworksecurityldapspringsecurityldaptemplate3executewithcontextspringsecurityldaptemplatejava198  orgspringframeworkldapcoreldaptemplateexecutewithcontextldaptemplatejava807  orgspringframeworkldapcoreldaptemplateexecutereadonlyldaptemplatejava793  orgspringframeworksecurityldapspringsecurityldaptemplatesearchforsingleentryspringsecurityldaptemplatejava196  orgspringframeworksecurityldapsearchfilterbasedldapusersearchsearchforuserfilterbasedldapusersearchjava116  orgspringframeworksecurityldapauthenticationbindauthenticatorauthenticatebindauthenticatorjava90  orgapacheambariserversecurityauthorizationambarildapbindauthenticatorauthenticateambarildapbindauthenticatorjava53  orgspringframeworksecurityldapauthenticationldapauthenticationproviderdoauthenticationldapauthenticationproviderjava178  orgspringframeworksecurityldapauthenticationabstractldapauthenticationproviderauthenticateabstractldapauthenticationproviderjava61  orgapacheambariserversecurityauthorizationambarildapauthenticationproviderauthenticateambarildapauthenticationproviderjava60  orgspringframeworksecurityauthenticationprovidermanagerauthenticateprovidermanagerjava156  orgspringframeworksecurityauthenticationprovidermanagerauthenticateprovidermanagerjava174  orgspringframeworksecuritywebauthenticationwwwbasicauthenticationfilterdofilterbasicauthenticationfilterjava168  orgspringframeworksecuritywebfilterchainproxyvirtualfilterchaindofilterfilterchainproxyjava342  orgspringframeworksecuritywebcontextsecuritycontextpersistencefilterdofiltersecuritycontextpersistencefilterjava87  orgspringframeworksecuritywebfilterchainproxyvirtualfilterchaindofilterfilterchainproxyjava342  orgspringframeworksecuritywebfilterchainproxydofilterinternalfilterchainproxyjava192  orgspringframeworksecuritywebfilterchainproxydofilterfilterchainproxyjava160  orgspringframeworkwebfilterdelegatingfilterproxyinvokedelegatedelegatingfilterproxyjava237  orgspringframeworkwebfilterdelegatingfilterproxydofilterdelegatingfilterproxyjava167  orgeclipsejettyservletservlethandlercachedchaindofilterservlethandlerjava1467  orgapacheambariserverapimethodoverridefilterdofiltermethodoverridefilterjava72  orgeclipsejettyservletservlethandlercachedchaindofilterservlethandlerjava1467  orgapacheambariserverapiambaripersistfilterdofilterambaripersistfilterjava47  orgeclipsejettyservletservlethandlercachedchaindofilterservlethandlerjava1467  orgeclipsejettyservletsuseragentfilterdofilteruseragentfilterjava82  orgeclipsejettyservletsgzipfilterdofiltergzipfilterjava294  orgeclipsejettyservletservlethandlercachedchaindofilterservlethandlerjava1467  orgeclipsejettyservletservlethandlerdohandleservlethandlerjava501  orgeclipsejettyserverhandlerscopedhandlerhandlescopedhandlerjava137  orgeclipsejettysecuritysecurityhandlerhandlesecurityhandlerjava557  orgeclipsejettyserversessionsessionhandlerdohandlesessionhandlerjava231  orgeclipsejettyserverhandlercontexthandlerdohandlecontexthandlerjava1086  orgeclipsejettyservletservlethandlerdoscopeservlethandlerjava429  orgeclipsejettyserversessionsessionhandlerdoscopesessionhandlerjava193  orgeclipsejettyserverhandlercontexthandlerdoscopecontexthandlerjava1020  orgeclipsejettyserverhandlerscopedhandlerhandlescopedhandlerjava135  orgapacheambariservercontrollerambarihandlerlistprocesshandlersambarihandlerlistjava209  orgapacheambariservercontrollerambarihandlerlistprocesshandlersambarihandlerlistjava198  orgapacheambariservercontrollerambarihandlerlisthandleambarihandlerlistjava132  orgeclipsejettyserverhandlerhandlerwrapperhandlehandlerwrapperjava116  orgeclipsejettyserverserverhandleserverjava370  orgeclipsejettyserverabstracthttpconnectionhandlerequestabstracthttpconnectionjava494  orgeclipsejettyserverabstracthttpconnectionheadercompleteabstracthttpconnectionjava971  orgeclipsejettyserverabstracthttpconnectionrequesthandlerheadercompleteabstracthttpconnectionjava1033  orgeclipsejettyhttphttpparserparsenexthttpparserjava644  orgeclipsejettyhttphttpparserparseavailablehttpparserjava235  orgeclipsejettyserverasynchttpconnectionhandleasynchttpconnectionjava82  orgeclipsejettyionioselectchannelendpointhandleselectchannelendpointjava696  orgeclipsejettyionioselectchannelendpoint1runselectchannelendpointjava53  orgeclipsejettyutilthreadqueuedthreadpoolrunjobqueuedthreadpooljava608  orgeclipsejettyutilthreadqueuedthreadpool3runqueuedthreadpooljava543  javalangthreadrunthreadjava745  code  solution  ldap  search  upon  login  ambari  lead  multiple  match  user  match  due  user  appears  multiple  domain  show  error  message  user  prompting  providing  domain  well  login  eg  login  failed  please  append  domain  username  try  example  usernamedomain  user  provides  domain  information  login  well  ambari  look  user  ldap  using  different  filter  configurable  configuration  set  ambari  default  filter  userprincipalname,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5427,custom  service  need  way  integrate  upgrade  process  currently  upgrade  defined  series  xml  file  specific  current  stack  version  target  stack  version  upgrade  xml  defines  overall  sequence  upgrade  need  done  service  custom  service  need  able  specify  upgrade  process  step  fit  upgrade  process,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5428,introduce  configuration  file  introduce  configuration  file  allows  user  pick  data  store  implementation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
5429,decrease  load  ambari  database  cluster  creation  decrease  load  generated  query  periodically  executed  cluster  creation  query  executed  frequently  code  select  t0serviceconfigid  t0clusterid  t0createtimestamp  t0groupid  t0note  t0servicename  t0username  t0version  t0stackid  serviceconfig  t0  t0clusterid  p0  t0createtimestamp  select  maxt1createtimestamp  serviceconfig  t1  t1servicename  t0servicename  t1clusterid  p1  t1groupid  null  code  code  select  maxt0skippable  mint1starttime  maxt1endtime  t1stageid  sumcase  t1status  p0  p1  else  p2  end  sumcase  t1status  p3  p4  else  p5  end  sumcase  t1status  p6  p7  else  p8  end  sumcase  t1status  p9  p10  else  p11  end  sumcase  t1status  p12  p13  else  p14  end  sumcase  t1status  p15  p16  else  p17  end  sumcase  t1status  p18  p19  else  p20  end  sumcase  t1status  p21  p22  else  p23  end  sumcase  t1status  p24  p25  else  p26  end  sumcase  t1status  p27  p28  else  p29  end  sumcase  t1status  p30  p31  else  p32  end  stage  t0  hostrolecommand  t1  t0stageid  t1stageid  t0requestid  t1requestid  group  t1requestid  t1stageid  t1requestid  p33  code  code  select  distinct  t0taskid  hostrolecommand  t0  host  t1  t1hostname  p0  t0role  p1  t0status  p2  t1hostid  t0hostid  order  t0taskid  code  code  select  distinct  taskid  hostrolecommand  role  p0  status  p1  order  taskid  code  code  select  counttaskid  hostrolecommand  status  p0p1p2p3p4p5  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5430,simplify  state  controller  state  machine  state  redundant  stopped  state  also  state  transition  end  dead  end,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5431,provide  metric  discovery  api  am  quotewsv1timelinemetricsmetadataquote  endpoint  provides  json  data  representing  metric  metadata  metric  ever  received  am  groupbed  appid  sent  metric  quotewsv1timelinemetricshostsquote  endpoint  provides  json  data  representing  host  along  apps  reported  metric,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5432,investigate  implement  guice  statemachineinvoker  think  thought  put  guice  applied  statemachineinvoker  aid  testability  id  also  like  remove  static  datastructures  since  make  difficult  use  class  unit  test,0,1,0,1,0,0,0,0,1,0,1,0,0,0,0,0,1
5433,create  stack  flattener  need  able  flatten  inheriting  stack  single  stack  also  generates  whole  configuration  role  including  client  role,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5434,refactor  collector  logging  am  current  aggregator  log  hard  read  since  log  print  class  name  sufficiently  indicate  aggregator  thread  responsible  message,1,0,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0
5435,improve  job  diagnostics  number  improvement  id  like  make  job  diagnostics  including  allowing  zooming  job  swimlane  timeline  view  overlaying  additional  metric  timeline,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5436,add  ability  restart  host  component  staleconfigstrue  one  api  request  provide  ability  filter  host  component  using  predicate  allows  bulk  ops  like  restart  stale  configs  simple  api  call  example  code  requestinfo  context  restart  stale  operationallevel  hostcomponent  command  restart  requestsresourcefilters  hostspredicate  hostrolesstaleconfigstrue  code  api  call  allow  user  perform  custom  command  restart  host  component  stale  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5437,allow  client  specify  context  value  asynchronous  request  context  value  added  associated  request  resource  give  context  request  context  value  meaning  asynchronous  request  ignored  synchronous  request  request  ui  team,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5438,make  host  table  update  dynamically,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5439,improve  error  checking  blueprint  resource  creation  improving  error  checking  avoid  npe  error  blueprint  resource  creation  request  missing,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5440,ambari  api  add  additional  query  operator  isempty  category  add  additional  query  operator  including  isempty  determine  category  contains  property  example  categoryisempty  return  true  property  category  named  category  otherwise  return  false,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5441,dynamic  stack  extension  install  upgrade  support  custom  service  purpose  proposal  facilitate  adding  custom  service  existing  stack  ideally  would  support  adding  upgrading  custom  service  separately  core  service  defined  stack  particular  looking  custom  service  need  support  several  different  stack  different  distribution  ambari  release  cycle  custom  service  may  different  core  stack  custom  service  may  upgraded  different  rate  core  distribution  may  upgraded  multiple  time  within  lifespan  single  release  core  distribution  one  possible  approach  handling  would  dynamically  extending  stack  install  time  would  best  extend  stack  package  stack  extension  package  one  custom  service,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
5442,ambari  api  support  explicit  predicate  grouping  provide  support  explicit  predicate  grouping  using  bracket  example  a1b2c3,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5443,improve  agent  registration  heartbeat  json  improve  data  coming  back  agent  registration  include  rpm  query  flexible  way  add  directory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5444,api  support  cascade  delete  specified  cluster  need  able  allow  user  reconfigure  cluster  installation  fails  would  greatly  simplify  ui  logic  api  supported  cascade  delete  cluster  delete  cluster  subresources  way  ui  simply  issue  delete  cluster  proceed  performing  fresh  cluster  install  minimizes  code  change  ui  side  support  ambari1193,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5445,capsched  improvement  add  automatic  resourcemanager  url  configuration  httphttps  validate  queue  capacity  add  100  allow  space  configuration  code  property  nameyarnschedulercapacityrootacladministerqueuename  value  value  property  property  nameyarnschedulercapacityrootaclsubmitapplicationsname  value  value  property  code  allow  view  created  duplicate  name  allow  view  created  empty  name,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5446,ru  install  repo  batch  distribution  bit  prevent  denialofservice  attack  distribution  bit  call  yum  command  simultaneously  case  1300  host  bound  fail  large  cluster  batch  distribution  bit  prevent  denialofservice  attack,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5447,ru  improvement  part  1  important  running  hdfs  finalize  run  server  action  similar  finalizeupgradeaction  confirm  host  component  upgraded  version  action  inform  user  may  fail  user  skip  update  modify  finalizeupgradeaction  work  apiv1clustersc1hostshostnamehostcomponentscomponentname  show  current  version  field,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5448,remove  agent  entity  bean  public  schema  xsd  agent  entity  bean  located  ambariclient  orgapacheambaricommonrestentitiesagent  hence  schema  xsd  generation  public  rest  api  include  agent  entity  bean  move  orgapacheambaricommonrestagent  exclude  agent  entity  expose  public,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5449,add  dispatch  counter  jmx  destination  view  make  dequeue  counter  number  message  acked,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5450,allow  messagetransformer  registered  producer  consumer  help  transform  message  going  onto  bus  coming  bus  example  user  may  wish  use  objectmessage  code  deployment  use  textmessage  xstream  jaxb  marshalling,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5451,support  selector  virtual  destination  allow  message  dispatched  multiple  phyiscal  queue  match  selector,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5452,support  blobmessage  interface  support  inband  outofband  file  transfer  new  api  like  code  public  class  activemqsession  send  local  file  stream  jms  public  blobmessage  createblobmessageinputstream  inputstream  public  blobmessage  createblobmessagefile  file  send  remote  url  jms  public  blobmessage  createblobmessageurl  url  public  interface  blobmessage  extends  message  access  remote  resource  local  resource  force  creation  temporary  file  resource  parsed  multiple  time  etc  url  geturl  inputstream  getinputstream  code  discussion  see  httpwwwnabblecomsupportforfilemessagetf2641673htmla7373916,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5453,amq975  provide  way  setting  timetolive  point  time  message  received  broker  avoid  clock  sync  issue  jms  default  use  timetolive  relative  client  send  mean  thing  get  converted  gmt  suffer  clock  sync  issue  useful  alternative  could  set  timetolive  message  relative  broker  clock  receives  way  there  need  rely  properly  syncd  clock  could  either  use  new  header  activemqbrokertimetolive  something  use  negative  time  live  value  indicate  time  live  relative  broker  rather  relative  client  wondering  negative  timetolive  value  would  break  existing  software  currently  tend  ignore  ttl  value  le  equal  zero,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5454,amq1109  jdbc  based  masterslave  supported  transactsql  based  database  sql  server  sybase  main  issue  figuring  exclusive  lock  sql  syntax  think  following  valid  select  table  xlock,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5455,provide  new  simple  api  end  user  view  available  destination  query  find  statistic  queue  depth  etc  dev  list  3907  dhawan  vikram  lngday  vikramdhawanlexisnexiscom  wrote  hi  direct  way  using  openwire  client  api  get  number  consumer  attached  queue  given  point  time  know  done  using  jmx  api  wondering  done  using  open  wire  client  api  42  command  agent  httpactivemqapacheorgcommandagenthtml  used  sending  simple  text  command  broker  getting  reply  enquire  queue  depth  like  there  also  advisory  message  listen  operation  broker  seeing  new  destination  consumer  producer  etc  however  weve  never  yet  wrapped  little  easy  api  folk  use  client  easily  view  available  destination  get  stats  etc  something  like  following  code  collectionactivemqqueue  connectionfindqueues  collectionactivemqtopic  connectionfindtopics  look  stats  like  queue  depth  etc  destinationstats  getdestinationstatisticsactivemqdestination  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5456,allow  broker  configured  using  property  file  running  broker  via  code  activemq  propertiesfooproperties  code  using  brokerfactory  using  java  code,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
5457,xstream  message  transformer  work  direction  enhanced  transformer  could  configured  work  direction  contains  reverse  property  false  default  case  work  exactly  working  case  true  change  direction  transformation  producer  transforms  text  object  message  consumer  transforms  form  object  text  needed  use  rest  api  order  intercept  transform  message  submitted  post  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5458,amq1883  maven  plugin  could  locate  activemqdata  directory  target  dir  id  like  maven  plugin  coerce  activemqdata  directory  build  output  target  directory  deleted  clean  useful  integration  test  dont  need  activemqdata  directory  survive  broker  instantiation  attached  patch  cause  activemqdata  directory  located  existing  configured  outputdirectory  default  target  essentially  change  current  behavior,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5459,make  webconsole  run  standalone  war  webconsole  really  nice  thing  however  able  run  standalone  war  connecting  remote  broker  another  vm  another  server  improves  following  imo  stability  broker  webconsole  fe  eat  available  memory  try  looking  large  queue  bad  thing  deployment  many  company  standard  deployment  process  warfiles  well  preconfigured  application  server  put  backwardcompatibility  webconsole  per  se  depend  42  broker  run  fine  41  40  support  masterslave  configuration  autofailover  fe  failover  jmx  syntax  well  existing  failover  syntax  jms  connection  related  bugimprovement  current  mean  behaviour  webconsole  nondefault  named  broker  sometimes  using  webconsole  end  second  broker  beeing  started,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5460,amq  print  warning  throw  exception  message  received  nonstarted  connection  following  scenario  occur  1  create  javaxjmsconnection  dont  start  2  create  messageconsumer  connection  subscribe  queue  3  send  message  queue  case  turning  trace  logging  message  received  connection  silently  discarded  poor  bloke  forgot  call  connectionstart  look  like  message  simply  disappeared  universe  torturing  must  endure  horror  tracing  code  trying  find  cruel  god  consuming  message  discover  six  hour  later  forgot  call  connectionstart  thus  punchline  cruel  joke  life  delivered  he  prompted  thought  self  destruction  spilling  blood  innocent  prevent  scenario  would  nice  amq  printed  warning  better  yet  threw  exception  indicating  activity  occurring  connection  started  case  programmer  could  clearly  see  forgot  call  connectionstart  happily  add  line  continue  brave  future,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5461,display  establised  neteowork  connector  bridge  via  jmx,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5462,allow  view  connection  consumer  webconsole  patch  enables  viewing  open  connection  active  consumer  queue  activemq  webconsole  also  contains  minor  fix  enabling  use  password  protected  connection  remote  broker,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5463,exclusive  consumer  selected  front  consumer  get  registered,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5464,logging  improvement  contribution  hello  people  proposal  time  ago  view  httpwwwnabblecomloggingimprovementproposaltf3570794s2354htmla9976200  would  like  add  little  contribution  activemq  code  hope  activemq  developer  user  like  thought  would  good  improve  activemq  logging  capability  order  make  debugging  tracing  understanding  activemq  easier  added  customization  activemqs  transport  level  logging  allowing  user  write  logging  format  also  added  dynamic  control  logging  function  via  jmx  also  developed  simple  tool  analyze  log  file  produced  split  contribution  2  patch  one  add  customized  log  format  functionality  add  dynamic  management  logging  via  jmx  1st  patch  svn  rev  564978  2nd  patch  1st  patch  incremental  new  feature  1  logging  enhancement  1st  patch  possible  customize  written  log  file  transport  level  writing  custom  class  implement  new  logwriter  interface  also  option  logwritername  name  added  transport  uri  choose  class  format  used  detail  implement  class  format  later  activate  transport  logging  tracetrue  flag  used  people  dont  want  use  new  functionality  change  uris  2  dynamic  control  logging  enhancement  2nd  patch  added  ability  reload  log4jproperties  file  brokerview  mbean  b  option  dynamicmanagementtrue  appended  uri  transport  logging  managed  jmx  logging  switched  every  transport  option  startloggingfalse  appended  uri  transport  initially  log  transportlogger  instance  created  later  activated  jmx  another  option  let  user  change  jmx  port  used  function  3  log  parsing  analysis  tool  tool  par  log  file  number  customlogwriter  format  implementation  logwriter  interface  following  feature  tool  detects  incorrect  situation  transport  level  sent  received  message  duplicate  message  transport  level  b  tool  show  communication  sequence  message  travel  path  message  c  feature  c1  loading  log  file  done  choosing  directory  c2  incorrect  feature  filtered  per  type  per  connection  c3  long  hard  read  connection  client  id  replaced  short  easy  compare  id  c4  summary  connection  producer  consumer  log  file  screen  shot  included  continues  first  comment,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5465,support  mirrored  queue  make  easier  monitor  message  flow  via  topic  queue  via  virtual  topic  thing  like  bam  monitoring  etc  mirrored  queue  would  handy  enabled  folk  monitor  virtual  topic  see  message  delivered  topic  band  queue  message  flow  ie  existing  queue  based  application  work  meanwhile  service  consume  message  via  topic  virtual  topic,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
5466,stomp  frame  translator  improvement  added  spring  context  marshaller  changed  header  semantics  eg  jmsxml  jmsobjectxml  added  support  map  byte  message  added  transformation  error  header  ignored  jms  object  transformation  header,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1
5467,add  option  backup  channel  already  connected  failover  transport  already  established  transport  backup  fault  tolerant  transport  failure  occurs  failover  accomplished  quickly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5468,improvementsbug  fix  ldap  discovery  mechanism  ldap  network  connector  much  needed  improvement  bug  fix  amq358  original  patch  worked  subset  case  updated  original  network  connector  submitted  following  feature  fix  detection  handling  multiple  ldap  entry  pointing  upstream  broker  anonymous  binding  support  everyone  want  put  login  credential  xml  file  ldap  server  failover  support  general  logging  improvement  fix  bug  allowed  single  discovered  network  connector  broker  persistent  search  capability  allowing  broker  stay  sync  ldap  server  entry  work  ldap  server  support  extension  defined  draftietfldapextpsearch03txthttpwwwietforgproceedings01augiddraftietfldapextpsearch03txt,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5469,confirmation  delivery  confirmation  arrive  reporting  message  support  would  nice  activemq  could  support  confirmation  delivery  confirmation  arrive  report  message  ibm  webspheremq  example  broker  could  send  report  message  sending  application  put  message  target  queue  application  get  queue,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5470,make  activemqconsole  jar  osgi  bundle  reused  servicemix  4,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
5471,improve  destinationviewmbean  sendtextmessage  opersation  allows  optional  username  password  destinationviewmbeans  sendtextmessage  method  provide  option  specifying  username  password  therefore  authentication  service  enabled  broker  youre  precluded  using  sendtextmessage  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5472,amqstore  enable  transaction  sync  write  default  add  option  parameter  enable  transaction  sync  write  disk  default,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5473,jmx  destinationviewmbeanbrowse  return  compositedata  expose  user  property  string  addition  property  exposed  jmsxgroupid  jmsxgroupseq,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5474,tcptransportserverbind  use  serversocketsetreuseaddressbooleantrue  test  restart  broker  apps  require  fast  restarts  using  reuseaddress  server  socket  make  sense  default  true  option  control  transport  option  help  robustness  duplexnetworkmbeantest  bunch  broker  restarts  check  leaked  mbeans,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5475,amq2046  activemqtextmessage  tostring  method  call  gettext  currently  tostring  newly  consumed  message  show  text  field  null  value  gettext  never  called,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5476,create  simple  java  stomp  client  something  must  mostly  testing  purpose  writing  complex  stomp  test  case  tedious  result  unreadable  test  part  user  asked  one  would  good  ive  started  work  basically  adding  method  stompconnection  class  moved  test  main  tree  also  need  easy  way  parse  stomp  frame  string  check  frame  broker  return  extract  header  messageid  ill  add  method  stompframe,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5477,shutdown  broker  default  message  store  cannot  access  disk  default  message  store  behave  journaled  message  store  see  httpsissuesapacheorgactivemqbrowseamq2038,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5478,masterconnectoruri  using  failover  use  case  configuring  two  pair  masterslave  follows  amasteraslave  bmasterbslave  clientproducerconsumer  use  failovertcpamaster  tcpbmaster  aslave  bslave  used  replicate  data  master  receives  case  want  use  failovertcpamaster  masterconnectoruri  aslave  similar  b  amaster  go  get  restarted  aslave  able  reconnect  dont  need  anything  aslave  amaster  attached  patch  based  tagsactivemq520  intended  address  please  review  appreciate  applied  trunk  tag  trunk  previous  file  please  let  know  question  regarding  thank  patch  httpsissuesapacheorgactivemqbrowseamq2070  amq2070  amq2071  related  cannot  use  failover  uri  masterconnectoruri  start  slave  master  issue  failover  take  care,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5479,make  pooled  session  implement  xasession  case  need  specific  management,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5480,implement  activemqadvisorynoconsumerqueue  although  documented  message  sent  queue  without  consumer  sent  appropriate  advisory  topic  behave  consumer  topic  feature  send  nonpersistent  message,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
5481,allow  suppression  duplicate  queue  subscription  cyclic  network  topology  cyclic  network  broker  broker  know  possible  cyclic  graph  multiple  route  across  network  occurs  broker  pick  second  order  advisory  arise  broker  responding  advisory  another  broker  result  consumer  one  broker  manifest  multiple  consumer  broker  across  network  network  priority  give  precedence  shortest  route  configured  enhancement  would  ensure  one  route  given  destination  make  network  deterministic  little  simpler  small  number  broker  network  often  want  topic  involved  duplication  lead  duplicate  message  duplicate  topic  suppressed  default  trunk  53  queue  message  go  one  consumer  duplicate  issue  indeterminism  message  routed  network  indeterminism  mean  fault  tolerance  good  thing  feature  enabled  via  configuration  queue  see  background  topic  case  httpsissuesapacheorgactivemqbrowseamq2030,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5482,enable  tracing  message  network  broker  environment  larger  network  broker  set  sometimes  interest  path  message  taken  producer  consumer  one  could  enable  tracing  broker  kind  review  log  file  time  consuming  impossible  propose  small  brokerplugin  used  append  brokername  given  message  property  consumer  side  log  could  evaluate  property  see  exactly  broker  touched  message,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5483,amq2448  make  network  duplicate  subscription  suppression  feature  priority  based  networkconsumerprioritys  play  improvement  duplicate  subscription  suppression  feature  queue  httpissuesapacheorgactivemqbrowseamq2198  rather  first  subscription  win  allow  higher  priority  subscription  replace  existing  duplicate  subscription  given  broker  abc  consumer  visible  c  ac  abc  suppression  one  would  allowed  non  deterministic  improvement  decreasenetworkconsumerpriority  us  ac  replace  abc  higher  priority,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5484,forwarded  message  cannot  distributed  original  broker  simple  cause  cause  dispatch  problem  1  setup  network  broker1  broker2  bridged  multicast  discovery  2  make  producer  send  5  msg  queuea  broker2  3  make  consumer  consume  broker1  queuea  make  slow  consumer  1  msg  make  sure  5  msg  broker2  forwared  broker1  4  stop  consumer  broke1  restart  consume  broker2  queuea  5  4  msg  originally  published  broker2  forwarded  broker1  yet  consumed  stuck  broker1  forwarded  broker2  consumer  consume  solution  check  forwarded  broker  eg  broker1  see  whether  active  consumer  able  forward  message  back  original  broker  active  consumer  forwarded  broker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5485,restrict  lifetime  pooled  connection  might  make  sense  restrict  lifetime  connection  connection  pool  connection  refreshed  providing  chance  connection  load  balancing  network  broker,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5486,improve  scalability  stompnio  transport  currently  stompnio  transport  still  us  one  thread  per  client  use  selector  minimize  number  thread  improve  scalability,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5487,allow  xmpp  client  message  directly  test  updated  schema  working  getting  activemqxmpp  transport  work  simple  xmpp  server  unit  test  camelxmpp  component  multiuser  chat  worked  great  direct  chat  test  would  fail  ive  implemented  functionality  activemqxmpp  bunch  test  well  also  updated  xmpp  schema  file  added  one  though  werent  many  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5488,separate  thread  pool  per  usage  requires  lot  thread  separate  memoryusage  defined  destination  system  couple  hundred  queue  configured  separate  memoryusage  separate  sla  enforcement  memoryusage  separate  threadpoolexecutor  corepoolsize  1  maximumpoolsize  1  used  notifying  interested  listener  usage  change  drop  100  basically  mean  started  queue  memoryusage  additional  thread  created  eg  named  mainmemoryqueuequeuexmemory  usage  thread  pool  start  hundred  thread  increase  system  load  possible  share  thread  pool  memoryusages  somehow  decrease  number  thread  required  usage  monitoring  btw  executor  created  even  listener  registered  given  usage  run  following  runnable  iterating  empty  list  fireevent  runnable  listenernotifier  new  runnable  public  void  run  iteratorusagelistener  iter  listenersiterator  iterhasnext  usagelistener  l  iternext  lonusagechangedusagethis  oldpercentusage  newpercentusage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5489,try  stop  osgi  bundle  closing  application  context  using  destroyapplicationcontextonshutdowntrue  activemq  try  close  application  context  error  database  encountered  allow  cleanly  stopped  environment  servicemix  however  broker  started  osgi  bundle  bundle  left  status  started  event  context  destroyed  try  stop  appropriate  bundle  case,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5490,dont  use  kaha  creation  temporary  file  filependingmessagecursor  us  kaha  persistent  engine  nonpersistent  message  flushed  disk  memory  limit  run  low  reduce  use  file  descriptor  use  kahadb  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5491,amq2904  failover  connection  recovery  need  new  command  indicate  recovery  completion  gate  dispatch  recovered  consumer  unconsumed  message  consumer  need  rolledback  recovery  get  redispatched  arbitrary  order  see  httpsissuesapacheorgactivemqbrowseamq2573  operation  progress  like  send  transaction  rollback  cannot  happen  till  send  transaction  commit  completes  must  async  failover  interruption  dispatch  need  gated  completion  outstanding  operation  currently  resolution  amq2573  however  possibility  broker  start  dispatch  consumerconnection  recovery  complete  block  receipt  message  response  send  commit  example  dispatch  waiting  send  complete  unconsumed  message  rolledback  advance  dispatch  asyncdispatchfalse  optimizeddispatch  possible  simulate  solution  requires  two  wireformat  change  indication  connection  recovering  propagated  consumer  indication  recovery  complete  dispatch  recovered  consumer  complete  additional  ackmode  ackrecoverycomplete  could  thus  dispatch  would  gated  cannot  interfere  outstanding  work  need  restored  completed  inorder  correctly  clear  unconsumed  delivered  message,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5492,implement  stompniossl  transport,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5493,make  jdbc  store  resilient  broker  sequence  id  order  currently  message  sent  transaction  there  chance  message  added  cursor  order  regarding  broker  seq  id  problem  jdbc  store  message  recovery  based  seq  id  lead  kind  problem  orphaned  message  database  solution  refactor  jdbc  store  use  seq  generator  recovering  purpose  replace  broker  seq  id  message  id  operation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5494,update  client  connection  information  cluster  networked  broker  currently  client  decide  broker  connect  would  beneficial  allow  client  informed  broker  joiningleaving  cluster  networked  broker  optionally  load  balance  across,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5495,add  support  setting  differentiated  service  type  service  outgoing  tcpip  packet  support  quality  service  possible  specify  desired  differentiated  service  class  outlined  rfc  2475  httptoolsietforghtmlrfc2475  type  service  value  outgoing  tcpip  packet  specifying  diffserv  typeofservice  tcp  transport  option  httpactivemqapacheorgtcptransportreferencehtml  eg  tcpsomehost61616tracefalsesotimeout60000diffservaf21  eg  tcpsomehost61616tracefalsesotimeout60000typeofservice3  part  student  group  httpmaljub01svnrepositorycomcomp190traccgiwiki  tuft  university  implementing  functionality  activemq  potential  use  mit  lincoln  lab  part  nextgen  network  enabled  weather  program  httpswikiucaredudisplaynnewdthennewwiki  would  like  contribute  change  back  activemq  trunk  possible  attached  initial  patch  530  release  version  implement  setting  differentiated  service  class  via  tcp  transport  option  connection  uri  note  approach  basic  underlying  mechanism  actually  setting  bit  packet  header  javanetsocketsettrafficclass  method  elegant  implementation  possible  implementation  came  order  settrafficclass  work  jdk  6  necessary  set  system  property  javanetpreferipv4stack  true  found  precedent  activemq  httpactivemqapacheorgmulticastwatchoutforipv6vsipv4supportonyouroperatingsystemordistributionornetworkhtml  hoping  issue  resolved  jdk  7  use  ipv6  stack  possible  addition  current  implementation  set  specified  differentiated  service  bit  outgoing  packet  control  acknowledgment  sent  back  packet  yet  find  elegant  crossplatform  way  activemq  broker  find  differentiated  service  bit  incoming  packet  directly  java  although  considering  approach  would  involve  calling  shell  script  tcptransportserver  would  utilize  iptables  would  like  know  might  interested  accepting  work  activemq  trunk  sooner  let  u  know  one  way  another  better  singlesemester  project,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5496,make  fileserver  app  jettyneutral  currently  app  us  class  jettyutil  also  wed  want  trim  size  war  doesnt  need  jar  webinflib  folder,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5497,amq2680  allow  setting  storeusage  limit  per  individual  queuetopic  moment  possible  configure  storelimit  per  broker  case  want  set  upper  bound  individual  queue  guarantee  storage  available  queue  example  consider  setup  request  queue  response  queue  request  response  message  huge  situation  want  set  overall  store  limit  prevent  flooding  filesystem  time  dont  want  allow  request  queue  consume  100  broker  store  example  wed  like  define  total  broker  store  limit  20  gb  queue  requestqueue  store  limit  15  gb  queue  responsequeue  store  limit  5  gb,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
5498,localize  springrelated  class  separate  module  try  reducing  spring  dependency  broker  core  module  move  springrelated  class  separate  module,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5499,npe  writetimeoutfilter  nio  add  support  sowritetimeout  nio  transport  config  show  problemcode  amqtransportconnectors  amqtransportconnector  nameopenwire  urinio000061616transportsowritetimeout5000transportsotimeout5000  amqtransportconnector  namestomp  uristompnio000061618transportsowritetimeout5000transportsotimeout5000  amqtransportconnectors  code  event  write  time  nio  npe  appears  log  20100412  181703159  error  orgapacheactivemqtransportwritetimeoutfiltertimeoutthreadrunwritetimeoutfilterjava177  writetimeoutfiltertimeout1  writetimeout  thread  unable  validate  existing  socket  javalangnullpointerexception  null  issue  nio  transport  doe  support  narrow  tcpbufferedoutputstreamclass  little  refactor  implementation  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5500,provide  visibility  onto  destination  slowconsumerstrategy  via  jmx  would  nice  jmx  visibility  possibly  ability  force  abort  slowconsumerstrategy  httpsissuesapacheorgactivemqbrowseamq378  ability  see  current  list  slow  consumer  manual  abort  option,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5501,add  support  message  priority  add  support  delivering  message  priority,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5502,additional  support  dynamic  uris  failovertransport  environment  would  convenient  allow  dynamic  addition  transport  uris  failovertransport  currently  supported  network  broker  doesnt  help  certain  scenario  here  one  scenario  im  interested  sharedstorage  masterslave  configuration  broker  multiple  client  since  one  master  broker  active  time  master  aware  slave  broker  cannot  communicate  new  broker  url  transport  connected  client  client  must  use  tcpip  protocol  ie  multicastdiscovery  isnt  option  there  way  client  dynamically  learn  new  broker  deployed  must  update  client  configuration  restart  connection  updated  list  transport  uris  patch  allow  failovertransport  read  new  transport  uris  file  file  read  doreconnect  processing  new  processing  driven  client  lost  connectionis  establishing  new  connection  use  new  feature  use  failover  uri  like  following  failovertcplocalhost61616tcplocalhost61626updateurisfileyourlistoftransporturis  even  failoverupdateurisfileyourlistoftransporturis  file  content  would  look  like  tcplocalhost61616tcplocalhost61626  new  broker  added  configuration  append  new  transport  uri  file  patch  includes  new  test  test  new  feature  failoverupdateuristestjava  comment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5503,fanout  unable  apply  parameter  discovered  broker  currently  way  apply  parameter  discovered  broker  using  fanout  transport  discovery  transport  allows  calling  discoverytransportsetparametersmap  discoverytransportfactorycreatetransportcompositedata  example  following  uri  would  apply  connection  timeout  3  second  discovered  tcp  transport  broker  nbspnbspnbspnbspdiscoverymulticastdefaultconnectiontimeout3000  corresponding  fanout  uri  would  apply  connection  timeout  discovered  tcp  broker  nbspnbspnbspnbspfanoutmulticastdefaultconnectiontimeout3000  functionality  requested  discovered  broker  may  become  unreachable  circumstance  default  30  connection  timeout  tcp  transport  cause  considerable  delay  attached  patch  proposed  solution  transport  use  discovery  transport  failover  fanout  common  code  path  discoverytransportfactory  creating  discovery  transport  code  path  set  parameter  consistently  transport  although  relies  new  static  method  discoverytansportfactory  transportfactory  object  static  method  fanouttransportfactory  already  making  static  call  discoveryagentfactory  patch  also  two  new  test  case  one  apply  parameter  another  minor  fix  discoverytransport  cache  added  uri  parameter  applied  uri  removed  onserviceremove  issue  created  discussion  activemq  user  discussion  board  nbspnbspnbspnbsphttpoldnabblecomapplyingparameterstodiscoveredbrokerstd29239157html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5504,add  ability  kahadb  log  file  created  perdestination  basis  kahadb  persistence  us  rolling  log  file  store  unconsumed  message  named  db1log  db2log  db3log  present  file  contain  message  destination  managed  broker  configurable  option  could  added  would  allow  file  created  perdestination  basis  example  broker  contained  two  queue  destination  queue1  queue2  log  file  would  become  queue11log  queue12logetc  queue21log  queue22logetc  set  log  file  would  contain  message  relevant  destination  would  help  following  situation  queue1  receives  one  message  every  15  second  message  remain  unconsumed  several  hour  queue2  receives  thousand  message  per  second  message  consumed  arrive  present  scenario  lead  log  file  containing  message  yet  consumed  thousand  message  consumed  log  file  cannot  deleted  message  logged  consumed  may  hour  later  logging  perdestination  basis  would  allow  log  file  queue2  example  deleted  meaning  unconsumed  message  queue1  take  far  le  disk  space  would  also  reduce  number  file  handle  required,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
5505,implement  custom  brokerid  assignment  strategy  network  broker  duplicate  route  detection  done  checking  broker  id  restart  broker  id  change  cause  duplicate  route  message  stuck  due  reached  ttl  need  provide  mechanism  user  configure  broker  id  assigned  make  sure  stay  restart  ensure  correct  duplicate  route  detection  even  broker  mesh  restarted,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5506,allow  option  dlq  per  durable  subscription  deadletterstrategy  httpsissuesapacheorgactivemqbrowseamq2584  durable  subscription  sharing  dlq  duplicate  sends  dlq  one  durable  sub  reject  message  durables  suppressed  provided  already  acked  case  duplicate  hang  auditfalse  option  dlq  work  around  begs  question  know  durable  subscription  refused  message  facilitate  dlq  pre  durable  sub  nice  option  use  clientid  subscribername  postfix  activemqdlqclientidsubscribername  subscriber  change  subsequent  message  go  different  dlq  destination  would  need  manually  deleted  longer  needed  require  additional  method  orgapacheactivemqbrokerregionpolicydeadletterstrategy  need  version  update,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5507,activemqinputstream  allow  specify  timeout  like  messageconsumerreceive  using  activemqinputstream  able  todo  kind  polling  consuming  soon  call  activemqinputstreamread  block  receive  message  could  block  forever  sometime  would  usefull  allow  kind  polling  even  using  stream,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5508,fire  advisory  network  bridge  starterstopped,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5509,outbound  bridge  handle  remote  connectivity  problem  startup  jmstojms  bridge  one  configure  jmsqueueconnector  jmstopicconnector  outbound  bridge  mode  mode  foreign  jms  provider  remote  service  therefore  subject  disconnection  failure  etc  connector  support  reconnecting  remote  provider  connector  start  correctly  remote  service  available  startup  time  attached  patch  test  case  solves  problem  separating  initialization  local  remote  part  bridge  failure  initialization  remote  broker  considered  fatal  since  bridge  attempt  reconnect  foreign  provider  message  received  local  broker  anyway  logic  could  also  implemented  inbound  bridge  slightly  difficult  itll  require  separate  thread  manage  connectivity  state  remote  ie  system  fails  connect  remote  startup  time  separate  thread  created  periodically  continue  try  connect  would  also  apply  inbound  bridge  lose  connection  due  remote  losing  connectivity  recycled  done  yet,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
5510,full  table  scan  durable  sub  jdbc  store  priority  enabled  slow  large  message  backlog  priority  support  delegate  db  currently  requires  full  table  scan  recover  new  batch  message  slow  message  table  large  consumer  offline  time  multiple  concurrent  consumer  get  worse  store  need  use  internal  state  wrt  priority  simplerfaster  query  used,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5511,networkconnector  initialization  backed  executor  many  network  connector  slow  network  starting  serially  mean  last  network  connector  may  wait  n  slow  connection  establishment  process  connection  initiation  fails  fast  really  problem  start  process  move  quickly  possible  start  network  connector  using  executor  start  parallel  fast  connection  running  immediately,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5512,stomp  frame  mask  passcode  header  tostring  output  pollute  log  logging  stomp  connect  frame  includes  raw  passcode  masked  instead  ofcode220110318  093830634  381714340701  warn  transportconnection  failed  add  connection  idxxxx384569923  reason  javalangsecurityexception  user  name  password  invalid  20110318  093830634  381714340701  warn  protocolconverter  exception  occurred  processing  connect  hostbig77  acceptversion1011  passcodebar  loginfoocode  becode220110318  093830634  381714340701  warn  transportconnection  failed  add  connection  idxxxx384569923  reason  javalangsecurityexception  user  name  password  invalid  20110318  093830634  381714340701  warn  protocolconverter  exception  occurred  processing  connect  hostbig77  acceptversion1011  passcode  loginfoocode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5513,enable  propertiesloginmodule  jaas  module  optionally  cache  value  memory  currently  propertiesloginmodule  load  usersproperties  groupsproperties  file  every  connection  ok  case  stomp  connection  come  go  frequently  cause  performance  issue  provide  configuration  parameter  reloadfalse  make  module  cache  value  file  memory  example  config  code  activemqdomain  orgapacheactivemqjaaspropertiesloginmodule  required  debugtrue  reloadfalse  orgapacheactivemqjaaspropertiesuserorgapacheactivemqsecurityusersproperties  orgapacheactivemqjaaspropertiesgrouporgapacheactivemqsecuritygroupsproperties  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5514,support  temporary  destination  network  without  advisory  typically  network  require  advisory  message  allow  peer  broker  know  dynamic  destination  consumer  creation  however  advisory  overhead  significant  number  peer  broker  network  increase  double  digit  statically  configured  network  exist  without  advisory  using  request  reply  temporary  currently  destination  fails  way  configure  statically  included  generated  name  dynamically  created  connectionid  contain  wild  card  separator  b  possible  auto  create  temp  destination  replying  message  producer  amq2571  discussion  httpmailarchivesapacheorgmodmboxactivemqusers201103mbox3caanlktin3laq4awp8hk48oyagwpsvodvjw4an57j3vzmailgmailcom3e,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5515,cannot  use  sslcontext  tag  blueprint  configuration  couldnt  use  sslcontext  tag  blueprint  configuration  setting  string  attribute  sslcontext  element  resulted  error  cannot  convert  string  spring  resource  type  tried  use  blueprint  file  turn  java  source  defines  property  spring  resource  type  string  pulling  resource  type  api  pushing  implementation  keep  schema  string  type  matching  api  natural  work  easily  blueprint,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5516,implement  exactly  delivery  kahadb  xa  event  failure  post  prepare  xa  2pc  camel  route  jms  jdbc  ensure  exactly  delivery  jdbc  event  failure  prepare  commit  jdbc  done  jms  message  must  remain  pending  ack  till  commit  outcome  relayed  transaction  manager  current  version  geronimo  correctly  retry  commit  timer  thread  activemq  eventually  get  commit  outcome  recovery  btw  look  like  howl  persist  commit  outcome  per  namedxaresource  failure  tm  may  consier  transaction  completed  message  may  still  pending  need  check  moment  activemq  heuristic  rollback  recovery  lead  message  redelivery  error  fix  acked  message  remains  pending  awaiting  outcome  commit  message  acked  rollback  message  available  redelivery,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5517,usage  temp  store  index  plist  need  improved  problem  manifest  systemusage  memory  limit  triggered  pending  message  cursor  non  persistent  message  flushing  memory  cache  temp  store  taking  long  time  mean  time  cursor  need  flush  disk  blocking  temp  store  sends  destination  blocked  scenario  broker  come  back  life  flush  completes  problem  cursor  see  limit  time  try  flush  usage  temp  store  index  plist  need  improved  optimal  moment  us  much  space  index  us  page  per  entry  reading  page  cache  exhausted  slow,1,0,1,0,1,0,1,0,0,1,0,0,0,0,0,1,1
5518,broker  check  expired  persistent  topic  msg  using  topic  durable  subscription  subscriber  disconnect  task  check  expired  message  durable  subscription  case  subscriber  disconnected  hour  message  still  sent  ttl  may  happen  either  producer  get  blocked  case  flow  control  broker  run  persistent  storage  flow  control  msg  already  expired  similar  queue  periodic  task  check  expired  msg  durable  topic  sub  task  also  configurable  using  property  similar  expiremessagesperiodhttpactivemqapacheorgperdestinationpolicieshtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5519,admin  command  take  amqurl  accept  user  pas  option  using  fix  amq3410  realized  username  password  available  passed  via  command  line  ill  add  new  parameter  user  pas  allow  username  password  passed  amqurl  passed,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,1
5520,make  use  remote  port  connection  mbeannames  optional  useful  ephemeral  range  cycle  quickly  fast  connection  closecreation  like  stomp  client  side  ephemeral  port  range  result  duplicate  mbean  name  close  async  potential  failed  mbean  registration  due  port  reuse  codedebug  managedtransportconnection  failure  reason  javaxmanagementinstancealreadyexistsexception  orgapacheactivemqbrokernamexxxxxxtypeconnectionconnectornamestompviewtypeaddressnamexxxx52170code  make  registration  address  type  mbean  configurable  case  avoided  main  handy  see  remote  address  mbean  name  default  use  remote  port  client  id  default  connection  id  used  mbean  name  use  remote  port  allowed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5521,add  stomp  v11  support  stomp  v11  spec  finalized  add  support  amq  add  support  connection  inactivity  monitoring  stomp  client  le  stale  stomp  connection  stomp  v11  client  enable  heart  beat  also  add  support  queue  browsing  via  stomp  v11  client  send  browsertrue  header  subscription  command  nack  message  also  supported  stomp  v11,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
5522,provide  ability  ra  given  existing  connectionfactory  ra  could  given  existing  connectionfactory  connection  factory  could  reused  inbound  outbound  messaging  without  requiring  two  different  factory  created,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5523,enhance  http  transport  support  wire  level  compression  using  gzip  provide  mean  enabling  http  compression  using  gzip  data  sent  received  http  http  transport  separate  functionality  form  message  level  compression  used  compress  message  body  configuring  activemqconnectionfactorysetusecompression  http  transport  level  compression  would  enabled  via  uri  option  noformat  httplocalhost8161transportusecompressiontrue  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5524,stomp  11  introduced  heartbeat  header  implemented  inactivity  monitor  would  nice  option  stomp  10  stomp  10  provide  inactivity  monitor  client  connect  stay  idle  remain  active  broker  indefinitely  11  inactivity  monitor  come  play  response  heartbeat  header  10  client  need  way  indicate  default  heartbeat  header  broker  readtimeout  expectation  writetimeout  providing  transport  option  stomp  like  stomp00000transportdefaultheartbeat50000  would  nice  absence  heartbeat  header  stomp  10  case  default  value  would  cause  inactivitymonitor  readcheck  500  installed  new  broker  stomp  transport  connection  client  remains  inactive  5  second  broker  connection  closed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5525,revert  oracle  jdbc  adapter  variant  default  jdbc  adapter  place  one  supporting  blob  blob  support  non  atomic  update  message  add  little  inefficient  due  need  insert  update  blob  latest  ojdbc6jar  oracle  driver  blob  used  hood  default  jdbc  adapter  work  oracle  currently  following  configuration  achieve  codepersistenceadapter  jdbcpersistenceadapter  datasourceoracleds  adapter  defaultjdbcadapter  statement  statement  longdatatypenumber  sequencedatatypenumber  statement  defaultjdbcadapter  adapter  jdbcpersistenceadapter  persistenceadapter  code  oracleds  beancodebean  idoracleds  classorgapachecommonsdbcpbasicdatasource  destroymethodclose  property  namedriverclassname  valueoraclejdbcoracledriver  property  nameurl  valuejdbcoraclethinlocalhost1521amq  property  nameusername  valueuser  property  namepassword  valuepass  beancode  enhancement  make  oracle  adapter  behave  like  default  following  configuration  workcodejdbcpersistenceadapter  datasourceoracleds  code  manipulate  blob  directly  blob  support  necessary  backward  compatibility  earlier  driver  blob  adapter  specified  using  adapter  elementcodepersistenceadapter  jdbcpersistenceadapter  datasourceoracleds  adapter  oracleblobjdbcadapter  adapter  jdbcpersistenceadapter  persistenceadaptercode,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5526,rename  rendezvous  discovery  scheme  zeroconf  activemq  implement  2  protocol  discover  agent  broadcast  packet  multicast  default  rendezvous  make  sense  use  zeroconf  name  instead  rendezvous  avoid  confusion  tibco  rendezvous  technology  rendezvous  name  longer  used  apple  due  trademarkcopyright  issue  apple  changed  name  bonjour  httpenwikipediaorgwikibonjoursoftware  implement  zeroconf  protocol  exact,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,0
5527,modify  mkahadb  support  using  one  adapter  per  destination  without  explicity  listing  every  desintation  configuration  would  like  ability  configure  mkahadb  use  one  adapter  per  queue  without  explicitly  list  every  queue  activemq  configuration  httpactivemq2283324n4nabblecommkahadbconfiguretouseoneadapterperqueuetd4204743html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5528,allow  kahadb  run  without  disk  syncs  higher  put  without  jms  persistence  guarantee  using  broker  buffer  persistent  data  large  burst  addition  periodic  batch  remove  want  become  disk  bound  waiting  disk  syncs  cause  unnecessary  pause  jms  durability  guarantee  needed  possible  execute  without  disk  syncs  syncing  shutdown,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
5529,slave  broker  cannot  stopped  jdbc  masterslave  configuration  within  osgi  blueprint  container  cannot  stopped  state  creating  operation  synchronized  blueprintcontainerimpl  impact  slave  broker  cannot  stopped  fortunately  broker  stopped  first  osgi  service  unregistered  call  configured  osgi  unregistration  listener  patch  provides  class  osgi  service  unregistration  listener  allow  stop  database  locker  blocked  creating  state,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5530,failover  transport  support  priority  url  use  case  important  detect  local  broker  available  force  reconnecting  example  url  like  codefailovertcplocal61616tcpremote61616prioritybackuptruecode  try  backup  local  transport  ready  reconnect  available  default  first  url  considered  priority  want  tune  url  considered  prioritized  use  something  like  codefailovertcplocal161616tcplocal261616tcpremote61616prioritybackuptruepriorityuristcplocal161616tcplocal261616code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5531,dynamic  failover  sends  client  resolved  host  name  hello  using  dynamic  failover  broker  appears  resolve  transport  connector  ip  address  available  host  returned  client  ip  address  case  desirable  ip  address  sent  client  resolved  host  broker  return  exact  address  shown  transport  configuration  dynamically  configure  client  desirable  thanks  scott  e  httpfusesourcecom,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5532,recover  scheduler  database  option  sure  scheduler  database  got  corrupted  message  couldnt  delivered  broker  got  many  exception  similar  code  20120302  032608234  error  jms  failed  schedule  job  orgapacheactivemqbrokerschedulerjobschedulerimpl  jobschedulerjms  javaioioexception  could  locate  data  file  correctfilepathdb2log  orgapachekahadbjournaljournalgetdatafilejournaljava350  orgapachekahadbjournaljournalreadjournaljava597  orgapacheactivemqbrokerschedulerjobschedulerstoregetpayloadjobschedulerstorejava315  orgapacheactivemqbrokerschedulerjobschedulerimplfirejobjobschedulerimpljava421  orgapacheactivemqbrokerschedulerjobschedulerimplmainloopjobschedulerimpljava473  orgapacheactivemqbrokerschedulerjobschedulerimplrunjobschedulerimpljava429  javalangthreadrununknown  source  code  problem  way  restore  database  like  working  main  activemq  database  fix  main  database  specifying  following  configuration  code  persistenceadapter  kahadb  directoryactivemqbasedatakahadb  ignoremissingjournalfilestrue  checkforcorruptjournalfilestrue  checksumjournalfilestrue  persistenceadapter  code  would  nice  feature  scheduler  database,0,0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,1
5533,support  nonblocking  sends  us  async  callback  get  notified  send  received  broker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5534,add  pluggable  policy  fired  background  timer  detect  slow  consumer  nondurable  topic  kill  maybe  prewarning  slow  little  killed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5535,add  support  mqtt  support  mqtt  v31  protocol  see  httpmqttorg,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
5536,usecompression  server  side  specially  network  broker  wan  connection  network  broker  need  utilize  bandwidth  thats  compression  entered  server  side  usefull  option,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5537,w  transport  feature  request  w  transport  secure  websocket  connection  cannot  bind  secure  websocket  http  page  got  j  security  exception,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5538,activemqjaas  authorization  doesnt  work  karaf  jaas  loginmodule  currently  activemqjaas  cant  work  karaf  loginmodule  reason  come  compare  amq  groupprincipal  karaf  userprincipalroleprincipal  doesnt  work  detail  please  see1  similar  issue  servicemix  nmr2  fix  honor  compare  amq  groupprincipal  karaf  userprincipalroleprincipal  yet  introduce  dependency  activemqjaas  karaf  jaas  1httpkaraf922171n3nabblecomkarafactivemqauthorizationproblemtd4024834html  2httpsissuesapacheorgjirabrowsesmx4nmr283,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
5539,expose  transport  connector  uris  uniform  fashion  right  jmx  method  like  getopenwireurl  getting  address  transport  connector  api  particularly  nice  doesnt  scale  well  new  transport  added  deprecate  method  introduce  new  one  mapstring  string  gettransportconnectors  return  connector  name  key  public  string  gettransportconnectorbytypestring  type  return  connector  address  certain  prefixtype  like  tcp  stomp  w,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
5540,output  version  number  started  log  line  consistent  amq  log  starting  later  started  1st  log  line  version  number  would  good  version  number  2nd  line  well  code  main  brokerservice  info  activemq  560  jms  message  broker  mybroker  starting  main  brokerservice  info  help  information  please  see  httpactivemqapacheorg  jmx  connector  managementcontext  info  jmx  console  connect  servicejmxrmijndirmilocalhost1099jmxrmi  main  transportserverthreadsupport  info  listening  connection  tcp12700161616  main  transportconnector  info  connector  tcplocalhost61616  started  main  brokerservice  info  activemq  jms  message  broker  mybroker  iddavsclauslan54124134582075214301  started  code  stopping  broker  version  number  longer  included  would  good  consistent  code  activemq  shutdownhook  brokerservice  info  activemq  message  broker  mybroker  iddavsclauslan54124134582075214301  shutting  cplocalhost12700161616  failovertransport  warn  transport  tcp12700161616  failed  reason  javaioeofexception  attempting  automatically  reconnect  cplocalhost12700161616  failovertransport  warn  transport  tcp12700161616  failed  reason  javaioeofexception  attempting  automatically  reconnect  cplocalhost12700161616  failovertransport  warn  transport  tcp12700161616  failed  reason  javaioeofexception  attempting  automatically  reconnect  cplocalhost12700161616  failovertransport  warn  transport  tcp12700161616  failed  reason  javaioeofexception  attempting  automatically  reconnect  activemq  shutdownhook  transportconnector  info  connector  tcplocalhost61616  stopped  cplocalhost12700161616  failovertransport  warn  transport  tcp12700161616  failed  reason  javaioeofexception  attempting  automatically  reconnect  activemq  shutdownhook  brokerservice  info  activemq  jms  message  broker  mybroker  iddavsclauslan54124134582075214301  stopped  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5541,implement  pluggable  broker  locker  currently  shared  storage  masterslave  locking  job  persistence  adapter  hardcoded  kahadb  use  shared  file  locking  jdbc  allows  least  customization  idea  create  general  locker  interface  share  across  available  persistence  adapter  example  jdbc  use  shared  file  lock  kahadb  use  zookeeper  lock  available  also  consider  moving  locking  persistence  layer  making  job  broker,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,1,1
5542,refactor  introspectionsupport  avoid  using  java  bean  property  editor  java  bean  property  editor  slow  thread  safe  use  apache  camel  removed  usage  camel  type  converter  system  activemq  number  default  converter  needed  fairly  easy  implement  hand  eg  string  number  booleans  etc  fix  issue  amq  causing  memory  leak  dynamic  environment  may  run  multiple  broker  hot  deploy  broker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5543,make  better  use  commonspool  activemqpool  currently  activemqpool  us  tiny  portion  functionality  thats  available  commonspool  opting  instead  reinvent  lot  thing  exists  keyed  object  pool  refactor  current  codebase  better  use  commonpool  allows  easily  adding  feature  like  enabling  async  check  connection  idled  removing  pool  well  adding  diagnostic  method  api  using  well  tested  pooling  backend  instead  custom  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5544,refactor  logic  shutdown  thread  pool  using  single  api  ensure  better  shutdown  offer  logging  et  apache  camel  centralized  api  thread  pool  allows  u  track  camel  ensure  thread  pool  enlisted  jmx  also  unregistered  well  log  thread  pool  created  shutdown  etc  also  better  logic  shutdown  graceful  fallback  aggressive  etc  add  thread  factory  offer  naming  pattern  style  end  user  customize  thread  naming  etc  activemqcore  piece  logic  tidy  especially  ensure  shutdown  happening  consistent  graceful  etc  help  make  possible  camel  also  enlist  thread  pool  jmx,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5545,job  scheduler  store  growth  unrestricted  using  scheduled  delivery  possible  grow  job  scheduler  store  indefinitely  quota  set  size  store  malfunctioning  malicious  prodigious  producer  easily  consume  available  storage  scheduled  message  without  alert  raised  broker  operator  disk  space  monitoring  place  outside  broker  broker  become  innoperable  without  warning  provide  mechanism  set  usage  quota  job  scheduler  store  mechanism  conform  current  resource  quota  model  provided  systemusage  well  provide  monitoring  jmx  attached  basic  patch  add  management  enforcement  configurability  size  job  scheduler  data  store  guidance  thing  missed  account  would  greatly  appreciated  testing  size  reporting  jmx  noticed  kaha  persistence  adapter  seems  calculate  size  differently  job  scheduler  store  appears  job  scheduler  store  reporting  size  data  file  index  kaha  persistence  adapter  reporting  size  data  file  reason  difference  noticed  difference  broker  reporting  33  usage  job  scheduler  store  100mb  limit  immediately  clean  broker  startup,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5546,refactor  network  bridge  startstop  reduce  async  task  synchronisation  way  complicated  atm  sequence  event  start  way  random  result  many  async  task  shouldcould  simple  start  remote  transport  wait  remote  broker  info  start  local  transport  local  bridge  start  remote  bridge  nothing  wrt  success  failure  sufficient  test  place  safely  refactor  stage  many  bug  area  still  outstanding  httpsissuesapacheorgjirabrowseamq3993,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5547,remove  pure  masterslave  functionality  pure  masterslave  introduced  7  year  ago  mean  getting  tick  box  high  availability  severely  limited  one  slave  supported  slave  must  running  master  attempt  made  synchronising  new  slave  unfortunately  pure  masterslave  sometimes  used  option  activemq  user  unaware  danger  extreme  risk  others  pure  masterslave  spawn  hell  removed  forthwith,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5548,use  hawtbuf  activemqclient  make  message  property  mapmessage  body  unmarshal  lazy  message  property  mapmessage  body  already  use  lazy  unmarshal  strategy  use  hawtbuf  utf8buffer  object  unmarshal  byte  string  property  map  value  utf8  decode  back  string  instance  needed  contrived  test  case  able  get  extra  100  msgssec  consumer  read  portion  payload  large  mapmessage  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5549,pooledconnectionfactory  track  session  checkout  close  associated  resource  user  code  close  connection  checked  pool  would  expect  activemqpool  close  session  messageconsumers  messageproducers  created  unfortunately  activemqpool  clean  session  connectionclose  one  else  referencing  connection  referencecount  0  make  session  consumer  producer  outlive  code  actually  us  thus  leading  increased  resource  consumption  message  trapped  prefetch  buffer  longer  monitored  instead  keep  track  session  created  specific  connection  checkout  close  borrowed  connection  closed  otherwise  bump  situation  like  spr10092httpsjiraspringsourceorgbrowsespr10092  using  spring  defaultmessagelistenercontainer  case  dmlc  forgets  explicitly  close  messageconsumers  session  even  though  connection  always  closed  pool  doesnt  take  care  cleaning  associated  session,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5550,jmx  objectnames  follow  jmx  best  practice  use  hierarchical  format  current  jmx  objectnames  result  disjointed  view  jconsole  managed  object  service  activemq  broker  following  best  practice  easier  find  monitor  endpoint  associated  destination  example,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5551,add  mutual  authentication  needclientauth  http  transport  would  like  able  force  client  authenticate  broker  trust  store  similar  needclientauth  ssl  transport,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5552,message  amqscheduleddelay  respect  transaction  currently  delayed  message  delivered  even  session  sent  rolled  back  according  httpactivemq2283324n4nabblecomamqscheduleddelayandtransactionalboundariestd4658339html  message  delivered  far  future  transaction  would  take  long  dont  agree  argument  transaction  short  living  enqueuing  delayed  message  broker  part  transaction  delivery  consumer  part  transaction  anymore  eg  consider  scenario  following  preudo  code  applicationruns  try  msg  sessionreceive  sessionsenddelayedanothermessage  random5  0  throw  exception  sessioncommit  catch  sessionrollback  currently  delayed  message  sent  retry  get  lot  message  future  would  expect  delayed  message  would  respect  transaction  successful  one  would  enqueued  one  rolledback  transaction,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5553,brokerbased  redelivery  plugin  support  maximumredeliveries1  itd  great  redeliveryplugin  would  allow  policy  configuration  maximumredeliveries1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5554,allow  lease  locker  used  jdbcpersistenceadapter  kahadb  lock  locker  interface  need  another  configure  option  provide  broker  service  need  brokerservice  aware  locker  get  identity  access  io  exception  handler  lease  database  locker  dependent  jdbc  pa  get  statement  data  source  possible  configure  independently  used  standalone  broker  lock  setter  help  sort  dependency  broker  lock  implementation  also  making  possible  use  lease  lock  kahadb  example  context  httpmailarchivesapacheorgmodmboxactivemqusers201303mbox3ccaj5znhuruzaewsaabajtwbbpkwn06ryyyt6nqsdgsu7vmocgmailgmailcom3e,1,0,1,0,1,0,0,1,0,0,0,1,1,0,0,0,0
5555,allow  xapooledconnectionfactory  used  ee  implement  objectfactory  queuetopicconnectionfactory  easily  bind  connection  factory  aware  container  transaction  managertm  use  javaxnaming  objectfactory  come  handy  allows  connection  factory  create  instance  jndi  lookup  tm  resolved  jndi  runtime  make  sense  avoid  wiring  dependency  xapooledconnectionfactory  implement  ee  type  queue  topic  connection  factory  interface  make  factory  useable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5556,improve  dlq  handling  provide  way  see  destination  dlq  retry  message,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
5557,activemqmavenplugin  stop  goal  mavenactivemqplugin  aka  activemqmavenplugin  multimodule  maven  project  would  like  stop  start  activemq  module  needed  stop  start  goal  rather  run  goal  shutdown  hook  cannot  run  individual  module  multimodule  project  start  activemq  aggregate  pomxml  approach  would  also  resolve  amq1628  different  way  suggested  approach  suggesting  similar  cargo  plugin  handle  tomcat,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,0
5558,allow  scheduled  delivery  message  rather  dispatched  immediately  would  good  support  custom  header  indicate  delivery  time  future,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5559,expired  message  check  done  really  needed  performance  issue  case  checking  expired  message  dlqing  sending  advisory  dont  really  need  one  example  destroy  tempqueue  call  purge  queue  end  removing  message  sake  freeing  memoryusage  end  processing  expired  message  case  doesnt  make  lot  sense  since  destination  going  away  generally  really  want  process  expired  purge  call  expired  message  lead  advisory  dlqd  message  might  really  need  done,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5560,activemq  automatically  restart  locker  loos  lock  right  locker  loos  lock  broker  stop  restart  retry  acquiring  lock,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5561,add  endpointcompleter  functionality  activemq  camel  component  make  available  tool  autocomplete  destination  name  creating  route,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
5562,network  connector  new  messagettl  consumerttl  split  usage  networkttl  mesh  topology  currently  networkttl  networkconnector  default1  mean  message  go  one  hop  demand  info  consumer  go  one  hop  network  ab  message  consumer  flow  linear  network  abc  networkttl  need  2  message  consumer  flow  two  hop  c  mesh  topology  abca  networkttl1  consumer  make  sense  one  hop  however  message  networkttl  1  necessary  consumer  need  hop  around  broker  imagine  consumer  pull  message  b  consumer  move  c  message  need  hop  c  repeat  essentially  messagettlnetworkttl  need  infinite  consumerttl  1  mesh  managing  demand  proxy  demand  consumer  proxy  proxy  consumer  becomes  difficult,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5563,enable  mqtt  websocket  protocol  support  multiple  protocol  w  transport  easily  itd  good  provide  mqtt  support,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5564,provide  polling  slowconsumerpolicy  us  lastack  time  sub  existing  abortslowconsumer  policy  event  driven  depends  consumer  slow  event  triggered  prefetch  reached  subsequent  dispatch  prefetch01  still  need  throughput  determine  consumer  slow  one  message  pending  new  message  sent  destination  providing  alternative  implementation  periodically  poll  consumer  last  ack  time  deterministic  slow  advisory  may  never  fire  consumer  get  aborted  ack  timely  manner  lastacktime  exceeds  max  dispatched  message  candidate  removal  optionally  lastacktime  exceeding  dispatched  message  way  remove  idle  consumer  sure  necessary,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5565,runtime  configuration  allow  selective  application  change  xml  configuration  without  broker  restart  support  fly  configuration  change  appropriate  via  jmx  possible  make  change  dont  persist  via  osgi  restart  broker  pick  change  xml  config  make  sense  able  apply  change  fly  first  example  would  addition  new  network  connector  addition  relevant  xml  config  edit  copy  use  broker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5566,provide  generic  jms  xa  connection  pool  jms  bridge  camel  used  third  party  jms  provider  need  connection  pooling  xa  enlistment  remains  existing  activemqpool  hard  dependency  activemq  cannot  used  idea  extract  amq  deps  make  activemqjmspool  dependent  activemqpool  leverage  shared  pool  impl  end  jms  bridge  camel,1,1,1,0,1,1,0,0,1,1,1,1,1,0,0,0,1
5567,runtime  config  support  addition  composite  virtual  destination  forwardto  add  support  runtime  addition  formcodedestinationinterceptorsvirtualdestinationinterceptorvirtualdestinations  compositequeue  namevirtualdestinationcompositequeue  forwardto  queue  physicalnamevirtualdestinationqueueconsumer  topic  physicalnamevirtualdestinationtopicconsumer  forwardto  compositequeuevirtualdestinationsvirtualdestinationinterceptordestinationinterceptorscode  currently  composite  dest  runtime  addition  result  npecodecaused  javalangnullpointerexception  orgapacheactivemqbrokerregionvirtualcompositedestinationfiltersendcompositedestinationfilterjava53  orgapacheactivemqbrokerregionabstractregionsendabstractregionjava394  orgapacheactivemqbrokerregionregionbrokersendregionbrokerjava442  orgapacheactivemqbrokerjmxmanagedregionbrokersendmanagedregionbrokerjava283  orgapacheactivemqbrokerbrokerfiltersendbrokerfilterjava147  orgapacheactivemqbrokercompositedestinationbrokersendcompositedestinationbrokerjava96  orgapacheactivemqbrokertransactionbrokersendtransactionbrokerjava307  orgapacheactivemqbrokerbrokerfiltersendbrokerfilterjava147  orgapacheactivemqbrokerbrokerfiltersendbrokerfilterjava147  orgapacheactivemqbrokermutablebrokerfiltersendmutablebrokerfilterjava152  orgapacheactivemqbrokertransportconnectionprocessmessagetransportconnectionjava467  orgapacheactivemqcommandactivemqmessagevisitactivemqmessagejava751  orgapacheactivemqbrokertransportconnectionservicetransportconnectionjava292  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5568,added  jmx  metic  network  per  destination,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5569,add  new  mode  jms  pool  allows  caching  producer  current  jms  pool  creates  single  anonymous  producer  instance  request  create  producer  case  user  might  want  separate  producer  instance  created  requestor  add  new  option  pooledconnectionfactory  pooledsessions  create  separate  messageproducers  topicpublishers  queuesenders  create  call,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5570,secure  server  simple  do  attack  originating  httpforumslogicblazecompostslist205page  simply  start  40  server  used  stock  config  another  window  telnet  localhost  61616  receieve  activemq12c  type  asdfasdf  connection  close  future  tcp  connection  either  telnet  real  jms  client  hang,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
5571,improve  performance  composite  topic  fanout  persistent  asyncsend  publisher  publishing  topic  5  topic  queue  routings  get  max  message  rate  attainable  833  messagessec  message  around  5k  size  test  set  jms  config  topic  queue  topic  topicrouted1  topicrouted11  topic  increasing  number  routings  queue  client  set  subscribe  queue  rough  message  rate  routings  messagessec  0  2500  1  1428  2  2000  3  1428  4  1111  5  833  occurs  whether  broker  config  producerflowcontrolfalse  set  true  false  kahadb  disk  synching  turned  also  tried  experimenting  concurrentstoreanddispatch  didnt  seem  help  leveldb  didnt  give  notable  performance  improvement  either  also  asyncsend  enabled  producer  requirement  use  persistent  message  also  experimented  sending  message  transaction  hasnt  really  helped  seems  like  producer  throughput  rate  across  queue  destination  connection  publisher  machine  limited  something  broker  mechanism  producer  flow  control  think  prime  suspect  still  contention  index  test  yourkit  profiler  profiler  attached  broker  startup  allowed  run  topic  publisher  started  routing  5  queue  profiler  statistic  reset  publisher  allowed  run  60  second  profiling  snapshot  taken  time  9600  message  logged  sent  rate  160sec  tie  roughly  invocation  count  recorded  snapshot  think  43k  call  work  snapshot  filtering  everything  orgapacheactivemqstorekahadb  60  second  sample  period  248  second  elapsed  orgapacheactivemqstorekahadbkahadbtransactionstore1removeasyncmessageconnectioncontext  messageack  183  second  elapsed  orgapacheactivemqstorekahadbkahadbtransactionstore1asyncaddqueuemessageconnectioncontext  message  boolean  large  portion  time  spent  inside  messagedatabase  orgapacheactivemqstorekahadbmessagedatabaseprocesskaharemovemessagecommand  location  10  sec  elapsed  orgapacheactivemqstorekahadbmessagedatabaseprocesskahaaddmessagecommand  location  85  sec  elapsed  lock  indexlockwritelock  take  place  nio  transport  thread  think  account  least  message  throughput  limit  message  added  removed  index  one  one  regardless  sync  type  setting  add  fair  amount  overhead  synchronising  writes  disk  performing  work  nio  worker  thread  block  lock  could  account  behaviour  weve  seen  client  side  reproduce  1  install  broker  use  attached  configuration  2  use  580  example  ant  script  consume  queue  topicqueuerouted1  5  eg  ant  consumer  durltcplocalhost61616  dsubjecttopicqueuerouted1  duseradmin  dpasswordadmin  dmax1  3  use  modified  version  580  example  ant  script  attached  send  message  topic  topicrouted1  5  eg  ant  producer  durltcplocalhost61616jmsuseasyncsendtruewireformattightencodingenabledfalsekeepalivetruewireformatmaxinactivityduration60000socketbuffersize32768  dsubjecttopicrouted1  duseradmin  dpasswordadmin  dmax1  dtopictrue  dsleeptime0  dmax10000  dmessagesize5000  modified  version  script  print  number  message  per  second  print  console,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5572,add  mbean  method  browse  message  queue  purge  queue  delete  message,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5573,switch  using  proton  event  logic  detecting  amqp  state  change  currently  use  polling  model  detect  state  change  proton  engine  new  data  arrives  recent  update  proton  v070  allows  u  switch  new  event  collector  model  remove  polling  code  change  result  lower  overhead  processing  incoming  amqp  frame  increase  performance  amqp  transport  layer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5574,allow  changing  logger  level  via  jmx  create  new  mbean  loaded  broker  running  log4j  would  allow  changing  level  logger  via  jmx  enable  debug  without  needing  access  log4jproperties,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5575,queue  able  pauseresume  dispatch  message  consumer  would  good  able  pauseresume  dispatch  message  queue  queue  consumer  queue  paused  message  sent  associate  consumer  message  still  enqueued  queue  ability  able  browse  queue  jmx  counter  queue  available  correct,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5576,add  inmemory  jobschedulerstore  implementation  broker  run  persistence  disabled  currently  inmemory  job  scheduler  store  embedded  broker  without  persistence  cant  scheduled  message  broker  led  redelivery  without  manually  configuring  normal  jobschedulerstore  impl  requires  disk  based  store  add  memory  variant  default  persistence  disabled  scheduler  support  enabled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5577,mqtt  client  using  durable  subscription  networked  broker  received  duplicate  mqtt  client  create  durable  subscription  operate  network  broker  receive  duplicate  message  start  failing  back  forth  broker  network  investigate  using  virtual  destination  cover  instead  durable  topic  subscription  known  problem  durable  topic  case  virtual  destination  client  would  subscribed  queue  would  receive  message  sent  target  topic,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
5578,unify  client  sampler  timing  activemqperfmavenplugin  fundamentally  2  entity  plugin  managed  different  threadsthreadpools  client  generic  term  producer  consumer  sampler  throughput  cpu  entity  configured  separately  plugin  complete  slowest  done  problem  thing  separate  flag  generally  arent  overridden  unless  want  use  really  long  command  line  example  get  perf  test  run  10  second  following  mvn  activemqperfproducer  dproducersendduration10000  dtpsamplerduration10000  dtpsamplerrampuptime0  dtpsamplerrampdowntime0  dcpusamplerduration10000  dcpusamplerrampuptime0  dcpusamplerrampdowntime0  start  adding  flag  anything  useful  1  sampler  thread  sleep  rampup  time  default  30  longer  producer  send  duration  sampler  wont  even  start  anything  producer  well  truly  completed  2  test  run  longest  configured  sampler  default  throughput  cpu  run  kind  mess  id  love  able  use  principle  least  surprise  configuration  mvn  activemqperfproducer  dproducersendduration10000  mvn  activemqperfproducer  dproducersendtypecount  dproducersendcount10000,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
5579,destination  numerical  suffix  singledest  perf  test  performance  test  module  assumes  multiple  destination  put  load  thereby  assigns  numerical  suffix  destination  name  specified  command  line  thus  producerconsumer  configured  topicfoo  actually  sendreceive  topicfoo0  annoying  load  testing  particular  broker  setup  composite  destination  need  explicit  destination  targeted  always  possible  tweak  broker  configuration  propose  singledestination  test  numerical  suffix  added  patch  incoming,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5580,runtime  configuration  allow  change  destination  configuration  element  extend  runtime  configuration  feature  amq4682  allow  change  destination  configuration  element  5100  create  compositetopic  queuestopics  filtered  destination  within  destinationinterceptorsvirtualdestinationinterceptorvirtualdestinations  element  compositetopic  showup  broker  manager  topic  page  codexml  destinationinterceptors  virtualdestinationinterceptor  virtualdestinations  add  compositetopic  activemq  start  compositetopic  namecompositetopic  forwardonlyfalse  forwardto  queue  physicalnameforwardedqueue  forwardto  compositetopic  virtualdestinations  virtualdestinationinterceptor  destinationinterceptors  destination  compositetopic  forwardedqueue  queue  showup  broker  manager  unless  defined  someone  sends  message  compositetopic  topic  physicalnamecompositetopic  queue  physicalnameforwardedqueue  destination  code  note  usabilitymanagement  improvement  broker  correctly  forward  message  forwardedqueue  defined  destination  element,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0
5581,ignorenetworkconsumers  available  abortslowconsumerstrategy  abortslowackconsumerstrategyignorenetworkconsumers  introduced  httpsgitwipusapacheorgreposasfpactivemqgitacommith77bcffc9  placement  abortslowackconsumerstrategy  mean  cant  used  abortslowconsumerstrategy  without  abortconnectiontrue  cause  brokertobroker  network  connector  aborted  reestablished  described  httpirclogsdankulpcomlogsircloggerlogactivemqdate20130916montextoff  httpactivemq2283324n4nabblecomdroppingslowconsumerstd4671468html  httpactivemq2283324n4nabblecomabortconnectionquottruequottd4685674html  abortslowconsumerstrategy  would  benefit  able  use  flag  moved  abortslowconsumerstrategy  code  updated  use  allow  set  via  xml  config,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
5582,update  disk  based  limit  periodically  moment  set  store  temp  limit  broker  startup  based  configuration  available  space  possible  artefact  log  reduce  available  disk  space  limit  effect  itd  good  periodically  check  usable  space  left  adjust  limit  accordingly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5583,add  mean  dynamically  allocate  port  number  integration  testing  using  maven  plugin  port  number  connector  dynamically  allocated  using  special  port  number  0  currently  way  integration  client  determine  correct  port  number  registering  connector  uris  maven  project  property  make  easy  use  dynamicallyallocated  port  number  making  integration  test  safer  run  shared  server  eliminating  possibility  port  conflict,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5584,add  support  brokerview  mbean  get  uptime  millisecond  currently  one  get  broker  uptime  formatted  string  via  jmx  need  able  get  uptime  millisecond  using  datadog  monitoring  tool  doesnt  understand  current  uptime  formatted  string  uptime  formatted  string  remain  asis,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5585,upgrade  karaf  241  matching  camel  seems  stable  itests  wrt  hang  shutdown,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5586,make  activemq  jar  executable  able  sendreceive  message  would  nice  basic  verificationexample  tool  builded  directly  activemqclientjar  folk  something  like  codejava  jar  libactivemqclientxxxjar  producer  java  jar  libactivemqclientxxxjar  consumercode,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5587,amqp  implement  jms  mapping  spec  evolves  amqp  jms  mapping  specification  currently  development  oasis  issue  cover  work  done  implement  mechanic  necessary  broker  side  allow  jms  client  operate  amqp,1,0,1,0,1,0,0,1,1,1,1,0,0,1,1,1,1
5588,consider  preallocation  journal  file  batch  increment  right  activemq  512  release  preallocate  journal  file  scope  entire  journal  file  potential  issue  user  configures  large  journal  file  size  end  stalling  writes  log  rotation  allocation  process  two  way  allocation  configurable  userspace  defer  kernel  space  nevertheless  would  good  avoid  issue  altogether  preallocating  small  batch  size  regardless  journal  max  file  size,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5589,allow  advisory  message  traverse  broker  network  currently  filter  applied  forwarding  consumer  restrictive  suppress  advisory  message  two  type  advisory  used  network  bridge  allowing  propagation  selective  advisory  like  new  connection  advisory  handy  monitoring  application  level,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5590,jdbc  database  fails  log  next  exception  see  root  cause  database  failure,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5591,time  queue  statistic  handy  would  keen  jmx  console  exposed  queue  statistic  average  length  time  queue  current  message  longestshortest  time  queue  current  message  average  time  queue  serviced  message  opposed  waiting  longestlshortest  time  list  message  queue  posted  long  waiting,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5592,add  option  virtual  topic  selector  cache  enforce  single  selector  given  time  moment  virtualtopicselectorcache  pretty  bare  bone  allow  configuration  persist  period  file  location  operational  insight  via  jmx  also  allow  configure  cache  single  number  selector  enforce  automatic  cleanup  nonused  selector  avoid  large  pileup  message  ensure  consistent  usage  across  queue  used  virtual  topic,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5593,logging  database  locked  done  level  debug  sharedfilelocker  try  acquire  lock  activemq  lock  file  everytime  lock  output  logging  message  info  level  slave  try  forever  till  master  propose  log  debug  level  message  fill  log  global  default  info  log  level  20150407  123536522  info  database  activemqdatalock  locked  waiting  10  second  database  unlocked  reason  javaioioexception  file  activemqdatalock  could  locked  orgapacheactivemqstoresharedfilelocker  main,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5594,add  ability  get  message  size  message  store  currently  messagestore  interface  support  getting  count  message  ready  deliver  using  getmessagecount  method  would  also  useful  able  retrieve  message  size  count  well  keeping  track  metric  ive  created  pull  request  address  add  getmessagesize  method  focus  specifically  kahadb  memory  store  kahadb  store  us  strategy  existing  getmessagecount  method  iterate  index  total  size  message  unit  test  show  size  calculation  unit  test  show  store  based  version  5  working  new  version  index  rebuilt  one  extra  issue  size  serialized  index  included  marshaller  required  making  slight  change  adding  new  marshaller  location  store  size  location  index  store  without  change  size  computation  would  work  broker  restarted  since  size  serialized  note  wasnt  sure  best  way  handle  new  marshaller  version  compatibility  incremented  kahadb  version  5  6  old  version  index  loaded  index  detected  corrupted  rebuilt  new  format  better  way  handle  upgrade  let  know  patch  certainly  updated,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5595,add  test  stomp  websockets  fix  improve  close  handling  add  test  using  jetty  websocket  client  cover  stomp  websockets  fix  issue  connection  close  inactivity  handling  broker  side  want  ensure  close  inactivity  shut  stompsocket  resource,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
5596,amqp  add  support  heartbeat  inactivity  monitoring  update  protonj  091  able  take  advantage  idle  processing  added  release  send  empty  keep  alive  frame  order  keep  idle  connection  active  detect  dropped  connection,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5597,activemqsslconnectionfactory  hardcodes  keystore  type  issue  present  earlier  version  510x  maintained  right  minimum  use  keystoregetdefaulttype  even  sufficient  one  may  use  different  keystore  type  pkcs12  bk  keychain  osx  etc  configurable  default  getdefaulttype  defined  javasecurity  default  jks  shouldnt  impact  current  user  testing  patch  able  commit  day  two,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5598,amqp  allow  delivery  transformer  fallback  lower  level  transformer  transformation  fails  client  sends  amqp  cannot  transformed  using  configured  transformer  broker  shouldnt  drop  message  instead  attempt  fallback  le  aggressive  transformer  example  would  broker  configured  use  jms  transformer  incoming  message  contains  body  consisting  describedtype  jms  transformer  would  fail  direct  way  map  jms  message  type  could  case  fallback  native  transformer  still  process  message  openwire  client  instance  would  receive  bytesmessage  amqp  client  would  get  message  form  sent  allows  message  roundtrip  instance  amqp  openwire  openwire  amqp  broker  network  bridge  without  losing  original  payload  message  property,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5599,amqp  return  complete  source  client  look  existing  durable  subscription  client  looking  existing  durable  subscription  resubscribe  need  return  source  instance  contains  much  original  information  used  create  durable  sub  thing  like  nolocal  flag  selector  used  returned  client  validate  request  subscription  attempting  make  fail  otherwise  respond  old  one  match  expectation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5600,revisit  topic  statistic  currently  topic  statistic  confusing  especially  youre  using  wildcard  subscriber  case  inflight  count  dequeue  count  never  updated  message  acked  user  think  message  consumed  statistic  primarily  developed  queue  adapted  topic  doesnt  make  sense  use  case  itd  make  sense  keep  enqueuedequeue  property  topic  see  general  behaviour  topic  every  consumer  keep  enqueue  dequeue  inflight  enqueuedequeue  count,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5601,amqp  support  transaction  span  multiple  session  single  txn  client  ability  single  txn  span  multiple  session  desired  tx  coordinator  link  opened  session  still  allow  link  session  send  receive  inside  tx  coordinator  declared  moment  client  appear  work  case  leak  memory  transacted  sends  session  associated  coordinator  link  rolled  back  redelivered  correctly,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5602,improve  performance  textfilecertificateloginmodule  many  entry  textfilednuser  file  large  number  entry  200000  orgapacheactivemqjaastextfilednuser  file  performance  seemed  degrade  demonstrate  performance  difference  code  1  100  entry  calling  initializelogincommit  10  time  time  taken  73  miliseconds  2  200000  entry  calling  initializelogincommit  10  time  time  taken  5020  miliseconds  code  suggested  improvement  avoid  loading  orgapacheactivemqjaastextfilednuser  file  time  propertiesloginmodulejava  file  read  change  using  file  modification  time  avoid  iterating  property  object  using  map  instead  retrieve  username,1,0,1,0,1,0,1,0,0,0,1,1,0,0,0,0,0
5603,support  single  port  wire  protocol  apollo  artemis  support  ability  use  single  port  protocol  automatic  detection  protocol  used  would  nice  able  support  least  subset  feature  5x  broker  well  ideally  least  able  detect  openwire  mqtt  stomp  amqp  tcp  ssl  nio  transport  websockets  http  would  bonus  could  difficult  implement  depending  could  work  jetty  would  take  investigation  especially  useful  environment  open  several  new  port  difficult  firewall  security  restriction,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5604,support  java  api  runtimeconfigurationplugin  currently  runtimeconfigurationplugin  support  modifying  part  broker  runtime  changing  xml  configuration  broker  doesnt  need  restarted  pick  change  however  2  issue  approach  first  situation  always  use  xml  configure  broker  many  time  broker  configured  using  java  configuring  brokerservice  directly  store  configuration  different  way  manage  second  dont  always  want  permanently  change  configuration  sometimes  need  temporarily  create  new  virtual  destination  dynamic  data  flow  dont  necessarily  need  persist  restarts  would  useful  case  able  make  change  broker  configuration  using  java  api  programmatically  thing  modifying  virtual  destination  change  would  temporary  nature  wouldnt  persisted  would  xml  used  however  change  need  persisted  user  could  simply  use  xml  configure  broker  responsible  storing  information  however  want  recover  restart  broker,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
5605,improve  performance  virtual  topic  fanout  virtual  topic  provide  nice  alternative  durable  sub  durable  sub  modeled  separate  queue  performance  implication  however  message  sent  fanout  queue  durable  sub  single  message  journal  index  update  sub  improve  performance  three  way  improve  comparison  virtual  topic  durable  sub  avoid  disk  sync  associated  enqueue  parallel  enqueues  get  store  batching  writes  introduce  message  reference  journal  reduce  disk  io  1  introducing  transaction  either  client  side  automatically  broker  side  ensures  single  disk  sync  commit  2  using  executor  sends  parallel  allows  journal  batch  seen  amq5077  3  implementation  lot  involved  recovery  need  journal  write  per  destination  reading  journal  require  two  read  indirection  tracking  gc  need  handled  ensure  referenced  entry  maintained  short  lot  work  visible  large  8k  message  cost  large  v  small  journal  write  noticeable  messageid  datalocator  provides  entry  point  work  considering  1  2  combined  give  3x  improvement  dont  think  worth  effort  added  complexity  moment,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5606,add  pending  message  size  metric  right  pendingmessagecursor  keep  track  number  pending  message  size  method  would  useful  also  report  back  total  message  size  besides  count  know  much  memory  disk  space  used  pending  message  kahadb  keeping  track  size  message  512  possible  report  back  value  nonblocking  way  queue  pretty  straightforward  durablesubscriptions  work  need  done  keep  track  message  size  unacked  message  subscription,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
5607,add  removemessageid  jmx  operation  offline  durable  subscription  mirroring  queue  remove  jmx  operaton  jmx  operation  remove  message  offline  durable  subscription  essentially  force  ack  subscription  usage  browse  find  required  messagid  string  invoke  removemessageid,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5608,improve  disk  based  limit  configuration  amq5393  configuration  option  added  update  disk  based  limit  periodically  disk  space  shrank  would  useful  improve  allow  disk  based  limit  also  regrow  size  maximum  disk  space  becomes  free  also  would  useful  able  specify  limit  percentage  partition  size  instead  absolute  value,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5609,amqp  add  support  sending  scheduled  message  using  message  annotation  add  support  reading  scheduled  message  instruction  specific  message  annotation  mapped  value  work  builtin  broker  scheduler  feature  annotation  namedescription  xoptdeliverytimeanalogous  jms  20  delivery  time  message  property  value  set  millisecond  since  unix  epoch  xoptdeliverydelaytime  millisecond  wait  dispatching  message  xoptdeliveryrepeatnumber  time  reschedule  message  sent  fixed  delay  xoptdeliveryperiodthe  time  m  wait  successive  repeat  scheduled  message  xoptdeliverycrona  crontab  entry  control  message  scheduled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5610,better  configuration  restricted  class  client  amq6013  introduces  check  class  allowed  serialized  objectmessages  original  implementation  designed  protect  broker  system  property  configuration  easiest  solution  change  affect  client  us  objectmessagesgetobject  method  need  provide  better  way  configuring  client  initial  idea  provide  configuration  activemqconnectionfactory  activemqcomponent  class,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
5611,java  runtime  policy  update  support  list  property  apply  retrospectively  right  javaruntimeconfigurationbroker  used  update  policy  entry  every  property  policy  reapplied  matching  destination  update  would  also  nice  optional  list  property  could  provided  update  behavior  option  would  still  apply  entire  policy  entry  update  new  destination  get  policy  change  existing  destination  property  match  whats  property  list  would  get  applied  use  case  would  wanting  apply  one  property  changed  policy  destination  wanting  overwrite  property  might  changed  since  creation  destination  example  say  jmx  someone  updated  maxpagesize  property  specific  queue  something  specified  policy  fact  might  desirable  update  different  property  policy  match  queue  applied  queue  normally  policy  update  would  overwrite  property  existing  queue  case  would  want  overwrite  maxpagesize  setting  changed  fact  providing  list  property  apply  would  prevent  setting  changed,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5612,improve  nio  transport  scalability  nio  transport  us  unbounded  thread  pool  executor  handle  read  operation  large  number  connection  load  could  lead  large  number  thread  eventually  oom  error  exact  problem  nio  transport  supposed  solve  work  done  amq5480  make  configurable  there  still  work  make  robust  creating  fixed  thread  pool  queue  front  give  much  better  result  test  additionally  thread  pool  used  accepting  connection  amq5269  lead  broker  able  accept  new  connection  load  got  much  better  result  experimenting  implementing  acceptor  logic  directly  handling  thread  without  reintroducing  old  problem  two  improvement  place  broker  accept  handle  number  connection  system  limit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5613,kahadb  allow  rewrite  message  acks  older  log  prevent  cleanup  case  chain  journal  log  grow  due  acks  message  older  log  needing  kept  recovery  proper  state  restored  older  message  resurrected  many  case  moving  acks  one  log  forward  new  log  free  entire  chain  subsequent  gc  cycle  compacted  ack  log  written  time  gc  cycle  without  index  lock  held  meaning  normal  broker  operation  continue,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
5614,max  frame  size  error  exception  show  incorrect  value  time  value  size  1  mb  error  message  read  0  mb  instead  scaling  byte  kb,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5615,add  xaconnectionfactory  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5616,allow  advisory  consumer  prefetch  configuration  network  consumer  place  prefetch  value  advisory  consumer  configured  separately  prefetch  value  nonadvisory  consumer  default  advisory  consumer  configured  optimize  acknowledgement  however  networkbridgeconfiguration  allows  setting  prefetchsize  allow  configuring  advisory  prefetch  size  would  useful  able  configure  prefetch  size  separately  advisory  consumer  well  percentage  prefetch  used  determining  send  back  ack  currently  set  75,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5617,kahadb  journal  recovery  last  append  error  normal  restart  case  normal  restart  journal  replayed  last  append  location  error  reporting  unnecessary  info  logging  formcodeinfo  recovering  journal  1503  info  recovery  replayed  1  operation  journal  00  secondscode  recovery  required  last  append  location  different  recovery  location,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5618,amqp  add  support  amqp  websockets  add  support  amqp  connection  w  w  transport,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,1
5619,add  option  time  connection  attempt  blocked  ensureconnectioninfosent  rare  case  client  side  stack  trace  show  client  stuck  ensureconnectioninfosent  wanting  forever  response  broker  add  optional  timeout  allow  operation  fail  default,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5620,add  command  synchronize  durable  subscription  network  bridge  dynamicallyincludeddestinations  used  networkconnector  durable  subscription  tracked  addedremoved  connector  allows  broker  create  network  subscription  automatically  remote  broker  match  demand  created  destroy  network  subscription  longer  needed  problem  bridge  restarted  broker  restarted  information  durable  subscription  lost  example  bridge  stopped  local  durable  subscription  added  new  durable  added  remote  conduit  network  conduit  subscription  reconnect  local  durable  subscription  removed  bridge  offline  reconnect  remote  durable  sub  cleaned  even  matching  durables  fix  need  add  new  openwire  command  support  syncing  durable  subscription  bridge  restarted  goal  command  readd  missing  subscription  clean  longer  needed  subscription  reconnect  note  new  sync  option  apply  dynamiconly  false  conduitsubscriptions  true  enabled  default,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5621,amqp  improve  message  transformation  provide  better  cross  protocol  messaging  current  jms  message  transformer  always  convert  incoming  amqp  message  type  appropriate  consumption  openwire  client  also  sometimes  transform  message  back  expected  amqp  type  sending  stored  message  back  amqp  client,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5622,add  nonblocking  subscription  statistic  kahadb  currently  kahadb  topicmessagestore  support  returning  messagecount  messagesize  subscription  requires  locking  index  iterating  compute  information  use  case  query  information  regularly  status  broker  performance  take  hit  locking  option  enable  statistic  counter  keep  track  information  queried  without  locking  like  store  currently  track  total  count  size  subscription  also  disabled  default  overhead  computing  metric  lot  subscription  store,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
5623,introduce  periodic  disk  sync  mode  kahadb  journal  kahadb  two  mode  journal  disk  syncs  either  always  sync  write  never  sync  im  proposing  add  third  option  period  disk  sync  intended  behavior  would  run  task  file  appender  would  sync  file  necessary  periodic  interval  every  500  m  1  second  etc  instead  every  write  file  would  also  synced  close  file  rollover  shutdown  testing  syncing  every  1  second  proven  nearly  indistinguishable  performance  never  disk  syncing  safer  option  insure  sync  performed  least  per  interval,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
5624,add  flag  allow  forcing  network  subscription  durable  network  bridge  two  broker  topic  included  conduit  subscription  created  topic  cause  issue  mixture  durable  nondurable  subscription  issue  conduit  subscription  get  created  type  subscription  across  bridge  either  durable  nondurable  depending  local  subscription  get  created  first  problem  might  end  local  durable  sub  network  bridge  conduit  sub  actually  nondurable  also  cause  issue  consumer  go  away  conduit  sub  get  destroyed  instead  retained  durable  fix  scenario  think  option  force  conduit  subscription  durable  could  done  per  topic  basis  topic  hierarchy  something  like  following  codexml  networkconnector  namebroker1  duplextrue  uristatictcp10xxx61616  dynamicallyincludeddestinations  topic  physicalnametesttopicforcedurabletrue  dynamicallyincludeddestinations  networkconnector  code,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
5625,add  method  sending  message  topic  queue  simplify  testing  embeddedactivemqbroker  activemqjunit  method  send  message  topic  queue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5626,implement  jmx  destination  query  api  environment  thousand  destination  broker  current  way  exposing  mbeans  looking  tool  scale  need  implement  api  used  tool  filter  sort  page  destination  scenario,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5627,durable  sync  network  bridge  sync  forced  durable  subscription  syncdurablesubs  flag  network  bridge  cause  durable  subscription  synced  connection  however  applies  real  durable  subscription  there  another  option  network  bridge  added  amq6383  allows  forcing  subscription  bridge  always  durable  make  sure  normal  topic  subscription  synced  properly  virtual  consumer  subscription  also  synced  properly  consumer  part  destination  configured  force  durables,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5628,amqp  add  frame  inspection  capability  test  client,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
5629,support  ssl  configuration  using  jndi  add  ability  configure  ssl  parameter  using  jndiproperties  file  current  apachemqinitialcontextfactory  support  configuring  connection  factory  type  activemqsslconnectionfactory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5630,update  protonj  0160  update  protonj  0160  add  support  answering  sender  request  link  capability  delivery  delay,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5631,refactoring  karaf  itests  karaf  itests  improved  quite  lot  prepare  bigger  refactoring  bring  test  good  condition,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
5632,update  amq  c  client  attached  new  update  c  client  zipfile  contains  full  source  since  update  major  overhaul,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5633,add  new  implementation  writeutf8  readutf8  method  provide  implementation  based  apache  harmony  code  remove  code  duplication,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5634,improve  performance  kahadb  recovery  check  checkforcorruptjournalfilestrue  kahadb  checkforcorruptjournalfiles  option  validates  checksum  every  journal  batch  record  startup  single  producer  writes  many  small  message  batch  size  journal  small  current  check  implementation  read  batch  time  fseekread  sequence  slow  shared  disk  check  quick  buffered  sequential  read  using  maxbatchsize  already  tuned  match  disk  transfer  rate,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5635,several  function  spelled  wrong  impairs  code  readability  openwire  marshalling  code  script  java  sunmarsalunmarshal  openwireformatjava  wireformatnegotiatorjava  openwireformatfactoryjava  snegociatnegotiate  nitpicks  yes  cause  wasted  time  looking  around  function  didnt  exist,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5636,allow  customisation  network  bridge  creation  logic  currently  network  bridge  factory  fixed  logic  would  nice  make  customizable,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
5637,startup  performance  improvement  log  contains  prepared  transaction  kahadb  thats  performing  recovery  startup  digging  deeper  ive  found  issue  dblog  contains  prepared  transaction  messagedatabase  discard  entry  memory  however  remove  transaction  info  message  believe  thats  design  restart  broker  find  entry  discard  memory  access  broker  via  jmx  go  prepared  xas  execute  clear  one  one  restart  broker  dont  recovery  attempted  performing  remove  operation  message  time  consuming  id  like  introduce  optional  parameter  allow  prepared  xas  removed  recovery  please  see  forth  coming  patch  unit  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5638,destinationmap  access  inside  abstract  region  readwrite  lock  need  sync  using  multiple  virtual  topic  publisher  unnecessary  serialisation  via  destination  map  read  write  lock  introduced  amq3454  sufficient  guard  access  case  read  operate  parallel  many  thousand  destination  lookup  expensive  serialisation  becomes  apparent,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5639,add  support  tl  hostname  verification  add  support  transport  server  client  side  configure  hostname  verification  enabled  disabled,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5640,suppress  optionally  warn  logging  eof  reset  exception  remote  socket  closed  loadbalancer  health  check  ping  transport  connector  endpoint  verify  broker  listening  port  using  socketopenclose  subsequent  read  failure  treated  error  logged  warn  make  sense  general  bc  indicative  rogue  client  however  norm  ie  health  check  log  get  filled  worrying  message  fact  expected  somtp  transport  protocol  close  method  already  suppress  eof  connection  reset  exception  improvement  would  make  default  behaviour  tcp  transport  allow  enabled  required  via  configuration  codejava  transportconnector  warnonremoteclosetrue  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5641,activemq  read  lot  index  page  upon  startup  graceful  ungraceful  shutdown  hi  noticed  activemq  read  lot  page  index  file  starting  recover  destination  statistic  httpsgithubcomapacheactivemqblobmasteractivemqkahadbstoresrcmainjavaorgapacheactivemqstorekahadbkahadbstorejaval819  nowadays  order  activemq  traverse  storeddestinationlocationindex  get  messagecount  totalmessagesize  destination  destination  lot  message  process  take  making  startup  process  take  long  time  case  masterslave  broker  prevent  broker  fast  failover  meet  stated  httpactivemqapacheorgsharedfilesystemmasterslavehtml  quoteif  san  shared  file  system  used  provide  high  availability  broker  killed  another  broker  take  immediately  quote  one  solution  keep  track  destination  statistic  summary  index  file  dont  need  read  locationindex  start  code  change  proposed  backward  compatible  need  bump  kahadb  version  information  index  broker  fall  back  current  implementation  mean  first  time  people  upgrade  new  version  still  read  locationindex  subsequent  restarts  fast  change  negligible  performance  impact  normal  activemq  operation  change  introduce  byte  data  index  information  checkpoint  also  new  information  synchronized  locationindex  update  transaction,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5642,publish  brokerservice  osgi  service  local  broker  started  karaf  might  come  later  user  code  connects  lead  unnecessary  error  publish  brokerservice  osgi  service  user  depend  service  delay  startup  service  present,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5643,nice  destinationviewbrowse  could  accept  message  selector  string  would  nice  destinationview  mbean  could  implement  browse  command  could  accept  message  selector  filter  message  could  browsed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5644,mapmessage  support  nested  map  object  create  typesafe  hierarchial  message  used  rv  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5645,support  spool  disk  nonpersistent  topic  consumer  rather  blocking  ram  full  could  highwater  mark  start  spooling  message  disk  sufficient  ram  hold  message  good  thing  approch  avoids  blocking  producer  ram  full  downside  spooling  start  producer  slowed  speed  disk  spooling  due  ram  exhaustion  steady  state  producer  wait  message  spooled  disk  evict  ram  send  next  message  though  journal  quite  fast  slow  shouldnt  many  order  magnitude  better  making  thing  appear  lock  wait  slowest  consumer  acknowledge  message,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5646,allow  asynchronous  dispatch  consumer  broker  nondurable  topic  typically  use  current  thread  broker  dispatch  available  nondurable  consumer  performance  hugely  reduces  context  switching  increase  performance  however  see  amq688  sometimes  cause  one  dead  consumer  block  producer  folk  may  want  switch  strategy  use  slower  asynchronous  dispatch  thread  pool  reduce  risk  blocking  producer  expensive  lower  performance,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5647,support  tracetrue  option  http  client  side  transport,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5648,amq376  ldap  based  authorization  support  patch  kindly  added  ngcutura  discussion  thread  httpwwwnabblecomldapauthorizationtf1851705htmla5344494,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5649,add  support  prefetchsize  0  feature  would  enable  support  following  test  case  2  server  processing  3  submitted  job  following  processing  time  10  min  1  min  1  min  sequence  finish  10  minute  one  service  pick  10  minute  job  meanwhile  one  manage  two  1  minute  job  since  cannot  set  prefetchsize0  one  1  minute  job  sitting  prefetch  buffer  job  processed  11  minute  instead  10  simplification  real  scenario  30  consumer  submitting  job  20  consumer  amq  401  following  problem  \x95  message  sitting  prefetch  buffer  available  processor  result  lot  idle  time  \x95  order  processing  random  reason  job  20  processed  job  1500  since  sender  synchronously  blocked  result  timeouts  \x95  request  realtime  ie  user  waiting  system  cannot  wait  amq850  fix  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5650,allow  messageevictionstrategy  evict  one  messagereference  evictmessagelinkedlist  message  method  slow  consumer  every  time  single  message  added  topicsubscription  pending  message  limit  reached  new  call  evictmessage  made  allow  flexible  efficient  mean  evicting  message  would  nice  able  evict  multiple  message  one  call  evictmessage  allows  new  messageevictionstrategy  implementation  evict  based  age  message  eg  evict  message  pending  message  list  older  x  m  duplicate  message  evict  message  redundant  based  newer  message  currently  pending  message  list  etc  single  call  evictmessage  method  may  opportunity  reduce  size  pending  message  list  one  mean  next  message  added  topicsubscription  may  need  call  evictmessage,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5651,patch  refactoring  allow  alternative  using  different  storage  interface  destination  implementation  looking  alternate  message  persistence  mechanism  coexist  current  activemq  code  base  thinking  mechanism  somewhat  incompatible  current  messagestore  persistenceadapter  apis  unfortunately  current  activemq  broker  doesnt  allow  change  persistenceadapter  messagestore  interface  referenced  directly  regionbroker  queue  topic  region  implementation  therefore  proposing  relatively  small  backwards  compatible  refactoring  broker  code  would  eliminate  dependency  persistenceadapter  messagestore  interface  class  use  directly  refactoring  would  also  allow  creation  custom  destination  implementation  may  use  alternative  persistence  mechanism  destination  destination  basis  exactly  need  main  idea  behind  refactoring  replace  many  reference  persistenceadapter  new  interface  destinationfactory  public  abstract  class  destinationfactory  abstract  public  destination  createdestinationconnectioncontext  context  activemqdestination  destination  destinationstatistics  destinationstatistics  throw  exception  abstract  public  set  getdestinations  abstract  public  subscriptioninfo  getalldurablesubscriptionsactivemqtopic  topic  throw  ioexception  abstract  public  long  getlastmessagebrokersequenceid  throw  ioexception  abstract  public  void  setregionbrokerregionbroker  regionbroker  note  destinationfactory  doesnt  mandate  specific  persistence  mechanism  class  would  reference  instead  persistenceadapter  regionbroker  abstractregion  queueregion  topicregion  also  abstractregioncreatedestination  method  would  changed  abstract  implementation  us  destinationfactory  create  destination  brokerservice  could  changed  use  destinationfactory  one  provided  none  provided  create  destinationfactory  implementation  instantiates  queue  topic  using  persistenceadapter  currently  hence  full  backwards  compatibility  maintained  patch  attached,1,1,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0
5652,allow  message  copied  moved  deleted  using  jms  selector,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5653,make  activeio  dependency  optional  dependency  need  move  core  class  activeio  activemq  needed  run  right  real  functionality  provides  optional  journal  implementation  everything  else  use  activeio  abstract  interface  think  need  movedcopied  activemq,1,1,1,1,1,0,0,1,0,0,0,0,0,0,0,0,1
5654,activemq  support  ssl  authentication  authorization  patch  add  new  transport  broker  plugins  needed  authentication  authorization  based  ssl  certificate  also  add  unit  test  mentioned  class  new  heavily  modified  ssltransport  ssltransportserver  ssltransportfactory  class  allow  access  underlying  socket  need  want  client  auth  setting  certificate  found  set  transportcontext  created  connection  jaascertificateauthenticationbroker  us  new  certificateloginmodule  authenticate  certificate  class  abstract  allow  different  backends  certificate  authentication  concrete  class  textfilecertificateloginmodule  jaascertificateauthenticationbroker  also  set  security  context  user  name  provided  certificate  login  module  allows  authorization  using  existing  authorization  broker,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5655,two  tcp  connection  requirement  bidirectional  message  flow  noticed  following  testing  broker  establishes  connection  broker  b  message  flow  unidirectional  b  issue  u  example  consider  broker  associated  business  critical  service  x  many  secondary  service  either  monitorfeed  message  coming  foo  service  would  like  process  message  going  x  foos  broker  configuration  add  x  name  however  message  going  flow  x  foo  till  x  initiate  connection  foo  may  desirablepossible  change  business  critical  broker  configuration  usage  scenario  like  tcp  bidirectional  asymmetry  connection  establishment  translated  higher  level  network  connector  fundamental  needjustification  design  may  aware  otherwise  would  like  explore  design  option  thanks  regard  sridhar  komandur,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5656,improved  error  reporting  ssl  transport  changed  username  ssl  cert  dn  attached  patch  provides  better  error  reporting  transport  error  reporting  host  trying  connect  also  provides  tostring  ssltransport  distinguish  regular  tcp  transport  includes  improved  javadoc  new  ssl  client  certificate  authentication  feature  additionally  change  username  reported  jmsxuserid  field  full  distinguished  name  rather  username  mapped  user  property  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5657,add  support  stompssl,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5658,deal  null  value  measure  inmem  cubing  previously  null  value  dealt  dimension  layered  cubing  inmem  cubing  however  null  value  measure  dealt  layered  cubing  null  value  measure  inmem  cubing  also  dealt,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
5659,fix  sonar  reported  static  code  issue  phase  1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5660,reduce  number  visiting  metastore  job  scheduler  kylin3470  introduced  cache  job  metadata  also  used  job  scheduler  reduce  pressure  metastore,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5661,make  calcite  extra  prop  available  jdbc  driver  like  kylin3475  calcite  configured  server  kylinproperties  jdbc  driver  closer  real  query  sql  generation  calcite  configured  jdbc  client  would  flexable  various  situation  like  quoting  mysql  use  mysqlspecified  sql  grammer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5662,make  jdbc  module  testable  trying  work  kylin3496  found  difficult  test  would  offer  work  make  testable,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
5663,support  mysql  kylin  metadata  storage  kylin  us  hbase  metastore  case  user  expects  metadata  hbase  sonny  heer  mailing  list  mentioned  im  fairly  certain  anyone  using  kylin  aws  emr  benefit  multiple  hbase  cluster  across  az  huge  benefit  btw  thing  blocking  moment  write  operation  happening  kylin  query  node,1,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0
5664,fix  potential  threadsafe  problem  resourcetool  class  orgapachekylincommonpersistenceresourcetool  called  method  command  line  got  potential  threadsafe  problem  regarding  static  variable  pathsskipchildrencheck  multiple  thread  trying  modify  variable  screen  shot  20180716  23639  pmpng,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5665,improve  cube  building  process  using  global  dictionary  current  cubing  process  global  dictionary  large  since  raw  data  record  unsorted  hard  encode  raw  value  id  input  bitmap  due  frequent  swap  dictionary  slice  need  refined  process  idea  follows  source  data  block  mapper  generating  distinct  value  sort  encode  sorted  distinct  value  generate  shrunken  dict  source  data  block  building  base  cuboid  use  shrunken  dict  source  data  block  encoding,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5666,fact  distinct  column  spark,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5667,single  column  query  dictionary  enough  common  use  case  bi  tool  follows  firstly  extract  value  dimension  column  select  part  value  filter  condition  previously  query  first  step  requires  hit  segment  cuboid  data  may  efficient  especially  segment  occupy  many  region  use  dictionary  rather  cuboid  data  answer  kind  query  reduce  cost  many  rpcs  hbase  sample  query  follows  code  select  group  code  code  select  distinct  code  code  select  maxa  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5668,support  prepare  statement  kylin  server  side  kylin  use  calcite  sql  engine  sql  come  kylin  server  requires  parsed  optimized  code  gen  query  kylins  cube  storage  previous  3  step  often  take  50150  m  completedepends  complexity  sql  support  cache  parsed  result  kylin  server  3  step  saved  idea  cache  calcite  preparedstatement  object  related  olapcontexts  server  side  prepare  request  come  sql  reuse  preparedstatement  execution  since  preparedstatement  thread  safe  planned  use  objectpool  cache  preparedstatementuse  apache  commonspool  lib,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5669,merge  dictionary  statistic  yarn  currently  merge  dictionary  statistic  step  kylins  jvm  cause  great  burden  kylin  move  step  yarn,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5670,improve  http  return  code  rest  api  kylin  return  500  error  invalid  input  example  invalid  cube  name  job  exceeds  maximum  number  etc  need  refine  behavior  invalid  user  input  return  4xx  http  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
5671,improve  cube  size  estimation  topn  count  distinct  currently  kylin  poor  cube  size  estimation  topn  count  distinct  improve  get  reasonable  split  num  cube  building,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5672,user  interface  hybrid  model  hybrid  model  useful  model  change  entry  gui  make  many  user  dont  see  feature,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5673,optimize  spark  cubing  memory  footprint  noticed  step  optimized  1  cuboidfindformandatory  create  new  object  time  cached  2  executor  repeatedly  load  dictionary  hit  cache  3  ndcuboidbuilder  rowkeyencoder  optimize  le  array  copy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5674,kill  spark  app  cube  job  discarded  currently  discard  spark  job  spark  job  still  running  restart  jobserver  sparkexecutable  submit  new  spark  job  handle  spark  job  mr  job,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5675,merge  cube  segment  spark,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5676,performance  improvement  factdistinctcolumnsmapper  currently  factdistinctcolumnsmapper  writes  every  cell  mapper  output  spite  mapper  side  combiner  could  better  dedup  using  available  mapper  memory  situation  becomes  worse  kylin3370  dictionary  column  every  dimension  column  get  written  mapper  output  suggest  nondictionary  dimension  column  write  minmax  value  mapper  output,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5677,enhance  segment  pruning  1compute  store  dimension  range  cubesegment  2if  query  condition  dont  satisfy  dimension  range  need  scan  segment,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
5678,convert  hfile  spark  reference  httpswwwopencorecomblog201610efficientbulkloadofhbaseusingspark,1,1,1,0,1,1,0,0,0,1,1,0,1,0,0,0,0
5679,support  kafka  table  join  hive  table  moment  data  source  kafka  1  table  allowed  data  model  case  joining  kafka  stream  hive  lookup  table  expected,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5680,enhance  hql  materializing  view  hard  maintain  code  creating  hql  insert  overwrite  table  viewname  select  tablename  n  liable  miss  thus  add  ut  prevent  situation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5681,refactor  storage  garbage  clean  code  kylin  produce  garbage  data  storage  run  clean  tool  kylinsh  orgapachekylintoolstoragecleanupjob  show  garbage  data  clean  garbage  setting  option  –delete  false  delete  true  kylin  cant  show  size  garbage  data  user  reconfiguration  add  member  variable  method  recording  garbage  size  detection  process  clean  job  running  kylin  get  information  garbage  size,1,0,1,0,1,0,1,0,0,1,1,0,0,0,0,0,1
5682,allow  project  set  source  project  level  currently  project  connect  source  set  kylinproperties  kylinsourcedefault  property  better  allow  project  set  source  project  level  override  configuration  result  project  connects  jdbc  project  b  connects  hive,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1
5683,util  class  encryption  decryption  extract  method  encrypt  decrypt  orgapachekylinrestsecuritypasswordplaceholderconfigurer  util  class  corecommon  package  make  reusable,0,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0
5684,add  unit  test  storagecleanupjob,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5685,add  manager  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5686,add  manager  project  acl  aclrecord  need  cached,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5687,add  hook  customer  made  testcasedata,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5688,improve  ci  coverage  current  ci  aka  buildcubewithengine  test  merge  mr  engine  merge  operation  tested  spark  engine  need  improve  test  coverage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5689,resourcestore  add  api  recursively  list  path,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5690,clean  necessary  cache  cubemigrationcli  currently  simply  clear  cache  cubemigrationcli  make  query  slower  prod  env  many  table  model  cube  migrate  cube  often  could  clean  necessary  cache  cubemigrationcli,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5691,support  kafka  json  message  whose  property  name  includes  far  kylin  doesnt  support  json  message  property  name  would  conflict  kylins  logic  example  json  message  code  user  firstname  tom  age  20  code  map  topic  table  firstname  mapped  userfirstname  kylin  parse  message  separate  try  find  user  first  name  first  property  error  reported,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5692,remove  getkeyvalue  setkeyvalue  kylins  pair  pair  semantic  keyvalue  serializingdeserializing  pair  firstsecond  keyvalue,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5693,tolerate  broken  job  metadata  caused  executable  classnotfoundexception  kylin  evolves  many  executable  class  renamed  deprecated  lead  broken  job  metadata  classnotfoundexception  thrown  many  place  code  better  tolerate  error  metadata,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5694,refine  email  template  notification  freemarker,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
5695,metadata  broadcast  retry  failed  node  commit  httpsgithubcomapachekylincommitecc01458c4ad361aaf863505884d51474a8fec9d  kylin  start  retry  failed  metadata  sync  event  however  reposts  failed  event  node  retry  apply  failed  node,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5696,enhance  query  timeout  entire  query  life  cycle  nowadays  kylins  query  timeout  kylinquerytimeoutseconds  one  olap  context  entire  query  life  cycle,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5697,improve  hbase  coprocessor  exception  handling  kylin  server  side  query  may  need  bunch  hconnections  visit  hbase  anyone  fails  whole  query  interrupted  related  hconnections  released  future  query  despite  currently  cannot  interrupt  thread  hbase  coprocessor  side  achieve  goal  one  property  added  querycontext  keep  throwable  substep  query  detects  throwable  stop  expectedsizeiterator  two  part  detection  needed  putting  data  queue  iteration  exception  happens  query  stop  related  thread  thus  querystoplistener  added,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5698,make  query  visible  interruptible  improve  server  stablility  problem  1  large  query  result  break  kylin  server  example  select  facttable  even  property  kylinqueryscanthreshold  kylinquerymembudget  set  properly  oom  still  happens  hbase  rpc  thread  interrupted  result  continually  go  kylin  server  server  run  oom  quickly  multiple  query  2  tow  many  slow  query  occupy  tomcat  thread  make  server  unresponsed  3  there  corelation  id  specified  query  hard  find  rpc  log  specified  query  many  query  running  concurrently  solution  1  interrupt  rpc  thread  main  query  thread  return  result  size  larger  config  limit  size  2  make  query  visible  admin  view  running  query  detail  query  split  query  following  step  1  sql  parse  2  cube  plan  3  query  cache  4  multiple  cube  segment  query  segment  request  muliple  endpoint  range  request  b  endpoint  range  request  multiple  coprocessor  request  c  coprocessor  request  multiple  region  server  rpc  admin  view  starttimeendtime  step  thread  stack  trace  step  running  3  add  query  id  corelation  id  rpc  log  4  admin  interrupt  running  query  release  thread  memory  etc,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5699,support  sql  server  data  source  kylin1351httpsissuesapacheorgjirabrowsekylin1351  added  vertica  data  source  base  work  kylin1351  id  like  enable  sql  server  data  source  kylin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5700,enable  job  retry  configurable  exception  production  environment  always  get  certain  exception  hadoop  hbase  like  orgapachekylinjobexceptionnoenoughreplicationexception  javautilconcurrentmodificationexception  result  job  failure  exception  handled  retry  actually  much  convenient  able  make  job  retry  configurable  exception,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5701,introduce  projectlevel  concurrent  query  number  control  one  kylin  server  may  contain  many  project  avoid  project  occupying  much  resource  like  http  connection  projectlevel  query  number  limit  useful,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5702,enlarge  reducer  number  hyperloglog  statistic  calculation  step  factdistinctcolumnsjob  currently  one  reducer  assigned  hll  stats  calculation  may  become  bottleneck  slow  step  since  stats  different  cuboid  influence  better  divide  cuboid  set  several  assign  reduce  subset  strategy  patch  assign  100  cuboid  subset  there  upper  limit  reducer  hll  stats  calculation  currently  50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5703,use  multiple  thread  calculate  hyperloglogpluscounter  factdistinctcolumnsmapper,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5704,synchronize  readwrite  operation  manager  prevent  abnormal  behavior  reading  cache  getxxx  method  writing  cache  broadcast  reload  happens  time  manager,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
5705,refactor  consolidate  cache  manager  kylinconfig  refactor  consolidate  cache  manager  kylinconfig  single  place  clear  gc  cache  kylinconfig,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
5706,enable  kylinsourcehiveflattablestorageformat  flat  table  storage  format  flat  table  storage  format  currently  hardcoded  sequencefile  corejobsrcmainjavaorgapachekylinjobjoinedflattablejava  prevents  using  impala  sql  engine  using  beeline  cli  via  custom  jdbc  url  impala  cannot  write  sequence  file  adding  parameter  kylinproperties  override  default  setting  would  address  issue  removing  hardcoded  value  storage  format  might  good  idea,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5707,avoid  useless  work  checking  query  deadline  high  load  request  spend  long  time  waiting  rpc  queue  probably  longer  query  timeout  however  current  coprocessor  timeout  mechanism  doesnt  take  rpc  queue  time  account  result  handling  request  waste  server  resource  nothing  useful  also  cause  cascading  failure  server  crash  client  retries  recover  server  overload  asap  check  query  deadline  stage  query  processing  avoid  spending  resource  query  exceed  deadline,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
5708,support  usergroup  role  authentication  ldap  currently  user  authentication  interface  provided  kylin  third  party  support  user  role  authentication  however  user  group  authentication  function  use  ldap  authentication  fact  authentication  user  role  authentication  user  group  functional  characteristic  different  appplication  system  submit  new  feature  support  authentication  user  role  authentication  user  group  ldap  authentication  enabled  supplied  checkpermission  interface  implement  new  feature  interface  set  user  group  information  userroles  parameter  ldap  enabled  contrary  set  user  role  information  userroles  parameter  interface  following  check  user  permission  entity  param  user  param  userroles  param  entitytype  string  constant  defined  aclentitytype  param  entityuuid  param  permission  return  true  permission  abstract  public  boolean  checkpermissionstring  user  liststring  userroles  string  entitytype  string  entityuuid  permission  permission,1,0,1,0,1,0,0,0,0,0,0,0,0,1,1,0,1
5709,table  level  acl  planning  introduce  table  level  acl  kylin  table  level  acl  control  whether  user  query  data  table  table  go  project  table  level  acl  set  project  project  basis  instance  start  first  time  upgrade  lower  version  every  user  default  access  table  loaded  project  admin  modify  table  level  acl  removing  user  table’s  access  list  admin  disable  user’s  query  access  table  several  case  user’s  table  level  acl  checked  ensure  acl  integrity  1  user  visit  insight  page  browse  table  table  user  access  current  project  visible  user  2  user’s  query  hit  cube  table  level  acl  dependent  table  user  checked  user  access  dependent  table  query  refused  cube,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
5710,unclosed  statement  test  statement  resource  closed  test  eg  queracltestutiljava  code  statement  statement  conncreatestatement  return  statementexecutequerysql  code  statement  closed  use,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5711,global  dict  specific  info  use  absolute  path  saved  currently  absolute  path  used  global  dictionary  saving  location  specific  info  like  next  json  code  uuid  b82505d85b40400988398456500ea6a8  lastmodified  0  version  23020500  sourcetable  kylinyifei1011testglobaldictmigrationkylinsales  sourcecolumn  price  sourcecolumnindex  6  datatype  decimal194  input  path  hdfssandboxhortonworkscom8020kylinkylindefaultkylind213a963b5e34e75a1a28af93ca83a80globaldictcubefactdistinctcolumnskylinsalesprice  size  81150  lastmodifiedtime  1508133611074  dictionaryclass  orgapachekylindictappendtriedictionary  cardinality  8878  hdfsmaster8020kylinkylinyifei1011testglobaldictmigrationresourcesglobaldictdictkylinyifei1011testglobaldictmigrationkylinsalesprice  code  change  path  configuration  migrate  data  another  cluster  node  name  different  original  host  cannot  reached  meet  problem  reusing  like  rebuilding  merge  dictionary  transfer  column  dictionary  building  cube  dictionary  info  cannot  found,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5712,build  dict  uhc  column  mr  kylin2217  built  dict  normal  column  mr  uhc  column  still  build  dict  jobserver  like  kylin2217  also  could  use  mr  build  dict  uhc  column  could  thoroughly  release  memory  pressure  improve  job  concurrent  jobserver  well  speed  multi  uhc  column  procedure  mr  input  output  extract  fact  table  distinct  column  mr  output  uhc  column  dict  hard  build  global  dict  multi  reducer  use  one  reducer  handle  one  uhc  column  allocate  enough  memory  reducer  according  test  8g  memory  enough,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5713,refactor  datamodeldesc  refactor  datamodeldesc  flexible  extensible  splitting  metadatamanager  dedicated  datamodelmanager,1,0,1,0,1,0,1,0,1,1,1,0,0,0,0,1,1
5714,refactor  cuboidscheduler  extensible  allow  implementation  like  kylin2727,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5715,move  concept  table  project  move  concept  table  project  reloading  table  one  project  wont  affect  cube  another  project,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5716,log  pushdown  query  kind  badquery  user  want  know  past  pushdown  query  possibly  create  modelcube  enhance  speed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5717,inspect  available  memory  mr  job  sometimes  hard  figure  reason  oom  mr  job  especially  kylin  run  different  environment  hence  helpful  memory  info  step  setupcleanup,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5718,pushdown  non  select  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5719,new  metric  framework  based  dropwizard  httpsissuesapacheorgjirabrowsekylin2721we  plan  release  new  metric  framework  new  metric  different  hadoop  metric  based  dropwizard  following  advantage  welldefined  metric  model  frequentlyneeded  metric  ie  jvm  metric  welldefined  measurement  metric  ie  max  mean  stddev  meanrate  etc  builtin  pluggable  reporting  framework  like  jmx  console  log  json  refactored  querymetric  new  metric  notice  exposed  jmx  mbeans  changed  little  bit  new  tool  called  perflog  also  introduced  perflog  trace  call  duration  time  current  active  call  recording  metric  system  snapshot  new  jmx  mbeans  seen  attachment,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5720,refactor  daterange  sourceoffset  cubesegment  two  concept  similar  confusing  refactor  clean  tech  debt,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,1
5721,make  hbase  1x  default  master,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5722,refine  spark  cubing  reduce  serialization  overhead  spark  cubing  lot  variable  defined  driver  used  closure  cause  extra  serialization  overhead  meanwhile  remove  method  reading  kylinconfig  hdfs,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5723,make  default  precision  scale  datatype  hive  configurable  currently  value  hard  coded  codejava  fixme  256  unknown  string  precision  nameequalschar  nameequalsvarchar  precision  1  precision  256  save  memory  frontend  eg  tableau  allocate  memory  according  nameequalschar  precision  1  255  according  httpscwikiapacheorgconfluencedisplayhivelanguagemanualtypeslanguagemanualtypescharcharchar  fixme  194  unknown  decimal  precision  nameequalsdecimal  nameequalsnumeric  precision  1  precision  19  scale  4  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5724,enhance  project  level  acl  planning  enhancing  project  level  acl  plan  five  type  predefined  user  access  system  admin  project  admin  management  operation  query  syncing  ldap  new  user  admin  option  set  new  user  system  admin  user  access  however  need  set  project  level  mean  system  admin  applied  globally  instance  four  user  access  granted  project  project  basis  one  user  say  johndoe  project  admin  project  management  access  project  b  user  role  modeler  analyst  currently  set  syncing  user  retired  project  level  access  assigned  user  role  cube  level  acl  retired  user  access  control  cube  inherited  user  project  level  acl  expected  access  level  5  type  user  access  defined  attached  screenshot1png,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5725,support  rdbms  data  source  v20  kylins  plugin  architecture  make  possible  multiple  data  source  cube  engine  storage  user  ever  aksed  whether  kylin  support  source  data  feeded  rdbms  like  oracle  mysql  possible  tool  like  apache  sqoop  easily  export  data  rdbms  hdfs  would  help  kylin  get  data  build  cube,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5726,spark  cubing  read  metadata  hdfs  currently  spark  cubing  doesnt  support  hbase  cluster  kerberos  temporarily，we  could  support  hbase  cluster  kerberos  yarn  client  mode  easy  long  term，we  avoid  access  hbase  spark  cubing,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5727,keep  uuid  metadata  constant  user  reset  restore  metadata  keep  uuid  unchanged  thus  ensure  uuid  identifier  metadata  table  however  operation  read  alter  metadata  allowed  copy  uuid  metadata  achieve  add  resource  filed  uuid  excludes  list  copyr  resetr  method  resourcetooljava  make  operation  attending  copy  reset  field  skip  uuid  read  operation  example  operation  relating  backup  provide  overriding  copy  method  permit  getting  uuid  metastable  resolved  please  refer  commit  071f3b92caccf56ed70c15147da32a9ef2538bff  author  auphyroc99  454530524qqcom  date  thu  jun  22  171058  2017  0800  kylin2676  allow  backup  operation  copying  uuid  commit  b6cdab0eefc81dca79ec8eea0740de566a6cdb7d  author  auphyroc99  454530524qqcom  date  thu  jun  22  171058  2017  0800  kylin2676  allow  backup  operation  copying  uuid  commit  66dc5418ce9860103a67398256ee11a7e428d4a0  author  auphyroc99  454530524qqcom  date  fri  jun  16  153233  2017  0800  kylin2676  add  uuid  excludes  list  commit  25861c3732ef5312debada5d7fba111df0ef7694  author  auphyroc99  454530524qqcom  date  fri  jun  16  153233  2017  0800  kylin2676  add  uuid  excludes  list,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5728,route  unsupported  query  back  query  source  directly  kylin  cannot  support  query  due  lack  prepared  mode  cube  query  routed  back  executing  original  source  may  integrate  hive  sparksql  drill  anything  desired  must  interface  defined  first  allow  plugin  adhoc  query  engine  carryon  kylin742,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5729,speed  prepared  query  execution  bi  tool  use  prepared  query  function  probing  kylin  execute  query  standard  way  costly  still  worth  mentioning  standard  preparebindparameterexecute  way  preparedstatement  still  supported  kylin  support  prepared  statement  without  parameter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5730,refactor  kylinconfig  default  configuration  hidden  kylindefaultsproperties  currently  ship  confkylinproperties  file  lot  configuration  override  standard  approach  compared  project  like  hadoop  spark  better  kylindefaultsproperties  file  hide  default  configuration  user  override  necessary  configuration  blank  kylinproperties  refactor  config  might  override  following  precedence  1  kv  kylinpropertiesoverride  secret  feature  never  documented  2  kv  kylinproperties  user  suggested  override  configs  3  kv  kylindefaultsproperties  readonly  user  4  kv  kylinconfigbase  readonly  user  refactor  backward  compatible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5731,use  resourcestore  manage  acl  file,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,0,0
5732,project  level  query  authorization  introduced  adhoc  query  httpsissuesapacheorgjirabrowsekylin2515  well  need  adjust  query  authorization  follows  query  authorization  encouraged  set  project  level  someone  assigned  read  permission  project  access  query  table  project  regardless  thru  adhoc  cube  user  read  permission  cube  read  permission  project  issue  query  query  satisfied  cube  read  permission,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5733,prune  cuboid  capping  number  dimension  scene  like  20  dimension  however  query  use  5  dimension  dimension  cuboid  contains  5  dimensionsexcept  base  cuboid  useless  think  add  configuration  cube  limit  max  dimension  cuboid  includes  whats  config  levelnumber  dimension  need  calculate  scene  calculate  leve  12345  skip  level  5  dimension  capping  turned  adding  dimcap  property  aggregationgroups  definition  example  following  aggregation  group  set  dimension  cap  3  cuboid  containing  3  dimension  skipped  aggregation  group  codenone  aggregationgroups  includes  partdt  metacategname  categlvl2name  categlvl3name  leafcategid  lstgformatname  lstgsiteid  opsuserid  opsregion  buyeraccountaccountbuyerlevel  selleraccountaccountsellerlevel  buyeraccountaccountcountry  selleraccountaccountcountry  buyercountryname  sellercountryname  selectrule  hierarchydims  metacategname  categlvl2name  categlvl3name  leafcategid  mandatorydims  partdt  jointdims  buyeraccountaccountcountry  buyercountryname  selleraccountaccountcountry  sellercountryname  buyeraccountaccountbuyerlevel  selleraccountaccountsellerlevel  lstgformatname  lstgsiteid  opsuserid  opsregion  dimcap  3  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5734,optimize  determined  case  filter  currently  calcite  handle  determined  filter  like  1  1  1  true  2  1  1  x  2  true  3  case  x  1  else  x  1  x  1  first  two  case  handled  kylin2539  however  third  case  handled  yet  jira  track  third  case  theory  jira  together  kylin2539  kylin2597  solved  calcite  rather  kylin  however  urgent  demand  well  fix  kylin  first,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5735,push  filter  storage  know  push  filter  storage  good  done  filter  possible  push  filter  storage  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5736,correct  reporting  hbase  error  whenever  hbase  error  occurs  metadata  access  fails  user  must  see  clear  error  message  saying  hbase  failing  kylin,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
5737,resourcestore  support  simple  rollback  useful  updating  multiple  resource  allornothing  fashion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5738,move  outputhbase  related  code  mr  engine  outputside,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
5739,enable  generating  multiple  streaming  message  one  input  message  streaming  parser  class  orgapachekylinsourcekafkastreamingparser  support  onetoone  message  generating  support  onetomany  case,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5740,refactor  distributedlock  current  distributedlock  could  use  improvement  lockclient  unnecessarily  required  watchpath  actually  onunlock  listener  current  name  failed  make  clear  could  add  blocking  version  lockpath  ease  use  case  like  kylin2557  globaldictionarybuilderlock  add  javadoc  interface,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5741,code  refactor  move  data  source  statement  query  module,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5742,refactor  global  dictionary  main  point  refactor  1  fix  bug  removelistener  loadingcache  swallowed  exception  building  globaldict  2  fix  bug  hdfs  filename  dictslicekey  illegal  character  3  fix  bug  hdfs  filename  dictslicekey  maybe  longer  255  4  fix  bug  dictnode  split  failed  value  length  greater  255  byte  5  decouple  build  query  globaldict  abstract  builder  appendtriedictionary  appendtriedictionarybuilder  add  loadingcache  appendtriedictionary  make  appendtriedictionary  readable  6  remove  dependence  loadingcache  building  globaldict  7  abstract  hdfs  operation  globaldictstore  8  abstract  metadata  globaldict  globaldictmetadata  9  delete  cachedtreemap  10  add  distributed  lock  globaldict,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,1,1
5743,number2bytesconverter  could  tolerate  malformed  number  malformed  number  like  0100  1001200  currently  work  number  dictionary  could  improved,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5744,use  hive  table  statistic  data  get  total  count  kylin  count  intermediate  flat  hive  table  get  total  row  number  redistribute  hive  wiki  hive  automatically  collect  table  statistic  run  insert  overwrite  statement  subsequent  select  count  fast  see  httpscwikiapacheorgconfluencedisplayhivestatsdev  kylin  executing  insert  overwrite  directory  kylinrowcount  select  count  still  cause  mrtez  job  started  cause  step  take  longer  time  change  sql  select  count  using  hive  api  get  statistic  cost  saved  sample  table  kylinintermediateqqdbe874d2bb9a4375ba503dcf096a13c5  intermediate  table  directly  run  count  pretty  fast  hive  select  count  kylinintermediateqqdbe874d2bb9a4375ba503dcf096a13c5  ok  970033  time  taken  0112  second  fetched  1  row  today  kylins  sql  cause  job  started  hive  insert  overwrite  directory  kylinrowcount  select  count  kylinintermediateqqdbe874d2bb9a4375ba503dcf096a13c5  query  id  root201611060808080099b622c0bd41daaee52321adf7bdda  total  job  1  launching  job  1  1  number  reduce  task  determined  compile  time  1  order  change  average  load  reducer  byte  set  hiveexecreducersbytesperreducernumber  order  limit  maximum  number  reducer  set  hiveexecreducersmaxnumber  order  set  constant  number  reducer  set  mapreducejobreducesnumber  starting  job  job146370191591946208  tracking  url,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5745,stream  aggregate  gtrecords  query  server  problem  query  server  need  handle  million  record  cubetupleconverter  could  become  performance  bottleneck  experiment  show  converting  5  million  record  take  11  account  50  total  query  time  motivation  record  returned  storage  partition  guaranteed  ordered  therefore  could  reduce  number  record  passed  cubetupleconverter  merge  sorted  record  partition  similar  done  kylin1787  use  stream  aggregatehttpsblogsmsdnmicrosoftcomcraigfr20060913streamaggregate  algorithm  merged  stream  aggregate  record  key  proposal  add  new  physical  operator  gtstreamaggregatescanner  implement  stream  aggregate  algorithm  refine  sortediteratormergerwithlimit  used  merge  sort  record  different  partition  previous  implementation  performance  issue  kylin2483  due  expensive  record  clone  leverage  gtstreamaggregatescanner  aggregate  record  merged  stream  scope  stream  aggregate  good  property  low  memory  usage  streamable  ordered  output  making  better  hashsort  based  alternative  input  already  sorted  bet  new  gtstreamaggregatescanner  operator  also  used  accelerate  cubing  coprocessor  aggregation  certain  case  ill  focus  query  server  jira  leave  optimization  future  work,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,1,0
5746,smooth  upgrade  200  older  metadata,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5747,improve  sampling  performance  factdistinctcolumns  step  method  putrowkeytohll  factdistinctcolumnsmapper  slow  sampling  rate  high  carefully  profiling  believe  performance  improved  modifying  hash  method  time  also  found  algorithm  estimate  row  nums  cuboid  accurately  lower  sampling  rate  share  test  result  detail  algorithm  issue  done,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5748,spark  cubing  step  show  yarn  app  link  sample  output  170306  144444  info  client  submitting  application  16  resourcemanager  170306  144445  info  yarnclientimpl  submitted  application  application14888055756870016  170306  144446  info  client  application  report  application14888055756870016  state  accepted  170306  144446  info  client  client  token  na  diagnostics  na  applicationmaster  host  na  applicationmaster  rpc  port  1  queue  default  start  time  1488811485001  final  status  undefined  tracking  url  httpsandboxhortonworkscom8088proxyapplication14888055756870016  user  root,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
5749,optimize  performance  selfdefinesortablekey  kylin1851  introduce  new  sorting  key  selfdefinesortablekey  kylin  new  dictionary  need  ordered  input  value  recently  found  user  apply  dictionary  encoding  double  type  column  sorting  procedure  selfdefinesortablekey  slow  optimization  need  made  fix,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1
5750,replace  scan  threshold  max  scan  byte  order  guard  bad  query  consume  lot  memory  potentially  crash  kylin  hbase  server  kylin  limit  maximum  number  row  query  scan  maximum  value  chosen  based  two  configs  kylinqueryscanthreshold  used  query  doesnt  contain  memoryhungry  metric  kylinquerymembudget  estimatedrowsize  used  otherwise  per  region  maximum  approach  however  several  deficiency  doesnt  work  complex  varlen  metric  well  estimated  threshold  could  either  small  large  small  good  query  killed  large  bad  query  banned  row  count  doesnt  correspond  memory  consumption  thus  difficult  determine  large  scan  threshold  set  kylinqueryscanthreshold  cant  override  cube  level  jira  propose  replace  current  row  count  based  threshold  intuitive  size  based  threshold  kylin2437  collect  number  byte  scanned  region  query  level  new  configuration  kylinquerymaxscanbytes  added  limit  maximum  number  byte  query  scan  kylinquerymembudget  renamed  kylinstoragehbasecoprocessormaxscanbytes  kylinstoragepartitionmaxscanbytes  limit  region  level  need  rely  estimation  row  size  two  configs  scan  override  cube  level  old  kylinqueryscanthreshold  deprecated,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
5751,refactor  refine  number  dictionary  three  king  number  dictionary  numberdictionaryclass  numberdictionary2class  numberdictionaryforestclass  confused,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
5752,cleanup  unnecessary  shaded  library  jobcoprocessorjdbcserver  kylin  release  three  library  kylincoprocessor  kylinjdbc  kylinjob  one  web  application  server  currently  library  shaded  used  third  party  library  package  example  guava  curator  common  kyro  kylinjob  duplicate  library  runtime  classpath  may  potential  class  loading  conflict  waste  computing  resource  leverage  hadoop  provided  library  runtime  instead  shaded  one,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5753,add  configuration  knob  disable  spilling  aggregation  cache  kylins  aggregation  operator  spill  intermediate  result  disk  estimated  memory  usage  exceeds  threshold  kylinquerycoprocessormemgb  specific  useful  feature  general  prevent  regionserver  oom  time  aborting  kind  memoryhungry  query  immediately  suitable  choice  user  accommodate  requirement  suggest  adding  new  configuration  named  kylinstoragehbasecoprocessorspillenabled  kylinstoragepartitionaggrspillenabled  default  value  would  true  keep  behavior  changed  false  query  us  aggregation  memory  threshold  fail  immediately,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5754,recalculate  expansion  rate  count  raw  data  size  regardless  flat  table  compression  right  expansion  rate  calculated  cube  size  raw  data  size  raw  data  size  size  intermediate  hive  table  mean  raw  data  size  depends  compression  format  intermediate  table  affect  correctness  expansion  rate  estimate  based  raw  data  size  change  intends  calculate  raw  data  size  based  uncompressed  cell  value  intermediate  hive  table  cell  take  string  form  sum  string  byte  size  utf8  encoding  result  serf  raw  data  size  stable  regardless  compression  env  parameter,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5755,report  coprocessor  error  information  back  client  query  abort  coprocessor  current  error  message  list  doesnt  carry  concrete  reason  user  check  regionservers  log  order  figure  whats  happening  tedious  work  always  possible  cloud  environment  noformat  subthread  query  4fb68974de704f6ea2ee7048202e51a7  gtscanrequest  4d65f9bfthe  coprocessor  thread  stopped  due  scan  timeout  scan  thresholdcheck  region  server  log  failing  current  query  noformat  would  better  report  error  message  client,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5756,collect  number  byte  scanned  query  metric  besides  scanned  row  count  useful  know  many  byte  scanned  hbase  fulfil  query  perhaps  better  indicator  row  count  show  much  pressure  query  put  hbase,1,1,1,0,1,1,0,0,1,1,0,0,0,0,0,0,0
5757,hot  load  kylin  config  web  allow  admin  user  reload  kylin  config  web  could  improve  operational  efficiency  service  stability,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
5758,distinguish  uhc  column  normal  column  kylin2217  current  implement  kylin  disable  whole  feature  kylin2217  found  kylinenginemruhcreducercount1  actually  distinguish  uhc  dictionary  normal  dictionary  leave  uhc  dictionary  job  node  build,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5759,allow  kylin  store  metadata  hdfs  instead  hbase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5760,create  branch  v15  hbase  11  api  create  new  branch  kylin  v15  compile  hbase  v11  api,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5761,percentile  preaggregation  implementation,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
5762,new  bitmapcounter  better  performance  found  old  bitmapcounter  perform  well  large  bitmap  inefficiency  come  poor  serialize  implementation  instead  serialize  bitmap  directly  bytebuffer  us  bytearrayoutputstream  temporal  storage  cause  superfluous  memory  allocation  poor  peeklength  implementation  whole  bitmap  deserialized  order  retrieve  serialized  size  extra  deserialize  cost  even  cardinality  info  needed  answer  query  whole  bitmap  deserialize  mutableroaringbitmap  new  bitmapcounter  designed  solve  problem  come  tow  flavor  mutable  immutable  based  mutableimmutable  roaringbitmap  correspondingly  immutablebitmapcounter  lower  deserialize  cost  map  copied  buffer  always  deserialize  immutablebitmapcounter  first  convert  mutablebitmapcounter  necessary  peeklength  implemented  using  immutableroaringbitmapserializedsizeinbytes  fast  since  header  roaring  format  examined  directly  serializes  bytebuffer  intermediate  buffer  allocated  wire  format  roaringformatspechttpsgithubcomroaringbitmaproaringformatspec  therefore  cube  rebuild  needed,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1
5763,upgrade  calcite  111  avatica  19  calcite  release  1110  recently  jira  kylin  upgrade  calcite  1110  avatica  190  potential  refactor  may  required  since  protobuf  30upgrade  25  needed  calcite,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
5764,improve  resource  utilization  distributedscheduler  currently  distributedscheduler  lock  segment  jobservice  make  job  segment  schedule  jobserver  job  submitted  could  fully  utilize  threadpool  resource  jobservers  example  two  jobserver  max  concurrent  job  10  continuously  submit  20  job  jobserver1  10  job  running  time  20  job  running  jobserver2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5765,simplify  dictionary  interface  remove  byte  related  interface  keep  int  getidfromvaluet  value  int  getidfromvaluet  value  int  roundingflag  getvaluefromidint  id,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
5766,refactor  dbunit  assertion  tolerate  data  type  mismatch  int  bigint  allow  verify  query  limit,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5767,layer  spark  cubing  using  apache  spark  engine  build  cube  bylayer  iterative  algorithm,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,1
5768,cuboidreducer  many  aggrmaski  check,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5769,refine  table  loadunload  error  message  exception  handling  tablecontroller  exception  found  kylinlog  kylinout  tablecontroller  provide  useful  message  stable  exception  happens,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5770,reduce  size  metadata  uploaded  distributed  cache  currently  mr  job  uploads  metadata  belonging  cube  distributed  cache  total  size  metadata  increase  submission  time  mapreduce  waiting  monitor  ui  also  increase  could  become  significant  problem  could  actually  optimize  amount  metadata  uploaded  according  type  job  example  cuboidjob  need  dictionary  building  segment  cubehfilejob  doesnt  need  dictionary,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5771,add  integration  test  snowflake,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
5772,hyperloglog  codec  performance  improvement  cube  ten  distinct  count  measure  use  hll15  store  value  found  slow  hyperloglogpluscounter  three  method  called  frequentlly  mergewriteregistersreadregisters  found  kylin15x  add  parameter  singlebucket  store  one  bucket  optimize  base  cuboid  however  step  cuboid  building  slow  modify  code  speed  speed  three  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5773,refactor  ci  merge  withslr  withoutslr  cube  try  reduce  ci  time  also  prepare  snowflake  cube  ci,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5774,load  kafka  client  configuration  property  file  latest  kafka  source  hardcode  connection  propertiessuch  timeoutms  source  file  could  better  could  refactor  property  file,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5775,refactor  ci  blend  view  cube  rest,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5776,minor  improvement  limit  1  deprecate  kylinquerymaxlimitpushdown  there  already  storage  scan  threshold  limit  good  2  simply  enable  limit  logic  minor  refactors,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5777,general  purpose  data  generation  tool  generate  random  data  according  data  model  help  troubleshooting  testing,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
5778,add  project  config  make  config  priority  become  cube  project  server  case  want  override  global  kylinproperties  scope  project  eg  queue  name  hadoop  job  finally  config  priority  kylin  cube  project  server  think  reasonable,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5779,display  reasonable  exception  message  could  find  kafka  dependency  streaming  build  kafka  optional  dependency  kylin  install  mandatory  streaming  build  currently  kafkahome  exported  build  show  error  without  detail  message  convenient  new  user,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5780,snowflake  schema  support,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5781,redesign  way  decide  layer  cubing  reducer  count  currently  sizing  algorithm  leverage  cubestatsreader,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5782,robust  global  dictionary  global  dictionary  released  2  month  ive  received  feedback  bug  report  here  patch  make  global  dictionary  robust  including  functional  improvement  break  255  byte  limitation  value  still  recommend  value  length  le  8k  avoiding  stack  overflow  error  fix  value  exists  stack  overflow  error  dict  size  larger  1gb  root  cause  similar  kylin1834  check  tool  also  provided  check  corrupted  existing  dict  data  support  parallel  dictionary  building  one  job  server  used  parallel  segment  building,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
5783,reducer  build  dictionary  locally  kylin1851  reduce  peek  memory  usage  dictionarybuilding  procedure  splitting  single  trie  tree  structure  trie  forest  still  exist  bottleneck  dictionary  built  kylin  client  issue  want  use  multi  reducer  build  different  dictionary  locally  concurrently，which  reduce  peek  memory  usage  well  speed  dictionarybuilding  procedure,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
5784,setup  naming  convention  kylin  property,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5785,cannot  support  column  name  different  table  currently  implicitly  assume  column  model  unique  name  example  row  key  aggregation  group  use  column  name  without  tablename  identify  column,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5786,enhance  tableext  metadata  metadata  tableext  elegant  difficult  manage  enrich,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5787,mapperreducer  cleanup  exception  handling  could  override  real  exception  happened  mapper  reducer,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5788,make  job  engine  distributed  ha  currently  kylin  job  build  server  singlepoint。  order  make  kylin  job  build  server  extensible  available  reliable  support  distributed  job  build  server,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5789,refactor  abstractexecutable  respect  kylinconfig,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5790,move  partition  offset  calculation  submitting  job,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5791,enhance  cubing  algorithm  selection  protective  select  inmem  cubing  report  inmem  cubing  selected  run  slowly  even  timeout  small  poc  cluster  apart  limited  resource  poc  another  important  cause  algorithm  selection  didnt  concern  scale  job  mapper  many  mapper  slot  take  many  round  finish  mapper  total  time  inmem  cubing  becomes  slow  scale  job  taken  consideration  auto  selecting  cubing  algorithm  namely  mapper  limit  configuration  introduced  stop  inmem  cubing  number  mapper  go  beyond  threshold,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5792,scalable  streaming  cubing  try  achieve  1  scale  streaming  cubing  workload  computation  cluster  eg  yarn  2  support  kafka  formal  data  source  3  guarantee  data  loss  reading  kafka  even  record  strictly  ordered  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5793,support  embedded  structure  parsing  streaming  message  according  doc  httpkylinapacheorgdocs15tutorialcubestreaminghtml  kafka  incoming  message  flatten  structure  limit  json  message  request  feature  would  support  embedded  structure  raw  message  convert  flatten  table  structure  cube  building  sql  query,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5794,add  api  init  startpoint  parition  streaming  cube  like  normal  cube  need  partition  start  date  creation  used  start  point  first  segment  streaming  cube  also  need  starting  point  topic  collection  offset  partition  otherwise  kylin  build  topic  begining  may  expected,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5795,topn  counter  merge  performance  improvement  observed  reduce  phase  cube  build  slow  topn  counter  room  performance  improvement,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5796,support  usage  schema  name  default  sql  calcite  treat  default  internal  keyword  default  also  used  hive  default  schema  name  need  escape  case  usage  quote,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
5797,hive  mr  job  use  overrided  mr  job  configuration  cube  property  currently  user  also  apply  property  cube  level  cube  config  kylinjobmrconfigoverridemapreducejobqueuenameyourqueuebut  hive  job  invalid,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5798,support  intersect  count  calculation  retention  conversion  rate  retention  conversion  rate  important  data  analyze  calculated  two  dataset  two  different  value  one  dimension  example  count  distinct  measure  like  uvdataset  uuid  one  dimension  like  date  retention  uv  20161015  20161016  intersection  two  uv  datasets  fortunately  implement  dataset  kylin  bitmap  precisely  count  distinct  udaf  needed  calculate  intersection  two  bitmap  ill  try  post  patch  later,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
5799,add  api  check  fill  segment  hole  segment  cube  sequence  overlap  hole  say  gap  might  hole  especially  streaming  case  exceptional  case  need  api  report  hole  trigger  filling  automatically,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5800,split  kylinproperties  two  file  split  kylinproperties  two  file  normal  property  security  sensitive  property,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5801,refactor  broadcast  metadata  change,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1
5802,lookup  table  support  countdistinct  column  dimension  column  fact  table  write  sql  like  select  countdistinct  columnname  lookup  table  supported  need  add,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5803,new  fixlengthhex  encoding  support  hash  value  better  integer  encoding  support  negative  value  1  use  case  string  value  represent  hash  code  used  string  consist  09af  hex  value  two  character  squashed  one  byte  2  current  integerdimenc  support  negative  value  need  another  integerdimenc  support  negative  value,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1
5804,improve  logic  decide  whether  pre  aggregate  region  server,1,0,1,0,1,0,1,1,0,0,0,0,1,0,0,0,0
5805,send  mail  notification  runtime  exception  throw  buildmerge  cube  currently  mail  notification  sent  onexecutefinished  method  notification  sent  runtimeexception  throw  may  cause  user  miss  important  job  build  failure  especially  automation  merge  job  sometimes  job  state  update  failsthe  hbase  metastore  unavailable  short  time  make  job  always  look  like  running  state  actually  failed  send  mail  notify  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5806,make  creating  intermediate  hive  table  step  configurable  two  option  153  kylin1677  kylin  changed  step  pull  data  hive  1  count  source  table  2  create  intermediate  flat  table  redistribution  reducer  number  determined  step1  work  good  many  case  may  benefit  case  like  view  join  several  table  fact  table  better  keep  option  1  create  intermediate  flat  table  2  count  intermediate  table  3  redistribute  based  output  step  2  plan  make  configurable  system  level  cube  level,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5807,allow  bigintlong  partition  date  column  many  case  hive  table  may  use  long  bigint  date  column  currently  kylin  support  yyyymmdd  yyyymmdd  date  format  jira  support  long  bigint  format,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5808,webui  globaldictionary  global  dictionary  introduced  since  v153  however  there  web  ui  config  global  dict  convenience  user  use  case  found  examplestestcasedatalocalmetacubedesctestkylincubewithoutslrleftjoindescjson  dictionary  array  one  global  dict  config  may  contains  three  element  column  column  generate  dict  builder  builder  build  dict  reuse  column  reused,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5809,refactor  ijoinedflattabledesc  make  ijoinedflattabledesc  independent  dont  depend  cubedesc  cubesegment  time,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5810,collect  metric  jmx  known  performance  metric  important  enterprise  application  support  collect  metric  jmx  kylin  method  done  shown  1  use  orgapachehadoopmetrics2  metric  collection  framework  2  define  mbean  class  metric  need  collect  3  update  metric  right  place  question  1  depend  orgapachehadoopmetrics2  directly  2  think  method,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
5811,improve  enable  limit  logic  exactaggregation  strict  zhaotianshuomeizucom  recently  got  following  error  execute  query  cube  big  400mb  20milion  record  error  executing  sql  select  fcrashtimecount1  uxipedlfdtoucuploadfiles  group  fcrashanalysisidfcrashtime  limit  1  scan  row  count  exceeded  threshold  10000000  please  add  filter  condition  narrow  backend  scan  range  like  clause  guess  scan  intermediate  result  doesnt  order  byalso  result  count  limit  1so  could  scan  find  record  two  dimension  wala,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,1
5812,region  server  metric  replace  int  type  long  type  scanned  row  count,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5813,support  grouping  funtions  usually  used  group  dim1  dim2  fetch  metric  every  value  dims  also  want  summary  metric  dim2  rolled  case  could  resolved  union  two  query  like  code  select  dim1  dim2  metric  table  group  dim1  dim2  union  select  dim1  metric  table  group  dim1  code  expression  cuberollupgrouping  set  calcite  make  query  sql  simple  clearly  code  select  dim1  casegroupingdim2  1  else  dim2  end  metric  table  group  grouping  setsdim1  dim2  dim1  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5814,globaldictionary  may  corrupt  server  suddenly  crash  global  dictionary  store  data  hdfs  directly  overwrite  directly  data  file  updated  server  crashed  suddenly  writing  file  data  file  may  corrupt  cant  recovered  resolve  problem  copy  data  file  tmp  directory  copy  back  file  updated  successfully  ill  post  patch  later  solution,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5815,cubetupleconvertertranslateresult  slow  due  date  conversion  attached  profiling  show  current  filling  tuple  slow  especially  date  norm  form  yyyymmdd  parsed  date  converted  since  epic  day  slow  java  slow  simpledateformat  idea  refine  norm  form  datetime  time  millis  save  lot  str  date  conversion  however  change  impact  dictionary  lookup  snapshot  maybe  data  ingestion  also  need  think  backward  compatibility,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,1,0
5816,topn  measure  support  nondictionary  encoding  ultra  high  cardinality  topn  measure  us  dictionary  encode  literal  column  may  work  cardinality  ultra  high  need  support  encoding  like  fixedlength,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5817,stable  functional  precise  count  distinct  implement  kylin1186  kylin1186  weve  gained  ability  count  distinct  int  type  column  precisely  however  implement  kylin1186  stable  especially  2xstaging  branch  reason  measure  maxlength  used  allocate  memory  2x  version  bitmapmeasure  hardcoded  8mb  kylin1186  causing  oom  cube  building  resolve  problem  introduce  precision  bitmap  measure  bitmap100  bitmap10000  bitmap1000000  meaning  measure  could  accept  100100001m  cardinality  solution  fine  considering  reality  count  value  1000000  hyperloglog  measure  produce  approx  result  acceptable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5818,make  job  engine  scheduler  configurable  today  job  engine  scheduler  simple  implementation  need  abstract  decouple  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5819,use  kylinconfig  inside  coprocessor,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5820,introduce  dictionary  metadata  allow  special  dictionary  builder  specified  column  two  column  share  dictionary,1,0,1,0,1,0,1,0,0,1,0,0,0,0,0,0,1
5821,grow  bytebuffer  dynamically  cube  building  query  cube  building  mapperreducer  cubevisitservice  use  allocated  bytebuffer  store  encoded  metric  value  constant  size  rowconstantsrowvaluebuffersize  1mb  default  metric  value  larger  1mb  high  cardinality  bitmap  bufferoverflowexception  threw  need  grow  bytebuffer  exception  occured,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
5822,distribute  source  data  certain  column  creating  flat  table  inspired  kylin1656  kylin  distribute  source  data  certain  column  creating  flat  hive  table  data  assigned  mapper  similarity  aggregation  happen  mapper  side  le  shuffle  reduce  needed  column  used  distribution  includes  ultra  high  cardinality  column  mandantory  column  partition  datetime  column  etc,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
5823,improve  performance  mrv2  engine  making  mapper  handle  configured  number  record  current  version  mrv2  build  engine  mapper  handle  one  block  flat  hive  table  stored  sequence  file  two  major  problem  difficult  user  control  parallelism  mapper  cube  user  change  dfsblocksize  kylinhiveconfxml  however  global  configuration  cannot  override  using  overridekylinproperties  introduced  kylin1534httpsissuesapacheorgjirabrowsekylin1534  may  encounter  mapper  execution  skew  due  skew  distribution  block  record  number  severe  problem  since  factdistinctcolumn  inmemcubing  step  mrv2  cpu  intensive  map  task  give  sense  bad  one  cube  factdistinctcolumnstep  take  100min  total  average  mapper  time  11min  exists  several  skewed  map  task  handled  10x  record  average  map  task  inmemcubing  step  failed  skewed  mapper  task  hit  mapredtasktimeout  avoid  skew  happen  wed  better  make  mapper  handle  configurable  number  record  instead  handle  sequence  file  block  way  achieved  add  redistributeflathivetablestep  right  flathivetablestep  here  redistributeflathivetablestep  1  run  select  count1  intermediatetable  determine  inputrowcount  build  2  run  insert  overwrite  table  intermediatetable  select  intermediatetable  distribute  rand  evenly  distribute  record  reducer  number  reducer  specified  inputrowcount  mapperinputrows  mapperinputrows  new  parameter  user  specify  many  record  mapper  handle  since  reducer  write  record  one  file  guaranteed  redistributeflathivetablestep  sequence  file  flathivetable  contains  around  mapperinputrows  since  followed  job  mapper  handle  one  block  sequence  file  wont  handle  mapperinputrows  added  redistributeflathivetablestep  usually  take  small  amount  time  compared  step  benefit  brings  remarkable  here  performance  improvement  saw  cube  factdistinctcolumn  redistributeflathivetablestep  factdistinctcolumn  case1  5178min  840min  1306min  case2  9565min  246min  2637min  since  mapperinputrows  kylin  configuration  user  override  cube,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5824,specify  region  cut  size  cubedesc  leave  realizationcapacity  model  hint  currently  cube  region  size  determined  model  capacityrealizationcapacity  enforce  different  realization  model  uniformed  region  size  wanted  feature  cube  builder  might  need  try  different  region  size  tune  performance  im  suggesting  add  field  called  regionsize  float  type  10  mean  1g  per  region  cube  desc  explicitly  indicate  cube  region  size  field  regionsize  included  cubedescs  signature  calculation  regionsize  specified  case  legacy  cube  hint  model  capacityrealizationcapacity  used  determine  region  size,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5825,bring  information  diagnosis  tool,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
5826,support  hive  view  lookup  table  use  view  lookup  table  cube  building  job  fails  executing  3rd  step  build  dimension  dictionary  log  javaioioexception  javalangnullpointerexception  orgapachekylindictlookuphivetablegetsignaturehivetablejava72  orgapachekylindictdictionarymanagerbuilddictionarydictionarymanagerjava202  orgapachekylincubecubemanagerbuilddictionarycubemanagerjava166  orgapachekylincubeclidictionarygeneratorcliprocesssegmentdictionarygeneratorclijava52  orgapachekylincubeclidictionarygeneratorcliprocesssegmentdictionarygeneratorclijava41  orgapachekylinjobhadoopdictcreatedictionaryjobruncreatedictionaryjobjava52  orgapachehadooputiltoolrunnerruntoolrunnerjava70  orgapachehadooputiltoolrunnerruntoolrunnerjava84  orgapachekylinjobcommonhadoopshellexecutabledoworkhadoopshellexecutablejava62  orgapachekylinjobexecutionabstractexecutableexecuteabstractexecutablejava107  orgapachekylinjobexecutiondefaultchainedexecutabledoworkdefaultchainedexecutablejava51  orgapachekylinjobexecutionabstractexecutableexecuteabstractexecutablejava107  orgapachekylinjobimplthreadpooldefaultschedulerjobrunnerrundefaultschedulerjava130  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1142  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava617  javalangthreadrunthreadjava745  caused  javalangnullpointerexception  result  code2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5827,improve  performance  converting  data  hfile  supposed  got  100gb  data  cuboid  building  setting  10gb  per  region  10  split  key  calculated  10  region  created  10  reducer  used  ‘convert  hfile’  step  optimization  could  calculate  100  split  key  use  ‘covert  file’  step  sampled  10  key  create  region  result  still  10  region  created  100  reducer  used  ‘convert  file’  step  course  hfile  created  also  100  load  10  file  per  region  that’s  fine  doesn’t  affect  query  performance  dramatically,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5828,count  distinct  dimension  work  even  predefined  measure  currently  count  distinct  dimension  work  sqlselect  date20150718  countdistinct  country  uniquecountry  pcsession  e  inner  join  pccal  c  epartdate  ccaldt  partdate  date20150718  date20150819  offset0limit10acceptpartialtrueprojecttracking  exception  cant  find  realization  please  confirm  provider  sql  digest  fact  table  defaultpcsessiongroup  filter  defaultpcsessionpartdatewith  aggregatesfunctiondesc  expressioncountdistinct  parameterparameterdesc  typecolumn  valuecountry  returntypenull  executing  sql  select  date20150718  countdistinct  country  uniquecountry  pcsession  e  inner  join  pccal  c  epartdate  ccaldt  partdate  date20150718  date20150819  limit  10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5829,tool  dump  information  diagnosis,1,0,1,0,1,0,0,1,0,1,0,0,0,0,0,0,0
5830,persist  recent  bad  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5831,print  version  information  kylinsh,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5832,cube  empty  signature  consistent  cube  desc  update  allowed  currently  user  update  cube  desc  warned  update  cause  inconsistency  existing  segment  might  get  purged  however  user  never  know  ahead  whether  update  consistent  word  user  sure  effect  change  specific  cube  desc  field  cube  desc  update  current  cube  empty  well  radically  allow  desc  update  even  change  signature  side  cube  existing  segment  well  check  signature  consistency  allowing  update  failure  signature  consistency  return  error  message  update  performed  lead  lessconfusing  interactivity  user,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5833,metadata  upgrade  1013  15  including  metadata  correction  relevant  tool  etc  since  14x  branch  never  released  officially  user  might  need  upgrade  15  compatible  metadata  format  10x  11x  12x  13x  release,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0
5834,custom  dimension  encoding  currently  dimension  encoded  either  dictionary  fixedlength  could  better  custom  encoding  support  case  like  bank  account  card  id  help  enabling  ultra  high  cardinality  column  time  make  data  compressed  save  storage,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
5835,upgrade  calcite  version  16  calcite  going  release  16  well  upgrade  contains  bug  fix  block  u,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
5836,define  stream  config  table  level  instead  cube  level  20  streaming  user  need  enter  kafka  information  create  cube  like  topic  broker  list  etc  info  independent  cube  reused  across  cube  share  table  expected  design  define  kafka  config  adding  table,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5837,support  hive  client  beeline  user  ever  mentioned  environment  hive  shell  client  isnt  available  beeline  allowed  kylin  support  using  beeline  would  nice  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5838,cuboid  sharding  based  specific  column  currently  cuboid  sharding  based  hash  value  row  key  allow  computing  hash  value  specific  column  c  actually  partitioning  data  wrt  c  benefit  later  query  filter  like  c  xyz  kylin  skip  shard  also  filter  like  c  many  candidate  kylin  prune  candidate  sent  different  shard,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
5839,tool  extract  cubehybridproject  related  metadata  facilitate  diagnosingdebuggingsharing  list  extracted  item  cube  cube  desc  cube  instance  data  model  related  table  desc  possibly  ext  table  info  segment  dict  snapshotstatistics  cube  related  job  job  output  optional  list  extracted  item  hybrid  hybrid  instance  cube  hybrid  collect  list  extracted  item  cube  list  extracted  item  project  project  instance  cube  project  collect  list  extracted  item  cube  hybrid  project  collect  list  extracted  item  hybrid,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
5840,aggregation  group  validation  add  validation  aggregation  group  loading  cube,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5841,enable  deriving  dimension  non  pkfk  currently  derived  column  column  look  table  derived  host  column  pkfkits  also  problem  lookup  table  grows  every  large  sometimes  column  fact  exhibit  deriving  relationship  here  example  fact  table  dt  date  sellerid  bigint  sellername  varchar100  itemid  bigint  itemurl  varchar1000  count  decimal  price  decimal  sellername  uniquely  determined  seller  id  itemurl  uniquely  determined  itemid  user  expect  filtering  column  like  seller  name  itemurl  want  retrieve  groupingfiltering  dimension  like  selller  id  item  id  even  dimension  like  dt,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5842,upgrade  tool  put  oldversion  cube  newversion  cube  hybrid  model,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5843,enhance  deploycoprocessorcli  support  cube  level  filter  currently  deploycoprocessorcli  filter  table  need  enhance  support  cube  filter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5844,query  storage  v2  enable  parallel  cube  visiting  currently  cube  multiple  segment  endpoint  coprocessor  invocation  segment  executed  sequentially  well  try  parallize  see  contributes  performance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5845,check  kryo  performance  spilling  aggregation  cache  shown  mahone  kryo  performance  issue  deserialization  need  double  check  impact  aggregation  cache  spill  merge,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5846,replace  gtscanrequests  serder  form  kryo  manual  kryo  greatly  simplifies  bject  serder  cost  performance  therere  ten  segment  cost  accumulates  big  accept  going  serialize  gtscanrequests  manual  serialization,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5847,support  custom  aggregation  type  currently  kylin  support  6  basic  aggregation  measure  function  minmaxsumcountavgdistinctcount  also  many  case  require  support  complicate  measure  expression  example  countcase  soft  fv  soisc  else  null  end  sumif  even  complicated  measure  like  topn  rawrecords  open  jira  tracking  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5848,spill  disk  aggregationcache  need  many  memory  class  gtaggregatescanneraggregationcache  hard  coded  10gb  max  limit  aggregationcache  exceeded  exception  thrown  leverage  disk  ensure  stable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5849,switch  layer  cubing  inmem  cubing  according  stats  without  smart  switch  inmem  cubing  could  slow  worst  case  though  best  case  super  fast  layer  cubing  however  stable  kinda  always  middle,1,1,1,0,1,1,0,0,1,0,1,0,0,0,0,0,1
5850,redesign  aggregation  group  proposal  hongbin  cuboid  white  list  detail  please  refer  kylin  dev  mailing  list  devkylinincubatorapacheorg  logically  cube  contains  cuboid  representing  combination  dimension  apparently  naive  cube  building  strategy  materializes  cuboid  easily  meet  curseofdimension  problem  currently  kylin  leverage  strategy  called  aggregation  group  reduce  number  cuboid  need  materialized  however  query  pattern  simple  fixed  aggregation  group  strategy  still  efficient  enough  example  suppose  therere  five  dimension  namely  abcd  e  data  modeler  sure  combination  abc  de  ae  queried  he’ll  use  aggregation  group  tool  optimize  cube  definition  however  whatever  aggregation  group  chooses  lot  useless  combination  would  materialized  new  strategy  called  cuboid  whitelist  data  modeler  guide  kylin  materialize  cuboid  he  interested  depending  whitelist  kylin  materialize  minimal  set  cuboid  cover  cuboid  whitelist  support  following  functionality  added  1  frontendui  specifying  whitelist  member  persistent  cube  description  2  enhanced  job  engine  scheduler  calculate  minimal  spanning  build  tree  based  whitelist  3  optional  enhanced  job  engine  support  dynamic  whitelist  trigger  new  build  lately  added  whitelist  member  hongbin  imported  github  url  httpsgithubcomkylinolapkylinissues263  created  lukehanhttpsgithubcomlukehan  label  enhancement  milestone  backlog  assignee  binmahonehttpsgithubcombinmahone  created  thu  dec  25  131711  cst  2014  state  open,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
5851,factdistinctcolumnsjob  support  high  cardinality  column  factdistinctcolumnsjobs  combiner  reducer  us  hashset  remove  duplicated  value  column  cardinality  big  say  10  million  may  report  outofmemory  error  enhanced  support  case,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5852,cube  parallel  scan  hbase  currently  cube  scanned  sequential  way  endpoint  introduced  cube  scanning  parallelized  lead  1  faster  cube  scanning  2  topn  query  made  possible,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
5853,distinguish  fast  build  mode  complete  build  mode  currently  buildcubewithenginetest  responsible  building  4  test  cube  test  case  use  intend  build  cube  stagesuse  incremental  cube  building  cube  merging  meaning  multiple  round  mr  job  make  sure  cover  job  engine  cube  building  merging  function  hand  sometimes  working  module  dont  care  cube  built  need  queryable  cubelike  developing  query  engine  fast  mode  would  help  full  buildcubewithenginetest  fast  mode  every  test  cube  built  single  segment  mean  single  round  mr  required  cube  make  buildcubewithenginetest  much  faster,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5854,v2  storagefor  parallel  scan  backward  compatibility  v1  storage  kylin942  introduced  new  storage  format  shard  put  beginning  rowkeywe  call  v2  storage  cube  built  previous  version  job  engine  longer  compatible  current  query  engine  need  refactor  job  engine  query  engine  support  version  cube  storage,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1
5855,support  dictionary  cardinality  10  million  many  use  case  involve  column  high  cardinality  10  million  dictionary  supported  column  assuming  mem  sufficient,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5856,use  local  dictionary  invertedindex  batch  building  invertedindex  two  dictionary  type  global  dictionary  local  dictionary  batching  building  us  global  dict  streaming  building  us  local  dict  make  consistent  easy  maintain  use  one  type  dictionary  local,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,1,1
5857,allow  yyyymmdd  date  partition  column  many  hive  table  use  format  yyyymmdd  effective  date  column  however  kylin  currently  require  date  format  yyyymmdd  support  yyyymmdd  right  away  save  user  effort  many  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5858,optimize  memory  footprint  topn  counter  topn  implementation  streamsummary  perfect  kylin  kylin  use  double  typed  counter  big  data  scenario  possibility  multiple  key  double  counter  low  data  structure  may  memory  economic,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5859,add  streaming  ui  since  enable  streaming  feature  also  need  enable  streaming  module  ui  user  use  web,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5860,route  unsupported  query  hive  spark  kylin  cant  serve  coming  sql  better  route  enabled  sql  hadoop  like  sparksql  execute  get  result  return  client  kylin  server,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
5861,approximate  topn  supported  cube  spacesaving  topn  algorithm  code  could  copy  httpsgithubcomaddthisstreamlibblobmastersrcmainjavacomclearspringanalyticsstreamstreamsummaryjava  don’t  need  whole  streamlib  one  two  class  enough  make  sure  give  credit  streamlib  class  comment  order  run  spacesaving  parallel  topn  merged  using  httparxivorgpdf14010702pdf  existing  impl  searched  implement  cheer  yang  li  yang  sent  2015年8月7日  1243  dlebaykylin  subject  distributed  topn  paper  basic  algorithm  1  httpsicmicsucsbeduresearchtechreportsreports200523pdf  application  distributed  system  2  httpwwwcsutahedujeffppapersmergesummtodspdf  3  httpwwwcrmumontrealcapubrapports330033993322pdf  cheer  yang,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5862,support  hbase  separate  cluster  currently  kylin  assumes  hbase  deployed  cluster  hive  table  resides  necessarily  case  support  kylin  write  cube  hbase  another  cluster,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5863,allow  user  configure  region  split  size  cube  kylin  hardcoded  region  split  size  rangekeydistributionreducerjava  use  10g  20g  100g  split  smallmediumlarge  cube  besides  set  limit  max  region  count  500  hardcode  good  externalize  value  config  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5864,split  storage  module  corestorage  storagehbase  modularization  purpose  code  refactor  applied  storage  module,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5865,adapt  gtstore  hbase  endpoint  adapt  hbase  cube  gtstore  cube  hbase  read  endpoint,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
5866,growing  dictionary  streaming  potentially  memory  consuming  slowly  increasing  dictionary,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5867,decouple  hadoop  allow  alternative  input  build  engine  storage  weve  got  many  request  use  input  source  hive  use  spark  instead  hadoop  mr  use  cassandra  place  hbase  order  decouple  hadoop  interface  must  defined  input  source  build  engine  storage  respectively  let  hive  mr  hbase  become  piece  plugin  implementation,0,0,0,0,0,0,0,0,1,1,1,0,0,0,1,0,0
5868,move  streaming  related  parameter  streamingconfig,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5869,add  retentionrange  attribute  cube  instance  automatically  drop  oldest  segment  exceeds  retention  sometimes  user  want  keep  certain  range  data  cube  example  1  month  kylin  allow  define  retentionrange  cube  instance  level  new  segment  built  check  drop  oldest  segment  head  retention  exceeded,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5870,kylin  performance  insight  dashboard  enable  front  end  dashboard  show  kylin  performance  data,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5871,hybrid  model  multiple  realizationscubes  scenario  user  cube  already  built  history  data  create  new  cube  adding  dimension  due  reason  user  expects  history  cube  current  cube  scanned  get  full  result  set  hybrid  realization  introduced  composed  multiple  cube  cube  overlapgap  partition  date  hybrid  delegate  query  cube  merge  result,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5872,upgrade  calcite  130,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5873,script  fill  streaming  gap  automatically,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5874,growing  dictionary  streaming  case  streaming  cube  generate  lot  dictionary  may  differ  little  growing  dict  swallow  new  entry  generate  bigger  dict  time  new  segment  built  way  entry  dicts  get  controlled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5875,backport  coprocessor  improvement  08  07,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5876,improve  performance  job  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5877,streamingolap,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
5878,allow  gap  cube  segment  streaming  case  current  implementation  kylin  doesnt  allow  gap  cube  segment  segment  must  sequential  gap  overlap  streaming  case  segment  failed  build  block  building  segment  kylin  allow  gap  failed  segment  fixed  later  without  impacting  ongoing  building,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5879,ipartitionconditionbuilder  flexible  range  condition  match  hive  partition,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5880,streaming  cubing  allow  multiple  kafka  clusterstopics,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5881,memory  mapper  building  cube  mem  20150408  030856992  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnresourcemanagerkeytab  ignoring  20150408  030856996  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobhistoryhttppolicy  ignoring  20150408  030856999  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobendnotificationmaxretryinterval  ignoring  20150408  030857003  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerkeytab  ignoring  20150408  030857004  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnresourcemanagerprincipal  ignoring  20150408  030857006  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  nettopologyscriptfilename  ignoring  20150408  030857012  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobhistorywebapphttpsaddress  ignoring  20150408  030857021  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerlogdirs  ignoring  20150408  030857022  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  fsdefaultfs  ignoring  20150408  030857029  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobhistorykeytab  ignoring  20150408  030857034  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnhttppolicy  ignoring  20150408  030857041  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerlocaldirs  ignoring  20150408  030857043  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerlinuxcontainerexecutorgroup  ignoring  20150408  030857043  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobhistoryprincipal  ignoring  20150408  030857047  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagercontainerexecutorclass  ignoring  20150408  030857048  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobendnotificationmaxattempts  ignoring  20150408  030857050  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnadminacl  ignoring  20150408  030857053  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerprincipal  ignoring  20150408  030858279  info  main  orgapachehadoopmetrics2implmetricsconfig  loaded  property  hadoopmetrics2properties  20150408  030858347  info  main  orgapachehadoopmetrics2implmetricssinkadapter  sink  ganglion  started  20150408  030858492  info  main  orgapachehadoopmetrics2implmetricssystemimpl  scheduled  snapshot  period  10  second  20150408  030858492  info  main  orgapachehadoopmetrics2implmetricssystemimpl  maptask  metric  system  started  20150408  030858570  info  main  orgapachehadoopmapredyarnchild  executing  token  20150408  030858571  info  main  orgapachehadoopmapredyarnchild  kind  hdfsdelegationtoken  service  101152061128020  ident  hdfsdelegationtoken  token  8430348  bkylin  20150408  030858650  info  main  orgapachehadoopmapredyarnchild  kind  mapreducejob  service  job1427705526386110981  ident  orgapachehadoopmapreducesecuritytokenjobtokenidentifier69607702  20150408  030858928  info  main  orgapachehadoopmapredyarnchild  sleeping  0ms  retrying  got  null  20150408  030859367  info  main  orgapachehadoopmapredyarnchild  mapreduceclusterlocaldir  child  hadoop1scratchlocalusercachebkylinappcacheapplication1427705526386110981hadoop2scratchlocalusercachebkylinappcacheapplication1427705526386110981hadoop3scratchlocalusercachebkylinappcacheapplication1427705526386110981hadoop4scratchlocalusercachebkylinappcacheapplication1427705526386110981hadoop5scratchlocalusercachebkylinappcacheapplication1427705526386110981hadoop6scratchlocalusercachebkylinappcacheapplication1427705526386110981hadoop7scratchlocalusercachebkylinappcacheapplication1427705526386110981hadoop8scratchlocalusercachebkylinappcacheapplication1427705526386110981  20150408  030859567  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnresourcemanagerkeytab  ignoring  20150408  030859568  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobhistoryhttppolicy  ignoring  20150408  030859569  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobendnotificationmaxretryinterval  ignoring  20150408  030859570  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerkeytab  ignoring  20150408  030859571  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnresourcemanagerprincipal  ignoring  20150408  030859571  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  nettopologyscriptfilename  ignoring  20150408  030859573  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  dfsnamenodecheckpointdir  ignoring  20150408  030859573  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobhistorywebapphttpsaddress  ignoring  20150408  030859576  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerlogdirs  ignoring  20150408  030859577  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  fsdefaultfs  ignoring  20150408  030859579  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobhistorykeytab  ignoring  20150408  030859579  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  dfsnamenodenamedir  ignoring  20150408  030859582  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnhttppolicy  ignoring  20150408  030859585  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerlocaldirs  ignoring  20150408  030859586  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerlinuxcontainerexecutorgroup  ignoring  20150408  030859586  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobhistoryprincipal  ignoring  20150408  030859587  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagercontainerexecutorclass  ignoring  20150408  030859588  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  mapreducejobendnotificationmaxattempts  ignoring  20150408  030859589  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnadminacl  ignoring  20150408  030859591  warn  main  orgapachehadoopconfconfiguration  jobxmlan  attempt  override  final  parameter  yarnnodemanagerprincipal  ignoring  20150408  030900499  info  main  orgapachehadoopconfconfigurationdeprecation  sessionid  deprecated  instead  use  dfsmetricssessionid  20150408  030901285  info  main  orgapachehadoopmapredtask  using  resourcecalculatorprocesstree  20150408  030902362  info  main  orgapachehadoopmapredmaptask  processing  split  orgapachehivehcatalogmapreducehcatsplit47e7cecf  20150408  030902500  info  main  orgapachehadoopmapredmaptask  map  output  collector  class  orgapachehadoopmapredmaptaskmapoutputbuffer  20150408  030903706  info  main  orgapachehadoopmapredmaptask  equator  0  kvi  2684354521073741808  20150408  030903706  info  main  orgapachehadoopmapredmaptask  mapreducetaskiosortmb  1024  20150408  030903706  info  main  orgapachehadoopmapredmaptask  soft  limit  966367616  20150408  030903706  info  main  orgapachehadoopmapredmaptask  bufstart  0  bufvoid  1073741824  20150408  030903706  info  main  orgapachehadoopmapredmaptask  kvstart  268435452  length  67108864  20150408  030903717  info  main  comhadoopcompressionlzogplnativecodeloader  loaded  native  gpl  library  20150408  030903720  info  main  comhadoopcompressionlzolzocodec  successfully  loaded  initialized  nativelzo  library  hadooplzo  rev  dbd51f0fb61f5347228a7a23fe0765ac1242fcdf  20150408  030903846  info  main  orgapachehadoopiocompresszlibzlibfactory  successfully  loaded  initialized  nativezlib  library  20150408  030903847  info  main  orgapachehadoopiocompresscodecpool  got  brandnew  decompressor  deflate  20150408  030904348  info  main  orgapachehadoopiocompresscodecpool  got  brandnew  decompressor  gz  20150408  030904348  info  main  orgapachehadoopiocompresscodecpool  got  brandnew  decompressor  gz  20150408  030904349  info  main  orgapachehadoopiocompresscodecpool  got  brandnew  decompressor  gz  20150408  030904349  info  main  orgapachehadoopiocompresscodecpool  got  brandnew  decompressor  gz  20150408  030904359  info  main  orgapachehivehcatalogmapreduceinternalutil  initializing  orgapachehadoophiveserde2lazylazysimpleserde  property  namedefaultkylinintermediatepcsessioncopy2015032200000020150323000000841ce77b81c54c0c941a6f2e309a131f  numfiles0  fielddelim\x7f  columnstypesstringintstringstringstringstringstringstringstringstringstringstringstringstringbigintbigintbigintbigint  serializationformat\x7f  columnsdefaultpcsessiontenantnamedefaultpcsessiontenantsitedefaultpcsessiondevicefamilydefaultpcsessiondeviceclassdefaultpcsessionosfamilydefaultpcsessionosversiondefaultpcsessionbrowserfamilydefaultpcsessionbrowserversiondefaultpcsessiontrafficsourcedefaultpcsessioncontinentdefaultpcsessioncountrydefaultpcsessionregiondefaultpcsessioncitydefaultpcsessionstreamiddefaultpcsessionbouncedefaultpcsessionretvisitordefaultpcsessionserveventcntdefaultpcsessionabsduration  rawdatasize50265185482  numrows507325307  externaltrue  serializationliborgapachehadoophiveserde2lazylazysimpleserde  columnstatsaccuratetrue  totalsize0  serializationnullformatn  transientlastddltime1427989487  20150408  030904454  info  main  orgapachekylinjobhadoopabstracthadoopjob  absolute  path  meta  dir  hadoop8scratchlocalusercachebkylinappcacheapplication1427705526386110981container142770552638611098101000026meta  20150408  030904456  info  main  orgapachekylincommonkylinconfig  use  kylinconfhadoop8scratchlocalusercachebkylinappcacheapplication1427705526386110981container142770552638611098101000026meta  20150408  030904476  info  main  orgapachekylincubecubemanager  initializing  cubemanager  config  hadoop3scratchlocalusercachebkylinfilecache1483meta  20150408  030904480  info  main  orgapachekylincommonpersistenceresourcestore  using  metadata  url  hadoop3scratchlocalusercachebkylinfilecache1483meta  resource  store  20150408  030904955  info  main  orgapachekylincubecubedescmanager  initializing  cubedescmanager  config  hadoop3scratchlocalusercachebkylinfilecache1483meta  20150408  030904956  info  main  orgapachekylincubecubedescmanager  reloading  cube  metadata  folder  hadoop3scratchlocalusercachebkylinfilecache1483metacubedesc  20150408  030905177  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  create  base  cuboid  8191  20150408  030908171  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  100000  record  20150408  030909776  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  200000  record  20150408  030911903  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  300000  record  20150408  030913739  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  400000  record  20150408  030915243  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  500000  record  20150408  030915389  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  received  500000  row  going  compress  base  cuboid  table  20150408  030925455  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  scanandaggregategridtable  cuboid  8191  row  87680  20150408  030925455  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  compress  finished  took  10  second  20150408  030927213  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  600000  record  20150408  030928391  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  700000  record  20150408  030929963  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  800000  record  20150408  030931408  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  900000  record  20150408  030933124  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1000000  record  20150408  030933300  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  received  1000000  row  going  compress  base  cuboid  table  20150408  030945069  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  scanandaggregategridtable  cuboid  8191  row  183872  20150408  030945070  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  compress  finished  took  11  second  20150408  030946535  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1100000  record  20150408  030947942  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1200000  record  20150408  030949166  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1300000  record  20150408  030950398  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1400000  record  20150408  030951170  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  totally  handled  1453555  record  20150408  030951302  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  source  data  1453555  row  20150408  030951303  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  received  1453555  row  going  compress  base  cuboid  table  20150408  031054326  error  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  stream  build  failed  javautilconcurrentexecutionexception  javalangoutofmemoryerror  gc  overhead  limit  exceeded  javautilconcurrentfuturetaskreportfuturetaskjava122  javautilconcurrentfuturetaskgetfuturetaskjava188  orgapachekylinjobhadoopcubev2inmemcuboidmappercleanupinmemcuboidmapperjava96  orgapachehadoopmapreducemapperrunmapperjava148  orgapachehadoopmapredmaptaskrunnewmappermaptaskjava764  orgapachehadoopmapredmaptaskrunmaptaskjava340  orgapachehadoopmapredyarnchild2runyarnchildjava167  javasecurityaccesscontrollerdoprivilegednative  method  javaxsecurityauthsubjectdoassubjectjava415  orgapachehadoopsecurityusergroupinformationdoasusergroupinformationjava1650  orgapachehadoopmapredyarnchildmainyarnchildjava162  caused  javalangoutofmemoryerror  gc  overhead  limit  exceeded  orgapachekylincommonhllhyperloglogpluscounterinithyperloglogpluscounterjava64  orgapachekylincommonhllhyperloglogpluscounterinithyperloglogpluscounterjava55  orgapachekylinmetadatameasurehllcaggregatoraggregatehllcaggregatorjava39  orgapachekylinmetadatameasurehllcaggregatoraggregatehllcaggregatorjava27  orgapachekylinstoragegridtablegtaggregatescanneraggregationcacheaggregategtaggregatescannerjava85  orgapachekylinstoragegridtablegtaggregatescanneriteratorgtaggregatescannerjava57  orgapachekylinjobhadoopcubev2inmemcubebuilderscanandaggregategridtableinmemcubebuilderjava193  orgapachekylinjobhadoopcubev2inmemcubebuildercompressbasecuboidinmemcubebuilderjava376  orgapachekylinjobhadoopcubev2inmemcubebuilderruninmemcubebuilderjava318  javautilconcurrentexecutorsrunnableadaptercallexecutorsjava471  javautilconcurrentfuturetaskrunfuturetaskjava262  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1145  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava615  javalangthreadrunthreadjava745  20150408  031054329  info  main  orgapachehadoopmapredmaptask  starting  flush  map  output  20150408  031054334  info  main  orgapachehadoopconfconfigurationdeprecation  hadoopnativelib  deprecated  instead  use  ionativelibavailable  20150408  031054336  info  main  orgapachehadoopiocompresscodecpool  got  brandnew  compressor  lzodeflate  20150408  031054591  warn  main  orgapachehadoopmapredyarnchild  exception  running  child  javaioioexception  failed  build  cube  mapper  28  orgapachekylinjobhadoopcubev2inmemcuboidmappercleanupinmemcuboidmapperjava99  orgapachehadoopmapreducemapperrunmapperjava148  orgapachehadoopmapredmaptaskrunnewmappermaptaskjava764  orgapachehadoopmapredmaptaskrunmaptaskjava340  orgapachehadoopmapredyarnchild2runyarnchildjava167  javasecurityaccesscontrollerdoprivilegednative  method  javaxsecurityauthsubjectdoassubjectjava415  orgapachehadoopsecurityusergroupinformationdoasusergroupinformationjava1650  orgapachehadoopmapredyarnchildmainyarnchildjava162  caused  javautilconcurrentexecutionexception  javalangoutofmemoryerror  gc  overhead  limit  exceeded  javautilconcurrentfuturetaskreportfuturetaskjava122  javautilconcurrentfuturetaskgetfuturetaskjava188  orgapachekylinjobhadoopcubev2inmemcuboidmappercleanupinmemcuboidmapperjava96  8  caused  javalangoutofmemoryerror  gc  overhead  limit  exceeded  orgapachekylincommonhllhyperloglogpluscounterinithyperloglogpluscounterjava64  orgapachekylincommonhllhyperloglogpluscounterinithyperloglogpluscounterjava55  orgapachekylinmetadatameasurehllcaggregatoraggregatehllcaggregatorjava39  orgapachekylinmetadatameasurehllcaggregatoraggregatehllcaggregatorjava27  orgapachekylinstoragegridtablegtaggregatescanneraggregationcacheaggregategtaggregatescannerjava85  orgapachekylinstoragegridtablegtaggregatescanneriteratorgtaggregatescannerjava57  orgapachekylinjobhadoopcubev2inmemcubebuilderscanandaggregategridtableinmemcubebuilderjava193  orgapachekylinjobhadoopcubev2inmemcubebuildercompressbasecuboidinmemcubebuilderjava376  orgapachekylinjobhadoopcubev2inmemcubebuilderruninmemcubebuilderjava318  javautilconcurrentexecutorsrunnableadaptercallexecutorsjava471  javautilconcurrentfuturetaskrunfuturetaskjava262  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1145  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava615  javalangthreadrunthreadjava745,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5882,optimize  memory  usage  gtsimplememstore  gtaggregationscanner  currently  gtcombostore  switch  memory  local  disk  according  memory  usage  reduce  size  memory  store  lead  le  disk  io  significantly  reduce  time  cost  mapper  phase  cube  building,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5883,reorganize  test  case  unit  test  integration  test  test  case  current  version  treated  like  unit  test  casesmeaning  integration  test  leading  many  problem  including  1  jenkins  separate  test  process  buildcube  buildii  test  troublesome  wrong  way  2  hbasemeatadatatestscase  pollute  classpath  subsequent  localmetadatatestcase  described  httpsissuesapacheorgjirabrowsekylin694  3  vague  boundary  unit  test  integration  test  make  difficult  running  unit  testintegration  test  maven  provided  full  stack  tool  case  like  u  could  put  unit  test  test  phrase  integration  test  integrationtest  phrase  also  put  buildcubebuildii  test  case  preintegrationtest  phrase  since  treated  part  environment  preparation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5884,migrate  cube  storage  query  side  use  gridtable  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5885,refactor  storage  layer  cache  currently  storage  layer  cache  implemented  cachefledgedstorageengine  logically  independent  storage  engine  design  unfriendly  test  case  hard  maintain  refactor  make  wrapper  cubeii  storage  engine,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
5886,igtstore  implementation  use  disk  memory  run  short  main  idea  use  disk  memory  run  short  right  cuboid  intermediate  aggregationcache  stay  memory  least  cuboid  go  disk  necessary  minimal  need  one  aggregationcache  memory  time  biggest  aggregationcache  size  base  cuboid  cuboid  stored  gtsimplememstore  currently  replace  flexible  store  switch  memory  disk  need  budget  total  free  memory  command  memorytodisk  switch  smartly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5887,support  timestamp  type  ii  cube,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5888,iiendpoint  eliminate  nonaggregate  routine  nonaggregate  routine  make  code  difficult  maintain,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5889,optimize  endpoint  response  structure  suit  nodictionary  data  current  endpoint  response  designed  data  endpoint  assumed  encoded  dict  longer  true  streaming  case  data  structure  like  iirow  redesigned  accordingly,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1
5890,bundle  statistic  info  endpoint  response  bundle  statistic  info  endpoint  response  could  help  spotlight  performance  issue,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
5891,performance  tuning  inmem  cubing  got  performance  data  need  improve  performance  cubing  mem  20150409  183115792  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  create  base  cuboid  8191  20150409  183119872  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  100000  record  20150409  183122442  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  200000  record  20150409  183124677  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  300000  record  20150409  183127146  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  400000  record  20150409  183129106  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  500000  record  20150409  183130899  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  600000  record  20150409  183132954  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  700000  record  20150409  183134940  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  800000  record  20150409  183137271  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  900000  record  20150409  183139576  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1000000  record  20150409  183142153  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1100000  record  20150409  183144334  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1200000  record  20150409  183146187  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1300000  record  20150409  183148076  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1400000  record  20150409  183150557  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1500000  record  20150409  183153111  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1600000  record  20150409  183156725  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1700000  record  20150409  183159761  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1800000  record  20150409  183204190  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  1900000  record  20150409  183208442  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  handled  2000000  record  20150409  183208804  info  main  orgapachekylinjobhadoopcubev2inmemcuboidmapper  totally  handled  2010788  record  20150409  183212368  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  base  cuboid  305547  row  20150409  183212368  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  8191  built  cache  calculate  child  20150409  183212377  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  6143  parent  8191  20150409  183224372  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  6143  row  235115  20150409  183224372  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  6143  built  cache  calculate  child  20150409  183224373  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  2047  parent  6143  20150409  183234832  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  2047  row  235115  20150409  183234832  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  2047  built  cache  calculate  child  20150409  183234833  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  1535  parent  2047  20150409  183243139  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  1535  row  229236  20150409  183243139  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  1535  built  cache  calculate  child  20150409  183243140  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  511  parent  1535  20150409  183251396  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  511  row  224480  20150409  183251397  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  511  built  cache  calculate  child  20150409  183251397  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  383  parent  511  20150409  183257896  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  383  row  205364  20150409  183257896  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  383  built  cache  calculate  child  20150409  183257897  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  127  parent  383  20150409  183304131  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  127  row  184514  20150409  183304131  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  127  built  cache  calculate  child  20150409  183304131  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  95  parent  127  20150409  183313391  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  95  row  139926  20150409  183313391  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  95  built  cache  calculate  child  20150409  183313391  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  31  parent  95  20150409  183315882  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  31  row  70702  20150409  183315882  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  31  built  cache  calculate  child  20150409  183315882  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  15  parent  31  20150409  183317560  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  15  row  36141  20150409  183317560  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  15  built  cache  calculate  child  20150409  183317560  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  14  parent  15  20150409  183318815  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  14  row  1944  20150409  183318815  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  14  built  cache  calculate  child  20150409  183318815  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  12  parent  14  20150409  183318849  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  12  row  213  20150409  183318849  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  12  built  cache  calculate  child  20150409  183318850  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  8  parent  12  20150409  183318851  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  8  row  7  20150409  183318851  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  8  built  cache  calculate  child  20150409  183318852  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  8  child  completed  output  20150409  183318853  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  12  child  completed  output  20150409  183318889  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  14  child  completed  output  20150409  183319118  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  15  child  completed  output  20150409  183319827  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  30  parent  31  20150409  183320457  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  30  row  6942  20150409  183320457  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  30  built  cache  calculate  child  20150409  183320457  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  28  parent  30  20150409  183320507  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  28  row  836  20150409  183320508  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  28  built  cache  calculate  child  20150409  183320508  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  24  parent  28  20150409  183320513  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  24  row  50  20150409  183320513  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  24  built  cache  calculate  child  20150409  183320513  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  16  parent  24  20150409  183320514  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  16  row  9  20150409  183320514  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  16  built  cache  calculate  child  20150409  183320515  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  16  child  completed  output  20150409  183320515  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  24  child  completed  output  20150409  183320515  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  28  child  completed  output  20150409  183320519  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  30  child  completed  output  20150409  183320549  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  31  child  completed  output  20150409  183320872  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  79  parent  95  20150409  183324827  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  79  row  97732  20150409  183324827  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  79  built  cache  calculate  child  20150409  183324828  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  78  parent  79  20150409  183325872  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  78  row  11343  20150409  183325872  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  78  built  cache  calculate  child  20150409  183325872  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  76  parent  78  20150409  183325961  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  76  row  1620  20150409  183325961  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  76  built  cache  calculate  child  20150409  183325961  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  72  parent  76  20150409  183325972  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  72  row  129  20150409  183325972  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  72  built  cache  calculate  child  20150409  183325973  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  64  parent  72  20150409  183325974  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  64  row  29  20150409  183325974  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  64  built  cache  calculate  child  20150409  183325975  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  64  child  completed  output  20150409  183325975  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  72  child  completed  output  20150409  183325975  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  76  child  completed  output  20150409  183325982  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  78  child  completed  output  20150409  183326033  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  79  child  completed  output  20150409  183327730  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  94  parent  95  20150409  183329563  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  94  row  26497  20150409  183329563  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  94  built  cache  calculate  child  20150409  183329563  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  92  parent  94  20150409  183329743  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  92  row  4133  20150409  183329743  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  92  built  cache  calculate  child  20150409  183329743  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  88  parent  92  20150409  183329771  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  88  row  483  20150409  183329771  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  88  built  cache  calculate  child  20150409  183329772  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  80  parent  88  20150409  183329777  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  80  row  128  20150409  183329777  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  80  built  cache  calculate  child  20150409  183329777  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  80  child  completed  output  20150409  183329778  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  88  child  completed  output  20150409  183329780  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  92  child  completed  output  20150409  183329799  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  94  child  completed  output  20150409  183329912  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  95  child  completed  output  20150409  183330844  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  111  parent  127  20150409  183336064  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  111  row  142538  20150409  183336064  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  111  built  cache  calculate  child  20150409  183336065  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  110  parent  111  20150409  183337519  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  110  row  34983  20150409  183337520  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  110  built  cache  calculate  child  20150409  183337520  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  108  parent  110  20150409  183337842  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  108  row  8076  20150409  183337842  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  108  built  cache  calculate  child  20150409  183337843  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  104  parent  108  20150409  183337915  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  104  row  2040  20150409  183337915  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  104  built  cache  calculate  child  20150409  183337916  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  96  parent  104  20150409  183337942  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  96  row  916  20150409  183337942  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  96  built  cache  calculate  child  20150409  183337943  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  96  child  completed  output  20150409  183337946  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  104  child  completed  output  20150409  183337954  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  108  child  completed  output  20150409  183337985  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  110  child  completed  output  20150409  183338158  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  111  child  completed  output  20150409  183340041  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  126  parent  127  20150409  183342976  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  126  row  61521  20150409  183342976  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  126  built  cache  calculate  child  20150409  183342976  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  124  parent  126  20150409  183343633  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  124  row  15454  20150409  183343633  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  124  built  cache  calculate  child  20150409  183343633  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  120  parent  124  20150409  183343755  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  120  row  4711  20150409  183343755  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  120  built  cache  calculate  child  20150409  183343756  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  112  parent  120  20150409  183343803  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  112  row  2253  20150409  183343803  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  112  built  cache  calculate  child  20150409  183343804  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  112  child  completed  output  20150409  183343812  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  120  child  completed  output  20150409  183343832  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  124  child  completed  output  20150409  183343902  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  126  child  completed  output  20150409  183344437  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  127  child  completed  output  20150409  183346319  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  351  parent  383  20150409  183356565  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  351  row  171433  20150409  183356565  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  351  built  cache  calculate  child  20150409  183356565  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  287  parent  351  20150409  183401896  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  287  row  143877  20150409  183401896  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  287  built  cache  calculate  child  20150409  183401896  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  271  parent  287  20150409  183405170  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  271  row  101700  20150409  183405170  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  271  built  cache  calculate  child  20150409  183405171  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  270  parent  271  20150409  183405983  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  270  row  12894  20150409  183405983  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  270  built  cache  calculate  child  20150409  183405984  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  268  parent  270  20150409  183406080  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  268  row  1866  20150409  183406080  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  268  built  cache  calculate  child  20150409  183406081  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  264  parent  268  20150409  183406093  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  264  row  164  20150409  183406093  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  264  built  cache  calculate  child  20150409  183406093  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  256  parent  264  20150409  183406095  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  256  row  39  20150409  183406095  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  256  built  cache  calculate  child  20150409  183406096  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  256  child  completed  output  20150409  183406096  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  264  child  completed  output  20150409  183406099  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  268  child  completed  output  20150409  183406117  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  270  child  completed  output  20150409  183406180  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  271  child  completed  output  20150409  183407848  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  286  parent  287  20150409  183409051  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  286  row  29466  20150409  183409052  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  286  built  cache  calculate  child  20150409  183409052  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  284  parent  286  20150409  183409215  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  284  row  4782  20150409  183409215  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  284  built  cache  calculate  child  20150409  183409215  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  280  parent  284  20150409  183409244  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  280  row  626  20150409  183409244  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  280  built  cache  calculate  child  20150409  183409244  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  272  parent  280  20150409  183409250  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  272  row  172  20150409  183409250  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  272  built  cache  calculate  child  20150409  183409251  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  272  child  completed  output  20150409  183409251  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  280  child  completed  output  20150409  183409254  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  284  child  completed  output  20150409  183409273  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  286  child  completed  output  20150409  183409404  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  287  child  completed  output  20150409  183410074  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  335  parent  351  20150409  183414470  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  335  row  127985  20150409  183414470  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  335  built  cache  calculate  child  20150409  183414470  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  334  parent  335  20150409  183415526  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  334  row  22752  20150409  183415527  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  334  built  cache  calculate  child  20150409  183415527  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  332  parent  334  20150409  183415715  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  332  row  3727  20150409  183415715  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  332  built  cache  calculate  child  20150409  183415715  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  328  parent  332  20150409  183415740  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  328  row  442  20150409  183415740  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  328  built  cache  calculate  child  20150409  183415740  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  320  parent  328  20150409  183415745  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  320  row  121  20150409  183415745  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  320  built  cache  calculate  child  20150409  183415745  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  320  child  completed  output  20150409  183415746  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  328  child  completed  output  20150409  183415748  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  332  child  completed  output  20150409  183415764  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  334  child  completed  output  20150409  183415896  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  335  child  completed  output  20150409  183416630  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  350  parent  351  20150409  183419604  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  350  row  46650  20150409  183419604  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  350  built  cache  calculate  child  20150409  183419604  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  348  parent  350  20150409  183420104  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  348  row  8741  20150409  183420105  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  348  built  cache  calculate  child  20150409  183420105  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  344  parent  348  20150409  183420188  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  344  row  1488  20150409  183420188  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  344  built  cache  calculate  child  20150409  183420188  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  calculating  cuboid  336  parent  344  20150409  183420201  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  336  row  471  20150409  183420201  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  336  built  cache  calculate  child  20150409  183420201  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  336  child  completed  output  20150409  183420202  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  344  child  completed  output  20150409  183420207  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  348  child  completed  output  20150409  183420238  info  pool5thread1  orgapachekylinjobhadoopcubev2inmemcubebuilder  cuboid  350  child  completed  output,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5892,replace  aliasmap  storage  context  clear  specified  return  column  list,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
5893,implement  fine  grained  cache  cube  ii,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5894,replace  bitset  aggrkey  inside  endpoint  order  get  hashcode  compareto  use  bitset  store  column  need  calculated  quite  inefficient,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5895,export  dictionary  map  speed  repeated  lookup  localdict  scenario,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5896,push  time  condition  ii  endpoint,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5897,create  gridtable  data  structure  abstract  vertical  horizontal  partition  table,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5898,clean  useless  code  improve  code  coverage,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5899,data  model  upgrade  legacy  cube  descs,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,0,0
5900,support  incrementmerge  job  holistic  count  distinct  requires  cube  one  segment  every  incremental  segment  must  followed  merge,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5901,build  job  flow  inverted  index  building  hongbin  going  finish  development  seperate  job  step  inverted  index  time  build  job  flow  combine  step  submit  job  enigne,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,0
5902,make  hive  table  cardinality  calculation  job  today  source  table  cardinality  calculation  synced  action  need  taken  admin  action  trigger  mapreduce  job  block  user  action  hive  table  small  okay  big  table  job  may  take  ten  minute  finish  user  friendly  generic  job  flow  engine  released  cardinality  calculation  able  converted  backend  job  user  doesnt  need  hold  ui,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5903,improve  release  selection  range  currently  range  10  work  incapable  locating  newest  version  10  also  range  10  result  release  may  present  artifact  replace  augment  release  full  listing  version  artifact  repository  would  repository  metadata  fashion  plugin  prefix  id  mapping,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5904,implement  groupartifactid  looked  plugin  prefix  default  rule  used  fallback  prefix  idea  turned  mavenideaplugin  retained  information  found  applying  default  rule  metadata  repository  consulted  stored  group  level  named  pluginsxml  orgapachemavenpluginspluginsxml  orgapachemavenpluginspluginsxml  could  potentially  include  version  information  well  worth  able  check  pluginbyplugin  basis  also  fit  potential  release  specifier  dependency  could  reconsidered  future  version  format  file  simple  prefix  groupidorgapachemavenpluginsgroupid  plugins  plugin  prefixideaprefix  artifactidmavenideapluginartifactid  plugin  plugins  prefix  particular  file  also  updated  release  time  plugin  though  rarely  necessary  new  addition  need  published  back  list  group  id  search  configured  settingsxml  default  orgapachemavenplugins  process  load  pluginsxml  file  configured  group  build  map  prefix  plugin  groupartifactids  clash  initially  fail  might  allow  using  first  discovered  resolution  mechanism  would  hope  get  situation  goal  representation  might  start  taking  different  meaning  different  context,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5905,clean  exception  handling  error  reporting  logging  need  get  rid  trace  nonfatal  error  give  something  user  friendly  trace  fatal  error  need  descriptive,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5906,improve  transparent  plugin  downloading  currently  relies  plugin  mavenmavenxxxplugin  version  10snapshot  unless  specified  plugin  management  super  pom  need  allow  groupsartifact  id  perhaps  repository  metadata,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1
5907,allow  separate  snapshot  repository,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5908,refactor  release  plugin  handle  reactored  build  releasepomxmlscm  interaction  release  plugin  refactored  1  handle  injectiondeletion  releasepomxml  scm  headtrunk  taggingwere  waiting  mavenscm  settle  little  implementing  see  mng607  information  2  handle  reactored  build  rather  build  pom  module  section  using  r  tag  see  mng521  information,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5909,separate  build  strategy  implementation  current  different  build  strategy  conflated  lifecycle  starter  easy  create  new  implementation  strategy  build  project  different  way  make  code  hard  read  make  first  attempt  isolate  strategy  discus  done  think  would  make  sense  remove  weave  mode  would  greatly  simplify  code  allow  another  set  simplification,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
5910,jdkjdk  clause  activation  section  provide  complex  expression  jdkjdk  provides  one  operator  mean  negation  would  great  use  operator  jdk15jdk  activated  current  jdk  version  15  eg  16  jdk11  14jdk  activated  current  jdk  version  11  14  jdk  13jdk  activated  current  jdk  version  13  jdk14  jdk  15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5911,support  ear  lifecycle  following  patch  integrates  ear  plugin  m2  lifecycle  m2  package  install  deploy  etc  goal  could  used  ear  packaging  first  patch  applied  mavencore  register  ear  lifecycle  second  patch  applied  mavenpluginsmavenearplugin  add  support  generateapplicationxml  flag  state  whether  applicationxml  generated  default  true  relates  mng563  original  discussion  took  place,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5912,allow  substitute  custom  artifact  resolver  embedder  allow  substitute  custom  artifact  resolver  usecase  able  use  project  deployed  maven  repository  available  ide  eg  eclipse  workspace  would  also  allow  resolve  source  project  deployed  maven  repository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5913,improve  output  readability  maventransferlistener  implementation  current  output  downloadingdownladeduploadinguploaded  transfer  notification  flaw  1  scale  number  1  1000  appropriate  unit  2  use  correct  size  kb  mb  gb  time  unit  doesnt  see  httpsenwikipediaorgwikibinaryprefix  httpsenwikipediaorgwikimetricprefix  3  aether  downloads  parallel  applies  nonpom  file  progress  interleaf  due  race  condition  systemout  know  resource  progress  belongs  let  use  improved  version  mpir  dependenciesrenderers  filedecimalformathttpsgithubcomapachemavenpluginsblobtrunkmavenprojectinforeportspluginsrcmainjavaorgapachemavenreportprojectinfodependenciesrendererdependenciesrendererjaval1583  concrete  example  noformat191191  kb  2748  kb  48119  kb  8087  kb  1313  kb  noformat  noformatprogress  4  500800  b  4045  kb  193  kb315  kb  1390  mb  1230  mbnoformat  total  size  unavailable  file  already  downloaded  removed  list  output  noformatprogress  4  800  b  4045  kb  193  kb  90  mb  12  mbnoformat  debug  mode  noformatprogress  5  xmlapis1304jar  progress  mavensharedutils06jar  progress  xercesimpl291jar  progress  commonsdigester16jar  progress  mavenreportingimpl23jar  progressnoformat  scale  1  10  one  decimal  place  printed  10  1000  integer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5914,several  small  stylistic  spelling  improvement  code  documentation  following  easily  squashed  noformat  d99f9ef8c7ffe56966945d6f1b66f0280866ded5  fix  checkstyle  error  1c9362be4328713386bd23b01f9e2c87674cb952  use  static  final  value  instead  literal  52945a679ec8f3f571d77658eda2fce06d637aa7  use  proper  spelling  eg  a26cc1b9636e19c28cd32ed1c844fec64dec55b6  use  proper  term  char  u002d  hyphenminus  instead  dash  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5915,mojo  need  way  indicate  support  multithreading,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5916,deprecate  replace  incorrectly  spelled  public  api  according  pr  101httpsgithubcomapachemavenpull101  public  api  method  incorrectly  spelled  let  clean  deprecating  adding  correctly  spelled  version  old  version  simply  call  new  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5917,executionevent  give  exception  encountered  projectfailed  forkedprojectfailed  could  usefull  exception  detail  executionlistener  impls  something  like  wait  end  maven  execution  api  change  code  executioneventgetexception  code,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5918,add  getwagonrepository  method  wagonmanager  getwagonstring  protocol  return  unconfigured  wagon  confusing  deprecate  add  new  getwagonrepository  return  configured  wagon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5919,make  url  inheritance  algorithm  visible  currently  default  url  calculated  child  parent  value  often  discussed  implementation  easy  find  mix  defaultinheritanceassemblergetchildpathadjustment  calculates  path  adjustment  mavenmodelbuilderappendpath  calculates  child  url  general  parent  url  used  childpathadjustment  set  algorithm  extrapolate  child  parent  imho  test  childpathadjustement  hack  fact  use  method  overriding  default  method  return  arent  defaultinheritanceassemblerinheritancemodelmerger  override  extrapolation  algorithm  would  make  code  lot  clear  help  future  enhancement,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
5920,implement  repository  pom  confidence  level  let  add  source  distributionmanagement  pom  rewritten  repository  tool  none  information  pom  confidence  level  default  converted  converted  maven  1x  pom  sure  format  valid  data  within  may  incomplete  partner  synced  directly  partner  site  maven2  pom  current  partner  converted  instead  deployed  deployed  repository  directly  using  deploydeploy  verified  hand  verified  information  pom  think  sliding  scale  confidence  data  think  able  interval  attached  check  metadata  update  update  jar  redownloading  pom  default  would  check  none  converted  daily  rest  never  cli  switch  could  check  release  could  requires  certain  level  confidence  accept  anything  le  verified  might  risk  reproducibility  problem  future  one  change  might  needed  get  mavenproxy  recognise  one  instance  jar  getting  corrupted  repository  compromised  might  propogated  multiple  level  need  way  integrity  check  local  internal  repository  main  one  checking  sha1s  match  match  local  something  added  later  date  wanted  keep  mind,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5921,printout  version  last  built  module  reactor  build  mng6352  introduced  printout  version  reactor  build  build  multimodule  project  parent  version  printout  also  last  built  module  codejava  info  info  reactor  summary  info  info  parent  400snapshot  success  3610  info  parentlib  success  0492  info  common  success  25444  info  loadbalancerstarter  success  21198  info  proxyconfigstarter  400snapshot  success  7496  info  info  build  success  info  code  remove  proxyconfigstarter  module  loadbalancerstarter  got  version  printout  also  order  configured  module  parent  pom  think  could  something  side  codejava  module  modulecommonsmodule  moduleloadbalancerstartermodule  moduleparentlibmodule  moduleproxyconfigstartermodule  module  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5922,ansi  color  logging  improved  output  visibility  possible  maven  use  ansi  color  logging  imo  would  make  maven  log  much  easier  read  increase  visibility  item  user  want  see  given  point  time  think  andrew  williams  work  plexus  sandbox  enable  color  logging  also  color  logger  available  ant  httpantapacheorgmanuallistenershtmlansicolorlogger,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5923,implement  version  range  support  artifact  collector  httpdocscodehausorgdisplaymavendependencymediationandconflictresolution,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5924,remove  console  logging  defaultmaven  console  based  logging  code  need  move  mavencli,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5925,mavenbuildtimestamp  use  utc  instead  local  timezone  configurable  mavenbuildtimestamp  property  currently  us  default  local  timezone  lead  problem  used  build  output  dependent  local  timezone  would  nice  defaulted  utc  could  configured  maybe  similar  mavenbuildtimestampformat  see  also  eclipse  bug  367945httpsbugseclipseorgbugsshowbugcgiid367945  also  discussed,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5926,make  aggregation  feasible  plugins  need  able  aggregate  eg  assembly  plugin  could  take  content  based  descriptor  subprojects  include  base  path  however  moment  run  across  subprojects  well  need  able  goal  turn  execution  reactor  essentially  aggregation  mode  project  available  possibly  collecting  see  bug  reactor  execution  mode,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5927,set  property  containing  currently  executing  maven  version  would  helpful  easy  way  access  current  version  maven  might  accomplished  setting  property  like  mavenversion  startup  would  available  pom  andor  plugins  could  used  record  version  maven  used  build  facilitate  build  reproducibility,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5928,control  warning  message  displayed  would  really  nice  control  warning  message  maven  spit  default  building  clean  repo  bunch  warning  unable  get  resource  message  litter  console  output  really  make  hard  see  actually  going  id  like  mvn  show  default  flag  enable  needed  kinda  like  w  flag  gcc  imo  warning  message  useful  5  time  strange  dependency  problem  pop  would  better  imo  remaining  95  mvn  didnt  complain  much  stuff  really  problem,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5929,process  profile  repository  used  building  project  inherit  parent  pom  installed  remote  repo  define  remote  repo  parent  pom  cannot  downloaded  resolve  need  able  configure  bootstrap  repo  definition  settingsxml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5930,improve  message  version  missing  dependency  using  dependencymanagement  element  easy  tell  dependency  element  current  pom  actually  problem  get  message  like  following  project  id  orgapachegeronimospecsj2ee  pom  location  homejvanzyljsorgapachegeronimospecstrunkj2eepomxml  validation  message  0  dependenciesdependencyversion  missing  1  dependenciesdependencyversion  missing  2  dependenciesdependencyversion  missing  3  dependenciesdependencyversion  missing  4  dependenciesdependencyversion  missing  would  nice  also  displayed  standard  ga  tell  referring,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5931,custom  packaging  type  configuring  defaultlifecyclemapping  mojo  execution  currently  defaultlifecyclemapping  support  mapping  phase  goal  custom  configuration  see  mavencoresrcmainresourcesmetainfplexusdefaultbindingsxml  impossible  bind  say  assembly  plugin  package  phase  within  custom  packaging  type  since  assembly  plugin  requires  meaningful  configuration  set  job  number  pom  serving  purpose  defining  lifecycle  particular  type  project  there  one  jar  couple  war  several  type  deployable  artifact  somewhat  understand  maven  lifecycle  seems  natural  convert  pom  custom  packaging  type  leaving  single  parent  global  config  pluginmanagement  currently  impossible  since  using  mostly  standard  plugins  occasional  dedicated  one  configure  project  lifecycles  digging  around  put  together  relatively  straightforward  change  mavencore  httpsgithubcomapachemavencomparemasteratanasenkomng5805lifecyclemojoconfigw1  introduces  support  specifying  configuration  dependency  mojo  execution  codexml  install  mojo  mojo  goalorgapachemavenpluginsmaveninstallplugin24installgoal  configurationconfiguration  dependenciesdependencies  mojo  mojo  mojo  mojo  install  code  well  retains  support  existing  mapping  syntax  codexml  installorgapachemavenpluginsmaveninstallplugin24install  install  code  put  together  well  make  sure  existing  running  ok  create  pull  request  also  couple  change  break  api  orgapachemavenlifecyclelifecyclejava  orgapachemavenlifecyclemappinglifecyclejava  critical  mantain  compatibility  two  httpsgithubcomapachemavenintegrationtestingcomparemasteratanasenkomng5805lifecyclemojoconfigw1,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5932,allow  plugin  implementors  choose  want  configuration  created  particular  mojoexecution  provide  finer  grained  control  configuration  processed  handing  final  mojo  configuration  configurator  take  configuration  applies  mojo  specific  use  case  want  allow  many  mojo  configured  clearly  scoping  configuration  mojo  mojo  name,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5933,use  beanconfigurator  configuration  subelements  attached  patch  extends  beanconfigurator  allow  picking  individual  configuration  subelements  useful  embedding  application  like  m2e  need  access  subset  original  configuration  change  addition  brand  new  api  introduced  30  fully  backwards  compatible  unlikely  existing  client  wonder  okay  include  change  301,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5934,add  setting  able  control  settingsxml  file  m2  cli  us,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5935,allow  user  specify  logging  text  file  option  log  text  file  mvn  l  buildtxt  clean,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5936,plugindescriptor  location  enhancement  got  following  error  javalangillegalstateexception  plugin  descriptor  id  incomplete  nullnullnull  orgapachemavenplugindescriptorplugindescriptorgetidplugindescriptorjava112  orgapachemavenplugindefaultpluginmanagercomponentdiscovereddefaultpluginmanagerjava129  fixed  errormessage  include  location  plugin  descriptor  pluginxml  file  modify  plugindescriptor  add  source  attribute  modify  mavencores  mavenplugindiscoverer  disregard  source  parameter  pas  mavenplugindescriptors  plugindescriptorbuilder  retaining  backwards  compatiblity  set  errormessage  look  like  javalangillegalstateexception  plugin  descriptor  id  incomplete  nullnullnull  jarfilehomeforgem2repositoryorgapachemavenpluginsmavenwarplugin10snapshotmavenwarplugin10200504051621441jarmetainfmavenpluginxml  orgapachemavenplugindescriptorplugindescriptorgetidplugindescriptorjava112  orgapachemavenplugindefaultpluginmanagercomponentdiscovereddefaultpluginmanagerjava130  lot  helpful  thought  id  share  hoping  youll  find  useful  enough  incorporate  way  exception  triggered  new  nullpointerexception  defaultpluginmanager  warning  plugindescriptors  version  null  constructing  message  another  exception  triggered  original  error  doesnt  get  record  tried  enhance  plexus  componentsetdescriptor  found  could  access  source  parameter  2  5  place  without  api  modification  abandoned  approach  might  prove  wise  include  source  rather  special  case  maven  pluginmanager,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5937,open  climanager  make  climanager  class  public  people  embedding  maven  like  reuse  command  line  parsing  facility,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
5938,add  input  location  tracking  site  reportplugins  injected  report  conversion  working  mph160  explanation  site  reportplugins  injected  report  conversion  decoupled  site  pluginhttpsmavenapacheorgref360mavenmodelbuilder,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5939,implement  releasepomxml  design  doc  2  component  writing  pom  release  plugin  scm  operation  using  instead  present  build  time  instead  pomxml  second  im  sure  automatic  controlled  f  switch  think  automatic  f  switch  implemented  allow  pomxml  used  releasepomxml  well  pom  file  design  httpdocscodehausorgdisplaymavendependencymediationandconflictresolution,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
5940,access  toolchains  without  maventoolchainplugin  original  idea  toolchains  tool  used  different  plugins  within  project  seems  like  good  approach  several  case  want  control  tool  choose  instance  mavencompilerplugin  use  lowest  preferably  matching  jdk  version  ensure  proper  bytecode  class  mavensurefireplugin  might  need  higher  version  due  requirement  testing  framework  codegenerators  require  recent  jdk  compared  code  theyre  actually  producing  lookandfeel  javadoc  changed  per  jdk  like  latest  able  use  case  maveninvokerplugin  able  test  combination  jdk  maven  runtime  environment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5941,ide  embedding  way  collecting  model  problem  without  failing  process  currently  ide  integration  need  perform  2  step  1  load  pom  validation  place  mavenproject  instance  case  possible  important  2  display  warning  pom  editor  elsewhere  one  run  least  projectbuildermodelbuilder  proper  validation  level  collect  result  either  result  object  exception  thrown  proposed  patch  httpsgithubcommkleintmaven3commitstrunk  make  possible  mavenproject  instance  minimal  validation  constraint  collect  validation  problem  higher  validation  level  additional  benefit  patch  log  since  version  maven  problem  valid  used  cmd  line  ide  error  reporting,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
5942,provide  exact  pointer  documentation  specific  known  exception  occur  improve  exception  handler  pointer  provided  user  give  full  explanation  error  occurred,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5943,implement  remaining  lifecycle  feature  httpdocscodehausorgdisplaymavenlifecycle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5944,allow  extension  plugins  contribute  noncore  component  reused  plugins  maven  2x  build  extension  contribute  component  realize  custom  impl  api  defined  maven  core  like  artifact  handler  lifecycle  mapping  however  support  thing  like  tycho  stock  maven  distro  need  build  extension  provide  component  realize  apis  defined  merely  extension  unknown  maven  b  looked  accessed  via  api  extension  plugins  project  c  shared  among  project  reactor  using  extension  including  state  kept  singleton  see  also  httpsissuessonatypeorgbrowsetycho236,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
5945,compile  package  reactoraware  compiling  packaging  project  consisting  subprojects  one  depends  another  maven  first  check  build  environment  existing  jar  class  target  directory  dependent  subproject  rather  always  looking  local  remote  repository  jar  artifact  attached  simple  testcase  2  subprojects  one  depends  m2  install  work  m2  compile  m2  package  also  work,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5946,parallel  resolution  artifact  artifact  resolved  parallel  grouped  group  id  get  around  lack  synchronization  local  repository  patch  following  use  threadpoolexecutor  parallelize  artifact  resolution  take  care  resolve  multiple  artifact  group  id  simultaneously  requires  java  5  make  http  wagon  default  instead  poor  performing  httpclient  disadvantage  requires  java  5  backport  jar  could  substituted  pretty  easily  break  plugins  due  commonslogging  maven  uber  jar  required  commonshttpclient  notably  apt  plugin  maybe  use  isolatedrealm  setting  screw  progress  monitor  multiple  thread  updating  advantage  much  faster  combined  http  wagon  wagon98  seeing  40  improvement  test  build,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5947,setup  lax  parsing  repository  pom  metadata  also  need  slip  piece  metadata  metadata  token  publish  repo  20  support  dropped,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5948,built  notion  mirror  repository  probably  relates  repository  work  much  maven  work  currently  user  wish  use  mirror  ibiblio  specify  alternative  remote  repository  m1  cause  problem  add  new  repository  equivalent  project  buildproperties  m2  added  list  mirror  used  first  others  may  also  checked  better  still  requires  user  specify  configuration  may  used  project  never  needed  would  good  could  repository  descriptor  base  repository  list  mirror  first  use  repository  user  could  prompted  select  mirror  theyd  like  use  saved  configuration  repository  id  way  project  listing  ibiblio  repository  could  actually  use  say  planetmirror  instead  fall  back  ibiblio  last,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5949,aether  integration  aether  aim  standard  library  interacting  maven  repository  maven  repository  play  critical  role  within  jvmbased  development  infrastructure  aether  provide  necessary  interoperability  common  set  tool  apis  thats  critical  happy  user  ecosystem  jvz  full  introduction  read  httpwwwsonatypecompeople201008introducingaether,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
5950,add  new  requiresdependencycollection  mojo  feature  corresponding  annotation  grab  dependency  tree  without  file  see  thread  add  new  mojo  annotation  requiresdependencycollectionhttpmarkmailorgmessageui2eywpqux4zi74f  detail  annotation  trigger  new  plugin  descriptor  requiresdependencycollection  element  httpmavenapacheorgref310mavenpluginapipluginhtmlclassmojo,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5951,provide  line  number  information  error  processing  pomxml  error  pomxml  maven  2  reasonable  job  identifying  error  doesnt  provide  location  error  example  forget  include  version  inside  one  dependency  noformat  bash300  mvn  info  scanning  project  info  error  fatal  error  info  info  error  building  pom  may  project  pom  project  id  hivemindhivemind  pom  location  cworkspacejakartahivemindlibrarypomxml  validation  message  0  dependenciesdependencyversion  missing  reason  failed  validate  pom  info  info  trace  orgapachemavenreactormavenexecutionexception  failed  validate  pom  orgapachemavendefaultmavengetprojectsdefaultmavenjava359  orgapachemavendefaultmavendoexecutedefaultmavenjava276  orgapachemavendefaultmavenexecutedefaultmavenjava113  orgapachemavenclimavenclimainmavenclijava249  sunreflectnativemethodaccessorimplinvoke0native  method  sunreflectnativemethodaccessorimplinvokenativemethodaccessorimpljava39  sunreflectdelegatingmethodaccessorimplinvokedelegatingmethodaccessorimpljava25  javalangreflectmethodinvokemethodjava585  orgcodehausclassworldslauncherlaunchenhancedlauncherjava315  orgcodehausclassworldslauncherlaunchlauncherjava255  orgcodehausclassworldslaunchermainwithexitcodelauncherjava430  orgcodehausclassworldslaunchermainlauncherjava375  caused  orgapachemavenprojectinvalidprojectmodelexception  failed  validate  pom  orgapachemavenprojectdefaultmavenprojectbuilderprocessprojectlogicdefaultmavenprojectbuilderjava774  orgapachemavenprojectdefaultmavenprojectbuilderbuilddefaultmavenprojectbuilderjava624  orgapachemavenprojectdefaultmavenprojectbuilderbuildfromsourcefiledefaultmavenprojectbuilderjava298  orgapachemavenprojectdefaultmavenprojectbuilderbuilddefaultmavenprojectbuilderjava276  orgapachemavendefaultmavengetprojectdefaultmavenjava509  orgapachemavendefaultmavencollectprojectsdefaultmavenjava441  orgapachemavendefaultmavengetprojectsdefaultmavenjava345  11  info  info  total  time  1  second  info  finished  sat  dec  10  100916  pst  2005  info  final  memory  1m2m  info  noformat  maven  identified  line  number  file  shouldnt  pick  way  though  document  maven  already  better  yet  display  invalid  portion  file  highlight  exact  point  error  realize  controversial  add  issue  bug  enhancement  feel  strongly  absolute  importance  developer  feedback  complex  tool,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5952,provide  extension  point  track  artifact  addition  local  repository  integrator  like  m2eclipe  would  like  get  notified  update  local  repository  order  update  auxiliary  data  structure  like  index,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5953,improved  userconfigurable  core  extension  mechanism  version  325  maven  provides  two  mechanism  contribute  additional  component  maven  core  runtime  possible  add  component  jar  m2homelibext  directory  also  possible  specify  component  jar  using  dmavenextclasspath  command  line  parameter  neither  mechanism  user  friendly  case  user  expected  manually  locate  download  required  jar  file  case  done  system  extension  needed  case  extra  jar  loaded  single  classloader  extension  must  agree  set  dependency  jira  track  change  needed  make  possible  configure  core  extension  term  groupidartifactidversion  share  set  required  extension  across  multiple  system  specifically  introduce  new  mavenprojectbasedirmvnextensionsxml  descriptor  specify  list  extension  initially  descriptor  allow  specification  extension  groupidartifactidversion  extended  support  dependency  includesexcludes  mechanism  configuration  parameter  later  codexml  xml  version10  encodingutf8  extension  extension  groupidgroupid  artifactidartifactid  versionversion  extension  extensionextension  extension  code  change  maven  read  load  core  extension  separate  class  realm  part  plexus  container  setup  provide  mechanism  extension  declare  exported  artifact  package  using  metainfmavenextensionxml  descriptor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
5954,new  resolution  local  repository  confusing  discover  change  introduced  maven  3x  try  improve  resolution  mechanism  avoid  use  local  artifact  may  available  remote  repository  httpscwikiapacheorgconfluencedisplaymavenmaven3xcompatibilitynotesmaven3xcompatibilitynotesresolutionfromlocalrepository  even  feature  interesting  several  problem  artifact  isnt  accessible  remote  repository  isnt  used  maven  reply  classical  dependency  found  error  really  annoying  user  maven  2  skill  look  local  repo  find  artifact  wont  understand  maven  doesnt  use  least  error  reported  maven  clear  even  dependency  available  locally  isnt  used  remote  repository  isnt  available  behavior  cannot  configured  warning  example  really  annoying  doesnt  take  care  context  constraint  may  development  team  let  imagine  remote  artifact  really  removed  cool  maven  broke  build  warn  u  brake  build  team  whereas  perhaps  one  may  try  solve  issue  long  resolution  thus  ability  configure  control  blocker  warning  may  allow  team  configure  blocker  ci  server  warning  development  environment  behavior  may  introduce  bad  practice  example  using  staging  feature  repository  manager  case  team  dedicated  profile  activate  staging  repository  validating  release  recommend  profile  always  activated  ondemand  avoid  dl  staging  stuff  dont  need  new  feature  need  build  run  activate  staging  profile  binary  stored  20  time  per  day  minimum  let  imagine  developer  add  alwaysactive  profile  forget  remove  release  ended  reason  would  like  improve  feature  make  usable  bet  understandable  user,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5955,hide  driverelative  path  plugins  take  nice  path  tmp  note  leading  slash  absolute  path  unix  derivates  driverelative  path  window  box  driverelative  path  resolved  prepending  drive  current  directory  entire  current  directory  notation  driverelative  path  wellknown  even  among  window  user  particular  easy  going  crossplatform  java  tool  java  developer  usually  assumes  path  either  directoryrelative  absolute  avoid  unnecessary  complication  seen  multios  ci  grid  cf  dev  thread  ci  grid  window  pathshttpwwwnabblecomcigrid2cwindowsandpathsto21153292html  reported  user  eg  meclipse404  core  align  directoryrelative  path  also  resolve  driverelative  path,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5956,provide  extension  point  provide  alternate  cli  configuration  mechanism  currently  way  configure  execution  session  settingsxml  file  mechanism  essence  code  currently  work  read  settingsxml  file  stuff  bunch  value  mavenexecutionrequest  possible  easily  use  different  source  value  use  different  logic  populate  value,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
5957,allow  specification  toolchainsxml  location  command  line  allowing  cli  specification  toolchainsxml  file  allow  flexible  configuration  ci  environment,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
5958,reactor  summary  time  taken  next  success  message  subproject,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
5959,allow  build  lifecycle  execute  project  parallel  one  great  advantage  maven  scripted  build  environment  calculate  dependency  build  could  execute  item  independent  parallel  unfortunately  currently  doesnt  would  big  win  tool  ant  also  mean  multicore  machine  lot  idle  capacity  running  serial  build  could  utilised  quick  shot  seeing  might  required  bear  mind  first  time  looked  maven  internally  trying  feel  way  around  build  poc  got  way  build  thread  dont  seem  correct  classpath  think  something  plexus  classworlds  dont  know  enough  itd  great  get  feature  future  version  way  running  hack  figuring  thread  plexus  stuff  interim,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
5960,projectbuilderbuildfileprojectbuildingrequest  return  null  project  dependency  version  info  missing  projectbuilderbuildfileprojectbuildingrequest  return  null  mavenproject  instance  following  pomxml  even  using  modelbuildingrequestvalidationlevelminimal  expecteddesired  behaviour  return  mavenproject  instance  populated  goodresolved  dependency  information  badmissing  dependency  mavenexecutionresultgetexceptions  andor  mavenexecutionresultgetdependencyresolutionresult  noformat  project  modelversion400modelversion  groupidxxxgroupid  artifactidm01artifactid  version001snapshotversion  dependency  dependency  groupidjunitgroupid  artifactidjunitartifactid  dependency  dependency  project  noformat  original  m2e  bugreport  httpsbugseclipseorgbugsshowbugcgiid343568,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5961,provide  hand  holding  dependency  nondistributable  jar  create  pom  thing  like  jdbc  jdo  etc  house  jar  ibiblio  attempt  use  present  locally  provide  sensible  error  message  provide  plugin  install  file  local  repository  ie  m2  installinstall  dartifactpathtojdbc20jar  dgroupidjdbc  dartifactidjdbc  dversion20  modify  installinstall  mojo  allow  taking  parameter  instead  project,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
5962,reimplement  parallel  artifact  download  current  maven3  trunk  30alpha3  doesnt  contains  nice  feature  exists  2x  parallel  download  artifact  made  really  faster  starting  empty  repo,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5963,adding  method  abstractmavenreport  obtain  newsink  actually  extending  abstractmavenreport  get  sink  write  one  page  report  need  create  page  like  new  method  called  newsinkfilewriter  write  page  could  sinkfactory  object  injected  abstractmavenreport  note  need  sink  current  site  skin  thanks  olivier,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5964,add  module  mavenbuildersupport  almost  duplicate  class  used  modelbuilder  settingsbuilder  enhancement  toolchains  there  another  need  class  let  extract  class  separate  module  mavenbuildersupport,1,1,0,1,0,0,0,0,0,0,0,1,1,0,0,0,0
5965,allow  exclusion  certain  dependency  inclusion  archive  requested  war  apply  archive  include  dependency,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5966,maven  lifecycle  participant  attached  patch  introduces  abstractmavenlifecycleparticipant  allows  maven  core  extension  participate  maven  lifecycle  immediate  use  case  injection  osgi  dependency  tycho  believe  approach  applied  problem  like  example  reworked  reporting  plugins  discussed  30  however  need  new  callback  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5967,allow  goal  cleanclean  specified  clean  would  real  nice  specifying  goal  without  colon  eg  clean  site  would  check  see  plugin  name  goal  name  think  would  ease  transition  people  greatly  help  people  like  cant  type  worth  darn,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5968,build  mavenproject  instance  incrementally  embedding  scenario  like  m2e  workspace  dependency  resolution  implemented  efficiently  maven  core  allowed  incremental  construction  mavenproject  instance  build  mavenproject  basic  project  information  properly  inherited  interpolated  first  populate  project  dependency  populate  project  plugins  plugins  configuration  attached  proposed  implementation  support  incremental  mavenproject  construction,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5969,inherited  url  always  artifact  id  url  scm  web  etc  inherited  always  artifactid  appended  default  avoid  needing  respecify  however  path  structure  doesnt  match  artifactid  convention  respecify  happen  regardless  original  structure  url  wasnt  really  instance  inheriting  url  doesnt  change  make  sense,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5970,reactor  failed  project  behaviour  reactor  ignorefailures  like  m1  smarted  failure  setting  fail  build  first  subproject  failure  process  overall  fail  failure  process  report  success  regardless  eg  running  site  want  continue  something  else  next  additionally  second  two  option  play  project  fail  one  dependency  failed  eg  mavenartifact  fails  build  mavencore  mavenmodel,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5971,allow  configuring  deployment  timedstamped  artifact  using  snapshot  version  essentially  issue  mpartifact59  maven  2  code  base  current  version  contains  snapshot  every  deploy  creates  snapshot  artifact  artifact  datetime  cause  lot  artifact  created  using  continuous  build  would  like  see  feature  configurable  turn  least  happen  want  scheduled  basis  related  note  think  would  good  datetimestamped  version  still  contain  word  snapshot  way  easy  determine  whether  project  currently  dependency  snapshot  unreleased  version  parse  datetime  format  well  common  snapshot  keyword  would  easier,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5972,provide  beforeafter  callback  project  mojo  execution  build  extension  developer  would  like  able  receive  beforeafter  callback  event  project  mojo  execution  projectlevel  event  need  mavensession  manveproject  obviously  well  calculated  project  execution  plain  mojo  execution  need  mavensession  manveproject  mojoexecution  mojo  instance  idea  allow  extension  observe  participate  project  build  whole  set  independent  mojo  execution,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5973,provide  extension  point  alternate  implementation  construct  build  graph,1,0,1,0,1,0,0,0,0,1,1,0,0,0,0,0,0
5974,move  detection  pluginexecution  idcollisions  project  validator  rather  defaultmavenprojectbuilder,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5975,check  artifact  pomdefined  repository  checking  central  repository  maven  102  build  environment  went  trouble  building  replica  ibiblio  repository  local  machine  would  build  hang  minute  ibiblio  decided  hiccup  build  trying  update  snapshot  current  project  would  nice  maven  2  would  look  dependency  local  repository  defined  project  parent  pom  looking  central  repository  would  allow  locallyproduced  artifact  found  faster  especially  internet  connection  dialup  would  probably  also  reduce  load  ibiblio  server,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5976,support  selection  wagon  implementation  particular  protocol  competing  bug  list  different  implementation  http  wagon  itd  nice  provide  default  lightweight  wagon  implementation  allow  user  need  specify  httpclientdriven  implementation  via  maven  configuration  implemented  maven  221  need  integration  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5977,modify  maventoolchain  look  mavenhomeconftoolchainsxml  userhomem2toolchainsxml  actually  specify  toolchainsxml  userhomem2toolchainsxml  however  like  settingsxml  would  convenient  specify  default  toolchainsxml  mavenhomeconftoolchainsxml  idea  userhomem2toolchainsxml  us  mavenhomeconftoolchainsxml  otherwise  none  defined  merging  would  also  good  necessary  change  simple  edit  file  maventoolchainsrcmainjavaorgapachemaventoolchaindefaulttoolchainmanagerjava  replace  codejava  private  persistedtoolchains  readtoolchainsettings  throw  misconfiguredtoolchainexception  file  tch  new  filesystemgetpropertyuserhome  m2toolchainsxml  tchexists  maventoolchainsxpp3reader  reader  new  maventoolchainsxpp3reader  code  codejava  private  persistedtoolchains  readtoolchainsettings  throw  misconfiguredtoolchainexception  file  tch  null  tch  new  filesystemgetpropertyuserhome  m2toolchainsxml  tch  null  tchexists  tch  new  filesystemgetpropertymavenhome  conftoolchainsxml  tchexists  maventoolchainsxpp3reader  reader  new  maventoolchainsxpp3reader  code  local  environment  compiling  2011snapshot  class  integrating  maven209uberjar  work  perfectly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5978,make  plugin  discovery  reactor  aware  plugin  discovery  reactor  aware  plugins  part  reactor  build  used  aid  build  used  one  go  else  first  plugin  installed  rest  project  built  mainly  aid  integration  testing  plugins  mavenitplugin  sandbox  cant  add  current  plugin  artifact  lifecycle  without  making  method  public  plugin  discovered  using  reactor  method  remain  private,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
5979,simplify  mojo  qdox  specification  mapped  field  name  type  default  value  derived  field  definition  instead  simplifying  rest  validator  longer  necessary  parameter  attribute  required  expression  could  specified  field  description  javadoc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5980,make  like  reactor  mode  add  commandline  option  enable  maven  expand  reactor  scope  find  project  dependency  project  currently  reactor  add  currently  current  project  child  project  included  reactor  search  im  proposing  add  commandline  switch  let  maven  check  parent  directory  find  root  project  tree  normal  reactor  scan  adding  project  would  normally  added  theyre  needed  dependency  project  would  normally  built  here  sample  project  tree  root  p1  c1  depends  p2  p2  depends  c2  p3  c2  sample  algorithm  building  c1  reactor  would  contain  c1  maven  would  check  p1  root  etc  using  parent  tag  without  version  see  project  still  current  reactor  would  create  second  list  project  reactor2  containing  project  using  newly  discovered  root  root  p1  c2  p2  remove  project  reactor2  contained  reactor  reactor2  root  p1  p2  resolve  direct  dependency  project  reactor  reactor2  add  reactor  taking  version  account  reactor  p2  c1  repeat  previous  step  project  dependency  resolved  reactor  2  first  iteration  would  yield  reactor  c2  p2  c1  next  iteration  would  stop  since  c1  doesnt  dependency  present  reactor2  would  ensure  local  project  source  changed  theyll  incorporated  build  regardless  build  dont  reactor  build  time  change  1  project  dont  remember  project  changed  build  correct  order  manually,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5981,introduce  password  encryption  trunk,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5982,poor  projectbuilderbuild  performance  project  unresolvable  extension  plugins  need  extend  pluginartifactscache  also  cache  extension  plugin  artifact  resolution  error  otherwise  defaultprojectbuildinghelper  keep  failing  resolve  plugin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5983,projectspecific  default  jvm  option  command  line  parameter  project  build  work  require  special  jvm  option  like  minimal  xmx  value  specific  command  line  parameter  like  builder  currently  manually  configure  every  time  run  build  rather  annoying  error  prone  manual  configuration  also  make  harder  new  external  developer  build  project  many  simply  give  trying  mvn  package  work  first  try  enhancement  request  proposes  introduce  two  new  optional  configuration  file  mvnjvmconfig  mvnmavenconfig  located  base  directory  project  source  tree  present  file  provide  default  jvm  maven  option  file  part  project  source  tree  present  project  checkout  automatically  used  every  time  project  build,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5984,api  calculate  execution  plan  without  full  mojo  execution  configuration  m2e  us  project  execution  plan  determine  configure  project  eclipse  workspace  workbench  build  mojo  execution  bound  execution  plan  relevant  think  enforcer  deploy  plugin  m2e  need  api  analyse  execution  plan  perform  full  configuration  interesting  mojo  execution  original  m2e  jira  httpsissuessonatypeorgbrowsemngeclipse2724  proposed  patch  attached,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
5985,update  slf4j  simplify  color  integration  update  dependence  maven  build  slf4j  1722  1725  slf4j394httpsjiraqoschbrowseslf4j394  slf4j395httpsjiraqoschbrowseslf4j395  slf4j389httpsjiraqoschbrowseslf4j389  slf4j  update  simplify  mavenslf4jprovider  implementation  given  slf4j394httpsjiraqoschbrowseslf4j394,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
5986,add  optional  flag  dependency  optional  equivalent  compile  passed  transitive  deps  allow  u  repair  dependency  like  dom4j  avoid  lot  exclusion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5987,consider  layout  mirror  selection  extension  like  tycho  employ  custom  repo  layout  access  p2  obr  repos  come  mirroring  desirable  use  different  mirror  normal  maven  repos  osgi  repos  neverthess  user  still  able  use  wildcards  easy  mirror  maintenance  wildcard  match  repo  regardless  layouttype  enrich  setting  model  allow  specification  layout  mirror  considered  selecting  mirror  specific  repository,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5988,use  int  long  instead  bigintegers  little  number  comparableversion  working  mng6571  found  could  enhance  performance  many  version  compared  perhaps  maven  build  since  probably  negligible  scenario  version  comparison  used  could  useful  see  httpsgithubcomapachemavenblobmastermavenartifactsrcmainjavaorgapachemavenartifactversioningcomparableversionjava  every  integer  biginteger  currently  used  integer  le  10  digit  int  would  sufficient  would  lot  efficient  integer  le  19  digit  long  would  way  go  biggest  number  get  usually  timestamp  snapshot  like  20171015230843  yyyymmddhhmmss  int  sufficient  vast  majority  case,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
5989,provide  way  customize  lifecycle  mapping  logic  default  lifecycle  mapping  logic  us  phase  plugin  execution  configuration  element  map  lifecycle  instance  custom  lifecycles  would  like  able  provide  custom  logic  specific  usecase  able  define  custom  lifecycle  run  specific  phase  default  lifecycle  nothing  else,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
5990,improve  version  resolution  logging  couple  thing  missing  log  range  restricted  due  encountering  dep  different  version  log  version  selected  range  later  log  conflict  resolution  also  verbose  junitjunitjar381  removed  nearer  found  381,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5991,allow  class  realm  manager  delegate  alter  public  part  maven  core  realm  part  fix  mng4747  new  class  realm  introduced  represents  public  part  maven  core  life  integrator  need  contribute  additional  class  like  polyglot  maven  m2eclipse  would  easier  realm  also  subject  class  realm  delegate  would  allow  inject  custom  type  central  place  rather  injecting  every  plugin  realm,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5992,improve  checksum  handling  presently  missing  invalid  checksum  warned  sha1  md5  always  uploaded  need  pick  one  repository  might  choose  upload  though  probably  worth  testing  way  need  way  specify  master  override  command  line  turn  strict  checking  thing  like  anything  else  eg  skip  bad  transitive  deps  might  want  retry  failure  discussion  seems  better  allow  specified  project  encourage  bad  metadata  fix  need  still  reassess  impact  user  position  make  sure  repo1  verified  integrity  maintained,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5993,m2  eclipse  plugin  improvement  source  download  attachment  customization  naturesbuildersconclasspath  flexible  project  dupport  refactoring  patch  add  following  m2  eclipse  plugin  downloading  source  attachment  configuration  classpath  customization  project  builder  nature  project  like  m1  plugin  additional  conclasspath  entry  classpath  like  m1  plugin  fix  dont  add  duplicate  directory  mainresources  directory  overlap  like  m1  plugin  support  flexible  project  wtpmodules  file  generation  utility  module  war  ejbs  along  new  feature  plugin  refactored  splitting  single  big  eclipsewriter  class  several  specific  class  message  externalized  property  file  still  todos  code  probably  m2  guru  could  look  anyway  existing  functionality  continue  work  test  added  due  refactoring  patch  look  like  complete  rewrite  sorry  adding  new  feature  without  splitting  existing  file  ugly,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
5994,perf  enhance  code  applying  best  practice  part  myfaces  small  change  reduce  ammount  object  created  make  iteration  faster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5995,allow  view  state  rendered  beginning  form  discussed  user  list  leonardo  uribe  asked  create  ticket  feature  idea  allow  view  state  rendered  beginning  form  avoid  viewexpiredexception  case  postback  page  isnt  completely  loaded  yet  detail  httpmarkmailorgsearchqview20list3aorgapachemyfacesusersqueryview20list3aorgapachemyfacesusers20order3adatebackwardpage1miduqp2l6y2iwlmwbsostateresults  workaround  im  using  primefaces  deferred  loading  hide  form  component  page  isnt  fully  loaded  httpwwwprimefacesorgshowcaseuioutputpaneljsf  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5996,improvement  state  saving  algorithm  following  improvement  done  myfaces3117  current  server  state  saving  implementation  prevents  multiwindow  usage  included  also  myfaces3134  move  code  related  state  caching  one  place  myfaces3137  align  responsestatemanager  implementation  spec  myfaces3138  simplify  responsestatemanager  implementation  code  possible  improve  part  lot  part  code  work  fine  old  well  understood  think  reasonable  review  part  deep  note  could  suppose  change  serversidestatecacheimpl  related  class  ps  algorithm  good  change  related  logic  involved  saverestore  state  mode  client  side  server  side  state  saving  possible  imagine  mixed  strategy  client  side  server  side  state  saving  could  reduce  session  size  way  achieve  even  better  scalability  also  possible  imagine  way  secure  token  sent  view  server  side  state  saving  used  using  random  number  allowing  disable  encryption  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5997,jsr252  issue  54  added  new  extension  element  face  xml  schema  added  new  extension  element  face  xml  schema  please  see  section  11  xml  schema  definition  also  see  httpsjavaserverfacesspecpublicdevjavanetissuesshowbugcgiid54,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
5998,remove  servlet  25  compatibility  hack,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
5999,dont  deserialize  viewstateid  state  saving  method  server  currently  viewstateid  provided  user  deserialized  via  java  deserialization  even  javaxfacesstatesavingmethod  set  server  default  deserialization  case  unecessary  likely  even  slower  sending  viewstate  id  directly  developer  disables  viewstate  encryption  setting  orgapachemyfacesuseencryption  false  myfaces  security  advicehttpswikiapacheorgmyfacessecureyourapplication  might  unintentionally  introduced  dangerous  remote  code  execution  rce  vulnerability  described  herehttpswwwalphabotcomsecurityblog2017javamisconfiguredjsfviewstatescanleadtoseverercevulnerabilitieshtml  discussed  issue  myfaces4021httpsissuesapacheorgjirabrowsemyfaces4021,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6000,make  jsp  21  optional  myfaces  120  requires  jsp  21  present  otherwise  startupservletcontextlistener  fails  error  exception  sending  context  initialized  event  listener  instance  class  orgapachemyfaceswebappstartupservletcontextlistener  javalangnosuchmethoderror  javaxservletjspjspfactorygetjspapplicationcontextljavaxservletservletcontextljavaxservletjspjspapplicationcontext  orgapachemyfaceswebappdefaultfacesinitializerinitfacesdefaultfacesinitializerjava102  orgapachemyfaceswebappstartupservletcontextlistenercontextinitializedstartupservletcontextlistenerjava57  jsp  version  21  better  jsp  general  optional  dependency  like  discussed  implemented  sun  ri  httpwwwnabblecomdoesmyfaces12requirejsp21tf4112432htmla11693501  use  case  run  myfaces  120  jee  14  environment  tomcat  5x  easier  setup  smaller  distribution  running  myfaces  embedded  servlet  container  jetty  facelets  example  im  using  jetty  junit  test  havent  found  working  setup  solves  jsp  problem,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1,0
6001,javaxfacesvalidator  doublerangevalidator  lengthvalidator  longrangevalidator  similar  refactor  common  behaviour  3  class  similar  except  type  minimum  maximum  value  course  therefore  ill  suggest  extracting  common  behaviour  common  parent  class,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,0
6002,gae  add  param  select  jar  file  scanned  facesconfigxml  taglibxml  annotation  myfaces  user  list  reported  spring  jsf  slow  gae  start  necessary  scan  classpath  facesconfigxml  taglibxml  annotation  possible  put  myfaces  jar  jsf  related  jar  outside  webinflib  folder  gae  skip  limitation  becomes  effective  indicate  jar  file  scan  web  config  param  orgapachemyfacesgaejsfjarfiles  myfaces  jar  need  scanned  param  possible  set  contextparam  paramnameorgapachemyfacesgaejsfjarfilesparamname  paramvaluenoneparamvalue  contextparam  skip  scanning  webinfclasses  still  scanned  change  startup  gae  quick  note  necessary  application  container  initialization  occur  application  deployed  take  second  anyway  consider  worth,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6003,performance  improvement  htmlrenderkitimpl  profiling  project  found  htmlrenderkitimpl  creates  amount  transient  object  garbage  getrenderer  called  self  8005  000  792  0  2894448  jorgapachemyfacesrenderkithtmlhtmlrenderkitimplgetrendererljavalangstringljavalangstringljavaxfacesrenderrenderer  child  24015  000  469  0  1714064  jjavalangstringbufferappendljavalangstringljavalangstringbuffer  value  recorded  2  request  page  many  component  28mb  transient  object  created  8005  call  getrenderer  assume  due  keying  currenlty  implemented  always  creates  concatinated  string  guess  using  mapstring  mapstring  renderer  doublemap  could  improve  performance  since  string  creation  keying  would  nessary  might  also  touch  12  20,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6004,perf  minimize  facescontextgetcurrentinstance  call  part  ii  still  possible  minimize  even  number  call  facescontextgetcurrentinstance  small  change  method  example  applicationcreatecomponentstring  componenttype  internal  call  facescontextgetcurrentinstance  variant  applicationcreatecomponentfacescontext  context  string  componenttype  string  renderertype  retrieved  parameter  since  renderertype  null  according  jsf  spec  result  method  equivalent  possible  use  second  variant  save  one  call  per  component  renderertype  important  place  el  evaluation  occur  facescompositeelresolver  facescontextgetcurrentinstance  always  called  preferred  get  facescontext  elcontext  first  get  map  1  2  element  faster  threadlocal  lookup  proportional  number  thread  running,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6005,lookup  expressionfactory  also  supportjspandfacesel  false  currently  supportjspandfacesel  set  false  myfaces  cant  initialize  without  setting  orgapachemyfacesexpressionfactory  simply  define  list  known  expressionfactory  implementation  orgapachemyfacesexpressionfactory  optional,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6006,searchexpression  api  proposal  primefaces  guy  include  search  expression  api  locate  component  case  like  fajax  executerender  attribute  hmessage  attribute  others  idea  come  httpblogprimefacesorgp2740  idea  support  syntax  like  attribute  clientid  id  ididid  keywordid  idkeyword  keywordparam1  keywordparam1param2  patch  working  last  week  still  require  test  update  component  myfaces  core  23  use  new  api,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6007,core  improve  ps  algorithm  dynamic  view  use  cif  uiinclude  src  used  implement  change  according  mail  sent  dev  list  name  core  improve  ps  algorithm  dynamic  view  use  cif  uiinclude  src  used  last  month  working  solution  improve  partial  state  saving  ps  performance  case  view  updated  dynamically  effect  facelet  tag  like  cif  cwhen  uiinclude  src  uidecorate  template  simple  word  use  previous  tag  page  cause  component  inside  saved  restored  fully  side  effect  overall  state  get  bigger  introduction  ps  jsf  20  instead  save  array  property  keyvalue  pair  used  usually  effect  difficult  notice  relevant  specially  uiinclude  src  used  update  content  dynamically  quite  simple  find  example  search  engine  internet  ill  explain  detail  whats  going  let  see  happen  cif  used  cif  testcondition  houtputtext  valuesome  text  cif  first  time  view  rendered  condition  false  component  added  later  postback  condition  change  false  true  component  added  algorithm  two  option  1  ignore  2  mark  component  branch  restored  fully  time  ignore  1  ok  complex  case  state  synch  lost  testcondition  evaluated  every  time  view  restored  different  result  user  usually  reported  state  get  lost  classcastexception  problem  deal  case  special  mode  added  myfaces  implement  2  web  config  param  called  orgapachemyfacesrefreshtransientbuildonpss  happen  algorithm  save  cif  condition  first  time  view  rendered  ps  algorithm  always  restore  initial  view  expected  recently  2010  214  improvement  myfaces3329  added  longer  necessary  enable  web  config  param  great  note  solve  state  get  bigger  problem  consider  happen  cif  condition  saved  every  time  change  render  response  condition  false  change  true  initial  state  restored  including  component  called  markinitialstate  component  delta  saved  state  size  smaller  finally  saved  efficently  initial  state  one  get  bigger  instead  part  saved  delta  solution  applied  cif  cwhen  uiinclude  src  uidecorate  template  enough  cforeach  replaced  hdatatable  rowstatepreservedtrue  similar  component  like  one  available  tomahawk  variant  interesting  note  solution  also  fix  problem  hdatatable  rowstatepreservedtrue  used  inside  dynamic  part  fortunately  spec  doesnt  say  anything  markinitialstate  called  let  implementation  detail  also  javaxfacesisbuildinginitialstate  description  general  even  change  need  change  javadoc  considering  history  behind  ps  algorithm  seems  reasonable  activate  markinitialstate  call  set  javaxfacesisbuildinginitialstate  true  dynamic  update  component  tree  done  facelet  tag  deactivate  soon  code  process  content  end  application  using  previous  tag  really  huge  improvement  state  anyway  since  extension  initial  intention  flag  consider  desirable  mention  difficult  measure  impact  depends  view  structure  sound  like  promising  change  suggestion  opinion  want  say  proposed  change  welcome  objection  ill  commit  proposed  change  soon,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6008,improve  plugin  mechanism  forgot  add  version,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6009,perf  check  duplicate  id  saving  view  production  stage  see  discussion  httpwwwmailarchivecomdevmyfacesapacheorgmsg52995html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6010,perf  additional  performance  improvement  performance  improvement  1  applicationimpljava  2  servletexternalcontextimpljava  3  htmlresponsewriterimpljava  4  htmlencoderjava  also  discussed  mailing  list  changing  encodeuriatributte  encodeuriattribute  fix  typo  method  name  ill  well  5  resourcevalidationutilsjava  following  change  made  skip  calling  concurrenthashmapcontainskey  since  call  get  afterward  containskey  true  stop  using  boolean  variable  dont  null  meaning  null  false  use  boolean  default  false  dont  call  stringlength  constantly  string  variable  arent  reassigned  change  conditional  order  avoid  calling  validateresourcename  unless  condition  true,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6011,enable  standard  checkstyle  check  myfacescore  currently  minimal  check  enabled  core  actually  check  correct  license  header  go  standard  checkstyle  rule  even  would  take  time  fix  found  1111  error  first  module,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6012,utility  method  classutils  throw  exception  new  utility  method  called  simpleclassfornamestring  type  boolean  logexception  added  classutils  throw  exception  boolean  false  method  would  nice  websphere  webconfigprovider  implementation  patch  provided,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6013,support  valuechangelistener  method  without  valuechangeevent  parameter  valuechangelistener  method  also  take  argument  see  javadoc  methodexpressionvaluechangelistener  detail,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6014,catch  throwable  error  using  errorpagewriter  myfaces  error  handling  one  possible  enhancement  myfaces  error  handling  capability  catch  throwable  error  using  myfaces  error  handling  done  taking  account  spec  say  call  execute  method  saved  lifecycle  instance  passing  facescontext  instance  request  parameter  execute  method  throw  facesexception  rethrow  servletexception  facesexception  root  cause  call  render  method  saved  lifecycle  instance  passing  facescontext  instance  request  parameter  render  method  throw  facesexception  rethrow  idea  catch  rethrow  non  exception  class  like  error  extends  throwable  error  class  directly  myfaces  error  handling  used  use  show  error  page  info  taking  account  info  could  available  idea  facesservlet  try  lifecycleexecutefacescontext  handlequeuedexceptionsfacescontext  lifecyclerenderfacescontext  catch  exception  e  handlelifecycleexceptionfacescontext  e  catch  throwable  e  handle  error  throwable  error  case  outofmemoryerrors  handlelifecyclethrowablefacescontext  e  finally  facescontextrelease  please  note  change  break  old  functionality,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6015,perf  use  grail  streamcharbuffer  instead  fastwriter  htmlresponsewriterimpl  looking  solution  replace  default  fastwriter  implementation  one  allocate  multiple  block  demand  way  reduce  memory  used  render  page  founded  one  cool  implementation  orgcodehausgroovygrailswebutilstreamcharbuffer  httpgrailsorgdoclatestapiorgcodehausgroovygrailswebutilstreamcharbufferhtml  file  apache  v20  license  include  myfaces  use  htmlresponsewriterimpl  internal  buffer  performance  test  notice  impact  speed  minimal  non  existent  memory  good  enough  htmlresponsewriterimpl  usually  cloned  ajax  request  fastwriter  always  initialize  buffer  matter  used  page  big  buffer  grows  without  unnecessary  copy  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6016,perf  implement  oamsupportmanagedbeans  running  stress  test  one  blocked  thread  blocked  arraylist  monitor  tomcat  internals  orgapachecatalinacorecontainerbasefirecontainereventstring  object  orgapachecatalinasessionstandardsessionfirecontainereventcontext  string  object  orgapachecatalinasessionstandardsessionsetattributestring  object  boolean  orgapachecatalinasessionstandardsessionsetattributestring  object  orgapachecatalinasessionstandardsessionfacadesetattributestring  object  orgapachemyfacescontextservletsessionmapsetattributestring  object  orgapachemyfacesutilabstractthreadsafeattributemapputstring  object  orgapachemyfacesutilabstractthreadsafeattributemapputobject  object  happens  someone  put  attribute  httpsession  orgapachemyfacesutilabstractthreadsafeattributemapputobject  object  orgapachemyfacesrenderkitserversidestatecacheimplnextviewsequencefacescontext  orgapachemyfacesviewfaceletsfaceletviewdeclarationlanguagegetresponseencodingfacescontext  string  orgapachemyfacesrenderkitserversidestatecacheimplsaveserializedviewinservletsessionfacescontext  servlet  container  delivers  event  httpsessionbindingevent  myfaces  httpsessionattributelistener  implemented  oamstartupservletcontextlistener  handle  stuff  managed  bean  review  needed  ideally  remove,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
6017,perf  optimize  uileaf  uileaf  facelets  internal  class  act  wrapper  html  markup  since  stateless  transient  class  used  intensively  jsf  better  reduce  size  overhead  caused  class  1  make  class  extends  uicomponent  instead  uicomponentbase  reduce  overall  size  object  memory  2  use  extra  object  implement  attribute  map  3  use  variable  componentsupportmarkcreated  instead  store  hashmap  optimization  reduce  object  size  le  half  replace  lot  call  hashmapget  simple  variable  assignment,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6018,provide  interface  override  find  spi  interface  last  step  solve  myfaces2944  myfaces2945  problem  related  osgi  spi  possible  call  serviceloaderfinderfactorysetserviceloaderfinderexternalcontext  ectx  serviceloaderfinder  slp  serviceloaderfinderfactorysetserviceloaderfinderservletcontext  ctx  serviceloaderfinder  slp  initialization  set  serviceloaderfinder  used  later  locate  spi  interface  way  possible  provide  code  look  spi  interface  using  osgi  bundle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6019,google  app  engine  support  myfaces  2  google  app  engine  support  myfaces  2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6020,perf  cache  el  expression  using  indirection  uiparam  user  tag  attribute  trying  time  find  new  way  improve  code  inside  myfaces  working  myfaces3811  fix  cforeach  realized  way  variablemapper  work  allows  u  cache  el  expression  place  thought  el  caching  possible  fact  important  change  way  thinking  around  view  pooling  technique  see  myfaces3664  detail  valueexpressionmethodexpression  instance  view  considered  static  word  change  time  view  built  refreshed  sure  plain  visittree  call  possible  reset  view  reuse  safely  even  case  like  uiparam  used  user  facelet  tag  component  view  support  pooling  hardsoft  reset  using  savestate  method  view  using  component  poolable  first  let  remember  variablemapper  work  basically  map  var  name  key  valueexpression  value  el  expression  created  variable  context  variablemapper  used  solve  expression  copied  stored  inner  variablemapper  created  el  expression  example  cset  varitem  valuehello  cset  varitem2  valueitem  cset  varitem3  valueitem2  el  expression  item2  inner  variablemapper  el  expression  pointing  hello  need  remember  problematic  case  el  caching  1  use  combination  cset  cif  cif  testcondition  cset  varitem  valuehello  cif  houtputtext  valueitem  case  unlikely  refactored  easily  avoid  cif  move  condition  cset  el  expression  common  found  technique  old  jsp  page  clear  jsf  kind  logic  reside  managed  bean  end  big  deal  anyway  mode  called  strict  disable  el  caching  whole  page  cset  found  2  use  uiparam  uidecorate  templateuiparamcache11xhtml  uidecorate  uidecorate  templateuiparamcache11xhtml  uiparam  nameparam1  valuealfa  uidecorate  first  time  template  called  params  expression  cached  inside  inner  template  call  template  cached  expression  invalid  need  recalculated  hack  done  alwaysrecompile  mode  recompiles  facelet  take  account  known  parameter  template  way  el  expression  affected  param  cached  3  use  facelet  user  tag  userusertagtest1  var1alfa  idcomp1  userusertagtest1  userusertagtest1  var2beta  idcomp2  userusertagtest1  userusertagtest1  var1gamma  var2omega  idcomp3  userusertagtest1  quite  case  uiparam  case  affect  facelet  tag  attribute  4  expression  us  variable  resolved  variablemapper  unlikely  standard  tag  using  strategy  possible  create  facelet  tag  us  variablemapper  wrapper  something  worry  myfaces3811  fix  cforeach  part  wrapper  iteratedvalueexpression  mappedvalueexpression  required  hold  associated  item  inject  variablemapper  indeed  good  idea  show  put  wrapper  inside  variablemapper  thing  keep  working  substitute  valueexpression  associated  var  something  else  avoid  propagation  effect  make  el  caching  fail  2  3  trick  use  unique  id  associated  facelet  tag  put  real  el  expression  central  point  like  faceletstate  object  stored  uiviewroot  resulting  structure  generated  ps  enabled  disable  need  saved  state  component  tree  change  dynamically  generated  structure  change  final  effect  100  el  expression  managed  facelets  using  alwaysrecompile  mode  cacheable  great  improvement  also  remove  one  biggest  disadvantage  include  view  pooling  technique  myfaces  22x,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6021,enabled  exception  handling  like  facelets  rest  myfaces  lifecycle  express  permission  jacob  hookom  dual  licensing  one  class  facelets  asl  ive  added  faceletserrorhandling  code  rest  myfaces  lifecycle  jacob  icla  file  paperwork  done  tweak  behaviour  two  new  contextparameters  added  add  webxml  need  use  tweaking  private  static  final  string  errorhandlingparameter  orgapachemyfaceserrorhandling  want  disable  behaviour  completely  private  static  final  string  errorhandlerparameter  orgapachemyfaceserrorhandler  want  choose  different  class  handling  exception  enjoy  regard  martin  see  maildiscussion  attached  reference  problem  think  itd  cool  solution  jsf  12  grab  elresolver  walk  feature  even  custom  elresolvers  would  able  output  custom  variable  jacob  72307  martin  marinschek  martinmarinschekgmailcom  wrote  hi  jacob  ok  use  errorhandling  page  also  error  full  lifecycle  myfaces  love  page  would  want  see  exception  renderexceptions  well  id  surely  add  author  wed  definitely  need  put  asllicense  top  though  regard  martin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6022,todo  65  partial  view  lifecycle  add  partial  view  lifecycle  described  134  partial  view  traversal  edr2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6023,reload  facesconfigfiles  change  detected  check  regularly  change  webxml  file  reloads  needed  time  interval  set  mean  context  parameter  default  2  second  right,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6024,add  serviceloader  code  chainloading  init  code  set  internal  event  go  beyound  jsf  2x  deliver  use  add  context  param  webxml  jdk6  service  faclity  use  optionally  present  load  plugins  service  commits  issue  enable  facilty  present,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6025,add  annotation  processing  logic  jsf  20  specifies  use  following  annotation  managed  bean  configuration  managedbean  managedbeans  managedproperty  requestscoped  sessionscoped  viewscoped  applicationscoped  nonescoped  annotation  already  need  processing  logic  im,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6026,reviewrefactordocument  viewstate  handling  currently  thing  viewstate  handling  could  get  even  improved  3  main  goal  achieve  order  importance  1  security  easily  possible  create  state  key  clash  2  performance  still  use  java  13  trick  eg  barely  use  javautilconcurrent  3  memory  shall  keep  mem  footprint  low  possible,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6027,make  create  ajaxbehavior  accessible  ajaxhandler  im  currently  trying  create  custom  ajax  tag  based  fajax  support  additional  attribute  wanted  create  new  tag  handler  extends  ajaxhandler  found  hard  creation  ajaxbehavior  buried  inside  applyattachedobject  reasonable  way  found  set  additional  value  expression  created  ajaxbehavior  pas  wrapped  facescontextapplication  derived  class  would  much  easier  instance  creating  behavior  would  done  protected  method  behavior  would  accessible  derived  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6028,perf  uiforminvokeoncomponent  prependidtrue  case  invokeoncomponent  used  form  prependidtrue  early  skip  whole  component  tree  baseclientid  form  clientid  also  check  component  uidata  already  contains  enhancement,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6029,lifecycle  phase  execution  repetition  every  phase  lifecycleimpl  look  like  private  boolean  applyrequestvaluesfacescontext  facescontext  phaselistenermanager  phaselistenermgr  throw  facesexception  boolean  skipfurtherprocessing  false  logistraceenabled  logtraceentering  applyrequestvalues  lifecycleimplclassgetname  try  phaselistenermgrinformphaselistenersbeforephaseidapplyrequestvalues  ifisresponsecompletefacescontext  applyrequestvalues  true  return  right  away  return  true  ifshouldrenderresponsefacescontext  applyrequestvalues  true  skipfurtherprocessing  true  facescontextgetviewrootprocessdecodesfacescontext  finally  phaselistenermgrinformphaselistenersafterphaseidapplyrequestvalues  isresponsecompletefacescontext  applyrequestvalues  false  shouldrenderresponsefacescontext  applyrequestvalues  false  since  phase  completed  dont  need  return  right  away  even  response  completed  skipfurtherprocessing  true  skipfurtherprocessing  logistraceenabled  logtraceexiting  applyrequestvalues  lifecycleimplclassgetname  return  skipfurtherprocessing  repeated  many  time  phase  fix  extract  common  behavior  method  receives  one  additional  parameter  phaseexecutor  delegate  real  execution,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
6030,implementation  new  jsr252  class  uicomponentclassictagbase  new  class  jsr252  must  implemented  uicomponentclassictagbase  superclass  jsp  tag  httpjavasuncomjavaeejavaserverfaces12docsapiindexhtml,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1
6031,perf  calculate  facelets  view  mapping  context  suffix  necessary  perf  test  notice  method  defaultviewhandlersupport  defaultrestoreviewsupport  called  multiple  time  always  return  value  based  initialization  params  change  application  lifetime  solution  small  change  two  class  passing  facescontext  constructor  calculating  value  first  time  class  created,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6032,include  uncompressed  jsfjs  file  use  development  mode  used  reading  blog  jsf  20  notice  mojarra  include  uncompressed  jsfjs  file  use  development  mode  used  difficult  debug  myfaces  javascript  user  think  worth,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
6033,perf  use  shared  stringbuilder  instance  method  javaxfacescomponentuicomponentbasegetsharedstringbuilderfacescontext  already  provide  add  method  public  api  use  requestshared  stringbuilder  instance  renderers,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6034,make  add  method  public  webxml  geronimo  integration  work  internal  structure  parsed  webxml  file  hope  use  instance  fill  orgapachemyfacessharedwebappwebxmlwebxml  myfaces  need  parse  webxml  file  add  method  package  scope  possible  make  method  public  see  break  anyting  thanks,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6035,minor  performance  improvement  orgapachemyfacesel  orgapachemyfacescontext  orgapachemyfacesutil  fixed  findbugs  error  performance  category  apply  many  pmd  optimization  rule  made  many  class  final  method  argument  never  assigned  declared  final  local  variable  assigned  declared  final,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6036,jsr252  unified  el  implement  section  55  56  57  58  jsf  12  spec  specific  eg  issue  number  jira  task  serve  catchall  integration  new  unified  el  provided  jsp  21,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6037,javaxfacesconvert  refactor  common  behaviour  datetimeconverter  change  available  converter  look  similar  extract  common  behavior  base  class  also  datetimeconverter  migrated  work  type  safe  enums  style  type  property  comment  source  like  todo  validate  timestyle  according  java  doc  datetimeconverter  sun  validation  validation  performed  asstringasobject  method  called,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6038,fix  ps  algorithm  ensure  cif  uiinclude  src  related  use  case  work  without  rely  orgapachemyfacesrefreshtransientbuildonpsspreservestate  well  known  issue  related  use  cif  uiinclude  src  described  different  way  long  time  example  see  myfaces3271  uiinclude  tag  handler  evaluates  binding  soon  jsf  lifecycle  lot  related  issue  keep  thing  simple  ps  algorithm  based  following  condition  1  time  view  build  first  time  restored  initial  state  retrieved  2  possible  calculate  delta  state  based  initial  state  practice  use  case  break  cif  tag  b  cchoose  cwhen  cotherwise  c  uiinclude  src  usually  known  dynamic  include  uidecorate  template  e  cforeach  reason  change  component  tree  dynamically  example  cif  tag  could  bound  valueexpression  one  moment  could  true  false  initial  state  calculated  ps  algorithm  vdlbuildview  different  time  breaking  condition  1  true  exists  workaround  orgapachemyfacesrefreshtransientbuildonpsspreservestate  mark  part  tree  restored  fully  matter  initial  state  end  restore  part  fully  everything  work  facelets  11x  even  workaround  need  better  solution  practice  point  b  c  relevant  case  e  related  cforeach  iterated  data  usually  life  longer  view  session  conversation  view  scope  exclude  case  solution  problem  store  result  evaluated  expression  within  view  work  good  orgapachemyfacesrefreshtransientbuildonpsspreservestate  need  generate  unique  id  per  tag  make  component  tag  inside  generate  unique  tag  id  generated  time  view  build  matter  condition  example  houtputtext  valuea  cif  testcondition  houtputtext  valueb  cif  houtputtext  valuec  c  id  time  matter  happen  inside  cif  since  ps  algorithm  us  clientids  store  delta  state  component  ensure  critical  otherwise  state  get  mixed  lost  additionally  must  restore  facelet  state  view  built  use  initial  state  derived,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6039,implement  viewhandlergetviews,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
6040,make  way  get  facesconfig  provider  currently  myfaces  startup  listener  parse  face  configuration  file  sort  startup  time  better  deployment  time  get  data  structure  instance  provider  one  possible  way  make  facesconfig  class  serializable,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
6041,implement  resourcehandlermarkresourcerendered  resourcehandlerisresourcerendered  implement  resourcehandlermarkresourcerendered  resourcehandlerisresourcerendered  described  spec  current  implementation  move  code  resourceutils  us  simple  map  relevant  see  feature  work  dynamic  resource  loaded  ajax  request,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6042,implement  cdi  change  jsf  23  idea  implement  following  annotation  applicationmap  flowmap  headermap  headervaluesmap  initparametermap  requestcookiemap  requestmap  requestparametermap  requestparametervaluesmap  sessionmap  viewmap  tricky  part  object  managed  jsf  others  cdi,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6043,unify  reflectutil  classutils  class  currently  historically  grown  2  different  class  responsible  class  loading  one  reflectutil  class  originates  facelets  codebase  one  homegrown  classutils  advantage  disadvantage  probably  unify  class  shared  classutils  long  run  post  20,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6044,make  method  determinine  app  context  factoryfinder  pluggable  discussed  dev  list  geronimo  would  like  explicitly  mark  component  boundary  rather  relying  tccl  changing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6045,cdi  support  converter  validators  contextparam  paramnameorgapachemyfacescdimanagedconvertersenabledparamname  paramvaluetrueparamvalue  contextparam  contextparam  paramnameorgapachemyfacescdimanagedvalidatorsenabledparamname  paramvaluetrueparamvalue  contextparam  possible  enable  cdi  support  convertersvalidators  need  config  postponed  spec,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
6046,perf  concurrency  check  correct  logger  creation  blockedjavautilloggingloggergetloggerstring  javaxfacescomponentuiviewrootinit  problem  nonstatic  logger  logger  requested  every  view  init  class  static  method  monitor  associated  class  object  method  class  used  check  myfaces  code  base  usage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6047,csp  nonce  attribute  script  tag  ignored  ajax  update  simple  csp  case  add  static  nonce  via  phaselistenerservlerfilter  header  add  static  nonce  script  tag  work  fine  get  request  nonajax  post  ajax  engine  ignores  nonce  attribute  script  following  error  occurs  browser  content  security  policy  die  einstellungen  der  seite  haben  da  laden  einer  ressource  auf  inline  blockiert  scriptsrc  probably  ticket  future  thats  first  basic  case  must  supported  course  problem  like  onclick  handler  dom  eval  node  partialresponse  similar  httpsgithubcomjqueryjqueryissues3541,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6048,myfaces  12  doesnt  start  without  webxml  myfaces  12  fails  one  message  webxml  found  mapping  facesservlet  defined  couldnt  find  webxml  abort  initializing  myfaces  mapping  facesservlet  found  abort  initializing  myfaces  thats  quite  strict  interpretation  spec  say  implementation  may  check  presence  servletclass  definition  class  javaxfaceswebappfacesservlet  web  application  deployment  descriptor  mean  abort  configuration  process  reduce  startup  time  application  use  javaserver  face  technology  would  helpful  unit  test  webxml  servletmapping  mandatory  maybe  configurable  unit  test  start  embedded  jetty  server  whose  configuration  build  programmatically  server  jettyserver  new  server  context  webappcontext  new  contextjettyserver  contextpath  contextsessions  webappcontextaddeventlistenernew  startupservletcontextlistener  servletholder  facesservletholder  new  servletholdernew  facesservlet  webappcontextaddservletfacesservletholder  face  webappcontextgetserverstart  code  working  fine  myfaces  11  broken  12,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6049,update  model  didnt  throw  exception  exception  occurred  add  message  display  user  according  good  sense  update  model  throw  exception  show  message  message  list  setting  value  modelbean  throw  exception  hopefully  wont  make  problem  tck  challenge  regard  martin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6050,regression  detect  wpdate  head  body  target  content  updated  dynamically  related  topic  sent  jsr344experts  list  jsr344experts  facelet  page  dynamic  content  update  ajax  content  work  user  expects  take  look  example  includexhtml  hcommandlink  fajax  rendercontent  hcommandlink  fsubview  idcontent  uiinclude  srctestmanagedbeanpage  fsubview  page1xhtml  uicomposition  xmlnshhttpjavasuncomjsfhtml  xmlnsfhttpjavasuncomjsfcore  xmlnsuihttpjavasuncomjsffacelets  houtputtext  idcomponent1  valuepage  1  component  uicomposition  page2xhtml  uicomposition  xmlnshhttpjavasuncomjsfhtml  xmlnsfhttpjavasuncomjsfcore  xmlnsuihttpjavasuncomjsffacelets  houtputstylesheet  houtputtext  idcomponent2  valuepage  2  component  uicomposition  problem  dynamic  content  change  add  resource  head  target  houtputstylesheet  shouldnt  added  section  ajax  payload  update  head  section  theory  yes  break  encapsulation  principle  user  say  render  inside  content  head  section  change  responsability  framework  case  partialviewcontext  detect  send  correct  payload  right  two  option  keep  track  resource  rendered  save  state  use  information  check  head  rendered  b  use  postaddtoviewevent  check  change  component  tree  triggered  change  head  option  b  save  byte  state  could  cause  render  head  section  necessary  example  dynamic  change  head  already  rendered  resource  necessary  option  impose  need  way  check  head  changed  require  change  spec  ill  solve  problem  adding  web  config  param  orgapachemyfacesstrictjsf2refreshtargetajax  myfaces  change  algorithm  adding  flag  indicate  view  built  first  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6051,perf  avoid  forminfo  instance,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6052,create  new  module  junit  mock  testing  using  myfaces  core  myfaces  test  cdi  issue  next  step  work  started  myfaces3376  create  abstract  test  class  run  myfaces  core  container,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6053,create  sharedpublic  module  create  sharedpublic  module  discussed  dev  list  see  discussion  httpmarkmailorgmessageujqdvipurs6zzju5qdiscusshowtogetridoftonsofduplicatedcode,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6054,implement  bean  validation  implement  beanvalidator  class  corresponding  tagsconfigs  logic  related  bean  validation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6055,remove  compositecomponentresourcetaghandlerattachedobjecthadlerskey  attribute  map  another  state  saving  improvement  remove  attached  object  handler  component  attribute  map  instead  map  hold  attached  object  handler  indexed  component  reference  created  compositecomponentresourcetaghandler,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6056,allow  elresolvers  filtering  related  topic  httpwwwmailarchivecomdevmyfacesapacheorgmsg49177html  problem  disable  elresolver  smartly  adding  contextparam  overkill  httpscwikiapacheorgmyfaceselresolverorderinghtml  codebase  already  propose  add  new  feature  elresolver  filtering  new  contextparam  contextparam  paramnameorgapachemyfaceselresolverpredicateparamname  paramvalueorgfoobazzelresolverpredicateparamvalue  contextparam  filter  simple  instance  orgapachecommonscollectionspredicate  application  managedbeanresolver  used  flash  user  simply  return  false  predicateevaluate  elresolver  wont  installed  see  mail  thread  httpwwwmailarchivecomdevmyfacesapacheorgmsg52082html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6057,jsr252  javaxwebappconvertertag  replaced  convertereltag  jsr  spec  1032  javaxwebappconvertertag  replaced  convertereltag  convertertag  part  implementation,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
6058,ffacet  one  child  michael  kurz  tested  mojarra  found  ffacet  one  child  child  automaticall  put  uipanel  serve  facet  requirement  however  improvement  mentioned  spec  filed  spec  issue  httpsjavaserverfacesspecpublicdevjavanetissuesshowbugcgiid677,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6059,jsf  view  pooling  going  beyond  jsf  stateless  mode  last  month  investigation  around  stateless  jsf  idea  intention  try  find  way  improve  myfaces  core  performance  much  possible  without  lose  nice  feature  used  summary  justification  around  stateless  jsf  possible  cut  build  view  time  request  improvement  speed  memory  perspective  true  point  response  time  request  given  build  view  validationinvoke  application  render  response  time  get  goal  without  sacrifice  jsf  stateful  behavior  improvement  already  done  cache  el  expression  cache  id  make  tree  structure  lighter  idea  cache  stateless  information  place  reused  effectively  case  inside  facelet  abstract  syntax  tree  ast  worked  well  far  side  effect  enable  optimization  analysed  good  understanding  word  basic  idea  stateless  jsf  proposed  originally  rudi  simic  blog  mark  view  stateless  using  attribute  use  pool  view  view  thread  safe  store  view  pool  use  visittree  call  reset  field  unfortunately  quickly  found  implementation  proposed  requires  better  view  pool  try  reset  field  failsafe  component  tree  also  store  input  field  value  additionally  doesnt  provide  way  use  dynamic  view  provide  thread  safe  implementation  uicomponent  reused  across  thread  good  solution  anyway  information  inside  uicomponent  stored  per  thread  precisely  uicomponent  place  specifically  designed  store  information  based  previous  background  big  question  solution  based  object  pooling  pattern  done  effectively  web  framework  like  jsf  good  description  technique  tradeoff  found  httpenwikipediaorgwikiobjectpoolpattern  word  proposal  go  beyond  jsf  stateless  mode  instead  blame  state  make  friend  let  take  advantage  stateful  nature  jsf  allow  reuse  view  fully  partially  ps  algorithm  used  check  view  modified  checking  state  used  check  component  state  possible  provide  way  reset  state  component  initial  state  set  first  markinitialstate  restore  state  possible  view  cannot  reset  fully  possible  use  facelets  refreshing  algorithm  reuse  view  partially  add  additional  code  recover  view  instance  discarded  store  view  pool  requires  change  navigationhandlerimpl  possible  reuse  view  store  pool  still  usage  necessary  deferred  navigation  changing  default  actionlistenerimpl  ensure  handlenavigation  called  end  invoke  application  phase  outside  visittree  call  myfaces  exists  concept  faceletstate  possible  use  concept  cache  even  dynamic  view  different  faceletstate  identify  specific  view  structure,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6060,ajax  behavior  renderer  need  improvement  new  implementation  delta  state  saving  existing  ajax  behavior  renderer  implemented,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6061,findcomponent  slow  high  amount  call  profiling  showed  findcomponent  take  considerable  amount  time  complete  called  quite  often  many  component  call  findcomponent  proposed  solution  store  child  list  also  map  keyed  id  regard  martin,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6062,myfaces  performance  improvement  production  several  fix  enhance  startup  memory  footprint  runtime  performance  taking  advantage  projectstage  lazy  loading  validators  converter  behaviorscomponents  substantial  impact  startup  footprint  application  multiple  large  widget  library  turn  updating  resource  projectstageproduction  default  always  override  using  javaxfacesfaceletsrefreshperiod  change  default  facelets  refresh  interval  1  projectstage  production  gain  60  improvement  throughput  disable  reloading  webxml  facesconfig  first  load  store  map  cache  class  listenerfor  resourcedependency  annotation  production,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6063,implement  fwebsocket  related  api  implement  fwebsocket  proposal  described  latest  javadoc,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6064,remove  resolvecomponent  prototype  new  search  expression  think  create  patch  create  spec  issue  currently  need  leave  myfaces  discus  solution  first  spec  level,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6065,remove  el  22  compatibility  hack  also  removed  servlet  25  compatibility,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6066,perf  cache  facescontext  clientbehaviorbase  level  use  hack  done  uicomponentbase  avoid  call  facescontextgetcurrentinstance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6067,add  alwaysrecompile  mode  el  expression  cache  mode  myfaces3160  el  expression  cache  mode  introduced  soon  seen  problem  found  myfaces3169  uiparam  cset  implementation  work  expected  two  problem  limit  scope  el  expression  cache  used  1  facelets  user  tag  cannot  cache  el  expression  2  inclusion  using  uiparam  must  always  contains  number  parameter  understand  reason  worth  remember  example  axhtml  uicomposition  templatecxhtml  uiparam  namevar1  valuevalue1  uicomposition  bxhtml  uicomposition  templatecxhtml  uiparam  namevar1  valuevalue1  uiparam  namevar2  valuevalue2  uicomposition  cxhtml  uicomposition  houtputtext  valuevar1  houtputtext  valuevar2  uicomposition  facelet  cxhtml  constructed  axhtml  var2  recognized  parameter  el  expression  inside  cxhtml  holding  refereces  var2  cached  later  facelet  cxhtml  reused  bxhtml  since  el  expression  cached  passed  value  var2  taken  account  error  arise  point  good  remember  uiinclude  uidecorate  user  tag  build  view  time  tag  executed  view  built  parameter  attribute  passed  uiparam  user  tag  attribute  follows  principle  calculated  build  view  time  variablemapper  evaluation  stored  inside  el  expression  mean  el  expression  holding  reference  variable  cannot  cached  need  generated  time  view  built  way  know  beforehand  reference  affected  template  user  tag  declaration  parameter  attribute  user  point  view  thats  good  context  declaration  parameter  necessary  problem  uiparam  user  tag  useful  feature  widely  used  solution  problem  improve  performance  case  thinking  long  time  solve  trying  different  strategy  use  kind  concurrency  algorithm  inside  tagattributeimpl  work  expensive  use  central  storage  cache  expression  cost  involved  comparison  objective  cache  el  expression  inside  facelets  abstract  syntax  tree  ast  minimize  calculation  required  get  valid  expression  el  implementation  already  internal  map  cache  information  code  usually  synchronized  block  similar  thing  sense  idea  rely  storage  el  expression  choice  need  recreated  many  experiment  part  came  solution  involves  following  point  1  associate  facelet  parameter  considered  passed  uiparam  user  tag  attribute  point  time  know  example  cxhtml  us  var1  consider  cxhtmlvar1  2  use  defaultvariablemapper  track  parameter  passed  uiparam  user  tag  attribute  el  expression  created  us  least  one  parameter  mark  expression  cacheable  3  override  faceletcache  implementation  force  recompilation  facelet  new  parameter  detected  considered  first  time  template  created  4  facelet  stored  cache  used  parameter  used  template  considered  compiled  first  time  example  proposed  facelet  cxhtml  constructed  axhtml  say  cxhtml  built  var1  known  parameter  cxhtmlvar1  try  reuse  facelet  cxhtml  bxhtml  discover  var2  also  parameter  since  cached  facelet  cxhtmlvar1  algorithm  discard  facelet  create  new  one  taking  account  var2  new  facelet  becomes  cxhtmlvar1var2  call  cxhtml  params  considered  cxhtmlvar1var2  used  case  final  effect  extra  compilation  facelet  startup  mediumlong  term  information  need  calculated  associated  facelet  url  nice  facelet  fast  extra  compilation  step  final  effect  performance  really  pay  could  even  set  mode  default  disadvantage  strategy  current  contract  faceletcache  insuficient  described  myfaces3705  implementation  detail  inside  myfaces  core  facelets  implementation  need  exposed  proper  way  need  create  custom  abstractfaceletcache  specify  implement,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6068,use  key  server  side  state  saving  ajax  request  current  code  server  side  state  saving  creates  one  key  per  request  store  view  state  ok  necessary  ajax  request  reason  necessary  never  go  back  page  using  ajax  page  current  request  ajax  request  return  page  view  one  restored  key  token  sent  need  change  change  internal  state  view  client  side  page  take  advantage  fact  update  state  stored  serializedviewcollection  view  challenge  detect  strategy  applicable  example  happen  ajax  redirect  look  good  idea  implement  22  avoids  store  unnecessary  information  session  optimize  use  view  slot,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6069,handle  jspexceptions  myfaces  errorhandling  well  jspexceptions  hadnt  handled  specificially  stacktrace  cut  jspexceptions,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6070,refactor  uirepeat  code  implement  ps  algorithm  like  uidata  fix  state  behavior  right  code  orgapachemyfacesviewfaceletscomponentuirepeat  reviewed  fix  issue  related  jsf  2  spec  work  done  better  code  following  opportunity  implement  ps  algorithm  prevent  store  data  state  algorithm  used  uidata  handle  state  better  fix  myfaces3415,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
6071,improved  viewstate  handling  improved  performance  view  state  writing  myfaces  121  quite  bit  following  2  change  1  algorithm  replacing  form  state  marker  jspviewhandlerimpl  much  faster  improved  indexof  buffered  writing  stringbuilder  2  view  state  rendered  javascript  feature  enabled  via  context  parameter  orgapachemyfacesviewstatejavascript  view  state  hidden  input  form  rendered  empty  value  attribute  actual  viewstate  filled  client  rendered  javascript  function  simply  iterates  form,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6072,create  new  package  orgapachemyfacesspi  implement  provider  integration  point  application  container  jsf  12  earlier  necessary  one  point  integrate  application  container  lifecycleprovider2  handle  postconstruct  predestroy  annotation  jsf  20  many  stuff  introduced  requires  provide  spi  interface  application  container  could  integrate  better  one  problem  handle  jsf  library  outside  webinflib  directory  customize  algorithm  requires  knowledge  container  protocol  also  known  protocol  like  jar  cause  problem  try  scan  file  necessary  open  jar  file  scan  entry  find  one  file  see  myfaces2583  myfaces2833  detail  think  introduce  two  new  package  called  orgapachemyfacesspi  orgapachemyfacesspiimpl  deal  stuff  based  class  name  found  comsunfacesspi  package  provide  following  point  handling  postconstruct  predestroy  done  lifecycleprovider2  annotation  scanning  container  could  code  duplicated  framework  deal  stuff  like  possibility  overrideextend  facesconfigxml  facelettaglibxml  addition  possible  add  resource  file  included  process  serialization  partially  done  serialfactory  interface  jboss  provide  serialization  solution  time  clear  interface  look  like  ill  provide  proposal  stuff  take  time  necessary  think  carefully  interface,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
6073,perf  improve  html  renderers  improvement  html  renderers  complete  optimization  started  myfaces3237  reducing  call  getattributesget  replace  stringbuffer  stringbuilder  optimize  client  behavior  like  myfaces3237  valueexpressions  return  empty  string  passthrough  property  rendered  necessary  create  new  optimized  method  render  property  let  old  api  intact,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6074,implement  hselectoneradio  group  distributed  radio  button  implement  hselectoneradio  group  distributed  radio  button,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6075,perf  minimize  externalcontextgetinitparameter  invocation  myfaces  api  initparam  webapp  context  cannot  change  sufficient  read  constructor  applicationimpl  example  new  problem  new  21  great  javaxfaceshonorcurrentcomponentattributes  param  pushcomponenttoel  popcomponentfromel  least  cache  component  push  pop  called  one  one  lifecycle  maybe  cache  value  also  orgapachemyfacescontextservletservletexternalcontextimplbasegetinitparameterstring  90  000  invocation  getinitpaparameter  test  case  one  requestresponse  cheap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6076,use  java8  instead  common  eg  base64  check  used  part  collection  emptyiterator  lrumap  collectionutilsfilter  predicate  coded  hex  could  replaced  javaxxmlbinddatatypeconverter  decoderexception  base64  digester  digester  x  beanutils  beanutils  x  propertyutils  x,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6077,removed  method  uicomponentbodytag  extends  uicomponenttag  bodytag,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
6078,perf  use  lazy  init  hashmaphastset  possible  goal  make  component  tree  creation  fast  possible  avoid  unnecessary  instance  component  instantialize  attribute  direct  field  constructor  many  case  necessary  hashmapset  instance  used  current  requestresponse  depends  use  case  example  uiviewrootlistenersuccessmap  lazy  init  suitable  many  view  phase  listener  check  component  candidate  smarter  component  like  uidate  uiinput,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6079,cleanup  uiinput  looking  shouldvalidateemptyfields  see  code  externalcontext  extctx  contextgetexternalcontext  string  validateemptyfields  string  extctxgetinitparametervalidateemptyfieldsparamname  validateemptyfields  null  validateemptyfields  string  extctxgetapplicationmapgetvalidateemptyfieldsparamname  cached  applicationmap  instead  always  parsing  webxml  getinitparam  actually  dont  see  put  stored  applcaitonmap  inside  validate  see  similar  code  string  contextparam  contextgetexternalcontextgetinitparameteremptyvaluesasnullparamname  cached  similar  externalspecifications  clazz  cache  maintained,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6080,allow  use  different  expressionfactory  implementation  possible  use  different  expressionfactory  implementation  feature  required  use  3rd  party  el  implementation  like  jboss  el  mojarra  already  support  comsunfacesexpressionfactory  context  parameter  myfaces  core  12x  already  support  context  parameter  orgapachemyfacesexpressionfactory  evaluated  jsp  20  environment  see  myfaces1693  detail  possible  use  parameter  jsp  21  well  corresponding  code  refactored  jsp20facesinitializer  abstractfacesinitializer  usable  jsp  20  21  discussion  myfacesusers  httpwwwnabblecomreplacingexpressionfactorytd18867420html,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,0
6081,processor  counter  included  status  report  would  allow  processor  status  history  show  counter  maintained  time  period  instead  single  count  since  system  start,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
6082,allow  convertcharacterset  accept  expression  language  issue  arose  user  mailing  list  demonstrates  need  able  use  expression  language  set  incoming  potentially  outgoing  character  set  im  looking  process  many  file  common  format  source  file  coming  various  character  set  mime  type  new  line  terminator  thinking  data  flow  along  line  getfile  many  sub  directory  executestreamcommand  file  convertcharacterset  previous  command  utf8  replacetext  change  rn  n  putfile  directory  structure  based  value  found  original  file  path  filename  additional  step  would  added  archiving  copy  original  converting  xml  file  etc  attempting  process  nifi  leaf  confused  process  within  tool  want  convertcharacterset  know  input  type  setup  executestreamcommand  file  absolutepathappendfilename  returned  expected  value  dont  see  way  turn  result  input  processor  doesnt  accept  expression  language  field  also  considered  convertcsvtoavro  interim  step  notice  issue  suggestion  dataflow  look  like,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6083,support  attributestojson  processor  add  standard  processor  creating  new  attribute  flowfile  json  representation  default  userdefined  list  attribute  flowfile  foo  bar  content  sometext  attributestojson  output  foo  bar  content  sometext  json  foo  bar  content  sometext,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6084,dfm  allowed  inspectinteract  flowfiles  connection  user  able  see  attribute  well  download  content  flowfiles  top  active  queue  additional  ticket  created  linked  searching  removing  uploading  flowfiles  given  queue,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6085,add  option  executestreamcommand  put  value  execution  attribute  issue  arose  user  mailing  list  demonstrates  need  able  put  output  executestreamcommand  attribute  im  looking  process  many  file  common  format  source  file  coming  various  character  set  mime  type  new  line  terminator  thinking  data  flow  along  line  getfile  many  sub  directory  executestreamcommand  file  convertcharacterset  previous  command  utf8  replacetext  change  rn  n  putfile  directory  structure  based  value  found  original  file  path  filename  additional  step  would  added  archiving  copy  original  converting  xml  file  etc  attempting  process  nifi  leaf  confused  process  within  tool  want  convertcharacterset  know  input  type  setup  executestreamcommand  file  absolutepathappendfilename  returned  expected  value  dont  see  way  turn  result  input  processor  doesnt  accept  expression  language  field  also  considered  convertcsvtoavro  interim  step  notice  issue  suggestion  dataflow  look  like  bryan  bendes  response  one  problem  flow  executestreamcommand  replace  content  flowfile  result  command  flowfile  encoding  value  longer  original  content,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6086,refactor  invokehttp  invokehttp  currently  us  java  httpurlconnection  lacking  feature  easeofuse  order  support  current  invokehttp  pending  ticket  clear  new  underlying  library  needed  okhttp  look  promising  library  focusing  individual  transaction  opposed  apache  httpclient  focus  session,0,0,0,0,0,0,1,0,1,1,1,0,0,0,0,0,0
6087,add  multipart  upload  support  puts3object  new  puts3objectmultipart  processor  using  aws  s3  api  upload  file  larger  supported  puts3object  5gb  limithttpdocsawsamazoncomamazons3latestdevuploadingobjectshtml  limit  support  s3  compatible  endpoint  also  add  endpoint  override  url  property  abstractawsprocessor  set  service  endpointhttpdocsawsamazoncomawsjavasdklatestjavadoccomamazonawsamazonwebserviceclienthtmlsetendpointjavalangstring  override  endpoint  url  normally  selected  based  amazon  region,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6088,tailfile  file  tail  property  support  wildcards  challenge  around  log  rotation  high  volume  syslog  app  producer  customary  logging  platform  developer  promote  file  variable  based  file  name  dynafiles  rsyslog  macrossyslogngas  alternative  getting  sighups  sent  syslog  daemon  upon  every  file  rotation  certain  extent  used  even  nifis  similar  pattern  like  example  one  us  expression  language  set  puthdfs  destination  file  current  tailfile  strategy  suggests  rotation  pattern  like  code  logfolderapplog  logfolderapplog1  logfolderapplog2  logfolderapplog3  code  possible  fool  system  accept  wildcards  simply  using  strategy  like  code  logfoldertest1  logfolderserver1  logfolderserver2  logfolderserver3  code  configure  rolling  filename  pattern  feel  like  hack  rather  catering  ever  increasingly  prevalent  use  case  dynafilemacrosetc  would  great  instead  tailfile  ability  use  wildcards  file  tail  property,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6089,create  put  hbase  processor  put  multiple  cell  recently  added  puthbasecell  processor  work  great  writing  one  individual  cell  time  require  significant  amount  work  flow  create  row  multiple  cell  support  variation  processor  accept  flow  file  keyvalue  pair  content  flow  file  possibly  json  keyvalue  pair  turned  cell  given  row  get  added  one  put  operation,1,0,1,0,1,0,0,0,1,0,1,1,1,0,0,0,0
6090,allow  user  configure  batch  size  sitetosite  currently  way  user  specify  batch  size  sitetosite  use  framework  decides  however  want  use  listfetch  pattern  helpful  specify  small  batch  size  small  number  thing  listed  still  well  distributed  across  cluster,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6091,listensyslog  support  tl  would  good  listensyslog  supported  tl  described  httpwwwrsyslogcomdocv8stabletutorialstlscertsummaryhtml  httpswwwbalabitcomsitesdefaultfilesdocumentssyslogngoselatestguidesensyslogngoseguideadminhtmlprocedureconfiguringtlsserverhtml,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6092,allow  replacetext  expression  language  function  access  matching  group  value  chanru  user  mailing  list  asked  wed  support  pretty  simple  use  case  converting  quote  col1col2col3  20061001200410may2004  20071505200610jun2005  200988200810aug2008  quote  quote  col1col2col3  20061001200420040510  20071505200620050610  200988200820080810  quote  today  surprising  effort  problem  replacetext  asis  get  u  sooo  close  cannot  convert  original  column  three  formatted  date  object  written  formatted  string  could  would  easy  example  extracted  column  matching  group  replacement  value  could  code  3todateddmmmyyyformatyyyymmddd  code  wed  set  right  way  take  third  matching  group  anything  fun  expression  language  subject  passed  el  function  could  applied  instead  simply  added  matching  group  keyssubjects  available  el  becomes  quite  powerful  tool,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0
6093,provide  additional  kdfs  encryptcontent  currently  two  key  derivation  function  kdf  supported  nifi  legacy  1000  iteration  md5  digest  password  optional  salt  openssl  pkcs5  v15  single  iteration  md5  digest  password  optional  salt  weak  use  deprecated  cryptographic  hash  function  chf  known  weakness  susceptibility  collision  demonstrated  attack  nonconfigurable  tightly  coupled  iteration  count  derive  key  iv  current  best  practice  kdfs  work  factor  recommendation  follows  pbkdf2  variable  hash  function  sha1  sha256  sha384  sha512  ideally  hmac  variant  function  variable  iteration  count  10k  1m  range  bcrypt  work  factor  12  16  scrypt  work  factor  214  220  8  1  salt  iteration  count  stored  alongside  hashed  record  bcrypt  handle  natively  note  httpwildlyinaccuratecombcryptchoosingaworkfactor  httpblogircmaxellcom201212sevenwaystoscrewupbcrypthtml  httpsecuritystackexchangecomquestions17207recommendedofroundsforbcrypt  httpsecuritystackexchangecomquestions3959recommendedofiterationswhenusingpkbdf2sha25639933993  httpsecuritystackexchangecomquestions4781doanysecurityexpertsrecommendbcryptforpasswordstorage6415  httpwebarchiveorgweb20130407190430httpchargenmatasanocomchargen200797enoughwiththerainbowtableswhatyouneedtoknowaboutshtml  httpswwwnccgrouptrustusaboutusnewsroomandeventsblog2015marchenoughwiththesaltsupdatesonsecurepasswordschemes  httpwwwtarsnapcomscrypthtml  httpwwwtarsnapcomscryptscryptpdf,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
6094,add  support  relp  listensyslog  add  support  listening  syslog  event  using  reliable  event  logging  protocol  relp  1  httpwwwrsyslogcomdocrelphtml,1,0,1,0,1,0,1,1,1,1,1,0,0,0,0,0,1
6095,kerberos  based  authentication  add  support  kerberos  based  authentication,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6096,add  processor  support  elasticsearch  request  add  processor  nifi  elasticsearch  following  capability  bulk  insert  flowfile  content  fetch  file  document  id  support  secure  cluster  shield  plugin  available,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1
6097,create  queryflowfile  processor  processor  allows  user  easily  filter  specific  column  csv  data  instance  user  would  configure  two  different  property  column  interest  commaseparated  list  column  index  filtering  strategy  keep  column  remove  column  today  replacetext  far  difficult  would  processor  user  use  regular  expression  etc  replacetext  eventually  custom  ui  could  even  built  allows  user  upload  sample  csv  choose  column  similar  way  excel  work  importing  csv  dragging  selecting  desired  column  would  certainly  larger  undertaking  would  need  done  initial  implementation,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,1,1
6098,add  capability  kafka  nar  use  new  kafka  api  09  sure  address  interesting  comment  httpsgithubcomapachenifipull143  usage  new  api  may  introduce  issue  running  older  kafka  broker  eg  08  need  investigate,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
6099,enhance  aws  s3  fetch  access  bucket  across  account  aws  s3  fetch  object  component  allow  access  bucket  across  account  aws  s3  fetch  object  enhanced  provide  functionality  using  assume  role  sessioncredentials,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6100,create  avro  schema  inferring  csv  json  data  several  situation  ability  dynamically  create  avro  schema  desired  kite  provides  ability  dynamically  infer  avro  schema  csv  json  data  since  nifi  already  contains  kite  bundle  converting  csv  json  avro  feature  easy  add  propose  2  new  processor  inferavroschemafromcsv  inferavroschemafromjson  processor  reside  inside  existing  nifikitebundle  extend  upon  already  present  third  party  library  processor  accept  either  csv  json  produce  output  avro  schema  json  original  data  presented  processor  rely  kite  perform  actually  inferring  schema,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6101,expose  contenttype  used  invokeposthttp  invokehttp  posthttp  make  use  mimetype  attribute  documentation  apparent  user  kind  applied  behind  scene  would  nice  property  brings  forefront  processor  configuration  show  mapped  el  mimetype,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6102,splunk  processor  continue  improving  nifis  ability  collect  log  good  integration  point  would  processor  could  listen  data  splunk  forwarder  httpsdocssplunkcomsplexiconuniversalforwarder  able  push  log  message  splunk  would  also  useful  splunk  provides  sdk  may  helpful  httpsgithubcomsplunksplunksdkjava,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6103,develop  bootstrap  module  need  module  parse  configuration  file  order  determine  runtime  parameter  run  java  executable  nifi  include  jvm  args  agentlib  xmx  xms  etc  well  indicating  nifi  property  file  found  java  command  java  v  javahomebinjava  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6104,add  scriptable  reportingtask  nifi210  add  scriptable  processor  scripted  ontrigger  body  great  extension  would  add  scriptable  reportingtask  would  enable  user  script  reportingtasks  using  various  supported  scripting  language,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,1,0
6105,refactor  lifecycle  code  processor  component  similar  lifecycle  handling  improvement  went  part  nifi1164  controllerservices  couldshould  applied  component  eg  processor  improvement  may  also  help  address  nifi78  may  without  killing  thread,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6106,add  kerberos  support  hbase  processor  current  hbase  integration  support  communicating  kerberized  hbase  install  support  like  hdfs  processor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6107,add  multipart  request  support  listenhttp  processor  current  listenhttp  processor  seem  support  multipart  request  encoded  multipartformdata  multipart  request  received  listenhttpservlet  copy  request  inputstream  flowfiles  content  leaf  form  encoding  wrapper  content  turn  make  file  invalid  specifically  want  able  support  file  uploads  multipart  request  see  thread  mailing  list  info  httpmailarchivesapacheorgmodmboxnifiusers201602mbox3c6de9ceef2a37480f8d3c5028c590fd9e40acesincnet3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6108,remove  storage  component  stats  bulletin  ncm  currently  node  cluster  sends  period  heartbeat  contains  stats  component  node  happens  every  5  second  default  result  quite  lot  chatter  ncm  node  made  sense  take  approach  clustering  concept  designed  process  group  notion  merging  response  node  web  request  however  replicate  request  node  merge  response  demand  rather  storing  information  ncm  requires  far  le  bandwidth  need  pull  stats  particular  process  group  demand  instead  every  5  second  additionally  laying  groundwork  zeromaster  clustering  want  place  100  order  remove  stats  ncm  also  need  remove  bulletin  stats  history  request  need  federated  response  merged  ondemand,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
6109,allow  user  specify  file  filter  regex  unpacking  ziptar  archive  time  may  want  extract  portion  archive  specific  folder  perhaps  specific  file  similar  getfile  processor  work  provide  property  file  filter  default  extract  file  user  modify  property  extract  file  wish  process  downstream,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6110,add  ability  query  db  table  using  last  value  column  would  useful  feature  processor  able  query  database  table  record  addedavailable  since  last  time  query  executed  example  processor  could  keep  max  value  timestamp  column  last  result  set  returned  next  time  query  issued  could  use  timestamp  value  column  return  record  whose  timestamps  greater  last  time  shouldnt  limited  timestamps  course  would  useful  strictlyincreasing  value  like  primary  key  id  would  user  select  table  column  processor  would  simply  keep  state  specified  column  max  value  proposed  querydbtable  processor  would  property  specify  table  name  column  table  keep  state  information  last  maximum  value  retrieved  subsequent  query  table  use  value  filter  row  whose  value  specified  column  greater  last  maximum  value  upon  successful  query  last  maximum  value  updated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6111,new  processor  update  attribute  state  idea  sparked  thread  user  list  allow  basic  data  science  expect  future  i’ll  need  something  little  sophisticated  problem  simple  want  able  trigger  alert  attribute  incoming  stream  instance  go  predefined  threshold  processor  trigger  another  trigger  signal  go  back  normal  threshold  basically  routebyattribute  memory  thanks  claudio  hello  claudio  usecase  actually  could  leverage  couple  recently  added  feature  create  really  cool  opensource  processor  two  key  feature  added  state  management  ability  reference  processor  specific  variable  expression  language  take  look  routetext  see  action  utilizing  create  processor  configured  multiple  expression  language  expression  would  dynamic  property  would  accept  expression  language  store  evaluated  value  via  state  management  would  routing  property  support  expression  language  could  simply  add  attribute  flowfile  evaluated  value  would  allow  used  flowing  processor  routing  would  allow  usecase  store  value  incoming  stream  route  differently  go  threshold  could  even  allow  complex  usecases  one  instance  believe  would  possible  running  average  standard  deviation  route  data  different  location  based  standard  deviation  think  like  updateattribute  ability  store  calculate  variable  using  expression  language  joe,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6112,listhdfs  retaining  wrong  state  zookeeper  expected  state  retained  listhdfs  processor  last  modified  timestamp  processor  instead  retaining  filename  path  every  file  list  result  excessive  disk  usage  zookeeper  retain  filename  based  state,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6113,create  putudp  processor  create  processor  send  flowfile  datagram  udp  server  processor  must  provide  property  allow  user  configure  destination  host  address  port  send,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6114,improve  expression  language  enable  working  decimal  currently  math  operation  expression  language  use  longs  evaluate  number  lead  decimal  place  getting  truncated  performing  operation  like  divide  nifi  support  working  decimal,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
6115,add  support  orc  format  hiveorc  wiki  httpscwikiapacheorgconfluencedisplayhivelanguagemanualorc  optimized  row  columnar  orc  file  format  provides  highly  efficient  way  store  hive  data  using  orc  file  improves  performance  hive  reading  writing  processing  data  user  interested  nifi  integration  hive  nifi981  nifi1193  etc  nifi  able  support  orc  file  format  enable  user  efficiently  store  flow  file  use  hive,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6116,improve  provenance  event  emitted  putkafka  provenance  send  event  emitted  putkafka  include  amount  time  took  send  data  also  message  sent  using  delimiter  send  event  indicates  number  event  sent  transit  uri  also  include  kafka  protocol  name  beginning  include  topic  kafkaleaderbroker9092topicstopicdatawasplacedon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6117,node  cluster  use  zookeeper  store  heartbeat  message  instead  sending  ncm  currently  node  send  heartbeat  ncm  periodically  order  indicate  actively  participating  cluster  move  away  using  ncm  need  heartbeat  go  somewhere  else  zookeeper  reasonable  location  push  heartbeat  provides  ha  need,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
6118,extend  querydatabasetable  support  arbitrary  query  querydatabasetable  able  observe  configured  database  table  new  row  yield  flowfile  model  rdbms  however  often  always  normalized  would  need  join  various  table  order  flatten  data  useful  event  processing  pipeline  build  nifi  various  tool  within  hadoop  ecosystem  request  extend  processor  specify  arbitrary  sql  query  instead  specifying  table  name  column  addition  may  another  issue  desired  limit  number  row  returned  per  run  bandwidth  issue  nifi  pipeline  onwards  mainly  huge  database  may  able  return  many  record  within  reasonable  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6119,update  http  processor  allow  proxy  authentication  strategy  trying  use  http  processor  behind  proxy  server  following  error  occurs  received  error  httperror  http11  407  proxy  authentication  required  attempt  reconnect  library  nifi  us  http  processor  ability  set  proxy  authentication  strategy  currently  doesnt  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6120,simplify  revision  management  happens  standardnifiservicefacade  currently  standardnifiservicefacade  huge  amount  repetitive  code  ensure  change  flow  occur  always  appropriate  revision  revision  updated  appropriately  however  tedious  prone  copypaste  error  requires  updating  code  many  place  something  change  nifi  10  depending  java  8  make  use  java  lambda  function  order  dramatically  simplify  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6121,create  fetchhbase  processor  provide  processor  fetch  row  hbase  processor  support  receiving  incoming  flowfile  taking  row  id  fetch  attribute  incoming  also  able  fetch  static  row  id,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6122,create  general  mqtt  processor  mqtt1  great  internet  thing  iot  connectivity  protocol  implementing  processor  would  allow  nifi  continue  expanding  iot  domain  prime  opportunity  would  use  conjunction  apache  nifi  minifi  1  httpmqttorg,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6123,add  nifienv  script  nifienv  script  created  use  nifi  startup  status  shutdown  script  set  env  variable  like  javahome  location  log  dir  location  pid  dir  etc  make  easier  manage  location  single  script  example  currently  path  java  set  bootstrapconf  however  system  javahome  set  java  path  nifi  start  command  fails  user  explicitly  set  javahome  path  invoking  nifi  start,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6124,allow  concurrent  execution  executescript  currently  executescript  annotated  triggerserially  meaning  one  task  running  time  cause  issue  throughput  become  severe  bottleneck  flow  originally  done  binding  session  context  etc  put  single  script  engine  multiple  task  would  clobber  others  binding  however  tradeoff  memory  capability  would  better  pool  script  engine  instance  whose  size  perhaps  max  number  concurrent  task,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1
6125,allow  encrypted  password  configuration  file  storing  password  plaintext  configuration  file  security  best  practice  file  access  restricted  o  permission  configuration  file  accidentally  checked  source  control  shared  deployed  multiple  instance  etc  nifi  allow  deployer  provide  encrypted  password  configuration  file  minimize  exposure  password  application  startup  nifi  decrypt  password  memory  nifi  also  include  utility  encrypt  raw  password  optionally  populate  configuration  file  provide  additional  metadata  configuration  file  aware  simply  shift  responsibilitydelegation  trust  password  property  file  new  location  system  mitigating  visibility  raw  password  property  file  one  step  defense  depth  approach  often  mandated  security  policy  within  organization  using  nifi  key  used  encryption  hardcoded  application  source  code  universally  consistent  key  could  determined  reading  static  information  deployed  system  feeding  key  derivation  function  based  cryptographicallysecure  hash  function  pbkdf2  bcrypt  scrypt  however  introduce  upgrade  system  migration  portability  issue  challenge  kept  consideration  determining  key  derivation  process  manual  key  entry  possibility  master  key  would  present  memory  prevents  automatic  reboot  loss  power  recovery  scenario  must  backwardcompatible  allow  system  plaintext  password  continue  operating  option  achieving  attempt  decrypt  password  sibling  property  present  match  specific  format  example  used  following  default  value  code  password  thisisabadpassword  key  0123456789abcdeffedcba98765432100123456789abcdeffedcba9876543210  iv  0123456789abcdeffedcba9876543210  algorithm  aescbc  256bit  code  note  value  used  production  system  key  iv  common  test  value  aead  cipher  preferable  provide  cipher  text  integrity  assurance  however  openssl  support  use  aead  cipher  commandline  encryption  time  example  1  sibling  property  indicates  password  encrypted  implementation  absence  property  would  default  raw  password  code  hw12203usersaloprestoworkspacescratchencryptedpasswords  master  alopresto  🔓  0  162556  echo  thisisabadpassword  passwordtxt  hw12203usersaloprestoworkspacescratchencryptedpasswords  master  alopresto  🔓  0  162647  ossl  aes256cbc  e  nosalt  p  k  0123456789abcdeffedcba98765432100123456789abcdeffedcba9876543210  iv  0123456789abcdeffedcba9876543210  passwordtxt  passwordenc  key0123456789abcdeffedcba98765432100123456789abcdeffedcba9876543210  iv  0123456789abcdeffedcba9876543210  hw12203usersaloprestoworkspacescratchencryptedpasswords  master  alopresto  🔓  0  162709  xxd  passwordenc  0000000  5643  5856  6146  6250  4158  364f  5743  7646  vcxvafbpax6owcvf  0000010  6963  6b76  4a63  7744  3854  6b67  3731  4c76  ickvjcwd8tkg71lv  0000020  4d38  6d32  7952  4776  5739  413d  0a  m8m2yrgvw9a  hw12203usersaloprestoworkspacescratchencryptedpasswords  master  alopresto  🔓  0  162716  passwordenc  vcxvafbpax6owcvfickvjcwd8tkg71lvm8m2yrgvw9a  hw12203usersaloprestoworkspacescratchencryptedpasswords  master  alopresto  🔓  0  162755  code  nifiproperties  code  nifisecuritykeystorepasswdvcxvafbpax6owcvfickvjcwd8tkg71lvm8m2yrgvw9a  nifisecuritykeystorepasswdencryptedaescbc256  code  example  2  encrypted  password  header  tag  indicating  encrypted  algorithm  used  codejava  test  public  void  testshoulddecryptpassword  throw  exception  arrange  keyedcipherprovider  cipherprovider  new  aeskeyedcipherprovider  final  string  plaintext  thisisabadpassword  loggerinfoexpected  hexencodehexstringplaintextbytes  final  byte  iv  hexdecodehex0123456789abcdeffedcba9876543210  char  final  byte  localkey  hexdecodehex0123456789abcdeffedcba9876543210  2  char  generated  via  openssl  enc  final  string  ciphertext  vcxvafbpax6owcvfickvjcwd8tkg71lvm8m2yrgvw9a  byte  cipherbytes  base64decoderdecodeciphertext  secretkey  localkey  new  secretkeyspeclocalkey  aes  encryptionmethod  encryptionmethod  encryptionmethodaescbc  loggerinfousing  algorithm  encryptionmethodgetalgorithm  loggerinfocipher  text  nifipwciphertext  cipherbyteslength  8  act  cipher  cipher  cipherprovidergetcipherencryptionmethod  localkey  iv  false  byte  recoveredbytes  cipherdofinalcipherbytes  openssl  add  newline  character  encryption  string  recovered  new  stringrecoveredbytes  utf8trim  loggerinforecovered  recovered  hexencodehexstringrecoveredbytes  assert  assert  plaintextequalsrecovered  code  nifiproperties  code  nifisecuritykeystorepasswdnifipwvcxvafbpax6owcvfickvjcwd8tkg71lvm8m2yrgvw9a  code  ideally  nifi  would  use  pluggable  implementation  architecture  allow  user  integrate  variety  secret  management  service  commercial  open  source  solution  including  cyberark  enterprise  password  vault  1  hashicorp  vault  2  square  keywhiz  3  future  could  also  extended  hardware  security  module  hsm  like  safenet  luna  4  amazon  cloudhsm  5  1  httpwwwcyberarkcomproductsprivilegedaccountsecuritysolutionenterprisepasswordvault  2  httpswwwvaultprojectio  3  httpssquaregithubiokeywhiz  4  httpwwwsafenetinccomdataencryptionhardwaresecuritymoduleshsmslunahsmskeymanagementlunasanetworkhsm  5  httpsawsamazoncomcloudhsm,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6126,add  support  azure  blob  storage  table  storage  would  useful  azure  equivalent  current  s3  capability  azure  also  provides  table  storage  mechanism  providing  simple  key  value  storage  since  azure  sdks  apache  licensed  reasonably  straightforward  first  cut  available  addition  existing  azure  bundle,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0
6127,create  puttcp  processor  create  puttcp  processor  send  flowfile  content  tcp  connection  tcp  server,1,1,1,0,1,1,0,0,1,0,1,0,0,0,0,0,0
6128,jsontojson  schema  converter  editor  nifi361  implemented  user  embed  jolt  spec  transformjson  processor  however  building  spec  intuitive  enough  without  ability  obtain  real  time  feedback  spec  syntax  preview  output  data  would  like  specification  editor  transform  preview  view  added  processor  configuration  screen  allow  user  immediately  see  impact  output  json  data,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,1,1
6129,support  http  transport  mechanism  sitetosite  add  support  using  http  sitetosite  alternative  current  socket  based  approach  would  support  push  based  pull  based  approach  sitetosite  offer  would  use  http  interaction  include  learning  port  learning  ncm  topology  actually  exchanging  data  mechanism  also  support  interaction  via  http  proxy  would  also  require  ui  work  allow  user  specify  protocol  sitetosite  use  raw  v  http  also  need  document  limitation  regard  ssl  support  mode  wed  need  provide  howto  using  proxy  like  httpproxy  something  else,1,1,1,1,1,1,0,1,1,1,1,1,1,0,0,0,0
6130,add  support  hive  streaming  traditionally  adding  new  data  hive  requires  gathering  large  amount  data  onto  hdfs  periodically  adding  new  partition  essentially  “batch  insertion”  insertion  new  data  existing  partition  permitted  hive  streaming  api  allows  data  pumped  continuously  hive  incoming  data  continuously  committed  small  batch  record  existing  hive  partition  table  data  committed  becomes  immediately  visible  hive  query  initiated  subsequently  case  add  puthivestreaming  processor  nifi  leverage  hive  streaming  api  allow  continuous  streaming  data  hive  partitiontable,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
6131,autoadjust  template  layout  upon  placement  canvas  position  component  template  created  pre100  version  nifi  need  positionally  rescaled  due  ui  change  described  nifi1799  new  template  created  nifi  version  100  need  include  template  encoding  version  get  updated  template  dto  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6132,support  custom  property  expression  language  add  property  nifiproperties  config  file  allows  user  specify  list  custom  property  file  containing  data  environmental  specific  value  sensitive  value  etc  keyvalue  pair  loaded  upon  nifi  startup  availbale  processor  use  expression  language  optimally  lay  groundwork  ui  driven  variable  registry,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6133,enhance  jolttransformjson  processor  support  custom  transforms  jolt  support  additional  custom  transforms  via  fullyqualified  java  classnames  would  like  provide  ability  support  custom  transformation  via  drop  jar  jolt  transform  processor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6134,add  elasticsearch  processor  use  rest  api  current  elasticsearch  processor  use  transport  client  result  compatibility  issue  multiple  version  e  cluster  rest  api  much  standard  version  would  nice  e  processor  use  rest  api  enable  thing  like  migration  elasticsearch  cluster  older  version  cluster  newer  version,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0
6135,support  processor  implementation  across  several  programming  language  also  support  clojure  per  discussion  request  mailing  list  httpmailarchivesapacheorgmodmboxnifidev201506mbox3ccampsqch4gk1gnw6m1u8th6an8emixzn5snkaemjbujxygqjiw40mailgmailcom3e  update  scriptengine  clojure  maintained  currently  available  via  maven  central  public  repository  recommend  adding  clojure  separate  improvement  jira  case  update  scala  support  proved  buggy  using  plain  script  engine  need  much  analysisreviewtesting  inclusion,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6136,cache  compiled  xslt  transformxml  transformxml  appears  recompiling  xslt  every  ontrigger  event  slow  cache  compiled  stylesheets,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6137,improve  routetext  performance  precompilation  regex  certain  case  using  regex  match  routetext  processor  possibly  processor  regex  get  recompiled  every  time  processor  work  regex  could  precompiled  cached  certain  condition  order  improve  performance  processor  see  email  mark  payne  2  regular  expression  compiled  every  time  done  though  regex  allows  expression  language  used  regex  could  actually  different  flowfile  said  could  certainly  improved  either  precompiling  case  expression  language  used  andor  b  cache  say  10  regexes  compiled,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6138,move  controller  level  bulletin  controller  status  controller  level  bulletin  need  removed  controller  status  endpoint  endpoint  accessed  controller  resource  authorization  consistency  status  request  authorized  flow  bulletin  sensitive,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6139,convert  azure  event  hub  processor  use  correct  azure  event  hub  client  library  currently  nifi  us  event  hub  client  found  httpsgithubcomhdinsighteventhubsclient  however  use  client  library  found  httpsgithubcomazureazureeventhubstreemasterjava  azure  event  hub  client  target  jdk  18  therefore  resolution  jira  applicable  nifi  100  later,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6140,provide  way  processor  determine  running  nifi  node  type  standaloneclustered  primarynode  currently  there  way  processor  understand  running  standalone  cluster  cluster  primary  node  therere  processor  need  information  provide  cluster  friendly  behavior  monitoractivity  onprimarynodestatechange  annotation  already  available  however  notified  primary  node  changed  processor  added  existing  nifi  cluster  already  one  node  elected  primary  node  processor  notified  thus  wont  able  know  primary  node  ticket  meant  tracking  effort  adding  capability  provide  node  type  information,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
6141,mock  framework  need  allow  testrunnerrun  indicate  whether  call  onscheduled  method  currently  time  testrunnerrun  called  method  processor  onscheduled  annotation  get  called  cannot  avoided  cause  lot  problem  case  though  need  able  call  testrunnerrun  without  invoking  onscheduled  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6142,add  support  ldaps  authentication  provider  mcgilman  alopresto  please  add  thought  propose  add  support  ldaps  despite  starttls  preferred  approach  offer  flexibility  use  many  long  standing  ldap  environment,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6143,bump  tika  dependency  version  nifimedianar,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6144,update  usage  deprecated  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6145,decouple  usersuser  group  policy  currently  user  user  group  policy  persisted  file  policy  associated  particular  nifi  instance  make  file  portable  however  user  user  group  configuration  completely  independent  particular  instance  persisted  separate  file  promote  portable  configuration  nifi  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6146,new  processor  getignitecache  getting  value  apache  ignite  new  component  getting  value  ignite  cache,1,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0
6147,sslcontextservice  support  specifying  key  password  currently  sslcontextservice  support  keystore  password  assumes  key  password  support  setting  separate  password  key,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6148,testrunner  expose  variableregistry  construct  currently  testrunners  class  provides  mechanism  creating  testrunner  take  variable  registry  concept  providing  variable  test  runner  valuable  however  notion  variableregistry  internal  implementation  detail  getting  exposed  creating  leaky  abstraction  remove  override  createtestrunner  method  take  variable  registry  instead  expose  set  method  testrunner  void  setvariablestring  name  string  value  string  getvariablestring  name  void  setvariablesmapstring  string  variable  mapstring  string  getvariables  additionally  asis  variableregistry  provided  default  use  variable  registry  provides  system  environment  variable  avoided  encourages  unit  test  depend  environmentspecific  setting,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6149,allow  configuration  controller  service  reporting  task  ui  currently  controller  service  reporting  task  specified  configuration  file  nifi  installed  need  make  configuration  accessible  moving  ui  requiring  restart  application,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6150,querydatabasetable  support  splitting  resultset  multiple  flow  file  new  property  default  disabled  allow  resultsets  split  multiple  output  flow  file,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6151,add  attribute  track  flow  file  came  receiving  sitetosite  minifi  starting  used  send  data  central  nifi  would  helpful  information  sending  host  port  added  flow  file  received  sitetosite  currently  information  available  used  generate  transit  uri  receive  event  information  isnt  available  downstream  processor  might  want  make  routing  decision  reference  httpsgithubcomapachenifiblobe23b2356172e128086585fe2c425523c3628d0e7nifinarbundlesnififrameworkbundlenififrameworknifisitetositesrcmainjavaorgapachenifiremoteprotocolabstractflowfileserverprotocoljaval452  possible  approach  might  add  two  attribute  flow  file  something  like  remotehost  remoteaddress  remotehost  sending  hostname  remoteaddress  sending  host  port,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6152,add  ability  write  row  identifier  binary  hbase  using  puthbasecell  today  puthbasecell  processor  make  assumption  row  key  text  however  work  row  key  hbase  table  binary  row  key  specified  binary  string  format  x00x00x00x00x00x00x00x00x00x00x  00x00x00x00x00x00x00x00x00x00x00  x00x00x00x00x00x00x00x00x00x00x  00x00x00x00x00x00x00x00x00x00x00  x00x00x00x00x00x00x00x00x00x00x  00x00x00x00x00x00x00x00x00x00x00  x01x00x00x00x00x00x00x00x00x00x  00x00x00x00x00x00x00x00x00x00x00  x00x00x00x00x00x00x00x01x01x00x  00x00x00x00x00x00x00x00x00x00x00  x00x00x00x00x00x00x00x00x00x00x  00x00x00x00x00x00x01x00x00x01x00  x00x00x00x00x00x00x00x00x00x00x  00x00x01x00x00x01x00x00x00x00x01  x01x01x00x01x00x01x01x01x00x00x  00x00x00x00x01x01x01x01x00x00x00  x00x00x00x01x01x00x01x00x01x00x  00x01x01x01x01x00x00x01x01x01x00  x01x00x00  textual  representation  hbase  cli  would  return  nifi  call  getbytes  string  appropriately  hbase  encode  hex  code  x5c  resulting  output  string  look  like  x5cx00x5cx00  address  proposed  solution  would  add  tobytesbinary  method  hbaseclientservice  similar  one  already  added  1  update  putflowfile  putcolumn  pas  around  mostly  byte  string  today  jira  support  text  binary  added  rowkey  1  httpsgithubcomapachenifiblobmasternifinarbundlesnifistandardservicesnifihbase112clientservicebundlenifihbase112clientservicesrcmainjavaorgapachenifihbasehbase112clientservicejaval427,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
6153,jdbctoavro  processor  handle  bigdecimals  string  original  sql  processor  implemented  bigdecimal  value  string  avro  version  avro  used  176  support  decimal  type  avro  177  avro1402  type  supported  sql  hiveql  processor  updated  handle  bigdecimals  correctly  possible  updated  jira  improved  executesql  querydatabasetable  processor  selecthiveql  removed  target  hive  table  queried  executesqlquerydatabasetable  nifi3093  resolved  logical  type  also  supported  processor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6154,allow  publishjms  processor  create  textmessages  create  new  configuration  option  publishjms  allows  processor  configured  emit  instance  textmessages  well  bytesmessage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6155,lists3  improvement  use  version  commit  mode  team  need  able  list  individual  version  s3  also  ran  use  case  bucket  many  object  1  million  case  seemed  cause  lists3  run  forever  s3  list  command  finished  minute  believe  taking  long  time  nifi  commit  flow  file  handle  use  case  added  commit  mode  property  lists3  allows  specify  want  commit  per  page  v  proven  correctly  emit  flow  file  s3  paging  progress  also  implemented  support  s3  list  version  includes  s3version  s3islatest  attribute  applicable  s3version  attribute  turn  used  fetchs3  processor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6156,create  enrichment  processor  supporting  geolite  asn  current  enrichgeoip  support  maxminds  geolite  asn  api  database  would  great  processor  capable,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
6157,add  jms  property  flowfile  attribute  receive  consumejms  consumejms  currently  add  jms  header  flowfile  attribute  receives  message  ignores  jms  property  coming  reading  header  property  merging  flowfile  attribute,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6158,great  typo  cleanup,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6159,tlstoolkit  standalone  allow  dn  specification  running  tlstoolkit  standalone  mode  user  able  specify  dn  nifi  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6160,provide  ability  flowfile  migrated  one  process  session  another  currently  mergecontent  processor  creates  separate  processsession  flowfile  pull  done  ensure  commit  process  session  bin  full  unfortunately  mean  mergecontent  required  call  processsessionget  many  time  add  lot  contention  flowfile  queue  allow  flowfiles  migrated  1  session  another  session  per  bin  use  processsessionget100  greatly  reduce  lock  contention  likely  benefit  processor  well,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,0
6161,improve  performance  splittext  splittext  fairly  cpuintensive  quite  slow  simple  flow  split  14  million  line  text  file  5k  line  chunk  split  5k  line  chunk  1  line  chunk  capable  pushing  10k  line  per  second  equates  10  mbsec  jvisualvm  show  majority  time  spent  locatesplitpoint  method  isolating  code  inspecting  work  using  microbenchmarking  appears  refactor  call  inputstreamread  instead  read  byte  array  improve  performance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6162,enable  repository  support  upgrade  rollback  well  defined  scenario  flowfile  swapfile  provenance  content  repository  play  important  roll  nifis  ability  safely  upgraded  rolled  back  need  well  documented  behavior  design  version  adherence  user  safely  rely  mechanism  formalized  place  update  versioning  guidance  reflect  well  following  would  true  nifi  120  onward  change  repository  persisted  disk  made  break  forwardbackward  compatibility  specifically  mean  thing  like  way  serialized  disk  cannot  change  change  made  impact  forward  backward  compatibility  reserved  major  release  include  utility  help  user  preexisting  data  convert  older  format  newer  format  may  feasible  rollback  major  release  content  repository  changed  within  major  release  cycle  way  harm  forward  backward  compatibility  flow  file  repository  change  new  field  added  existing  write  ahead  log  record  type  field  removed  new  type  added  field  considered  required  must  remain  required  change  may  made  across  minor  version  change  incremental  swap  file  storage  follow  similar  rule  flow  file  repository  adding  schema  swap  file  header  may  allow  variation  variation  hint  optimize  theyre  processed  change  behavior  otherwise  change  permitted  minor  version  release  provenance  repository  change  permitted  minor  version  release  change  may  include  adding  removing  field  existing  event  type  field  considered  required  must  always  considered  required  field  removed  must  required  field  must  sensible  default  older  version  could  use  value  found  new  data  rolled  back  new  event  type  may  added  field  event  type  known  older  version  seen  rollback  simply  ignored  following  also  would  true  apache  nifi  100  repository  work  fine  applied  apache  nifi  110  installation  repository  madeupdated  apache  nifi  110  onward  would  work  older  apache  nifi  release  100,1,1,1,0,1,1,0,1,1,0,1,1,1,0,0,0,1
6163,nifi  sitetosite  port  forwarding  would  useful  able  use  port  forwarding  nifi  sitetosite  would  allow  nifi  appear  externally  listening  privileged  port  without  granted  elevated  permission  example  administrator  could  configure  iptables  forward  traffic  port  443  port  9443  user  could  use  nifi  port  443  provides  flexibility  far  firewall  configuration  concerned  scenario  cause  problem  sitetosite  though  clustered  scenario  node  still  advertise  port  9443  would  prevent  sitetosite  client  able  talk  outside  firewall  need  way  probably  nifi  property  tell  nifi  listen  one  port  9443  advertise  another  443  sitetosite  purpose  enable  usecase,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6164,refactor  textlinedemarcator  streamdemarcator  common  abstract  class  based  work  performed  part  nifi2851  new  class  significantly  faster  logic  perform  demarcation  inputstream  textlinedemarcator  new  class  initial  starting  point  existing  linedemarcator  share  6070  common  code  would  important  extract  common  abstract  class  well  incorporate  new  faster  demarcation  logic  int  streamdemarcator,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,1
6165,provide  framework  mechanism  loading  additional  classpath  resource  currently  several  component  property  specifying  additional  classpath  resource  dbcp  connection  pool  scripting  processor  jms  component  responsible  handling  way  framework  provide  integrated  solution  make  easier  component  developer  deal  scenario  requirement  need  met  solution  multiple  instance  component  different  resource  added  classpath  interfering  ie  two  dbcp  connection  pool  using  different  driver  ability  modify  actual  classloader  component  deal  framework  use  classforname  without  passing  classloader  meaning  processor  load  class  class  call  classfornameclassbname  class  b  need  available  classloader  loaded  processor  class  turn  loaded  class  component  developer  able  indicate  given  propertydescriptor  represents  classpath  resource  framework  take  care  classloader  manipulation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6166,remote  inputoutput  port  local  process  group  treated  completely  different  component  addition  multitenancy  user  restrict  user  particular  process  group  user  cannot  create  input  output  port  root  canvas  user  able  create  remote  inputoutput  port  within  process  group  assign  s2s  policy  thing  need  admin  add  server  user  add  global  retrieve  sitetosite  detail  policy  allows  better  separation  dataflow  designerimplementordfm  nifi  admin  added  benefit  treating  remote  local  inputoutput  port  unique  component  could  add  anywhere  flow  including  imbedded  within  process  group  perhaps  making  configurable  local  remote  port  defaulting  remote  added  root  canvas  local  added  within  process  group  way  preserve  backwards  compatibility  still  improving  usability  multitenancy  environment,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,1,1
6167,tlstoolkit  allow  user  specify  separate  input  output  location  client  configuration  setting  currently  using  tlstoolkit  generate  client  certificate  artifact  keystoretruststore  etc  user  option  provide  location  configuration  file  provide  information  necessary  create  item  using  f  argument  another  option  used  allow  toolkit  write  setting  generated  back  indicated  input  file  using  f  argument  scenario  user  may  want  pipe  input  using  stdin  v  referring  file  disk  optimal  since  toolkit  attempt  write  stdin  causing  error  prevent  error  proposing  f  argument  also  support  output  location  separate  location  provided  f  argument,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6168,bouncycastle  dependency  duplicated  throughout  nars  working  nifi  dependency  incorporation  withuse  minifi  saw  several  library  duplicated  throughout  nars  note  bouncycastle  dependency  together  4mb  size  code  apiri  computer  usrlocaloptnifilibexec  172023  find  libwork  type  f  name  bcprovjdk15on  wc  l  54  apiri  computer  usrlocaloptnifilibexec  172028  find  libwork  type  f  name  bcpkix  wc  l  53  apiri  computer  usrlocaloptnifilibexec  172033  l  lash  worknarframeworknififrameworknar100narunpackedmetainfbundleddependenciesbcprovjdk15on154jar  32m  rwrr  1  apiri  admin  32m  oct  4  1224  worknarframeworknififrameworknar100narunpackedmetainfbundleddependenciesbcprovjdk15on154jar  apiri  computer  usrlocaloptnifilibexec  172039  l  lash  worknarframeworknififrameworknar100narunpackedmetainfbundleddependenciesbcpkixjdk15on154jar  660k  rwrr  1  apiri  admin  658k  oct  4  1224  worknarframeworknififrameworknar100narunpackedmetainfbundleddependenciesbcpkixjdk15on154jar  code,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6169,add  pgp  gpg  support  encryptcontent  processor,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6170,add  expression  language  support  jolttransformjson  processor  provide  ability  incorporate  expression  language  within  jolt  specification  certain  operation  dynamic  creation  keyvalue  pair  achieved,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6171,ldap  support  configurable  user  identity  current  ldap  provider  support  configurable  search  filter  allow  user  specified  login  name  matched  ldap  entry  attribute  offer  configuration  option  indicate  use  ldap  entry  dn  use  login  name  used  search  filter  instance  would  allow  admin  configure  user  login  samaccountname  subsequently  use  name  user  identity  note  default  option  user  dn  order  ensure  backwards  compatibility,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6172,encrypted  configuration  migrator  able  update  sensitive  property  key  migrate  flowxmlgz  order  allow  changing  nifisensitivepropskey  updating  flowxmlgz  configencryptiontool  able  accept  new  value  field  update  encrypted  value  flowxmlgz  appropriately,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6173,s2s  initial  connection  behavior  enhancement  s2s  client  behavior  initial  connection  improvement  needed  current  experience  client  eg  minifi  connect  nifi  cluster  eg  10  node  need  specify  1  node  url  establish  connection  node  may  available  100  go  case  initial  connection  wont  work  s2s  make  first  connection  list  node  check  status  first  connection  failure  would  concern  specified  url  somehow  working  usually  problem  client  able  specify  multiple  url  according  multiple  target  cluster  node  commaseparated,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
6174,refactor  base  class  mergecontent  binning  logic  mergecontent  extremely  useful  could  pulled  abstract  superclass  would  allow  processor  perform  binning  logic  without  tied  merged  flow  file  example  processor  may  want  submit  batch  request  database  like  solr  rest  endpoint  vast  majority  code  mergecontent  would  remain  concrete  class  several  point  binmanager  usage  could  abstracted  easy  extensibility,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,1
6175,restrict  dangerous  processor  special  permission  evidenced  nifi3045  discovery  eg  using  executescript  processor  iterate  nifiproperties  instance  application  already  decrypted  sensitive  property  nifiproperties  file  disk  using  getfile  processor  retrieve  etcpasswd  etc  nifi  powerful  tool  allow  unauthorized  user  perform  malicious  action  tool  versatile  nifi  ever  completely  immune  insider  threat  restrict  potential  abuse  certain  processor  designated  restricted  processor  added  canvas  modified  user  along  proper  permission  modify  canvas  special  permission  interact  dangerous  processor  security  feature  roadmaphttpscwikiapacheorgconfluencedisplaynifisecurityfeatureroadmap  quote  dangerous  processor  processor  directly  affect  behaviorconfiguration  nifiother  service  getfile  putfile  listfile  fetchfile  executescript  invokescriptedprocessor  executeprocess  executestreamcommand  processor  creatableeditable  user  special  access  control  policy  marked  restricted  annotation  processor  class  flowfiles  originatingpassing  processor  special  attributeprotection  perhaps  file  processor  access  certain  location  default  cannot  access  root  filesystem  without  special  user  permission  quote  mcgilman  pr  tomorrow,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6176,consider  deprecating  orgapachenifistreamiobytearrayoutputstream  favor  javaiobytearrayoutputstream  believe  efficiency  statement  need  revisited  example  preliminary  testing  show  performance  difference  using  one  provided  javaio,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6177,remove  jasypt  library  jasypthttpwwwjasyptorgindexhtml  library  used  internally  nifi  string  encryption  operation  specifically  passwordbased  encryption  pbe  encryptcontent  sensitive  processor  property  protection  feel  number  reason  remove  library  nifi  provide  centralized  symmetric  encryption  operation  using  java  cryptographic  primitive  bouncycastle  feature  necessary  library  last  updated  february  25  2014  comparison  bouncycastle  updated  5  timeshttpswwwbouncycastleorgreleasenoteshtml  since  standardpbestringencryptor  highlevel  class  wrapped  nifis  stringencryptor  final  make  feature  relying  difficult  test  isolation  jasypt  encapsulates  many  decision  cipher  configuration  specifically  saltgeneration  strategy  valuable  feature  pluggable  library  le  ideal  dealing  encryption  key  derivation  constant  struggle  evolving  attack  improving  hardware  hardcoded  constant  compatible  better  decision  available  ie  requiring  custom  implementation  saltgenerator  interface  provide  new  derivation  existence  value  opaque  nifi  led  serious  compatibility  issue  nifi1259  nifi1257  nifi1242  nifi1463  nifi1465  nifi3024  stringencryptor  nifi  class  wrapping  standardpbestringencryptor  also  final  expose  method  instantiate  relevant  value  ie  algorithm  provider  password  rather  requires  entire  nifiproperties  instance  stringencryptorcreateencryptor  performs  unnecessary  validation  check  instantiation  one  cause  reported  issue  secure  nodecluster  block  startup  vms  due  lack  entropy  devrandom  use  custom  salt  pbe  mean  internal  cipher  object  must  recreated  initialized  key  rederived  password  every  decryption  call  symmetric  keyed  encryption  strong  kdf  order  magnitude  higher  iteration  stronger  algorithm  unique  initialization  vector  iv  value  would  substantially  resistant  brute  force  attack  yet  performant  scale  already  implemented  backwardscompatible  code  perform  action  symmetric  key  encryption  using  key  derived  password  configencryptiontool  opensslpkcs5cipherprovider  nifilegacycipherprovider  class  empirical  test  confirm  compatible  jasypt  output  additional  research  underlyingrelated  issue  java  allow  aes256  bit  encryption  system  without  jce  unlimited  strength  policy  using  pbehttpssecuritystackexchangecomquestions107321whydoesjavaallowaes256bitencryptiononsystemswithoutjceunlimitedstre  decrypt  opensslencrypted  data  apache  nifihttpscommunityhortonworkscomarticles5319howtodecryptopensslencrypteddatainapachenihtml  devnifiapacheorg  password  encryptcontenthttpslistsapacheorgthreadhtmlb93ced98eff6a77dd0a2a2f0b5785ef42a3b02de2cee5c17607a8c493cdevnifiapacheorg3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6178,add  support  exporting  lineage  graph  svg,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
6179,add  method  distributedmapcacheclient  replace  existing  key  hasnt  changed  would  helpful  processor  able  get  list  key  distributed  map  cache  match  pattern  even  get  list  key  update  distributedmapcacheclient  method  like  getkeysstring  pattern  replace  existing  key  distributed  map  cache  concurrency  control  key  replaced  hasnt  updated  operation  since  updating  client  program  fetched  key  updated  jira  description  mentioned  nifi3216httpsissuesapacheorgjirabrowsenifi3216focusedcommentid15812535pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment15812535,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6180,add  ability  wait  n  signal  waitnotify  processor  recently  added  wait  notify  processor  allow  flow  file  held  wait  processor  signal  received  notify  processor  would  nice  able  wait  n  signal  releasing  one  way  could  done  property  like  signal  count  wait  processor  count  key  cache  starting  pattern  release  key  equal  signal  count  would  require  ability  get  key  cache  least  get  key  matching  pattern  httpsissuesapacheorgjirabrowsenifi3214,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6181,allow  publishamqp  use  nifi  expression  language  enable  use  nifi  expression  language  publishamqp  processor  routing  key  value  allow  better  used  within  nifi  workflow  publishamqp  field  enable  routing  key,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6182,attributestojson  performance  improvement  attributestojson  lot  work  every  ontrigger  doesnt  need  lot  attribute  map  logic  done  schedule  time  doesnt  need  done  every  trigger  also  property  gotten  process  context  fetched  onschedule,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6183,tl  toolkit  add  possibility  define  san  issued  certificate  ease  deployment  load  balancer  front  nifi  would  nice  allow  user  define  san  certificate  issued  ca  load  balance  access  ui  even  listenhttp  processor  cause  error  host  mismatch  kind  error  different  fqdn  node  certificate  lb  certificate  also  discussed  httpstackoverflowcomquestions40035356nifiloadbalancer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6184,provide  newly  refactored  provenance  repository  persistent  provenance  repository  redesigned  different  time  several  year  original  design  repository  provide  storage  event  sequential  iteration  event  via  reporting  task  added  ability  compress  data  could  held  longer  introduced  notion  indexing  searching  via  lucene  weve  since  made  several  modification  try  boost  performance  point  however  repository  still  bottleneck  many  flow  handle  large  volume  small  flowfiles  need  new  implementation  based  around  current  goal  repository  provide  better  throughput,1,1,1,1,1,0,0,1,1,0,1,0,0,0,0,0,1
6185,movehdfs  processor  today  puthdfs  processor  merely  place  file  hdfs  nifi  time  may  want  move  filesdirectories  around  hdfs  part  workflow  could  puthdfs  processor  placed  file  trigger  initially  targeting  take  flow  file  attribute  absolute  hdfs  path  able  move  target  hdfs  path  using  filesystem  rename  api,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6186,add  nififlowconfigurationarchivemaxcount  property  currently  limit  number  flowxmlgz  archive  file  total  archive  size  nififlowconfigurationarchivemaxstorage  archive  file  age  nififlowconfigurationarchivemaxtime  addition  condition  manage  old  archive  there  demand  simply  limiting  number  archive  file  regardless  time  size  constraint  httpslistsapacheorgthreadhtml4d2d9cec46ee896318a5492bf020f60c28396e2850c077dad40d45d23cusersnifiapacheorg3e  provide  adding  new  property  nififlowconfigurationarchivemaxcount  specified  n  latest  config  file  archived  make  property  optional  process  following  order  maxcount  specified  archive  latest  n1  removed  maxtime  specified  archive  older  maxtime  removed  maxstorage  specified  old  archive  deleted  total  size  greater  configuration  create  new  archive  keep  latest  archive  regardless  limitation  illustrate  flowxml  archiving  work  simulation  updated  logic  size  flowxml  keep  increasing  h3  case1  archivemaxstorage10mb  archivemaxcount  5  time  flowxml  archive  archive  total  t1  f1  5mb  f1  5mb  t2  f2  5mb  f1  f2  10mb  t3  f3  5mb  f2  f3  10mb  t4  f4  10mb  f4  10mb  t5  f5  15mb  f5  15mb  t6  f6  20mb  f6  20mb  t7  f7  25mb  t7  25mb  t3  oldest  f1  removed  f1  f2  f3  10mb  t5  even  flowxml  size  exceeds  maxstorage  latest  archive  created  f4  removed  f4  f5  10mb  war  message  logged  f5  greater  10mb  case  nifi  keep  logging  war  message  indicating  archive  storage  size  exceeding  limit  t5  t5  nifi  keep  latest  flowxml  h3  case2  least  5  archive  need  kept  matter  set  blank  maxstorage  maxtime  archivemaxstorage  archivemaxtime  archivemaxcount  5  limit  archive  count  time  flowxml  archive  archive  total  t1  f1  5mb  f1  5mb  t2  f2  5mb  f1  f2  10mb  t3  f3  5mb  f1  f2  f3  15mb  t4  f4  10mb  f1  f2  f3  f4  25mb  t5  f5  15mb  f1  f2  f3  f4  f5  40mb  t6  f6  20mb  f2  f3  f4  f5  f6  55mb  t7  f7  25mb  f3  f4  f5  f6  f7  50mb  75mb  t8  f8  30mb  f3  f4  f5  f6  50mb  t6  oldest  archive  removed  keep  number  archive  5  t7  disk  60mb  space  f7  wont  archived  point  archive  mechanism  stop  working  trying  create  new  archive  keep  getting  exception  space  left  device  either  case  flowxml  grown  size  human  intervention  would  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6187,multiple  version  component  ticket  track  work  supporting  multiple  version  component  within  nifi  overall  design  feature  described  detail  following  wiki  page  httpscwikiapacheorgconfluencedisplaynifimultipleversionsofthesameextension  ticket  track  core  nifi  work  separate  ticket  created  track  enhancement  nar  maven  plugin,1,0,1,0,1,0,1,0,1,1,0,0,0,0,0,1,1
6188,add  rollback  failure  property  puthivestreaming  puthiveql  putdatabaserecord  putsql  many  put  processor  puthivestreaming  puthiveql  putsql  offer  failure  retry  relationship  flow  file  cannot  processed  perhaps  due  issue  external  system  error  however  use  case  put  fails  flow  file  processed  issue  resolved  configurable  said  processor  enable  current  behavior  stop  failure  type  behavior  propose  property  added  put  processor  minimum  puthivestreaming  puthiveql  putsql  processor  called  rollback  failure  offer  true  false  value  set  true  failure  retry  relationship  removed  processor  instance  set  false  relationship  offered  rollback  failure  false  processor  continue  behave  set  true  error  occurs  processing  flow  file  session  rolled  back  rather  transferring  flow  file  errorhandling  relationship  may  also  case  rollback  failure  true  incoming  connection  must  use  fifo  prioritizer  im  positive  documentation  updated  include  requirement,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0,1
6189,support  batch  update  notify  processor  nifi3216  added  ability  wait  n  signal  support  waiting  n  fragment  split  splitxxxx  processor  however  since  notify  processor  increase  count  one  one  calling  expensive  replace  cache  operation  network  doesnt  provide  practical  performance  user  configured  flow  look  like  n  glow  code  split  original  wait  n  split  something  notify  1  code  jira  improves  notify  processor  add  signal  buffer  count  specify  max  number  flow  file  buffered  update  cache  add  signal  counter  delta  specify  delta  grater  1  el  supported  signal  buffer  count  would  useful  flow  like  code  split  original  wait  n  split  filter  something  notify  code  buffer  incoming  flow  file  perform  cache  replace  operation  signal  counter  delta  code  split  original  wait  n  split  filter  something  merge  putxxx  notify  code  specify  via  attribute  expression  language,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6190,add  multipart  request  support  handlehttprequest  processor  currently  handlehttprequest  output  single  flowfile  containing  multipart  value  following  code  ef07e8bf36c274d3  contentdisposition  formdata  namep1  v1  ef07e8bf36c274d3  contentdisposition  formdata  namep2  v2  ef07e8bf36c274d3  code  many  user  requested  adding  upload  file  support  nifi  order  handlehttprequest  support  multipart  data  need  add  following  based  brief  researching  complex  simple  need  use  httpservletrequestgetparts  written  stackoverflow  thread  httpstackoverflowcomquestions3337056convenientwaytoparseincomingmultipartformdataparametersinaservlet  also  probably  need  custom  multipartinputstreamparser  implementation  jetty  default  implementation  writes  input  data  temporary  directory  file  system  instead  wed  like  nifi  write  output  flowfiles  content  streaming  fashion  need  request  size  validation  check  threshold  validation  passed  via  javaxservletmultipartconfigelement  finally  something  handlehttpresponse  processor  handlehttprequest  processor  start  splitting  incoming  request  multiple  output  flowfiles  need  wait  every  fragment  processed  execute  handlehttprequest  think  waitnotify  processor  available  next  version  helpful,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6191,generatetablefetch  allow  right  boundary  using  generatetablefetch  place  right  hand  boundary  page  data  lead  issue  statement  say  get  next  1000  record  greater  specific  key  record  added  table  time  processor  executed  sql  executed  result  pull  record  exist  processor  run  next  execution  processor  record  pulled  second  time  example  partition  size  1000  first  run  state  count4700  maxid4700  5  flowfiles  generated  last  one  say  fetch  1000  700  dont  think  really  bug  observation  5  flow  file  queue  executed  executesql  5th  file  execute  400  new  row  added  table  final  sql  statement  executed  300  extra  record  higher  id  value  also  pulled  nifi  second  run  state  id4700  count  id4700  400  maxid5100  1  flow  file  generated  includes  300  record  already  pulled  nifi  solution  optional  property  let  user  use  new  maxid  right  boundary  generating  query,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6192,tl  toolkit  define  san  standalone  mode  following  nifi3331  would  useful  option  add  subject  alternative  name  certificate  using  tl  toolkit  standalone  mode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6193,let  flowfilews  pas  n  signal  arrive  wait  processor  let  flow  file  pas  n  notify  signal  arrived  key  k  support  variety  type  usecases  currently  support  let  1  flow  file  pas  n  notify  signal  arrived  key  k  h3  work  simulation  example  let  say  50  incoming  flow  file  beginning  f1  f50  n3  m100  read  wait  processor  allowed  convert  3  signal  get  100  pas  ticket  1  there  signal  k  flow  file  waiting  2  notify  sends  signal  k  n1  doesnt  meet  wait  condition  wait  processor  still  waiting  3  notify  sends  another  two  signal  k  n3  match  wait  condition  4  wait  processor  start  consuming  flow  file  f1  f50  update  k  n3  m50  denotes  remaining  number  flow  file  go  5  another  30  flow  file  arrive  wait  processor  consumes  f51  f80  update  k  n0  m20  6  another  30  flow  file  arrive  wait  processor  consumes  f81  f100  k  k  n0  m0  since  n  used  wait  processor  remove  k  f101  f110  waiting  signal  state  1  h4  alternative  path  6  7a  notify  sends  additional  signal  f101  f110  go  7b  notify  doesnt  send  signal  f101  f110  routed  expired  h4  alternative  path  5  6a  notify  sends  additional  signal  point  k  would  k  n1  m20  wait  processor  process  20  flow  file  still  m20  6b  notify  sends  additional  three  signal  k  would  kn3  m20  wait  processor  consumes  20  flow  file  21th  flow  file  come  immediately  convert  n  meaning  consume  n3  create  m100  pas  kn0  m100  additionally  let  user  configure  m0  meaning  wait  release  number  incoming  flow  file  long  n  meet  condition  notify  1  behave  open  gate  notify  –1  close  h4  another  possible  usecase  limit  data  flow  rate  cluster  wide  complex  supporting  gate  openclose  state  however  support  flow  file  go  also  provide  rate  limit  across  cluster  example  use  case  nifi  push  data  via  s2s  nifi  b  want  limit  100  flow  file  per  5  min  nifi  notify  part  flow  generateflowfile5  min  primary  notifyk  n1  wait  part  flow  ingested  data  waitk  n1  m100  since  waitnotify  state  managed  globally  via  distributedcache  limit  throughput  cluster  wide  use  case  requires  limit  rate  exactly  design  notify  part  generateflowfile5  min  primary  notifyk  n0  notifyk  n1  avoids  n  added  there  traffic,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6194,add  detectduplicateusinghbase  processor  detectduplicate  processor  make  use  distributed  map  cache  maintaining  list  unique  file  identifier  hash  distributed  map  cache  functionality  could  provided  hbase  table  allows  reliably  storing  huge  volume  file  identifier  auditing  information  downside  approach  course  hbase  required  storing  unique  file  identifier  reliable  queryable  manner  along  audit  information  benefit  several  use  case,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6195,create  policybasedauthorizer  interface  allow  authorization  chain  rather  using  abstractpolicybasedauthorizer  trigger  policy  management  refactor  use  new  interface  new  implementation  interface  create  authorization  chain  existing  abstractpolicybasedauthorizer  subclass  investigating  alternate  implementation  authorizer  interface  see  abstractpolicybasedauthorizer  meant  extended  authorize  method  final  however  abstract  doauthorize  method  subclass  extend  particular  existing  abstractpolicybasedauthorizer  authorize  method  take  account  authorizationrequest  resourcecontext  authorization  decision  especially  important  authorizing  access  event  provenance  place  attribute  resoucecontext  authorizationrequest  obtaining  authorization  decision  would  like  use  attribute  authorize  access  provenance  download  view  content  feature  subclass  abstractpolicybasedauthorizer  availability  doauthorize  method  could  maintain  user  policy  allowing  access  flowfile  content  via  provenance,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
6196,add  schema  access  strategy  record  reader  writer  currently  record  reader  mostly  configured  schema  registry  service  name  schema  instead  allow  user  choose  one  several  strategy  determining  schema  schema  registry  schemaname  attribute  schema  registry  identifier  version  embedded  start  recordstream  avroschema  attribute  embedded  schema  case  like  avro  schema  embedded  content  writer  side  also  expose  option  order  convey  schema  information  others,1,0,1,0,1,0,0,0,1,1,1,0,0,1,1,1,0
6197,fetcher  parse  follow  nth  degree  outlinks  fetcher  improvement  parse  follow  outlinks  specified  depth  number  outlinks  follow  decreased  depth  using  divisor  patch  introduces  three  new  configuration  directive  code  property  namefetcherfollowoutlinksdepthname  value1value  descriptionexpertwhen  fetcherparse  true  value  greater  0  fetcher  extract  outlinks  follow  desired  depth  reached  value  1  mean  generated  page  fetched  first  degree  outlinks  fetched  parsed  careful  feature  agnostic  state  crawldb  know  already  fetched  page  setting  larger  2  likely  fetch  home  page  twice  fetch  cycle  highly  recommended  set  dbignoreexternallinks  true  restrict  outlink  follower  url  within  domain  disabled  false  feature  likely  follow  duplicate  even  depth1  value  1  0  disables  feature  description  property  property  namefetcherfollowoutlinksnumlinksname  value4value  descriptionexpertthe  number  outlinks  follow  fetcherfollowoutlinksdepth  enabled  careful  multiply  total  number  page  fetch  work  fetcherfollowoutlinksdepthdivisor  default  setting  followed  outlinks  depth  1  8  4  description  property  property  namefetcherfollowoutlinksdepthdivisorname  value2value  descriptionexpertthe  divisor  fetcherfollowoutlinksnumlinks  per  fetcherfollowoutlinksdepth  decrease  number  outlinks  follow  increasing  depth  formula  used  outlinks  floordivisor  depth  numlinks  prevents  exponential  growth  fetch  list  description  property  code  please  use  unless  know  youre  feature  consider  state  crawldb  consider  generator  setting  limiting  number  page  per  domainhostip  queue  polite  use  feature  high  setting  fetch  many  page  domain  including  duplicate  also  feature  work  fetcherparse  disabled  parsing  enabled  might  want  consider  store  downloaded  content,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6198,standard  metadata  property  name  parsedata  metadata  currently  people  free  name  stringbased  property  anything  want  name  contenttype  contenttype  contenttype  meaning  stefan  g  believe  proposed  solution  property  name  converted  lower  case  essence  really  fix  half  problem  right  case  identifying  contenttype  contenttype  permutation  really  named  content  type  contenttype  propose  way  correct  would  create  standard  set  named  string  parsedata  class  protocol  framework  parsing  framework  could  use  identify  common  property  contenttype  creator  language  etc  property  would  defined  top  parsedata  class  something  like  public  class  parsedata  public  static  final  string  contenttype  contenttype  public  static  final  string  creator  creator  fashion  user  could  least  know  name  standard  property  obtain  parsedata  example  making  call  parsedatagetmetadatagetparsedatacontenttype  get  content  type  call  parsedatagetmetadatasetparsedatacontenttype  textxml  course  wouldnt  preclude  user  currently  would  provide  standard  method  obtaining  common  critical  metadata  without  pouring  code  base  figure  named  ill  contribute  patch  near  end  week  beg  next  week  address  issue,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0
6199,nutch  2x  upgrade  gora  04  nutch  upgrade  gora94  branch  implemented  discus  detail  issue,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
6200,indexerelastic  plugin  use  elasticsearch  bulkprocessor  backoffpolicy  elasticsearchs  api  since  least  v20  includes  bulkprocessor  automatically  handle  flushing  bulk  request  given  max  doc  count  andor  max  bulk  size  also  believe  since  220  offer  backoffpolicy  option  allowing  bulkprocessorclient  retry  bulk  request  elasticsearch  cluster  saturated  using  bulkprocessor  originally  suggested  herehttpsissuesapacheorgjirabrowsenutch1527focusedcommentid13666616pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelcomment13666616  refactoring  indexerelastic  plugin  use  bulkprocessor  greatly  simplify  existing  plugin  cost  slightly  le  debug  logging  additionally  allow  plugin  handle  cluster  saturation  gracefully  rather  raising  runtimeexception  killing  reduce  task  using  configurable  exponential  backoff  policy  httpswwwelasticcoguideenelasticsearchclientjavaapi23javadocsbulkprocessorhtml,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6201,alternative  generator  generate  several  segment  one  parse  crawldb  using  nutch  large  scale  eg  billion  url  operation  related  crawldb  generate  update  tend  take  biggest  part  time  one  solution  limit  operation  minimum  generating  several  fetchlists  one  parse  crawldb  update  db  several  segment  existing  generator  allows  several  successive  run  generating  copy  crawldb  marking  url  fetched  practice  approach  work  well  need  read  whole  crawldb  many  time  generate  segment  patch  attached  contains  implementation  multigenerator  generate  several  fetchlists  reading  crawldb  multigenerator  differs  generator  aspect  filter  url  score  normalisation  optional  ip  resolution  done  entry  selected  fetching  partitioning  running  ip  resolution  whole  crawldb  slow  usable  large  scale  max  number  url  per  host  domain  ip  choose  partition  host  domain  ip  typically  unit  eg  domain  would  used  maxing  url  partitioning  however  cant  count  max  number  url  ip  another  unit  must  chosen  partitioning  ip  found  using  filter  score  dramatically  improve  performance  reduces  amount  data  sent  reducer  multigenerator  called  via  nutch  orgapachenutchcrawlmultigenerator  following  option  multigenerator  crawldb  segmentsdir  force  topn  n  numfetchers  numfetchers  adddays  numdays  nofilter  nonorm  maxnumsegments  num  parameter  similar  default  generator  apart  nonorm  explicit  topn  max  number  url  per  segment  maxnumsegments  actual  number  segment  generated  could  le  max  value  select  eg  enough  url  available  fetching  fit  le  segment  please  give  try  le  know  think  julien  nioche  httpwwwdigitalpebblecom,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
6202,add  solr5  solrcloud  indexer  support  nutch  cannot  index  solr5  also  proper  solrcloud  support  missing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6203,refactor  linkdb  linkdbmerger  reuse  code  linkdbmergerreduce  linkdbreduce  work  way  refactor  nutch  use  code,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6204,change  htmlparsefilter  return  parseresult  object  instead  parse  object  current  implementation  htmlparsefiltersjava  doesnt  allow  filter  add  parse  object  parseresult  object  change  htmlparsefilter  needed  allows  filter  return  parseresult  ofcourse  change  htmlparsefilters,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6205,add  alias  capability  parsepluginsxml  file  allows  mimetypeextensionid  mapping  jerome  talking  idea  address  current  issue  raised  stefan  g  mapping  mimetypelist  pluginids  rather  mimetypelist  extensionids  parsepluginsxml  file  weve  come  following  proposed  update  would  seemingly  fix  problem  propose  concept  alias  parsepluginsxml  file  defined  end  file  something  lie  parseplugins  mimetype  nametexthtml  plugin  idparsehtml  mimetype  alias  alias  nameparsehtml  extensionpointorgapachenutchparsehtmlhtmlparser  alias  nameparsehtml2  extensionpointmyotherhtmlparser  alias  parseplugins  guy  think  approach  would  flexible  enough  allow  mapping  extensionids  mimetypes  without  impacting  current  pluginid  concept  comment  welcome,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6206,integrate  solrnutch  hi  trying  sami  patch  regarding  solrnutch  found  httpblogfoofactoryfi200702onlineindexingintegratingnutchwithhtml  confirm  worked  lead  request  following  would  great  full  could  included  nutch  09  trying  eliminate  python  based  crawler  post  document  solr  corporate  enviornment  cant  install  trunk  version  production  enviornment  thus  asking  included  09  release  hope  wish  would  granted  look  forward  get  feedback  thank,1,1,1,1,1,0,0,0,1,0,1,0,0,0,0,0,0
6207,bad  language  identifier  plugin  performance  reported  stefan  groschupf  httpwwwmailarchivecomnutchdeveloperslistssourceforgenetmsg04090html  language  identifier  plugin  consumes  lot  processing  time  optimization  andor  configuration  option  required,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6208,nutchgora  configure  minimum  throughput  fetcher  like  trunk  nutchgora  also  feature  configure  fetcher  minimum  throughput  see  nutch1067  work  done  markus  implemented  almost  way  except  number  time  throughput  fall  threshold  measured  sequentially  counter  reset  throughput  healthy  work  even  better  temporary  dip  default  disabled  commit  later  today  objection,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6209,remove  deprecated  hadoop  api  call  f  quite  lot  call  deprecated  hadoop  api  functionality  following  patch  take  care  f  related  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6210,simple  admin  api  fetch  status  stop  service  rest  api  need  simple  info  stats  service  ability  shutdown  server,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6211,fetcher  improvement  fetcher  improvement,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,1,1
6212,refactor  fetcher  trunk  put  simply  fetcherhttpsgithubcomapachenutchblobtrunksrcjavaorgapachenutchfetcherfetcherjava  big  kinda  strange  size  file  unique  think  every  class  within  nutch  others  reasonably  well  modularized  split  constituent  class  make  sense,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0
6213,configure  minimum  throughput  fetcher  large  fetch  contain  lot  url  domain  slow  crawl  due  politeness  robotstxt  eg  10  per  url  url  fetched  queue  stall  entire  fetcher  60  url  take  10  minute  even  usually  dealt  using  time  bomb  time  bomb  value  hard  determine  patch  add  fetcherthroughputthreshold  setting  meaning  minimum  number  page  per  second  fetcher  give  doesnt  use  global  number  page  running  time  record  actual  page  processed  previous  second  value  compared  configured  threshold  besides  check  fetchers  status  also  updated  actual  number  page  per  second  byte  per  second,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6214,upgrade  carrot2  clustering  plugin  newest  stable  release  21  issue  upgrade  carrot2  search  result  clustering  plugin  newest  stable  version,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6215,remove  static  nutchconf  removing  static  nutchconfget  required  set  improvement  new  feature  allows  better  integration  nutch  j2ee  system  allows  management  nutch  web  based  gui  kind  nutch  appliance  improve  usability  also  increase  user  acceptance  nutch  allows  change  configuration  property  runtime  allows  implement  nutchconf  abstract  class  interface  provide  configuration  value  source  xml  file  community  request,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,0,1
6216,update  complete  api  doc  overview  page  api  overview  page  eg  18httpnutchapacheorgapidocs18indexhtml  need  review  completion  parse  filter  shown  instead  parser  latter  missing  url  normalizer  url  filter  consequency  parse  url  filter  plugins  listed  section  core  plugins  listed  eg  scoringdepth  neither  overview  package  list  missing  package  description  many  plugins,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6217,upgrade  instance  common  logging  slf4j  log4j  backend  whilst  working  another  issue  noticed  class  still  import  use  common  logging  example  httpbasejava  code  import  javautil  common  logging  import  import  orgapachecommonslogginglog  import  orgapachecommonslogginglogfactory  nutch  import  import  orgapachenutchcrawlcrawldatum  code  stage  unsure  many  others  still  import  reply  upon  common  logging  however  upgraded  slf4j  branch14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6218,use  multipleinputs  injector  make  single  mapreduce  job  currently  injector  creates  two  mapreduce  job  1  sort  job  get  url  seed  file  emit  crawldatum  object  2  merge  job  read  crawldatum  object  crawldb  output  sort  job  merge  emit  final  crawldatum  object  using  multipleinputs  read  crawldatum  object  crawldb  url  seed  file  simultaneously  perform  inject  single  mapreduce  job  also  additional  thing  covered  jira  1  pushed  filtering  normalization  metadata  extraction  unwanted  record  ruled  quickly  2  migrated  new  mapreduce  api  3  improved  documentation  4  new  junits  better  coverage  relevant  discussion  nutchdev  found  httpmailarchivesapacheorgmodmboxnutchdev201401mbox3ccafkhtfyxo6wl7gyuva5y1pzntdcoqpz4jzupbkp9cje80kgmailgmailcom3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6219,upgrade  recent  junit  4x  improve  test  flexibility  wanted  try  using  ignore  functionality  within  junit  however  dont  think  available  current  junit  version  use  nutch  upgrade,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
6220,port  mime  type  framework  use  tika  mime  detection  framework  tika  httpincubatorapacheorgtika  nearing  stable  01  release  candidate  think  would  good  time  patch  nutch  use  tikas  mime  detection  system  improvement  existing  nutch  one  written  primarily  jerome  tikas  mime  system  based  mime  system  freedesktoporg  includes  several  improvement  existing  nutch  mime  system  1  reliable  xmlbased  content  detection  clear  issue  plaguing  nutch  time  ability  delineate  r  xml  atom  etc  2  mime  magic  pattern  matching  including  support  multiple  pattern  3  glob  pattern  match  ability  support  1  ill  get  together  patch  attach  list  relatively  stable,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6221,better  cmd  line  parsing  nutchserver  cant  currently  stop  running  server  without  killing  job  via  pid  something  similar  simple  switch  added  permit  need  call  nutchserverstop  check  see  running  task  gracefully  shut  server  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6222,rest  api  refactoring  id  reviewed  rest  api  code  realized  old  clunky  want  make  refactoring  part  propose  change  patch,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
6223,variable  generatemaxcount  fetcherserverdelay  case  need  use  host  specific  characteristic  determining  crawl  speed  bulk  size  openindex  setting  recrawl  host  800k  url  patch  solves  problem  introducing  hostdb  generator  providing  powerful  jexl  expression  check  two  expression  added  generator  code  dgeneratemaxcountexpr  unfetched  fetched  800000  return  confgetintfetchertimelimitmins  12  60  pct95rs  500  1000  confgetintfetcherthreadsperqueue  1  else  return  confgetdoublegeneratemaxcount  300  dgeneratefetchdelayexpr  unfetched  fetched  800000  return  pct95rs  500  else  return  confgetdoublefetcherserverdelay  1000  code  large  host  select  many  record  possible  possible  fetch  based  number  thread  95th  percentile  response  time  fetch  limit  queuemaxcount  timelimit  resonsetime  numthreads  second  expression  follows  setting  crawldelay  fetch  queue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6224,scoring  api  extension  point  scoring  filter  opic  plugin  patch  refactors  place  nutch  manipulates  page  score  pluginbased  api  using  api  possible  implement  different  scoring  algorithm  also  much  easier  understand  scoring  work  multiple  scoring  plugins  run  sequence  manner  similar  urlfilters  included  also  opicscoringfilter  plugin  contains  current  implementation  scoring  algorithm  together  scoring  api  provides  fully  backwardcompatible  scoring,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6225,reduce  dependency  nutch  config  file  currently  many  component  nutch  rely  reading  configuration  file  file  need  classpath  packed  job  jar  inconvenient  want  manage  configuration  via  api  eg  embedding  nutch  running  many  job  slightly  different  configuration  issue  track  improvement  make  various  component  read  config  directly  configuration  property,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6226,parser  add  paragraph  line  break  initially  reported  patchpullrequest  vipul  behl  see  190httpsgithubcomapachenutchpull190  parser  parsetika  parsehtml  could  improved  add  line  break  paragraph  instead  writing  whole  document  single  line,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6227,rest  api  nutch  issue  discussing  reststyle  api  accessing  nutch  here  initial  idea  propose  use  orgrestlet  handling  request  returning  jsonxmlwhatever  response  hook  regular  tool  driven  via  api  would  async  api  since  nutch  operation  take  long  time  execute  follows  need  able  also  list  running  operation  retrieve  current  status  possibly  abortcancelstopsuspendresume  also  mean  would  potentially  create  manage  many  thread  servlet  afaik  frowned  upon  j2ee  purist  package  webapp  includes  deps  essentially  nutchjob  content  restlet  servlet  entry  point  open  issue  implement  reading  crawl  result  via  api  manage  crawl  use  single  configuration  per  webapp  notion  crawl  context  set  crawl  configs  crud  ops  would  nice  would  allow  managing  several  different  crawl  different  configs  single  webapp  complicates  implementation  lot,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6228,refactor  checker  class  use  base  class  common  code  various  checker  class  implementation  quite  bit  duplicated  code  refactored  cleanliness  maintainability,1,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,1
6229,indexingfilterchecker  optionally  follow  n  redirects  mentioned  nutch2194  sometimes  use  backend  web  application  least  able  follow  n  redirects,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6230,port  nutch1467  nutch1561  2x  nutch1467  nutch1561  include  improvement  plugins  parsemetatags  indexmetadata  ported  1x  2x,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6231,precise  data  parsing  using  jsoup  cs  selector  far  know  currently  nutch  1x  2x  feature  extractparse  exact  content  specific  website  ive  developed  plugin  parsejsoup  using  jsoup  current  project  extract  precise  content  site  specific  crawling  using  detailed  xml  configurationfield  name  cssselector  attribute  extraction  rule  datatype  defaultvalue  etc  please  let  know  feature  seems  relevant  currently  present  nutch  also  plan  export  nutch  1x,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6232,new  configuration  commoncrawldatadumper  tool  hi  find  attachment  new  patch  including  support  new  option  commoncrawldatadumper  particultar  new  option  passed  commoncrawlformat  object  provides  method  create  json  output  using  configuration  object  commoncrawlconfig  particular  patch  commoncrawldatadumper  provides  support  following  option  simpledataformat  enables  timestamps  gmt  epoche  millisecond  format  epochfilename  file  extracted  organized  reverseddns  tree  based  fqdn  webpage  followed  sha1  hash  complete  url  scraped  data  stored  directory  individual  gmttimestamped  file  using  epoche  time  millisecond  plus  file  extension  jsonarray  organizes  request  response  header  json  array  instead  using  json  subobject  reversekey  enables  use  layout  described  epochfilename  option  underscore  place  directory  separator  use  option  addition  option  already  supported  described  nutch  wikihttpswikiapacheorgnutchcommoncrawldatadumper  page  patch  start  nutch1974httpsissuesapacheorgjirabrowsenutch1974  thanks  chrismattmann  annieburgess  supporting  work,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6233,hbase  integration  issue  track  nutchhbase  integration,1,1,1,1,1,0,0,0,1,0,1,0,0,0,0,1,1
6234,injector  filter  normalize  existing  url  crawldb  nutch1712  behavior  injector  changed  case  new  url  added  existing  crawldb  injected  url  filtered  normalized  filter  normalizer  applied  url  including  already  crawldb  default  filter  existing  url  filtering  normalizing  may  take  long  large  crawldbs  andor  complex  url  filter  url  filter  normalizer  rule  changed  need  apply  anew  every  time  new  url  added  course  injected  url  filtered  normalized  default,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6235,support  nondefault  filesystem  path  input  output  belong  configured  default  filesystem  various  nutch  tool  may  raise  exception  like  noformat  exception  javalangillegalargumentexception  wrong  f  s3a  expected  hdfs  noformat  fixed  getting  reference  filesystem  path  object  noformat  filesystem  f  pathgetfilesystemgetconf  noformat  instead  noformat  filesystem  f  filesystemgetgetconf  noformat  given  path  eg  s3a  may  belong  default  file  system  hdfs  file  local  mode  simple  check  fsexistspath  fail  cf  filesystemcheckpathpathhttpshadoopapacheorgdocsr272apiorgapachehadoopfsfilesystemhtmlcheckpathorgapachehadoopfspath  filesystemgetconfhttpshadoopapacheorgdocsr272apiorgapachehadoopfsfilesystemhtmlgetorgapachehadoopconfconfiguration  v  filesystemgeturiconfhttpshadoopapacheorgdocsr272apiorgapachehadoopfsfilesystemhtmlgetjavaneturi20orgapachehadoopconfconfiguration  called  pathgetfilesystemconfhttpshadoopapacheorgdocsr272apiorgapachehadoopfspathhtmlgetfilesystem28orgapachehadoopconfconfiguration29  note  filesystem  input  output  may  different  eg  read  hdfs  write  s3,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6236,allow  perhost  configurable  protocol  plugin  introduces  new  configuration  file  mapping  protocol  plugins  hostnames  code  file  defines  hostname  protocol  plugin  mapping  line  take  host  name  followed  tab  followed  id  protocol  plugin  find  id  protocol  plugins  pluginxml  file  hostnametpluginidn  nutchapacheorg  orgapachenutchprotocolhttpclienthttp  tikaapacheorg  orgapachenutchprotocolhttphttp  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6237,port  pluggable  indexing  architecture  2x  would  like  port  work  done  julien  nutch1047  2x  issue  track  would  nice  upgrade  nutch1486  upgrade  people  get  using  solr  4x  asap,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,1,1
6238,implement  ssl  connection  test  testnutchapi  currently  testing  ssl  ignored  testnutchapi  complete  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6239,document  webpageavsc  hostavsc  easily  document  avro  schema  file  defined  current  avro  specification  httpavroapacheorgdocscurrentspechtmlschemacomplex  document  file  provide  meaningful  comment  generated  source,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6240,enhance  parserfactory  plugin  selection  policy  parserfactory  choose  parser  plugin  use  based  contenttypes  pathsuffix  defined  parser  pluginxml  file  selection  policy  follow  content  type  priority  first  plugin  found  whose  contenttype  attribute  match  beginning  content  type  used  none  match  first  whose  pathsuffix  attribute  match  end  url  path  used  neither  match  first  plugin  whose  pathsuffix  empty  string  used  policy  lot  problem  matching  found  random  parser  used  lot  chance  parser  cant  handle  content  hand  contenttype  associated  parser  plugin  specified  pluginxml  plugin  value  used  parserfactory  code  parser  check  code  contenttype  ok  us  hardcoded  contenttype  value  us  value  specified  pluginxml  possibility  missmatches  contenttype  hardcoded  contenttype  delcared  pluginxml  complete  list  problem  discussion  aout  point  available  httpwwwmailarchivecomnutchuser40luceneapacheorgmsg00744html  httpwwwmailarchivecomnutchdev40luceneapacheorgmsg00789html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6241,run  indexingfilterchecker  simple  telnet  server  used  customized  indexingfilterchecker  running  server  able  quickly  testcheck  page  web  application  ill  add  feature  back  letting  indexingfilterchecker  run  optionally  simple  server  run  code  export  nutchheapsize25  binnutch  indexchecker  normalize  dumptext  followredirects  listen  1234  code  perform  request  tcp  code  echo  httpapacheorg  nc  localhost  1234  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6242,solrindexer  write  multiple  server  solrutils  return  array  solrservers  read  solrurl  comma  delimited  list  url  using  configurationgetstring  solrwriter  able  handle  list  solrservers  useful  want  send  document  multiple  server  replication  available  want  send  document  multiple  noc  edit  replace  nutch1377  complement  nutch1377  issue  allows  index  multiple  solrcloud  cluster  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6243,any23  plugin  add  contenttype  filtering  possible  filter  based  document  contenttype  using  any23  extractor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6244,add  protocolhtmlunit  htmlunit  opposed  javascript  enabled  headless  browser  portable  library  therefore  better  suited  large  scale  crawl  issue  attempt  implement  protocolhtmlunit,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6245,upgrade  nutch  hadoop  07  upgrade  nutch  hadoop  07  replace  occurences  utf8  text  utf8  deprecated  use  discouraged  due  limitation  change  break  api  sense  thirdparty  addition  updated  use  new  apis  use  text  instead  utf8  method  parameter  change  also  break  backward  compatibility  data  crawldb  linkdb  segment  tool  upgrade  crawldb  linkdb  segment  created  facilitate  upgrade  path,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6246,code  dedup  fetcher  queue  redirects  20  line  duplicated  code  fetcher  new  fetchitem  created  redirect  queued,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6247,improve  usability  parsemetatags  indexmetadata  usually  plugins  parsemetatags  indexmetadata  used  combination  former  extract  meta  tag  latter  add  extracted  tag  field  index  configuration  two  plugins  differs  cause  pitfall  reduces  usability  see  example  config  property  metatagsnames  parsemetatags  us  separator  instead  used  indexmetadata  meta  tag  lowercased  indexmetadata  code  property  namemetatagsnamesname  valuedccreatordctermsbibliographiccitationvalue  property  property  nameindexparsemdname  valuemetatagdccreatormetatagdctermsbibliographiccitationvalue  property  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6248,update  jakarta  poi  jar  relevant  version  update  jakarta  poi  jar  relevant  version  close  bug  nutch591,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6249,support  http  auth  solr  communication  moment  cannot  send  data  directly  public  http  auth  protected  solr  instance  ive  wip  pass  configured  httpclient  object  commonshttpsolrserver  work  issue  add  ability  indexing  dedup  clean  configured  configuration  file  enable  solr  http  auth  communication  setting  following  parameter  nutchsite  config  solrauthtrue  solrauthusernameusername  solrauthpasswordpassword,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6250,update  latest  selenium  add  code  use  chrome  firefox  headless  mode  remote  web  driver  selenium  need  updated  missing  remote  web  driver  chrome  necessity  add  headless  mode  remote  webdriverbase  firefox  chrome  use  case  selenium  grid  using  docker  1  hub  docker  container  several  node  different  docker  container  nutch  another  docker  container  streaming  apache  solr  docker  container  least  4  different  docker  container,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6251,allow  overwrite  crawldatums  injected  entry  injector  reducer  permit  overwriting  existing  crawldatum  entry  however  useful  optionally  overwrite  user  reset  metadata  manually,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6252,multi  language  support  add  multilingual  support  nutch  described  httpwikiapacheorgnutchmultilingualsupport  document  analysis  part  actually  implemented  two  analysis  plugins  fr  de  provided  testing  deployed  default  query  analysis  part  missing  complete  multilingual  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6253,indexer  filter  normalize  url  indexer  able  normalize  url  useful  new  normalizer  applied  entire  crawldb  without  record  segment  cannot  indexed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6254,support  sitemap  processing  hostname  add  support  sitemap  processor  processing  hostnames  similar  mapper  eating  sitemap  url  baserobotrules  finding  sitemap  url  upload  patch  soon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6255,jexl  support  generator  job  generator  support  jexl  expression  would  make  much  easier  implement  focussing  crawler  rely  information  stored  crawldb  hostdb  possible  restrict  generator  select  interesting  record  cumbersome  involves  domainblacklisturlfiltering  jexl  support  hassle  crawl  english  record  code  binnutch  generate  crawlcrawldb  crawlsegments  expr  lang  en  code  crawl  html  record  code  binnutch  generate  crawlcrawldb  crawlsegments  expr  contenttype  texthtml  contenttype  applicationxhtmlxml  code  keep  mind  jexl  doesnt  allow  hyphenminus  field  identifier  transformed  underscore  string  literal  must  quote  surrounding  qoute  need  escaped  backslash,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6256,speed  indexing  eliminating  indexreducer  currently  indexer  nutchgora  consists  mapper  reduces  reduce  code  actually  iterate  groupedsorted  value  simply  index  individual  keyvalue  stringwebpage  pair  therefore  moving  indexing  code  mapper  eliminate  reduce  step  therefore  making  indexing  job  much  faster  unnecessary  spilling  disknetwork  cpu  wasted  sorting  note  directly  applicable  trunk  trunk  us  quite  different  approach  different  type  input  combined  single  value  reducer  although  think  possible  implement  similar  optimization  sure  anyone  want  trunk  feel  free  implement  similar  patch,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1
6257,improved  tokenization  similarity  scoring  plugin  patch  would  add  lucene  based  tokenization  cosine  similarity  plugin  clean  code  currently  present,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6258,pas  additional  solrparams  indexing  solr  simple  improvement  solrindexer  add  ability  pas  additional  solr  parameter  applied  updaterequest  useful  pas  parameter  specific  particular  indexing  run  solr  invariant  update  handler  modifying  solr  configuration  different  indexing  run  inconvenient,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6259,delegate  language  identification  tika  20  language  identification  delegated  tika  done  part  parsing  step  indexing  done  currently  patch  attached  backport  trunk  implement  add  new  parameter  determine  strategy  use  codexml  property  namelangextractionpolicyname  valuedetectidentifyvalue  descriptionthis  determines  plugin  us  detection  statistical  identification  mechanism  order  detect  identify  written  determine  extraction  policy  default  case  detectidentify  mean  plugin  first  try  extract  language  info  page  header  metadata  successful  try  using  tika  language  identification  possible  value  detect  identify  detectidentify  identifydetect  description  property  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6260,index  checker  server  optionally  keep  client  connection  open  title  say  easier  testing  without  start  indexchecker  jvm  every  time  code  binnutch  orgapachenutchindexerindexingfilterschecker  normalize  followredirects  keepclientcnxopen  listen  5000  code  telnet  send  url  line  feed  get  output  fast,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6261,scoring  filter  distribute  score  outlinks  currently  scoringfilterdistributescoretooutlink  name  implies  take  single  outlink  work  would  suggest  change  distributescoretooutlinks  would  take  outlinks  page  several  advantage  1  scoringfilter  plugin  return  single  adjust  datum  set  score  instead  returning  several  2  scoringfilter  plugin  change  score  original  page  via  adjust  datum  even  outlinks  useful  scoringfilter  plugin  say  score  page  based  content  instead  outlinks  3  since  scoringfilter  plugin  recieves  outlinks  make  better  decision  distribute  score  example  right  possible  create  plugin  always  distributes  exactly  page  cash  outlinksthat  page  score  5  always  distribute  exactly  5  point  outlinks  matter  internalexternal  factor  internal  external  score  factor  1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6262,redirected  url  handled  cleanly  like  outlink  url  specifically  nutch2x  handling  redirects  url  like  outlink  much  cleaner  make  simple  trace  new  url  added  webpage  database  instant  fetching  redirects  wont  work  small  price  pay  note  currently  work  httpmaxredirect  property  effect  attaching  patch  upcoming  day,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6263,need  character  encoding  detector  transferred  httpsourceforgenettrackerindexphpfuncdetailaid995730groupid59548atid491356  submitted  jungshik  shin  followup  bug  993380  figure  charset  meta  tag  although  cover  lot  ground  using  ct  header  field  http  header  corresponding  meta  tag  html  document  case  xml  use  similar  different  parsing  wild  lot  document  without  information  character  encoding  used  browser  like  mozilla  search  engine  like  google  use  character  encoding  detector  deal  unlabelled  document  mozillas  character  encoding  detector  gplmpld  might  able  port  java  unfortunately  foolproof  however  along  heuristic  used  mozilla  elsewhere  itll  possible  achieve  high  rate  detection  following  page  link  related  page  httptrainedmonkeycomweek200426  addition  character  encoding  detection  also  need  detect  language  document  even  harder  separate  bug  although  related,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6264,upgrade  code  base  orgapachehadoopmapred  orgapachehadoopmapreduce  nutch  still  using  deprecated  orgapachehadoopmapred  dependency  deprecated  need  updated  orgapachehadoopmapreduce  dependency,1,0,1,0,1,0,0,0,1,1,1,1,0,0,0,1,1
6265,support  solr  authentication  nutch  2x  solr  authentication  nutch  2x  like  1x,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6266,move  statistical  language  identification  indexing  parsing  step  statistical  identification  language  currently  done  part  indexing  step  whereas  detection  based  http  header  html  code  done  parsing  could  keep  logic  ie  statistical  detection  nothing  found  previous  method  part  parsing  would  useful  parsefilters  need  language  information  use  scoringfilters  eg  focus  crawl  set  language  since  statistical  model  ported  tika  probably  rely  instead  maintaining  thought,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6267,fetcher  guarantee  delay  hostdomainip  independent  httphttps  protocol  fetcher  us  combination  protocol  hostdomainip  id  fetch  item  queue  see  fetchitemjavahttpsgithubcomapachenutchblob2b93a66srcjavaorgapachenutchfetcherfetchitemjaval101  inhibits  guaranteed  delay  case  http  http  url  fetched  hostdomainip  eg  large  delay  30  sec  noformat  20180723  145439834  info  fetcherfetcherthread  fetcherthread  24  fetching  httpnutchapacheorg  queue  crawl  delay30000ms  20180723  145439846  info  fetcherfetcherthread  fetcherthread  23  fetching  httpsnutchapacheorg  queue  crawl  delay30000ms  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6268,ability  index  raw  content  usecases  require  nutch  actually  write  raw  content  configured  indexing  backend  since  content  never  read  plugin  question  therefore  need  force  indexjob  process  content  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6269,pluggable  indexing  backends  one  possible  feature  would  add  new  endpoint  indexingbackends  make  indexing  plugable  moment  hardwired  solr  ok  resource  like  elasticsearch  becoming  popular  would  better  handle  plugins  sure  name  endpoint  though  already  indexingplugins  generating  field  sent  backends  moreover  backends  necessarily  indexing  searching  could  external  storage  eg  couchdb  term  backend  would  confusing  20  could  pertaining  storage  gora  indexingbackend  best  name  came  mind  far  please  suggest  better  one  come  generic  mapreduce  job  indexing  deduplicating  cleaning  maybe  add  nutch  extension  point  easily  hook  indexing  cleaning  deduplicating  various  backends,1,0,1,0,1,0,0,1,1,1,1,0,0,0,0,0,1
6270,flexible  url  normalization  patch  heavily  restructured  version  patch  nutch253  much  decided  create  separate  issue  change  url  normalization  selectable  single  class  flexible  contextaware  chain  normalization  filter  highlight  rename  urlnormalizer  urlnormalizer  consistency  use  chained  filter  pattern  running  several  normalizer  sequence  order  normalizer  executed  defined  urlnormalizerorder  property  list  spaceseparated  implementation  class  normalizer  active  explicitly  named  list  run  random  order  one  specified  list  executed  define  set  context  scope  normalizer  may  called  scope  list  normalizer  via  urlnormalizerscopescopename  property  order  via  urlnormalizerorderscopename  property  property  missing  default  setting  used  normalizer  may  select  among  many  configuration  depending  context  called  using  modified  api  urlnormalizernormalizestring  url  string  scope  config  given  scope  defined  default  config  used  several  standard  context  scope  defined  various  application  modified  attempt  using  appropriate  normalizer  context  junit  test  modified  run  successfully  nutch363  suggests  change  may  required  area  perhaps  combine  urlfilters  urlnormalizers  single  subsystem  url  munging  support  scope  flexible  combination  normalizer  could  turn  urlfilters  special  case  normalizer  vice  versa  depending  point  view,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,1,0
6271,enhance  searcher  interface  current  searcher  interface  limited  many  purpose  hit  searchquery  query  int  numhits  string  dedupfield  string  sortfield  boolean  reverse  throw  ioexception  would  nice  interface  allowed  adding  different  feature  without  changing  interface  proposing  deprecate  current  search  method  introduce  something  like  hit  searchquery  query  metadata  context  throw  ioexception  also  time  enhance  queryfilter  interface  look  something  like  booleanquery  filterquery  input  booleanquery  translation  metadata  context  throw  queryexception  would  like  hear  comment  proceeding  patch,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6272,distributedsearch  update  search  server  added  searchserverstxt  fly  distributedsearch  client  update  search  server  added  searchserverstxt  file  fly  patch  update  search  server  fly  client  need  restart,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6273,support  crawldelay  robotstxt  nutch  need  support  crawldelay  defined  robotstxt  standard  defacto  standard  see  httphelpyahoocomhelpusysearchslurpslurp03html  webmaster  start  blocking  nutch  since  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6274,bulk  rest  api  retrieve  crawl  result  json  would  useful  able  retrieve  result  crawl  json  thing  need  discussed  return  bulk  result  using  restlet  writablerepresentation  subclass  format  result  think  would  make  sense  provide  single  record  retrieval  primary  key  record  record  within  range  incidentally  match  well  capability  gora  query  class,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
6275,redirection  handling  yahooslurps  algorithm  reading  yahoo  algorithm  one  andrzej  linked  httphelpyahoocomlnzyahooxtrasearchwebcrawlerslurp11html  redirectalias  handling  discussion  bit  spare  time  implemented  note  patch  attaching  choosing  algorithm  described  yahoo  help  page  make  attempt  handle  alias  way  see  httpwwwnabblecomredirectsandaliashandling28long29tf4270371htmla12154362  discussion  alias  handling  eg  generate  httpwwwmilliyetcomtr  fetch  httpwwwmilliyetcomtr  redirects  httpwwwmilliyetcomtr20070829indexhtmlver39  update  second  page  datum  metadata  indicate  httpwwwmilliyetcomtr  representative  form  updatedb  invertlinks  etc  indexing  second  page  change  url  field  httpwwwmilliyetcomtr,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6276,ntlm  basic  digest  authentication  scheme  webproxy  server  added  basic  digest  ntlm  authentication  scheme  protocolhttpclient  authentication  scheme  configured  proxy  server  well  web  server  domain  http  authentication  take  place  http10  http11  http  authentication  guide  found  httpwikiapacheorgnutchhttpauthenticationschemes,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6277,allow  parser  return  multiple  parse  object  speed  r  parser  allow  parserparse  return  mapstringparse  way  r  parser  return  multiple  parse  object  indexed  separately  advantage  need  fetch  feeditems  separately  see  discussion  httpwwwnabblecomrssfecterandindexindividulhowcanirealizethisfunctiontf3146271html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6278,nutch  delegate  compression  hadoop  data  structure  within  nutch  content  parsetext  handle  compression  delegate  compression  hadoop  also  nutch  respect  ioseqfilecompressiontype  setting  currently  even  ioseqfilecompressiontype  block  record  nutch  override  structure  set  none  however  imo  parsetext  always  compressed  record  performance  reason,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6279,increase  fetching  speed  discussion  nutch  mailing  list  fetcher  slow  patch  tried  address  patch  quich  hack  need  cleaning  also  currently  applies  08  branch  trunk  also  tested  large  change  metadata  original  metadata  us  spellchecking  new  version  decorator  provided  perhaps  used  http  header  handled  case  functionality  required  readingwriting  various  data  structure  patch  try  io  efficiently  see  patch  detail  initial  benchmark  small  benchmark  done  measure  performance  change  script  basically  following  inject  list  url  fresh  crawldb  create  fetchlist  10k  url  pointing  local  filesystem  fetch  updatedb  original  code  08branch  real  10m51907s  user  10m9914s  sys  0m21285s  applying  patch  real  4m15313s  user  3m42598s  sys  0m18485s,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0
6280,upgrade  tika  version  17  hi  folk  nutch  currently  us  version  16  tika  significant  api  change  16  17  one  line  update,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6281,upgrade  parsetika  use  tika  118  tika  118  released  nutch2583  includes  upgrade  tikacore  see  howtoupgradetikahttpsgithubcomapachenutchblobmastersrcpluginparsetikahowtoupgradetikatxt,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
6282,upgrade  nutch  use  released  apachetika01incubating  patch  upgrade  nutch  use  released  tika01incubating  jar  containing  stable  apis  code  opposed  dev  version  jar  file  thats  currently  place  svn,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6283,consolidate  code  fetcher  fetcher2  id  like  consolidate  lot  common  code  fetcher  fetcher2java  seems  like  following  difference  fetcher  relies  protocol  obey  robotstxt  crawl  delay  setting  whereas  fetcher2  implement  fetcher2  us  different  queueing  model  queue  per  crawl  host  accomplish  perhost  limiting  without  making  protocol  ive  begun  work  want  check  people  following  reason  fetcher  existing  since  fetcher2  seems  superset  functionality  road  map  remove  robotsdelay  logic  http  protocol  make  fetcher2s  delegation  duty  standard  improvement  wanted  fetcher  around  code,0,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0
6284,support  sitemaps  nutch  2x  sitemap  support  implemented  2x  branch  discussed  nutch1465  trunk,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6285,workflow  action  allow  user  auto  retry  workflow  action  allows  transient  error  retry  currently  user  often  want  control  retry  action  level  define  custom  retry  count  action  failed  action  possible  reason  could  startdata  enddata  set  el  exception  potential  problem  worth  retry  oozie  able  get  running  job  hadoop  id  error  action  error  come  job  application  error  failed  parse  action  conf  buffer  overflow  ssh  executor  file  existed  f  action  executor  solution  define  03  workflow  schema  new  attribute  action  level  get  user  defined  retry  add  default  oozie  conf  system  level  max  userretry  ex  workflowxml  workflowapp  xmlnsurioozieworkflow03  nametestwf  action  namea  retrymax2  retryinterval1  action  ooziedefaultxml  workflow  action  automatic  retry  property  nameoozieserviceliteworkflowstoreserviceuserretrymaxname  value3value  description  automatic  retry  max  count  workflow  action  3  default  description  property  property  nameoozieserviceliteworkflowstoreserviceuserretryintevalname  value10value  description  automatic  retry  interval  workflow  action  minute  default  value  10  minute  description  property  property  nameoozieserviceliteworkflowstoreserviceuserretryerrorcodename  value  ja017  value  description  automatic  retry  interval  workflow  action  handled  specified  error  code  description  property  property  nameoozieserviceliteworkflowstoreserviceuserretryerrorcodeextname  value  value  description  automatic  retry  interval  workflow  action  handled  specified  extra  error  code  description  property,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6286,add  el  function  allow  date  range  used  dataset  range  dataset  range  currently  specified  el  function  coordcurrentint  n  basically  return  nominal  datetime  nth  dataset  instance  relative  coordinator  action  creation  materialization  time  word  specifies  multiple  dataset  frequency  would  useful  new  function  let  user  specify  date  range  offset  instead  frequency  range  offset  new  function  coordoffsetint  n  string  timeunit  would  similar  coordcurrentint  n  function  except  offset  would  based  timeunit  ie  minute  hour  day  month  year  instead  frequency  example  frequency  1  day  following  would  equivalent  coordcurrent1  coordoffset1  day  coordoffset24  hour  coordoffset1440  minute  specifying  dataset  instance  resolved  value  coordoffsetint  n  string  timeunit  would  line  offset  multiple  frequency  used  instance  element  however  used  startinstance  endinstance  function  would  automatically  resolve  range  instance  match  offset  multiple  frequency  would  fall  startinstance  endinstance  example  frequency  1  hour  startinstance  coordoffset90  minute  15  hour  startinstance  would  effectively  equivalent  coordoffset60  minute  dealing  range,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6287,improve  forkjoin  validation  allow  errorto  transition  seems  common  user  error  transition  every  action  go  action  node  eg  email  action  go  kill  node  instead  going  kill  node  directly  done  action  node  within  forkjoin  path  forkjoin  validation  doesnt  allow  improve  forkjoin  validation  code  allow  error  transition  long  eventually  lead  kill  node,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6288,optimize  latest  future  el  resolution  case  startinstance  endinstance  startinstancecoordlatest23startinstance  endinstancecoordlatest0endinstance  assuming  24  instance  available  oozie  make  30012324  call  instead  24  call  lead  high  cpu  usage  number  latest  instance  high,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6289,add  dryrun  option  workflow  add  dryrun  option  workflow  would  validationparsingcheckingetc  normally  happens  submit  workflow  without  actually  submitting,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6290,create  example  using  altkerberosauthenticationhandler  hadoop9054  add  altkerberosauthenticationhandler  allows  nonbrowsers  use  kerberos  authentication  allowing  browser  use  alternative  authentication  implemented  subclass  particularly  useful  user  oozie  want  use  kerberos  oozie  client  allow  access  web  ui  using  mean  authentication  ldap  encourage  create  example  implementation  altkerberosauthenticationhandler  login  server  example  work  example  isnt  designed  secure  make  easier  user  integrate  authentication  system  oozie  two  main  component  1  examplealtauthenticationhanlder  extends  altkerberosauthenticationhandler  altkerberosauthenticationhandler  deal  determining  useragent  browser  falling  back  kerberosauthenticationhandler  examplealtauthenticationhandler  create  authenticationtoken  see  user  cookie  named  ooziewebloginauth  browser  value  cookie  username  2  login  server  example  examplealtauthenticationhandler  redirect  unauthenticated  user  two  implementation  one  basic  servlet  loginservlet  provides  form  get  username  password  check  equal  eg  userfoo  passfoo  writes  cookie  named  ooziewebloginauth  username  second  implementation  ldaploginservlet  check  username  password  ldap  server  writing  cookie  flow  would  user  go  oozie  web  ui  browser  examplealtauthenticator  determines  authenticated  redirects  login  server  example  authenticates  user  writes  cookie  redirects  back  web  ui  examplealtauthenticationhandler  see  cookie  authenticated  nonbrowser  oozie  client  examplealtauthenticationhandler  would  fall  back  kerberosauthenticationhandler  detailed  information  documentation  patch  examplealtauthenticationhandler  loginservlet  ldaploginservlet  part  new  login  module  build  oozieloginwar  oozieloginjar  loginserverexample  maven  profile  activated  much  like  workflow  generator  built  oozieloginwar  deployed  tomcat  oozie  somewhere  else  examplealtauthenticationhandler  depends  altkerberosauthenticationhandler  isnt  current  hadoop  release  temporarily  include  copy  create  jira  delete  later,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6291,improve  logic  purge  service  current  logic  purge  service  flat  ie  wf  purging  take  account  wf  end  time  take  account  wf  started  coord  job  mean  completed  wfs  running  coord  job  could  purge  coord  job  run  longer  purge  age  one  way  addressing  would  wf  purging  purge  wf  job  started  directly  client  call  coord  purging  purge  coord  job  started  directly  client  call  also  purge  wf  job  created  coord  job  purged  bundle  purging  purge  bundle  job  corresponding  coord  job  wf  job  could  handled  new  property  job  bean  jobowner  set  self  would  mean  purged  job  type  purger  set  value  higher  level  purger  one  responsible  purging  mean  wf  job  started  coord  job  started  bundle  job  wf  job  coord  job  would  bundle  job  owner  bundle  self  owner  ownership  propagation  would  also  caveat  would  handle  subworkflows  guess  check  wf  created  coord  let  coord  purge  take  care  meaning  wf  purge  purge  wf  started  coords  similarly  also  apply  subwfs,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6292,print  helpful  message  proxyuserservice  configured  wrong  dont  properly  configure  oozieserviceproxyuserserviceproxyuseruserhosts  oozieserviceproxyuserserviceproxyuserusergroups  try  use  proxyuserservice  get  exception  like  noformat  20130114  134625482  error  v1jobsservlet536  user  group  token  app  job  action  urlget  httplocalhost11000ooziev1jobsdoasfoo  error  proxyuser  cannot  null  javalangillegalargumentexception  proxyuser  cannot  null  orgapacheoozieutilparamcheckernotemptyparamcheckerjava68  orgapacheoozieserviceproxyuserservicevalidateproxyuserservicejava131  orgapacheoozieservletjsonrestservletgetuserjsonrestservletjava553  orgapacheoozieservletjsonrestservletservicejsonrestservletjava278  javaxservlethttphttpservletservicehttpservletjava717  orgapachecatalinacoreapplicationfilterchaininternaldofilterapplicationfilterchainjava290  orgapachecatalinacoreapplicationfilterchaindofilterapplicationfilterchainjava206  orgapacheoozieservletauthfilter2dofilterauthfilterjava126  orgapachehadoopsecurityauthenticationserverauthenticationfilterdofilterauthenticationfilterjava372  orgapacheoozieservletauthfilterdofilterauthfilterjava131  orgapachecatalinacoreapplicationfilterchaininternaldofilterapplicationfilterchainjava235  orgapachecatalinacoreapplicationfilterchaindofilterapplicationfilterchainjava206  orgapacheoozieservlethostnamefilterdofilterhostnamefilterjava67  orgapachecatalinacoreapplicationfilterchaininternaldofilterapplicationfilterchainjava235  orgapachecatalinacoreapplicationfilterchaindofilterapplicationfilterchainjava206  orgapachecatalinacorestandardwrappervalveinvokestandardwrappervalvejava233  orgapachecatalinacorestandardcontextvalveinvokestandardcontextvalvejava191  orgapachecatalinacorestandardhostvalveinvokestandardhostvalvejava127  orgapachecatalinavalveserrorreportvalveinvokeerrorreportvalvejava103  orgapachecatalinacorestandardenginevalveinvokestandardenginevalvejava109  orgapachecatalinaconnectorcoyoteadapterservicecoyoteadapterjava293  orgapachecoyotehttp11http11processorprocesshttp11processorjava861  orgapachecoyotehttp11http11protocolhttp11connectionhandlerprocesshttp11protocoljava606  orgapachetomcatutilnetjioendpointworkerrunjioendpointjava489  javalangthreadrunthreadjava680  noformat  would  helpful  user  gave  information  proxyuser  cannot  null  please  make  sure  oozieserviceproxyuserserviceproxyuseruserhosts  oozieserviceproxyuserserviceproxyuserusergroups  configured  correctly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6293,optimize  current  el  resolution  case  startinstance  endinstance  startinstance  coordcurrent23  startinstance  endinstance  coordcurrent0  endinstance  assuming  24  instance  available  oozie  make  30012324  call  instead  24  call  lead  high  cpu  usage  number  current  instance  high  oozie1073  fix  similar  issue  latest  future,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6294,sla  support  oozie  would  like  following  feature  oozie  jms  notification  sla  met  sla  start  miss  sla  end  miss  sla  duration  miss  email  alerting  sla  start  miss  sla  end  miss  sla  duration  miss  api  query  sla  metmiss  information  currently  sla  information  queried  sla  registration  event  job  status  event  one  calculate  actual  miss  simple  dashboard  view  query  sla  metmiss  information  built  api  mentioned,1,0,1,0,1,0,0,0,0,1,1,0,1,0,0,1,1
6295,refactor  action  main  class  sharelibs  refactor  pigmain  hivemain  sqoopmain  class  respective  sharelib  remove  dependency  ooziecore  help  prevent  dependency  issue  future  eg  different  version  antlr  main  class  would  end  sharelib  instead  launcher  jar  test  would  also  moved  sharelib  actionexecutors,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0
6296,refactor  class  launcher  jar  oozie  sharelib  look  refactoring  class  get  put  launcher  jar  oozie  sharelib  ie  shareliboozie  currently  json  jar  would  allow  u  get  rid  launcher  jar,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,1
6297,compress  lob  column  storing  database  storing  huge  data  lob  inefficient  making  oozie  compress  data  storing  reduce  size  data  stored  lob  help  reducing  time  query  also  database  like  oracle  mysql  support  storing  lob  data  tablerow  inline  data  smaller  size  inline  storage  much  better  performance  compared  outline  storage  storage  outside  tablerow,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
6298,fix  logging  issue  latency  accurate  job  id  coord  job  ui  show  job  log  example  warn  callablequeueservice542  user  group  queue  full  ignoring  queuing  orgapacheooziecommandwfsignalxcommand5c819194orgapacheooziecommandwfactionendxcommand3e7cbafeorgapacheooziecommandwfsignalxcommand6ed899beorgapacheooziecommandwfactionendxcommand4e55c1ccorgapacheooziecommandwfactionstartxcommand60266041orgapacheooziecommandwfactionstartxcommand77797cb7orgapacheooziecommandwfactionstartxcommand48eb0fa8orgapacheooziecommandwfactionstartxcommand405103feorgapacheooziecommandwfactionstartxcommand6dd39aforgapacheooziecommandwfactionstartxcommand25f613ae  illustration  log  message  unclear  one  print  reference  address  information  command  instead  meaningful  info  jobid  user  command  pertains  log  message  around  callable  command  fixed  place,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6299,add  ability  issue  kill  coordinator  action  directly  id  nominal  daterange  want  kill  coordinator  action  particular  way  currently  kill  issued  coordinator  job  level  percolate  action  jira  enhancing  kill  command  coord  action  specifically,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
6300,cut  number  small  file  created  track  running  action  oozie  creates  multiple  file  running  action  observed  overkill  consolidated  applicable  lesser  file  advantage  involve  staying  within  user  storage  quota  also  reducing  namenode  pressure  large  production  environment  static  final  string  actionconfxml  actionxml  public  static  final  string  actionpreparexml  oozieactionpreparexml  private  static  final  string  actionoutputprops  outputproperties  private  static  final  string  actionstatsprops  statsproperties  private  static  final  string  actionexternalchildidsprops  externalchildidsproperties  private  static  final  string  actionnewidprops  newidproperties  private  static  final  string  actionerrorprops  errorproperties  consolidate  reduce  number  file  required,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6301,make  sure  ha  work  secure  zookeeper  need  make  sure  ha  work  secure  zookeeper  includes  sasl  acl  setting  prevent  someone  else  deleting  oozie  znodes,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,0
6302,make  sure  ha  work  hcat  sla  notification  need  make  sure  ha  work  hcat  integration  sla  notification  inmemory  datastructures  ha  impact,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6303,db  optimization  revisit  eagerloadstate  place,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6304,workflow  performance  optimization  creating  combo  jira  small  performance  optimization  1  changing  asynchronous  action  start  synchronous  one  overcome  undue  delay  transitioning  start  control  node  actual  first  node  owing  loaded  queue  delay  observed  close  30  min  time  stress  condition,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6305,cleanup  database  every  test  investigating  flakey  test  orgapacheoozieslatestslajobeventlistenertestonjobevent  realized  flakey  sla  test  ive  seen  lately  issue  database  leftover  stuff  previous  test  expecting  normally  easy  fix  simply  call  cleanupdbtables  however  cleanupdbtables  requires  service  running  call  starting  service  failure  occurring  service  initialization  specifically  slaservice  initializes  slacalculatormemory  try  load  data  database  may  incomplete  eg  sla  registration  job  doesnt  exist  case  cant  call  cleanupdbtables  starting  service  brings  larger  issue  cleaning  database  every  test  anyway  make  sure  test  truly  independent  prevent  harmful  leaking  like  back  service  think  xtestcasesetup  call  cleanupdbtables  every  test  automatically  handle  service  dependency  appropriately,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6306,applicationmaster  restarts  restarts  launcher  job  using  yarn  situation  applicationmaster  restarted  eg  rm  failover  dy  another  attempt  made  etc  happens  start  launcher  job  start  launcher  already  launched  job  well  end  two  instance  job  problematic  example  pig  action  pig  client  might  run  job  launcher  get  restarted  restart  launch  job  dont  way  reattaching  previously  launched  job  however  yarn1461  mapreduce5699  use  yarn  tag  find  anything  launcher  previously  launched  thats  running  kill  still  start  least  running  two  instance  job  time  here  action  type  pig  sqoop  hive  kill  previously  launched  job  start  mapreduce  different  optimization  exit  launcher  previously  launched  job  already  exists  java  shell  outofthebox  support  like  thing  java  action  take  advantage  like  pig  sqoop  hive  user  add  code  distcp  supported  ssh  email  na  yarn  tag  wont  available  hadoop  240  nightly  ie  hadoop  300snapshot  obviously  hadoop  1x  able  use  yarn  method  new  method  tagging  add  new  type  hadooplib  called  hadoop  utils  put  class  specific  specific  version  hadoop  implementation  dummy  version  example  hadoop2  hadoop  utils  put  method  foo  call  yarn  stuff  hadoop1  hadoop  utils  foo  method  would  either  equivalent  mr1  noop  put  method  hadoop3  hadoop  utils  use  tag  hadoop1  hadoop2  hadoop23  hadoop  utils  dummy  implementation  dont  anything  existing  behavior  preserved  hadoop  utils  module  allow  u  take  advantage  hadoop  2  feature  future  still  able  compile  hadoop  1  limited  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6307,create  oozie  application  master  yarn  first  release  oozie  hadoop  2  good  user  set  execution  engine  oozie  conf  yarn  traditional  mr  target  post  oozie  41  release,1,0,1,0,1,0,0,0,1,1,1,0,0,0,1,1,1
6308,improvement  purge  service  current  purge  service  oozie  performance  issue  might  help  look  query  index  improve  purge  service,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
6309,oozie  timer  biased  oozie  timer  biased  statistical  metric  expose  runtime  oozie  server  instead  window  time  make  useful  especially  server  running  codehale  efficient  easy  use  biased  histogram  used  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6310,change  hadoop1  profile  use  121  change  hadoop1  profile  use  121  instead  111,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6311,use  pom  property  rather  specific  version  number  pom  file  hbaselibs  hcataloglibs  sharelib  etc  version  number  hbase  hive  hcatalog  sqoop  etc  hard  coded  pom  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6312,devise  way  turn  sla  alert  bundlecoordinator  flexibly  user  need  turn  sla  miss  alert  job  bundle  suspended  grid  upgrade  similar  work  resumed  arent  flooded  bunch  alert,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
6313,use  curator  leader  latch  instead  checking  order  oozie  server  currently  task  eg  purging  old  job  want  one  oozie  server  currently  simply  check  oozie  server  first  zookeepers  list  server  ie  order  connected  havent  seen  problem  might  good  idea  replace  curator  leaderlatch  sound  robust  leader  path  probably  something  like  servicesleader  make  sure  error  edge  case  handled  properly  including  happens  leader  dy  without  unregistering  etc  httpcuratorapacheorgcuratorrecipesleaderlatchhtml,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6314,specifying  coordinator  input  datasets  logical  way  dataset  instance  specified  input  coordinator  currently  work  logic  ie  available  workflow  start  enhance  include  logical  way  specifying  availability  criterion  eg  instance  minimum  n  k  instance  delta  datasets  process  data  incrementally  usecases  different  datasets  bcp  workflow  run  either  whichever  arrives  earlier  data  guaranteed  coordlatest  allows  skipping  available  one  workflow  never  trigger  unless  mentioned  number  instance  found  workflow  like  ‘refining’  algorithm  run  minimum  required  datasets  ready  process  delta  efficiency  jira  discus  design  review  implementation  feature,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
6315,add  spark  action  executor,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
6316,bulk  kill  suspend  resume  job  using  existing  filter  offset  len  jobtype  params  currently  bulk  write  operation  job  api  would  like  first  introduce  bulk  kill  operation  kill  job  satisfy  filter  desired  usage  noformatoozie  job  oozie  httplocalhost11000oozie  kill  filter  namesomethingnoformat,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6317,support  getting  at  delegation  token  tez  job  need  new  server  side  option  enable  getting  delegation  token  at  application  timeline  server  generic  history  server  yarn  apps  tez  job  putting  yarntimelineserviceenabledtrue  yarnsitexml  enable  mapreduce  job  well  needed  fix  done  future  release  yarn  tez  fail  warn  proceed  could  talk  at  server  since  available  at  stable  yet  hadoop  26  preferable  use  tez  job  impact  mapreduce  job  job  fail  at  token  could  fetched,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6318,oozie  validate  command  moved  serverside  oozie  validate  command  run  xml  validator  workflow  coordinator  bundle  xml  file  check  valid  xsd  schema  file  currently  implemented  oozie  cli  oozieclivalidatecommand  downside  available  ooziecli  user  anyone  using  rest  api  cant  use  currently  hardcoded  specific  xsd  file  ship  oozie  whenever  add  new  schema  also  manually  update  easy  forget  user  cant  validate  custom  schema  oozie  server  would  accept  move  oozie  server  perhaps  new  validate  endpoint  able  accept  local  file  path  current  behavior  perhaps  also  hdfs  file  local  xml  file  uploaded  part  rest  call  also  description  command  need  updated  mention  also  handle  coordinator  bundle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6319,add  missing  admin  command  oozieclient  ooziecli  oozieclient  ooziecli  missing  admin  command  available  rest  api  long  time  add  get  configuration  get  o  env  get  java  system  property  get  instrumentationmetrics  one  either  make  separate  command  one  command  try  one  endpoint  ill  see  work  best,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
6320,add  way  specify  default  jtrm  nn  oozie  cluster  agnostic  require  rmjt  nn  per  action  workflow  via  global  section  practice  many  user  use  one  oozie  server  per  cluster  extra  burden  specify  time  would  convenient  added  configuration  property  ooziesite  would  let  specify  default  rmjt  nn  use  way  user  could  completely  omit  jobtracker  namenode  field  workflow  added  benefit  easily  update  value  ever  renamemove  rmjt  nn  wed  course  still  allow  specifying  jobtracker  namenode  action  global  allow  individual  workflow  action  override  default,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6321,use  hadoops  credentialprovider  password  ooziesite  password  ooziesite  oozieemailsmtppassword  oozieservicejpaservicejdbcpassword  would  good  supported  hadoops  credentialprovider  password  specified  external  encrypted  file  file  prepared  described  herehttphadoopapacheorgdocsr270hadoopprojectdisthadoopcommoncommandsmanualhtmlcredential  hadoop  doc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6322,add  support  bundleconf  function,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6323,add  ability  provide  hive  hive  2  action  query  inline  workflow  id  like  ability  specify  hive  query  within  workflowxml  hs2  action,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
6324,fluentjob  minimum  viable  fluent  job  api  user  often  complain  xml  write  oozie  job  would  nice  could  write  something  like  java  dont  want  maintain  separate  java  api  looking  around  saw  jaxb  might  right  thing  tell  let  create  java  class  xsd  schema  able  autogenerate  java  api  writing  oozie  job  without  really  maintain  investigate  feasible  implement  useful  looking  link  jaxb  overviewhttpsenwikipediaorgwikijavaarchitectureforxmlbinding  jaxb  descriptionhttpsjaxbjavanet2211docsch03html  maven  jaxb  pluginhttpsjavanetprojectsmavenjaxb2pluginpageshome  apache  falconhttpsfalconapacheorg  key  feature  must  inside  fluentjobapi  artifact  able  create  workflow  coordinator  bundle  definition  programmatically  synchronizing  every  xsd  change  rebuild  write  workflowxml  coordinatorxml  bundlexml  jobsproperties  artifact  every  xsd  version  cloneability  workflow  etc  object  perform  cross  check  eg  workflow  graph  dag  latest  xsd  version  supported  must  nice  xsd  version  provided  provided  latest  one  considered  valid  implement  fluent  apihttpsenwikipediaorgwikifluentinterface  python  jython  py4j  repl  make  easy  experiment  also  data  engineer  data  scientist  create  documentation  usage  read  workflowxml  coordinatorxml  bundlexml  jobsproperties  artifact  every  xsd  version  convert  xsd  version  support  xsd  change  fly  within  repl  support  hdfs  read  writes  support  dry  run  oozie  server  perform  check,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
6325,allow  table  drop  hcat  prepare  hcat  prepare  allows  drop  partition  would  nice  also  allow  dropping  table  depending  url  current  format  url  codehcatmetastore  serverportdatabase  nametable  namepartkey1valuepartkey2valuecode  least  one  partition  must  provided  otherwise  prepare  step  fails  fololwing  exception  code  starting  execution  prepare  action  creating  hcatclient  userehsanhaq  authsimple  serverthriftdatavaultprodapp2internalmachines9083  prepare  execution  launcher  mapper  failed  failing  oozie  launcher  main  class  orgapacheoozieactionhadoopsqoopmain  exception  invoking  main  error  trying  drop  hcatdatavaultprodapp2internalmachines9083testrdbmsimport2015110600test  orgapacheoozieactionhadooplauncherexception  error  trying  drop  hcatdatavaultprodapp2internalmachines9083testrdbmsimport2015110600test  orgapacheoozieactionhadooplaunchermappermaplaunchermapperjava178  orgapachehadoopmapredmaprunnerrunmaprunnerjava54  orgapachehadoopmapredmaptaskrunoldmappermaptaskjava450  orgapachehadoopmapredmaptaskrunmaptaskjava343  orgapachehadoopmapredyarnchild2runyarnchildjava163  javasecurityaccesscontrollerdoprivilegednative  method  javaxsecurityauthsubjectdoassubjectjava415  orgapachehadoopsecurityusergroupinformationdoasusergroupinformationjava1628  orgapachehadoopmapredyarnchildmainyarnchildjava158  caused  orgapacheoozieactionhadooplauncherexception  error  trying  drop  hcatdatavaultprodapp2internalmachines9083testrdbmsimport2015110600test  orgapacheoozieactionhadoophcatlauncherurihandlerdeletehcatlauncherurihandlerjava64  orgapacheoozieactionhadoopprepareactionsdriverexecuteprepareactionsdriverjava89  orgapacheoozieactionhadoopprepareactionsdriverdooperationsprepareactionsdriverjava67  orgapacheoozieactionhadooplaunchermapperexecutepreparelaunchermapperjava446  orgapacheoozieactionhadooplaunchermappermaplaunchermapperjava174  8  caused  javaneturisyntaxexception  uri  path  expected  format  hcatdatavaultprodapp2internalmachines9083testrdbmsimport2015110600test  orgapacheoozieutilhcaturiparsehcaturijava66  orgapacheoozieutilhcaturiinithcaturijava52  orgapacheoozieutilhcaturiinithcaturijava48  orgapacheoozieactionhadoophcatlauncherurihandlerdeletehcatlauncherurihandlerjava52  12  oozie  launcher  failed  finishing  hadoop  job  gracefully  code  h3  suggestion  url  partition  provided  delete  entire  table,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6326,ooziesetupsh  sharelib  create  take  long  time  large  cluster  cluster  256  node  take  5  minute  create  sharelib  copy  tarball  take  around  10  second  seems  like  performance  could  improved  loading  file  concurrently  many  thread,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6327,completely  rewrite  graphgenerator  code  web  ui  currently  generates  graph  workflow  dag  png  image  show  user  graphgenerator  class  unfortunately  number  downside  current  implementation  image  generated  serverside  doesnt  scale  well  eats  lot  memory  help  combat  issue  generate  graph  workflow  le  25  node  disabled  refresh  button  ui  slow  us  library  netsfjung  httpjungsourceforgenet  hasnt  updated  since  2010  library  also  dependency  fork  commonscollections  netsourceforgecollections  httpsourceforgenetprojectscollections  similarly  hasnt  updated  since  2010  problem  cant  update  commonscollections  security  concern  collections580  though  oozie  susceptible  attack  would  good  complete  rewrite  using  different  library  remove  jung  commonscollections  fork  whatever  choose  svg  draw  image  browser,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,0,0
6328,add  bcc  oozie  email  action  oozie  email  action  support  cc  request  made  add  support  bcc  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6329,sortby  filter  ordering  job  query  result  currently  job  query  result  order  job  creation  time  good  filter  option  ordering  result  lastmodifiedtime  createdtime,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6330,ability  use  local  path  sharelib  oozie2590  part  oozie1770  oozie  yarn  work  oozie  full  control  classpath  given  launcher  cluster  node  everything  installed  locally  path  possible  launcher  reference  local  jar  instead  localize  hdfs  example  hive  installed  node  usrlibhive  hive  jar  usrlibhivelib  could  launcher  add  usrlibhivelib  classpath  save  overhead  localizing  jar  hive  sharelib  hdfs  think  best  way  implement  augment  sharelib  mapping  filehttpsoozieapacheorgdocs420aginstallhtmlooziesharelib  feature  accept  file  path  also  work  oozie  sharelib  oozie  jar  individual  sharelibs  eg  mapping  file  take  commaseparated  dirsjars  cluster  everything  installed  node  wouldnt  need  bother  sharelib,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6331,read  property  file  action  configuration  current  logic  acton  configuration  read  xml  file  within  oozie  action  directory  pig  application  property  file  supported  may  default  configuration  file  format  simplify  logic  reusing  property  file  using  oozie  add  property  file  reading  action  conf,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6332,oozie  coordinator  el  function  get  first  day  weekmonth  user  demanding  function  give  first  day  week  first  day  month  would  help  aggregation  job  accumulating  data  first  day  monthweek  intended  date  current  date  currently  way  define  startinstance  existing  el  function,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6333,queue  dump  command  message  confusing  queue  empty  callable  queue  empty  run  queue  dump  command  message  say  noformat  oozie  admin  queuedump  server  queue  dump  queue  dump  null  server  uniqueness  map  dump  uniqueness  dump  null  noformat  message  make  sound  like  bad  thing  especially  exclamation  mark  change  message  something  neutral  helpful  like  queue  empty  something  like,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6334,deprecate  instrumentation  favor  metric  oozie1817  added  option  use  dropwizard  metric  instead  homegrown  instrumentation  left  instrumentation  default  compatibility  oozie  5  drop  instrumentation  metric  also  use  opportunity  clean  code  interface  metric  currently  conform  instrumentation  pluggability  update  500  deprecate  instrumentationservice  make  metricsinstrumentationservice  default,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6335,extend  http  configuration  setting  embedded  jetty  regarding  http  setting  currently  oozie  support  ooziehttpsincludeprotocols  ooziehttpsexcludeciphersuites  introduced  oozie2666  however  jetty  sslcontextfactory  support  following  configuration  excludeprotocols  includeprotocols  excludeciphersuites  includeciphersuites  control  employed  protocol  cipher  suite  extend  current  implementation  allow  user  configure  excludeprotocols  includeciphersuites  sensible  default  also  needed,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6336,oozie  handle  transient  database  problem  problem  oozie  cannot  update  database  properly  recently  experienced  erratic  behavior  two  setup  mysql  galera  cluster  manager  galera  us  clusterwide  optimistic  locking  might  cause  transaction  rollback  two  parallel  transaction  running  one  cannot  complete  conflict  mysql  percona  xtradb  cluster  one  mysql  instance  killed  oozie  might  get  communication  link  failure  exception  failover  problem  failed  db  transaction  later  might  cause  workflow  startedrestarted  recoveryservice  get  stuck  clear  u  happens  fact  certain  db  update  executed  solution  use  sort  retry  logic  exponential  backoff  db  update  fails  could  start  100ms  wait  time  doubled  every  retry  operation  considered  failure  still  fails  10  attempt  value  could  configurable  discus  initial  value  scope  jira  note  solution  handle  transient  failure  db  longer  period  time  accept  internal  state  oozie  corrupted,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
6337,improve  spark  option  parsing  two  issue  w  spark  action  argument  parsing  within  sparkmain  h5  driver  executor  extra  classpaths  equal  sign  used  user  specifies  conf  sparkexecutorextraclasspathxyz  conf  sparkdriverextraclasspathabc  option  conf  added  sparkargs  code  try  evaluate  sparkexecutorextraclasspathxyz  us  special  logic  set  addtosparkargs  false  result  extra  conf  sparkargs  eventually  example  conf  sparkexecutorextraclasspathxyz  conf  otherpropertyabc  become  conf  conf  otherpropertyabc  cause  spark  job  submit  failure  later  might  need  remove  one  prior  conf  sparkargs  current  evaluated  opt  executorclasspath  driverclasspath  h5  user  provided  file  archive  equal  sign  used  following  workflow  xml  snippet  codexml  sparkoptsfilesnamenodehomesharehivesitexml  numexecutors  4  executormemory  7g  drivermemory  7gsparkopts  code  filesnamenodehomesharehivesitexml  opt  placed  sparkargs  previous  oozie  version  without  modification  dont  special  handling  file  opt  user  specifies  filesnamenodehomesharehivesitexml  numexecutor  4  sparkmain  code  treat  numexecutor  file  path  name  caused  issue  described  previous  comment  might  need  change  handling  logic  filesoption  archivesoption  driverclasspathoption,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,0
6338,make  oozie  junit  test  pas  disttest  oozie  junit  test  case  2000  piece  right  run  junit  test  patch  submission  overkill  since  take  two  hour  workaround  use  disttesthttpsgithubcomclouderadisttest  framework  allows  parallel  test  execution  load  distributed  across  possibly  hundred  cloud  engine  slave  junit  test  run  time  equal  longest  junit  test  run  order  10ish  minute  whole  test  suite  across  oozie  component  nevertheless  test  case  try  read  file  relative  access  eg  srctestresourcesooziesitexml  get  system  property  present  cloud  slave  certainly  fail  improvement  address  exact  issue  making  test  pas  also  cloud,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6339,implement  new  mechanism  specify  sharelibs  workflow  action  oozie2687  introduces  launcher  element  workflow  code  launcher  memory1024memory  vcores1vcores  javaoptsdsomepropertytrue  xxrandomjvmswitchjavaopts  envkeyvalueenv  queuerootooziequeue  sharelibsparkhivesharelib  launcher  code  purpose  ticket  discus  implement  new  mechanism  handling  sharelib  addactionsharelib  javaactionexecutor  adjusted  regarding  precedence  order  global  action  level  launcher  configuration  eg  oozieactionsharelibforactiontype  try  override  sharelib  following  apply  quote  config  property  defined  action  configuration  priority  action  jobxml  priority  global  section  configuration  jobxml  priority  action  default  ooziesite  quote  multiple  choice  handle  sharelib  alternative  1  override  sharelib  way  consistent  current  way  handling  oozie  configuration  setting  alternative  2  make  sharelib  additive  example  global  launcher  sharelib  element  workflow  includes  multiple  sharelibs  eg  ab  oozieactionsharelibforactiontype  also  specified  action  configuration  eg  cd  take  union  specified  entity  abcd  would  included  inconsistent  everything  else,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6340,add  option  allow  list  user  access  system  config  currently  allow  access  system  config  user  though  mask  sensitive  information  unnecessary  show  user  restrict  access  admins  service  like  hue  use  server  side  config  value  display  ui  accordingly  eg  server  timezone  whether  sla  configured  kind  credential  supported  etc  would  good  support  restricting  admins  list  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6341,instrument  slacalculatormemory  lot  workflowjobbean  coordinatorjobbean  instance  followed  creating  slasummarybean  instance  following  occur  set  oozieslaserviceslaservicecapacity  sane  value  like  10000  preserve  heap  consumption  slacalculatormemoryaddregistration  slacalculatormemoryupdateregistration  would  either  emit  trace  level  log  like  sla  registration  event  job  showing  add  update  slaregistrationbean  successful  emit  error  level  log  like  slacalculator  memory  capacity  reached  cannot  add  update  new  sla  registration  entry  job  showing  add  update  slaregistrationbean  successful  since  sometimes  stale  already  processed  slaevent  entry  slacalculatormemoryslamap  get  removed  pretty  hard  say  actual  size  whether  next  add  update  command  succeed  need  instrumentationcounter  instance  get  incremented  slacalculatormemoryslamapput  new  entry  added  get  decremented  happens  slacalculatormemoryslamapremove  existing  entry  removed  counter  automatically  present  within  rest  interface  oozie  client,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6342,enable  definition  admin  user  using  ooziesitexml  currently  list  admin  user  defined  adminuserstxt  file  hard  coded  oozie  config  dir  streamlined  solution  could  define  list  admin  user  via  ooziesitexml  introducing  following  configuration  receives  comma  separated  value  user  admins  oozieserviceauthorizationserviceadminusers,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6343,client  ui  improved  sla  filtering  option  currently  apply  range  filter  top  v2slaservlet  used  rich  undocumented  set  way  id  parentid  eventstatus  appname  nominalstart  nominalend  need  refactor  v2slaservlet  feature  richer  set  slaevent  slaregistration  slasummary  filtering  based  attribute  filter  option  always  anded  never  ored  maintain  compatibility  parameter  name  behavior  used  thus  far  remove  slasummaryfilter  refactor  slasummarygetforfilterjpaexecutor  another  possibility  confusion  document  new  functionality  rich  use  case  example  library  user  leverage,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,1,0
6344,upgrade  derby  101410  upgrade  derby  101410,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
6345,fluentjob  create  error  handler  action  needed  shell  multipleshellactions  example  fluent  job  api  generates  multiple  action  name  emailonerror  give  e0705  error  code  multipleshellactions  generated  xml  noformat  workflow  job  definition  generated  api  jar  xml  version10  encodingutf8  standaloneyes  workflowworkflowapp  xmlnsemailurioozieemailaction02  xmlnsworkflowurioozieworkflow10  xmlnsshellurioozieshellaction10  nameshellexample  workflowstart  toparent  workflowkill  namekill  workflowmessageaction  failed  error  messagewferrormessagewflasterrornodeworkflowmessage  workflowkill  workflowaction  nameemailonerror  emailemail  emailtosomebodyapacheorgemailto  emailsubjectworkflow  erroremailsubject  emailbodyshell  action  failed  error  messagewferrormessagewflasterrornodeemailbody  emailemail  workflowok  tokill  workflowerror  tokill  workflowaction  workflowaction  nameparent  workflowaction  workflowdecision  namedecision1  workflowdecision  workflowaction  nameemailonerror  workflowaction  workflowaction  namehappypath0  workflowaction  workflowdecision  namedecision2  workflowaction  noformat  error  message  noformat  binoozie  job  oozie  httplocalhost11000oozie  runjar  fluenttestjar  config  jobproperties  verbose  error  e0705  e0705  nnode  already  defined  node  emailonerror  noformat  shell  example  also  creates  xml  multiple  emailonerror  action,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6346,example  action  fix  git  example  prepareactionshandler  support  xml  namespace  prefix  git  action  example  working  give  e0701  error  code  noformat  binoozie  job  oozie  httplocalhost11000oozie  config  examplessrcmainappsgitjobproperties  run  dnamenodehdfslocalhost9000  jobtrackerlocalhost8032  error  e0701  e0701  xml  schema  error  cvccomplextype24c  matching  wildcard  strict  declaration  found  element  git  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6347,core  coordinator  action  status  submitted  e1003  error  try  run  coordinator  job  give  e1003  error  code  coordinator  status  changed  failed  using  following  coordinatorxml  noformat  coordinatorapp  namecroncoord  frequency010  startstart  endend  timezoneutc  xmlnsuriooziecoordinator02  action  workflow  apppathworkflowappuriapppath  configuration  property  nameresourcemanagername  valueresourcemanagervalue  property  property  namenamenodename  valuenamenodevalue  property  property  namequeuenamename  valuequeuenamevalue  property  property  nameusernamename  valueadminvalue  property  configuration  workflow  action  coordinatorapp  noformat  status  coordinator  job  running  noformat  oozie  job  oozie  httplocalhost11000oozie  info  0000000181105104843399oozieandrc  job  id  0000000181105104843399oozieandrc  job  name  croncoord  app  path  hdfslocalhost9000userandrassalamonexamplesappscronschedule  status  running  start  time  20100101  0000  gmt  end  time  20100101  0100  gmt  pause  time  concurrency  1  id  status  ext  id  err  code  created  nominal  time  0000000181105104843399oozieandrc1  submitted  20181105  0954  gmt  20100101  0000  gmt  0000000181105104843399oozieandrc2  ready  20181105  0954  gmt  20100101  0010  gmt  0000000181105104843399oozieandrc3  ready  20181105  0954  gmt  20100101  0020  gmt  0000000181105104843399oozieandrc4  ready  20181105  0954  gmt  20100101  0030  gmt  0000000181105104843399oozieandrc5  ready  20181105  0954  gmt  20100101  0040  gmt  0000000181105104843399oozieandrc6  ready  20181105  0954  gmt  20100101  0050  gmt  noformat  status  first  coordinator  action  submitted  noformat  distrotargetoozie520snapshotdistrooozie520snapshotbinoozie  job  oozie  httplocalhost11000oozie  info  0000000181105104843399oozieandrc1  id  0000000181105104843399oozieandrc1  action  number  1  console  url  error  code  error  message  external  id  external  status  job  id  0000000181105104843399oozieandrc  tracker  uri  created  20181105  0954  gmt  nominal  time  20100101  0000  gmt  status  submitted  last  modified  20181105  0954  gmt  first  missing  dependency  noformat  log  contains  e1003  error  message  noformat  oozie  job  oozie  httplocalhost11000oozie  log  0000000181105104843399oozieandrc  20181105  110457837  error  coordactionstartxcommand517  serversalamonandrasmbp15local  user  group  token  app  job0000000181105104843399oozieandrc  action0000000181105104843399oozieandrc1  xexception  orgapacheooziecommandcommandexception  e1003  invalid  coordinator  application  attribute  usernameadmin  orgapacheooziecommandcoordcoordactionstartxcommandmergeconfigcoordactionstartxcommandjava180  orgapacheooziecommandcoordcoordactionstartxcommandexecutecoordactionstartxcommandjava197  orgapacheooziecommandcoordcoordactionstartxcommandexecutecoordactionstartxcommandjava63  orgapacheooziecommandxcommandcallxcommandjava291  orgapacheoozieservicecallablequeueservicecompositecallablecallcallablequeueservicejava363  orgapacheoozieservicecallablequeueservicecompositecallablecallcallablequeueservicejava292  javautilconcurrentfuturetaskrunfuturetaskjava266  orgapacheoozieservicecallablequeueservicecallablewrapperruncallablequeueservicejava210  javautilconcurrentthreadpoolexecutorrunworkerthreadpoolexecutorjava1149  javautilconcurrentthreadpoolexecutorworkerrunthreadpoolexecutorjava624  javalangthreadrunthreadjava748  noformat  change  status  failed  case,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6348,ssh  action  optimize  process  stream  draining  oozie3354  improved  sshactionexecutor  avoid  processwaitfor  block  modified  drainbuffers  method  keep  draining  standard  output  standard  error  continuously  right  speed  drain  hardwired  long  process  running  method  read  1024  byte  cycle  half  second  take  long  time  want  drain  several  megabyte  instance  oozieservletcallbackservletmaxdatalen  increased  let  optimize  draining  either  read  1024  byte  multiple  time  cycle  long  data  buffer  increase  value  buffer  size  1024  latter  case  default  buffer  size  could  half  oozieservletcallbackservletmaxdatalen  value  also  need  additional  property  specify  buffer  size  avoid  memory  problem  using  big  buffer  keep  1024  minimum  buffer  size  would  also  useful  refactor  code  put  buffer  draining  separate  class  create  unit  test  class  using  class  shellmain  avoid  code  duplication  would  also  useful  fix  oozie3359  first,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6349,ssh  action  show  empty  error  message  error  code  currently  ssh  action  fails  message  returned  status  neither  error  message  error  code  field  filled  make  reporting  cause  ssh  action  failure  via  oozie  highly  impractical  meaningful  bit  information  failed  ssh  action  status  status  filled  based  presence  lack  error  file  produced  case  user  submitted  script  return  value  0  noformat  sshactionexecutorgetactionstatus  string  outfile  getremotefilenamecontext  action  error  false  true  string  checkerrorcmd  sshcommandbase  actiongettrackeruri  l  outfile  int  retval  getreturnvaluecheckerrorcmd  noformat  user  requirement  provide  detailed  information  successfailure  usersubmitted  script  could  minimum  return  value  optionally  last  1k  stderr  drained  information  could  communicated  via  errormessage  errorcode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6350,f  action  refactor  optimize  fsactionexecutorjava  decision  making  part  read  fsactionexecutorjava  found  good  code  class  judging  logic  use  based  command  use  switchcase  replace  ifelse  “ifelse”  make  code  hard  read  “ifelse”  make  code  hard  extend  “ifelse”  low  efficience  suggest  using  “switchcase”  instead,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6351,oozie  allow  drill  hadoop  job  detail  highlevel  requirement  since  oozie  designed  gateway  grid  need  support  w  api  common  hadoop  command  oozie  user  doesnt  want  go  multiple  system  get  required  data  based  propose  implement  following  requirement  oozie  r1  oozie  provide  w  endpoint  get  hadoop  job  detail  including  job  counter  r2  support  type  hadoop  job  mr  job  created  mr  action  mr  job  created  part  pig  script  r3  addition  pig  action  oozie  provide  way  query  pig  stats  proposed  design  d1  oozie  store  summary  jobcounter  pigstats  oozie  db  item  summary  stats  determined  oozie  limit  size  howeverthe  commonly  used  stats  include  summary  important  note  summary  information  collected  job  finished  d2  user  asks  detail  hadoop  job  stats  user  need  query  using  different  w  api  query  user  specify  hadoop  job  id  oozie  directly  query  hadoop  jtrmhs  since  external  call  undetermined  response  time  oozie  provide  one  hadoop  job  id  perrequest  avoid  timeout  w  call  caveat  hadoop  job  jtrmhistory  server  oozie  fail  collect  detail  d3  pig  oozie  store  piggenerated  hadoop  id  db  expose  user  throw  verbose  query  d4  oozie  need  collect  summary  pig  stats  corresponding  job  counter  store  oozie  db  pigstats  way  getting  job  counter  hadoop  job  submits  could  use  api  collect  summary  counter  pigcreated  job  d5  completedetail  pigstats  stored  pig  launcher  mapper  job  counter  user  want  get  detail  pig  stats  could  get  lm  directly  open  question  summary  countersstats  max  size  stats  advanced  planning  scope  task  might  required  design  support  later  user  asking  query  job  stats  job  running  need  decide  subsequent  job  submission  design  user  could  use  d2  get  counter  mr  action  running  however  pig  straight  forward  pig  submits  job  execution  new  pigrunner  provide  listener  concept  user  get  notification  new  mr  job  submitted  id  using  oozie  could  get  running  hadoop  job  id  instantly  future  user  might  want  query  using  d2,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6352,support  high  availability  oozie  service  oozie  becomes  critical  component  hadoop  ecosystem  user  need  assured  availability  service  provided  oozie  support  need  oozie  include  new  feature  support  high  availability  feature  need  take  consideration  oozie  provides  restful  apis  java  apis  command  line  api  insensitive  availability  specific  server  component  yahoo  required  session  failover  client  acceptable  client  reconnect  session  lost  long  state  data  managed  oozie  service  lost,1,1,1,1,1,0,0,1,0,1,1,0,0,0,0,1,1
6353,add  library  used  action  oozie  oozie  610  action  specific  share  libs  added  jira  proposes  enhancement  library  added  shared  action  eg  modifying  pig  store  stats  json  library  required  putting  json  lib  common  location  action  like  hive  distcp  use  library  future  eg  common  libs  stored  shareliboozie  also  action  specific  share  libs  override  common  libs,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6354,improveconsolidate  hadoop  job  id  log  harvesting  logic  currently  logic  duplicated  pigmain  hivemain  used  also  sqoop  logic  moved  launchermain  also  regex  pattern  used  finally  case  sqoop  hadoop  job  id  captured  hadoop  logging  line  format  old  mr1  new  new  mr2  job  completed  message  thus  multiple  regex  supported,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
6355,simplify  kerberoshadoopaccessorservice  code  remove  kerberosdoas  code  kerberoshadoopaccessorservice  subclass  implemented  separate  implementation  provide  support  preugi  ugi  version  hadoop  time  doaskerberosdoas  class  make  testcases  run  preugi  ugi  version  hadoop  time  version  hadoop  supported  trunk  320  ugi  dont  need  class  anymore  kerberoshadoopaccessorservice  logic  folded  hadoopaccessorservice  doas  class  removed  simplify  code  avoid  common  source  confusion  user,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6356,enhance  ooziedb  tool  require  manual  upgrade  step  require  sqlfile  option  currently  upgrade  tool  requires  manual  step  alter  column  length  upgrade  done  way  openjpa  schematool  ignores  column  length  modification  ooziedb  tool  use  direct  jdbc  corresponding  syntax  db  addition  sqlfile  file  option  required  provide  sql  script  written  file  tmp,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
6357,add  default  action  configs  per  cluster  similar  hadoop  configs  per  cluster  oozie  support  default  action  configuration  per  cluster  default  config  per  action  per  cluster  mechanism  would  act  default  action  configuration  section  enabling  thing  like  defining  special  queue  launcher  job  setting  property  required  tune  pighive  etc  loadwork  identical  way  hadoop  configuration  instead  using  hostname  key  would  use  composed  key  hostname  actiontype,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6358,add  support  multipleconfigurable  sharelibs  action  type  currently  fixed  sharelib  per  action  type  ie  code  sharelibmapreducestreaming  pig  hive  sqoop  code  many  situation  would  desirable  support  multiple  version  sharelib  per  component  system  default  allow  user  override  default  specific  version  ie  code  sharelibmapreducestreaming  pig08  default  pig09  sqoop  code,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6359,support  choosing  timezone  oozie  ui  add  ability  choose  different  timezone  eg  pst  oozie  web  ui  command  line  would  superficial  change  affect  web  ui  command  line  output  wouldnt  change  actual  processing  log  etc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6360,support  hive  oozie  cli  add  support  oozie  hive  cli,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1
6361,clarify  improve  oozie  logging  configuration  streaming  oozies  logging  configuration  number  restriction  listed  anywhere  arent  obvious  also  improvement  streaming  log  code  made  simplify  make  robust  additionally  ability  automatically  delete  old  log  file  help  prevent  problem  many  file  directory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6362,add  name  node  jobxml  configuration  element  f  action  adding  name  node  element  f  action  allow  user  shorten  f  action  avoid  specifying  name  node  hdfshostport  multiple  time  also  add  jobxml  configuration  element  allow  user  set  property  f  instance  created  eg  code  action  namefsnode  f  namenodehdfshostportnamenode  jobxmlfsinfoxmljobxml  configuration  property  namesomepropertyname  valuesomevaluevalue  property  configuration  mkdir  pathuserwfuseroutputdata1  mkdir  pathuserwfuseroutputdata2  f  ok  toend  error  tofail  action  code  also  leverage  global  section  oozie874  automatically,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6363,remove  duplicated  code  fsactionexecutor  oozie913  add  code  fsactionexecutor  parse  jobxml  configuration  element  similar  code  javaactionexecutor  minor  refactoring  code  javaactionexecutor  used,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6364,add  formal  parameter  bundle  xml  like  oozie239  add  formal  parameter  bundle  job  there  also  minor  bug  oozie239  prevent  oozie  printing  warning  user  submits  coordinator  job  using  schema  04  without  parameter  section,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6365,add  support  oozie  coordinator  work  utc  offset  current  oozie  coordinator  expects  resolve  date  utc  ie  20090810t0000z  utc  datetimes  used  startendpause  job  datasets  initialinstance  resolve  dataset  instance  uri  template  adding  support  non  utc  timezone  would  enable  deployment  use  timezone  different  utc  standard  seems  quite  common  country  dont  observe  dst  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6366,refactor  defaulttokencontextgenerator  make  easier  create  subclass  refactor  defaulttokencontextgenerator  make  easier  create  subclass  basically  need  change  member  visibility  protected  create  method  creates  default  context  list  subclass  use  method  without  arraylist  conversion,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6367,create  factory  customize  po  tagger  provide  mechanism  customize  po  tagger  using  factory  component  get  following  object  factory  context  generator  sequence  validator  po  dictionary  implementation  one  issue  solve  initialize  object  example  sequence  validator  might  initialized  using  po  dictionary,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
6368,add  lbfgs  parameter  estimation  training  maxent  add  support  lbfgs  algorithm  train  maxent  classifier,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6369,parallel  computing  objective  function  gradient  maxentqn  although  current  lbfgs  trainer  run  sequential  manner  maxents  objective  function  ie  negative  loglikelihood  function  gradient  computed  parallel  jira  focus  improving  training  time  maxentqn,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6370,refactoring  command  line  parameter  interface  refactoring  command  line  parameter  interface  described  httpscwikiapacheorgopennlpcommandlineparameterinterfaceshtml,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
6371,merge  trainingparameters  pluggableparameters  pluggableparameters  class  added  pull  getintstringbooleanparameters  method  abstracttrainer  merge  functionality  pluggableparameters  trainingparameters,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
6372,extend  morfologik  addon  extends  morfologik  addon  functionality  adding  tag  dictionary  implementation  adding  support  build  morfologik  binary  dictionary  cli  adding  postaggerfactory  extension  load  morfologik  binary  dictionary  embedded  po  tagger  model  bundle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6373,clark  cluster  namefinder  feature  add  token  based  feature  clark  cluster  clark  2003  feature  actually  one  implemented  wordclusterfeaturegenerator  somehow  make  separate  perhaps  implementing  dynamic  prefix  id  one  dictionary  feature  shown  combination  clusteringbased  feature  improve  result  clark  cluster  generated  using  tool  httpsgithubcomninjinclarkposinduction,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6374,refactor  data  indexer  code  data  indexer  code  never  changed  much  since  first  write  lot  potential  improved  java  8,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
6375,skip  postag  dictionary  validation  runtime  po  tagger  tool  validates  po  dictionary  checking  po  tag  dictionary  known  model  depending  dictionary  size  take  several  second  validate  mechanism  validate  model  creation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6376,add  convenience  method  load  model  path  add  convenience  method  load  model  path  user  need  code  look  slightly  nicer  directly  instantiate  model  path,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6377,add  sequence  classification  support  current  machine  learning  integration  doesnt  support  sequence  model  model  classify  entire  sequence  compared  classification  support  right  make  single  decision  time,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6378,small  refactoring  arvores  deitadas  format  class  small  refactoring  make  clear  use  arvores  deitadas  formatters  rename  class  contractionutility  portuguesecontractionutility  move  ad  package  rename  class  adparagraphstream  adsentencestream  improved  corpus  parsing  move  test  related  arvores  deitadas  ad  package,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,1,0
6379,improve  osgi  support  opennlp  extension  basic  osgi  support  currently  simply  export  package  dont  use  osgi  feature  work  well  anything  expect  place  try  access  class  class  name  eg  load  custom  factory  via  classforname  user  happy  call  work  osgi  environment  class  try  load  class  path  osgi  done  via  service  need  use  running  osgi  environment  anyway  opennlp  need  work  without  osgi  suggest  make  osgi  optional  dependency  write  code  detect  osgi  class  instantiate  user  class  would  need  something  like  try  load  via  classforname  cannot  found  check  running  osgi  environment  try  get  osgi  service  provides  instance  user  class,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6380,move  porter  stemmer  opennlp  tool  similarity  package  contribution  contains  porter  stemmer  stemmer  moved  opennlp  tool  test  need  written,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6381,absence  logging  usage  systemout  seems  concept  logging  used  library  instead  systemoutprintln  hardcoded  many  place  debug  information  using  logging  framework  would  make  awkward  use  module  integrated  different  application  spam  log  console  usage  systemout  core  class  like  gistrainer  choice  simply  technical  debt  happy  work  provide  patch  technical  debt,1,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0
6382,add  cross  validation  cmd  line  tool  name  finder  cmd  line  interface  cross  validation  tool  name  finder,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6383,add  pluggable  machine  learning  support  opennlp  tool  currently  use  classifier  inside  maxent  library  possible  plugin  3rd  party  machine  learning  library  integrated  seamlessly  maxent  library  achieve  two  task  need  solved  define  machinelearningfactory  capable  instantiating  trainer  classifer  based  given  parameter  property  file  algorithm  name  could  name  factory  use  additional  code  opennlp  tool  need  refactored  use  factory  interface  instead  trainutil  refactor  opennlp  tool  use  interface  instead  abstractmodel  interface  identical  current  maxentmodel  additional  support  serialization  avoid  interface  layer  opennlp  tool  maxent  maxent  class  moved  opennlptoolsml,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6384,create  detailed  fmeasure  result  listener  create  evaluation  listener  would  output  detailed  fmeasure  sample  us  typed  span  example  let  user  know  individual  precision  recall  person  organization  date  namefinder  model,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6385,evaluator  allow  tool  register  report  interface  opennlp220  introduced  misclassified  argument  enables  evaluator  print  misclassified  item  using  command  line  evaluator  expand  allow  tool  us  evaluator  register  interface  get  information,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6386,cli  tool  format  refactored  proposed  patch  refactors  cli  tool  simplifies  code  introducing  hierarchy  removing  lot  code  duplication  also  introduces  better  error  help  message  including  help  format  listing  available  format  various  tool  able  work  format  directly  turn  eliminates  need  keep  converted  file  disk,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,0,0
6387,fix  remaining  issue  lbfgs  parameter  estimation  get  stable  enhance  lbfgs  parameter  estimation  code  least  perform  well  gi  training  work  issue  bring  implementation  level  experimental  flag  removed  remaining  problem  see  issue  opennlp338,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
6388,make  bigram  name  feature  generator  public  name  finder  us  bigram  name  feature  generator  inner  class  default  name  context  generator  class  made  public  moved  featuregen  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6389,add  train  method  tokennamefinder  take  trainingparameters  generatordescriptor  resourcemap  cant  train  tokennamefinder  using  params  argument  generatordescriptor  resourcemap,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6390,add  additional  context  support  po  tagger  application  would  benefit  additional  context  support  po  tagger  example  could  improve  model  accuracy  using  output  name  finder  change  would  include  field  string  additionalcontext  possample  modify  code  allow  po  tagger  use  training  runtime,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6391,evaluator  cli  tool  use  parameter  interface  cli  evaluation  tool  using  parameter  interface  describe  argument  easier  set  optional  parameter  tool  using  interface,0,0,0,0,0,0,1,0,1,0,1,0,0,0,0,0,0
6392,detailed  evaluator  output  cli  evaluation  tool  evaluator  crossvalidator  optionally  print  detail  false  positive  negative  wrong  tag  add  optional  argument  printerrors  cli  tool,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6393,add  mergeboth  option  detokenizer  mergeboth  option  would  useful  train  using  corpus  example  portuguese  corpus  devolva  livro  give  book  back  need  detokenize  devolvame  livro  configure  token  mergeboth  detokenizer  dictionary  would  helpful,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6394,add  test  data  verificatin  ontonotes4  eval  test  verified  test  run  data  expected  checksum,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6395,add  multi  threading  support  gi  training  gi  training  famous  taking  quite  time  finish  day  cpu  many  core  training  algorithm  updated  use  multiple  cpu  core  perform  training  various  approach  solve  task  document  wiki  discus  mailing  list,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6396,refactor  cross  validation  training  code  always  use  new  training  parameter  object  backward  compatibility  opennlp  still  need  support  direct  passing  iteration  cutoff  params  many  method  code  related  training  component  iteration  cutoff  parameter  always  wrapped  training  parameter  object  new  method  called,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6397,markablefileinputstreamfactory  public  addons  need  use  markablefileinputstreamfactory  since  public  accessible  set  package  private  unless  reason  package  private  public,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6398,model  also  constructor  accept  url  file  object  add  url  file  constructor  model  information  found  thread  httpmailarchivesapacheorgmodmboxopennlpdev201204mbox3c4f9a5e8c400010440gmailcom3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6399,sentencedetector  support  new  line  end  sentence  char  sentence  detector  support  consider  new  line  char  end  sentence  probably  require  special  handling  training  code  assume  new  line  char  eos  missing,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6400,create  factory  customize  tokenizer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6401,add  format  support  french  treebank  opennlp  format  package  support  french  treebank  obtained  without  paying  research  purpose  information  httpwwwllfcnrsfrgensabeillefrenchtreebankfrphp,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6402,change  generatorfactory  class  allow  registering  custom  feature  generator  trying  setup  opennlp  namefinder  project  xml  feature  generator  descriptor  nonstandard  feature  xml  descriptor  support  custom  feature  generator  generator  cache  generator  custom  classcomexamplemyfeaturegenerator  cache  generator  however  possible  pas  parameter  custom  feature  generator  registering  new  feature  generator  currently  possible  due  access  restriction  opennlptoolsutilfeaturegengeneratorfactory  class  lifting  access  restriction  private  public  would  solve  issue  see  also  httpstackoverflowcomquestions19375053usingcustomfeaturegeneratorswithparametersinopennlp,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6403,po  tagger  context  generator  use  feature  generation  class  part  name  finder  refactoring  number  reusable  feature  generator  class  created  po  tagger  use  class  drop  custom  feature  generation  code  much  possible,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6404,add  language  detection  component  many  component  opennlp  sensitive  input  language  would  nice  opennlp  would  component  detect  language  input  text  two  commonly  used  solution  today  apache  tikas  language  identifier  language  detection  shuyo  nakatani,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6405,add  cli  tool  doccat  evaluation  support  command  line  tool  used  evaluate  document  categorizer  model  test  file,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6406,add  letsmt  format  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6407,facilitating  specialization  posdictionary  train  method  postaggerme  receives  input  posdictionary  make  implementation  custom  dictionary  painful  suggest  replace  posdictionary  input  tagdictionary  another  improvement  may  also  declaration  posdictionary  field  protected  help  extension  class,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6408,add  util  method  po  tagger  build  ngram  dictionary  po  tagger  support  ngram  dictionary  code  creates  ngram  dictionary  inside  postaggertrainer  refactored  moved  util  method  additionally  cmd  line  interface  extended  train  ngram  dictionary,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6409,model  package  ignore  notice  license  file  able  directly  distribute  model  apache  opennlp  package  need  contain  license  notice  file  model  loading  fails  currently  present,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6410,add  name  finder  factory  support  instantiate  highly  modified  name  finder  via  model  component  opennlp  support  user  defined  factory  customize  aspect  name  finder  support  user  defined  factory  yet  change  implement  name  finder  factory  style  already  existing  factory,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6411,add  support  influence  available  machine  learning  setting  training  component  quite  setting  influence  training  classification  model  currenlty  difficult  control  setting  many  changed  recompiling  improve  situation  user  able  pas  object  contains  machine  learning  setting  various  train  method  command  line  interface  extended  accept  property  file  contains  machine  learning  setting  setting  also  contain  training  algorithm  enables  u  use  either  maxent  perceptron  component  solution  implemented  discussed  thread  httpmailarchivesapacheorgmodmboxincubatoropennlpdev201105mbox3c4dd284da1000900gmailcom3e,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6412,add  extra  information  documentsample  often  document  additional  information  field  title  sender  date  key  word  add  field  documentsample  store  information  change  api  way  user  could  implement  feature  generator  using  information,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6413,remove  deprecated  iteration  cutoff  params  deprecated  iteration  cutoff  parameter  replaced  property  file  trainingparameters  object  contain  necessary  parameter  certain  machine  learning  implementation  remove  deprecated  api  still  using  also  remove  parameter  command  line  interface,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6414,refactor  gi  trainer  integration  gi  code  never  reshaped  fit  properly  new  training  api  couple  issue  eg  using  parameter  fixed  todo  update  description  list  change,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6415,move  arvores  deitadas  format  class  sub  package  arvores  deitadas  class  moved  sub  package  opennlptoolsformats  package  eg  formatsad  class  added  150  release  moving  break  backward  compatibility,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6416,unify  code  sum  input  context  feature  code  sum  input  feature  mal  package  duplicated  unified  util  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6417,deprecate  method  take  list  chunker  interface  method  chunker  interface  take  list  deprecated,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6418,add  ontonotes  format  support  add  native  format  support  ontonotes  opennlp  possible  train  po  tagger  parser  name  finder  ontonotes  data,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
6419,refactor  perceptrontrainer  class  address  couple  problem  changed  update  actual  perceptron  update  label  gold  label  chosen  event  parameter  associated  label  decremented  parameter  associated  gold  label  incremented  checked  empirically  several  datasets  work  better  previous  update  involves  fewer  update  stepsize  decreased  stepsize105  every  iteration  ensuring  better  stability  toward  end  training  actually  main  reason  training  set  accuracy  obtained  parameter  update  continued  different  computed  parameter  arent  updated  parameter  dont  jump  much  later  iteration  thing  settle  two  accuracy  converge  enough  iteration  allowed  training  set  accuracy  computed  per  iteration  training  stop  current  training  set  accuracy  change  le  given  tolerance  accuracy  obtained  previous  three  iteration  averaging  done  differently  rather  immediate  update  parameter  simply  accumulated  iteration  make  code  much  easier  understandmaintain  also  every  iteration  used  tends  give  much  weight  final  iteration  dont  actually  differ  much  one  another  tried  thing  found  simple  method  work  well  sum  parameter  first  20  iteration  sum  parameter  iteration  perfect  square  25  36  49  etc  get  good  diverse  sample  parameter  averaging  since  distance  subsequent  parameter  set  get  larger  number  iteration  get  bigger  added  listeventstream  make  stream  listevent  added  helper  method  eg  maxindex  simplify  code  main  algorithm  training  stats  arent  shown  every  iteration  first  10  every  10th  iteration  modeldistribution  params  evalparams  others  longer  class  variable  pushed  findparameters  method  variable  couldshould  made  nonglobal  leaving,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6420,adding  new  functionality  know  possible  lemma  given  word  po  tag  pair  currently  various  lemmatizers  dictionarylemmatizer  lemmatizerme  morfologiklemmatizer  allow  obtain  posible  lemma  given  word  postag  pair  functionality  useful  added,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6421,probabilistic  lemmatizer  current  simplelemmatizer  dictionarybased  probabilistic  lemmatizer  work  better  unknown  word  combined  dictionary  method  implement  based  grzegorz  chrupała  2008  towards  machinelearning  architecture  lexical  functional  grammar  parsing  phd  dissertation  dublin  city  university  httpgrzegorzchrupalamepapersphdsinglepdf,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6422,make  eos  character  set  configurable  currently  eos  symbol  used  sentence  detector  cannot  configured  moment  user  would  make  change  opennlptoolssentdetectlangfactory  since  important  use  eos  symbol  training  testingprediction  eos  symbol  stored  model  property,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6423,add  perceptron  sequence  training  support  name  finder  name  finder  also  support  perceptron  sequence  training,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6424,use  object  value  trainingparameters  instead  string  worked  opennlp1032  realized  trainingparameters  manages  parameter  mapstringstring  user  set  int  parameter  like  code  trainparamputname  100  code  look  like  code  trainparamputname  100  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6425,dictionary  implement  serializableartifact  dictionary  implement  interface  use  new  robust  serialization  mechanism,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6426,use  stupid  backoff  default  ngramlanguagemodel  ngramlanguagemodel  already  using  stupid  backoffhttpwwwaclweborganthologyd071090pdf  discounting  contains  1m  ngrams  however  since  good  performance  laplace  smoothing  smaller  model  itd  better  simply  use  stupid  backoff  case,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6427,name  finder  sequence  validator  configurable  via  api  name  finder  us  sequence  validator  create  valid  name  sequence  user  might  want  restrict  possible  sequence  purpose  necessary  pas  custom  sequence  validator  name  finder  constructor  extended  accept  custom  user  defined  sequence  validator  make  current  sequence  validator  public,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6428,add  concatenate  stream  method  collection  stream  minor  change  opennlptoolsutilobjectstreamutls  first  change  signature  createobjectstreamfinal  objectstreamt  stream  concatenateobjectstreamfinal  objectstreamt  stream  add  method  concatenateobjectstreamfinal  collectionobjectstreamt  stream  reason  behind  often  pull  data  multiple  file  whereas  possible  create  array  objectstreams  easier  work  list  also  name  method  clearer  concatenates  listarray  objectstreams  opposed  createobjectstreamfinal  collectiont  collection  make  obectstream  item  collection,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6429,remove  deprecated  leipzig  doccat  format  support,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6430,error  message  command  line  argument  introduced  command  line  tool  command  line  tool  report  error  message  resorting  always  showing  help  bit  confusing  attached  patch  improves,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6431,chunker  output  chunk  also  span  chunker  currently  take  string  array  input  output  tag  input  string  interface  extended  way  output  array  span  instead  span  contains  type  beginend  offset  input  array  like  name  finder  like  done  chunksamplegetphrasesasspanlist,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6432,feature  cutoff  done  data  indexer  currently  data  indexer  maxent  training  code  cutoff  feature  feature  cutoff  removed  maxent  training  code  done  data  indexer,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0
6433,add  support  custom  feature  generator  configuration  embedded  model  package  add  support  custom  feature  generator  configuration  embedded  model  package  configuration  feature  generator  name  finder  component  quite  complex  configuration  must  always  done  twice  training  tagging  twice  two  different  point  time  make  feature  generation  error  prone  small  mistake  lead  drop  detection  performance  might  difficult  notice  solve  issue  add  configuration  model  must  specified  training  loaded  model  tagging  another  advantage  custom  feature  generation  difficult  use  otherwise  integration  code  must  deal  setting  feature  generator  case  user  even  control  code  want  change  eg  uima  wrapper  logic  used  po  tagger  chunker  issue  migrated  sourceforge  httpssourceforgenettrackerfuncdetailaid1941380groupid3368atid353368,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6434,remove  pmap  indirection  via  int  mapping  currently  hot  loop  classifier  use  mapping  string  int  context  reduced  direct  mapping  string  context  increase  performance  2  10  maxent  depending  component,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6435,restore  abbreviation  dictionary  support  sentencedetector  today  abbreviation  dictionary  feature  sentencedetector  usable  though  api  add  mechanism  allow  training  abbreviation  dictionary  command  line  also  add  dictionary  model  po  tagger,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6436,optimize  xml  parser  configuration,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6437,add  l1regularization  lbfgs  l1regularization  useful  training  maximum  entropy  model  since  push  parameter  irrelevant  feature  zero  hence  parameter  vector  sparse  trained  model  compact  number  feature  much  larger  number  training  example  l1  often  give  better  accuracy  l2  implementation  l1regularization  lbfgs  follow  method  described  paper  httpresearchmicrosoftcomenusumpeoplejfgaopapericml07scalablepdf,1,0,1,0,1,0,0,1,1,0,1,0,0,0,0,1,1
6438,add  validate  check  validity  parameter  process  framework  worked  opennlp1039  saw  client  code  throw  illegalargumentexception  isvalid  return  false  think  kind  method  throw  exception  timing  use  controlled  framework  look  like  code  public  abstract  class  abstracttrainer  depracated  public  boolean  isvalid  subclass  override  call  supervalidate  public  void  validate  throw  illegalargumentexception  default  implementation  controller  flow  training  public  final  void  train  initializing  init  validating  parameter  validate  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6439,remove  deprecated  gi  class,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6440,organize  import  according  new  order  would  nice  code  base  enforce  via  checkstyle  tell  people  make  sure  ide  configured  correctly  everything  fine,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6441,brat  document  parser  support  name  type  filter  brat  document  parser  fails  span  overlap  sometimes  interested  type  case  could  ignore  overlapping  interest,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6442,extend  eval  test  run  ml  algorithm,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6443,add  abbreviation  dictionary  support  tokenizer  tokenizer  component  take  advantage  using  abbreviation  dictionary  context  generator  although  modifies  default  tokenizer  context  generator  wont  break  compatibility  old  model  feature  would  applied  dictionary  present,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6444,create  eval  test  lemmatizer  two  evaluation  test  lemmatizer  train  spanish  ud  corpus  measure  accuracy  load  180  model  test  leipzig  corpus,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6445,write  test  posdictionary  test  case  sensitiveinsensitive  flag  test  part  existing  posdictionarytest  class  test  following  loading  xml  dict  case  sensitive  flag  work  case  writing  dictionary  tag  serialized  correctly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6446,refactor  chunksample  class  class  need  improvement  1  internally  work  list  method  output  array  always  making  list  array  conversion  better  work  array  directly  2  create  static  method  create  span  phrase  chunk  3  add  javadoc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6447,move  arraymath  general  package  opennlp1195  joern  mentioned  quote  usage  argmax  opennlp  source  code  propose  create  one  common  method  try  use  one  could  move  arraymath  general  package  place  common  method  keep  existing  one  quote  want  solve  opennlp1195,1,1,1,0,1,1,0,0,0,0,0,0,0,0,0,0,0
6448,replace  reference  deprecated  namefindermetrain  replace  reference  deprecated  namefindermetrain  remove  deprecated  method,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6449,make  sequence  codec  name  finder  configurable  name  finder  ability  change  sequence  codec  name  finder  us  default  iob2  possible  use  codecs  bilou  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6450,add  test  data  verification  test  opennlptoolseval  add  test  data  verification  test  opennlptoolseval  class  verify  test  data  prior  executing  test  class,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
6451,refactor  bratnamesamplestream  create  bratannotationparser  par  bratdocument  creates  listnamesample  namesamplestreamread  method  would  call  directly  consider  making  change  format  well,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6452,add  cmdline  interface  entity  linker  entity  linker  command  line  interface  command  line  tool  capable  running  entity  linker  sample  data,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6453,addition  prepositional  phrase  attachment  dataset  unit  test  obtained  permission  adwait  ratnaparkhi  include  prepositional  phrase  attachment  dataset  distribution  test  case  jorn  correctly  point  need  see  whether  asf  compliant  original  dataset  httpsitesgooglecomsiteadwaitratnaparkhipublicationsppatargzattredirects0,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6454,improve  resource  loading  custom  feature  generator  currently  feature  generator  matched  tokennamefindertool  part  cmd  line  interface  improve  logic  moved  generatorfactory,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6455,add  training  format  support  brat  format  brat  rapid  annotation  tool  defines  format  store  annotation  would  nice  format  support  directly  train  opennlp  brat  format  information  tool  found  httpbratnlplaborg,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6456,support  skewed  outer  join  similarly  skewed  inner  join  skewed  outer  join  help  scale  presense  join  key  dont  fit  memory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6457,optimize  nested  distinctsort  use  secondary  key  nested  foreach  plan  contains  sortdistinct  possible  use  hadoop  secondary  sort  instead  sorteddatabag  distinctdatabag  optimize  query  eg1  load  mydata  b  group  0  c  foreach  b  order  1  generate  group  store  c  myresult  specify  secondary  sort  a1  drop  order  1  eg2  load  mydata  b  group  0  c  foreach  b  a1  e  distinct  generate  group  e  store  c  myresult  specify  secondary  sort  key  a1  simplify  da1  edistinct  special  version  distinct  sorting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6458,integration  hadoop  20  new  api  hadoop  21  yet  released  know  switch  new  mr  api  coming  jira  early  integration  portion  api  implemented  hadoop  20,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
6459,zebra  support  recordrowbased  file  split  zebra  tableinputformat  tfile  currently  support  split  record  sequence  number  see  jira  hadoop6218  want  utilize  provide  recordrowbased  input  split  support  zebra  one  prominent  benefit  case  large  data  file  create  much  finegrained  input  split  create  one  big  split  one  big  file  detail  new  rowbased  getsplits  work  default  user  specify  split  generated  follows  1  select  biggest  column  group  term  data  size  split  tfiles  according  hdfs  block  size  64  mb  128  mb  get  list  physical  byte  offset  output  per  tfile  example  let  u  assume  1st  tfile  get  offset1  offset2  offset10  2  invoke  tfilegetrecordnumnearlong  offset  get  recordnum  keyvalue  pair  near  byte  offset  example  say  get  recordnum1  recordnum2  recordnum10  3  stitch  0  recordnum1  recordnum11  recordnum2  recordnum91  recordnum10  recordnum101  lastrecordnum  split  column  group  respectively  form  11  recordbased  input  split  1st  tfile  4  input  split  need  create  tfile  scanner  tfilecreatescannerbyrecordnumlong  beginrecnum  long  endrecnum  note  conversion  byte  offset  record  number  done  mapper  rather  done  job  initialization  phase  due  performance  concern  since  conversion  incurs  tfile  reading  overhead,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,1
6460,zebra  zebra  performance  optimization  many  incore  performance  optimization  opportunity  exist  zebra  removal  redundant  precautionary  check  use  better  collection  type  reduce  level  indirection  memory  object  changing  input  split  ascending  size  descending  size  observed  improvement  wall  clock  time  pig  load  query  around  10,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6461,zebra  provide  streaming  support  zebra  hadoop  streaming  popular  among  hadoop  user  main  attraction  simplicity  use  user  write  application  logic  language  process  large  amount  data  using  hadoop  framework  people  start  use  zebra  store  data  expect  user  would  like  run  hadoop  streaming  script  easily  process  zebra  table  following  list  simple  example  using  hadoop  streaming  access  zebra  data  load  data  foo  table  using  zebra  tableinputformat  writes  data  output  using  default  textoutputformat  hadoop  jar  hadoopstreamingjar  mapredreducetasks0  input  foo  output  output  mapper  cat  inputformat  orgapachehadoopzebramapredtableinputformat  detailed  zebra  us  pig  defaulttuple  implementation  tuple  record  currently  zebra  tableinputformat  used  input  user  script  see  line  containing  keyifanyttupletostring  plan  generate  csv  format  representation  pig  tuples  end  plan  following  1  derive  sub  class  zupletuple  pig  defaulttuple  class  override  tostring  method  present  data  csv  format  2  zebra  side  tuple  factory  changed  create  zebratuple  object  instead  defaulttuple  object  note  support  streaming  input  side  ability  use  streaming  read  data  zebra  table  output  side  streaming  support  feasible  since  streaming  mapper  reducer  emits  textttext  output  collector  way  knowing  convert  byteswritabletuple,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6462,zebra  use  hadoop  20  apis  currently  zebra  still  using  already  deprecated  hadoop  18  apis  need  upgrade  20  apis,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6463,logicalplan  optimizer  complex  hard  work  current  implementation  logical  plan  logical  optimizer  pig  proven  easily  extensible  developer  feedback  indicated  adding  new  rule  optimizer  quite  burdensome  addition  logical  plan  area  numerous  bug  many  difficult  fix  developer  also  feel  logical  plan  difficult  understand  maintain  root  cause  issue  number  design  decision  made  part  02  rewrite  front  end  proven  suboptimal  heart  proposal  revisit  number  proposal  rebuild  logical  plan  simpler  design  make  much  easier  maintain  logical  plan  well  extend  logical  optimizer  see  httpwikiapacheorgpigpiglogicalplanoptimizerrewrite  full  detail,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6464,zebra  performance  improvement  current  input  split  generation  rowbased  split  individual  tfiles  leaf  undesired  fact  even  tfiles  smaller  one  block  one  split  still  generated  consequently  many  mapper  many  wave  needed  handle  many  small  tfiles  generated  many  mappersreducers  wrote  data  issue  addressed  generating  input  split  include  multiple  tfiles  sorted  table  key  distribution  generation  table  used  generated  proper  input  split  includes  key  distribution  column  group  even  projection  incurs  extra  cost  perform  unnecessary  computation  inappropriately  creates  unreasonable  result  input  split  generation  unsorted  table  row  split  generated  union  table  filesplits  generated  table  lumped  together  form  final  list  split  mapreduce  undesirable  fact  number  split  subject  number  table  table  union  controlled  number  split  used  mapreduce  framework  input  split  goal  size  calculated  column  group  even  projection  input  split  multiple  file  one  column  group  file  opened  startup  unnecessary  take  unnecessarily  resource  start  end  file  opened  needed  closed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6465,pig  script  run  half  way  report  syntax  error  pig  script  structured  following  way  code  register  cpjar  dataset  load  datadataset  using  pigstorageu0001  col1  col2  col3  col4  col5  filtereddataset  filter  dataset  col1  1  projfiltereddataset  foreach  filtereddataset  generate  col2  col3  rmf  output1  store  projfiltereddataset  output1  using  pigstorage  secondstream  foreach  filtereddataset  generate  col2  col4  col5  groupsecondstream  group  secondstream  col4  output2  foreach  groupsecondstream  secondstreamcol2  b  distinct  secondstreamcol5  c  order  b  0  generate  1  key  group  keyword  myudfc  100  finalcalc  rmf  output2  syntax  error  store  output2  output2  using  pigstorage  code  run  script  using  multiquery  option  run  successfully  till  first  store  later  fails  syntax  error  usage  hdfs  option  rmf  cause  first  store  execute  option  run  explain  running  script  grunt  explain  script  myscriptpig  explainout  moving  rmf  statement  top  script  question  option  something  like  checkscript  instead  explain  get  syntax  error  way  ensure  run  34  hour  encountering  syntax  error  b  pig  figure  way  reorder  rmf  statement  since  store  directory  variable  thanks  viraj,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6466,use  distributed  cache  store  sample  currently  case  skew  join  order  use  sample  written  dfs  distributed  cache  result  get  opened  copied  around  necessary  impact  query  performance  also  place  unnecesary  load  name  node,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6467,binary  comparator  secondary  sort  hadoop  framework  sorting  try  use  binary  version  comparator  available  benefit  binary  comparator  need  instantiate  object  compare  see  30  speedup  switch  binary  comparator  currently  pig  use  binary  comparator  following  case  1  semantics  order  doesnt  matter  example  distinct  need  sort  order  filter  duplicate  value  however  care  comparator  sort  key  groupby  also  share  character  case  rely  hadoops  default  binary  comparator  2  semantics  order  matter  key  simple  type  case  implementation  simple  type  integer  long  float  chararray  databytearray  string  however  key  tuple  sort  semantics  matter  binary  comparator  implementation  especially  matter  switch  use  secondary  sort  secondary  sort  convert  inner  sort  nested  foreach  secondary  key  rely  hadoop  sorting  main  key  secondary  key  sorting  key  become  two  item  tuple  since  secondary  key  sorting  key  nested  foreach  sorting  semantics  matter  turn  binary  comparator  use  secondary  sort  see  significant  slow  binary  comparator  tuple  doable  understand  binary  structure  serialized  tuple  focus  common  use  case  first  group  followed  nested  sort  case  use  secondary  sort  semantics  first  key  matter  semantics  secondary  key  matter  need  identify  boundary  main  key  secondary  key  binary  tuple  buffer  without  instantiate  tuple  first  key  equal  use  binary  comparator  compare  secondary  key  secondary  key  also  complex  data  type  first  step  focus  simple  secondary  key  common  use  case  mark  issue  candidate  project  google  summer  code  2010  program,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6468,zebra  support  locally  sorted  input  split  current  zebra  support  sorted  unsorted  input  split  sorted  table  sorted  table  union  sorted  input  split  based  upon  key  range  overlap  split  basically  globally  sorted  locally  sorted  key  range  overlap  biggest  problem  keyrange  split  performance  hit  suffered  data  skew  present  particularly  key  range  contains  duplicate  key  solely  make  data  trunk  duplicate  key  virtually  unsplittable  regardless  many  mapper  available  processed  single  mapper  hand  scenario  globally  sorted  split  overkill  locally  sorted  split  good  enough  example  use  zebra  sorted  table  probe  table  mapside  merge  inner  join,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6469,api  interface  pig  would  nice  make  pig  friendly  application  like  workflow  would  executing  pig  script  user  behalf  currently  would  use  pig  command  line  execute  code  however  limitation  kind  output  would  delivered  instance  hard  produce  error  information  easy  use  programatically  collect  statistic  proposal  create  class  mimic  behavior  main  give  user  status  object  back  main  code  pig  would  look  somethig  like  public  static  void  mainstring  args  pigstatus  p  pigmainexecargs  exit  pigstatusrc  need  define  following  content  pigstatus  least  include  return  code  error  string  exception  statistic  way  propagate  status  class  pig  code,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
6470,pig  exclude  hadoop  conf  local  mode  currently  behavior  hadoop  conf  look  local  mode  hadoop  conf  bail  hadoop  conf  launch  local  mode  hadoop  mode  hadoop  conf  use  conf  launch  pig  still  launch  without  warning  many  functionality  go  wrong  bring  intuitive  way  local  mode  always  launch  pig  local  mode  hadoop  mode  hadoop  conf  use  conf  launch  pig  bail  meaningful  message,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6471,zebra  avoid  making  unnecessary  name  node  call  writes  zebra  currently  table  column  group  level  meta  data  extracted  job  configuration  object  written  onto  hdfs  disk  within  checkoutputspec  later  writer  back  end  open  file  access  meta  data  writes  put  extra  load  name  node  since  writer  need  make  name  node  call  open  file  propose  following  approach  problem  writer  back  end  extract  meta  information  job  configuration  object  directly  rather  making  name  node  call  going  hdfs  disk  fetch  information,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6472,zebra  type  check  write  basic  table  zebra  type  check  writing  basic  table  say  schema  f1int  f2string  however  write  tuple  abc  123  without  problem  definitely  desirable  overcome  problem  decide  perform  certain  amount  type  checking  zebra  check  first  row  writer  serf  sanity  check  purpose  case  user  screw  specifying  output  schema  perform  rigorous  type  checking  row  apparently  performance  concern,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6473,mapside  outer  join  pig  already  couple  mapside  join  implementation  merge  join  fragmentedreplicate  join  pretty  restrictive  merge  join  join  two  table  inner  join  fr  join  join  multiple  relation  also  inner  left  outer  join  restricts  size  side  relation  nice  map  side  join  multiple  table  well  inner  left  outer  right  outer  full  outer  join  lot  groundwork  already  done  pig1309  remaining  tracked  jira,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6474,zebra  support  writing  multiple  zebra  table  pig  zebra  already  multiple  output  support  mapreduce  support  feature  user  use  zebra  pig  jira  address  issue  plan  support  writing  multiple  output  table  pig  well  propose  support  following  pig  store  statement  multiple  output  store  relation  loc1loc2loc3  using  orgapachehadoopzebrapigtablestorerstoragehintstring  complete  name  custom  partition  class  argument  partition  class  certain  partition  class  argument  needed  store  relation  loc1loc2loc3  using  orgapachehadoopzebrapigtablestorerstoragehintstring  complete  name  custom  partition  class  partition  class  argument  needed  note  user  need  specify  three  argument  storage  hint  string  complete  name  partition  class  partition  class  argument  string,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6475,need  way  pig  take  alternative  property  file  currently  pig  read  first  ever  pigproperties  classpath  pig  default  pigproperties  user  different  pigproperties  conflict  since  read  one  couple  way  solve  1  give  command  line  option  user  pas  additional  property  file  2  change  name  default  pigproperties  pigdefaultproperties  user  give  pigproperties  override  3  consider  use  pigdefaultxmlpigsitexml  seems  natural  hadoop  community  shall  provide  backward  compatibility  also  read  pigproperties  pigclusterhadoopsitexml,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6476,implement  pig  counter  track  number  row  input  file  mr  job  generated  pig  multiple  output  case  multiquery  also  multiple  input  case  join  cogroup  case  existing  hadoop  counter  eg  mapinputrecords  reduceoutputrecords  used  count  number  record  given  input  output  pig1299  addressed  case  multiple  output  need  add  new  counter  job  multiple  input,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6477,allow  casting  relation  scalar  jira  implement  simplified  version  functionality  described  httpsissuesapacheorgjirabrowsepig801  proposal  allow  casting  relation  scalar  type  foreach  example  load  data  x  z  b  group  c  foreach  b  generate  counta  x  foreach  x  generate  1long  c  couple  additional  comment  1  cast  relation  including  single  value  error  reported  2  name  resolution  needed  since  relation  x  might  field  named  c  case  field  take  precedence  3  look  c  closest  implementation  thought  idea  store  c  file  convert  scalar  via  udf  believe  already  udf  ben  reed  contributed  purpose  work  would  update  logical  plan  1  store  c  2  convert  cast  udf,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6478,consider  clean  backend  code  prior  07  pig  local  execution  mode  addition  hadoop  map  reduce  execution  mode  support  two  different  execution  mode  pig  implemented  abstraction  layer  set  interface  abstract  class  pig  07  replaced  local  mode  hadoop  local  mode  made  abstraction  layer  redundant  goal  remove  extra  code  need  also  keep  code  backward  compatible  since  interface  exposed  toplevel  api  propose  first  step  deprecate  method  filelocalizer  datastorage  parameter  remove  execphysicaloperator  execphysicalplan  execscopedlogicaloperator  executionengine  utilexectools  orgapachepigbackendexecutionengine  package,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6479,optimize  serializationdeserialization  map  reduce  mr  job  certain  type  pig  query  execution  time  spent  serializingdeserializing  sedes  record  map  reduce  mr  job  example  pigmix  query  modified  specify  type  field  load  statement  schema  query  l2l3l9  l10  pigmix  v1  record  bag  map  transmitted  across  map  reduce  boundary  run  lot  longer  runtime  increase  time  seen  optimization  shown  improve  performance  sedes  test  1  use  smaller  number  byte  store  length  column  example  bytearray  smaller  255  byte  byte  used  store  length  instead  integer  currently  used  2  instead  custom  code  sedes  string  use  dataoutputwriteutf  datainputreadutf  reduces  cost  serialization  12  zebra  binstorage  known  use  defaulttuple  sedes  functionality  serialization  format  loader  use  cannot  change  optimization  format  going  different  format  used  mr  boundary,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
6480,embed  pig  scripting  language  possible  embed  pig  call  scripting  language  let  function  defined  script  available  udfs  spin  httpsissuesapacheorgjirabrowsepig928  let  user  define  udfs  scripting  language,0,0,0,0,0,0,0,0,0,1,0,0,0,1,1,0,1
6481,multi  file  input  format  loader  frequently  run  situation  pig  need  deal  small  file  input  case  separate  map  created  file  could  inefficient  would  greate  umbrella  input  format  take  multiple  file  use  single  split  would  like  see  working  different  data  format  possible  already  couple  input  format  similar  thing  multifileinputformat  well  combinedinputformat  howevere  neither  work  ne  hadoop  20  api  least  want  feasibility  study  pig  080,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6482,optimize  scalar  consolidate  part  file  current  scalar  implementation  write  scalar  file  onto  dfs  pig  need  scalar  open  dfs  file  directly  scalar  file  contains  one  part  file  though  contains  one  record  put  huge  load  namenode  consolidate  part  file  open  another  optional  step  put  consolicated  file  distributed  cache  bring  load  namenode,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6483,switch  new  parser  generator  technology  many  bug  pig  related  parser  particularly  bad  error  message  review  java  cc  feel  difficult  address  using  tool  also  jjt  file  used  javacc  hard  understand  maintain  antlr  reviewed  likely  choice  move  parser  reviewed  well  jira  act  umbrella  issue  parser  issue,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6484,suggest  allow  pigserver  register  pig  script  inputstream  currently  pig  allow  user  register  script  file  although  satisfy  people  requirement  sometimes  people  hope  build  pig  script  dynamically  using  code  need  create  temp  file  script  build  suggest  allow  pigserver  able  register  pig  script  inputstream  inputstream  general  type  file  pig  script  file  fileinputstream  inmemory  bytearrayinputstream  even  remote  machine  socketinputstream  here  blog  explains  using  inputstream  better  using  file  interface  httpjavadzonecomarticlesusingfilesyourinterfaces0  suggest  add  following  4  method  pigserver  code  public  void  registerscriptinputstream  throw  ioexception  public  void  registerscriptinputstream  mapstringstring  params  throw  ioexception  public  void  registerscriptinputstream  liststring  paramsfiles  throw  ioexception  public  void  registerscriptinputstream  mapstringstring  paramsliststring  paramsfiles  throw  ioexception  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6485,support  projectrange  expression  need  way  foreach  indicate  rest  field  common  use  case  see  pig  people  many  column  data  want  operate  consider  example  storing  data  ten  column  user  want  perform  cast  one  column  code  z  foreach  generate  intfirstcol  secondcol  thridcol  forthcol  fifthcol  sixthcol  seventhcol  eigthcol  ninethcol  tenthcol  store  z  output  code  obviously  get  worse  user  column  ideally  could  transformed  something  like  code  z  foreach  generate  intfirstcol  rest  store  z  output  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6486,update  pig  parser  function  argument  contain  newline  character  want  add  feature  user  put  long  function  argument  string  multiple  line  pig1748  depends,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6487,clean  duplicated  code  physical  operator  lot  getnext  implementation  physicaloperators  copypasted  method  signature  cast  changing  shorter  code  lead  le  bug  easier  read,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6488,removal  old  logical  plan  new  logical  plan  used  old  logical  plan  removed  new  one  stable  enough  scheduled  09  release,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,1
6489,add  macro  expansion  pig  latin  production  pig  script  grow  longer  longer  pig  latin  need  integrate  standard  programming  technique  separation  code  sharing  offered  function  module  proposal  adding  macro  expansion  pig  latin  posted  httpwikiapacheorgpigturingcompletepig  brief  summary  proposed  syntax  example  macro  definition  existing  define  keyword  expanded  allow  definition  pig  macro  syntax  code  define  name  params  return  alias  pig  latin  fragment  code  example  code  define  mymacroa  sortkey  return  c  b  filter  myfilter  c  order  b  sortkey  code  macro  expansion  syntax  code  alias  macro  name  params  code  example  use  macro  pig  script  code  x  load  foo  user  address  phone  mymacrox  user  store  bar  code  script  expanded  following  pig  latin  statement  code  x  load  foo  user  address  phone  macromymacrob1  filter  x  myfilter  order  macromymacrob1  user  store  bar  code  note  1  alias  macro  isnt  visible  outside  prefixed  macro  name  suffixed  instance  id  avoid  namespace  collision  2  macro  expansion  complete  replacement  function  call  recursive  expansion  supported  macro  import  new  import  keyword  used  add  macro  defined  another  pig  latin  file  syntax  code  import  pig  latin  file  name  code  example  code  import  mymacropig  code  note  macro  name  global  namespace,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6490,javascript  support  pig  embedding  udfs  scripting  language  attached  patch  proposes  javascript  implementation  pig  embedding  udfs  scripting  language  similar  jython  implementation  us  rhino  provided  jdk  difference  output  schema  provided  functionnameoutschemaschema  javascript  annotation  decorator  function  first  class  object  tuples  converted  object  using  input  schema  way  around  using  output  schema  attached  patch  final  yet  particular  lack  unit  test  see  testorgapachepigtestdatatcjs  transitive  closure  example  see  following  jiras  context  httpsissuesapacheorgjirabrowsepig928  httpsissuesapacheorgjirabrowsepig1479,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6491,ability  turn  write  ahead  log  pig  hbasestorage  added  option  allow  caller  hbasestorage  turn  writeaheadlog  feature  bulk  load  hbase  performance  tuning  wikipage  httpwikiapacheorghadoopperformancetuning  speed  insert  non  critical  job  like  import  job  use  putwritetowalfalse  bypass  writing  write  ahead  log  weve  tested  hbase  0206  help  dramatically  nowal  option  passed  like  option  hbase  storage  store  myalias  mytable  using  orgapachepigbackendhadoophbasehbasestoragemycolumnfamilyfield1  mycolumnfamilyfield2nowal  would  first  patch  please  educate  step  need,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6492,0  value  seen  pigstats  mapreduce  runtime  even  job  successful  pig  runtime  call  jobclientgetmaptaskreportsjobid  jobclientgetreducetaskreportsjobid  get  statistic  number  mapsreducers  well  maxminavg  time  task  time  time  call  return  empty  list  happens  pig  report  0  value  stats  jobtracker  keep  stats  information  limited  duration  based  configuration  parameter  mapredjobtrackercompleteuserjobsmaximum  mapredjobtrackerretiredjobscachesize  since  pig  collect  stats  job  finished  running  possible  stats  initial  job  longer  available  better  chance  getting  stats  collected  soon  job,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6493,typed  map  pig  currently  pig  map  type  untyped  mean  map  value  always  bytearrayie  unknown  type  pig1277  allow  unknown  type  shuffle  key  somewhat  relieve  problem  however  typed  map  still  beneficial  1  user  make  semantic  use  map  value  type  currently  user  need  explicitly  cast  map  value  ugly  2  though  pig1277  allow  unknown  type  shuffle  key  performance  suffers  dont  raw  comparator  unknown  type  instead  need  instantiate  value  object  invoke  comparator  proposed  syntax  typed  map  maptype  typed  map  used  place  untyped  map  could  occur  example  load  1txt  asmapint  b  foreach  generate  mapiinta0  map  value  tuple  b  stream  cat  mmapiintjchararray  map  value  bag  maplookup  typed  map  result  datatype  map  value  load  1txt  asmapint  b  foreach  generate  0key  schema  b  b  int  behavior  untyped  map  remain,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6494,need  special  interface  penny  inspector  gadget  proposed  penny  tool  need  access  pig  new  logical  plan  order  inject  code  dataflow  modified  plan  need  able  hand  back  modified  plan  pig  execute  dont  want  open  functionality  general  user  proposal  subclass  pigserver  new  class  marked  limitedprivate  penny  class  provide  call  parse  pig  latin  script  return  logical  plan  one  take  logical  plan  execute,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6495,support  projectrange  udf  argument  change  pig1693  projectrange  supported  use  case  projectstar  supported  except  udf  argument  consistent  usage  projectstar  projectrange  supported  udf  argument  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6496,hbasestorage  constructor  syntax  error  prone  using  hbasestorage  like  seems  like  reasonable  thing  yield  unexpected  result  code  store  result  hbasefoo  using  orgapachepigbackendhadoophbasehbasestorage  infofirstname  infolastname  code  problem  u  column  named  infofirstname  created  trailing  comma  included  ive  numerous  developer  get  tripped  issue  since  everywhere  else  pig  variable  separated  comma  propose  fix  propose  trim  leadingtrailing  comma  column  name  im  open  idea  also  accept  column  name  commandelimited  without  space,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6497,allow  macro  return  void  pig  macro  allowed  output  alias  property  isnt  clear  macro  definition  macro  invocation  macro  inline  propose  make  clear  1  macro  doesnt  output  alias  must  specify  void  return  value  example  code  define  mymacro  return  void  code  2  macro  doesnt  output  alias  must  invoked  without  return  value  example  invoke  macro  specify  code  mymacro  code  3  nonvoid  return  alias  macro  definition  must  exist  macro  body  prefixed  example  code  define  mymacro  return  b  b  filter  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6498,bundle  registered  jar  via  distributed  cache  currently  registered  jar  get  collapsed  single  job  megajar  get  submitted  hadoop  better  pattern  would  take  advantage  distributed  cache,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6499,make  pig  work  hadoop  next  need  make  pig  work  hadoop  next  svn  branch  currently  httpssvnapacheorgreposasfhadoopcommonbranchesmr279,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
6500,allow  registering  multiple  jar  dfs  via  single  statement  pig  currently  allows  user  register  jar  local  remote  filesystems  one  jar  specified  time  would  great  able  say  something  along  line  register  hdfsusermeliblucenejar  get  jar  registered  one  go,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6501,make  pigstorage  optionally  store  schema  improve  doc  id  like  propose  allow  greater  degree  customization  pigstorage  incomplete  list  feature  might  want  add  flag  tell  overwrite  existing  output  exists  flag  tell  compress  output  using  gzipbziplzo  currently  achieved  setting  directory  name  end  gz  bz2  bit  awkward  flag  tell  store  schema  header  perhaps  merging  pigstorageschema  work,1,1,1,0,1,1,0,0,1,0,1,1,1,0,0,0,0
6502,improve  nested  cross  stream  one  relation  pig1916  added  nested  cross  support  pig  one  optimization  instead  materialize  bag  producing  result  stream  one  input  save  memory,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6503,add  append  support  databytearray  recently  writing  udf  use  databytearray  similar  concat  thought  would  convenient  dba  supported  append  option  similar  appendable  also  string  together  wish  dbaappendfooappendbar,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6504,support  partial  aggregation  map  task  h3  introduction  pig  sort  based  partial  aggregation  map  side  use  combiner  mr  serializes  output  map  buffer  sort  key  deserializes  pass  value  grouped  key  combiner  phase  work  combiner  done  map  phase  using  hashmap  key  hash  based  partial  aggregation  done  without  combiner  phase  h3  benefit  send  fewer  record  combiner  thereby  save  cost  serializing  deserializing  save  cost  lock  call  combiner  input  buffer  found  significant  cost  query  multiple  groupbys  single  mr  job  thejas  problem  running  memory  reduce  side  query  like  countdistinct  col  avoided  oom  issue  happens  large  record  get  created  combiner  run  merged  reduce  input  case  combiner  way  telling  mr  combine  record  reduce  side  workaround  disable  combiner  completely  opportunity  reduce  map  output  size  lost  foreach  groupby  algebraic  nonalgebraic  function  bag  projected  combiner  used  data  size  reduction  typical  case  significant  enough  justify  additional  deserialization  cost  hash  based  aggregation  used  case  well  possible  turn  inmap  combine  automatically  enough  combination  taking  place  justify  overhead  inmap  combiner  idea  borrowed  hive  jira  input  data  sorted  possible  efficient  map  side  partial  aggregation  inmap  combiner  design  proposal  httpscwikiapacheorgconfluencedisplaypigpiginmapcombinerproposal,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
6505,allow  compression  codec  specified  avrostorage  currently  possible  specify  deflate  would  useful  able  specify  snappy  avro  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6506,set  default  number  reducer  s3n  filesystem  currently  pig  estimate  default  reducer  based  input  file  size  hdfs  local  file  system  patch  add  support  s3n  file  system  well,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6507,support  efficient  tuples  schema  known  pig  tuples  significant  overhead  due  fact  field  object  tuple  contains  primitive  field  ints  longs  etc  possible  avoid  overhead  would  result  significant  memory  saving,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6508,reduce  code  duplication  sum  max  min  udfs  current  typespecific  implementation  max  min  sum  lot  duplicated  code  reduce  significantly,1,1,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0
6509,streaming  udfs  allow  user  easily  write  udfs  scripting  language  jvm  implementation  goal  streaming  udfs  allow  user  easily  write  udfs  scripting  language  jvm  implementation  limited  jvm  implementation  initial  proposal  outlined  httpscwikiapacheorgconfluencedisplaypigstreamingudfs  order  implement  need  new  syntax  distinguish  streaming  udf  embedded  jvm  udf  id  propose  something  like  following  although  im  sure  language  best  term  using  codedefine  mystreamingudfs  languagepython  shipmystreamingudfspycode  well  also  need  languagespecific  controller  script  get  shipped  cluster  responsible  reading  input  stream  deserializing  input  data  passing  user  written  script  serializing  script  output  writing  output  stream  finally  well  need  add  streamingudf  class  extends  evalfunc  class  likely  share  existing  code  postream  executablemanager  make  sense  pull  shared  code  stream  data  tofrom  controller  script  one  alternative  approach  creating  streamingudf  evalfunc  use  postream  operator  directly  would  involve  inserting  postream  operator  instead  pouserfunc  operator  whenever  encountered  streaming  udf  building  physical  plan  approach  seemed  problematic  would  need  lot  change  order  support  postream  place  want  able  use  udfs  example  operate  single  field  inside  statement,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0
6510,speed  testbuiltin  build  testbuiltin  take  4  minute  reason,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6511,make  reducer  estimator  plugable  id  like  refactor  logic  contained  method  pluggable  interface  noformat  static  int  jobcontrolcompilerestimatenumberofreducersconfiguration  conf  listpoload  lds  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6512,support  multiple  input  schema  avrostorage  barebones  patch  avrostorage  enables  support  multiple  input  schema  assumption  input  consists  avro  file  different  schema  unioned  eg  flat  record  simple  illustrative  example  attached  avrostorageunionschematesttargz  run  createavro1pig  followed  createavro2pig  followed  readavropig,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6513,add  source  location  alias  physical  plan  goal  provide  better  information  actually  running  job  particular  alias  name  reused  example  following  script  code  load  foo  using  pigstorage  b  group  0  foreach  b  generate  counta  store  bar  code  job  conf  contain  following  information  code  pigaliaslocation  a14a34b24  c  a34b24  r  a34  code  caveat  logical  plan  optimizer  throw  away  original  information  merging  logical  operator  already  case  today  pigalias,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6514,make  pig  unit  faciliities  generalizable  update  javadocs  ticket  two  goal  pig  unit  1  pig  unit  really  nice  method  assertoutputstring  inputalias  string  inputvalues  string  outputalias  string  expectedoutputvalues  method  let  override  input  alias  variable  hardcoded  list  value  way  script  doesnt  actually  read  input  variable  hdfs  cassandra  run  script  check  specified  output  alias  variable  expected  set  value  really  nice  way  test  entire  pig  script  single  method  call  script  exactly  1  input  1  output  want  test  complicated  script  jump  hoop  order  override  input  variable  would  fairly  easy  change  pigunit  override  number  input  check  number  output  easily  thats  basically  change  put  base  testing  class  wrote  would  better  push  pigunit  something  could  easily  done  afternoon  2  update  javadocs  pig  unit  test  class  make  readable,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6515,pretty  print  schema  currently  describe  dump  schema  one  line  long  complicated  schema  pretty  much  impossible  figure  schema  look  fileds  provide  example,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6516,improve  planhelper  allow  finding  physicaloperator  plan  planhelper  handy  method  finding  load  store  native  mr  operator  physicalplan  bit  refactoring  make  planhelper  find  physicaloperator  instead  hardcoding  po  find,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6517,add  recursive  record  support  avrostorage  currently  avrostorage  allow  recursive  record  avro  schema  possible  define  pig  schema  recursive  record  ie  record  selfreferencing  field  cause  infinite  loop  supported  even  though  natural  way  handling  recursive  record  pig  schema  id  like  propose  following  workaround  mapping  recursive  record  bytearray  take  example  following  avro  schema  code  type  record  name  recursiverecord  field  name  value  type  null  int  name  next  type  null  recursiverecord  code  following  data  code  value1nextrecursiverecordvalue2nextrecursiverecordvalue3nextnull  value2nextrecursiverecordvalue3nextnull  value3nextnull  code  define  pig  schema  follows  code  value  intnext  bytearray  code  even  though  pig  think  next  field  bytearray  theyre  actually  loaded  tuples  since  avrostorage  us  avro  schema  loading  file  code  grunt  load  testrecursiveschemaavro  using  orgapachepigpiggybankstorageavroavrostorage  grunt  dump  123  23  3  code  point  discrepancy  avro  schema  pig  schema  nevertheless  still  refer  field  tuples  follows  code  grunt  first  foreach  generate  0  grunt  dump  first  1  2  3  grunt  second  foreach  generate  10  grunt  dump  second  2  3  code  lastly  store  tuples  avro  file  specifying  schema  since  longer  construct  avro  schema  pig  schema  required  user  provide  avro  schema  via  schema  parameter  store  function  code  grunt  store  first  output  using  orgapachepigpiggybankstorageavroavrostorage  schema  null  int  grunt  store  output  using  orgapachepigpiggybankstorageavroavrostorage  schema  type  record  name  recursiveschema  field  name  value  type  null  int  name  next  type  null  recursiveschema  code  implement  workaround  following  work  required  update  current  generic  union  check  handle  recursive  record  currently  avrostorage  check  avro  schema  contains  1  recursive  record  2  generic  union  fails  since  going  remove  1st  check  2nd  check  able  handle  recursive  record  without  stack  overflow  update  avroschema2pig  recursive  record  detected  mapped  bytearrays  pig  schema  add  noschemacheck  parameter  store  function  result  stored  even  though  exists  discrepancy  avro  schema  pig  schema  since  avro  schema  store  function  cannot  constructed  pig  schema  specified  user  via  schema  parameter  schema  check  disabled  noschemacheck  update  avrostorage  wiki  add  unit  test  think  incompatibility  issue  introduced  p  reason  chose  map  recursive  record  bytearray  instead  empty  tuple  cannot  refer  field  use  empty  tuple  example  pig  schema  defined  follows  code  value  intnext  code  get  exception  attempt  refer  field  loaded  tuples  since  schema  defined  ie  empty  tuple  code  error  1127  index  0  range  schema  code  found  trial  error  might  something  missing  please  let  know  thanks,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6518,improve  performance  popartialagg  performance  testing  found  popartialagg  cause  performance  degradation  pig  job  algebraic  udfs  applied  arent  well  suited  operator  assumption  changing  implementation  flexible  hashbased  model  provide  significant  performance  improvement,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6519,add  function  read  schema  outout  schematostring  want  tostring  schema  send  backend  via  udfcontext  moment  requires  writing  tostring  method  utilsgetschemafromstring  read  making  readable  schema  backend  would  improvement  spoke  thejas  belief  bug  workaround  moment  example  string  schemastring  inputschematostringsubstring1  inputschematostringlength  1  set  input  schema  processing  udfcontext  context  udfcontextgetudfcontext  property  udfprop  contextgetudfpropertiesthisgetclass  udfpropsetpropertyhortonjsonudfschema  schemastring  schema  utilsgetschemafromstringstrschema,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6520,lazily  register  bag  spillablememorymanager  currently  spillable  databags  get  registered  bagfactory  moment  creation  practice  lot  bag  get  large  enough  worth  spilling  avoid  lot  memory  overhead  cheapen  process  finding  bag  spill  need  allowing  bag  register  grow  respectable  threshold  related  jiras  pig2917  pig2918,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6521,hbasestorage  filter  optimization  hbase  palguru  gary  helmling  kind  enough  code  review  hbasestorage  suggested  good  filter  optimization  using  lt  gt  option  set  startstop  row  scan  instance  least  addition  rowfilters  without  youre  full  table  scan  regardless  rowfilters  selecting  specific  column  entire  family  return  would  efficient  set  family  column  scan  object  addfamily  addcolumn  instead  using  filterlist  im  familiar  familyprefix  handling  mention  would  still  seem  require  filter  thats  used  would  better  avoid  filterlist  column  minimum  probably  call  scanaddfamily  distinct  family  skip  entire  column  family  used  case  table  4  cf  say  1  used  could  big  gain,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6522,modernize  chunk  test  lot  test  use  antiquated  pattern  goal  refactor  couple  way  get  rid  annotation  specifying  junit  4  use  junit  4  question  junit  3  dependency  even  pulled  nothing  extend  testcase  everything  annotation  driven  properly  use  asserts  lot  asserttruenullthing  replaced  assertnullthing  get  rid  minicluster  use  handful  case  ive  run  every  test  pas  except  testlargefile  failing  trunk  anyway,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
6523,support  credential  udfloader  storer  pig  clean  way  apis  support  adding  credential  hbase  token  hcathive  metastore  token  job  retrieving,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6524,trigger  popartialagg  compaction  gc  pressure  partial  aggregation  turned  pig  10  11  20  default  available  heap  consumed  popartialagg  operator  cause  memory  issue  job  use  nearly  heap  already  make  popartialagg  spillable  trigger  compaction  memory  reduction  required  would  much  nicer  highmemory  job,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6525,check  size  relation  adding  distributed  cache  replicated  join  right  someone  make  mistake  put  large  relation  last  pig  copy  huge  file  distributed  cache  take  long  time  job  eventually  fails  would  better  check  copying  relation  reasonable  size  1  gb,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6526,make  pigstoragereadfield  protected  case  need  extend  pigstorage  override  readfield  currently  need  copypaste  several  private  field  getnext  ive  changed  readfield  private  protected  added  new  method  protected  void  addtocurrenttupledatabytearray  data,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6527,change  hbasestorage  permit  overriding  pushprojection  case  useful  subclass  hbasestorage  override  logic  pushprojection  need  create  following  protected  method  noformat  protected  void  setcolumninfolistlistcolumninfo  columninfolist  protected  void  storeprojectedfieldnamesrequiredfieldlist  requiredfieldlist  throw  frontendexception  noformat,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6528,simplify  logical  plan  removing  unneccessary  identity  projection  typecastinserter  insert  loforeach  logical  plan  even  doesnt  need  make  cast  attached  patch  add  special  case  typecastinserter  skip  behaviour  possible  patch  also  refactors  ifinstanceofxelseifinstanceofy  behaviour  subclass,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6529,decouple  pigserverexecutebatch  compilation  batch  executebatch  currently  parsing  building  logicalplan  addition  actual  execution  beneficial  separate  parsingbuilding  execution  allow  u  get  handle  loadstore  operator  execution  batch  useful  folk  using  pigserver  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6530,giving  csvexcelstorage  option  handle  header  row  add  argument  csvexcelstorage  skip  header  row  loading  work  properly  multiple  small  file  header  combined  one  split  large  file  single  header  split  multiple  split  also  fix  bug  csvexcelstorage  including  pig2470  bug  involving  quoted  field  end  line  escaping  properly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6531,pigtestassertoutput  doesnt  allow  nondefault  delimiter  pigtestassertinputstring  aliasinput  string  input  string  alias  string  expected  assumes  default  delimiter  used  ie  tab  char  input  data  codetitletestpigjava  overridealiasinput  stringformat  load  aliasinput  destination  sbtostring  code  useful  able  use  nondefault  delimiter  example  email  user  mailing  list  httpsearchhadoopcommpxcfq1trnibpigunittestforscriptwithnondefaultpigstoragedelimitersubjpigunittestforscriptwithnondefaultpigstoragedelimiter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6532,add  log4jproperties  unit  test  currently  debug  level  message  logged  unit  test  helpful  enable  debug  unit  test,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6533,allow  pig  use  hive  udfs  would  nice  pig  provide  interoperability  hive  wrap  hive  udf  pig  use  hive  udf  pig  candidate  project  google  summer  code  2013  information  program  found  httpscwikiapacheorgconfluencedisplaypiggsoc2013,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
6534,refactor  physical  operator  remove  method  parameter  always  null  physical  operator  sometimes  overly  complex  im  trying  cleanup  unnecessary  code  particular  array  getnextt  v  value  v  seem  importance  used  pick  correct  method  started  refactoring  readable  getnextt,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6535,avro  support  user  specified  schema  load  would  useful  user  able  explicitly  specify  schema  use  reading  avro  input  allows  user  exactly  specify  resolve  input  multiple  schema  rather  depending  guessing  done  multipleschemas  set,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6536,strict  datetime  parsing  improve  performance  loading  datetime  value  performance  loading  datetime  value  improved  25  moving  single  line  todatejava  public  static  datetimezone  extractdatetimezonestring  dtstr  pattern  pattern  patterncompilezt09012d2d2  become  static  pattern  pattern  patterncompilezt09012d2d2  public  static  datetimezone  extractdatetimezonestring  dtstr  need  recompile  regular  expression  every  value  im  sure  function  ever  called  concurrently  pattern  object  threadsafe  anyways  test  created  file  10m  timestamps  010000000  put  20000101t00000023  end  ran  script  grunt  load  data  adatetime  b  filter  null  dump  b  change  took  160s  change  script  took  120  another  performance  improvement  made  invalid  datetime  value  datetime  value  invalid  exception  created  thrown  costly  way  fail  validity  check  test  performance  impact  created  10m  invalid  datetime  value  010000000  put  20009901t00000023  end  test  regex  pattern  always  recompiled  ran  script  grunt  load  data  adatetime  b  filter  null  dump  b  script  took  190s  understand  could  considered  edge  case  might  worth  changing  however  use  case  invalid  date  part  normal  processing  might  consider  fixing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6537,register  statement  param  substitution  macro  gap  functionality  macro  ive  made  patch  address  goal  provide  everything  youd  need  make  reusable  algorithm  library  1  cant  register  udfs  inside  macro  2  paramater  substitution  arent  done  inside  macro  3  resource  including  macro  redundantly  acquired  already  present  rohinis  patch  httpsissuesapacheorgjirabrowsepig3204  address  problem  3  pig  reparses  everything  every  time  read  line  still  would  problem  two  separate  file  import  macro  udf  file  get  working  moved  method  registering  jarsudfs  param  substitution  pigserver  pigcontext  accessed  queryparserdriver  process  macro  qpd  already  passed  pigcontext  reference  ok,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6538,pluggable  execution  engine  effort  adapt  pig  work  using  apache  tez  httpsissuesapacheorgjirabrowsetez  made  change  allow  cleaner  executionengine  abstraction  existed  change  major  pig  already  relatively  abstracted  frontend  backend  change  attached  commit  essentially  barebones  change  tried  change  structure  pig  different  component  much  think  interesting  see  future  refactor  area  pig  really  honor  abstraction  frontend  backend  change  reinstate  executionengine  interface  tie  together  front  end  backend  making  change  pig  delegate  ee  necessary  creating  mrexecutionengine  implement  interface  work  included  changing  exectype  cycle  executionengines  classpath  select  appropriate  one  done  using  java  serviceloader  exactly  mapreduce  choosing  framework  use  local  distributed  mode  also  tried  make  scriptstate  jobstats  pigstats  abstract  possible  current  state  think  future  work  need  done  perhaps  reevaluate  usage  scriptstate  responsibility  different  statistic  class  havent  touched  ppnl  think  abstraction  needed  perhaps  separate  patch,0,0,0,0,0,0,1,0,0,1,0,0,0,1,1,1,1
6539,return  information  parsing  related  exception  number  place  pig  code  information  useful  debugging  parsing  problem  buried  patch  try  expose  information  passing  way  main  run  method  attaching  pigstats  object,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6540,reduce  threadlocal  conf  access  backend  record  noticed  thing  browsing  code  1  defaulttuple  protected  boolean  isnull  false  never  used  removing  give  35  improvement  big  job  2  config  checking  threadlocal  conf  repeatedly  done  record  eg  createdatabag  pocombinerpackage  initialized  first  time  place  like  popackage  pojoinpackage  etc,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6541,pig  use  hadoop  local  mode  small  job  pig  use  hadoop  local  mode  small  job  mapper  reducer  mb  data,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6542,make  size  pigscript  property  configurable  application  eg  lipstick  use  pigscript  property  display  script  since  size  limited  hardcoded  max  always  possible  store  entire  script  would  nicer  size  pigscript  configurable,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
6543,orc  support  pig  adding  loadfunc  storefunc  orc,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6544,support  adding  archive  distributed  cache  support  adding  archive  distributed  cache  calling  distributedcachefileaddcachearchive  instead  addcachefile  jobcontrolcompilersetupdistributedcache  common  archive  ending  zip  tgz  targz  tar  extension  checked  downloadcacheobject  orgapachehadoopfilecachetrackerdistributedcachemanager,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6545,direct  hdfs  access  small  job  fetch  patch  id  like  add  possibility  directly  read  data  hdfs  instead  launching  mr  job  case  simple  maponly  task  hive  already  feature  fetch  patch  share  similarity  local  mode  pig  06  fetching  kick  following  hold  script  contains  limit  filter  union  split  generated  stream  nested  foreach  expression  operator  custom  udfsetc  scalar  alias  sampleloader  single  leaf  job  dump  store  feature  enabled  default  toggled  n  nofetch  set  optfetch  truefalse  there  store  support  wanted  make  explicit  optimization  launching  smallsimple  script  development  rather  querying  filtering  large  number  row  client  machine  however  threshold  could  given  input  size  estimation  determine  whether  prefer  fetch  mr  job  similar  hive  hivefetchtaskconversionthreshold  pig  loadmetadatagetstatistic,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6546,move  filelocalizersetr  call  unit  test  currently  temporary  path  generated  filelocalizer  using  randomnextint  provide  strong  randomness  mapreducelauncher  reset  random  object  every  time  compiling  physical  plan  mr  plan  code  mrcompiler  comp  new  mrcompilerphp  pc  comprandomizefilelocalizer  turn  call  filelocalizersetrnew  random  code  besides  couple  place  calling  filelocalizersetr  eg  mrcompiler  random  seed  think  randomizing  random  seed  unnecessary  switch  uuid  setting  random  object  code  like  errorprone  easily  broken  missing  filelocalizersetr  somewhere  else  see  example  herehttpsearchhadoopcomm2nxtzqxfhw1  propose  remove  randomizing  random  seed  code  use  uuid  instead  temporary  path  unit  test  compare  result  gold  file  still  allow  set  random  seed  filelocalizersetr  method  annotated  visiblefortesting  ensure  used  nowhere  else  unit  test  regarding  existing  gold  file  easily  regenerated  testmrcompiler  follows  code  fileoutputstream  fo  new  fileoutputstreamexpectedfile  new  printwriter  pw  new  printwriterfos  pwwritecompiledplan  code  assume  wont  kind  regression  due  change  please  let  know  wrong,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6547,ability  disable  pig  command  operator  admin  feature  providing  ability  blacklist  orand  whitelist  certain  command  operation  pig  expose  could  safe  multitenant  environment  example  sh  invokes  shell  command  set  allows  user  change  nonfinal  configs  tremendously  useful  general  ability  disable  would  make  pig  safer  platform  goal  allow  administrator  able  control  user  script  default  behaviour  would  still  filter  applied  command  operator,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1
6548,remodel  xmlloader  work  faster  maintainable  recreated  xmlloader  piggybank  work  line  line  instead  character  character  make  efficient  us  precompiled  regular  expression  line  instead  check  character  character  basis  code  also  significantly  smaller  make  maintainable  put  perspective  im  phd  student  university  minnesota  built  spatialhadoop  httpspatialhadoopcsumnedu  extension  hadoop  add  spatial  data  type  index  hdfs  system  open  source  downloads  75000  time  far  part  provide  simple  high  level  language  work  spatial  data  proposed  pigeon  httpspatialhadoopcsumnedupigeon  spatial  extension  pig  case  study  planet  file  openstreetmap  450gb  xml  file  contains  information  whole  planet  previously  used  xmlloader  parse  found  bug  fixed  previous  issue  found  take  lot  time  parse  xml  file  good  citizen  remodeled  xmlloader  work  line  line  use  precompiled  regular  expression  make  faster  parsing  time  compressed  osm  planet  file  drop  530  hour  330  hour  cluster  setup  hadoop  121  way  pigeon  presented  icde  2014  httpieeeicde2014eecsnorthwesterneduprogramhtml  top  conference  data  engineering  code  maintainable  example  easily  modify  add  accept  regular  expression  xml  identifier  match  tag  satisfy  regular  expression  instead  returning  fixed  static  tag  version  didnt  add  new  feature  added  future,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6549,move  multi  store  counter  pigstatsutil  mrpigstatsutil  multistore  counter  applicable  framework  tez  well  support  multiquery  moving  pigstatsutil  related  tez  jira  pig3842  contains  change  tez  branch,1,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0
6550,change  taskcontext  abstract  class  pig3860  introduced  generic  taskcontext  different  execution  mode  one  suggestion  rohini  change  taskcontext  abstract  class  avoid  instanceof  call  putting  shim  layer,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6551,add  loadcaster  evalfuncudf  ticket  close  httpstackoverflowcomquestions8828839howcancorrectdatatypesonapachepigbeenforced  reproduce  issue  first  udf  cast  map  bag  code  almost  likehttpstackoverflowcomquestions12476929groupkeyvalueofmapinpiganswertabvotestabtop  codetitletestpig  cat  testpig  register  polisanmaptobagjar  define  maptobag  maptobagmaptobag  load  polisaninput1txt  using  pigstorage  idchararray  kv  b  foreach  generate  id  maptobagkv  tobag  c  foreach  b  generate  id  flattentobag  keychararray  valuechararray  group  c  id  key  e  foreach  generate  group  mincvalue  dump  e  code  codetitlepolisaninput1pig  1  x1yab  1  x2ycd  code  run  pig  got  exception  following  noformat  20140515  194452944  thread2  warn  orgapachehadoopmapredlocaljobrunner  joblocal0001  orgapachepigbackendexecutionengineexecexception  error  0  exception  executing  name  local  rearrangetupletuplefalse  scope42  operator  key  scope42  orgapachepigbackendexecutionengineexecexception  error  2106  error  computing  min  initial  orgapachepigbackendhadoopexecutionenginephysicallayerphysicaloperatorprocessinputphysicaloperatorjava289  orgapachepigbackendhadoopexecutionenginephysicallayerrelationaloperatorspolocalrearrangegetnexttuplepolocalrearrangejava263  orgapachepigbackendhadoopexecutionenginemapreducelayerpiggenericmapbaserunpipelinepiggenericmapbasejava282  orgapachepigbackendhadoopexecutionenginemapreducelayerpiggenericmapbasemappiggenericmapbasejava277  orgapachepigbackendhadoopexecutionenginemapreducelayerpiggenericmapbasemappiggenericmapbasejava1  orgapachehadoopmapreducemapperrunmapperjava144  orgapachehadoopmapredmaptaskrunnewmappermaptaskjava764  orgapachehadoopmapredmaptaskrunmaptaskjava370  orgapachehadoopmapredlocaljobrunnerjobrunlocaljobrunnerjava212  caused  orgapachepigbackendexecutionengineexecexception  error  2106  error  computing  min  initial  orgapachepigbuiltinstringmininitialexecstringminjava81  orgapachepigbuiltinstringmininitialexecstringminjava1  orgapachepigbackendhadoopexecutionenginephysicallayerexpressionoperatorspouserfuncgetnextpouserfuncjava352  orgapachepigbackendhadoopexecutionenginephysicallayerexpressionoperatorspouserfuncgetnexttuplepouserfuncjava391  orgapachepigbackendhadoopexecutionenginephysicallayerphysicaloperatorgetnextphysicaloperatorjava334  orgapachepigbackendhadoopexecutionenginephysicallayerrelationaloperatorspoforeachprocessplanpoforeachjava378  orgapachepigbackendhadoopexecutionenginephysicallayerrelationaloperatorspoforeachgetnexttuplepoforeachjava298  orgapachepigbackendhadoopexecutionenginephysicallayerphysicaloperatorprocessinputphysicaloperatorjava281  8  caused  javalangclasscastexception  orgapachepigdatadatabytearray  cannot  cast  javalangstring  orgapachepigbuiltinstringmininitialexecstringminjava73  15  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6552,merge  tez  branch  trunk  month  development  feel  tez  branch  reach  point  merge  back  trunk  merge  introduce  known  regression  1  existing  unit  test  pas  mr  mode  2  existing  e2e  test  pas  mr  mode  3  backwardincompitable  change  tez  branch  stable  enough  1  migrated  unit  test  pas  tez  mode  2  vast  majority  e2e  test  pas  tez  mode  minor  number  failure  properly  investigated  ongoing  tez  work  continue  merge  unlikely  major  change  part  pig  code  involved  going  forward  known  limitation  pig  tez  moment  1  unit  test  ported  pig3840  2  several  operator  missing  native  mergesparse  join  collected  cogroup  3  autoparallelism  pig3846,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
6553,group  performance  garbage  collection  incremental  aggregation  pig  statement  similar  summary  foreach  group  data  generate  countdatacol1  sumdatacol2  sumdatacol2  momentscol3  momentsdatacol4  couple  hundred  column  set  following  set  pigexecmappartagg  true  set  pigexecmappartaggminreduction  3  set  pigcachedbagmemusage  005  found  ran  jvm  insufficient  memory  process  eventually  timed  infinite  garbage  collection  loop  problem  invariant  memusage  setting  solved  problem  making  change  orgapachepigbackendhadoopexecutionenginephysicallayerrelationaloperatorpopartialaggjava  rather  reading  10000  record  establish  estimate  reduction  make  estimate  reading  enough  tuples  fill  pigcachedbagmemusage  percent  runtimegetruntimemaxmemory  also  made  change  guarantee  least  one  record  allowed  second  tier  storage  current  implementation  reduction  high  10001  space  second  tier  storage  zero  change  summarize  large  data  set  small  jvms  also  find  setting  pigcachedbagmemusage  small  number  005  result  much  better  garbage  collection  performance  without  reducing  throughput  suppose  tuning  gc  would  also  solve  problem  excessive  garbage  collection  performance  sweet,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6554,create  jobjar  submitting  job  currently  pig  creates  jobjar  per  job  submitting  mapreduce  job  several  disadvantage  1  jobjar  varies  job  job  jobjar  get  reused  even  jar  cache  used  pig2672  2  job  submission  need  pack  jobjar  mostly  repacking  existing  jar  waste  time  3  jobjar  uber  jar  make  debug  harder  could  lead  jar  conflicting  issue  eg  pig3039  tez  side  situation  similar  consequence  worse  since  container  reused  instead  jobjar  would  like  ship  individual  jar  distributed  cache  note  issue  essence  independent  pig4047  however  pig4047  would  make  picture  complete  dont  uber  jar,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6555,pig  spark  setting  development  environment  0  download  spark  release  packagecurrently  pig  spark  support  spark  16  1  check  pig  spark  branch  2  build  pig  running  ant  jar  ant  dhadoopversion23  jar  hadoop2x  version  3  configure  environmental  variable  export  hadoopuserclasspathfirsttrue  support  “local”  yarnclient  mode  export  system  variable  “sparkmaster”  like  export  sparkmasterlocal  export  sparkmasteryarnclient  4  local  mode  pig  x  sparklocal  xxxpig  yarnclient  mode  export  sparkhomexx  export  sparkjarhdfsexamplecom8020xxxx  hdfs  location  upload  sparkassemblyjar  pig  x  spark  xxxpig,1,1,1,0,1,1,0,0,0,0,1,0,0,0,0,0,0
6556,fix  e2e  test  orcstorage,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6557,new  logical  optimizer  rule  constantcalculator  pig  used  logicexpressionsimplifier  simplify  expression  also  calculates  constant  expression  optimizer  rule  buggy  disable  default  pig2316  however  need  feature  especially  partitionpredicate  push  since  deal  complex  constant  expression  wed  like  replace  expression  constant  actual  push  yes  user  may  manually  calculation  rewrite  query  even  rewrite  sometimes  possible  consider  case  user  want  push  datetime  predicate  user  write  todate  udf  since  pig  datetime  constant  jira  provide  new  rule  constantcalculator  much  simpler  much  le  error  prone  replace  logicexpressionsimplifier,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6558,ship  udfloadfuncstorefunc  dependent  jar  automatically  user  use  avrostoragejsonstorageorcstorage  need  register  dependent  jar  manually  would  much  convenient  provide  mechanism  udfloadfuncstorefunc  claim  dependency  ship  jar  automatically,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
6559,hbasestorage  implement  getshipfiles  hbasestorageinitializehbaseclassloaderresources  us  tablemapreduceutil  apis  add  dependency  jar  set  tmpjars  setting  make  jobclient  ship  jar  hdfs  use  path  distributed  cache  bypass  optimization  pig2672  pig3861  avoid  shipping  jar  hdfs  instead  implement  getshipfiles  api  introduced  pig4141  pig2672  pig3861  avoid  shipping  jar  multiple  time  hdfs  job,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6560,add  uniqueid  udf,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6561,make  roundrobinpartitioner  public  use  case  user  want  distribute  dataset  evenly  without  regard  key  orgapachepigbackendhadoopexecutionenginetezruntimeroundrobinpartitioner  perfect  use  case  shall  open  public  oppose  internal  class  inside  tez  package,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6562,add  pattern  matching  plucktuple  plucktuple  useful  cleaning  long  prefix  lengthy  pig  script  currently  udf  filter  field  exact  match  would  useful  could  filter  based  regexwildcard,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6563,support  vertex  level  configuration  like  speculative  execution  need  add  code  pig  translate  user  setting  mapreducemapreducespeculative  enable  speculative  execution  tezamspeculationenabled  tez  need  take  tez1788  allow  vertex  level  disabling  speculation  done,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6564,pig  register  command  support  automatic  fetching  jar  repo  currently  pig  register  command  take  local  path  dependency  jar  clutter  local  filesystem  user  may  forget  remove  jar  later  would  nice  pig  supported  gradle  like  notation  download  jar  repository  ex  top  pig  script  user  could  add  register  groupmoduleversion  backward  compatible  support  local  file  path  desired  rb  httpsreviewsapacheorgr31662,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6565,pig  support  reading  log4jproperties  file  classpath  well  currently  specify  log4jproperties  file  pig  command  line  like  noformat  pig  4  pathtolog4jproperties  noformat  quite  helpful  read  log4jproperties  classpath  well  instance  command  specify  noformat  pig  4  log4jproperties  noformat  pig  first  try  read  file  failing  could  try  reading  classpath  similar  log4j  handle  property  log4jconfiguration  needed  one  project  contained  log4jproperties  file  embedded  inside  project  jar  ive  attached  simple  patch  testcase  effect,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6566,improve  autoparallelism  tez  tez  autoparallelism  currently  limitation  1  shuffledvertexmanager  decrease  parallelism  increase  2  pig  currently  exaggerate  parallelism  frontend  shuffledvertexmanager  might  get  initial  parallelism  way  large  actual  would  costly  instead  gradually  adjust  initial  vertex  parallelism  runtime  upstream  vertex  finish,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6567,built  udf  replacemulti  given  string  search  replace  occurrence  search  key  replacement  value  let  say  string  a1b2c3d4  objective  replace  1  b  2  c  3  4  derive  11223344  string  using  existing  replace  method  replacereplacereplacereplacea1b2c3d4a1b2c3d4  proposed  udf  replacemulti  method  general  syntax  replacemulti  sourcestring  search1replacement1  replacemulti  a1b2c3d4  a1b2  c3  d4  advantage  1  function  call  reduced  2  ease  code  better  readable  let  know  thought  input  udf  piggy  bank  take  based,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6568,serialize  relevant  part  udfcontext  per  vertex  reduce  payload  size  hcatloaderhcatstorer  put  udfcontext  huge  multiple  pig  script  size  data  sent  tez  huge  also  size  data  tez  sends  task  huge  causing  rpc  limit  exceeded  oom  issue  respectively  pig  serializes  part  udfcontext  required  vertex  save  lot  hcat  folk  also  looking  cleaning  go  conf  end  serializing  whole  job  conf  hivesitexml  moving  common  part  shared  hcat  loader  store  also  looking  option  faster  compact  serialization  create  separate  jiras  use  pig4653  cleanup  pig  config  udfcontext,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6569,print  job  stats  information  tez  like  mapreduce  job  stats  information  mapreduce  extremely  useful  debugging  looking  performance  bottleneck  mapreduce  job  taking  time  hard  figure  alias  processed  vertex  tez  without,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6570,honor  tezstagingdir  setting  tezsitexml  want  independent  setting  tez  staging  directory  currently  tez  staging  directory  set  pig  temporary  directorypigtempdir,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6571,autoparallelism  estimate  le  combiner  combiner  reduces  record  lot  autoparallelism  take  account  also  currently  multiply  factor  10  flatten  user  usually  flattengroup  group  key  compound  key  end  estimating  high  flatten  bag  considered,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6572,turn  unionoptimizer  unsupported  storefuncs  case  vertex  group  turn  unionoptimizer  unsupported  storefuncs  writing  two  vertex  may  overwrite  data  case  one  unique  union  member  dont  create  vertex  group  merge  union  operator  split  vertex  turn,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6573,popartialagg  processing  spill  improvement,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6574,serialize  pigcontext  configuration  backend  increase  conf  size  tez  really  worse  multiple  copy  conf  task  input  output  edge  processor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6575,input  empty  dir  produce  empty  output  part  file  tez,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6576,provide  option  disable  dag  recovery  tez  07  lot  issue  dag  recovery  auto  parallelism  causing  hung  dag  many  case  writing  auto  parallelism  decision  recovery  history  rewrite  done  tez  08  handle  code  added  tez  automatically  disable  recovery  auto  parallelism  would  benefit  pig  tez  work  fine  second  attempt  fails  dag  cannot  recovered  error  see  vertex  auto  parallelism  problem  hard  see  actual  problem  user  hard  debug  well  whole  ui  state  rewritten  partial  recovery  information  disabling  recovery  pig  setting  tezdagrecoveryenabledfalse  make  go  second  attempt  eventually  fail  also  make  easy  debug  original  failure,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6577,drop  hadoop  1x  support  pig  017  facilitate  future  development  want  get  rid  legacy  hadoop  1x  support  reduce  code  complexity,0,0,0,0,0,0,0,1,0,1,1,0,0,0,0,0,1
6578,add  bloom  join  pig4925  added  option  pas  bloomfilter  scalar  bloom  function  found  actually  using  big  data  required  huge  vector  size  inefficient  led  oom  initially  calculated  would  take  around  12mb  bytearray  100  million  vectorsize  100000000  7  8  12500000  byte  would  scalar  value  broadcasted  would  take  much  space  problem  12mb  written  every  input  record  buildbloominitial  aggregation  happens  arrive  final  bloomfilter  vector  popartialagg  run  oom  issue  added  bloom  join  implementation  combined  hash  skewed  join  would  boost  performance  lot  job  bloom  filter  smaller  table  sent  bigger  table  scalar  data  filtered  hash  skewed  join  used,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6579,add  api  getdisplaystring  pigstats  working  pig  interpreter  zeppelin  zeppelin335  copy  code  simplepigstatsdisplay  tezpigscriptstatsdisplay  private  would  helpful  provide  api  pigstatsgetdisplaystring,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6580,pig  need  native  keyword  assume  user  job  broke  easily  three  piece  assume  piece  one  three  easily  expressible  pig  piece  two  needed  written  map  reduce  whatever  reason  performance  something  pig  could  easily  express  legacy  job  important  change  etc  today  user  would  either  use  map  reduce  entire  job  manually  handle  stitching  together  pig  map  reduce  job  instead  pig  provided  native  keyword  would  allow  script  pas  data  stream  underlying  system  case  map  reduce  semantics  native  would  vary  underlying  system  map  reduce  case  would  assume  indicated  collection  one  fully  contained  map  reduce  job  pig  would  store  data  invoke  map  reduce  job  read  resulting  data  continue  might  look  something  like  code  load  myfile  x  load  myotherfile  b  group  0  c  foreach  b  generate  group  myudfb  native  jarmymrjar  infilefrompig  outfiletopig  e  join  0  x  0  code  differs  streaming  allows  user  insert  arbitrary  amount  native  processing  whereas  streaming  allows  insertion  one  binary  also  differs  streaming  data  piped  directly  binary  part  pig  pipeline  pipeline  would  broken  data  written  disk  native  block  invoked  data  read  back  disk  another  alternative  say  unnecessary  user  coordination  java  using  pigserver  interface  run  pig  calling  map  reduce  job  explicitly  advantage  native  keyword  user  need  worried  coordination  job  pig  take  care  also  user  make  use  existing  java  application  without  java  programmer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6581,support  flatten  map  come  across  user  asking  quite  time  dont  see  support  flatten  instead  user  write  udf,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6582,upgrade  spark  20  upgrade  spark  20  latest,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,1
6583,customizable  error  handling  loader  pig  add  error  handling  loader  pig  user  choose  allow  error  load  data  set  error  number  rate  idea  based  error  handling  store  func  see  httpsissuesapacheorgjirabrowsepig4704,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6584,fix  dot  file  parsing  enable  dotbased  physical  plan  testing,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6585,performance  multiquery  optimization  currently  pig  script  contains  multiple  store  shared  computation  pig  execute  several  independent  query  instance  load  data  b  c  b  filter  5  store  b  output1  c  group  b  b  store  c  output2  script  result  maponly  job  generated  output1  followed  mapreduce  job  generated  output2  resuld  data  read  parsed  filetered  twice  unnecessary  costly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6586,need  give  user  control  outputformat  pig  currently  allows  user  control  inputformat  via  slicer  slice  interface  allow  control  outputformat  recordwriter  interface  allows  user  implement  storage  function  control  data  serialized  hadoop  table  need  allow  custom  outputformats  prepare  output  information  object  needed  table  store  function,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6587,autocompletion  doesnt  complete  alias  autocompletion  know  keywords  different  context  would  nice  completed  alias  alias  expected,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6588,add  limit  statement  work  nested  foreach  id  like  compute  top  10  result  group  natural  way  express  pig  would  code  load  using  pigstorage  date  int  count  int  url  chararray  b  group  date  c  foreach  b  order  count  desc  e  limit  10  generate  flattene  dump  c  code  yeah  could  write  udf  piggybank  function  take  top  n  result  since  limit  already  exists  statement  seems  like  also  work  nested  foreach  context  example  workaround  code  code  c  foreach  b  order  count  desc  e  utiltopd  10  generate  flattene  dump  c  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6589,use  combiner  algebraic  udfs  used  expression  currently  pig  us  combiner  ab  c  algebraic  eg  sum  avg  etc  foreach  foreach  x  generate  abc  performance  improvement  us  combiner  mix  algebraic  nonalgebraic  function  used  well,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6590,error  reporting  failed  mr  job  multiple  mr  job  run  fail  behavior  system  stop  first  failure  keep  going  way  job  depend  failed  job  might  still  succeed  question  best  report  scenario  user  tell  job  failed  didnt  one  way  could  tie  job  store  report  store  location  wont  data  one,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6591,performance  support  skewed  join  pig  fragmented  replicated  join  limitation  one  table  need  loaded  memory  join  limited  two  table  skewed  join  partition  table  join  record  reduce  phase  computes  histogram  key  space  account  skewing  input  record  adjusts  number  reducer  depending  key  distribution  need  implement  skewed  join  pig,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6592,support  conversion  numeric  type  chararray,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6593,make  import  list  configurable  currently  hardwired  pigcontext,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6594,performance  merge  join  thsi  join  would  work  data  table  sorted  join  key,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6595,use  distributed  cache  replicated  data  set  fr  join  currently  replicated  file  read  directly  dfs  map  number  concurrent  map  huge  overwhelm  namenode  open  call  using  distributed  cache  address  issue  might  also  give  performance  boost  since  file  copied  locally  reused  task  running  machine  basic  approach  would  use  cachearchive  place  file  cache  frontend  backend  task  would  need  refer  data  using  path  cache  note  cachearchive  work  hadoop  local  mode  problem  u  right  dont  use,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6596,create  sampler  interface  improve  skewed  join  sampler  need  different  sampler  order  skewed  join  thus  need  better  sampling  interface  design  described  httpwikiapacheorgpigpigsampler,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
6597,support  cast  chararray  simple  type  pig  support  casting  chararray  integerlongfloatdoublebytearray  conversion  fails  reason  overflow  cast  return  null  log  warning,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6598,provide  multiple  version  hashfnv  piggybank  hashfnv  take  1  2  parameter  better  create  2  version  hashfnv  pig902  solved  let  pig  pick  right  version  type  cast  otherwise  user  explicit  cast,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0
6599,logical  optimizer  push  project  continuation  work  pig697httpsissuesapacheorgjirabrowsepig697  need  add  another  rule  logical  optimizer  push  project  ie  prune  column  early  possible,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
6600,udfs  scripting  language  possible  write  udfs  scripting  language  python  ruby  etc  free  user  needing  compile  java  generate  jar  etc  also  open  pig  programmer  prefer  scripting  language  java,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6601,enable  merge  join  pig  work  loader  store  function  internally  index  sorted  data  currently  merge  join  implementation  pig  includes  construction  index  sorted  data  use  index  seek  right  input  efficiently  perform  join  operation  loader  notably  zebra  loader  internally  implement  index  sorted  data  perform  seek  efficiently  using  index  use  index  need  abstracted  way  loader  support  indexing  pig  us  indirectly  loader  construct  index,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6602,using  hadoops  optimized  linerecordreader  reading  tuples  pigstorage  pigstorages  reading  tuples  line  optimized  using  hadoops  linerecordreader  help  following  area  improving  performance  reading  tuples  line  pigstorage  future  improvement  line  reading  done  hadoops  linerecordreader  automatically  carried  pig  issue  handled  patch  bzip  us  internal  buffer  positioning  determining  number  byte  read  hence  buffering  done  linerecordreader  turned  current  implementation  localseekableinputstream  implement  available  method  method  implemented,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6603,proposed  rework  loadfunc  storefunc  slicer  interface  propose  rework  loadfunc  storefunc  slicer  interface  significantly  see  httpwikiapacheorgpigloadstoreredesignproposal  full  detail,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6604,performance  implement  mapside  group  operator  speed  processing  ordered  data  general  group  operation  pig  need  mapper  reducer  aggregation  done  reducer  incurs  disk  writesreads  mapper  reducer  however  case  input  data  following  property  1  record  key  grouped  together  data  sorted  key  2  record  key  mapper  input  group  operation  performed  mapper  thus  remove  overhead  disk  writesreads  alan  proposed  adding  hint  group  clause  like  one  code  load  input  using  someloader  b  group  0  using  mapside  c  foreach  b  generate  code  proposed  addition  using  mapside  group  mapside  group  operator  collect  record  given  key  buffer  see  key  change  emit  key  bag  record  buffered  assume  key  given  record  collected  together  thus  need  buffer  across  key  expected  someloader  implemented  data  system  zebra  ensure  data  emitted  loader  satisfies  property  1  2  responsibility  user  loader  guarantee  property  1  2  invoking  mapside  hint  group  clause  pig  runtime  cant  check  error  input  data  group  clause  mapside  hint  pig  latin  support  group  column  including  group  expression  group,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6605,zebra  zebra  column  group  access  control  access  control  process  try  read  column  group  zebra  able  handle  allowed  v  disallowed  userapplication  access  security  eventuallt  granted  corresponding  hdfs  security  data  stored  expected  behavior  column  group  permission  set  user  selects  column  permission  access  zebra  return  error  message  error  permission  denied  accessing  column  column  name  name  access  control  applies  entire  column  group  column  column  group  permission,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6606,zebra  separate  schemarelated  file  schema  package  hope  facilitate  future  sharing  schema  code  different  module  andor  product,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6607,zebra  sorted  table  support  zebra  new  feature  zebra  support  sorted  data  storage  storage  library  zebra  sort  data  support  creation  use  sorted  data  either  pig  mapreduce  task  use  zebra  storage  format  sorted  table  keep  data  totally  sorted  manner  across  tfiles  created  potentially  mapper  reducer  sorted  data  creation  pig  store  operator  input  data  sorted  order  new  zebra  table  marked  sorted  sorted  column  sorted  data  creation  though  mapreduce  task  three  new  static  method  basictableoutput  class  provided  allow  help  user  achieve  goal  setsortinfo  allows  user  specify  sorted  column  input  tuple  stored  getsortkeygenerator  getsortkey  help  user  generate  key  acceptable  zebra  sorted  key  based  upon  schema  sorted  column  input  tuple  sorted  data  read  pig  load  operator  pas  string  sorted  extra  argument  tableloader  constructor  ask  sorted  table  loaded  sorted  data  read  mapreduce  task  new  static  method  tableinputformat  class  requiresortedtable  called  ask  sorted  table  read  additionally  overloaded  version  new  method  called  ask  sorted  table  specified  sort  column  comparator  release  sorted  table  supported  sorting  ascending  order  descending  order  addition  sort  key  must  simple  type  complex  type  record  collection  map  multiplekey  sorting  supported  ordering  multiple  sort  key  significant  first  sort  column  primary  sort  key  second  secondary  sort  key  etc  release  sort  key  stored  along  sort  column  key  originally  created  resulting  data  storage  redundancy,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
6608,ranger  tagsync  support  atlas  notification  hdfs  path  currently  ranger  tagsync  support  atlas  notification  hive  resource  ie  entitytypes  hivedbhivetablehivecolumn  updated  support  hdfs  path  well,1,0,1,0,1,0,0,0,0,0,0,0,1,0,0,0,1
6609,remove  code  duplication  privilegedaction  handling  code  repeated  couple  time  miscutilgetugiloginuser  refactored,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6610,provide  api  get  policyversion  use  ranger  plugins  service  like  hbase  large  number  node  master  region  server  run  ranger  authorization  plugins  large  deployment  100  node  might  challenging  find  node  use  latest  authorization  policy  ranger  admin  api  get  status  plugins  given  service  helpful  troubleshoot  issue  api  return  following  detail  plugin  hostname  plugin  ipaddress  policyversion  use  time  policy  downloaded  time  policy  become  effective  tagversion  use  time  tag  downloaded  time  tag  become  effective,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
6611,optimize  tagdownload  include  tag  policy  call  download  tag  plugins  ranger  admin  return  serviceresources  one  tag  associated  optimized  include  serviceresources  tag  policy  exists  example  tagbased  policy  exists  tag  pii  pci  ranger  admin  return  serviceresources  associated  pii  pci  tag  serviceresource  associated  either  tag  excluded  addition  reducing  size  tagdownload  improve  policyengine  performance  deal  tag  dont  policy,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6612,ranger  policy  support  notion  owner  user  component  like  hdfs  notion  owner  resource  accessed  component  possible  setup  ranger  policy  grant  specific  permission  owner  accessed  resource  example  usecase  user  readwriteexecutedelegateadmin  privilege  file  directory  home  ranger  policy  like  noformat  pathhome  user  owner  permission  read  write  execute  isdelegateadmintrue  noformat,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6613,improve  ranger  usersync  sync  adldap  user  andor  group  incrementally  every  sync  cycle  ranger  usersync  performs  full  ldapad  sync  computes  delta  inmemory  update  ranger  admin  since  usersync  computes  delta  including  group  membership  user  sync’d  memory  every  sync  cycle  usersync  take  lot  resource  server  running  enhance  usersync  perform  full  sync  startup  incremental  delta  sync  subsequent  sync  cycle  way  delta  computation  group  membership  highly  reduced  increase  usersync  performance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6614,support  filename  basefilename  token  hdfs  plugin  use  case  possible  allow  access  file  directly  directory  say  dataoracle  file  subdirectory  dataoraclepii  cannot  done  using  wildcards  dataoracle  allows  access  recursively  file  dataoracle  including  subdirectory  ranger  support  token  introduced  ranger698  ranger  policy  dataoraclefilename  meet  need  filename  token  hold  value  file  accessed  moreover  specific  policy  dataoraclebasefilenametxt  match  file  txt  extension  used  demarcate  extension  base  filename,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6615,consolidate  xml  configuration  parsing  currently  duplicate  code  appears  several  place  parse  xml  instead  consolidated  single  place,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
6616,code  improvement  java  method  xtrxlogservicesearchxtrxlogs  method  searchxtrxlogs  class  securityadminsrcmainjavaorgapacherangerservicextrxlogservicejava  code  improved  1when  search  type  searchfieldsearchtypepartial  stringpredicate  generated  twice  first  redundant  code  ifattr  null  stringpredicate  criteriabuilderequalrootentitytypegetattr  paramvalue  searchfieldgetsearchtypeequalssearchfieldsearchtypepartial  string  val  paramvalue  stringpredicate  criteriabuilderlikerootentitytypegetattr  val  predicate  criteriabuilderandpredicate  stringpredicate  code  2datepredicate  criteriabuilderequal  repeated  first  redundant  duplicated  code  code  searchfieldgetcustomcondition  null  datepredicate  criteriabuilderequalrootentitytypegetattr  fieldvalue  searchfieldgetsearchtypeequalssearchfieldsearchtypelessthan  datepredicate  criteriabuilderlessthanrootentitytypegetattr  fieldvalue  else  searchfieldgetsearchtypeequalssearchfieldsearchtypelessequalthan  datepredicate  criteriabuilderlessthanorequaltorootentitytypegetattr  fieldvalue  else  searchfieldgetsearchtypeequalssearchfieldsearchtypegreaterthan  datepredicate  criteriabuildergreaterthanrootentitytypegetattr  fieldvalue  else  searchfieldgetsearchtypeequalssearchfieldsearchtypegreaterequalthan  datepredicate  criteriabuildergreaterthanorequaltorootentitytypegetattr  fieldvalue  else  datepredicate  criteriabuilderequalrootentitytypegetattr  fieldvalue  predicate  criteriabuilderandpredicate  datepredicate  code  3the  following  code  repated  java  method  xtrxlogservicesearchxtrxlogscount  refactored  method  codeforstring  key  paramlistkeysetcode  4do  code  improvement  java  method  xtrxlogservicesearchxtrxlogs  related  code  equal  usage  local  variable  etc  5xtrxlogservicesearchxtrxlogs  used  audit  admin  webpage  please  refer  screenshot  aduitadminsearchjpghttpsissuesapacheorgjirasecureattachment12855809aduitadminsearchjpg  detail  tested  easily,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6617,refactor  rangerpolicyengineoptions  rangerconfiguration  looked  many  time  rangerpolicyengineoptions  lot  public  field  written  various  place  code  base  avoided  object  configured  rangerconfiguration  middle  plugin  initialization  code  make  bit  complex  suggestion  rangerconfiguration  treated  object  static  facade  couple  config  value  rangerpolicyengineoptions  get  configuration  directly  rangerconfiguration  explicit  encapsulated  way,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6618,remove  keyprotector  code  km  km  service  us  reflection  call  comsuncryptoproviderkeyprotector  class  encryptdecrypt  key  using  password  cause  problem  java  9  generally  unnecessary  use  normal  java  api,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6619,avoid  classloading  default  atlasresourcemappers  atlasresourcemapperutil  classload  default  atlasresourcemappers  custom  one  unnecessary  instantiate  default  one  classload  custom  one,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6620,ranger  support  authorization  auditing  apache  solr  jira  track  work  enable  support  apache  argusranger  managing  authorization  policy  apache  solr  auditing  user  access  solr  model  similar  argusranger  support  apache  hive  apache  hbase,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6621,upgrade  ranger  support  apache  hadoop  300  task  upgrade  ranger  support  apache  hadoop  300  note  upgrade  hive  plugin  need  hadoop  300  jar  run  test  properly  hive  support  older  hadoop  version  exclusion  additional  300  dependency  need  added  b  storm  plugin  bundle  hadoopauth  jar  stormcore  although  really  renamed  therefore  option  package  storm  hadoop  27x  jar  time  storm  upgrade  hadoop  dependency  initial  patch  get  feedback  broad  agreement  upgrade  test  distribution  properly,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6622,rename  package  xasecure  apache  ranger,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6623,ranger  support  kafka  100  ranger  dont  support  kafka  100  support  kafka  100,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6624,auditing  ranger  usersync  operation  every  sync  cycle  ranger  usersync  audit  basic  information  like  number  user  number  group  syncd  cycle  also  provide  detail  sync  source  like  unix  file  ldap  relevant  configuration  like  ldap  filter  applied  sync  cycle  ldap  host  url  etc  add  new  tab  ranger  admin  ui  audit  usersync  show  information,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6625,policy  effective  date  support  timebound  temporary  authorization  currently  ranger  policy  effectiveness  period  permanent  ie  authored  disabled  enabled  many  use  case  policy  even  policy  condition  need  time  bound  example  certain  financial  information  earnings  sensitive  restricted  earnings  release  date  would  great  ability  specify  policy  time  horizon  effective  ie  either  effective  certain  date  andor  expire  specific  date  valid  within  certain  time  window  ranger  check  whether  policy  effective  evaluating  policy  engine  therefore  policy  authoring  simplified  require  subsequent  action  user  basically  making  policy  authoring  one  time  effort  user  go  back  disable  policy  past  expiration  date  mean  ranger  policy  engine  need  able  recognize  start  end  time  policy  enforce  based  period  validity  specified  user  active  policy  checked  based  resource  user  environment  context  also  whether  policy  effective,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6626,update  ranger  atlas  authorizer  authorization  model  change  atlas  apache  atlas  authorization  model  updated  master  branch  atlas2459  upcoming  10  release  requires  corresponding  update  ranger  atlas  authorizer  implementation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6627,good  coding  practice  km  unixauth  good  coding  practice  km  unixauth,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6628,update  ranger  authorizer  atlas  new  method  added  authorization  interface  atlas2765  atlas  authorizer  interface  updated  atlas2765  addition  method  scrubsearchresults  ranger  authorizer  atlas  updated  implement  new  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6629,optimize  trie  constuction  policy  lookup  ranger  us  trie  data  structure  look  policy  resource  efficient  access  trie  tree  may  optimized  contain  fewer  node  made  le  deep  allow  faster  construction  trie  tree  faster  lookup  resource,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
6630,support  multiple  thread  build  trie  onlookup  postsetup  trie  node  time  building  trie  index  resource  may  become  bottleneck  dealing  large  number  resource  desirable  build  different  nonoverlapping  part  trie  structure  using  multiple  thread  reduce  overall  build  time  configured  also  instead  building  trie  node  completely  propagating  wildcard  evaluator  way  leaf  trie  tree  initialization  time  optimal  trienode  accessed  first  time  resource  lookup,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6631,review  update  database  schema  ranger  policy  minimize  database  queriesupdates  currently  ranger  policy  fully  normalized  stored  multiple  relational  database  table  performance  overhead  incurred  retrieving  ranger  policy  multiple  database  access  required  fully  reconstruct  significant  large  ranger  policy  number  resource  addressed  policy  large  andor  large  number  ranger  policy  installation  jira  track  alternate  design  database  schema  policy  stored  denormalized  way  entirely  one  database  table  preferably  json  string,1,0,1,0,1,0,0,0,1,1,1,0,0,0,0,0,1
6632,support  incremental  policy  update  improve  performance  rangeradmin  plugins  optimal  building  policyengine  requirement  currently  every  change  policy  cause  rebuilding  policyengine  scratch  several  disadvantage  1  compute  time  rebuilding  2  large  traffic  rangeradmin  plugins  3  large  demand  jvm  memory  system  resulting  frequent  garbage  collection  pause  jvm  optimal  communicate  change  apply  existing  policyengine  design  note  policy  change  logged  new  database  table  cache  management  rangeradmin  enhanced  use  table  figure  change  using  previously  known  version  number  provided  module  requesting  updated  policy  policy  engine  support  update  operation  accepts  policydeltas  return  new  policy  engine  delta  applied  resource  trie  structure  copied  older  policyengine  selectively  rebuilt  scratch  backward  compatibility  maintained  older  plugins  adding  another  parameter  rest  api  downloading  policy  ranger  admin  well  component  plugins  may  configured  optionally  use  policy  delta  internal  policyengines  policy  delta  disabled  default  rangeradmin  policydeltas  enabled  rangeradmin  setting  configuration  variable  rangeradminsupportspolicydeltas  true  individual  plugins  policydeltas  enabled  setting  configuration  variable  rangerpluginservicetypepolicyrestsupportspolicydeltas  true  policy  delta  table  cleared  record  older  week  restart  rangeradmin,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6633,implement  import  export  policy  zone  implement  import  export  policy  zone,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6634,add  custom  condition  policy  level  add  custom  condition  policy  level  currently  custom  condition  policy  item  level  policy  level  also  give  flexible  intutive  also  policy  evaluation  doesnt  need  go  policy  item  level  checking  condition  applicable  policy  level,1,1,1,0,1,1,0,0,1,0,0,0,0,0,0,0,0
6635,ranger  work  ha  enabled  webhdfs  automatic  failover  ranger  work  ha  enabled  webhdfs  automatic  failover  speficially  file  look  ranger  admin  continue  work  namnode  fails,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6636,filterexclude  multiple  user  audit  search  currently  audit  search  allows  filter  one  user  activity  exclude  service  user  every  user  activity  way  search  multiple  user  exclude  multiple  user  search  list  would  make  debugging  complex  interaction  simpler  example  look  action  alice  hive  yarn,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6637,enhancement  support  role  ranger  policy  current  ranger  policy  model  support  authorizationcolumnmaskingrowfiltering  usersusergroups  based  various  criterion  like  accessedresource  resourceclassifications  ipaddress  custom  condition  given  widespread  use  rolebased  authorization  traditional  enterprise  application  like  rdbms  j2ee  useful  ranger  policy  model  support  role  ie  able  specify  authorizationcolumnmaskingrowfiltering  role  well  addition  existing  support  user  usergroups,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6638,ranger  spends  36  cpu  objectmapper  ranger  us  objectmapper  convert  tofrom  json  profile  workload  impala  authorization  test  see  36  ranger  cpu  spent  function  26  total  cpu  findrootdeserializer  method  get  cached  type  deserialized  multiple  time  however  caching  effective  objectmapper  reused  jsonutil  appears  create  new  objectmapper  every  call  defeat  caching,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6639,create  policycondition  apply  given  tag  present  accessed  resource  create  policycondition  apply  given  tag  present  accessed  resource  ie  tag  policy  condition  present  resource  user  access  allow  resource  accessed  user  built  policy  condition  created  defined  service  definition  service  need  addition  functionality,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6640,improvement  setting  cluster  name  rangeraccessrequest  handling  clustername  setting  part  policy  engine  instantiation,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6641,create  tag  service  resource  service  created  link  resource  service  ranger  support  tagbased  policy  box  however  configuration  step  need  performed  order  set  ranger  perform  tagbased  authorization  step  often  missed  useful  provide  commonly  usedstructured  way  automatically  creating  tag  service  linking  resource  service  may  controlled  configuration  parameter  rangertagserviceautocreatetruefalse  tagservice  need  created  resourceservice  created  rangertagserviceautonametagservicename  value  specified  used  name  tagservice  otherwise  name  tagservice  constructed  name  resourceservice  replacing  part  last  string  tag  character  resourceservice  name  tagservice  createdlinked  resourceservice  rangertagserviceautolinktruefalse  used  rangertagserviceautocreate  true  set  true  resourceservice  need  linked  tagservice,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6642,ranger  use  solr  api  upload  config  set  bootstrapping  ranger  remove  zk  znode  check  remove  zk  config  set  upload  remove  zk  acl  set  use  solr  config  set  api  httpsluceneapacheorgsolrguide74configsetshtml  upload  config  set  exists  also  probably  solr4j  call,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0
6643,good  coding  practice  concurrent  policy  label  creation  good  coding  practice  concurrent  policy  label  creation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6644,support  incremental  tag  update  improve  performance  currently  every  change  tagserviceresourceserviceresourcetag  mapping  cause  complete  rebuilding  portion  policyengine  map  accessed  resource  tag  several  disadvantage  1  compute  time  rebuilding  2  large  traffic  rangeradmin  plugins  3  large  load  jvm  memory  system  frequent  complete  rebuilding  portion  policyengine  optimal  communicate  change  tag  apply  existing  policyengine,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6645,export  api  get  zone  unzone  well  tag  based  policy  ranger  separate  policy  export  api  need  created  would  give  zone  unzone  well  tag  policy  specified  resourcecurrently  export  policy  give  zone  unzone  policy,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6646,constant  increase  memory  usage  rangerusersync  process  eventually  going  memory  usersync  configured  unix  sync  source  noticed  constant  increase  memory  usage  long  running  test  causing  memory  issue,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6647,good  coding  practice  storing  retrieving  data  history  ranger  good  coding  practice  storing  retrieving  data  history  ranger,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6648,need  change  usersyncunixldap  support  ha  without  load  balancer  need  change  usersyncunixldap  support  ha  without  load  balancer,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6649,add  support  tag  based  policy  add  support  tag  based  policy  ranger  user  able  specifies  resource  like  filesfolderstablescolumns  confidential  pii  able  define  access  policy  confidential  data  u1u2u2  group1  able  access  confidential  data,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6650,add  support  aggregating  audit  log  source  instead  logging  every  access  possible  add  aggregation  audit  log  entry  sending  audit  destination  user  steve  access  read  resource  filehrabctxt  nooftimesaccessed17,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,1
6651,rest  store  validation  policyserviceservicedef  policyserviceservicedef  validation  added  createupdatedelete  operation  validation  add  value  provided  mandatory  field  name  resource  etc  value  valid  example  based  validationregex  resource  def  enum  value  duplicate  name  servicedefservicepolicywithinaservice  ensure  user  permission  createupdateview  policyserviceservicedef  check  conflictingoverlapping  policy,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6652,policy  evaluation  optimization  reorder  policy  shortcircuit  evaluation  policy  engine  currently  evaluates  policy  order  received  cacherest  api  minimize  policy  evaluation  time  best  start  policy  likely  match  access  request  example  policy  deal  allwildcard  resource  name  etc  jira  implement  optimization  another  jira  track  sophisticated  optimization  like  use  caching  usage  pattern  etc,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
6653,remove  custom  class  loader  used  ranger  admin  resource  lookup  remove  custom  class  loader  used  ranger  admin  resource  lookup  right  ranger  admin  resource  lookup  hdfs  hive  hbase  relying  custom  classloader  orgapacherangerpluginclienthadoopclassloader  requires  u  define  property  name  site  file  eg  coresitexml  mapping  resourcenamemapproperties  try  eliminate  need  custom  class  loader  need  maintain  property  name  site  file  mapping  make  easy  onboard  new  plugins,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6654,implement  reliable  streaming  audit  configurable  destination  currently  audit  hdfs  ranger  writes  file  transfer  entire  file  hdfs  regular  interval  add  additional  write  operation  local  disk  proposal  write  intelligent  audit  writer  audit  sent  destination  real  time  batch  destination  write  local  file  destination  available  first  send  audit  log  file  system  caught  resume  realtime  streaming  design  also  need  address  use  case  destination  slower  audit  producer  case  internal  queue  reach  certain  threshold  audit  written  local  file  till  destination  till  inmemory  queue  drained  design  generic  enough  support  type  destination  default  implementation  following  destination  provided  1  hdfs  2  solr  3  local  file  4  log4j  supported  appender  additional  good  destination  1  rdbms  2  kafka,1,0,1,0,1,0,1,0,0,0,0,0,0,1,1,1,0
6655,provide  rest  api  change  user  role  provide  rest  api  change  user  role,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6656,provide  way  cleanup  old  policyengine  related  resource  updated  servicepolicies  fetched  plugin  rangeradmin  new  policyengine  created  process  authorization  request  using  updated  servicepolicies  clean  way  release  critical  resource  held  old  policyengine  instance  needed  optimal  use  system  resource,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6657,ranger  policy  support  variable  like  user  would  good  support  variable  resource  user  eg  hdfs  resource  homeuser  table  resource  user  user  allowed  user  user  expanded  current  user  think  resource  substitution  easy  permission  use  key  word  like  use  user  grouppublic  use  key  word  like  user  something  like,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6658,higher  level  policy  api  hide  complexity  policy  updatecreatedelete  ranger  good  finegrained  policy  api  user  define  access  control  rule  resource  sometimes  human  third  party  tool  may  use  ranger  policy  api  temporarily  block  unblock  user  third  party  tool  want  simply  tell  ranger  please  blockunblock  user  accessing  resource  third  party  tool  able  analyze  complicated  scenario  follows  1  exactly  rule  already  exists  resource  2  current  rule  resource  includes  new  rule  implicitly  3  rule  resource  admin  operate  policy  admin  analyze  policy  semantics  figure  create  new  policy  update  existing  policy  better  support  integration  third  party  tool  ranger  provide  higher  level  api  accepts  request  like  block  user  access  one  resource  internally  figure  policy  createupdate,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6659,create  new  project  serve  template  write  ranger  extension  context  enrichers  condition  evaluator  allow  people  write  extension  ranger  would  helpful  separate  sub  project  serve  repository  sample  code  serve  example  also  provide  maven  based  project  template  someone  use  base  writebuild  extension,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
6660,use  system  supplied  mechanism  get  user  group  unix  unix  user  sync  currently  read  etcpasswd  etcgroups  often  reflection  user  group  available  system  especially  nsswitch  configured  eg  sssd  ldap  etc  secondly  case  group  contain  user  name  returned  getent  passwd  especially  external  user  required  add  using  group  information,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6661,add  kerberos  support  ranger  admin  client  proposing  enable  kerberos  ranger  admin  client  plugins  usersync  km  tagsync  also  see  httpsissuesapacheorgjirabrowseranger686,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6662,rangerkms  luna  hsm  integration  jira  support  ranger  km  integration  safenet  luna  hsm  manage  master  key  also  see  httpsissuesapacheorgjirabrowseranger723,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0
6663,ranger  policy  model  support  data  masking  ability  mask  sensitive  data  based  user  group  criterion  one  often  asked  feature  jira  track  update  ranger  policy  model  policy  engine  support  mask  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6664,policy  engine  api  find  list  usersgroups  access  resource  jira  enhance  policy  engine  addition  api  find  list  usersgroups  specific  access  resource  api  helpful  purpose  like  reporting,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6665,ranger  policy  model  support  rowfiltering  ability  apply  filter  based  usergroupothercriteria  restrict  result  returned  query  one  often  asked  feature  jira  track  update  ranger  policy  model  policy  engine  support  rowfilter  feature,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6666,ranger  usersync  add  ability  transform  usergroup  name  file  source  ldap  source  provides  ability  transform  user  group  name  using  regular  expression  see  ranger684  add  ability  file  source,1,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0
6667,support  download  csv  report  page  enhancement  list  change  improvement  along  download  excel  spreadsheet  feature  add  support  download  file  csv  format  report  page  searched  policy  downloaded  policy  file  multiple  policy  item  separate  row,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6668,enduser  must  provide  easy  way  enabledisable  visualization  sorting  user  attribute  currently  syncope1005  specified  way  define  custom  attribute  sorting  user  self  createupdate  form  include  configurable  section  angularjs  application  configuration  define  also  attribute  showhide  sorting  strategy  introduce  also  readonly  flag  configuration  order  allow  enduser  edit  certain  field  configuration  confused  schema  readonly  flag  another  meaning  like  stated  httpssyncopeapacheorgdocsreferenceguidehtmlschema,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6669,user  authentication  using  email  additional  existing  user  authentication  using  username  email  used  user  authenticating  subject  modern  social  networking  site  mostly  us  email  user  authentication,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6670,template  mechanism  enduser  ui  provide  mechanism  defining  template  term  html  cs  image  file  simply  appearance  customization  enduser  ui  goal  issue  provide  way  avoid  html  code  duplication  define  reusable  component  define  html  template  mechanism  aim  improve  customizability  enduser  enduser  meant  customized  extended  finite  product  proposal  start  new  implementation  exploit  much  possible  code  reusability  feature  provided  angularjs  possible  needed  review  actula  cs  implementation  order  better  fit  new  template  mechanism  compromise  change  enduser  functionality  button  selects  wizard  component  preserve  role  function  core  logic  remain  though  enduser  open  discus  improvement  also  way  thishttpscodeangularjsorg163docsguidetemplates  could  good  starting  point  understand  use  angularjs  tool  implement  templating  btw  proposal  involve  angularjs  feature  well  accepted  accepted  anyway  feature  described  like  directive  also  used  enduser  define  reusable  component  eg  dynamicplainattribute,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6671,support  bpmn  call  activity  activiti  user  guidehttpswwwactivitiorguserguidebpmncallactivity  quote  bpmn  20  make  distinction  regular  subprocess  often  also  called  embedded  subprocess  call  activity  look  similar  conceptual  point  view  call  subprocess  process  execution  arrives  activity  difference  call  activity  reference  process  external  process  definition  whereas  subprocess  embedded  within  original  process  definition  main  use  case  call  activity  reusable  process  definition  called  multiple  process  definition  quote  currently  possible  create  process  definition  besides  default  userworkflow  empowering  rest  endpoint  code  put  workflowsanytypekind  code  new  process  defined  called  main  userworkflow  via  callactivity  element  main  advantage  problem  process  definition  version  apply  main  process  eg  userworkflow  currently  lacking  proper  management  getting  available  process  definition  proper  handling  initial  loading  several  process  definition  xml  file  proper  editing  feature  admin  console  item  consider  possibility  single  process  definition  available,1,0,0,0,0,0,1,0,0,0,0,1,0,0,0,1,1
6672,hide  key  creating  editing  security  question  admin  console  creating  editing  security  question  admin  console  key  autogenerated  field  interest  currently  reported  modifiable  better  hidden  instead,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6673,jwtbased  access  rest  service  since  beginning  access  rest  service  protected  via  basic  authentication  credential  sent  along  every  request  improvement  switch  architecture  explicit  rest  service  obtaining  sort  token  requiring  credential  rest  service  accessed  sending  along  token  instead  credential  ease  future  work  enabling  sso  via  saml  oauth  20  standard  token  format  seems  json  web  tokenshttpsjwtio  quite  default  choice  especially  considering  support  cxf  already  provides,1,0,1,0,1,0,1,0,1,0,1,0,0,0,0,1,1
6674,saml  20  service  provider  feature  provide  ability  perform  sso  admin  console  enduser  ui  via  external  saml  20  identity  provider,1,0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1
6675,replace  actionlinkspanel  togglepanel  data  table  used  across  almost  feature  admin  console  within  data  table  general  ui  paradigm  show  icon  per  row  icon  triggering  different  action  entity  represented  row  wicket  panel  implementing  multiicon  action  actionlinkspanelhttpsgithubcomapachesyncopeblob20xclientconsolesrcmainjavaorgapachesyncopeclientconsolewicketmarkuphtmlformactionlinkspaneljava  component  serving  purpose  might  useful  improve  ux  empowering  togglepanelhttpsgithubcomapachesyncopeblob20xclientconsolesrcmainjavaorgapachesyncopeclientconsolepanelstogglepaneljava  transparent  menu  activated  clicking  node  topology  idea  remove  icon  shown  data  table  row  clicking  given  data  table  row  show  menu  based  togglepanel  providing  access  action  available  entity  represented  row,1,0,1,0,1,0,1,0,0,1,1,0,0,0,0,1,0
6676,allow  easier  extension  rest  interface  exposed  angularjs  rest  interface  exposed  wicket  component  enduser  ui  based  wicket  mountresource  feature  however  resource  explicitly  mounted  syncopeenduserapplicationinit  syncope  extension  local  deployment  might  need  however  enrich  rest  interface,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0
6677,replace  activitibased  workflow  adapter  flowable  following  discussion  ml  idea  upgrade  current  workflow  engine  based  activiti  5x  one  featuring  flowable  6,0,0,0,0,0,0,0,1,1,1,1,0,0,0,0,1,1
6678,remove  final  landing  page  user  createupdate  remove  final  landing  page  user  successful  createupdate  restore  old  feedback  panel  show  success  visible  login  page,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6679,support  saml  20  redirect  profile  syncope1041  introduced  saml  20  sp  extension  supporting  post  binding  profile  adding  support  redirect  profile  hard  thanks  underlying  support  cxfrtrssecurityssosaml,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0
6680,improve  security  customization  mechanism  smart  malicious  user  could  hack  angularjs  frontend  component  send  info  allowed  createedit  solve  checking  info  server  side  form  customization  json,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6681,flexible  delegated  administration  model  current  implementation  delegated  administrationhttpssyncopeapacheorgdocsreferenceguidehtmldelegatedadministration  relies  role  role  associate  set  entitlement  eg  administrative  action  set  realm  eg  container  user  group  object  requires  however  set  user  group  object  administer  somehow  statically  defined  containment  administrator  role  r  manage  user  realm  b  work  long  user  administer  fully  contained  realm  b  set  user  r  administer  need  dynamically  defined  say  value  department  attribute,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0
6682,display  enable  add  button  realm  create  owned  realm  page  add  button  user  group  object  always  displayed  even  realm  logged  admin  granted  usercreate  groupcreate  dynamic  create  entitlement  generated  defined  object  type  lead  confusion  fatal  error  reported  last  step  create  add  button  could  hidden  disabled  realm  create  entitlement  granted  logged  admin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6683,extension  elasticsearchbased  search  engine  outlined  syncope1006  current  search  engine  somehow  fragile  based  sql  view  highly  depends  dbms  used  internal  storage  frequent  issue  mysql  mariadb  suggestedhttpsissuesapacheorgjirabrowsesyncope1006pagecomatlassianjirapluginsystemissuetabpanelscommenttabpanelfocusedcommentid15856313comment15856313  idea  could  provide  another  optional  search  engine  implementation  requires  elasticsearch  node,1,0,1,0,1,0,0,0,0,0,0,1,1,0,0,0,1
6684,downloaded  file  binary  attribute  better  naming  name  downloaded  file  like  keyschemanamestandard  extension  mimetype,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6685,option  disable  quartz  instance  across  cluster  considered  aspect  configuring  syncope  highavailabilityhttpssyncopeapacheorgdocsreferenceguidehtmlhighavailability  related  openjpas  remote  commit  provider  least  according  current  documentation  however  another  component  relevant  within  regard  eg  quartz  scheduler  currently  simply  setup  default  clusteringhttpwwwquartzschedulerorgdocumentationquartz22xconfigurationconfigjdbcjobstoreclusteringhtml  configuration  cluster  node  equally  selectable  processing  job  would  nice  though  gain  control  aspect  eg  able  restrict  node  job  run  example  one  3  syncope  core  node  configured  openjpa  remote  commit  provider  set  2  processing  rest  request  leaving  third  dedicated  running  job  eg  pull,0,0,0,0,0,0,0,0,1,1,1,0,0,1,0,0,0
6686,remove  misleading  getattrmap  similar  method  tos  connobjectto  class  implementing  attributableto  provide  method  like  getattrmap  getplainattrmap  getderattrmap  getvirattrmap  purpose  providing  readonly  view  attribute  different  type  using  method  however  costing  resulting  map  built  invocation  also  confusing  one  would  expect  adding  removing  entry  would  result  effective  attribute  change  method  removed  substituted  tailored  replacement  needed,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6687,support  function  internal  jexl  engine  jexl  register  object  class  used  function  namespaceshttpscommonsapacheorgpropercommonsjexlreferencesyntaxhtmlfunctions  since  jexl  expression  used  everywhere  feature  would  enhance  capability  adapt  different  use  case  one  intended  supported  syncope1116  realm  object  link,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6688,third  party  jwt  sso  integration  task  support  sso  using  third  party  jwt  token  involves  two  task  create  new  interface  extending  jwssignatureverifier  provide  method  resolve  jwt  subject  syncope  username  known  user  b  processing  received  token  issuer  different  known  issuer  jwtissuer  securityproperties  instead  retrieving  default  jwssignatureverifier  implementation  authentication  component  enable  classpathscanimplementationlookup  dynamically  discover  implementation  interface,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6689,update  relationshipto  also  report  left  end  relationship  currently  relationshipto  object  report  right  end  relationship  however  relationship  syncope  bidirectional  also  report  left  end  relationship  make  searching  anytypes  bit  easier  present,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,0
6690,finegrained  administration  right  connector  resource  current  delegated  administration  model  defines  coarsegrained  entitlement  come  connector  resource  either  administrator  manage  connector  resource  cannot  associating  connector  resource  consequence  realm  possible  grant  entitlement  via  role  given  subset  available  connector  resource  eg  one  associated  specific  realm  sample  connector  realm  abc  assigned  would  manageable  user  owning  connectorupdate  realm  abc  one  parent  resource  related  connector  realm  abc  assigned  would  manageable  user  owning  resourceupdate  realm  abc  one  parent,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6691,customizable  audit  appender  audit  mechanism  based  log4j  configured  use  jdbcappender  store  audit  statement  syncopeaudit  table  internal  storage  besides  base  mechanism  introduce  auditappender  interface  whose  instance  declare  event  invoked  declare  another  log4j  appender  send  statement  besides  jdbcappender  optionally  offer  ability  transform  standard  statement  format  suitable  target  appender,0,0,0,0,0,0,1,1,0,1,0,0,0,0,0,0,1
6692,connector  resource  configuration  versioning  often  happens  playing  connector  resource  configuration  everything  work  certain  point  misconfiguration  happens  error  start  appearing  situation  would  handy  simple  mechanism  revert  previous  working  situation,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
6693,onthefly  creation  unmatched  user  logging  via  saml  20  per  current  implementation  logging  admin  console  via  saml  20  internal  user  matching  configured  attribute  authentication  assertion  looked  found  error  raised  thing  could  configured  however  create  onthefly  internal  user  attribute  provided  authentication  assertion  let  log,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1
6694,clear  unneeded  anonymous  authenticated  service  following  discussionhttpswildernessapacheorgchannelsfapachesyncope20170628  irc  coheigea  seems  entitlement  available  since  earlier  version  might  reintroduced  properly  control  access  related  rest  service  grouplist  resourcelist  anytypelist  anytypeclasslist  schemalist  securityquestionlist  realmlist  rationale  entitlement  syncope  1x  related  information  made  available  selfregistration  enduser  ui  however  seems  possible  introduce  dedicated  rest  endpoint  serve  content  selfregistration  minimal  information  example  group  name  need  provide  extra  information  attribute  type  extension  etc  restore  appropriate  access  control  rest  endpoint  accessed  administrative  purpose,1,0,1,0,1,0,0,0,0,1,0,0,0,0,0,1,1
6695,complete  mapping  realm  provisioning  current  setting  realm  provisioning  minimal  compared  mapping  provided  user  group  object  essentially  external  attribute  object  link  applicable  specified  lead  limitation  apply  ordinary  provisioning,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1
6696,skip  relationship  page  relationship  type  exist  creating  new  user  console  relationship  type  defined  come  page  say  relationship  relationship  defined  would  better  skip  page  altogether  relationship  type  available,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
6697,validate  saml  response  cxfs  samlssoresponsevalidator  moment  saml  response  validated  via  samlprotocolresponsevalidatorhttpsgithubcomapachecxfblob31xfixesrtrssecurityssosamlsrcmainjavaorgapachecxfrssecuritysamlssosamlprotocolresponsevalidatorjava  cxf  also  offer  samlssoresponsevalidatorhttpsgithubcomapachecxfblob31xfixesrtrssecurityssosamlsrcmainjavaorgapachecxfrssecuritysamlssosamlssoresponsevalidatorjava  providing  check,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6698,realmbased  authorization  current  authentication  authorization  model  weakness  outlined  1  mail  thread  refactoring  proposal  shown  implementing  systemwide  realmbased  hierarchical  security  model  impact  nearly  every  component  layer  system  great  care  taken  extensive  testing  discussion  wiki  httpscwikiapacheorgconfluencedisplaysyncope5bdiscuss5drealms  1  httpsyncopedev1063484n5nabblecomsyncopedevauthorizationentitlementstd4830322html,1,1,0,1,0,1,0,1,0,0,1,0,0,1,1,1,1
6699,provide  latest  git  commit  hash  alongside  version  number  platforminfo  object  provides  version  number  running  platform  especially  snapshot  version  however  also  useful  know  latest  git  commit  included,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6700,allow  update  user  data  approval  even  though  supported  core  currently  possible  administrator  given  user  approval  edit  user  approval  feature  naturally  requires  underlying  workflow  definition  allows  update  user  approval  integration  test  casehttpsgithubcomapachesyncopeblob20xfitcorereferencesrctestjavaorgapachesyncopefitcoreuserworkflowitcasejaval214  implement  scenario,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6701,allow  anytypebased  condition  dynrealms  currently  dynrealms  allow  specify  single  matching  condition  applied  user  group  anyobjects  limitation  way  express  condition  might  relevant  user  example  group  membership,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
6702,allow  easier  pull  push  process  customization  current  pull  process  driven  pulljobdelegate  push  process  driven  pushjobdelegate  quite  allow  extended  given  deployment  mainly  private  field  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6703,password  change  external  resource  give  option  change  password  one  connected  external  resource  currently  possible  change  password  syncope  core  propagate  accordingly  connected  external  resource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6704,support  groovy  implementation  netbeans  ide  plugin  syncope956  introduced  possibility  provide  groovybased  implementation  netbeans  ide  plugin  extended  support  issue  basically  start  work  already  done  syncope808  mean  already  existing  netbeans  plugin  syncope  info  please  see  thishttpssyncopeapacheorgdocsreferenceguidehtmlnetbeansideplugin  httpssyncopeapacheorgdocsgettingstartedhtmlnetbeansideplugin  please  install  plugin  let  work  local  syncope  installation  order  understand  work  interacts  syncope  goal  improve  current  netbeans  plugin  create  edit  also  format  groovy  script  used  extend  default  syncope  behavior  refer  syncope956  idea  im  talking  basically  mean  default  open  implementation  functionality  syncope  idm  improved  developed  pluggin  groovy  script  mechanism  allows  develop  custom  behavior  syncope  based  specific  project  requirement  herehttpsyncopeapacheorgdocsreferenceguidehtmlcustomizationcore  list  customizable  feature  since  netbeans  9httpscwikiapacheorgconfluencedisplaynetbeansapachenetbeans90beta  near  released  develop  plugin  referring  netbeans  9  currently  beta,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6705,search  funcionality  schema  think  would  useful  environment  several  issue  able  search  schema  using  attribute  key  typeetc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6706,binary  schema  reported  1  string  enum  boolean  long  double  date  type  supported  mail  thread  certificate  2  1  httpscwikiapacheorgconfluencedisplaysyncopeschema2cattributesandmappingschema2cattributesandmappingschema  2  httpsyncopeuser1051894n5nabblecomcertificatesinsyncopetd5706704html,1,0,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0
6707,syncdelta  preprocessing  connids  syncdeltahttpconnidtirasanetapidocs14orgidentityconnectorsframeworkcommonobjectssyncdeltahtml  encapsulates  information  retrieved  object  pull  syncdelta  content  seen  real  starting  point  pull  process  certain  entry  currently  instance  modified  several  pullactionshttpsgithubcomapachesyncopeblob20xcoreprovisioningapisrcmainjavaorgapachesyncopecoreprovisioningapipushpullpullactionsjava  method  option  meant  allow  flexibility  dealing  wicked  use  case  several  scenario  however  kind  modification  occurs  much  later  process  need  extract  separate  syncdelta  preprocessing  dedicated  pullactions  method  invoked  beginning,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6708,prevent  task  execution  request  running  task  done  report  syncope102  discard  task  execution  request  task  currently  running,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6709,report  required  readonly  payload  property  openapi  spec  openapi  spec  currently  missing  required  readonly  information  payload  property  example  post  user  endpoint  report  following  sample  value  codejava  creator  string  creationdate  20180211t141938905z  lastmodifier  string  lastchangedate  20180211t141938905z  key  string  type  string  realm  string  status  string  password  string  token  string  tokenexpiretime  20180211t141938905z  username  string  lastlogindate  20180211t141938905z  changepwddate  20180211t141938905z  failedlogins  0  securityquestion  string  securityanswer  string  suspended  true  mustchangepassword  true  code  better  instead  codejava  realm  string  class  orgapachesyncopecommonlibtouserto  password  string  username  string  securityquestion  string  securityanswer  string  code  also  note  jackson  class  management  similar  model  see  attachment  sample,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6710,provide  live  update  running  task  report  currently  quite  hard  figure  running  task  report  admin  console  provides  feedback  fact  related  job  running  log  file  checked  see  whats  going  impossible  inspect  many  user  pulled  far,1,1,1,1,1,0,1,0,0,0,0,0,0,0,0,1,0
6711,privilege  management  longmissing  feature  enabling  syncope  manage  user  privilege  across  whole  set  external  application,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6712,remediation  error  pull  might  arise  various  reason  example  value  provided  mandatory  attribute  value  failing  configured  validation  currently  entity  user  group  object  failing  pull  task  execution  simply  reported  error  logged  execution  result  new  feature  administrator  could  given  chance  perform  remediation  failing  entity  similar  fashion  approval  form,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
6713,use  remote  key  pull  match  internal  entity  following  syncope1182  extend  approach  internal  entity  matching  pull  eg  use  uid  rather  value  attribute  flagged  remote  key  mapping,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6714,create  structured  wizard  edit  scim  20  configuration,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0
6715,manual  reconciliation  provide  feature  admin  console  either  user  group  object  external  resource  topology  given  user  group  object  external  resource  allows  force  pushing  pulling  value  mapped  attribute,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
6716,resource  ignorecase  match  add  flag  externalresource  indicate  whether  match  propagation  pull  performed  casesensitive  currently  implemented,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6717,assign  membership  role  schema  either  membership  role  membership  role  currently  membership  role  schema  defined  membership  role  mean  defining  mandatory  role  schema  role  must  provide  value  corresponding  attribute  applies  membership  mechanism  extended  choose  schema  associated  role  membership  order  give  flexibility,1,0,1,0,1,0,0,0,1,0,1,0,0,1,1,0,1
6718,dont  expose  rest  list  method  anonymous  currently  order  provide  authenticationless  feature  console  mainly  selfregistration  rest  service  dont  require  authentication,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,1
6719,add  userrequestcontrollerexecute  execute  provided  userrequest  remove  success  job  currently  performed  console,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6720,add  pagination  approval  form  many  approval  task  console  take  long  time  load  form  necessary  add  pagination  query,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6721,user  role  membership  property  derived  schema  allow  user  role  membership  property  like  id  name  example  used  derived  schema  definition,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6722,rest  replace  bulk  operation  batch  request  currently  quite  bulk  rest  endpoint  however  quite  limited  requires  either  provide  particular  input  besides  set  element  act  design  dedicated  payload  purpose  batch  approach  provided  odata  40  specificationhttpdocsoasisopenorgodataodatav40ospart1protocolodatav40ospart1protocolhtmltoc372793748  seems  perfect  match  replace  partial  approach  provided  bulk  endpoint,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,1,1
6723,password  reset  provide  password  reset  feature  accessed  either  trough  console  via  rest  call,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
6724,password  required  resource  subscription  currently  cleartext  password  always  required  subscribing  new  external  resource  however  case  example  password  stored  symmetric  algorithm  avoided  example  could  case  1  2way  aka  symmetric  password  cipher  algorithm  configured  syncope  use  decrypted  password  syncopeuser  subscribe  new  resource  case  2  1way  aka  hash  asymmetric  password  cipher  algorithm  configured  syncope  cleartext  password  available  example  passed  via  usermod  provided  synchronizing  resource  provide  resourcebasis  mean  configure  new  password  generated  constant  random  password  generation  compliant  resource  password  policy  present  see  syncope121  provide  custom  java  class  discussion  thread  httpsyncopedev1063484n5nabblecomnewpasswordissuetd5589622html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6725,user  request  user  request  user  initiate  whichever  request  among  one  defined  example  assign  mobile  phone  give  group  ad  behalf  others  initiated  request  follow  path  might  include  one  approval  step  also  limitation  number  concurrent  request  user  initiate  unfortunately  current  implementation  able  properly  implement  user  request  briefly  outlined  among  thing  impossibility  handle  approval  process  time  per  user  hence  major  refactoring  needed  remove  approval  feature  current  flowable  user  workflow  adapter  define  new  userrequest  entity  includes  least  triggering  condition  flowable  workflow  definition  possibly  containing  approval  form  adjust  rest  service  admin  console  enduser  ui  cope  new  user  request  entity,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6726,support  one  local  connector  bundle  directory  zero  connids  connector  server  currently  single  directory  scanned  searching  connids  connector  bundle  however  shouldnt  hard  add  support  directory  moreover  also  easy  integrate  remote  connids  connector  server  either  java  net  via  connectorinfomanagerfactorygetinstancegetremotemanager  instead  connectorinfomanagerfactorygetinstancegetlocalmanager,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
6727,make  configurable  resource  check  timeout  waiting  long  timeouts  resource  check  negatively  affect  functionality  console  give  possibility  disable  configure  check  timeouts,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6728,reduce  usage  reflection  improve  overall  performance  source  code  especially  core  extension  filled  reflectionintensive  invocation  supposed  negatively  affect  overall  performance  mostly  reflectionutils  spring  beanutilscopyproperties  reflectiontostringbuilder  equalsbuilderreflectionequals  hashcodebuilderreflectionhashcode,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1,0,1
6729,add  unclaim  capability  request  add  unclaim  capability  order  revert  claim  user  request  generic  createupdate  approval  coming  user  workflow,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6730,leverage  postgresqls  jsonb  type  discussedhttpslistsapacheorgthreadhtmlbcb72efa271c13e86a00b236d05518ebd56ee741624b1160f3fe4ac43cdevsyncopeapacheorg3e  enhance  jpa  layer  empowering  postgresqls  jsonbhttpswwwpostgresqlorgdocs10datatypejsonhtml  datatype  user  group  object  attribute,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6731,dynamic  role  group  membership  introduce  concept  dynamic  group  role  membership  eg  user  part  role  group  matching  given  search  condition,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,1
6732,concurrent  propagation  add  option  execute  propagation  ops  concurrently  consider  must  continue  propagate  towards  primary  resource  sequentially  respect  specified  priority  maybe  propagation  ops  towards  nonprimary  resource  executed  sequentially  respect  priority  specified  concurrently  case  resource  priority,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6733,remove  usersearchnullattr  view  remove  usersearchnullattr  view  affect  performance  negatively,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6734,permit  provide  custom  implementation  notificationmanager  auditmanager  permit  specify  custom  implementation  provisioningproperties,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6735,perform  inmemory  match  dynamic  condition  various  condition  specified  dynrealms  dynamic  group  role  membership  needed  several  place  check  given  user  group  object  match  condition  today  check  performed  via  search  eventually  involves  database  access  however  strictly  necessary  whole  check  could  performed  inmemory,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6736,configurable  user  request  approval  make  configurable  whether  userrequest  object  create  update  delete  need  approved  condition  including  membership  certain  role,1,0,1,0,1,0,1,0,1,0,1,1,1,0,0,0,1
6737,new  component  sra  api  gateway  highlevel  api  gatewayhttpsmicroservicesiopatternsapigatewayhtml  http  reverse  proxy  exposing  set  public  apis  response  invocation  public  api  result  configurable  process  involves  invocation  one  internal  apis  capability  configurable  mapping  public  internal  apis  authentication  authorization  enforcement  throttling  monitor  statistic  lifecycle  management  draft  staging  published  deprecated  reference  inspiration  httpsdocswso2comdisplayam260keyconcepts  httpsistioiodocsconceptswhatisistio  httpsgithubcomgetheimdallheimdall  good  candidate  building  upon  appears  spring  cloud  gatewayhttpsspringioprojectsspringcloudgateway,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6738,add  executor  information  task  report  execution  currently  possible  know  user  started  given  task  report  cannot  apply  scheduled  execution  naturally  always  run  admin,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6739,provide  refresh  button  task  report  modal  window  task  report  modal  window  would  benefit  refresh  execution  button  get  update  information  thing  happened  modal  window  open,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6740,provide  propagationactions  maintain  conservative  membership  policy  management  user  group  assigned  ldap  ad  group  managed  syncope  modification  user  syncope  remove  assignment  give  possibility  provide  conservative  management  assignment  group  user  resource  group  managed  syncope  group  already  assigned  user  ldap  ad  removed  group  managed  syncope,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6741,manage  creator  lastmodifier  approver  information  syncopeuser  bean  add  populatemanage  following  syncopeuser  bean  attribute  1  creator  created  user  2  lastmodifier  performed  last  modification  user  profile  3  approver  every  approver  approved  operation  user,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6742,rich  client  library  implement  client  library  encapsulated  single  jar  providing  client  access  feature,1,0,1,0,1,0,1,0,0,0,1,0,0,0,0,1,0
6743,find  anys  using  fiql  sql  improvement  pr  contains  improvement  anys  searched  using  fiql  query  resulted  sql  query  find  anytokeys  huge  list  clause  effective  realm  replaced  clause  codesql  select  uanyidsvusername  select  distinct  anyid  usersearch  realmid  anyid  select  distinct  anyid  usersearch  lastchangedate  uusersearch  sv  uanyidsvanyid  uanyid  select  anyid  usersearch  realmid  select  id  realmid  realm  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  id  order  svusername  asc  code  anys  searched  key  lot  single  sql  query  executed  improved  using  single  sql  query  clause,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6744,document  restful  service  provide  dynamic  documentation  restful  service  easiest  effective  way  seems  via  xslt  processing  wadl  information  autogenerated  cxf  see  1  information  relevant  discussion  dev  ml  2  1  httpcxfapacheorgdocsjaxrsservicesdescriptionhtmljaxrsservicesdescriptionwadlautogeneration  2  httpsyncopedev1063484n5nabblecomdiscussdocumentrestfulapistd5714317html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6745,support  scim  rest  api  scim  system  crossdomain  identity  management  open  api  managing  identity  specification  complete  published  ietf  overview  detailed  specification  found  official  website  httpwwwsimplecloudinfo  syncope  core  already  provides  fullfledged  restful  interfacehttpssyncopeapacheorgdocsreferenceguidehtmlrest  normally  available  rest  idea  add  another  restful  interface  available  scim  compliant  scim  v2  specification  referred  new  rest  interface  developed  extensionhttpssyncopeapacheorgdocsreferenceguidehtmlextensions  whose  feature  expose  fully  compliant  scim  v2  restful  interface  translate  incoming  outgoing  payload  scim  format  syncope  standard  format  invoke  underlying  logic  layerhttpssyncopeapacheorgdocsreferenceguidehtmllogic  actual  operation  implementation  additional  feature  needed  mapping  standard  syncope  schemahttpssyncopeapacheorgdocsreferenceguidehtmlschema  scim  attribute,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6746,virtual  attribute  cache  provide  simple  cache  virtual  attribute  value  order  avoid  query  external  resource  every  time,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6747,better  way  override  console  page  better  way  override  console  page  war  overlay,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6748,new  admin  ui  refactor  rewrite  current  console  new  cleaner  admin  ui  important  usability  improvement  provide  sensible  contextual  help  message  mostly  form  field  1  httpsyncopedev1063484n5nabblecomaboutadminconsolerefactoringtd5710115html  2  httpmarkmailorgmessagewtamknssq42pyjjc,1,1,1,0,1,1,0,0,0,1,1,0,1,0,1,0,0
6749,cli  admin  tool  hard  make  simple  commandline  tool  get  set  syncopeconf  item,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6750,passthrough  authentication  provide  possibility  authenticate  user  external  resource,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
6751,improve  virtual  attribute  value  retrieving  moment  virtual  attribute  value  retrieving  needed  search  per  virtual  attribute  performed  behaviour  must  changed  could  optimized  performing  single  search  virtual  attribute  mapped  resource,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6752,check  mandatory  condition  virtual  derived  attribute  mandatory  condition  jexl  expression  evaluating  boolean  specified  schema  mapping  1  enforce  mandatory  condition  checked  well  syncope  consider  attribute  part  schema  mapping  mandatory  condition  evaluated  true  mandatory  even  though  corresponding  attribute  schema  defined  mandatory  currently  feature  working  plain  attribute  schema  derived  virtual  1  httpscwikiapacheorgconfluencedisplaysyncopeschemaattributesandmappingschema2cattributesandmappingschemamapping,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6753,role  owner  add  notion  optional  inheritable  role  owner  syncopeuser  syncoperole  right  manage  role  role  owner  automatically  entitled  make  modification  owned  role  descendant  inheritowner  true,1,1,0,0,0,1,0,0,0,0,0,1,1,0,0,1,1
6754,using  standard  jaxrs  api  syncope  introducing  apache  cxf  w  stack  current  rest  interface  based  spring  webservice  framework  goal  task  replace  spring  cxf  relay  jaxb  jaxrs  annotation  rather  spring  annotation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6755,remove  code  replication  managing  resource  schema  mapping  remove  code  replication  managing  resource  schema  mapping  use  schemamappingutil  class  wrap  common  action,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6756,move  persistence  persistence  impl  separate  module  core  module  currently  contains  many  part  syncope  make  bigger  complex  necessary  possible  modularization  move  internal  model  orgapachesyncopecorepersistence  persistence  impl  orgapachesyncopecorepersistenceimpl  core  separate  module  one  big  advantage  would  jpa  code  enhancement  would  run  model  module  currently  run  problem  cxf  migration  running  rest  itests  core  may  caused  eclipse  overwriting  enhanced  class  plain  class  model  peristence  class  separate  module  could  leave  eclipse  would  issue  anymore  another  advantage  would  persistence  test  could  run  persistence  impl  module  working  core  would  run  time,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,0
6757,resolve  dependency  cycle  persistence  rest  syncope  core  analysing  could  move  persistence  persistence  impl  separate  module  found  lot  dependency  cycle  syncope  core  module  added  structure  101  diagram  cycle  issue  take  look  especially  cycle  persistence  rest  core  important  prevent  u  moving  package  core  already  done  experimentation  solve  cycle  pretty  sure  fix,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0
6758,improve  usertestitcase  roletestitcase  tasktestitcase  test  orgapachesyncopecorerestusertestitcase  highly  repetitive  code  attributetos  attributemods  created  created  two  small  helper  method  able  make  test  150  line  smaller,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6759,consolidate  task  execution  tasktestitcase  tasktestitcase  common  code  execute  task  wait  till  task  finish  consolidate  code  helper  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6760,implement  roleownerschema  role  propagation  synchronization  syncope225  introduced  concept  role  owner  could  either  user  another  role  time  test  content  provides  example  role  owner  propagated  empowering  derived  attribute  ownerdn  approach  working  propagation  make  accountlink  expression  duplicated  complete  approach  define  new  type  internal  mapping  roleownerschema  role  propagation  mappingutilgetintvalues  userowner  null  propagating  resource  umapping  defined  roleowner  null  propagating  resource  rmapping  ongoing  propagation  accountlink  accountid  accountlink  defined  generated  given  value  external  attribute  mapped  roleownerschema  role  synchronization  connobjectutilgetattributabletofromconnobject  value  present  connectorobject  role  synchronized  value  must  used  searching  connector  either  objectclassaccount  objectclassgroup  unique  match  found  matching  connectorobject  used  find  corresponding  syncope  entity  user  role  userowner  roleowner  role  synchronized  set  especially  case  roleowner  precedence  issue  must  taken  account  might  happen  fact  owned  role  synchronized  owner  role  synchronization  take  place,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6761,java  class  sync  policy  correlation  rule  give  possibility  specify  java  class  sync  policy  implement  custom  correlation  rule  specified  custom  rule  evaluated  place  correlation  attribute  rule,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6762,create  transitional  service  interface  switch  test  console  use  preparation  change  use  cxf  instead  spring  mvc  rest  controller  issue  introduce  transitional  service  interface  like  userservice  userservice  interface  later  used  core  provide  usercontroller  console  access  service  remotely  make  transition  easier  idea  already  introduce  interface  upfront  change  test  console  use  switch  implementation  interface  simply  use  resttemplate  cover  applied  similarly  spring  mvc  rest  controller,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6763,enable  rest  integrationtests  run  per  build  currently  many  rest  integrationtests  run  try  rerun  test  fail  due  fact  resource  already  exists  resource  deleted  previously  available  longer  work  fine  mvn  clean  verify  since  test  run  exactly  development  phase  inconvenient  testing  new  feature  refactorings  one  would  like  run  test  several  time  especially  fail  without  need  rebuildpackagedeploy  whole  core  module  task  jira  ticket  use  random  identifier  resource  user  role  avoid  collision  running  test  multiple  time  case  also  preferable  use  try  final  statement  cleanup  previously  created  resource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6764,encrypted  schema  1  main  purpose  store  arbitrary  string  value  encrypted  database  enforced  law  example  2  defining  encrypted  schema  must  provide  cypher  algorithm  used  passphrase  passphrase  stored  syncope  encrypted  internal  key  le  like  already  user  password  3  creating  attribute  schema  value  automatically  encrypted  syncope  using  provided  algorithm  passphrase  4  reading  attribute  schema  eg  contained  attributeto  value  sent  encrypted  know  algorithm  passphrase  able  decrypt  moreover  think  make  admin  console  able  show  attribute  value  encrypted  default  decrypt  demand  asking  algorithm  passphase  5  propagating  synchronizing  attribute  schema  guardedstring  used  string  6  changing  algorithm  passpshase  existing  schema  new  value  encrypted  old  value  remain  naturally  one  provide  update  procedure  1  httpmarkmailorgmessagerg7ryeknkrzae4xj,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6765,connector  instance  timeout  provide  execution  timeout  connectorfacadeproxy  method  timeout  must  specified  1  10x  using  global  configuration  parameter  timeout  connector  instance  2  11x  using  connector  instance  configuration  parameter  different  timeout  different  instance,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6766,refactor  client  module  move  common  class  common  module  currently  lot  common  class  inside  client  module  class  needed  client  server  side  goal  issue  introduce  new  common  module  contains  class  needed  side  client  server,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6767,typed  syncopeconf  currently  syncopeconf  instance  string  string  pair  course  various  drawback  check  mandatory  value  enums  available  relatively  easy  create  set  sschema  sattr  sattrvalue  sattruniquevalue  similar  currently  available  user  membership  role  replace  current  syncopeconf,1,0,1,0,1,0,1,0,0,0,0,0,0,1,1,0,1
6768,move  notfoundexception  corepersistencedao  notfoundexception  currently  located  util  good  place  part  dao  well  service  interface  like  discussed  dev  list  agree  move  exception  corepersistencedao  rest  service  exception  mapped  rsnotfoundexception,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6769,show  information  version  license  currently  static  label  core  console  version  add  new  link  open  modalpage  version  project  information  eg  link  license,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6770,supporting  feed  item  query  language  fiql  currently  search  condition  build  using  custom  component  orgapachesyncopecommonsearch  goal  issue  replace  current  implementation  support  supporting  feed  item  query  language  fiql  detail  take  look  discussion  development  mailing  list  httpsyncopedev1063484n5nabblecomdiscussfeeditemquerylanguagetd5712490html,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
6771,mapping  syncopeclientcompositeexception  client  side  actually  almost  exception  status  badrequest  notfound  mapped  syncopeclientcompositeerrorexception  client  side  absolutely  ok  composite  exception  containing  number  subexceptions  like  validation  propagation  however  single  exception  make  sense  map  syncopeclientcompositeerrorexception  directly  corresponded  exception  type  candidate  deadlock  existingresource  dataintegrityviolation  genericpersistence  unauthorizedrole  proposed  mapping  make  exception  processing  easy  effective  httpscwikiapacheorgconfluencedisplaysyncoperemoteexceptions,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6772,provide  feature  reloading  connector  feature  particularly  useful  project  deployment  allow  refresh  connector  bundle  configuration,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,1,1
6773,provide  access  user  role  data  external  resource  statuspanel  show  readonly  data  read  via  resourcecontrollergetobject  associated  resource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6774,disable  mapping  tab  underlying  connector  support  correspondent  objectclass  given  connector  support  objectclassaccount  enable  user  mapping  tab  otherwise  keep  disabled  given  connector  support  objectclassgroup  enable  role  mapping  tab  otherwise  keep  disabled,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6775,make  password  management  optional  currently  syncopeuserpassword  annotated  notnull  several  consequence  propagation  synchronization  even  admin  console  however  would  nice  addition  make  password  storage  management  optional  complex  idm  scenario  fact  might  even  business  requirement  store  password  syncope  internal  storage,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6776,full  reconciliation  syncope  resource  implement  full  reconciliation  syncope  towards  specific  resource  unmatching  user  found  syncope  resource  ignore  unlink  resource  keep  user  syncope  remove  resource  link  create  create  user  resource  create  capability  given  delete  remove  user  syncope  matching  user  found  syncope  resource  ignore  update  unlink  perform  deprovisioning  delete  capability  given  delete  delete  syncope  perform  deprovisioning  delete  capability  given,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6777,resource  unlink  give  possibility  unlink  resource  without  performing  deprovision  1  take  care  role  well  2  feature  must  independent  connector  capability,1,1,1,0,1,1,1,0,0,0,0,0,0,0,0,1,0
6778,inconsistent  status  user  edit  form  exception  returned  bad  propagation  primary  resource  creation  save  user  propagated  primary  resource  propagation  fails  due  error  return  propagation  exception  console  user  edit  form  go  inconsistent  status  stucks  possible  solution  go  directly  case  propagation  exception  summary  page  reporting  propagation  status  resource  particular  propagation  signaling  icon  failure  may  abled  show  exception  message  caught  propagationstatusto,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6779,replace  logback  log4j  2  discussed  dev  ml  1  1  httpsyncopedev1063484n5nabblecomdiscussreplacelogbackwithlog4j2td5714012html,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0
6780,invoke  bean  validation  via  jpa  entity  listener  currently  bean  validation  triggered  via  custom  aop  interceptor  1  save  method  dao  class  however  could  changed  happen  jpa  entity  listener2  resulting  widespread  robust  control  moreover  dependency  namely  aspectj  could  cut  1  httpssvnapacheorgreposasfsyncopetrunkcoresrcmainjavaorgapachesyncopecorepersistencevalidationentityentityvalidationinterceptorjava  2  httpopenjpaapacheorgbuilds222apacheopenjpadocsjpaoverviewpccallbackshtmljpaoverviewentitylistenersusing,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0
6781,add  claim  user  request  trace  user  request  history  syncopeuser  bean  add  claim  user  request  trace  user  request  history  syncopeuser  bean,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6782,add  ability  delete  user  username  via  rest  api  currently  possible  delete  user  username  via  rest  api  via  user  id  task  add  support,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6783,provide  user  role  preprocessing  mechanism  storingpropagatingsynchronizing  specific  user  role  preprocessor  could  called  order  allow  kind  manipulation  actual  operation  take  place  idea  provide  interface  implemented  overlay  order  perform  custom  preprocessing  operation  custom  implementation  class  name  could  defined  global  configuration  new  feature  would  give  handle  provide  several  attribute  value  manipulation  like  specific  value  translation  something  else,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6784,improve  audit  info  1  provide  info  case  operation  failure  well  currently  missing  2  increase  audit  info  message  length  bound  3  increase  audit  info  case  createdeleteupdate  userrolemembershipresource,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6785,rest  refactoring  complete  possible  adherence  restful  best  practice  started  cxf  migration  110  particular  fix  warning  reported  1  take  action  discussed  2  1  httpscwikiapacheorgconfluencedisplaysyncoperestapiupgrade  2  httpmarkmailorgmessagei3mtvq2vkseukbq2,1,1,1,0,1,1,1,1,1,1,1,0,0,0,0,1,1
6786,provide  resource  link  associate  provision  independent  feature  complete  abstractresourceassociator  1  created  syncope393  positive  method  eg  link  associate  provision  1  httpssvnapacheorgreposasfsyncopetrunkcoresrcmainjavaorgapachesyncopecorerestcontrollerabstractresourceassociatorjava,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6787,support  etagbased  conditional  request  user  role  syncope15  introduced  lastchangedate  creationdate  field  entity  namely  syncopeuser  syncoperole  externalresource  information  transferred  matching  eg  userto  roleto  resourceto  mean  respective  service  userservice  roleservice  could  enhanced  following  way  1  add  etag  response  header  method  directly  indirectly  via  responseentity  generated  creationdates  lastchangedates  value  2  implement  conditional  postput  logic  update  effective  update  request  effectively  accepted  provided  etag  match  latest  modification  currently  available,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
6788,support  returning  content  create  update  rest  method  mostly  userservice  roleservice  returning  created  updated  deleted  resource  response  body  entity  could  nice  provide  prefer  preferenceapplied  similar  respectively  1  2  http  header  mechanism  allowing  caller  declare  interested  getting  created  updated  deleted  resource  back  operation  result  status  1  httpmsdnmicrosoftcomenuslibraryhh537533aspx  2  httpmsdnmicrosoftcomenuslibraryhh554623aspx,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,1
6789,provide  debug  logging  controller  method  input  output  currently  controller  method  logdebug  statement  beginning  end  body  containing  input  parameter  output  returned  would  much  nicer  bind  logic  improved  audit  per  syncope422,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6790,replace  role  action  label  icon  available  throughout  admin  console  replace  link  accessing  role  management  feature  add  child  edit  drop  icon,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6791,provide  value  connids  apiconfiguration  via  conninstance  entity  provide  support  finegrain  configuration  connid  connector  bundle  via  apiconfiguration  storing  related  parameter  value  syncope  conninstance  entity  httpmarkmailorgmessagey5gbuiczztjvndvo,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6792,embed  activiti  modeler  graphical  workflow  editing  activiti  default  user  workflow  engine  shipping  latest  version  open  source  version  ki  bpm  process  solution  basically  web  editor  used  author  bpmn  20  compliant  process  graphically  information  httpwwwactivitiorgcomponentshtml  idea  embed  component  admin  console  next  current  xmlbased  editor,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6793,add  ability  search  role  via  rest  api  currently  possible  search  role  via  rest  api  however  search  list  user  member  particular  role  may  want  ability  search  role  attribute  etc  dont  forget  refactor  console  search  panel  accordingly,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6794,use  cached  virtual  attribute  value  offline  resource  virtual  attribute  cache  mustnt  expired  case  offline  resource  cached  value  returned  case  resource  unavailability  see  httpsyncopeuser1051894n5nabblecomvirtualattributeswithofflineresourcestd5707443html  discussion  thread,1,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,0
6795,use  webjars  avoid  including  3rd  party  j  cs  file  admin  console  currently  using  jqueryui  codemirror  two  javascript  project  included  source  tree  also  reported  license  notice  file  j  cs  file  webjars  project  1  offer  better  alternative  accomplish  provide  specific  binding  apache  wicket  reference  framework  admin  console  1  httpwwwwebjarsorgdocumentation,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0
6796,default  datasource  us  basicdatasource  replace  orgspringframeworkjdbcdatasourcedrivermanagerdatasource  orgapachecommonsdbcpbasicdatasource  recommended  spring  httpdocsspringiospringdocscurrentspringframeworkreferencehtmljdbchtmljdbcconnections  make  property  isolationlevelname  configurable  persistenceproperties  default  isolationreadcommitted  see  full  discussion  dev  ml  httpmarkmailorgmessage33aheawb5irzl3xc,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6797,add  information  component  refer  certain  policy  add  third  tab  policy  modal  window  showing  component  referring  policy  edited,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6798,implement  correlation  rule  management  push  task  1  extend  connector  infrastructure  order  perform  search  based  one  attribute  condition  2  give  possibility  specify  correlation  rule  push  task  like  already  done  sync  task,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1
6799,make  velocity  tool  available  template  notification  discussed  dev  mailing  list  1  could  useful  make  velocity  tool  available  template  notification  eg  able  urlencode  user  name  inside  generated  link  1  httpsyncopedev1063484n5nabblecomescapinginvelocitytemplatesfornotificationstd5714981html,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6800,cache  custom  implementation  class  syncope  defines  many  interface  allows  extend  customize  behavior  detail  1  list  available  implementation  given  various  restful  service  every  request  clearly  optimized  moreover  since  classpath  change  webapp  initialized  could  case  cache  information  startup  1  httpscwikiapacheorgconfluencedisplaysyncopeextendingsyncope,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
6801,allow  list  propagationactions  resource  syncactions  synctask  pushactions  pushtask  currently  resource  define  single  propagationactionshttpscwikiapacheorgconfluencedisplaysyncopepropagationactionsclass  class  synctask  define  single  syncactionshttpscwikiapacheorgconfluencedisplaysyncopesyncactionsclass  pushtask  define  single  pushactionshttpscwikiapacheorgconfluencedisplaysyncopepushactionsclass  class  somewhat  limiting  list  action  class  invoked  specified  order  look  powerful,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6802,support  propagating  noncleartext  password  external  resource  similarly  syncope313  synchronization  seems  feasible  provide  propagation  action  class  say  dbpasswordpropagationactions  ldappasswordpropagationactions  propagate  noncleartext  password  value  external  resource  might  require  change  related  connector  bundle,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6803,remove  md5  supported  password  cipher  algorithm  md5  currently  used  default  password  cipher  algorithm  remove  ability  use  md5  switch  using  secure  alternative,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6804,make  value  encryption  parametric  passwordencoder  11x  encryptor  12x  class  salt  mechanism  configuration  hardcoded  ldap  server  doesnt  use  salt  mechanism  configuration  password  cant  matched  authentication  example  ssha  defined  rfc  2307  code  digestersetiterations1  digestersetsaltsizebytes8  digestersetinvertpositionofplainsaltinencryptionresultstrue  digestersetinvertpositionofsaltinmessagebeforedigestingtrue  digestersetuselenientsaltsizechecktrue  code  see  jasypts  javadocshttpjasyptorgapijasypt192orgjasyptutilpasswordrfc2307rfc2307sshapasswordencryptorhtml  detail  encryptor  read  global  configuration  parameter  configure  aspect  way  ciphered  value  password  value  12x,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6805,empower  etag  console  admin  console  yet  empowering  etag  feature  introduced  syncope429,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,0
6806,report  default  value  connector  property  currently  default  value  connector  property  returned  rest  method  shown  admin  console  information  however  available  connid  framework  need  picked,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6807,use  json  serialized  pojos  internal  storage  currently  different  kind  pojos  stored  serialized  jpa  entity  field  connector  configuration  attribute  propagation  task  user  role  template  sync  task  till  object  deserialized  xml  via  xstream  remove  dependency  also  improve  performance  using  jackson  json,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,0,0
6808,externalize  war  configuration  main  webapps  core  console  require  several  configuration  file  property  work  properly  currently  configuration  file  need  reside  webapps  classpath  ideally  possible  define  configuration  directory  defined  via  maven  property  file  loaded  would  allow  implement  handful  deployment  scenario  eg  deploy  war  file  either  test  production  environment  idea  apply  email  template,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6809,ability  configure  user  role  membership  attribute  display  order  currently  admin  console  barely  display  defined  user  role  membership  attribute  alphabetical  order  enhanced  providing  mean  configure  attribute  order  displayed  admin  console  form  either  administration  selfmanagement  purpose,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6810,improving  management  xml  property  file  inside  installer  currently  installer  doesnt  read  xml  property  file  inside  core  console  module  embedded  statically  java  class  causing  following  error  syncope  syncope615,1,0,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0
6811,code  reorganization  heading  200  proposal  discussedhttpmarkmailorgmessagexfxn2xc6iolcmysp  code  reorganization  order  obtain  modularity  growing  codebase,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1
6812,improve  virattrcache  management  currently  virattrcache  final  class  turning  interface  default  implementation  would  open  possibility  provide  implementation  proper  cache  provider  say  ehcache,0,1,0,1,0,0,0,1,0,1,0,0,0,0,0,0,0
6813,provisioning  manager  integration  last  year  help  syncope  team  proposed  early  reformulation  provisioning  phase  provisioning  refers  method  used  provide  user  role  functionality  main  goal  proposal  reorganize  phase  allowing  custom  provisioning  behaviour  definition  provisioning  manager  see  1  detail  current  strategy  adopted  syncope  make  difficult  definition  custom  provisioning  behaviour  solution  enclosed  issue  aim  decompose  provisioning  phase  previously  userrole  controller  deal  directly  provisioning  proposal  controller  delegate  task  provisioning  manager  first  task  move  provisioning  functionality  provisioning  manager  inspect  userrole  controller  code  find  anymore  workflow  propagation  dependency  development  thought  make  provisioning  pluggable  order  allow  choice  provisioning  engine  default  provisioning  engine  choosed  editing  provisioningproperties  file  reason  hardcoded  previous  strategy  default  provisioning  manager  order  keep  standard  syncope  behaviour  proposed  initially  wanted  also  experiment  provisionig  manager  based  apache  camel  camel  powerful  integration  framework  implementing  enterprise  integration  pattern  current  solution  embeds  provisioning  logic  camel  route  moreover  current  solution  extends  also  syncope  console  added  new  new  functionality  related  camel  case  allows  read  edit  route  definition  find  new  service  consoleconfigurationroutes  section  case  route  expressed  spring  dsl  finish  thought  create  github  pull  request  2in  order  give  syncope  team  member  examine  work  possibly  integrate  1  httpsyncopedev1063484n5nabblecomproposalanapachecamelintegratationproposaltd5714531html  2  httpsgithubcomapachesyncopepull2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6814,camel  provisioning  manager  separate  user  role  route  management  introduce  unit  test  current  camel  provisioning  manager  distinguish  user  role  operation  rest  call  console  module  partially  support  difference  maybe  better  finegrained  method,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6815,let  user  choose  extension  syncope620  project  generated  installer  include  neither  activiti  workflow  adapter  camelbased  provisioning  manager  respective  plain  java  counterpart  possible  let  user  choose  workflow  adapter  provisioning  manager  include  moreover  optional  swagger  component  chosen  included,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
6816,notification  configuration  missing  label  event  sync  process  include  many  operation  example  “create””assign””link””unlink”  etc…  notification  configuration  find  “create””update””delete””none”  intercept  failuresuccess  “assing”  operation  different  “create””update””delete””none”,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6817,domain  purpose  new  feature  provide  possibility  defining  separated  container  entity  currently  managed  syncope  order  allow  execution  multitenant  environment  discussion  wiki  httpscwikiapacheorgconfluencedisplaysyncope5bdiscuss5ddomains,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1
6818,extend  control  asynchronous  job  execution  asynchronous  job  execution  generally  delegated  quartz  currently  checked  completion  indirectly  checking  status  related  jpa  entity  taskexec  reportexec  rest  endpoint  provided  reporting  job  execution  providing  ability  control  eg  stop  pause  resume,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6819,remove  overloaded  method  rest  service  various  rest  service  offer  overloaded  list  search  method  eg  method  differ  parameter  signature  trigger  need  cxfs  custom  queryresourceinfocomparator  order  able  select  appropriate  method  based  http  parameter  inline  jaxrs  best  practice  specifically  parameter  affect  method  selection,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6820,option  ignore  user  role  synchronization  push  currently  user  role  provided  external  resource  synchronization  sent  external  resource  push  considered  synchronization  push  matching  unmatching  rule  powerful  addition  provide  mean  safely  ignore  user  role  proper  place  implementing  custom  logic  syncactions  pushactions,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6821,object  introduce  concept  object  eg  extend  provisioning  engine  support  generalpurpose  definable  entity  besides  current  user  group  see  page  realm  understand  former  role  renamed  group  feature  onboard  syncope  suitable  managing  printer  service  thing  internetofthings  detail  httpscwikiapacheorgconfluencedisplaysyncope5bdiscuss5danyobjects,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6822,deferred  task  current  schedtask  synctask  pushtask  immediately  set  execution  without  cron  expression  aspect  enhanced  adding  instant  future  given  task  scheduled,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6823,custom  account  password  policy  specification  account  password  policy  fixed  specification  worth  reconsidering  aspect  order  allow  deploymentbased  extension  customization,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0
6824,must  change  password  next  login  add  feature  user  forced  administrator  change  password  next  login  idea  flag  set  given  user  user  requesting  rest  resource  authorized  method  one  updating  password  value  resource  raise  appropriate  error  message,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6825,use  connid  14  pagination  api  connid  14  introduces  standard  pagination  sorting  api  querying  connector  moment  ldap  connector  featuringhttpsconnidatlassiannetbrowseldap16  active  directory  connector  expectedhttpsconnidatlassiannetbrowsead47  align  soon,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6826,patch  put  update  user  group  object  currently  anyservice  derivative  providing  rest  service  user  group  object  defines  update  method  follows  code  post  pathkey  produce  mediatypeapplicationxml  mediatypeapplicationjson  consumes  mediatypeapplicationxml  mediatypeapplicationjson  response  updatenotnull  mod  anymod  code  mod  extends  anymod  idea  move  definition  like  follows  code  patch  pathkey  produce  mediatypeapplicationxml  mediatypeapplicationjson  consumes  mediatypeapplicationxml  mediatypeapplicationjson  response  updatenotnull  p  anypatch  code  eg  restcompliant  patchbased  update  additional  benefit  simplifying  interaction  client  javascript  particular  based  syncopeclient  java  library  could  also  useful  add  second  update  method  follows  code  put  pathkey  produce  mediatypeapplicationxml  mediatypeapplicationjson  consumes  mediatypeapplicationxml  mediatypeapplicationjson  response  updatenotnull  anyto  code  extends  anyto  latter  would  allow  build  simpler  create  update  interaction  client  based  syncopeclient  java  library,1,0,1,0,1,0,1,1,1,0,1,0,0,0,0,1,1
6827,allow  restrict  task  list  provide  mean  filter  task  list  returned  taskservice  external  resource  push  sync  propagation  task  external  resource  user  group  object  propagation  task  currently  taskservicelist  return  matching  task  given  type,1,1,1,0,1,1,1,0,0,0,1,0,0,1,1,1,1
6828,pluggable  transformation  resource  mapping  item  currently  internal  attribute  transferred  external  resource  according  related  mapping  actual  value  simply  copied  one  want  transform  value  propagation  option  available  generalpurpose  propagationactionshttpscwikiapacheorgconfluencedisplaysyncopepropagationactionsclass  class  similarily  synchronization  generalpurpose  syncactionshttpscwikiapacheorgconfluencedisplaysyncopesyncactionsclass  class  approach  working  anyway  might  overkill  additional  extension  point  defined  plug  value  transformer  optionally  associate  mapping  item,1,0,1,0,1,0,0,0,0,0,1,0,0,0,0,0,0
6829,rolemembership  attribute  propagation  propagation  rolemembership  attribute  must  possible  user  provisioning  mapped  rolemembership  attribute  ignored  synchronization,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6830,documentation  artifact  discussedhttpmarkmailorgmessagedpleneuzrfcsmq2r  mailing  list  setup  asciidoctormavenplugin  order  generate  alongside  build  project  documentation  html  pdf  generated  documentation  part  release  artifact  always  uptodate  current  release  preliminary  result  available  httpsyncopeapacheorg200snapshotdocs,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6831,swagger  extension  recently  cxf  added  native  supporthttpscxfapacheorgdocsswagger2featurehtml  swagger  mean  syncope  generate  swagger  description  jaxrs  service  also  provide  extension  interacting  based  swagger  uihttpswaggerio,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6832,conform  logger  service  stack  others  notice  loggerserviceimplread  method  performs  code  loggerlogic  create  new  method  called  read  also  loggerlogic  put  actual  loggerserviceimplread  code,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6833,virtual  attribute  management  refactoring  change  way  virtual  attribute  internally  managed  introducing  concept  linking  mapping  removing  need  explicitly  assign  virtual  attribute  user  group  object  discussion  wiki  httpscwikiapacheorgconfluencedisplaysyncope5bdiscuss5dvirtualattributesmanagementrefactoring,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,1,1
6834,add  possibility  override  capability  connector  currently  resource  configuration  override  connector  instance  property  would  useful  extend  behaviour  connector  capability,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1
6835,derived  attribute  management  refactoring  similarly  syncope709  virtual  change  way  derived  attribute  handled  particular  derived  attribute  assigned  user  group  object  long  user  group  object  assigned  anytypeclass  derived  schema  part  also  assigned  related  derived  attribute  derived  attribute  mapped  propagation  synchronization,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1
6836,finegrained  entitlement  object  current  entitlement  object  managed  user  group  result  anyobjectcreate  entitlement  owned  one  create  instance  type  defined  need  change  finegrained  management  entitlement  defined  type  defined  anyobjectcreate  rather  printercreate  foldercreate,1,0,1,0,1,0,0,0,1,0,0,0,0,0,0,1,1
6837,filtered  reconciliation  synchronization  discussed  mailing  listhttpmarkmailorgmessageck64v6jy4nseau2s  nice  improvement  synchronization  would  allow  definition  filtered  reconciliation  allowing  synchronize  certain  entity  external  resource  moment  synchronization  allowed  full  reconciliation  relying  connids  search  without  filter  active  synchronization  relying  connids  sync  leveraging  connids  search  appropriate  filter  filtered  reconciliation  obtained,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6838,exchange  json  default  rest  endpoint  currently  configured  dealing  xml  json  format  xml  set  default  accept  contenttype  http  header  set  changing  default  format  json  appear  wiser  nowadays,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6839,selectively  delete  task  report  execution  introduce  ability  delete  execution  given  task  report  date  parameter,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6840,statistic  simple  inexpensive  number  memory  usage  user  count  resource  count  provided  default  additional  metric  enabled  collected  purpose  idea  let  admin  console  display  number  dashboard  graph  usage  jmx  may  worth,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6841,allow  dynamic  reloading  report  stylesheets  syncope760  mail  template  manage  report  reportlets  xslt  xslfo  content  entity  use  filesystem,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6842,rename  sync  pull  rename  sync  thing  throughout  whole  system  pull  couple  reason  word  synchronization  evokes  kind  bidirectional  flow  instead  intend  pulling  user  group  object  external  resource  relying  either  search  sync  connid  operation  already  using  push  opposite  operation  moreover  would  good  changed  reference  include  synchronization  use  case  documentation  syncope700  involves  creating  pull  task  assign  matching  request  example  user  pulled  ldap  also  automatically  assigned  ldap  resource,0,1,0,1,0,0,0,1,1,1,1,0,0,0,0,1,1
6843,allow  admins  force  user  password  change  next  login  admin  console  lack  capability  force  user  change  password  next  login  operation  accessible  either  single  user  bulk  operation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6844,use  kendo  ui  boostrap  datetimepicker  replace  actual  bootstrap  datetimepicker  component  wicket  720  doesnt  support  java  date  format  see  syncope730  kendo  ui  datetimepicker  httpdemostelerikcomkendouidatetimepickerangular,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6845,show  propagation  task  linked  given  user  group  object  besides  ability  see  propagation  task  given  resource  helpful  provide  direct  link  propagation  task  executed  user  group  object,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6846,allow  user  group  object  admin  form  customization  syncope  12  used  possibility  determine  field  show  order  configuring  admin  console,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,1,1
6847,validate  standalone  resource  provisioning  lot  resource  configured  standalone  distribution  appear  missing  internal  attribute  provisioning  mapping  example  resourceldap  internal  attribute  specified  mapping  postal  click  next  mapping  page  get  error,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6848,editing  realm  select  account  password  policy  combo  box  done  editing  external  resource  security  allow  selecting  account  password  policy  combo  box  editing  realm,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0
6849,allow  optionally  specify  mappingitemtransformer  class  mapping  item  possible  row  mapping  given  objectclass  given  resource  specify  optional  mappingitemtransformer  take  care  transforming  attribute  value  propagation  pull  possible  via  rest  admin  console  allow  yet,1,0,1,0,1,0,0,0,0,0,0,1,0,0,0,0,0
6850,add  deletion  query  across  component  try  delete  user  syncope  console  prompt  pop  asking  really  want  delete  selected  item  however  delete  resourcesconnectorsschema  type  without  prompt  popping  consistency  message  always  appear  deleting  something  ui,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0
6851,allow  capability  override  resource  given  resource  might  override  capability  assigned  underlying  connector  currently  specifiable  via  admin  console,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6852,replace  long  autogenerated  key  uuids  discussed  mailing  listhttpmarkmailorgmessagefhdrwerdwdm3opdx  switch  jpa  entity  currently  set  using  long  autogenerated  key  uuids,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6853,pushpull  task  name  marked  mandatory  console  creating  pushpull  task  console  beside  name  indicating  mandatory  click  next  go  next  screen  see  error  finish  invalidschedtask  standard  javaxvalidationconstraintsnotnullmessage  think  destination  realm  pull  mode  also  marked  mandatory  pull  task,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0
6854,allow  specify  template  logic  action  realm  add  possibility  specify  template  select  logic  action  realm  detail,1,1,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0
6855,allow  specify  user  group  object  filter  push  task  allow  specify  user  group  object  filter  push  task,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6856,use  actual  pagination  resource  explore  feature  introduced  syncope789  us  wicket  ajaxdatatable  dataprovider  requires  pagination  implementation  total  number  item  show  known  upfront  unfortunately  result  resourceservicelistconnobjects  cannot  contain  information  due  way  underlying  search  implemented  connid  moment  console  code  store  item  100  maximum  temporary  protection  memory  paginates  natural  suboptimal  required  provide  different  wicket  component  ideally  listview  provide  full  pagination  feature  next  prev  button  adherent  underlying  data,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
6857,associate  notification  task  related  notification  currently  notificationmanager  generates  notificationtask  instance  defined  notification  instance  given  condition  generated  however  link  notification  notificationtask  connection  useful  trace  task  notification  see  given  notification  became  effective,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6858,single  websocketbehavior  per  page  discussed  wicket  user  mailing  listhttpmarkmailorgmessagebjtquixggo5klviu  needed  current  wicket  release  720  consolidate  various  websocketbehavior  instance  added  several  widget  namely  approvalswidget  jobwidget  reconciliationwidget  single  instance  added  basepage  selectively  embed  logic  currently  implemented  various  instance,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6859,allow  configure  group  type  extension  add  option  given  group  specify  additional  class  assigned  user  object  membership  group  referenced  type  extension,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1
6860,use  gzip  compression  default  since  syncope705  possible  optionally  configure  client  library  transparently  support  gzip  contentencoding  enable  default  client  application  console  enduser  cli,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6861,include  provision  information  virschemato  currently  virschemato  report  related  provision  uuid  would  make  sense  report  instead  external  resource  anytype  pair  console  side  editing  virtual  schema  might  also  improved  autocompletion  external  attribute  name,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
6862,add  title  per  wizard  step  usergroupanyobject  add  title  per  wizard  step  usergroupanyobject,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6863,synchronization  token  management  enhancement  case  error  overall  logic  synchronization  12  incremental  pull  20  process  summarized  invoke  underlying  connector  getlatestsynctoken  invoke  underlying  connector  sync  store  value  getlatestsynctoken  subsequent  invocation  consequence  one  synchronizing  item  syncdelta  generates  error  whole  process  might  interrupted  without  saving  updated  sync  token  next  invocation  start  beginning  without  considering  successful  item  passed  error  occurred  process  changed  follows  instead  invoke  underlying  connector  getlatestsynctoken  invoke  underlying  connector  sync  syncdelta  temporary  store  related  synctoken  field  store  last  successful  item  synctoken  value  getlatestsynctoken  error  occurred  subsequent  invocation,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,1
6864,jexlbased  transformation  mapping  item  mapping  item  transformer  currently  specified  would  handy  chance  provide  jexlbased  expression  apply  value  propagating  pulling  also  mapping  item  transformer  provided  context  ongoing  operation  moment  value  list  passed,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1
6865,external  resource  bulk  operation  migrate  12  ability  associate  disassociate  user  group  object  external  resource  browsing  given  external  resource,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6866,membership  type  extension  improvement  current  state  group  membership  type  extension  allow  implement  scenario  like  one  attached  picture  eg  let  user  u  assigned  group  g1  g2  g3  including  type  extension  attribute  user  u  three  different  value  a1  g1  a2  g2  a3  g3,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,0,1
6867,remove  list  method  user  group  anyobject  rest  apis  userservice  groupservice  anyobjectservice  provides  list  search  endpoint  former  look  quite  duplicated  latter  improvement  remove  list  adapt  remaining  code  work  search  small  change,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,0
6868,realm  provisioning  realm  introducedhttpscwikiapacheorgconfluencedisplaysyncope5bdiscuss5drealms  main  purpose  set  simpler  neat  approach  internal  security  model  though  least  popular  connid  connector  ldap  active  directory  googleapps  bearing  concept  organizational  unit  user  group  container  extending  realm  capability  match  concept  improve  syncope  capability  handle  complex  scenario,1,0,1,0,1,0,0,0,1,0,1,0,0,0,0,1,1
6869,identity  recertification  identify  recertification  required  many  national  international  standard  like  sox  gxp  etc  idea  implement  one  scheduled  task  filter  user  basing  attribute  example  last  recertification  date  role  move  one  state  certified  assign  one  task  group  responsibility  recertified  user  delete  system  report  report  evidence  user  recertified  certifier  feature  would  also  starting  point  create  account  role  group  recertifications,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6870,log  viewer  provide  ability  view  inspect  core  log  admin  console,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0
6871,allow  reference  username  group  object  name  search  parameter  several  search  clause  require  user  group  object  key  value  eg  uuid  value  difficult  handle  human  improve  search  feature  transparently  allowing  insertion  username  group  object  name  besides  key,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6872,consolidate  camel  processor  task  consolidate  camel  processor  currently  lot  duplicate  functionality  spread  different  processor  user  group  etc  task  focus  consolidating  single  implementation  per  operation,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0
6873,introduce  new  camel  propagation  component  task  introduce  new  camel  propagation  component  instead  camel  processor  instance  handle  individual  usecase  itll  make  route  bit  compact  easier  read,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6874,allow  domain  selection  swagger  ui  currently  possible  select  one  defined  domain  hence  master  assumed  performing  rest  call  via  swagger  ui,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0
6875,use  java  8  language  feature  java  8  minimum  requirement  21  codebase  scanned  making  profit  java  8  language  feature  might  eventually  lead  remove  commonslang3  commonscollections4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1
6876,optionally  provide  schema  information  attribute  value  searching  user  group  object  via  rest  currently  option  specify  detail  flag  false  username  plain  derived  attribute  returned  true  also  virtual  attribute  role  relationship  membership  included  moreover  attributeshttpsgithubcomapachesyncopeblob20xcommonlibsrcmainjavaorgapachesyncopecommonlibtoattrtojaval86  returned  alongside  sole  meta  information  related  schema  defined  readonly  detail  flag  used  additionally  indicate  true  full  information  attribute  schema  returned  together  value,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1
6877,leave  webapplicationexception  default  processing  discussed  mailing  listhttpslistsapacheorgthreadhtmla15ab3f335a9eb27a15482789c351bf3ddb694558961975bc39b0fa53cdevsyncopeapacheorg3e  currently  code  restserviceexceptionmapperjava  never  going  invoked  cxf  runtime  simplest  safer  option  moment  remove  code,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0
6878,provide  realm  management  enduser  add  wicket  endpoint  listing  existing  realm  optional  usage  realmservicejshttpsgithubcomapachesyncopeblob20xclientendusersrcmainresourcesmetainfresourcesappjsservicesrealmservicejs,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0
6879,allow  scripted  customizations  core  customized  several  wayshttpsyncopeapacheorgdocsreferenceguidehtmlcustomizationcore  customizations  require  written  java  class  generally  good  requires  redeploy  made  effective  unless  class  reloading  mechanism  place  jrebel  leveraging  groovy  could  overcome  limitation  allow  write  customizations  immediately  available  execution  runtime  implemented  core  feature  require  editing  capability  added  console  ide  plugins,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,1,1
6880,method  check  token  expired  would  like  check  token  expired  invalid  either  wrong  expired  think  make  sense  add  method  syncopeuser  hastokenexpired,1,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0
